{"highlight":{"page10":{},"page32":{"328":{"boxes":[175.33520000000001,170.63263999999995,366.5648,14.346720000000005,595.32,841.92],"refs":[[0,287,"Do đó trong bước này sẽ thực hiện loại bỏ một câu nếu có độ tương tự lớn hơn 0.8 với câu nào đó đứng trước nó, theo thứ tự vị trí trong văn bản"]]},"330":{"boxes":[119.06,648.19264,204.53000000000003,14.346720000000005,595.32,841.92],"refs":[[0,289,"Giải thuật chọn câu theo các bước sau: Bước 1: khởi tạo tâm là truy vấn Bước 2: tính độ tương đồng của các câu trong văn bản với tâm Bước 3: chọn câu có lớn nhất, kết hợp vào tâm, xóa câu đó khỏi văn bản Bước 4: kiểm tra độ dài, nếu chưa đủ, tính toán lại tâm và quay lại bước 2 Tâm của tóm tắt sẽ được tính toán lại dựa trên công thức tính vector trọng tâm của nhóm, và độ tương tự của 1 câu với tâm sẽ là độ tương tự với vector đó"]]}},"page11":{},"page33":{"332":{"boxes":[119.06,98.75263999999996,159.63,14.346720000000005,595.32,841.92],"refs":[[0,290,"*) Véc tơ trọng tâm của nhóm Giả sử có một tập câu = {s1, s2, ., sm} có lần lượt các véc tơ biểu diễn là v1, v2, ., vm"]]},"334":{"boxes":[143.78,248.15263999999993,103.35,14.346719999999976,595.32,841.92],"refs":[[0,292,"Giai đoạn hiển thị Ở bước này, văn bản tóm tắt sẽ được tạo ra bằng cách ghép các câu được chọn theo thứ tự trong văn bản, đó chính là phương pháp hiển thị phân đoạn"]]}},"page30":{"305":{"boxes":[152.3,204.47263999999998,114.26999999999998,14.346720000000005,595.32,841.92],"refs":[[0,264,"Xử lý từ đồng nghĩa Có 3 loại từ đồng nghĩa cần xét đến: Từ có nghĩa giống nhau hoặc gần giống nhau"]]},"306":{"boxes":[119.06,275.9026399999999,208.01,14.346720000000005,595.32,841.92],"refs":[[0,267,"Từ đồng nghĩa không hoàn toàn Ví dụ: Ăn, xơi, chén, .(biểu thị thái độ, tình cảm khác nhau đối với người đối thoại hoặc điều được nói đến)"]]},"307":{"boxes":[155.06,437.56263999999993,368.08448000000016,14.346720000000005,595.32,841.92],"refs":[[0,268,"Mang, khiêng, vác, .(biểu thị những cách thức hành động khác nhau)"]]},"308":{"boxes":[119.06,461.4426399999999,342.03848000000005,14.346720000000005,595.32,841.92],"refs":[[0,269,"Với loại 1 và loại 2 thì các từ đồng nghĩa có thể thay thế cho nhau"]]},"309":{"boxes":[467.60704,461.4426399999999,74.27232000000026,14.346720000000005,595.32,841.92],"refs":[[0,270,"Còn loại 3 thì phải xét đến ngữ nghĩa của từ trong ngữ cảnh của văn bản, đây có thể coi là bài toán phức tạp nhất trong xử lý ngôn ngữ, hiện nay chưa có nhiều nghiên cứu"]]},"310":{"boxes":[119.06,521.20264,422.82368000000014,14.346720000000005,595.32,841.92],"refs":[[0,271,"Việc xử lý từ đồng nghĩa là rất quan trọng, nhất là trong bài toán tóm tắt hướng truy vấn"]]},"311":{"boxes":[150.11648,539.20264,391.75231999999994,14.346720000000005,595.32,841.92],"refs":[[0,272,"Trong mô hình lần này, do chỉ xử lý ở mức nông, nên không xét đến các vấn đề ở mức cú pháp và ngữ nghĩa, nhưng để tăng độ chính xác, bài toán sẽ sử dụng việc đồng nhất các từ đồng nghĩa(xử lý chung cho cả 3 loại trên) dựa trên từ điển đồng nghĩa thô xây dựng sẵn, bộ từ điển này gồm gần 2800 mục, xây dựng bằng cách dùng công cụ tải các trang của từ điển Việt Việt tại trang tratu.soha.vn, sau đó tách thẻ có chứa các từ đồng nghĩa rồi ghép lại"]]},"312":{"boxes":[321.16664000000003,628.8726399999999,220.73336000000006,14.346720000000005,595.32,841.92],"refs":[[0,273,"Mỗi mục gồm các từ gần nghĩa hoặc đồng nghĩa với nhau về mặt nào đó, và mỗi từ chỉ xuất hiện trong một mục, trên thực tế có những từ có thể ở nhiều mục, nhưng số lượng các từ đó không nhiều nên trong bộ từ điển này sẽ sử dụng nghĩa phổ biến nhất của các từ đó"]]},"313":{"boxes":[388.61368000000004,682.7526399999999,153.28631999999993,14.346720000000005,595.32,841.92],"refs":[[0,274,"Tuy chưa được đầy đủ và xử lý đơn giản nhưng cũng góp phần tăng độ chính xác cho việc tóm tắt"]]},"314":{"boxes":[475.42,700.6326399999999,66.43680000000012,14.346720000000005,595.32,841.92],"refs":[[0,275,"Dưới đây là một số mục từ trong bộ từ đồng nghĩa sẽ sử dụng"]]}},"page31":{"318":{"boxes":[152.3,264.98263999999995,121.82999999999998,14.346720000000005,595.32,841.92],"refs":[[0,278,"Mô hình hóa văn bản Việc cuối cùng trong giai đoạn tiền xử lý là mô hình hóa văn bản, sử dụng mô hình không gian vector"]]},"319":{"boxes":[224.62607999999994,306.50263999999993,317.2633600000001,14.346720000000005,595.32,841.92],"refs":[[0,279,"Tương tự các công thức dùng để mô hình hóa văn bản ở trên, để mô hình hóa câu, ta sử dụng công thức sau TF.ISF, công thức này tương tự như TF.IDF nhưng các thông số ở trong phạm vi câu và văn bản"]]},"320":{"boxes":[413.34376000000003,342.3826399999999,128.55623999999995,14.346720000000005,595.32,841.92],"refs":[[0,280,"Cụ thể mỗi từ tần số của mỗi từ wi trong câu sj được tính như sau: Trong đó: fij là số lần xuất hiện của từ ti trong câu sj, m là tổng số câu trong văn bản hi là tổng số câu mà từ ti xuất hiện"]]},"321":{"boxes":[171.26,535.48264,370.5963200000002,14.346720000000005,595.32,841.92],"refs":[[0,281,"là hệ số đánh giá độ quan trọng của từ, nếu từ xuất hiện trong truy vấn thì >1, còn lại thì =1 Với hệ số cho từ xuất hiện trong truy vấn, trong quá trình kiểm thử trên tập mẫu thì =4 cho kết quả tốt nhất"]]},"323":{"boxes":[152.3,619.6326399999999,170.08999999999997,14.346720000000005,595.32,841.92],"refs":[[0,283,"Chọn câu phù hợp tạo tóm tắt Bước này sẽ áp dụng các giải thuật đánh giá câu quan trọng để đưa vào kết quả tóm tắt"]]},"324":{"boxes":[143.77232000000004,661.1526399999999,398.09792000000004,14.346720000000005,595.32,841.92],"refs":[[0,284,"Để hạn chế hiện tượng trùng lặp thông tin trong kết quả tóm tắt, trước khi đưa vào lựa chọn, các câu sẽ được so sánh với nhau để tìm các câu gần tương tự nhau, và loại bỏ câu có vị trí xa tiêu đề hơn"]]},"325":{"boxes":[295.49,697.0326399999999,246.40999999999997,14.346720000000005,595.32,841.92],"refs":[[0,285,"Độ đo sử dụng để loại bỏ câu trùng lặp và chọn câu phù hợp tạo tóm tắt là độ đo cosin đã trình bày ở trên, nhưng hai vector được tính toán bây giờ là biểu diễn cho hai câu"]]}},"page6":{},"page18":{"126":{"boxes":[117.26,98.93119999999996,165.51,14.528160000000014,595.32,841.92],"refs":[[0,93,"Phương pháp ngữ cố định Các ngữ cố định có đặc điểm thống kê rất tốt"]]},"127":{"boxes":[358.74424000000005,122.75263999999996,183.13032000000004,14.346720000000005,595.32,841.92],"refs":[[0,94,"Sau các ngữ này thường là các câu hay từ có độ quan trọng là xác định"],[7,385,"Sau các cụm từ này thường là các từ hay câu quan trọng"]]},"128":{"boxes":[295.72280000000006,140.63263999999995,246.17708,14.346720000000005,595.32,841.92],"refs":[[0,95,"Người ta chia thành hai loại ngữ cố định, một loại mang lại độ quan trọng cho thành phần đi sau, được gọi là ngữ nhấn mạnh, một loại giúp ta loại bỏ, không xét đến những thành phần đi sau vì nó không có nhiều giá trị trong việc trích rút, được gọi là ngữ dư thừa: Ngữ nhấn mạnh (Bonus phrase - Emphasizer): Ngữ nhấn mạnh gồm các ngữ như nói chung là., đặc biệt là., cuối cùng thì., trong bài viết này tôi muốn chỉ ra., bài viết nói về., nội dung gồm.,..v..v.."]]},"129":{"boxes":[117.26,278.12119999999993,424.6371200000001,14.528159999999957,595.32,841.92],"refs":[[0,96,"Ngữ dư thừa (Stigma phrases): Một số ngữ dư thừa: hiếm khi mà., bài này không nói đến., Không thể nào., ..v..v.."]]},"130":{"boxes":[117.26,320.3612,211.01,14.528159999999957,595.32,841.92],"refs":[[0,97,"Phương pháp thống kê tần suất từ Độ quan trọng của từ phụ thuộc vào số lần xuất hiện của từ đó trong các văn bản liên quan"]]},"131":{"boxes":[153.83855999999997,362.06263999999993,387.9541600000002,14.346720000000005,595.32,841.92],"refs":[[0,98,"Các kỹ thuật như TF.IPF hay Tập thuật ngữ thường xuyên (Frequent Item Set) dùng cho công việc xác định tần suất của từ"]]},"133":{"boxes":[178.82,404.30263999999994,127.71000000000004,14.346720000000005,595.32,841.92],"refs":[[0,100,"Phương pháp cấu trúc Là các phương pháp sử dụng các mối liên hệ cấu trúc - ngữ pháp - ngữ nghĩa để xác định các đơn vị ngữ liệu quan trọng"],[7,389,"b) Phương pháp cấu trúc Các phương pháp này sử dụng các mối liên hệ cấu trúc - ngữ pháp - ngữ nghĩa để xác định các đơn vị ngữ liệu quan trọng"]]},"134":{"boxes":[310.97336,445.84263999999996,230.84912000000014,14.346720000000005,595.32,841.92],"refs":[[0,101,"Tư tưởng chính của các phương pháp này là những đơn vị ngữ liệu nào có chứa các thành phần liên kết nhiều với các thành phần khác sẽ có độ quan trọng lớn"],[7,390,"Tư tưởng chính của các phương pháp này là những đơn vị ngữ liệu nào có chứa các thành phần liên quan nhiều với các thành phần khác sẽ có mức độ quan trọng cao"]]},"135":{"boxes":[259.47319999999996,481.72263999999996,282.4104800000002,14.346720000000005,595.32,841.92],"refs":[[0,102,"Việc đánh giá các mối quan hệ sẽ dựa trên các mạng ngữ nghĩa, các quan hệ cú pháp hoặc thông qua các phương pháp xác định độ liên quan truyền thống"],[7,391,"Việc đánh giá các mối quan hệ sẽ dựa trên các mạng ngữ nghĩa hoặc các quan hệ cú pháp"]]},"136":{"boxes":[119.78,541.3012,422.12,14.528159999999957,595.32,841.92],"refs":[[0,103,"Phương pháp quan hệ lẫn nhau: Phương pháp này xác định mối quan hệ giữa các đoạn trong văn bản hay các câu trong đoạn với nhau thông qua các kỹ thuật thu thập thông tin ở mức văn bản"],[7,392,"- Phương pháp sử dụng quan hệ giữa câu, đoạn Phương pháp này xác định mối quan hệ giữa các đoạn trong văn bản hay các câu trong đoạn với nhau thông qua việc tính toán mức độ liên quan giữa chúng"]]},"137":{"boxes":[275.07416000000006,577.3626399999999,266.80760000000015,14.346720000000005,595.32,841.92],"refs":[[0,104,"Các đoạn (câu) trong văn bản nguồn được tính toán độ liên quan lẫn nhau sử dụng các kỹ thuật như Cosine, TF.IPF hay N-gram Overlap"]]},"138":{"boxes":[99.984,613.2726399999999,265.00888000000003,14.346720000000005,595.32,841.92],"refs":[[0,105,"Sau đó chọn ra đoạn (câu) có độ liên quan lớn nhất"],[7,394,"Sau đó, ta chọn ra đoạn hay câu có độ liên quan lớn nhất"]]},"139":{"boxes":[119.78,637.0912,422.12,14.528159999999957,595.32,841.92],"refs":[[0,106,"Phương pháp liên kết từ vựng: Phương pháp liên kết từ vựng sử dụng các từ điển quan hệ từ vựng đế xây dựng các chuỗi từ liên kết với nhau vể mặt ngữ nghĩa"],[7,395,"+ Phương pháp chuỗi từ vựng (lexical chains) Phương pháp liên kết từ vựng sử dụng các từ điển quan hệ từ vựng để xây dựng các chuỗi từ liên kết với nhau về mặt ngữ nghĩa"]]},"140":{"boxes":[99.984,673.1526399999999,363.07024,14.346720000000005,595.32,841.92],"refs":[[0,107,"Ví dụ cây là một loại thực vật, có bộ phận là lá, chất liệu là gỗ"]]},"142":{"boxes":[418.5138400000001,691.0326399999999,123.3861599999999,14.346720000000005,595.32,841.92],"refs":[[0,109,"Sau khi xây dựng được các chuỗi từ này, đánh giá độ mạnh của chúng và có những trích chọn phù hợp"],[7,398,"8 các từ vựng này, ta đánh giá độ mạnh của chúng và chọn ra những câu phù hợp"]]},"143":{"boxes":[119.78,732.7271999999999,422.09648000000004,14.528159999999957,595.32,841.92],"refs":[[0,110,"Phương pháp Liên kết tham chiếu: Phương pháp liên kết tham chiếu còn được gọi là phương pháp trích chọn trùng lặp (Anaphora-based Method)"]]}},"page5":{},"page19":{"146":{"boxes":[224.05064000000002,74.85263999999998,317.8152799999999,14.346720000000005,595.32,841.92],"refs":[[0,112,"Sau khi phân tách các cụm trùng lặp, chúng ta tạo chuỗi các từ tham chiếu đến cùng một từ được tham chiếu"],[7,402,"Sau khi phân tách các cụm trùng lặp, chúng ta tạo chuỗi các từ (cụm từ) tham chiếu đến cùng một từ được tham chiếu"]]},"147":{"boxes":[355.99,92.75263999999996,185.89368000000013,14.346720000000005,595.32,841.92],"refs":[[0,113,"Chuỗi dài nhất sẽ được coi là trọng tâm của đoạn, các câu chứa các từ trong chuỗi này có một độ ưu tiên nào đó khi xét trích chọn"],[7,403,"Chuỗi dài nhất sẽ được coi là trọng tâm của đoạn, các câu chứa các từ trong chuỗi này có một độ ưu tiên nào đó thì sẽ được chọn"]]},"148":{"boxes":[119.78,152.45119999999994,422.0864,14.528160000000014,595.32,841.92],"refs":[[0,114,"Phương pháp quan hệ câu: Dựa trên các từ thể hiện mối quan hệ giữa các câu chúng ta cấu trúc hóa đoạn văn bản từ các đơn vị thành phần như ngữ, mệnh đề, câu.."]]},"149":{"boxes":[130.9728,188.51263999999995,296.7772,14.346720000000005,595.32,841.92],"refs":[[0,115,"Sau đó đơn vị được coi như trung tâm sẽ được trích chọn"]]},"151":{"boxes":[152.3,212.75263999999996,74.07,14.346720000000005,595.32,841.92],"refs":[[0,117,"Pha Biến đổi Ở pha này, các câu sẽ được biến đổi, làm gọn lại hoặc kết hợp nhiều câu tạo thành câu mới ngắn gọn hơn"]]},"152":{"boxes":[228.71816,254.27263999999994,313.18183999999997,14.346719999999976,595.32,841.92],"refs":[[0,118,"Các phương pháp trong pha này không làm tăng thêm độ chính xác mà chỉ giúp cho văn bản kết quả ngắn gọn hơn mà vẫn sát nghĩa và thuật toán thưởng rất phức tạp"]]},"153":{"boxes":[233.57000000000002,290.1826399999999,121.34,14.346720000000005,595.32,841.92],"refs":[[0,119,"Có thể chia làm 2 loại: 2.7.2.1"]]},"154":{"boxes":[178.82,314.5426399999999,145.85000000000002,14.346720000000005,595.32,841.92],"refs":[[0,120,"Giản lược về cấu trúc câu Giản lược về cấu trúc câu là việc lược bỏ trong câu các phần thừa, ít mang giá trị, làm cho cấu trúc câu thu gọn lại"]]},"155":{"boxes":[276.63608000000005,356.06263999999993,265.15184000000005,14.346720000000005,595.32,841.92],"refs":[[0,121,"Công việc này thường dựa trên phân tích cú pháp các thành phần trong câu"],[7,412,"Công việc này thường dựa trên phân tích cú pháp và phân tích ngữ nghĩa các thành phần trong câu"]]},"157":{"boxes":[178.82,398.30263999999994,157.97000000000003,14.346720000000005,595.32,841.92],"refs":[[0,123,"Giản lược về mặt ngữ nghĩa Phương pháp trừu tượng hóa khái niệm Tư tưởng của phương pháp này là từ các khái niệm cụ thể thay thế bằng khái niệm chung"]]},"158":{"boxes":[119.06,487.72263999999996,274.73,14.346720000000005,595.32,841.92],"refs":[[0,124,"Ví dụ: Tôi ăn dâu, táo và đào => Tôi ăn trái cây Phương pháp thay thế bộ phận Tư tưởng của phương pháp này là từ các khái niệm bộ phận thay thế bằng khái niệm toàn bộ"]]},"160":{"boxes":[117.26,601.5412,239.57,14.528159999999957,595.32,841.92],"refs":[[0,127,"Phương pháp thay thế ngữ tương đương Tư tưởng của phương pháp này là các ngữ đóng vai trò như nhau trong câu được thay bằng một ngữ chung"]]},"161":{"boxes":[119.06,667.2726399999999,422.8116800000002,14.346720000000005,595.32,841.92],"refs":[[0,128,"Ví dụ: Anh ấy bước vào, ngồi xuống ghế, xem thực đơn, gọi món, ăn, trả tiền và ra về => Anh ấy đi ăn tiệm"]]}},"page4":{},"page16":{"94":{"boxes":[152.3,57.21263999999999,143.19,14.346720000000005,595.32,841.92],"refs":[[0,61,"Mô hình tập thô dung sai Mô hình tập thô dung sai (Tolerance Rough Set Model) là một mô hình mới, tiên tiến dựa trên lý thuyết về logic mờ và tập mờ (Fuzzy Set)"]]},"95":{"boxes":[438.84471999999994,98.75263999999996,103.02552000000014,14.346720000000005,595.32,841.92],"refs":[[0,62,"Điều cốt lõi của lý thuyết này là việc xác định chính xác một giả thiết nào đó (ví dụ như hai văn bản này có phù hợp, có giống nhau không...) là một điều rất khó"]]},"96":{"boxes":[400.7260000000001,134.63263999999995,141.17399999999986,14.346720000000005,595.32,841.92],"refs":[[0,63,"Tuy nhiên chúng ta có thể chỉ ra một cặp xấp xỉ trên và xấp xỉ dưới để khẳng định được giả thiết đó là đúng"]]},"97":{"boxes":[524.4937600000002,152.63263999999995,17.406239999999798,14.346720000000005,595.32,841.92],"refs":[[0,64,"Sử dụng các suy diễn hợp lý để xác định và làm đẹp các ngưỡng này"]]},"98":{"boxes":[463.3410400000001,170.51263999999995,78.43392,14.346720000000005,595.32,841.92],"refs":[[0,65,"Các phép toán cơ bản trong mô hình tập thô dựa trên các quan hệ tương đương các tính chất như đối xứng, phản xạ, bắc cầu.."]]},"99":{"boxes":[231.15704000000002,206.39263999999994,310.7429599999999,14.346720000000005,595.32,841.92],"refs":[[0,66,"Lý thuyết logic mờ đã và đang được ứng dụng rất mạnh mẽ trong lĩnh vực Trí tuệ nhân tạo"]]},"100":{"boxes":[119.06,248.27263999999994,422.81408000000016,14.346719999999976,595.32,841.92],"refs":[[0,68,"Tuy nhiên khi áp dụng mô hình tập thô cho quá trình xử lý văn bản thì tính chất bắc cầu không còn phù hợp"]]},"101":{"boxes":[359.57464000000004,284.1826399999999,182.30856000000006,14.346720000000005,595.32,841.92],"refs":[[0,69,"Nhóm tác giả Hồ Tú Bảo, Saori Kawasaki, Nguyễn Ngọc Bình đã đề xuất ra mô hình tập thô dung sai trong đó bỏ đi tính chất bắc cầu trong quá trình xử lý văn bản"]]},"102":{"boxes":[342.53416000000004,320.06263999999993,199.35816,14.346720000000005,595.32,841.92],"refs":[[0,70,"Lý thuyết tập thô được các nhà nghiên cứu Trí tuệ nhân tạo phát triển và ngày càng thể hiện được tính ưu việt không chỉ trong việc biểu diễn và thao tác văn bản mà còn trong các vấn đề khác của lĩnh vực này"]]},"105":{"boxes":[119.78,612.9712,422.12,14.528159999999957,595.32,841.92],"refs":[[0,73,"Biến đổi (Transformation): Lựa chọn các thông tin trích chọn được, biến đổi để giản lược và thống nhất, kết quả là các đơn vị ngữ liệu đã được tóm tắt"]]},"106":{"boxes":[119.78,654.8512,422.1198800000001,14.528159999999957,595.32,841.92],"refs":[[0,74,"Hiển thị (Generation): Từ các đơn vị ngữ liệu đã tóm tắt, liên kết chúng lại thành đoạn theo một thứ tự nào đó hoặc theo cấu kết ngữ pháp rồi hiển thị phù hợp với yêu cầu người dùng"]]},"107":{"boxes":[119.06,714.9126399999999,422.84,14.346720000000005,595.32,841.92],"refs":[[0,75,"Một hệ Tóm lược (Abstraction) bao gồm tất cả các pha trên, tuy nhiên một hệ Trích rút (Extraction) chỉ gồm pha Phân tích và Pha Hiển thị, không có pha biến đổi"]]},"108":{"boxes":[99.264,750.78864,436.1396800000001,14.346720000000005,595.32,841.92],"refs":[[0,76,"Thậm chí trong các pha phân tích và hiển thị, chỉ có một số công đoạn được sử dụng"]]}},"page38":{},"page3":{},"page17":{"111":{"boxes":[257.57336,194.75263999999996,284.3376800000002,14.346720000000005,595.32,841.92],"refs":[[0,78,"Còn hệ Tóm lược thì phức tạp, do kết hợp các phương pháp của xử lý ngôn ngữ tự nhiên"]]},"112":{"boxes":[276.8876,212.75263999999996,265.01228000000003,14.346720000000005,595.32,841.92],"refs":[[0,79,"Vì vậy, kết quả của các hệ Tóm lược thường thuyết phục hơn (về mặt dễ đọc, dễ hiểu, liên kết ngôn ngữ tốt, gần gũi với con người)"]]},"113":{"boxes":[119.06,254.63263999999995,422.84023999999994,14.346719999999976,595.32,841.92],"refs":[[0,80,"Trong mỗi pha có thể áp dụng nhiều kỹ thuật xử lý khác nhau, chi tiết sẽ được trình bày ở phần tiếp theo"]]},"115":{"boxes":[143.78,296.9026399999999,230.33,14.346720000000005,595.32,841.92],"refs":[[0,82,"Các phương pháp áp dụng trong các pha 2.7.1"],[7,101,"Các phương pháp áp dụng trong pha phân tích"],[7,104,"Các phương pháp áp dụng trong pha biến đổi ........................................"],[7,375,"Các phương pháp áp dụng trong pha phân tích"]]},"116":{"boxes":[152.3,320.78263999999996,81.27000000000001,14.346720000000005,595.32,841.92],"refs":[[0,83,"Pha Phân tích Ở pha này văn bản nguồn sẽ được tách thành các đoạn, câu, từ, kết hợp với các thông số đầu vào và áp dụng một số thuật toán cụ thể để chọn ra các đoạn hoặc câu phù hợp làm đầu vào cho pha tiếp theo"]]},"117":{"boxes":[119.06,404.18263999999994,422.78864000000016,14.346720000000005,595.32,841.92],"refs":[[0,84,"Các phương pháp áp dụng trong pha Phân tích được chia thành hai loại: Phương pháp thống kê và Phương pháp cấu trúc"]]},"119":{"boxes":[178.82,446.4426399999999,129.87,14.346720000000005,595.32,841.92],"refs":[[0,86,"Phương pháp thống kê Phương pháp này sử dụng các số liệu thống kê về độ quan trọng của từ, câu hay đoạn, nhận được từ các nghiên cứu về ngôn ngữ học hay thông qua các phương pháp học máy dựa trên tập mẫu để trích rút ra các đơn vị ngữ liệu quan trọng Phương pháp vị trí Phương pháp vị trí bao gồm các phương pháp xác định độ quan trọng dựa trên thống kê về vị trí của từ, ngữ hay câu trong văn bản"]]},"120":{"boxes":[375.89368,571.72264,166.00631999999996,14.346720000000005,595.32,841.92],"refs":[[0,88,"Chủ đề - Tiêu đề (Title-based): Chủ đề các đoạn văn bản hay tiêu đề các bảng thường chứa các từ và ngữ quan trọng, nên trích rút thông tin từ đây"]]},"121":{"boxes":[117.26,655.3312,424.63988000000006,14.528159999999957,595.32,841.92],"refs":[[0,89,"Đầu - cuối đoạn (First - Last Sentence): Xác suất câu đầu đoạn hay câu cuối đoạn chứa ý chính của cả đoạn là rất lớn, đặc biệt là câu đầu đoạn"],[7,381,"7 + Câu ở đầu hoặc cuối đoạn: xác suất câu đầu đoạn hay câu cuối đoạn chứa ý chính của cả đoạn là rất lớn, đặc biệt là câu đầu đoạn"]]},"122":{"boxes":[489.80992000000003,673.5126399999999,52.034400000000005,14.346720000000005,595.32,841.92],"refs":[[0,90,"Ngoài ra, các đoạn đầu và cuối trong văn bản cũng quan trọng hơn các đoạn giữa"],[7,382,"Ngoài ra các đoạn đầu và cuối văn bản cũng quan trọng hơn các đoạn giữa"]]},"123":{"boxes":[117.26,715.2112,424.64023999999995,14.528159999999957,595.32,841.92],"refs":[[0,91,"Minh họa - Chú thích (Comments): Trong các câu chú thích, câu minh họa cho ảnh hay đồ thị thường chứa các thông tin quan trọng"],[7,383,"+ Minh hoạ, chú thích: trong các câu chú thích, câu minh hoạ cho ảnh hay đồ thị thường chứa các thông tin quan trọng"]]}},"page39":{},"page2":{},"page14":{"65":{"boxes":[348.07,56.85263999999998,193.82999999999998,14.346720000000005,595.32,841.92],"refs":[[0,33,"Tóm tắt hướng truy vấn được cài đặt và áp dụng nhiều hơn nhưng trong lĩnh vực hẹp hơn, đi sâu vào các chuyên ngành cụ thể"]]},"67":{"boxes":[143.78,117.11263999999997,152.43000000000004,14.346720000000005,595.32,841.92],"refs":[[0,35,"Mô hình biểu diễn văn bản Văn bản thông thường là dạng dữ liệu phi cấu trúc, do vậy muốn xử lý chúng trước hết phải biểu diễn thành dạng có cấu trúc"]]},"68":{"boxes":[355.94584000000003,158.63263999999995,185.94504,14.346720000000005,595.32,841.92],"refs":[[0,36,"Các cấu trúc này phải có khả năng thao tác bằng các phép toán cơ bản như cộng, nhân, đại số quan hệ.."]]},"69":{"boxes":[461.37328,176.51263999999995,80.46864000000016,14.346720000000005,595.32,841.92],"refs":[[0,37,"Có ba mô hình thỏa mãn yêu cầu đó thường được sử dụng là: 2.5.1"]]},"70":{"boxes":[152.3,218.75263999999996,97.22999999999999,14.346720000000005,595.32,841.92],"refs":[[0,38,"Mô hình boolean Trong mô hình boolean, văn bản, vốn là tập hợp của các term (thuật ngữ), được biểu diễn bởi chỉ số từng term và trọng số của chúng"]]},"71":{"boxes":[379.5988000000001,260.3026399999999,162.28488000000004,14.346720000000005,595.32,841.92],"refs":[[0,39,"Trọng số của từng term - dùng để đánh giá độ quan trọng của chúng - trong mô hình này chỉ mang hai giá trị 0 và 1, tùy theo sự xuất hiện của term đó trong văn bản"]]},"72":{"boxes":[171.26,369.62263999999993,269.08712,14.347680000000025,595.32,841.92],"refs":[[0,40,"Trong đó wi là trọng số của term ti trong văn bản D"]]},"73":{"boxes":[119.06,393.62263999999993,422.84,14.346720000000005,595.32,841.92],"refs":[[0,41,"Đối với vấn đề truy vấn, trong mô hình này câu truy vấn bao gồm các văn bản tìm kiếm liên hệ với nhau thông qua các phép đại số quan hệ cơ bản như NOT (phủ định), AND (và) hay OR (hoặc)"]]},"74":{"boxes":[270.64328000000006,429.50263999999993,271.2566,14.346720000000005,595.32,841.92],"refs":[[0,42,"Câu truy vấn có thể biểu diễn thành dạng vector với các thành phần liên kết và các phép toán quan hệ cơ bản"]]},"75":{"boxes":[402.65992000000006,447.4026399999999,139.24007999999992,14.346720000000005,595.32,841.92],"refs":[[0,43,"Từ đây, độ liên quan giữa một văn bản và truy vấn được xác định thông qua các thành phần liên kết"]]},"76":{"boxes":[499.15936000000005,465.4026399999999,42.72432000000009,14.346720000000005,595.32,841.92],"refs":[[0,44,"Độ liên quan này chỉ có thể mang hai giá trị : 0 văn bản không phù hợp với truy vấn và 1 văn bản phù hợp"]]},"77":{"boxes":[119.06,525.16264,422.84,14.346720000000005,595.32,841.92],"refs":[[0,45,"Do vậy có thể thấy rằng hạn chế lớn nhất của mô hình này đó là việc đánh giá độ liên quan chỉ trả về hai kết quả, hoặc phù hợp hoặc không, như vậy yêu cầu của hệ thống khi cần sắp xếp và chọn lựa các văn bản theo mức độ liên quan đến truy vấn sẽ không đạt"]]},"78":{"boxes":[158.52272000000002,579.0426399999999,383.35615999999993,14.346720000000005,595.32,841.92],"refs":[[0,46,"Độ liên quan của mô hình này không thể phân chia thành các mức khác nhau, do vậy không phản ánh được thực tế là việc liên quan giữa văn bản và truy vấn có thể là mờ, không chắn chắn"]]},"79":{"boxes":[262.2308,614.95264,279.63608000000016,14.346720000000005,595.32,841.92],"refs":[[0,47,"Hạn chế này được loại bỏ khi ta sử dụng một mô hình tổng quát hơn Mô hình không gian vector (VSM)"]]},"81":{"boxes":[152.3,657.19264,153.63,14.346720000000005,595.32,841.92],"refs":[[0,49,"Mô hình không gian vector Như trên đã đề cập, mô hình không gian vector là mô hình tổng quát hơn mô hình Boolean"]]},"82":{"boxes":[148.22688000000005,698.71264,393.6568000000001,14.346720000000005,595.32,841.92],"refs":[[0,50,"Các văn bản được biểu diễn thành các vector nhiều chiều, với trọng số không chỉ mang hai giá trị là 0 hay 1 mà có thể mang các giá trị khác tùy theo cách đánh giá, tính toán"]]},"83":{"boxes":[151.56480000000002,734.5886399999999,390.31600000000014,14.346720000000005,595.32,841.92],"refs":[[0,51,"Một khác biệt nữa so với mô hình boolean là các phép toán cơ bản của mô hình không gian vector"]]}},"page36":{"354":{"boxes":[143.78,57.21263999999999,144.03,14.346720000000005,595.32,841.92],"refs":[[0,309,"Thử nghiệm một văn bản Phần này em sử dụng công cụ tóm tắt đã xây dựng để thử nghiệm một văn bản"]]},"355":{"boxes":[99.264,98.75263999999996,192.74599999999998,14.346720000000005,595.32,841.92],"refs":[[0,310,"Kết quả thực hiện thu được như sau: 2.2.1"]]},"356":{"boxes":[146.66,123.11263999999997,49.110000000000014,14.346720000000005,595.32,841.92],"refs":[[0,311,"Đầu vào Văn bản: Bảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình{1} Chiều ngày 26-4, Chủ tịch nước Trương Tấn Sang và Tổ Đại biểu Quốc hội (ĐBQH) số 1, Đoàn ĐBQH TP Hồ Chí Minh tiếp tục có buổi tiếp xúc với gần 400 cử tri của quận 1{2}"]]},"357":{"boxes":[198.08624,230.39263999999994,343.7136800000003,14.346720000000005,595.32,841.92],"refs":[[0,312,"Ghi nhận các ý kiến của cử tri, Chủ tịch nước đánh giá cao tinh thần đóng góp ý kiến của mọi người, nhất là vấn đề sửa đổi Hiến Pháp và các đạo luật{3}"]]},"358":{"boxes":[143.7488,266.3026399999999,398.1512,14.346720000000005,595.32,841.92],"refs":[[0,313,"Trả lời câu hỏi được đông đảo cử tri quan tâm về chủ trương bảo vệ chủ quyền lãnh thổ, củng cố quốc phòng - an ninh, Chủ tịch nước Trương Tấn Sang khẳng định chủ trương của Đảng, Nhà nước trước sau như một là kiên quyết bảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình, theo hệ thống luật pháp quốc tế{4}"]]},"360":{"boxes":[99.264,373.9426399999999,442.63623999999993,14.346720000000005,595.32,841.92],"refs":[[0,315,"Nước ta cũng mua sắm trang bị vũ khí, nhưng không phải để gây chiến tranh, chạy đua vũ trang mà là tăng cường phòng thủ, bảo vệ chủ quyền lãnh thổ{6}"]]},"361":{"boxes":[493.4089600000001,391.9426399999999,48.48191999999983,14.346720000000005,595.32,841.92],"refs":[[0,316,"Chủ tịch nước cho biết, chủ trương hòa hiếu luôn được các nước bạn bè trên thế giới ủng hộ{7}"]]},"363":{"boxes":[180.46928,487.60263999999995,361.43071999999995,14.346720000000005,595.32,841.92],"refs":[[0,318,"Những mâu thuẫn trên Biển Đông là có, nhưng biện pháp hòa hiếu của nước ta đã có kết quả tốt, Nhà nước luôn hỗ trợ ngư dân ra khơi, số lượng tàu cá đánh bắt xa bờ ngày càng tăng{9}"]]},"364":{"boxes":[299.65352000000007,523.48264,242.2464799999999,14.346720000000005,595.32,841.92],"refs":[[0,319,"Nước ta phấn đấu đến năm 2020 sẽ phát triển kinh tế biển đạt 52%-53% GDP, trong đó, dầu khí, vận tải biển, đánh bắt hải sản là thế mạnh lớn{10}"]]},"365":{"boxes":[197.42576,559.3626399999999,344.46511999999996,14.346720000000005,595.32,841.92],"refs":[[0,320,"Mục tiêu cuối cùng của nước ta là chủ quyền lãnh thổ vững chắc, quốc phòng - an ninh ổn định, kinh tế phát triển{11}"]]},"366":{"boxes":[119.06,601.2426399999999,422.8073600000001,14.346720000000005,595.32,841.92],"refs":[[0,321,"Liên quan đến các vấn đề kinh tế - xã hội, Chủ tịch nước Trương Tấn Sang cho biết kinh tế nước nhà có những phát triển đáng kể, nông nghiệp đạt nhiều thắng lợi, các ngành thuộc về dầu khí tăng trưởng khá{12}"]]}},"page1":{},"page15":{"86":{"boxes":[273.25976,116.75263999999996,268.64023999999995,14.346720000000005,595.32,841.92],"refs":[[0,54,"Truy vấn là kết quả của các phép toán vector giữa các vector biểu diễn cho những văn bản cấu thành nên truy vấn, như vậy, truy vấn trong trường hợp này cũng là một văn bản đặc biệt"]]},"87":{"boxes":[371.57320000000004,152.63263999999995,170.32679999999993,14.346720000000005,595.32,841.92],"refs":[[0,55,"Việc xác định độ liên quan giữa truy vấn và văn bản được quy thành độ liên quan giữa văn bản và văn bản"]]},"88":{"boxes":[497.48656000000005,170.51263999999995,44.37504000000001,14.346720000000005,595.32,841.92],"refs":[[0,56,"Hai văn bản là hai vector, vậy khoảng cách hay góc giữa chúng đều có thể đại diện cho sự liên quan giữa hai văn bản này"]]},"89":{"boxes":[243.09896,206.39263999999994,298.80104000000006,14.346720000000005,595.32,841.92],"refs":[[0,57,"Tất nhiên, để áp dụng được các phép toán vector cơ bản, hai vector cần chuẩn hóa về số chiều (độ dài)"]]},"90":{"boxes":[119.06,248.27263999999994,229.97000000000003,14.346719999999976,595.32,841.92],"refs":[[0,58,"Các chỉ số sử dụng trong phương pháp này: Tần suất thuật ngữ của một từ w trong một văn bản d, ký hiệu TF(w,d), có thể sử dụng các công thức sau, với fij là số lần xuất hiện của từ wi trong văn bản dj: Tần suất văn bản của một từ w, ký hiệu DF(w) là số lượng văn bản mà từ w có xuất hiện"]]},"91":{"boxes":[171.9728,392.06263999999993,369.92719999999997,14.346720000000005,595.32,841.92],"refs":[[0,59,"Nghịch đảo của tần suất văn bản của một từ w, ký hiệu IDF(w) được cho bởi công thức: Trong đó: m là tổng số văn bản,, h là số văn bản chứa từ w Tần suất TF-IDF là kết hợp của hai loại tần suất nói trên: TF-IDF(w,d) = TF(w,d) * IDF(w) Theo mô hình này, mỗi văn bản sẽ được biểu diễn dưới dạng D(t1, t2,.,tn) với n là tổng số thuật ngữ xuất hiện, mỗi thuật ngữ sẽ được đánh index, ti là trọng số của thuật ngữ thứ i(trong danh sách thuật ngữ) trong văn bản D"]]},"92":{"boxes":[410.33128000000005,583.72264,131.56871999999993,14.346720000000005,595.32,841.92],"refs":[[0,60,"Khi đó độ liên quan giữa hai văn bản biểu diễn bởi 2 vector X(x1, x2, ., xn) và Y(y1, y2,.,yn) được tính bằng công thức Cosin: 2.5.3"]]}},"page37":{"370":{"boxes":[146.66,81.23263999999998,90.99000000000001,14.346720000000005,595.32,841.92],"refs":[[0,313,"Trả lời câu hỏi được đông đảo cử tri quan tâm về chủ trương bảo vệ chủ quyền lãnh thổ, củng cố quốc phòng - an ninh, Chủ tịch nước Trương Tấn Sang khẳng định chủ trương của Đảng, Nhà nước trước sau như một là kiên quyết bảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình, theo hệ thống luật pháp quốc tế{4}"]]},"372":{"boxes":[119.06,266.3026399999999,422.79248000000024,14.346720000000005,595.32,841.92],"refs":[[0,315,"Nước ta cũng mua sắm trang bị vũ khí, nhưng không phải để gây chiến tranh, chạy đua vũ trang mà là tăng cường phòng thủ, bảo vệ chủ quyền lãnh thổ{6}"]]},"373":{"boxes":[119.06,308.1826399999999,422.81984000000006,14.346720000000005,595.32,841.92],"refs":[[0,316,"Chủ tịch nước cho biết, chủ trương hòa hiếu luôn được các nước bạn bè trên thế giới ủng hộ{7}"]]},"374":{"boxes":[119.06,350.06263999999993,422.84023999999994,14.346720000000005,595.32,841.92],"refs":[[0,318,"Những mâu thuẫn trên Biển Đông là có, nhưng biện pháp hòa hiếu của nước ta đã có kết quả tốt, Nhà nước luôn hỗ trợ ngư dân ra khơi, số lượng tàu cá đánh bắt xa bờ ngày càng tăng{9}"]]},"375":{"boxes":[119.06,409.9426399999999,422.82512000000014,14.346720000000005,595.32,841.92],"refs":[[0,320,"Mục tiêu cuối cùng của nước ta là chủ quyền lãnh thổ vững chắc, quốc phòng - an ninh ổn định, kinh tế phát triển{11}"]]}},"page0":{},"page12":{"32":{"boxes":[128.05424,143.39263999999994,286.85576000000003,14.346720000000005,595.32,841.92],"refs":[[0,1,"Cụ thể bài toán cần giải quyết được phát biểu như sau: Đầu vào: Văn bản, truy vấn, độ rút gọn Đầu ra: Bản tóm tắt của văn bản đầu vào xoay quanh vấn đề nêu trong truy vấn Để giải quyết được bài toán này, việc trước hết là tìm hiểu cơ sở lý thuyết về tóm tắt văn bản, tóm tắt hướng truy vấn, từ đó xác định hướng giải quyết và thực hiện cài đặt thử nghiệm"]]},"34":{"boxes":[140.9,275.18035999999995,318.11,15.542280000000005,595.32,841.92],"refs":[[0,3,"TỔNG QUAN VỀ TÓM TẮT VĂN BẢN TỰ ĐỘNG 2.1"],[7,86,"2 CHƯƠNG 1: TỔNG QUAN VỀ TÓM TẮT VĂN BẢN ........................................"]]},"35":{"boxes":[143.78,300.74263999999994,65.07000000000002,14.346720000000005,595.32,841.92],"refs":[[0,4,"Định nghĩa Tóm tắt văn bản là quá trình làm giảm độ dài, độ phức tạp của văn bản mà vẫn giữ lại được nội dung quan trọng của văn bản đó"]]},"36":{"boxes":[359.80696000000006,342.2626399999999,182.09303999999992,14.346720000000005,595.32,841.92],"refs":[[0,5,"Công việc tóm tắt văn bản đã xuất hiện từ rất lâu đời, và nó được làm thủ công, do con người đọc, rút ra các ý chính rồi trình bày lại một cách ngắn gọn, dễ hiểu"]]},"37":{"boxes":[312.98744000000005,378.1426399999999,228.85928000000018,14.346720000000005,595.32,841.92],"refs":[[0,6,"Mục đích là giúp người sử dụng có cái nhìn tổng quan về nội dung trình bày trong văn bản, để quyết định sử dụng văn bản đó hợp lý"]]},"38":{"boxes":[116.04719999999999,414.0226399999999,425.8528,14.346720000000005,595.32,841.92],"refs":[[0,7,"Tuy nhiên với lượng văn bản nhiều và dài thì việc làm thủ công vô cùng tốn thời gian, công sức"]]},"39":{"boxes":[119.06,455.92263999999994,422.8400000000001,14.346720000000005,595.32,841.92],"refs":[[0,8,"Ngày nay, thời đại công nghệ thông tin phát triển mạnh, tóm tắt văn bản tự động (gọi tắt là tóm tắt văn bản) được nghiên cứu phát triển nhằm mục đích làm thay con người công việc nặng nhọc đó"]]},"40":{"boxes":[263.42456000000004,491.80263999999994,278.3326400000001,14.346720000000005,595.32,841.92],"refs":[[0,9,"Đã có rất nhiều định nghĩa được đưa ra, tuy nhiên có thể sử dụng định nghĩa ngắn gọn sau: Tóm tắt văn bản là quá trình rút ra những thông tin quan trọng nhất từ một hay nhiều nguồn văn bản để tạo ra một văn bản gọn hơn phục vụ cho một số nhiệm vụ hay người dùng cụ thể 2.2"]]},"41":{"boxes":[143.78,593.92264,120.27000000000001,14.346720000000005,595.32,841.92],"refs":[[0,10,"Các tiêu chí đánh giá Độ mạch lạc (Coherence): đánh giá mức độ rõ ràng của văn bản tóm tắt, tính súc tích, khả năng có thể đọc và hiểu được của bài viết"],[7,435,"10 Các tiêu chí đánh giá: - Độ mạch lạc (Coherence): đánh giá mức độ rõ ràng của văn bản tóm tắt, tính súc tích, khả năng có thể đọc và hiểu được của bài viết… - Độ hàm chứa thông tin (Informationess): tỉ lệ thông tin của văn bản gốc trong văn bản tóm tắt"]]},"42":{"boxes":[119.78,701.0512,422.12,14.528159999999957,595.32,841.92],"refs":[[0,12,"Độ liên quan (Relevance): xác định mức độ phù hợp của văn bản tóm tắt với chủ đề cho trước (chủ đề có thể là một câu truy vấn)"],[7,436,"- Độ liên quan (Relevance): xác định mức độ phù hợp của văn bản tóm tắt với chủ đề cho trước (chủ đề có thể là một câu truy vấn)"]]}},"page34":{"338":{"boxes":[143.78,82.55263999999991,147.15,14.346720000000005,595.32,841.92],"refs":[[0,295,"Chương trình thử nghiệm Để thực hiện thử nghiệm em đã xây dựng một số công cụ phục vụ tóm tắt 1 văn bản, công cụ tạo mẫu và công cụ kiểm thử trên mẫu: - Môi trường cài đặt: Java JDK 7u17, Windows 7 32bit"]]},"339":{"boxes":[117.26,171.7712,179.63592000000006,14.528160000000014,595.32,841.92],"refs":[[0,296,"- Công cụ lập trình Netbeans 7.3"]]},"341":{"boxes":[146.66,196.31264000000002,142.10999999999999,14.346720000000005,595.32,841.92],"refs":[[0,298,"Các công cụ đã xây dựng 2.1.1.1"]]},"342":{"boxes":[167.42,220.19264,123.39000000000001,14.346720000000005,595.32,841.92],"refs":[[0,299,"Chương trình tóm tắt Đây là chương trình thực hiện tóm tắt một văn bản dựa trên giải thuật đã phân tích ở trên"]]},"343":{"boxes":[158.42000000000002,261.74263999999994,376.9851200000002,14.346720000000005,595.32,841.92],"refs":[[0,300,"Chi tiết các chức năng đã ghi chú đầy đủ trên ảnh giao diện chương trình"]]},"344":{"boxes":[99.264,279.74263999999994,442.6235200000001,14.346720000000005,595.32,841.92],"refs":[[0,301,"Đầu vào của chương trình là văn bản gốc, truy vấn, và độ rút gọn, đầu ra sẽ là văn bản tóm tắt, có thể xem chi tiết một số bước xử lý ở chức năng Note góc dưới trái giao diện"]]},"346":{"boxes":[167.42,628.0326399999999,118.83000000000001,14.346720000000005,595.32,841.92],"refs":[[0,303,"Công cụ tạo tập mẫu Công cụ này hỗ trợ, tạo, chỉnh sửa các bản tóm tắt thủ công"]]},"347":{"boxes":[436.84456000000006,651.67264,105.01704000000012,14.346720000000005,595.32,841.92],"refs":[[0,304,"Chức năng chính là quản lý các văn bản mẫu bao gồm văn bản gốc và bản tóm tắt thủ công, được tích hợp chức năng tách từ, tách câu của VNTokenizer nên việc tạo văn bản mẫu sẽ chính xác và hiệu quả hơn"]]},"348":{"boxes":[208.73,705.43264,333.16999999999996,14.346720000000005,595.32,841.92],"refs":[[0,305,"Ngoài ra còn có chức năng phát hiện ra các văn bản lỗi font, các văn bản này không thể sử dụng trong các công cụ đi kèm nên cần loại bỏ"]]}},"page13":{"46":{"boxes":[143.78,117.11263999999997,172.47,14.346720000000005,595.32,841.92],"refs":[[0,15,"Ứng dụng của tóm tắt văn bản Tóm tắt văn bản có nhiều ứng dụng trong thực tế, một số ứng dụng nổi bật như: Tóm tắt tự động các tin tức trên báo điện tử"]]},"47":{"boxes":[135.26,188.33119999999994,289.0725600000003,14.528160000000014,595.32,841.92],"refs":[[0,16,"Trợ giúp thông minh việc đọc và khai thác thông tin"]]},"48":{"boxes":[135.26,212.33119999999994,286.8188,14.528160000000014,595.32,841.92],"refs":[[0,17,"Tóm lược danh sách tìm kiếm từ các Search Engine"]]},"49":{"boxes":[135.26,236.21119999999993,295.35032,14.528160000000014,595.32,841.92],"refs":[[0,18,"Giản lược nội dung trình bày cho các thiết bị cầm tay"]]},"50":{"boxes":[135.26,260.24119999999994,270.17,14.528159999999957,595.32,841.92],"refs":[[0,19,"Sinh tự động chủ đề, tiêu đề, dẫn đường văn bản"]]},"51":{"boxes":[135.26,284.12119999999993,406.48424000000045,14.528159999999957,595.32,841.92],"refs":[[0,20,"Hỗ trợ tóm lược nội dung cuộc họp, website, chương trình phát thanh và truyền hình, sổ tay công việc"]]},"53":{"boxes":[143.78,326.54263999999995,146.67,14.346720000000005,595.32,841.92],"refs":[[0,22,"Phân loại tóm tắt văn bản Có nhiều cách phân loại tóm tắt, phụ thuộc vào tiêu chí sử dụng để phân loại, sau đây là một số cách phân loại cần quan tâm: 2.4.1"],[2,15,"Phân loại tóm tắt văn bản: Có rất nhiều cách phân loại tóm tắt văn bản"]]},"54":{"boxes":[152.3,392.42263999999994,129.63,14.346720000000005,595.32,841.92],"refs":[[0,23,"Theo đầu vào hệ thống Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn gọn của văn bản đó"],[4,112,"Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn ngọn của văn bản đó"],[8,28,"Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn ngọn của văn bản đó"]]},"55":{"boxes":[119.65007999999999,433.9426399999999,422.24980000000005,14.346720000000005,595.32,841.92],"refs":[[0,24,"Ngược lại, tóm tắt đa văn bản là từ nhiều văn bản nguồn cũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng thời cho nhiều văn bản khác nhau"],[4,113,"Ngược lại tóm tắt đa văn bản là từ một văn bản nguồn cũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng thời cho nhiều văn bản khác nhau"],[8,29,"Ngược lại tóm tắt đa văn bản là từ một văn bản nguồn cũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng thời cho nhiều văn bản khác nhau"]]},"56":{"boxes":[281.65592000000004,469.84263999999996,260.1180800000003,14.346720000000005,595.32,841.92],"refs":[[0,25,"Rõ ràng, tóm tắt đa văn bản thì khó hơn, vì ngoài những công việc của tóm tắt đơn văn bản, tóm tắt đa văn bản còn phải thực hiện các công việc như tiền xử lý trích rút, tích hợp thống nhất khuôn dạng và hiển thị kết quả theo cách riêng"]]},"57":{"boxes":[184.57968000000002,523.60264,357.30639999999994,14.346720000000005,595.32,841.92],"refs":[[0,26,"Ngoài ra, tóm tắt đa văn bản còn phải đối mặt với các vấn đề như dư thừa trùng lặp dữ liệu giữa các văn bản nguồn, nội dung các văn bản nguồn phân tán, độ rút gọn yêu cầu cao, thời gian xử lý cần phải nhanh trong khi sự phức tạp trong xử lý lớn"]]},"59":{"boxes":[152.3,601.72264,122.43,14.346720000000005,595.32,841.92],"refs":[[0,28,"Theo đầu ra hệ thống Tóm tắt trích rút là quá trình thu gọn văn bản mà trong kết quả ra chứa các đơn vị ngữ liệu văn bản nguồn"]]},"60":{"boxes":[243.53,643.2726399999999,298.3162400000002,14.346720000000005,595.32,841.92],"refs":[[0,29,"Tóm tắt tóm lược là quá trình thu gọn văn bản mà trong kết quả ra có một số các đơn vị ngữ liệu mới được sinh ra từ các đơn vị ngữ liệu văn bản nguồn"]]},"62":{"boxes":[152.3,703.5126399999999,128.91000000000003,14.346720000000005,595.32,841.92],"refs":[[0,31,"Theo mục đích tóm tắt Tóm tắt chung là tóm tắt theo quan điểm ban đầu của tác giả văn bản gốc"]]},"63":{"boxes":[514.06,727.0326399999999,27.825120000000084,14.346720000000005,595.32,841.92],"refs":[[0,32,"Tóm tắt hướng truy vấn là tóm tắt theo quan điểm mong muốn của người dùng ứng dụng thông qua các tham số truyền vào câu truy vấn"]]}},"page35":{"351":{"boxes":[167.42,361.22263999999996,102.39000000000001,14.346720000000005,595.32,841.92],"refs":[[0,307,"Công cụ kiểm thử Công cụ này được xây dựng dựa trên việc tích hợp giải thuật đã đề xuất ở trên và tích hợp thêm hai giải thuật để so sánh, việc so sánh dựa trên độ đo BLEUS, chi tiết về cách thực hiện sẽ trình bày ở phần sau"]]}},"page9":{},"page8":{},"page7":{},"page21":{"183":{"boxes":[152.3,57.21263999999999,141.02999999999997,14.346720000000005,595.32,841.92],"refs":[[0,149,"Sử dụng so khớp n-gram Phương pháp này được Lin và Hovy đưa ra năm 2002 dựa trên mô hình n-gram của độ đo BLEU (Bilingual Evaluation Understudy [1], độ đo đánh giá kết quả dịch máy)"]]},"184":{"boxes":[132.48368000000002,116.75263999999996,409.4163199999999,14.346720000000005,595.32,841.92],"refs":[[0,150,"Ý tưởng của phương pháp này là so khớp n-gram liên tiếp của bản tóm tắt thủ công và tóm tắt tự động, theo công thức sau: Score=1*Score1+ 2*Score2+ 3*Score3+ 4*Score4 Trong đó: Scorei = Số i-gram trùng nhau/Tổng số i-gram của bản tóm tắt thủ công i là hệ số đánh giá độ quan trọng của các Scorei 2.8.2"]]},"185":{"boxes":[152.3,254.75263999999996,155.91000000000003,14.346719999999976,595.32,841.92],"refs":[[0,151,"Sử dụng các độ đo ROUGE ROUGE(Recall-Oriented Understudy of Gisting Evaluation [2]) cũng được đưa ra bởi Lin, vào năm 2009, đây là tập hợp các độ đo dựa trên mô hình n-gram của BLEU với nhiều cách tính khác nhau"]]},"186":{"boxes":[297.73760000000004,314.1826399999999,244.16239999999993,14.346720000000005,595.32,841.92],"refs":[[0,152,"Thường sử dụng nhất là độ đo ROUGE-N, với n là giá trị của mô hình n-gram, n={1,2,3,4}"]]},"187":{"boxes":[119.06,356.06263999999993,422.83988000000005,14.347680000000025,595.32,841.92],"refs":[[0,153,"Công thức của độ đo ROUGE-N như sau: Cho R=(r1, r2, ., rn) là tập các tóm tắt mẫu, s là tóm tắt tự động, n(d) là vector biểu diễn mô hình n-gram của văn bản d"]]},"190":{"boxes":[143.78,486.7626399999999,234.77,14.346720000000005,595.32,841.92],"refs":[[0,156,"Một số hệ thống tóm tắt văn bản tiêu biểu Hiện tại, trên thế giới đã có rất nhiều nghiên cứu và dự án xây dựng các ứng dụng tóm tắt văn bản"]]},"191":{"boxes":[185.54336,528.2826399999999,349.75376000000006,14.346720000000005,595.32,841.92],"refs":[[0,157,"Các ứng dụng này có thể đáp ứng rất nhiều các mục đích khác nhau"]]},"192":{"boxes":[99.264,546.16264,341.206,14.346720000000005,595.32,841.92],"refs":[[0,158,"Có thể kể ra một số ứng dụng Tóm tắt văn bản tiêu biểu như sau: SUMMARIST: Một hệ thống Trích rút văn bản năm thứ tiếng (tiếng Anh, tiếng Nhật, tiếng Tây Ban Nha, tiếng Ả-rập và tiếng Hàn Quốc)"]]},"193":{"boxes":[495.32464,588.0426399999999,46.57535999999999,14.346720000000005,595.32,841.92],"refs":[[0,159,"Hiện tại SUMMARIST đang nghiên cứu để cải tiến trở thành một hệ thống Tóm lược văn bản và hỗ trợ nhiều ngôn ngữ hơn như tiếng Pháp và Indonesia"]]},"194":{"boxes":[117.26,647.7712,424.64,14.528159999999957,595.32,841.92],"refs":[[0,160,"SweSUM: Ứng dụng Tóm tắt văn bản đa ngôn ngữ của Học viện công nghệ hoàng gia Thụy Điển"]]},"195":{"boxes":[251.89736,665.83264,290.0026400000001,14.346720000000005,595.32,841.92],"refs":[[0,161,"SweSUM có thể tóm tắt các văn bản có ngôn ngữ vùng Scandinavi như Thụy Điển, Đan Mạch, Na Uy và các ngôn ngữ khác như tiếng Anh, Pháp, Đức, Tây Ban Nha và cả tiếng Iran"]]}},"page22":{"198":{"boxes":[409.9474400000001,74.85263999999998,131.9525599999999,14.346720000000005,595.32,841.92],"refs":[[0,163,"SumUM có thể thực hiện cả chức năng tóm tắt chỉ định và tóm tắt thông tin rất tốt."]]},"199":{"boxes":[117.26,116.57119999999995,424.6001600000002,14.528160000000014,595.32,841.92],"refs":[[0,164,"FJCL: Hệ thống Rút trích văn bản tiếng Nhật được phát triển trong phòng nghiên cứu Ikeda của trường đại học Gifu"]]},"200":{"boxes":[363.62632000000013,134.63263999999995,178.24295999999975,14.346720000000005,595.32,841.92],"refs":[[0,165,"Đây là một hệ thống sử dụng các phương pháp áp dụng cho hệ ngôn ngữ đơn âm tiết (monosyllabic language system) như tiếng Nhật, Hàn Quốc, Trung Quốc và Việt Nam"]]},"201":{"boxes":[117.26,194.33119999999994,424.63988000000006,14.528160000000014,595.32,841.92],"refs":[[0,166,"Pertinence Summarizer: Hệ thống tóm tắt tin tức đa ngôn ngữ trực tuyến nổi tiếng"]]},"202":{"boxes":[167.41376,212.39263999999994,374.48623999999995,14.346720000000005,595.32,841.92],"refs":[[0,167,"Hiện tại để thử nghiệm khả năng của mình, Pertinence đã được tích hợp với Google và tóm tắt tự động danh sách tìm kiếm trả về từ Google thông qua câu truy vấn đưa vào"]]},"203":{"boxes":[247.69352,248.27263999999994,294.1232,14.346719999999976,595.32,841.92],"refs":[[0,168,"Chúng ta có thể thử nghiệm hệ thống này trên trang web: www.pertinence.net"]]},"204":{"boxes":[117.26,290.0011999999999,417.98432,14.528159999999957,595.32,841.92],"refs":[[0,169,"MEAD: Nền tảng cho các hệ thống Tóm tắt nhiều văn bản và đa ngôn ngữ"]]},"205":{"boxes":[135.26,308.1826399999999,406.64,14.346720000000005,595.32,841.92],"refs":[[0,170,"Đây là một bộ công cụ xây dựng trên nền Linux và Solaris, sử dụng ngôn ngữ Perl - Một ngôn ngữ có khả năng xử lý văn bản rất linh hoạt và mạnh mẽ"]]},"206":{"boxes":[135.26,344.06263999999993,406.53224000000034,14.346720000000005,595.32,841.92],"refs":[[0,171,"MEAD biểu diễn, lưu trữ dữ liệu ở dạng XML, cung tấp cho chúng ta khung ứng dụng để cài đặt các ứng dụng Tóm tắt văn bản cho ngôn ngữ mà ta muốn"]]},"207":{"boxes":[135.26,379.9426399999999,406.6241600000001,14.346720000000005,595.32,841.92],"refs":[[0,172,"Ngoài ra MEAD cũng cung cấp các công cụ để xây dựng các ứng dụng đánh giá hệ thống tóm tắt theo các tiêu chí và các tập mẫu nổi tiếng"]]},"208":{"boxes":[470.48656000000005,397.8226399999999,71.41367999999989,14.346720000000005,595.32,841.92],"refs":[[0,173,"MEAD được xây dựng bởi các chuyên gia nổi tiếng về Xử lý ngôn ngữ ở khắp nơi trên thế giới dưới sự tài trợ của Chương trình Nghiên cứu Công nghệ thông tin của Tổ chức Khoa học quốc gia Mỹ"]]},"209":{"boxes":[290.17736,451.72263999999996,251.72263999999996,14.346720000000005,595.32,841.92],"refs":[[0,174,"MEAD được cung cấp ở dạng mã nguồn mở để nghiên cứu và kế thừa"]]},"210":{"boxes":[263.9228,469.60263999999995,277.916,14.346720000000005,595.32,841.92],"refs":[[0,175,"Hiện tại phiên bản mới nhất của MEAD là MEAD v3.07"]]},"211":{"boxes":[117.26,511.3012,424.6155200000003,14.528159999999957,595.32,841.92],"refs":[[0,176,"Microsoft Word AutoSummary: Microsoft cũng cài đặt chức năng Trích rút và sinh tiêu đề trong Microsoft Word từ phiên bản Word '97"]]},"212":{"boxes":[456.28408,529.48264,85.61591999999996,14.346720000000005,595.32,841.92],"refs":[[0,177,"Chúng ta có thể thử bằng cách chọn Tools - AutoSummarize trên thanh công cụ (có thể khác tùy vào phiên bản)"]]},"213":{"boxes":[241.34552000000002,565.3626399999999,300.54968,14.346720000000005,595.32,841.92],"refs":[[0,178,"Công cụ này cho phép chúng ta chọn thông số về độ rút gọn, trích rút hay sinh tiêu đề.."]]},"214":{"boxes":[119.06,607.2426399999999,422.7125600000002,14.346720000000005,595.32,841.92],"refs":[[0,179,"Ngoài ra còn các hệ thống Tóm tắt văn bản nổi tiếng khác như ANES hay SUMMONS"]]},"215":{"boxes":[171.37344000000002,625.1526399999999,370.5299200000001,14.346720000000005,595.32,841.92],"refs":[[0,180,"Tuy nhiên tại Việt Nam hiện nay chưa có một nghiên cứu và ứng dụng Tóm tắt văn bản chính thức nào"]]}},"page41":{},"page20":{"164":{"boxes":[448.8124,74.85263999999998,93.08760000000007,14.346720000000005,595.32,841.92],"refs":[[0,130,"Điều này thường thông qua một từ điển các từ đồng nghĩa (Thesaurus)"]]},"165":{"boxes":[117.26,116.93119999999996,207.77000000000004,14.528160000000014,595.32,841.92],"refs":[[0,131,"Phương pháp thay thế bởi đại diện Tư tưởng của phương pháp này là thay thế một ngữ bằng một ngữ khác có ý nghĩa đại diện cho ngữ ban đầu"]]},"166":{"boxes":[119.06,182.51263999999995,422.7694400000001,14.346720000000005,595.32,841.92],"refs":[[0,132,"Ví dụ: Người phát ngôn viên của chính phủ Hoa Kỳ thông báo"]]},"169":{"boxes":[178.82,248.75263999999996,186.29000000000002,14.346719999999976,595.32,841.92],"refs":[[0,136,"Phương pháp hiển thị phân đoạn Đây là phương pháp đơn giản nhất"]]},"170":{"boxes":[309.39608000000004,272.3026399999999,232.50391999999994,14.346720000000005,595.32,841.92],"refs":[[0,137,"Các đơn vị ngữ liệu được trích rút hay giản lược từ các pha trước được liên kết lại thành đoạn theo thứ tự tiền định của chúng, không thêm bớt từ nối và cũng không sắp xếp lại các đơn vị ngữ liệu"],[7,420,"Các phương pháp trong pha tổng hợp kết quả a) Phương pháp hiển thị phân đoạn Các đơn vị ngữ liệu được trích xuất hay giản lược từ các pha trước được liên kết lại thành đoạn theo đúng thứ tự trong văn bản gốc, không thêm bớt từ nối và cũng không sắp xếp lại"]]},"171":{"boxes":[474.4528,308.1826399999999,67.44708000000003,14.346720000000005,595.32,841.92],"refs":[[0,138,"Văn bản kết quả của phương pháp này có độ dễ đọc dễ hiểu kém, thậm chí lủng củng về nghĩa vì các đơn vị ngữ liệu được trích rút mắc phải một số lỗi như mập mờ tham chiếu, không có từ nối hoặc là thừa từ và ngữ"],[7,421,"Văn bản kết quả của phương pháp này có độ dễ đọc và dễ hiểu kém, thậm chí lủng củng vì các đơn vị ngữ liệu có thể bị mập mờ tham chiếu, không có từ nối hoặc thừa từ"]]},"173":{"boxes":[178.82,386.30263999999994,168.17000000000002,14.346720000000005,595.32,841.92],"refs":[[0,140,"Phương pháp hiển thị liên kết Việc hiển thị liên kết là tiếp nhận các đơn vị ngữ liệu đã được trích rút và giản lược từ các pha trước đó, phân tích mối quan hệ về nghĩa của các câu rồi thêm bớt các từ nối, từ dẫn và sắp xếp theo một thứ tự mới dựa vào những gì đã thu thập sao cho thỏa mãn yêu cầu về hiển thị và yêu cầu về độ dễ đọc, dễ hiểu của người dùng"]]},"175":{"boxes":[143.78,488.0826399999999,141.51000000000002,14.346720000000005,595.32,841.92],"refs":[[0,142,"Đánh giá kết quả tóm tắt Đánh giá một bản tóm tắt là một công việc khó bởi không tồn tại một bản tóm tắt lý tưởng cho một (hoặc một tập) văn bản đưa ra"],[7,425,"Các phương pháp đánh giá Đánh giá một bản tóm tắt là một công việc khó bởi không tồn tại một bản tóm tắt lý tưởng cho một (hoặc một tập) văn bản đưa ra"]]},"176":{"boxes":[363.29944,529.60264,178.56024000000025,14.346720000000005,595.32,841.92],"refs":[[0,143,"Hơn nữa, việc đánh giá nội dung tóm tắt cũng rất khó khăn"],[7,426,"Hơn nữa, việc đánh giá nội dung tóm tắt cũng rất khó khăn"]]},"177":{"boxes":[239.48143999999996,547.48264,302.3859200000002,14.346720000000005,595.32,841.92],"refs":[[0,144,"Trường hợp kết quả là một câu trả lời cho một câu hỏi, ta có thể xác định được câu trả lời đó đúng hay sai, nhưng trong các trường hợp khác, thật khó trả lời liệu đầu ra là phải một kết quả đúng hay không"],[7,427,"Trường hợp kết quả là một câu trả lời cho một câu hỏi, ta có thể xác định được câu trả lời đó đúng hay sai, nhưng trong các trường hợp khác, thật khó trả lời liệu đầu ra là phải một kết quả đúng hay không"]]},"178":{"boxes":[434.3768800000002,583.3626399999999,107.52311999999978,14.346720000000005,595.32,841.92],"refs":[[0,145,"Thực tế luôn có khả năng một hệ thống sinh ra một bản tóm tắt tốt nhưng lại sai khác với bản tóm tắt do người thực hiện"],[7,428,"Thực tế luôn có khả năng một hệ thống sinh ra một bản tóm tắt tốt nhưng lại sai khác với bản tóm tắt do người thực hiện"]]},"179":{"boxes":[187.33376,619.2726399999999,354.5235200000002,14.346720000000005,595.32,841.92],"refs":[[0,146,"Bên cạnh đó, khi việc đánh giá được thực hiện bởi con người thì chi phí đánh giá sẽ rất cao"],[7,429,"Bên cạnh đó, khi việc đánh giá được thực hiện bởi con người thì chi phí đánh giá sẽ rất cao"]]},"180":{"boxes":[220.24184000000002,637.2726399999999,321.65816000000007,14.346720000000005,595.32,841.92],"refs":[[0,147,"Mặt khác, tóm tắt văn bản còn liên quan đến tỉ lệ nén văn bản, do đó, việc đánh giá bản tóm tắt cần phải quan tâm đến vấn đề này, khi đó độ phức tạp và chi phí đánh giá sẽ tăng cao"],[7,430,"Mặt khác, tóm tắt văn bản còn liên quan đến tỉ lệ nén văn bản, do đó, việc đánh giá bản tóm tắt cần phải quan tâm đến vấn đề này, khi đó độ phức tạp và chi phí đánh giá sẽ tăng cao"]]},"181":{"boxes":[119.06,697.3926399999999,356.22992,14.346720000000005,595.32,841.92],"refs":[[0,148,"Dưới đây là hai phương pháp đánh giá tự động thường sử dụng: 2.8.1"]]}},"page42":{},"page40":{},"page29":{"290":{"boxes":[119.06,290.3026399999999,422.81120000000004,14.346720000000005,595.32,841.92],"refs":[[0,249,"Đây là công cụ tách từ tự động cho tiếng Việt, mã nguồn mở, được viết bằng ngôn ngữ Java"]]},"291":{"boxes":[153.36272000000002,308.3026399999999,388.50464000000005,14.346720000000005,595.32,841.92],"refs":[[0,250,"Phiên bản cũ nhất là phiên bản vnTokenizer 2.0 được xây dựng vào năm 2005 khi đó nó mới là một ứng dụng đơn với giao diện đơn giản"]]},"292":{"boxes":[446.81656000000004,326.18263999999994,95.0685600000001,14.346720000000005,595.32,841.92],"refs":[[0,251,"Để sử dụng trong chương trình lần này, phiên bản mới nhất 4.1.1c, mã nguồn của công cụ được tải tại website của dự án VLSP [6]"]]},"293":{"boxes":[119.06,386.06263999999993,422.84,14.346720000000005,595.32,841.92],"refs":[[0,252,"Công cụ này được xây dựng sử dụng kết hợp từ điển (từ điển tiếng Việt được lấy từ đề tài VLSP) và ngram, trong đó mô hình ngram được huấn luyện sử dụng treebank tiếng Việt (70,000 câu đã được tách từ), treebank là kho ngữ liệu câu được chú giải ngữ pháp"]]},"294":{"boxes":[119.06,463.84263999999996,422.84,14.346720000000005,595.32,841.92],"refs":[[0,253,"Với độ chính xác xấp xỉ 97% (theo thống kê của tác giả trên website) là kết quả rất cao so với công cụ tách từ hiện nay"]]},"295":{"boxes":[119.06,505.72263999999996,422.8400000000001,14.346720000000005,595.32,841.92],"refs":[[0,254,"Ngoài ra việc tách câu khá đơn giản nhưng cần xử lý các trường hợp nhập nhằng dấu chấm câu và dấu chấm trong từ(trong email, số thập phân, địa chỉ web)"]]},"296":{"boxes":[506.0032,523.60264,35.873280000000136,14.346720000000005,595.32,841.92],"refs":[[0,255,"Do đó để tiết kiệm thời gian, việc tách câu trong phần này sử dụng luôn modul tách câu trong công cụ VNTokenizer"]]},"298":{"boxes":[152.3,583.84264,92.91,14.346720000000005,595.32,841.92],"refs":[[0,258,"nó có ý nghĩa lớn trong một số phương pháp dựa trên dấu hiệu đặc biệt, nhưng trong phương pháp dựa trên tần số từ đang xét thì các từ này làm giảm độ chính xác"]]},"299":{"boxes":[314.08376000000004,661.2726399999999,227.7999200000001,14.346720000000005,595.32,841.92],"refs":[[0,259,"Trong giải thuật này chủ yếu dựa trên trọng số từ nên việc loại bỏ từ dừng là rất cần thiết"]]},"300":{"boxes":[119.06,703.1526399999999,422.84,14.346720000000005,595.32,841.92],"refs":[[0,260,"Từ dừng sẽ được loại bỏ nhờ một danh sách từ dừng xây dựng sẵn, tham khảo tại [7], sau khi tách từ, các từ xuất hiện trong từ điển từ dừng sẽ bị xóa"]]},"301":{"boxes":[454.06,721.0326399999999,87.83987999999994,14.346720000000005,595.32,841.92],"refs":[[0,261,"Dưới đây là một số từ dừng trích trong file sẽ sử dụng"]]}},"page27":{"271":{"boxes":[144.38,82.31035999999993,307.55,15.542279999999991,595.32,841.92],"refs":[[0,231,"PHÂN TÍCH MÔ HÌNH THỰC HIỆN BÀI TOÁN Dựa vào các kiến thức về tóm tắt văn bản đã trình bày ở trên, trong phần này em sẽ trình bày chi tiết các kỹ thuật áp dụng trong từng bước của mô hình xử lý đã đề xuất"]]}},"page28":{"275":{"boxes":[146.66,81.23263999999998,64.35000000000002,14.346720000000005,595.32,841.92],"refs":[[0,234,"Chuẩn hóa Xử lý câu tiêu đề Câu tiêu đề của một văn bản (nếu có) thường mang nội dung chính trình bày trong văn bản, do đó các từ khóa trong đó cũng được dùng để phát hiện tóm tắt (một số giải thuật còn tăng trọng số cho những từ xuất hiện trong tiêu đề), nhưng không đưa câu tiêu đề vào kết quả tóm tắt, nên cần phát hiện để loại bỏ khỏi kết quả"]]},"276":{"boxes":[462.92368,182.51263999999995,78.97631999999999,14.346720000000005,595.32,841.92],"refs":[[0,235,"Việc phát hiện câu tiêu đề có thể dựa vào dấu hiệu câu tiêu đề là câu duy nhất của đoạn đầu tiên"]]},"277":{"boxes":[99.264,218.39263999999994,442.63588000000004,14.346720000000005,595.32,841.92],"refs":[[0,236,"Trong giải thuật này chỉ sử dụng câu tiêu đề như câu thông thường, sau đó loại khỏi kết quả (nếu nó được chọn vào kết quả)"]]},"278":{"boxes":[117.26,260.48119999999994,180.51,14.528159999999957,595.32,841.92],"refs":[[0,237,"Xử lý các cụm từ trong ngoặc Các cụm từ trong ngoặc có thể là chú thích hoặc viết tắt của cụm từ nào đó, nếu là chú thích thì có thể bỏ qua còn từ viết tắt thì khá quan trọng, nhất là đối với tóm tắt hướng truy vấn"]]},"279":{"boxes":[119.06,344.06263999999993,412.04,14.346720000000005,595.32,841.92],"refs":[[0,238,"Ví dụ: Sinh viên tình nguyện(SVTN) đi đến các vùng sâu để giúp đỡ đồng bào Các câu sau câu này sẽ sử dụng cụm từ SVTN, nếu truy vấn có từ khóa sinh viên tình nguyện thì các câu sử dụng từ viết tắt sẽ không được quan tâm"]]},"280":{"boxes":[119.06,409.9426399999999,422.82368000000014,14.346720000000005,595.32,841.92],"refs":[[0,239,"Việc xử lý từ viết tắt không đơn giản là phát hiện các từ trong ngoặc, tùy từng loại văn bản của chuyên ngành nào đó, các từ viết tắt vẫn được sử dụng mà không gây hiểu lầm cho người đọc, vì trong các lĩnh vực ấy nó chỉ có thể thay thế cho cụm từ cố định nào đó, hoặc do thói quen, sử dụng nhiều thì mọi người đều biết"]]},"281":{"boxes":[119.06,487.72263999999996,345.32,14.346720000000005,595.32,841.92],"refs":[[0,240,"Ví dụ: UBND thường được dùng thay thế cho Ủy ban nhân dân Trong giải thuật này chỉ xử lý các cụm từ viết tắt chữ đầu trong ngoặc đơn, còn các trường hợp khác do chưa xây dựng được bộ dữ liệu cụ thể nên không xét đến"]]},"282":{"boxes":[99.264,547.48264,238.32680000000005,14.346720000000005,595.32,841.92],"refs":[[0,241,"Các cụm từ trong ngoặc đơn khác sẽ bị xóa đi"]]},"284":{"boxes":[152.3,571.84264,99.87,14.346720000000005,595.32,841.92],"refs":[[0,243,"Tách câu, tách từ Trong tiếng Việt, dấu cách (space) không được sử dụng như 1 kí hiệu phân tách từ, nó chỉ có ý nghĩa phân tách các âm tiết với nhau, có khoảng 70% các từ gồm 2 âm tiết, và 14% các từ gồm 3 âm tiết, còn lại là 1 âm tiết"]]},"285":{"boxes":[382.37656000000004,631.2726399999999,159.48023999999998,14.346720000000005,595.32,841.92],"refs":[[0,244,"Hơn nữa, việc kết hợp các âm tiết có nhiều cách, mỗi cách cho một nghĩa khác nhau"]]},"286":{"boxes":[381.9965600000002,649.2726399999999,159.88088,14.346720000000005,595.32,841.92],"refs":[[0,245,"Vì thế, để xử lý tiếng Việt, bài toán tách từ (word segmentation) là 1 trong những bài toán cơ bản và quan trọng bậc nhất"]]},"287":{"boxes":[128.42,685.1526399999999,413.45216000000005,14.346720000000005,595.32,841.92],"refs":[[0,247,"do đó vấn đề này nhận được sự quan tâm rộng rãi và có nhiều hướng tiếp cận khác nhau"],[0,246,"Ngoài tiếng Việt, có khá nhiều các ngôn ngữ châu Á khác cũng cần bước tách từ, ví dụ như: tiếng Nhật, tiếng Trung, tiếng Hàn,"]]}},"page25":{"253":{"boxes":[374.3183200000001,56.85263999999998,167.5816799999999,14.346720000000005,595.32,841.92],"refs":[[0,215,"Do đó có một số ràng buộc với dữ liệu đầu vào"]]},"254":{"boxes":[119.06,98.75263999999996,422.84,14.346720000000005,595.32,841.92],"refs":[[0,216,"Vì văn bản đã được máy tìm kiếm lựa chọn nên nội dung của văn bản và truy vấn sẽ liên quan với nhau"]]},"255":{"boxes":[220.17008,116.75263999999996,321.66272000000026,14.346720000000005,595.32,841.92],"refs":[[0,217,"Do đó các câu chứa nhiều từ khóa trong truy vấn, hay trong trường hợp này là độ tương đồng lớn, sẽ mang các thông tin quan trọng liên quan đến truy vấn mà người dùng quan tâm"]]},"256":{"boxes":[281.89448,152.63263999999995,260.00552,14.346720000000005,595.32,841.92],"refs":[[0,218,"Tuy nhiên trong vấn đề tìm kiếm, phần lớn người dùng thường không nắm rõ được nội dung mình muốn biết nên mới sử dụng tìm kiếm, mà chỉ biết các từ khóa liên quan tới vấn đề đó"]]},"257":{"boxes":[350.5573600000001,188.51263999999995,191.32344000000006,14.346720000000005,595.32,841.92],"refs":[[0,219,"Ví dụ như tìm kiếm thông tin về giá vàng, người ta không biết giá vàng tăng hay giảm, có biến động gì gần đây"]]},"258":{"boxes":[490.8688,206.39263999999994,51.01152000000019,14.346720000000005,595.32,841.92],"refs":[[0,220,"Hoặc tìm cách sửa một lỗi máy tính thì người dùng sẽ đưa ra các thông tin về lỗi đó, sau khi xem bản tóm tắt của các kết quả từ máy tìm kiếm, sẽ biết được kết quả nào phù hợp để quyết định đọc hay không"]]},"259":{"boxes":[119.06,284.1826399999999,422.84,14.346720000000005,595.32,841.92],"refs":[[0,221,"Trong giải thuật chọn câu, các câu được chọn sẽ được thêm vào truy vấn, với mục đích làm thêm từ khóa liên quan đến truy vấn"]]},"260":{"boxes":[349.62280000000004,302.1826399999999,192.22200000000004,14.346720000000005,595.32,841.92],"refs":[[0,222,"Nhưng không phải từ nào trong các câu đó cũng đều quan trọng nên các từ xuất hiện trong truy vấn gốc được nhân lên một trọng số"]]},"261":{"boxes":[180.97328000000005,338.06263999999993,360.92671999999993,14.346720000000005,595.32,841.92],"refs":[[0,223,"Do đó kết quả tóm tắt sẽ ưu tiên các từ khóa trong truy vấn, và các từ khóa xuất hiện nhiều trong các câu được chọn"]]},"262":{"boxes":[341.81080000000003,355.9426399999999,200.05656000000005,14.346720000000005,595.32,841.92],"refs":[[0,224,"Theo đó thì bản tóm tắt sẽ dễ hiểu hơn vì bao gồm các thông tin liên quan tới truy vấn"]]},"263":{"boxes":[119.06,397.8226399999999,174.99,14.346720000000005,595.32,841.92],"refs":[[0,225,"Tổng quan về modul đó như sau: Đầu vào - Văn bản: văn bản đầu vào sử dụng bộ mã Unicode utf-8, chỉ chứa text, chính xác về chính tả, dấu câu, không quá ngắn(5 câu trở lên), nội dung phải liên quan tới truy vấn"]]},"264":{"boxes":[117.26,505.4212,424.6342400000001,14.528159999999957,595.32,841.92],"refs":[[0,226,"- Truy vấn: sử dụng bộ mã như văn bản, là một đoạn văn bản chứa các từ khóa cần tìm kiếm, nếu cần chính xác thì dùng dấu phảy để ngăn cách các từ khóa - Độ rút gọn: có thể là số lượng từ (100-150 từ) hoặc phần trăm văn bản nguồn (10-20%)"]]}},"page26":{"267":{"boxes":[117.26,134.45119999999994,146.55,14.528160000000014,595.32,841.92],"refs":[[0,228,"Đầu ra: văn bản tóm tắt Chi tiết các kỹ thuật sử dụng trong các bước sẽ trình bày ở phần sau"]]}},"page23":{"218":{"boxes":[140.9,56.97035999999991,343.06999999999994,15.542279999999998,595.32,841.92],"refs":[[0,182,"BÀI TOÁN TÓM TẮT VĂN BẢN HƯỚNG TRUY VẤN 3.1"]]},"219":{"boxes":[143.78,82.55263999999991,65.07000000000002,14.346720000000005,595.32,841.92],"refs":[[0,183,"Định nghĩa Theo định nghĩa ở trên, tóm tắt văn bản hướng truy vấn là một dạng tóm tắt văn bản (khi phân chia theo mục đích tóm tắt), điểm đặc trưng là ở giai đoạn tiền xử lý, việc tính toán sẽ phụ thuộc một phần vào truy vấn người dùng"]]},"221":{"boxes":[143.78,166.31264000000002,129.87000000000003,14.346720000000005,595.32,841.92],"refs":[[0,185,"Ứng dụng của bài toán Tóm tắt hướng truy vấn thường sử dụng trong việc tóm tắt kết quả trả về của máy tìm kiếm thông tin, hoặc trong các hệ thống hỏi đáp tự động"]]},"222":{"boxes":[119.06,231.83264,422.83088000000004,14.346720000000005,595.32,841.92],"refs":[[0,186,"Hiện nay, đối với máy tìm kiếm, hệ thống sẽ tóm tắt văn bản theo tóm tắt đơn văn bản thông thường, lưu vào cơ sở dữ liệu, và thực hiện tìm kiếm trên bản tóm tắt đó để giảm thời gian tìm kiếm"]]},"223":{"boxes":[249.2828,267.74263999999994,292.61719999999997,14.346720000000005,595.32,841.92],"refs":[[0,187,"Sau khi xác định được văn bản phù hợp, văn bản đó sẽ được tóm tắt lại theo truy vấn người dùng để đưa ra hiển thị kèm với kết quả"]]},"224":{"boxes":[499.17376,285.62263999999993,42.72623999999996,14.346720000000005,595.32,841.92],"refs":[[0,188,"Đối với hệ thống hỏi đáp tự động, hệ thống sẽ tiến hành phân loại câu hỏi và thực hiện so khớp hoặc tính tương đồng với câu hỏi trong cơ sở dữ liệu để xác định câu trả lời phù hợp nhất, sau đó tóm tắt văn bản chứa câu trả lời, sử dụng câu trả lời như truy vấn, và hiển thị kèm với câu trả lời, có đánh dấu câu trả lời"]]},"225":{"boxes":[119.06,381.3826399999999,422.84,14.346720000000005,595.32,841.92],"refs":[[0,189,"Tóm lại, tóm tắt hướng truy vấn thường được tích hợp ở giai đoạn xử lý kết quả của hệ thống tìm kiếm thông tin và hỏi đáp tự động, mục đích là thêm thông tin để kết quả rõ ràng và dễ hiểu hơn với người dùng 3.3"]]},"226":{"boxes":[143.78,441.5226399999999,178.73,14.346720000000005,595.32,841.92],"refs":[[0,190,"Một số hướng tiếp cận phổ biến 3.3.1"]]},"227":{"boxes":[152.3,465.5226399999999,88.71000000000001,14.346720000000005,595.32,841.92],"refs":[[0,191,"Dựa trên đồ thị Phương pháp này được đưa ra bởi [3] Jagadeesh và đồng sự, áp dụng cho tóm tắt trích rút đa văn bản"]]},"228":{"boxes":[205.58744000000002,507.0426399999999,336.30056000000013,14.346720000000005,595.32,841.92],"refs":[[0,192,"Đồ thị của văn bản sẽ được xây dựng dựa trên việc phân tích các câu trong đó để tìm ra các cụm danh từ(noun phrases), sau đó phân tích các cụm danh từ này để tìm ra mối quan hệ giữa các danh từ sử dụng các hàm heuristic"]]},"229":{"boxes":[485.54824000000013,542.92264,56.33832000000001,14.346720000000005,595.32,841.92],"refs":[[0,193,"Đồ thị thu được sẽ bao gồm 2 dạng nút, nút thành phần(là các danh từ trích rút từ văn bản) và nút liên kết, có 2 loại nút liên kết là isa(là một) và related_to(liên quan với)"]]},"230":{"boxes":[119.06,602.68264,422.8515200000001,14.346720000000005,595.32,841.92],"refs":[[0,194,"Sau khi xây dựng đồ thị cho mỗi câu, chúng sẽ được kết hợp để tạo đồ thị cho toàn văn bản"]]},"231":{"boxes":[170.76416,620.71264,371.11376,14.346720000000005,595.32,841.92],"refs":[[0,195,"Một thuật toán tìm kiếm sẽ được sử dụng để tìm các câu quan trọng đưa vào tóm tắt"]]},"232":{"boxes":[164.16656,638.59264,163.38344,14.346720000000005,595.32,841.92],"refs":[[0,196,"Có 3 giải thuật có thể áp dụng: - Dựa trên tâm các đồ thị: một đồ thị trung tâm cho tất cả văn bản được xây dựng, tích hợp thêm đồ thị của truy vấn"]]}},"page24":{"236":{"boxes":[152.3,158.99263999999997,160.23000000000002,14.346720000000005,595.32,841.92],"refs":[[0,199,"Dựa trên cấu trúc diễn ngôn Phương pháp này được trình bày bởi W"]]},"237":{"boxes":[335.33416,182.51263999999995,206.54520000000014,14.346720000000005,595.32,841.92],"refs":[[0,200,"Bosma [4], mục đích là tạo ra bản tóm tắt ngắn gọn chứa câu trả lời để đưa ra kết quả trong hệ thống hỏi đáp tự động"]]},"238":{"boxes":[506.98336000000006,200.51263999999995,34.91424000000006,14.346720000000005,595.32,841.92],"refs":[[0,201,"Trong đó mỗi văn bản được biểu diễn bởi đồ thị có trọng số dựa trên lý thuyết diễn ngôn, mỗi đỉnh đại diện cho một câu, trọng số trên mỗi cạnh là khoảng cách giữa hai câu"]]},"239":{"boxes":[99.264,254.27263999999994,442.63599999999997,14.346719999999976,595.32,841.92],"refs":[[0,202,"Một thuật toán tìm kiếm đồ thị sẽ được sử dụng để chọn ra các câu có tổng trọng số trên đường đi tới câu trả lời(vai trò như truy vấn) nhỏ nhất"]]},"241":{"boxes":[152.3,296.5426399999999,227.93,14.346720000000005,595.32,841.92],"refs":[[0,204,"Dựa trên tần số từ và độ tương đồng câu Phương pháp này trình bày bởi Siva kumar và đồng sự [5] áp dụng cho tóm tắt trích rút đa văn bản"]]},"242":{"boxes":[208.22696000000002,338.06263999999993,333.53888000000023,14.346720000000005,595.32,841.92],"refs":[[0,205,"Trước tiên các văn bản sẽ được biểu diễn trong mô hình không gian vector, mỗi câu được tính khoảng cách với câu truy vấn, sau đó sử dụng thuật toán phân cụm, chia các câu vào các cụm"]]},"243":{"boxes":[323.11,373.9426399999999,218.79000000000008,14.346720000000005,595.32,841.92],"refs":[[0,206,"Mỗi câu được tính điểm số vị trí và điểm số độ quan trọng trong cụm, sau đó từ các cụm có điểm số cao nhất, trích rút ra các câu có điểm số cao nhất tạo thành tóm tắt"]]},"245":{"boxes":[143.78,434.2026399999999,223.13000000000002,14.346720000000005,595.32,841.92],"refs":[[0,208,"Đề xuất hướng giải quyết cho tiếng Việt Qua tìm hiểu về các vấn đề liên quan trong tóm tắt và đặc trưng của tiếng Việt, dễ nhận thấy rằng việc tiếp cận ở mức cú pháp và ngữ nghĩa là khá khó khăn, một phần là vì công cụ và dữ liệu hỗ trợ, tuy đã có một số công cụ gán nhãn từ vựng và phân tích cú pháp cho độ chính xác cao nhưng thường chỉ áp dụng cho lĩnh vực hẹp, và còn ở mức nghiên cứu, chưa được công bố chính thức"]]},"246":{"boxes":[402.06088,529.48264,139.83911999999998,14.346720000000005,595.32,841.92],"refs":[[0,209,"Mặt khác, do đặc trưng về ngữ pháp nên các hướng tiếp cận đó thường không chính xác với tiếng Việt"]]},"247":{"boxes":[119.06,571.3626399999999,422.83988000000005,14.346720000000005,595.32,841.92],"refs":[[0,210,"Do đó em xin đề xuất mô hình trích rút các câu quan trọng cho bài toán tóm tắt hướng truy vấn dựa trên tần số từ và độ tương đồng câu, áp dụng cho tóm tắt đơn văn bản"]]},"248":{"boxes":[146.74736000000001,607.2426399999999,395.1152,14.346720000000005,595.32,841.92],"refs":[[0,211,"Mô tả sơ lược như sau: Đầu tiên sử dụng câu truy vấn làm tâm tóm tắt, sau đó tìm câu có độ tương đồng với tâm lớn nhất, mỗi câu được chọn sẽ kết hợp với tâm tạo nên tâm mới"]]},"249":{"boxes":[190.22288,643.1526399999999,272.71136,14.346720000000005,595.32,841.92],"refs":[[0,212,"Sau khi kết thúc sẽ loại bỏ câu truy vấn khỏi kết quả"]]},"250":{"boxes":[469.42,643.1526399999999,72.44639999999998,14.346720000000005,595.32,841.92],"refs":[[0,213,"Phương pháp này dựa theo ý tưởng ở giải thuật thứ 2 trong hướng tiếp cận dựa trên đồ thị đã nêu ở trên, nhưng các câu ở đây biểu diễn theo mô hình không gian vector và độ tương đồng sử dụng độ đo cosin"]]},"251":{"boxes":[119.06,720.9126399999999,422.84023999999994,14.346720000000005,595.32,841.92],"refs":[[0,214,"Phạm vi ứng dụng hướng tới của mô hình là tích hợp vào modul trả kết quả của bộ máy tìm kiếm văn bản(search engine), thực hiện tóm tắt văn bản kết quả theo tập từ khóa đã tìm kiếm(chính là truy vấn người dùng)"]]}}},"res":{"s":[{"saved_path":"/home/huong/InternetData/Data/LVTN/9.txt","r":96.11296081542969,"s":[[280,239,1,73,0,72,0,72,"Việc xử lý từ viết tắt không đơn giản là phát hiện các từ trong ngoặc, tùy từng loại văn bản của chuyên ngành nào đó, các từ viết tắt vẫn được sử dụng mà không gây hiểu lầm cho người đọc, vì trong các lĩnh vực ấy nó chỉ có thể thay thế cho cụm từ cố định nào đó, hoặc do thói quen, sử dụng nhiều thì mọi người đều biết","Việc xử lý từ viết tắt không đơn giản là phát hiện các từ trong ngoặc, tùy từng loại văn bản của chuyên ngành nào đó, các từ viết tắt vẫn được sử dụng mà không gây hiểu lầm cho người đọc, vì trong các lĩnh vực ấy nó chỉ có thể thay thế cho cụm từ cố định nào đó, hoặc do thói quen, sử dụng nhiều thì mọi người đều biết"],[281,240,0.9387755393981934,46,0,48,0,48,"Ví dụ: UBND thường được dùng thay thế cho “Ủy ban nhân dân” Trong giải thuật này chỉ xử lý các cụm từ viết tắt chữ đầu trong ngoặc đơn, còn các trường hợp khác do chưa xây dựng được bộ dữ liệu cụ thể nên không xét đến","Ví dụ: UBND thường được dùng thay thế cho Ủy ban nhân dân Trong giải thuật này chỉ xử lý các cụm từ viết tắt chữ đầu trong ngoặc đơn, còn các trường hợp khác do chưa xây dựng được bộ dữ liệu cụ thể nên không xét đến"],[282,241,1,11,0,10,0,10,"Các cụm từ trong ngoặc đơn khác sẽ bị xóa đi","Các cụm từ trong ngoặc đơn khác sẽ bị xóa đi"],[279,238,0.9399999976158142,47,0,49,0,49,"Ví dụ: Sinh viên tình nguyện(SVTN) đi đến các vùng sâu để giúp đỡ đồng bào Các câu sau câu này sẽ sử dụng cụm từ SVTN, nếu truy vấn có từ khóa “sinh viên tình nguyện” thì các câu sử dụng từ viết tắt sẽ không được quan tâm","Ví dụ: Sinh viên tình nguyện(SVTN) đi đến các vùng sâu để giúp đỡ đồng bào Các câu sau câu này sẽ sử dụng cụm từ SVTN, nếu truy vấn có từ khóa sinh viên tình nguyện thì các câu sử dụng từ viết tắt sẽ không được quan tâm"],[278,237,0.9902912378311157,51,1,51,0,50," Xử lý các cụm từ trong ngoặc Các cụm từ trong ngoặc có thể là chú thích hoặc viết tắt của cụm từ nào đó, nếu là chú thích thì có thể bỏ qua còn từ viết tắt thì khá quan trọng, nhất là đối với tóm tắt hướng truy vấn","Xử lý các cụm từ trong ngoặc Các cụm từ trong ngoặc có thể là chú thích hoặc viết tắt của cụm từ nào đó, nếu là chú thích thì có thể bỏ qua còn từ viết tắt thì khá quan trọng, nhất là đối với tóm tắt hướng truy vấn"],[276,235,0.8695651888847351,20,0,21,0,21,"Việc phát hiện câu tiêu đề có thể dựa vào dấu hiệu “câu tiêu đề là câu duy nhất của đoạn đầu tiên”","Việc phát hiện câu tiêu đề có thể dựa vào dấu hiệu câu tiêu đề là câu duy nhất của đoạn đầu tiên"],[277,236,1,27,0,26,0,26,"Trong giải thuật này chỉ sử dụng câu tiêu đề như câu thông thường, sau đó loại khỏi kết quả (nếu nó được chọn vào kết quả)","Trong giải thuật này chỉ sử dụng câu tiêu đề như câu thông thường, sau đó loại khỏi kết quả (nếu nó được chọn vào kết quả)"],[275,234,0.9808917045593262,77,0,78,0,77,"Chuẩn hóa  Xử lý câu tiêu đề Câu tiêu đề của một văn bản (nếu có) thường mang nội dung chính trình bày trong văn bản, do đó các từ khóa trong đó cũng được dùng để phát hiện tóm tắt (một số giải thuật còn tăng trọng số cho những từ xuất hiện trong tiêu đề), nhưng không đưa câu tiêu đề vào kết quả tóm tắt, nên cần phát hiện để loại bỏ khỏi kết quả","Chuẩn hóa Xử lý câu tiêu đề Câu tiêu đề của một văn bản (nếu có) thường mang nội dung chính trình bày trong văn bản, do đó các từ khóa trong đó cũng được dùng để phát hiện tóm tắt (một số giải thuật còn tăng trọng số cho những từ xuất hiện trong tiêu đề), nhưng không đưa câu tiêu đề vào kết quả tóm tắt, nên cần phát hiện để loại bỏ khỏi kết quả"],[366,321,1,44,0,43,0,43,"Liên quan đến các vấn đề kinh tế - xã hội, Chủ tịch nước Trương Tấn Sang cho biết kinh tế nước nhà có những phát triển đáng kể, nông nghiệp đạt nhiều thắng lợi, các ngành thuộc về dầu khí tăng trưởng khá{12}","Liên quan đến các vấn đề kinh tế - xã hội, Chủ tịch nước Trương Tấn Sang cho biết kinh tế nước nhà có những phát triển đáng kể, nông nghiệp đạt nhiều thắng lợi, các ngành thuộc về dầu khí tăng trưởng khá{12}"],[357,312,1,35,0,34,0,34,"Ghi nhận các ý kiến của cử tri, Chủ tịch nước đánh giá cao tinh thần đóng góp ý kiến của mọi người, nhất là vấn đề sửa đổi Hiến Pháp và các đạo luật{3}","Ghi nhận các ý kiến của cử tri, Chủ tịch nước đánh giá cao tinh thần đóng góp ý kiến của mọi người, nhất là vấn đề sửa đổi Hiến Pháp và các đạo luật{3}"],[356,311,0.9739130139350891,56,0,57,0,56,"Đầu vào  Văn bản: Bảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình{1} Chiều ngày 26-4, Chủ tịch nước Trương Tấn Sang và Tổ Đại biểu Quốc hội (ĐBQH) số 1, Đoàn ĐBQH TP Hồ Chí Minh tiếp tục có buổi tiếp xúc với gần 400 cử tri của quận 1{2}","Đầu vào Văn bản: Bảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình{1} Chiều ngày 26-4, Chủ tịch nước Trương Tấn Sang và Tổ Đại biểu Quốc hội (ĐBQH) số 1, Đoàn ĐBQH TP Hồ Chí Minh tiếp tục có buổi tiếp xúc với gần 400 cử tri của quận 1{2}"],[354,309,1,23,0,22,0,22,"Thử nghiệm một văn bản Phần này em sử dụng công cụ tóm tắt đã xây dựng để thử nghiệm một văn bản","Thử nghiệm một văn bản Phần này em sử dụng công cụ tóm tắt đã xây dựng để thử nghiệm một văn bản"],[355,310,1,9,0,8,0,8,"Kết quả thực hiện thu được như sau: 2.2.1","Kết quả thực hiện thu được như sau: 2.2.1"],[359,314,0.8620689511299133,25,0,27,0,27,"Tuy nhiên, Chủ tịch nước cũng khẳng định “không bao giờ bảo vệ chủ quyền bằng nói miệng”; chủ trương hòa hiếu không có nghĩa là không làm gì{5}","Tuy nhiên, Chủ tịch nước cũng khẳng định không bao giờ bảo vệ chủ quyền bằng nói miệng; chủ trương hòa hiếu không có nghĩa là không làm gi{5}"],[371,314,0.8474576473236084,25,1,28,0,27,"{5} Tuy nhiên, Chủ tịch nước cũng khẳng định “không bao giờ bảo vệ chủ quyền bằng nói miệng”; chủ trương hòa hiếu không có nghĩa là không làm gì","Tuy nhiên, Chủ tịch nước cũng khẳng định không bao giờ bảo vệ chủ quyền bằng nói miệng; chủ trương hòa hiếu không có nghĩa là không làm gi{5}"],[361,316,1,20,0,19,0,19,"Chủ tịch nước cho biết, chủ trương hòa hiếu luôn được các nước bạn bè trên thế giới ủng hộ{7}","Chủ tịch nước cho biết, chủ trương hòa hiếu luôn được các nước bạn bè trên thế giới ủng hộ{7}"],[373,316,0.9268292784690857,19,1,19,0,18,"{7} Chủ tịch nước cho biết, chủ trương hòa hiếu luôn được các nước bạn bè trên thế giới ủng hộ","Chủ tịch nước cho biết, chủ trương hòa hiếu luôn được các nước bạn bè trên thế giới ủng hộ{7}"],[360,315,1,32,0,31,0,31,"Nước ta cũng mua sắm trang bị vũ khí, nhưng không phải để gây chiến tranh, chạy đua vũ trang mà là tăng cường phòng thủ, bảo vệ chủ quyền lãnh thổ{6}","Nước ta cũng mua sắm trang bị vũ khí, nhưng không phải để gây chiến tranh, chạy đua vũ trang mà là tăng cường phòng thủ, bảo vệ chủ quyền lãnh thổ{6}"],[372,315,0.9538461565971375,31,1,31,0,30,"{6} Nước ta cũng mua sắm trang bị vũ khí, nhưng không phải để gây chiến tranh, chạy đua vũ trang mà là tăng cường phòng thủ, bảo vệ chủ quyền lãnh thổ","Nước ta cũng mua sắm trang bị vũ khí, nhưng không phải để gây chiến tranh, chạy đua vũ trang mà là tăng cường phòng thủ, bảo vệ chủ quyền lãnh thổ{6}"],[362,317,0.9473684430122375,36,0,37,0,37,"Đề cập đến tình hình biển, đảo, Chủ tịch nước bày tỏ thông cảm với những lo lắng, bức xúc của cử tri, mong cử tri phải bình tĩnh, không nghe những lời kích động của kẻ xấu{8}","Đề cập đến tình hình biển, đảo, Chủ tịch nước bày tỏ thông cảm với những lo lắng, bức xúc của cử tri, mong cử tri phải binh tĩnh, không nghe những lời kích động của kẻ xấu{8}"],[363,318,1,41,0,40,0,40,"Những mâu thuẫn trên Biển Đông là có, nhưng biện pháp hòa hiếu của nước ta đã có kết quả tốt, Nhà nước luôn hỗ trợ ngư dân ra khơi, số lượng tàu cá đánh bắt xa bờ ngày càng tăng{9}","Những mâu thuẫn trên Biển Đông là có, nhưng biện pháp hòa hiếu của nước ta đã có kết quả tốt, Nhà nước luôn hỗ trợ ngư dân ra khơi, số lượng tàu cá đánh bắt xa bờ ngày càng tăng{9}"],[374,318,0.9638554453849792,40,1,40,0,39,"{9} Những mâu thuẫn trên Biển Đông là có, nhưng biện pháp hòa hiếu của nước ta đã có kết quả tốt, Nhà nước luôn hỗ trợ ngư dân ra khơi, số lượng tàu cá đánh bắt xa bờ ngày càng tăng","Những mâu thuẫn trên Biển Đông là có, nhưng biện pháp hòa hiếu của nước ta đã có kết quả tốt, Nhà nước luôn hỗ trợ ngư dân ra khơi, số lượng tàu cá đánh bắt xa bờ ngày càng tăng{9}"],[365,320,1,25,0,24,0,24,"Mục tiêu cuối cùng của nước ta là chủ quyền lãnh thổ vững chắc, quốc phòng - an ninh ổn định, kinh tế phát triển{11}","Mục tiêu cuối cùng của nước ta là chủ quyền lãnh thổ vững chắc, quốc phòng - an ninh ổn định, kinh tế phát triển{11}"],[375,320,0.9411764740943909,24,1,24,0,23,"{11} Mục tiêu cuối cùng của nước ta là chủ quyền lãnh thổ vững chắc, quốc phòng - an ninh ổn định, kinh tế phát triển","Mục tiêu cuối cùng của nước ta là chủ quyền lãnh thổ vững chắc, quốc phòng - an ninh ổn định, kinh tế phát triển{11}"],[364,319,1,31,0,30,0,30,"Nước ta phấn đấu đến năm 2020 sẽ phát triển kinh tế biển đạt 52%-53% GDP, trong đó, dầu khí, vận tải biển, đánh bắt hải sản là thế mạnh lớn{10}","Nước ta phấn đấu đến năm 2020 sẽ phát triển kinh tế biển đạt 52%-53% GDP, trong đó, dầu khí, vận tải biển, đánh bắt hải sản là thế mạnh lớn{10}"],[358,313,1,70,0,69,0,69,"Trả lời câu hỏi được đông đảo cử tri quan tâm về chủ trương bảo vệ chủ quyền lãnh thổ, củng cố quốc phòng - an ninh, Chủ tịch nước Trương Tấn Sang khẳng định chủ trương của Đảng, Nhà nước trước sau như một là kiên quyết bảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình, theo hệ thống luật pháp quốc tế{4}","Trả lời câu hỏi được đông đảo cử tri quan tâm về chủ trương bảo vệ chủ quyền lãnh thổ, củng cố quốc phòng - an ninh, Chủ tịch nước Trương Tấn Sang khẳng định chủ trương của Đảng, Nhà nước trước sau như một là kiên quyết bảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình, theo hệ thống luật pháp quốc tế{4}"],[370,313,0.8363636136054993,69,25,93,0,68,"Kết quả tóm tắt Kết quả được chọn theo thứ tự 4, 11, 6, 5, 7, 9 tổng số 111 từ / 6 câu {4} Trả lời câu hỏi được đông đảo cử tri quan tâm về chủ trương bảo vệ chủ quyền lãnh thổ, củng cố quốc phòng - an ninh, Chủ tịch nước Trương Tấn Sang khẳng định chủ trương của Đảng, Nhà nước trước sau như một là kiên quyết bảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình, theo hệ thống luật pháp quốc tế","Trả lời câu hỏi được đông đảo cử tri quan tâm về chủ trương bảo vệ chủ quyền lãnh thổ, củng cố quốc phòng - an ninh, Chủ tịch nước Trương Tấn Sang khẳng định chủ trương của Đảng, Nhà nước trước sau như một là kiên quyết bảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình, theo hệ thống luật pháp quốc tế{4}"],[192,158,0.9638554453849792,40,0,41,0,40,"Có thể kể ra một số ứng dụng Tóm tắt văn bản tiêu biểu như sau:  SUMMARIST: Một hệ thống Trích rút văn bản năm thứ tiếng (tiếng Anh, tiếng Nhật, tiếng Tây Ban Nha, tiếng Ả-rập và tiếng Hàn Quốc)","Có thể kể ra một số ứng dụng Tóm tắt văn bản tiêu biểu như sau: SUMMARIST: Một hệ thống Trích rút văn bản năm thứ tiếng (tiếng Anh, tiếng Nhật, tiếng Tây Ban Nha, tiếng Ả-rập và tiếng Hàn Quốc)"],[190,156,1,33,0,32,0,32,"Một số hệ thống tóm tắt văn bản tiêu biểu Hiện tại, trên thế giới đã có rất nhiều nghiên cứu và dự án xây dựng các ứng dụng tóm tắt văn bản","Một số hệ thống tóm tắt văn bản tiêu biểu Hiện tại, trên thế giới đã có rất nhiều nghiên cứu và dự án xây dựng các ứng dụng tóm tắt văn bản"],[191,157,1,15,0,14,0,14,"Các ứng dụng này có thể đáp ứng rất nhiều các mục đích khác nhau","Các ứng dụng này có thể đáp ứng rất nhiều các mục đích khác nhau"],[193,159,1,30,0,29,0,29,"Hiện tại SUMMARIST đang nghiên cứu để cải tiến trở thành một hệ thống Tóm lược văn bản và hỗ trợ nhiều ngôn ngữ hơn như tiếng Pháp và Indonesia","Hiện tại SUMMARIST đang nghiên cứu để cải tiến trở thành một hệ thống Tóm lược văn bản và hỗ trợ nhiều ngôn ngữ hơn như tiếng Pháp và Indonesia"],[195,161,1,37,0,36,0,36,"SweSUM có thể tóm tắt các văn bản có ngôn ngữ vùng Scandinavi như Thụy Điển, Đan Mạch, Na Uy và các ngôn ngữ khác như tiếng Anh, Pháp, Đức, Tây Ban Nha và cả tiếng Iran","SweSUM có thể tóm tắt các văn bản có ngôn ngữ vùng Scandinavi như Thụy Điển, Đan Mạch, Na Uy và các ngôn ngữ khác như tiếng Anh, Pháp, Đức, Tây Ban Nha và cả tiếng Iran"],[194,160,0.9743589758872986,19,1,19,0,18," SweSUM: Ứng dụng Tóm tắt văn bản đa ngôn ngữ của Học viện công nghệ hoàng gia Thụy Điển","SweSUM: Ứng dụng Tóm tắt văn bản đa ngôn ngữ của Học viện công nghệ hoàng gia Thụy Điển"],[207,172,1,31,0,30,0,30,"Ngoài ra MEAD cũng cung cấp các công cụ để xây dựng các ứng dụng đánh giá hệ thống tóm tắt theo các tiêu chí và các tập mẫu nổi tiếng","Ngoài ra MEAD cũng cung cấp các công cụ để xây dựng các ứng dụng đánh giá hệ thống tóm tắt theo các tiêu chí và các tập mẫu nổi tiếng"],[208,173,1,42,0,41,0,41,"MEAD được xây dựng bởi các chuyên gia nổi tiếng về Xử lý ngôn ngữ ở khắp nơi trên thế giới dưới sự tài trợ của Chương trình Nghiên cứu Công nghệ thông tin của Tổ chức Khoa học quốc gia Mỹ","MEAD được xây dựng bởi các chuyên gia nổi tiếng về Xử lý ngôn ngữ ở khắp nơi trên thế giới dưới sự tài trợ của Chương trình Nghiên cứu Công nghệ thông tin của Tổ chức Khoa học quốc gia Mỹ"],[212,177,1,22,0,21,0,21,"Chúng ta có thể thử bằng cách chọn Tools - AutoSummarize trên thanh công cụ (có thể khác tùy vào phiên bản)","Chúng ta có thể thử bằng cách chọn Tools - AutoSummarize trên thanh công cụ (có thể khác tùy vào phiên bản)"],[214,179,1,17,0,16,0,16,"Ngoài ra còn các hệ thống Tóm tắt văn bản nổi tiếng khác như ANES hay SUMMONS","Ngoài ra còn các hệ thống Tóm tắt văn bản nổi tiếng khác như ANES hay SUMMONS"],[213,178,1,20,0,19,0,19,"Công cụ này cho phép chúng ta chọn thông số về độ rút gọn, trích rút hay sinh tiêu đề..","Công cụ này cho phép chúng ta chọn thông số về độ rút gọn, trích rút hay sinh tiêu đề.."],[215,180,1,22,0,21,0,21,"Tuy nhiên tại Việt Nam hiện nay chưa có một nghiên cứu và ứng dụng Tóm tắt văn bản chính thức nào","Tuy nhiên tại Việt Nam hiện nay chưa có một nghiên cứu và ứng dụng Tóm tắt văn bản chính thức nào"],[210,175,1,11,0,10,0,10,"Hiện tại phiên bản mới nhất của MEAD là MEAD v3.07","Hiện tại phiên bản mới nhất của MEAD là MEAD v3.07"],[211,176,0.978723406791687,23,1,23,0,22," Microsoft Word AutoSummary: Microsoft cũng cài đặt chức năng Trích rút và sinh tiêu đề trong Microsoft Word từ phiên bản Word '97","Microsoft Word AutoSummary: Microsoft cũng cài đặt chức năng Trích rút và sinh tiêu đề trong Microsoft Word từ phiên bản Word '97"],[209,174,1,15,0,14,0,14,"MEAD được cung cấp ở dạng mã nguồn mở để nghiên cứu và kế thừa","MEAD được cung cấp ở dạng mã nguồn mở để nghiên cứu và kế thừa"],[199,164,0.9777777791023254,22,1,22,0,21," FJCL: Hệ thống Rút trích văn bản tiếng Nhật được phát triển trong phòng nghiên cứu Ikeda của trường đại học Gifu","FJCL: Hệ thống Rút trích văn bản tiếng Nhật được phát triển trong phòng nghiên cứu Ikeda của trường đại học Gifu"],[197,162,0.7868852615356445,24,13,36,0,23,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 23  SumUM: Hệ thống Tóm lược văn bản kỹ thuật của nhóm nghiên cứu xử lý ngôn ngữ tự nhiên trường Đại học Montréal, Canada","SumUM: Hệ thống Tóm lược văn bản kỹ thuật của nhóm nghiên cứu xử lý ngôn ngữ tự nhiên trường Đại học Montréal, Canada"],[198,163,1,19,0,18,0,18,"SumUM có thể thực hiện cả chức năng tóm tắt chỉ định và tóm tắt thông tin rất tốt.","SumUM có thể thực hiện cả chức năng tóm tắt chỉ định và tóm tắt thông tin rất tốt."],[200,165,1,32,0,31,0,31,"Đây là một hệ thống sử dụng các phương pháp áp dụng cho hệ ngôn ngữ đơn âm tiết (monosyllabic language system) như tiếng Nhật, Hàn Quốc, Trung Quốc và Việt Nam","Đây là một hệ thống sử dụng các phương pháp áp dụng cho hệ ngôn ngữ đơn âm tiết (monosyllabic language system) như tiếng Nhật, Hàn Quốc, Trung Quốc và Việt Nam"],[201,166,0.9677419066429138,15,1,15,0,14," Pertinence Summarizer: Hệ thống tóm tắt tin tức đa ngôn ngữ trực tuyến nổi tiếng","Pertinence Summarizer: Hệ thống tóm tắt tin tức đa ngôn ngữ trực tuyến nổi tiếng"],[204,169,0.9696969985961914,16,1,16,0,15," MEAD: Nền tảng cho các hệ thống Tóm tắt nhiều văn bản và đa ngôn ngữ","MEAD: Nền tảng cho các hệ thống Tóm tắt nhiều văn bản và đa ngôn ngữ"],[203,168,1,13,0,12,0,12,"Chúng ta có thể thử nghiệm hệ thống này trên trang web: www.pertinence.net","Chúng ta có thể thử nghiệm hệ thống này trên trang web: www.pertinence.net"],[202,167,1,36,0,35,0,35,"Hiện tại để thử nghiệm khả năng của mình, Pertinence đã được tích hợp với Google và tóm tắt tự động danh sách tìm kiếm trả về từ Google thông qua câu truy vấn đưa vào","Hiện tại để thử nghiệm khả năng của mình, Pertinence đã được tích hợp với Google và tóm tắt tự động danh sách tìm kiếm trả về từ Google thông qua câu truy vấn đưa vào"],[206,171,1,34,0,33,0,33,"MEAD biểu diễn, lưu trữ dữ liệu ở dạng XML, cung tấp cho chúng ta khung ứng dụng để cài đặt các ứng dụng Tóm tắt văn bản cho ngôn ngữ mà ta muốn","MEAD biểu diễn, lưu trữ dữ liệu ở dạng XML, cung tấp cho chúng ta khung ứng dụng để cài đặt các ứng dụng Tóm tắt văn bản cho ngôn ngữ mà ta muốn"],[205,170,1,35,0,34,0,34,"Đây là một bộ công cụ xây dựng trên nền Linux và Solaris, sử dụng ngôn ngữ Perl - Một ngôn ngữ có khả năng xử lý văn bản rất linh hoạt và mạnh mẽ","Đây là một bộ công cụ xây dựng trên nền Linux và Solaris, sử dụng ngôn ngữ Perl - Một ngôn ngữ có khả năng xử lý văn bản rất linh hoạt và mạnh mẽ"],[90,58,0.9714285731315613,68,0,70,0,68,"Các chỉ số sử dụng trong phương pháp này:  Tần suất thuật ngữ của một từ w trong một văn bản d, ký hiệu TF(w,d), có thể sử dụng các công thức sau, với fij là số lần xuất hiện của từ wi trong văn bản dj:  Tần suất văn bản của một từ w, ký hiệu DF(w) là số lượng văn bản mà từ w có xuất hiện","Các chỉ số sử dụng trong phương pháp này: Tần suất thuật ngữ của một từ w trong một văn bản d, ký hiệu TF(w,d), có thể sử dụng các công thức sau, với fij là số lần xuất hiện của từ wi trong văn bản dj: Tần suất văn bản của một từ w, ký hiệu DF(w) là số lượng văn bản mà từ w có xuất hiện"],[88,56,1,27,0,26,0,26,"Hai văn bản là hai vector, vậy khoảng cách hay góc giữa chúng đều có thể đại diện cho sự liên quan giữa hai văn bản này","Hai văn bản là hai vector, vậy khoảng cách hay góc giữa chúng đều có thể đại diện cho sự liên quan giữa hai văn bản này"],[89,57,1,22,0,21,0,21,"Tất nhiên, để áp dụng được các phép toán vector cơ bản, hai vector cần chuẩn hóa về số chiều (độ dài)","Tất nhiên, để áp dụng được các phép toán vector cơ bản, hai vector cần chuẩn hóa về số chiều (độ dài)"],[86,54,1,39,0,38,0,38,"Truy vấn là kết quả của các phép toán vector giữa các vector biểu diễn cho những văn bản cấu thành nên truy vấn, như vậy, truy vấn trong trường hợp này cũng là một văn bản đặc biệt","Truy vấn là kết quả của các phép toán vector giữa các vector biểu diễn cho những văn bản cấu thành nên truy vấn, như vậy, truy vấn trong trường hợp này cũng là một văn bản đặc biệt"],[85,53,0.6153846383094788,24,30,53,0,23,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 16 thay vào đó là các phép toán vector như cộng hai vector, nhân hai vector, tích vô hướng… Khi biểu diễn văn bản thành các vector, vấn đề về truy vấn và xác định độ liên quan hoàn toàn được giải quyết","Khi biểu diễn văn bản thành các vector, vấn đề về truy vấn và xác định độ liên quan hoàn toàn được giải quyết"],[87,55,1,24,0,23,0,23,"Việc xác định độ liên quan giữa truy vấn và văn bản được quy thành độ liên quan giữa văn bản và văn bản","Việc xác định độ liên quan giữa truy vấn và văn bản được quy thành độ liên quan giữa văn bản và văn bản"],[91,59,0.9753694534301758,99,0,101,0,100,"Nghịch đảo của tần suất văn bản của một từ w, ký hiệu IDF(w) được cho bởi công thức: Trong đó: m là tổng số văn bản,, h là số văn bản chứa từ w  Tần suất TF-IDF là kết hợp của hai loại tần suất nói trên: TF-IDF(w,d) = TF(w,d) * IDF(w) Theo mô hình này, mỗi văn bản sẽ được biểu diễn dưới dạng D(t1, t2,…,tn) với n là tổng số thuật ngữ xuất hiện, mỗi thuật ngữ sẽ được đánh index, ti là trọng số của thuật ngữ thứ i(trong danh sách thuật ngữ) trong văn bản D","Nghịch đảo của tần suất văn bản của một từ w, ký hiệu IDF(w) được cho bởi công thức: Trong đó: m là tổng số văn bản,, h là số văn bản chứa từ w Tần suất TF-IDF là kết hợp của hai loại tần suất nói trên: TF-IDF(w,d) = TF(w,d) * IDF(w) Theo mô hình này, mỗi văn bản sẽ được biểu diễn dưới dạng D(t1, t2,.,tn) với n là tổng số thuật ngữ xuất hiện, mỗi thuật ngữ sẽ được đánh index, ti là trọng số của thuật ngữ thứ i(trong danh sách thuật ngữ) trong văn bản D"],[95,62,1,37,0,36,0,36,"Điều cốt lõi của lý thuyết này là việc xác định chính xác một giả thiết nào đó (ví dụ như hai văn bản này có phù hợp, có giống nhau không...) là một điều rất khó","Điều cốt lõi của lý thuyết này là việc xác định chính xác một giả thiết nào đó (ví dụ như hai văn bản này có phù hợp, có giống nhau không...) là một điều rất khó"],[92,60,0.8727272748947144,24,0,26,0,26,"Khi đó độ liên quan giữa hai văn bản biểu diễn bởi 2 vector X(x1, x2, …, xn) và Y(y1, y2,…,yn) được tính bằng công thức Cosin:","Khi đó độ liên quan giữa hai văn bản biểu diễn bởi 2 vector X(x1, x2, ., xn) và Y(y1, y2,.,yn) được tính bằng công thức Cosin: 2.5.3"],[94,61,1,35,0,34,0,34,"Mô hình tập thô dung sai Mô hình tập thô dung sai (Tolerance Rough Set Model) là một mô hình mới, tiên tiến dựa trên lý thuyết về logic mờ và tập mờ (Fuzzy Set)","Mô hình tập thô dung sai Mô hình tập thô dung sai (Tolerance Rough Set Model) là một mô hình mới, tiên tiến dựa trên lý thuyết về logic mờ và tập mờ (Fuzzy Set)"],[96,63,1,26,0,25,0,25,"Tuy nhiên chúng ta có thể chỉ ra một cặp xấp xỉ trên và xấp xỉ dưới để khẳng định được giả thiết đó là đúng","Tuy nhiên chúng ta có thể chỉ ra một cặp xấp xỉ trên và xấp xỉ dưới để khẳng định được giả thiết đó là đúng"],[98,65,1,27,0,26,0,26,"Các phép toán cơ bản trong mô hình tập thô dựa trên các quan hệ tương đương các tính chất như đối xứng, phản xạ, bắc cầu..","Các phép toán cơ bản trong mô hình tập thô dựa trên các quan hệ tương đương các tính chất như đối xứng, phản xạ, bắc cầu.."],[97,64,0.8125,13,0,15,0,15,"Sử dụng các suy diễn hợp lý để xác định và “làm đẹp” các ngưỡng này","Sử dụng các suy diễn hợp lý để xác định và làm đẹp các ngưỡng này"],[99,66,1,20,0,19,0,19,"Lý thuyết logic mờ đã và đang được ứng dụng rất mạnh mẽ trong lĩnh vực Trí tuệ nhân tạo","Lý thuyết logic mờ đã và đang được ứng dụng rất mạnh mẽ trong lĩnh vực Trí tuệ nhân tạo"],[320,280,1,49,0,48,0,48,"Cụ thể mỗi từ tần số của mỗi từ wi trong câu sj được tính như sau: Trong đó: fij là số lần xuất hiện của từ ti trong câu sj, m là tổng số câu trong văn bản hi là tổng số câu mà từ ti xuất hiện","Cụ thể mỗi từ tần số của mỗi từ wi trong câu sj được tính như sau: Trong đó: fij là số lần xuất hiện của từ ti trong câu sj, m là tổng số câu trong văn bản hi là tổng số câu mà từ ti xuất hiện"],[318,278,1,27,0,26,0,26,"Mô hình hóa văn bản Việc cuối cùng trong giai đoạn tiền xử lý là mô hình hóa văn bản, sử dụng mô hình không gian vector","Mô hình hóa văn bản Việc cuối cùng trong giai đoạn tiền xử lý là mô hình hóa văn bản, sử dụng mô hình không gian vector"],[319,279,1,45,0,44,0,44,"Tương tự các công thức dùng để mô hình hóa văn bản ở trên, để mô hình hóa câu, ta sử dụng công thức sau TF.ISF, công thức này tương tự như TF.IDF nhưng các thông số ở trong phạm vi câu và văn bản","Tương tự các công thức dùng để mô hình hóa văn bản ở trên, để mô hình hóa câu, ta sử dụng công thức sau TF.ISF, công thức này tương tự như TF.IDF nhưng các thông số ở trong phạm vi câu và văn bản"],[321,281,0.8979591727256775,44,1,49,0,47,"α là hệ số đánh giá độ quan trọng của từ, nếu từ xuất hiện trong truy vấn thì α>1, còn lại thì α=1 Với hệ số α cho từ xuất hiện trong truy vấn, trong quá trình kiểm thử trên tập mẫu thì α=4 cho kết quả tốt nhất","là hệ số đánh giá độ quan trọng của từ, nếu từ xuất hiện trong truy vấn thì >1, còn lại thì =1 Với hệ số cho từ xuất hiện trong truy vấn, trong quá trình kiểm thử trên tập mẫu thì =4 cho kết quả tốt nhất"],[160,127,0.9830508232116699,29,1,29,0,28," Phương pháp thay thế ngữ tương đương Tư tưởng của phương pháp này là các ngữ đóng vai trò như nhau trong câu được thay bằng một ngữ chung","Phương pháp thay thế ngữ tương đương Tư tưởng của phương pháp này là các ngữ đóng vai trò như nhau trong câu được thay bằng một ngữ chung"],[163,129,0.738095223903656,31,12,42,10,40,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 21 Một phương pháp khác khá dễ hiểu đấy là việc thay thế một từ, ngữ bằng một từ, ngữ khác đồng nghĩa hoặc gần nghĩa nhưng có độ dài ngắn hơn","Phương pháp thay thế từ, ngữ đồng nghĩa ngắn hơn Một phương pháp khác khá dễ hiểu đấy là việc thay thế một từ, ngữ bằng một từ, ngữ khác đồng nghĩa hoặc gần nghĩa nhưng có độ dài ngắn hơn"],[161,128,0.807692289352417,21,0,24,0,24,"Ví dụ: “Anh ấy bước vào, ngồi xuống ghế, xem thực đơn, gọi món, ăn, trả tiền và ra về” => “Anh ấy đi ăn tiệm”","Ví dụ: Anh ấy bước vào, ngồi xuống ghế, xem thực đơn, gọi món, ăn, trả tiền và ra về => Anh ấy đi ăn tiệm"],[165,131,0.9841269850730896,31,1,31,0,30," Phương pháp thay thế bởi đại diện Tư tưởng của phương pháp này là thay thế một ngữ bằng một ngữ khác có ý nghĩa đại diện cho ngữ ban đầu","Phương pháp thay thế bởi đại diện Tư tưởng của phương pháp này là thay thế một ngữ bằng một ngữ khác có ý nghĩa đại diện cho ngữ ban đầu"],[166,132,0.6666666865348816,10,0,11,0,11,"Ví dụ: “Người phát ngôn viên của chính phủ Hoa Kỳ thông báo…” => “Washington thông báo…”","Ví dụ: Người phát ngôn viên của chính phủ Hoa Kỳ thông báo"],[164,130,1,13,0,12,0,12,"Điều này thường thông qua một từ điển các từ đồng nghĩa (Thesaurus)","Điều này thường thông qua một từ điển các từ đồng nghĩa (Thesaurus)"],[239,202,1,33,0,32,0,32,"Một thuật toán tìm kiếm đồ thị sẽ được sử dụng để chọn ra các câu có tổng trọng số trên đường đi tới câu trả lời(vai trò như truy vấn) nhỏ nhất","Một thuật toán tìm kiếm đồ thị sẽ được sử dụng để chọn ra các câu có tổng trọng số trên đường đi tới câu trả lời(vai trò như truy vấn) nhỏ nhất"],[238,201,1,38,0,37,0,37,"Trong đó mỗi văn bản được biểu diễn bởi đồ thị có trọng số dựa trên lý thuyết diễn ngôn, mỗi đỉnh đại diện cho một câu, trọng số trên mỗi cạnh là khoảng cách giữa hai câu","Trong đó mỗi văn bản được biểu diễn bởi đồ thị có trọng số dựa trên lý thuyết diễn ngôn, mỗi đỉnh đại diện cho một câu, trọng số trên mỗi cạnh là khoảng cách giữa hai câu"],[236,199,1,14,0,13,0,13,"Dựa trên cấu trúc diễn ngôn Phương pháp này được trình bày bởi W","Dựa trên cấu trúc diễn ngôn Phương pháp này được trình bày bởi W"],[237,200,1,28,0,27,0,27,"Bosma [4], mục đích là tạo ra bản tóm tắt ngắn gọn chứa câu trả lời để đưa ra kết quả trong hệ thống hỏi đáp tự động","Bosma [4], mục đích là tạo ra bản tóm tắt ngắn gọn chứa câu trả lời để đưa ra kết quả trong hệ thống hỏi đáp tự động"],[41,10,0.7191011309623718,32,0,33,0,32,"Các tiêu chí đánh giá  Độ mạch lạc (Coherence): đánh giá mức độ rõ ràng của văn bản tóm tắt, tính súc tích, khả năng có thể đọc và hiểu được của bài viết…  Độ hàm chứa thông tin (Informationess): tỉ lệ thông tin của văn bản gốc trong văn bản tóm tắt","Các tiêu chí đánh giá Độ mạch lạc (Coherence): đánh giá mức độ rõ ràng của văn bản tóm tắt, tính súc tích, khả năng có thể đọc và hiểu được của bài viết"],[39,8,1,41,0,40,0,40,"Ngày nay, thời đại công nghệ thông tin phát triển mạnh, tóm tắt văn bản tự động (gọi tắt là tóm tắt văn bản) được nghiên cứu phát triển nhằm mục đích làm thay con người công việc nặng nhọc đó","Ngày nay, thời đại công nghệ thông tin phát triển mạnh, tóm tắt văn bản tự động (gọi tắt là tóm tắt văn bản) được nghiên cứu phát triển nhằm mục đích làm thay con người công việc nặng nhọc đó"],[40,9,0.9523809552192688,60,0,62,0,62,"Đã có rất nhiều định nghĩa được đưa ra, tuy nhiên có thể sử dụng định nghĩa ngắn gọn sau: “Tóm tắt văn bản là quá trình rút ra những thông tin quan trọng nhất từ một hay nhiều nguồn văn bản để tạo ra một văn bản gọn hơn phục vụ cho một số nhiệm vụ hay người dùng cụ thể” 2.2","Đã có rất nhiều định nghĩa được đưa ra, tuy nhiên có thể sử dụng định nghĩa ngắn gọn sau: Tóm tắt văn bản là quá trình rút ra những thông tin quan trọng nhất từ một hay nhiều nguồn văn bản để tạo ra một văn bản gọn hơn phục vụ cho một số nhiệm vụ hay người dùng cụ thể 2.2"],[34,3,1,10,0,9,0,9,"TỔNG QUAN VỀ TÓM TẮT VĂN BẢN TỰ ĐỘNG 2.1","TỔNG QUAN VỀ TÓM TẮT VĂN BẢN TỰ ĐỘNG 2.1"],[37,6,1,30,0,29,0,29,"Mục đích là giúp người sử dụng có cái nhìn tổng quan về nội dung trình bày trong văn bản, để quyết định sử dụng văn bản đó hợp lý","Mục đích là giúp người sử dụng có cái nhìn tổng quan về nội dung trình bày trong văn bản, để quyết định sử dụng văn bản đó hợp lý"],[38,7,1,21,0,20,0,20,"Tuy nhiên với lượng văn bản nhiều và dài thì việc làm thủ công vô cùng tốn thời gian, công sức","Tuy nhiên với lượng văn bản nhiều và dài thì việc làm thủ công vô cùng tốn thời gian, công sức"],[36,5,1,38,0,37,0,37,"Công việc tóm tắt văn bản đã xuất hiện từ rất lâu đời, và nó được làm thủ công, do con người đọc, rút ra các ý chính rồi trình bày lại một cách ngắn gọn, dễ hiểu","Công việc tóm tắt văn bản đã xuất hiện từ rất lâu đời, và nó được làm thủ công, do con người đọc, rút ra các ý chính rồi trình bày lại một cách ngắn gọn, dễ hiểu"],[35,4,1,32,0,31,0,31,"Định nghĩa Tóm tắt văn bản là quá trình làm giảm độ dài, độ phức tạp của văn bản mà vẫn giữ lại được nội dung quan trọng của văn bản đó","Định nghĩa Tóm tắt văn bản là quá trình làm giảm độ dài, độ phức tạp của văn bản mà vẫn giữ lại được nội dung quan trọng của văn bản đó"],[53,22,1,35,0,34,0,34,"Phân loại tóm tắt văn bản Có nhiều cách phân loại tóm tắt, phụ thuộc vào tiêu chí sử dụng để phân loại, sau đây là một số cách phân loại cần quan tâm: 2.4.1","Phân loại tóm tắt văn bản Có nhiều cách phân loại tóm tắt, phụ thuộc vào tiêu chí sử dụng để phân loại, sau đây là một số cách phân loại cần quan tâm: 2.4.1"],[56,25,1,53,0,52,0,52,"Rõ ràng, tóm tắt đa văn bản thì khó hơn, vì ngoài những công việc của tóm tắt đơn văn bản, tóm tắt đa văn bản còn phải thực hiện các công việc như tiền xử lý trích rút, tích hợp thống nhất khuôn dạng và hiển thị kết quả theo cách riêng","Rõ ràng, tóm tắt đa văn bản thì khó hơn, vì ngoài những công việc của tóm tắt đơn văn bản, tóm tắt đa văn bản còn phải thực hiện các công việc như tiền xử lý trích rút, tích hợp thống nhất khuôn dạng và hiển thị kết quả theo cách riêng"],[57,26,1,57,0,56,0,56,"Ngoài ra, tóm tắt đa văn bản còn phải đối mặt với các vấn đề như dư thừa trùng lặp dữ liệu giữa các văn bản nguồn, nội dung các văn bản nguồn phân tán, độ rút gọn yêu cầu cao, thời gian xử lý cần phải nhanh trong khi sự phức tạp trong xử lý lớn","Ngoài ra, tóm tắt đa văn bản còn phải đối mặt với các vấn đề như dư thừa trùng lặp dữ liệu giữa các văn bản nguồn, nội dung các văn bản nguồn phân tán, độ rút gọn yêu cầu cao, thời gian xử lý cần phải nhanh trong khi sự phức tạp trong xử lý lớn"],[55,24,1,43,0,42,0,42,"Ngược lại, tóm tắt đa văn bản là từ nhiều văn bản nguồn cũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng thời cho nhiều văn bản khác nhau","Ngược lại, tóm tắt đa văn bản là từ nhiều văn bản nguồn cũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng thời cho nhiều văn bản khác nhau"],[54,23,1,25,0,24,0,24,"Theo đầu vào hệ thống Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn gọn của văn bản đó","Theo đầu vào hệ thống Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn gọn của văn bản đó"],[284,243,1,56,0,55,0,55,"Tách câu, tách từ Trong tiếng Việt, dấu cách (space) không được sử dụng như 1 kí hiệu phân tách từ, nó chỉ có ý nghĩa phân tách các âm tiết với nhau, có khoảng 70% các từ gồm 2 âm tiết, và 14% các từ gồm 3 âm tiết, còn lại là 1 âm tiết","Tách câu, tách từ Trong tiếng Việt, dấu cách (space) không được sử dụng như 1 kí hiệu phân tách từ, nó chỉ có ý nghĩa phân tách các âm tiết với nhau, có khoảng 70% các từ gồm 2 âm tiết, và 14% các từ gồm 3 âm tiết, còn lại là 1 âm tiết"],[285,244,1,18,0,17,0,17,"Hơn nữa, việc kết hợp các âm tiết có nhiều cách, mỗi cách cho một nghĩa khác nhau","Hơn nữa, việc kết hợp các âm tiết có nhiều cách, mỗi cách cho một nghĩa khác nhau"],[292,251,1,27,0,26,0,26,"Để sử dụng trong chương trình lần này, phiên bản mới nhất 4.1.1c, mã nguồn của công cụ được tải tại website của dự án VLSP [6]","Để sử dụng trong chương trình lần này, phiên bản mới nhất 4.1.1c, mã nguồn của công cụ được tải tại website của dự án VLSP [6]"],[296,255,1,23,0,22,0,22,"Do đó để tiết kiệm thời gian, việc tách câu trong phần này sử dụng luôn modul tách câu trong công cụ VNTokenizer","Do đó để tiết kiệm thời gian, việc tách câu trong phần này sử dụng luôn modul tách câu trong công cụ VNTokenizer"],[295,254,1,32,0,31,0,31,"Ngoài ra việc tách câu khá đơn giản nhưng cần xử lý các trường hợp nhập nhằng dấu chấm câu và dấu chấm trong từ(trong email, số thập phân, địa chỉ web)","Ngoài ra việc tách câu khá đơn giản nhưng cần xử lý các trường hợp nhập nhằng dấu chấm câu và dấu chấm trong từ(trong email, số thập phân, địa chỉ web)"],[294,253,1,28,0,27,0,27,"Với độ chính xác xấp xỉ 97% (theo thống kê của tác giả trên website) là kết quả rất cao so với công cụ tách từ hiện nay","Với độ chính xác xấp xỉ 97% (theo thống kê của tác giả trên website) là kết quả rất cao so với công cụ tách từ hiện nay"],[293,252,1,54,0,53,0,53,"Công cụ này được xây dựng sử dụng kết hợp từ điển (từ điển tiếng Việt được lấy từ đề tài VLSP) và ngram, trong đó mô hình ngram được huấn luyện sử dụng treebank tiếng Việt (70,000 câu đã được tách từ), treebank là kho ngữ liệu câu được chú giải ngữ pháp","Công cụ này được xây dựng sử dụng kết hợp từ điển (từ điển tiếng Việt được lấy từ đề tài VLSP) và ngram, trong đó mô hình ngram được huấn luyện sử dụng treebank tiếng Việt (70,000 câu đã được tách từ), treebank là kho ngữ liệu câu được chú giải ngữ pháp"],[289,248,0.8965517282485962,104,12,118,8,112,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 30 o So khớp từ dài nhất (Longest Matching) o So khớp cực đại (Maximum Matching) o Mô hình Markov ẩn (Hidden Markov Models- HMM) o Học dựa trên sự cải biến (Transformation-based Learning – TBL) o Chuyển đổi trạng thái trọng số hữu hạn(Weighted Finite State Transducer) o Độ hỗn loạn cực đại (Maximum Entropy – ME) o Máy học sử dụng vectơ hỗ trợ (Support Vector Machines) o Trường xác xuất có điều kiện (CRFs) Bài toán tách từ khá phức tạp, do đó việc tách từ trong bước này sẽ sử dụng công cụ VNTokenizer, được phát triển bởi nhóm tác giả Lê Hồng Phương","Một số phương pháp có thể áp dụng: o So khớp từ dài nhất (Longest Matching) o So khớp cực đại (Maximum Matching) o Mô hình Markov ẩn (Hidden Markov Models- HMM) o Học dựa trên sự cải biến (Transformation-based Learning TBL) o Chuyển đổi trạng thái trọng số hữu hạn(Weighted Finite State Transducer) o Độ hỗn loạn cực đại (Maximum Entropy ME) o Máy học sử dụng vectơ hỗ trợ (Support Vector Machines) o Trường xác xuất có điều kiện (CRFs) Bài toán tách từ khá phức tạp, do đó việc tách từ trong bước này sẽ sử dụng công cụ VNTokenizer, được phát triển bởi nhóm tác giả Lê Hồng Phương"],[291,250,1,29,0,28,0,28,"Phiên bản cũ nhất là phiên bản vnTokenizer 2.0 được xây dựng vào năm 2005 khi đó nó mới là một ứng dụng đơn với giao diện đơn giản","Phiên bản cũ nhất là phiên bản vnTokenizer 2.0 được xây dựng vào năm 2005 khi đó nó mới là một ứng dụng đơn với giao diện đơn giản"],[290,249,1,20,0,19,0,19,"Đây là công cụ tách từ tự động cho tiếng Việt, mã nguồn mở, được viết bằng ngôn ngữ Java","Đây là công cụ tách từ tự động cho tiếng Việt, mã nguồn mở, được viết bằng ngôn ngữ Java"],[286,245,1,26,0,25,0,25,"Vì thế, để xử lý tiếng Việt, bài toán tách từ (word segmentation) là 1 trong những bài toán cơ bản và quan trọng bậc nhất","Vì thế, để xử lý tiếng Việt, bài toán tách từ (word segmentation) là 1 trong những bài toán cơ bản và quan trọng bậc nhất"],[287,247,0.6060606241226196,20,26,45,0,19,"Ngoài tiếng Việt, có khá nhiều các ngôn ngữ châu Á khác cũng cần bước tách từ, ví dụ như: tiếng Nhật, tiếng Trung, tiếng Hàn,… do đó vấn đề này nhận được sự quan tâm rộng rãi và có nhiều hướng tiếp cận khác nhau","do đó vấn đề này nhận được sự quan tâm rộng rãi và có nhiều hướng tiếp cận khác nhau"],[287,246,0.6944444179534912,25,0,24,0,24,"Ngoài tiếng Việt, có khá nhiều các ngôn ngữ châu Á khác cũng cần bước tách từ, ví dụ như: tiếng Nhật, tiếng Trung, tiếng Hàn,… do đó vấn đề này nhận được sự quan tâm rộng rãi và có nhiều hướng tiếp cận khác nhau","Ngoài tiếng Việt, có khá nhiều các ngôn ngữ châu Á khác cũng cần bước tách từ, ví dụ như: tiếng Nhật, tiếng Trung, tiếng Hàn,"],[311,272,0.9850746393203735,99,0,100,0,99,"Trong mô hình lần này, do chỉ xử lý ở mức nông, nên không xét đến các vấn đề ở mức cú pháp và ngữ nghĩa, nhưng để tăng độ chính xác, bài toán sẽ sử dụng việc đồng nhất các từ đồng nghĩa(xử lý chung cho cả 3 loại trên) dựa trên từ điển đồng nghĩa thô xây dựng sẵn, bộ từ điển này gồm gần 2800 mục, xây dựng bằng cách dùng công cụ tải các trang của từ điển Việt – Việt tại trang tratu.soha.vn, sau đó tách thẻ có chứa các từ đồng nghĩa rồi ghép lại","Trong mô hình lần này, do chỉ xử lý ở mức nông, nên không xét đến các vấn đề ở mức cú pháp và ngữ nghĩa, nhưng để tăng độ chính xác, bài toán sẽ sử dụng việc đồng nhất các từ đồng nghĩa(xử lý chung cho cả 3 loại trên) dựa trên từ điển đồng nghĩa thô xây dựng sẵn, bộ từ điển này gồm gần 2800 mục, xây dựng bằng cách dùng công cụ tải các trang của từ điển Việt Việt tại trang tratu.soha.vn, sau đó tách thẻ có chứa các từ đồng nghĩa rồi ghép lại"],[310,271,1,20,0,19,0,19,"Việc xử lý từ đồng nghĩa là rất quan trọng, nhất là trong bài toán tóm tắt hướng truy vấn","Việc xử lý từ đồng nghĩa là rất quan trọng, nhất là trong bài toán tóm tắt hướng truy vấn"],[306,267,0.675000011920929,27,22,50,0,28,"Ví dụ: siêng năng, chăm chỉ, cần cù, …  Từ đồng nghĩa hoàn toàn Ví dụ: hổ, cọp, hùm, …  Từ đồng nghĩa không hoàn toàn Ví dụ: Ăn, xơi, chén, …(biểu thị thái độ, tình cảm khác nhau đối với người đối thoại hoặc điều được nói đến)","Từ đồng nghĩa không hoàn toàn Ví dụ: Ăn, xơi, chén, .(biểu thị thái độ, tình cảm khác nhau đối với người đối thoại hoặc điều được nói đến)"],[309,270,1,39,0,38,0,38,"Còn loại 3 thì phải xét đến ngữ nghĩa của từ trong ngữ cảnh của văn bản, đây có thể coi là bài toán phức tạp nhất trong xử lý ngôn ngữ, hiện nay chưa có nhiều nghiên cứu","Còn loại 3 thì phải xét đến ngữ nghĩa của từ trong ngữ cảnh của văn bản, đây có thể coi là bài toán phức tạp nhất trong xử lý ngôn ngữ, hiện nay chưa có nhiều nghiên cứu"],[307,268,0.8333333134651184,10,0,11,0,11,"Mang, khiêng, vác, …(biểu thị những cách thức hành động khác nhau)","Mang, khiêng, vác, .(biểu thị những cách thức hành động khác nhau)"],[308,269,1,17,0,16,0,16,"Với loại 1 và loại 2 thì các từ đồng nghĩa có thể thay thế cho nhau","Với loại 1 và loại 2 thì các từ đồng nghĩa có thể thay thế cho nhau"],[316,276,0.8908296823501587,102,12,123,1,104,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 32 lãnh thổ, bờ cõi, biên thuỳ, biên giới,biên cương rỗi rãi, rỗi, rảnh rỗi, rảnh rang, rảnh thương nhân, nhà buôn, thương gia, doanh nhân, doanh gia quả cảm, gan góc, dũng cảm, gan dạ, dũng mãnh, can đảm, anh dũng tả, mô tả, miêu tả, diễn tả, diễn đạt, biểu đạt Bảng 2: Một số mục từ đồng nghĩa Sau bước tách từ và loại bỏ từ dừng, các câu sẽ được xử lý theo theo cách duyệt tất cả các từ, với mỗi từ, tìm từ đó trong từ điển đồng nghĩa, nếu có thì thực hiện thay thế từ đó bằng từ đầu tiên trong mục từ chứa nó","http://tratu.soha.vn/ lãnh thổ, bờ cõi, biên thuỳ, biên giới,biên cương rỗi rãi, rỗi, rảnh rỗi, rảnh rang, rảnh thương nhân, nhà buôn, thương gia, doanh nhân, doanh gia quả cảm, gan góc, dũng cảm, gan dạ, dũng mãnh, can đảm, anh dũng tả, mô tả, miêu tả, diễn tả, diễn đạt, biểu đạt Sau bước tách từ và loại bỏ từ dừng, các câu sẽ được xử lý theo theo cách duyệt tất cả các từ, với mỗi từ, tìm từ đó trong từ điển đồng nghĩa, nếu có thì thực hiện thay thế từ đó bằng từ đầu tiên trong mục từ chứa nó"],[313,274,1,22,0,21,0,21,"Tuy chưa được đầy đủ và xử lý đơn giản nhưng cũng góp phần tăng độ chính xác cho việc tóm tắt","Tuy chưa được đầy đủ và xử lý đơn giản nhưng cũng góp phần tăng độ chính xác cho việc tóm tắt"],[314,275,1,15,0,14,0,14,"Dưới đây là một số mục từ trong bộ từ đồng nghĩa sẽ sử dụng","Dưới đây là một số mục từ trong bộ từ đồng nghĩa sẽ sử dụng"],[312,273,1,61,0,60,0,60,"Mỗi mục gồm các từ gần nghĩa hoặc đồng nghĩa với nhau về mặt nào đó, và mỗi từ chỉ xuất hiện trong một mục, trên thực tế có những từ có thể ở nhiều mục, nhưng số lượng các từ đó không nhiều nên trong bộ từ điển này sẽ sử dụng nghĩa phổ biến nhất của các từ đó","Mỗi mục gồm các từ gần nghĩa hoặc đồng nghĩa với nhau về mặt nào đó, và mỗi từ chỉ xuất hiện trong một mục, trên thực tế có những từ có thể ở nhiều mục, nhưng số lượng các từ đó không nhiều nên trong bộ từ điển này sẽ sử dụng nghĩa phổ biến nhất của các từ đó"],[187,153,0.9189189076423645,34,0,36,0,36,"Công thức của độ đo ROUGE-N như sau: Cho R=(r1, r2, …, rn) là tập các tóm tắt mẫu, s là tóm tắt tự động, Ωn(d) là vector biểu diễn mô hình n-gram của văn bản d","Công thức của độ đo ROUGE-N như sau: Cho R=(r1, r2, ., rn) là tập các tóm tắt mẫu, s là tóm tắt tự động, n(d) là vector biểu diễn mô hình n-gram của văn bản d"],[188,154,1,21,0,20,0,20,"Độ đo ROUGE được sử dụng làm độ đo chính thức của các hội nghị DUC 2004- 2007 và TAC 2008-2012","Độ đo ROUGE được sử dụng làm độ đo chính thức của các hội nghị DUC 2004- 2007 và TAC 2008-2012"],[175,142,1,36,0,35,0,35,"Đánh giá kết quả tóm tắt Đánh giá một bản tóm tắt là một công việc khó bởi không tồn tại một bản tóm tắt lý tưởng cho một (hoặc một tập) văn bản đưa ra","Đánh giá kết quả tóm tắt Đánh giá một bản tóm tắt là một công việc khó bởi không tồn tại một bản tóm tắt lý tưởng cho một (hoặc một tập) văn bản đưa ra"],[185,151,1,41,0,40,0,40,"Sử dụng các độ đo ROUGE ROUGE(Recall-Oriented Understudy of Gisting Evaluation [2]) cũng được đưa ra bởi Lin, vào năm 2009, đây là tập hợp các độ đo dựa trên mô hình n-gram của BLEU với nhiều cách tính khác nhau","Sử dụng các độ đo ROUGE ROUGE(Recall-Oriented Understudy of Gisting Evaluation [2]) cũng được đưa ra bởi Lin, vào năm 2009, đây là tập hợp các độ đo dựa trên mô hình n-gram của BLEU với nhiều cách tính khác nhau"],[176,143,1,13,0,12,0,12,"Hơn nữa, việc đánh giá nội dung tóm tắt cũng rất khó khăn","Hơn nữa, việc đánh giá nội dung tóm tắt cũng rất khó khăn"],[179,146,1,21,0,20,0,20,"Bên cạnh đó, khi việc đánh giá được thực hiện bởi con người thì chi phí đánh giá sẽ rất cao","Bên cạnh đó, khi việc đánh giá được thực hiện bởi con người thì chi phí đánh giá sẽ rất cao"],[178,145,1,28,0,27,0,27,"Thực tế luôn có khả năng một hệ thống sinh ra một bản tóm tắt tốt nhưng lại sai khác với bản tóm tắt do người thực hiện","Thực tế luôn có khả năng một hệ thống sinh ra một bản tóm tắt tốt nhưng lại sai khác với bản tóm tắt do người thực hiện"],[177,144,1,47,0,46,0,46,"Trường hợp kết quả là một câu trả lời cho một câu hỏi, ta có thể xác định được câu trả lời đó đúng hay sai, nhưng trong các trường hợp khác, thật khó trả lời liệu đầu ra là phải một kết quả đúng hay không","Trường hợp kết quả là một câu trả lời cho một câu hỏi, ta có thể xác định được câu trả lời đó đúng hay sai, nhưng trong các trường hợp khác, thật khó trả lời liệu đầu ra là phải một kết quả đúng hay không"],[180,147,1,44,0,43,0,43,"Mặt khác, tóm tắt văn bản còn liên quan đến tỉ lệ nén văn bản, do đó, việc đánh giá bản tóm tắt cần phải quan tâm đến vấn đề này, khi đó độ phức tạp và chi phí đánh giá sẽ tăng cao","Mặt khác, tóm tắt văn bản còn liên quan đến tỉ lệ nén văn bản, do đó, việc đánh giá bản tóm tắt cần phải quan tâm đến vấn đề này, khi đó độ phức tạp và chi phí đánh giá sẽ tăng cao"],[183,149,1,37,0,36,0,36,"Sử dụng so khớp n-gram Phương pháp này được Lin và Hovy đưa ra năm 2002 dựa trên mô hình n-gram của độ đo BLEU (Bilingual Evaluation Understudy [1], độ đo đánh giá kết quả dịch máy)","Sử dụng so khớp n-gram Phương pháp này được Lin và Hovy đưa ra năm 2002 dựa trên mô hình n-gram của độ đo BLEU (Bilingual Evaluation Understudy [1], độ đo đánh giá kết quả dịch máy)"],[181,148,0.9629629850387573,13,0,12,0,12,"Dưới đây là hai phương pháp đánh giá tự động thường sử dụng:","Dưới đây là hai phương pháp đánh giá tự động thường sử dụng: 2.8.1"],[184,150,0.8999999761581421,54,0,59,0,59,"Ý tưởng của phương pháp này là so khớp n-gram liên tiếp của bản tóm tắt thủ công và tóm tắt tự động, theo công thức sau: Score=α1*Score1+ α2*Score2+ α3*Score3+ α4*Score4 Trong đó: Scorei = Số i-gram trùng nhau/Tổng số i-gram của bản tóm tắt thủ công αi là hệ số đánh giá độ quan trọng của các Scorei 2.8.2","Ý tưởng của phương pháp này là so khớp n-gram liên tiếp của bản tóm tắt thủ công và tóm tắt tự động, theo công thức sau: Score=1*Score1+ 2*Score2+ 3*Score3+ 4*Score4 Trong đó: Scorei = Số i-gram trùng nhau/Tổng số i-gram của bản tóm tắt thủ công i là hệ số đánh giá độ quan trọng của các Scorei 2.8.2"],[186,152,1,18,0,17,0,17,"Thường sử dụng nhất là độ đo ROUGE-N, với n là giá trị của mô hình n-gram, n={1,2,3,4}","Thường sử dụng nhất là độ đo ROUGE-N, với n là giá trị của mô hình n-gram, n={1,2,3,4}"],[257,219,1,25,0,24,0,24,"Ví dụ như tìm kiếm thông tin về giá vàng, người ta không biết giá vàng tăng hay giảm, có biến động gì gần đây","Ví dụ như tìm kiếm thông tin về giá vàng, người ta không biết giá vàng tăng hay giảm, có biến động gì gần đây"],[265,227,0.7651515007019043,101,1,103,0,102," Thực hiện tóm tắt Bước này áp dụng mô hình tóm tắt đã đề xuất để tạo kết quả - Chuẩn hóa: bước này sẽ thực hiện xử lý tiêu đề, các đoạn văn trong ngoặc đơn - Tách câu, tách từ: thực hiện tách câu, tách từ sử dụng công cụ VNTokenizer - Loại bỏ từ dừng: tìm kiếm và loại bỏ các từ dừng dựa trên danh sách có sẵn - Xử lý từ đồng nghĩa: đồng bộ các từ đồng nghĩa về cùng 1 dạng - Mô hình hóa văn bản: tính TF.IDF và chuyển các câu về dạng vector","Thực hiện tóm tắt Bước này áp dụng mô hình tóm tắt đã đề xuất để tạo kết quả - Chuẩn hóa: bước này sẽ thực hiện xử lý tiêu đề, các đoạn văn trong ngoặc đơn - Tách câu, tách từ: thực hiện tách câu, tách từ sử dụng công cụ VNTokenizer - Loại bỏ từ dừng: tìm kiếm và loại bỏ các từ dừng dựa trên danh sách có sẵn - Xử lý từ đồng nghĩa: đồng bộ các từ đồng nghĩa về cùng 1 dạng - Mô hinh hóa văn bản: tính TF.IDF và chuyển các câu về dạng vector - Trích rút câu, tạo tóm tắt: đây là giải thuật đã đề xuất, thực hiện tính toán độ tương đồng sử dụng độ đo cosin và một số phép toán trên vector để tìm kiếm các câu phù hợp đưa vào kết quả tóm tắt, và được ghép lại theo phương pháp hiển thị phân đoạn"],[267,228,0.9777777791023254,22,1,22,0,21," Đầu ra: văn bản tóm tắt Chi tiết các kỹ thuật sử dụng trong các bước sẽ trình bày ở phần sau","Đầu ra: văn bản tóm tắt Chi tiết các kỹ thuật sử dụng trong các bước sẽ trình bày ở phần sau"],[260,222,0.9824561476707458,28,0,27,0,27,"Nhưng không phải từ nào trong các câu đó cũng đều quan trọng nên các từ xuất hiện trong truy vấn gốc được nhân lên một trọng số α","Nhưng không phải từ nào trong các câu đó cũng đều quan trọng nên các từ xuất hiện trong truy vấn gốc được nhân lên một trọng số"],[258,220,1,48,0,47,0,47,"Hoặc tìm cách sửa một lỗi máy tính thì người dùng sẽ đưa ra các thông tin về lỗi đó, sau khi xem bản tóm tắt của các kết quả từ máy tìm kiếm, sẽ biết được kết quả nào phù hợp để quyết định đọc hay không","Hoặc tìm cách sửa một lỗi máy tính thì người dùng sẽ đưa ra các thông tin về lỗi đó, sau khi xem bản tóm tắt của các kết quả từ máy tìm kiếm, sẽ biết được kết quả nào phù hợp để quyết định đọc hay không"],[259,221,1,27,0,26,0,26,"Trong giải thuật chọn câu, các câu được chọn sẽ được thêm vào truy vấn, với mục đích làm thêm từ khóa liên quan đến truy vấn","Trong giải thuật chọn câu, các câu được chọn sẽ được thêm vào truy vấn, với mục đích làm thêm từ khóa liên quan đến truy vấn"],[264,226,1,55,0,54,0,54,"- Truy vấn: sử dụng bộ mã như văn bản, là một đoạn văn bản chứa các từ khóa cần tìm kiếm, nếu cần chính xác thì dùng dấu phảy để ngăn cách các từ khóa - Độ rút gọn: có thể là số lượng từ (100-150 từ) hoặc phần trăm văn bản nguồn (10-20%)","- Truy vấn: sử dụng bộ mã như văn bản, là một đoạn văn bản chứa các từ khóa cần tìm kiếm, nếu cần chính xác thì dùng dấu phảy để ngăn cách các từ khóa - Độ rút gọn: có thể là số lượng từ (100-150 từ) hoặc phần trăm văn bản nguồn (10-20%)"],[263,225,0.9677419066429138,45,0,46,0,45,"Tổng quan về modul đó như sau:  Đầu vào - Văn bản: văn bản đầu vào sử dụng bộ mã Unicode utf-8, chỉ chứa text, chính xác về chính tả, dấu câu, không quá ngắn(5 câu trở lên), nội dung phải liên quan tới truy vấn","Tổng quan về modul đó như sau: Đầu vào - Văn bản: văn bản đầu vào sử dụng bộ mã Unicode utf-8, chỉ chứa text, chính xác về chính tả, dấu câu, không quá ngắn(5 câu trở lên), nội dung phải liên quan tới truy vấn"],[262,224,1,21,0,20,0,20,"Theo đó thì bản tóm tắt sẽ dễ hiểu hơn vì bao gồm các thông tin liên quan tới truy vấn","Theo đó thì bản tóm tắt sẽ dễ hiểu hơn vì bao gồm các thông tin liên quan tới truy vấn"],[261,223,1,27,0,26,0,26,"Do đó kết quả tóm tắt sẽ ưu tiên các từ khóa trong truy vấn, và các từ khóa xuất hiện nhiều trong các câu được chọn","Do đó kết quả tóm tắt sẽ ưu tiên các từ khóa trong truy vấn, và các từ khóa xuất hiện nhiều trong các câu được chọn"],[256,218,1,39,0,38,0,38,"Tuy nhiên trong vấn đề tìm kiếm, phần lớn người dùng thường không nắm rõ được nội dung mình muốn biết nên mới sử dụng tìm kiếm, mà chỉ biết các từ khóa liên quan tới vấn đề đó","Tuy nhiên trong vấn đề tìm kiếm, phần lớn người dùng thường không nắm rõ được nội dung mình muốn biết nên mới sử dụng tìm kiếm, mà chỉ biết các từ khóa liên quan tới vấn đề đó"],[251,214,0.875,35,0,34,0,34,"Phạm vi ứng dụng hướng tới của mô hình là tích hợp vào modul trả kết quả của bộ máy tìm kiếm văn bản(search engine), thực hiện tóm tắt văn bản kết quả theo tập","Phạm vi ứng dụng hướng tới của mô hình là tích hợp vào modul trả kết quả của bộ máy tìm kiếm văn bản(search engine), thực hiện tóm tắt văn bản kết quả theo tập từ khóa đã tìm kiếm(chính là truy vấn người dùng)"],[255,217,1,38,0,37,0,37,"Do đó các câu chứa nhiều từ khóa trong truy vấn, hay trong trường hợp này là độ tương đồng lớn, sẽ mang các thông tin quan trọng liên quan đến truy vấn mà người dùng quan tâm","Do đó các câu chứa nhiều từ khóa trong truy vấn, hay trong trường hợp này là độ tương đồng lớn, sẽ mang các thông tin quan trọng liên quan đến truy vấn mà người dùng quan tâm"],[254,216,1,24,0,23,0,23,"Vì văn bản đã được máy tìm kiếm lựa chọn nên nội dung của văn bản và truy vấn sẽ liên quan với nhau","Vì văn bản đã được máy tìm kiếm lựa chọn nên nội dung của văn bản và truy vấn sẽ liên quan với nhau"],[253,215,1,12,0,11,0,11,"Do đó có một số ràng buộc với dữ liệu đầu vào","Do đó có một số ràng buộc với dữ liệu đầu vào"],[245,208,1,97,0,96,0,96,"Đề xuất hướng giải quyết cho tiếng Việt Qua tìm hiểu về các vấn đề liên quan trong tóm tắt và đặc trưng của tiếng Việt, dễ nhận thấy rằng việc tiếp cận ở mức cú pháp và ngữ nghĩa là khá khó khăn, một phần là vì công cụ và dữ liệu hỗ trợ, tuy đã có một số công cụ gán nhãn từ vựng và phân tích cú pháp cho độ chính xác cao nhưng thường chỉ áp dụng cho lĩnh vực hẹp, và còn ở mức nghiên cứu, chưa được công bố chính thức","Đề xuất hướng giải quyết cho tiếng Việt Qua tìm hiểu về các vấn đề liên quan trong tóm tắt và đặc trưng của tiếng Việt, dễ nhận thấy rằng việc tiếp cận ở mức cú pháp và ngữ nghĩa là khá khó khăn, một phần là vì công cụ và dữ liệu hỗ trợ, tuy đã có một số công cụ gán nhãn từ vựng và phân tích cú pháp cho độ chính xác cao nhưng thường chỉ áp dụng cho lĩnh vực hẹp, và còn ở mức nghiên cứu, chưa được công bố chính thức"],[246,209,1,21,0,20,0,20,"Mặt khác, do đặc trưng về ngữ pháp nên các hướng tiếp cận đó thường không chính xác với tiếng Việt","Mặt khác, do đặc trưng về ngữ pháp nên các hướng tiếp cận đó thường không chính xác với tiếng Việt"],[247,210,1,40,0,39,0,39,"Do đó em xin đề xuất mô hình trích rút các câu quan trọng cho bài toán tóm tắt hướng truy vấn dựa trên tần số từ và độ tương đồng câu, áp dụng cho tóm tắt đơn văn bản","Do đó em xin đề xuất mô hình trích rút các câu quan trọng cho bài toán tóm tắt hướng truy vấn dựa trên tần số từ và độ tương đồng câu, áp dụng cho tóm tắt đơn văn bản"],[250,213,1,46,0,45,0,45,"Phương pháp này dựa theo ý tưởng ở giải thuật thứ 2 trong hướng tiếp cận dựa trên đồ thị đã nêu ở trên, nhưng các câu ở đây biểu diễn theo mô hình không gian vector và độ tương đồng sử dụng độ đo cosin","Phương pháp này dựa theo ý tưởng ở giải thuật thứ 2 trong hướng tiếp cận dựa trên đồ thị đã nêu ở trên, nhưng các câu ở đây biểu diễn theo mô hình không gian vector và độ tương đồng sử dụng độ đo cosin"],[248,211,1,42,0,41,0,41,"Mô tả sơ lược như sau: Đầu tiên sử dụng câu truy vấn làm tâm tóm tắt, sau đó tìm câu có độ tương đồng với tâm lớn nhất, mỗi câu được chọn sẽ kết hợp với tâm tạo nên tâm mới","Mô tả sơ lược như sau: Đầu tiên sử dụng câu truy vấn làm tâm tóm tắt, sau đó tìm câu có độ tương đồng với tâm lớn nhất, mỗi câu được chọn sẽ kết hợp với tâm tạo nên tâm mới"],[249,212,1,13,0,12,0,12,"Sau khi kết thúc sẽ loại bỏ câu truy vấn khỏi kết quả","Sau khi kết thúc sẽ loại bỏ câu truy vấn khỏi kết quả"],[158,124,0.8607594966888428,34,0,39,0,38,"Ví dụ: “Tôi ăn dâu, táo và đào” => “Tôi ăn trái cây”  Phương pháp thay thế bộ phận Tư tưởng của phương pháp này là từ các khái niệm bộ phận thay thế bằng khái niệm toàn bộ","Ví dụ: Tôi ăn dâu, táo và đào => Tôi ăn trái cây Phương pháp thay thế bộ phận Tư tưởng của phương pháp này là từ các khái niệm bộ phận thay thế bằng khái niệm toàn bộ"],[157,123,0.9538461565971375,31,0,32,0,31,"Giản lược về mặt ngữ nghĩa  Phương pháp trừu tượng hóa khái niệm Tư tưởng của phương pháp này là từ các khái niệm cụ thể thay thế bằng khái niệm chung","Giản lược về mặt ngữ nghĩa Phương pháp trừu tượng hóa khái niệm Tư tưởng của phương pháp này là từ các khái niệm cụ thể thay thế bằng khái niệm chung"],[130,97,0.9824561476707458,28,1,28,0,27," Phương pháp thống kê tần suất từ Độ quan trọng của từ phụ thuộc vào số lần xuất hiện của từ đó trong các văn bản liên quan","Phương pháp thống kê tần suất từ Độ quan trọng của từ phụ thuộc vào số lần xuất hiện của từ đó trong các văn bản liên quan"],[128,95,0.8393782377243042,81,0,95,0,94,"Người ta chia thành hai loại ngữ cố định, một loại mang lại độ quan trọng cho thành phần đi sau, được gọi là ngữ nhấn mạnh, một loại giúp ta loại bỏ, không xét đến những thành phần đi sau vì nó không có nhiều giá trị trong việc trích rút, được gọi là ngữ dư thừa:  Ngữ nhấn mạnh (Bonus phrase - Emphasizer): Ngữ nhấn mạnh gồm các ngữ như “nói chung là…”, “đặc biệt là…”, “cuối cùng thì…”, “trong bài viết này tôi muốn chỉ ra…”, “bài viết nói về…”, “nội dung gồm…”,..v..v..","Người ta chia thành hai loại ngữ cố định, một loại mang lại độ quan trọng cho thành phần đi sau, được gọi là ngữ nhấn mạnh, một loại giúp ta loại bỏ, không xét đến những thành phần đi sau vì nó không có nhiều giá trị trong việc trích rút, được gọi là ngữ dư thừa: Ngữ nhấn mạnh (Bonus phrase - Emphasizer): Ngữ nhấn mạnh gồm các ngữ như nói chung là., đặc biệt là., cuối cùng thì., trong bài viết này tôi muốn chỉ ra., bài viết nói về., nội dung gồm.,..v..v.."],[129,96,0.6222222447395325,14,1,22,0,21," Ngữ dư thừa (Stigma phrases): Một số ngữ dư thừa: “hiếm khi mà…”, “bài này không nói đến…”, “Không thể nào…”, ..v..v..","Ngữ dư thừa (Stigma phrases): Một số ngữ dư thừa: hiếm khi mà., bài này không nói đến., Không thể nào., ..v..v.."],[120,88,0.8205128312110901,32,14,45,0,31,"Các thống kê này tất nhiên phụ thuộc vào thể loại văn bản…  Chủ đề - Tiêu đề (Title-based): Chủ đề các đoạn văn bản hay tiêu đề các bảng thường chứa các từ và ngữ quan trọng, nên trích rút thông tin từ đây","Chủ đề - Tiêu đề (Title-based): Chủ đề các đoạn văn bản hay tiêu đề các bảng thường chứa các từ và ngữ quan trọng, nên trích rút thông tin từ đây"],[121,89,0.9846153855323792,32,1,32,0,31," Đầu - cuối đoạn (First - Last Sentence): Xác suất câu đầu đoạn hay câu cuối đoạn chứa ý chính của cả đoạn là rất lớn, đặc biệt là câu đầu đoạn","Đầu - cuối đoạn (First - Last Sentence): Xác suất câu đầu đoạn hay câu cuối đoạn chứa ý chính của cả đoạn là rất lớn, đặc biệt là câu đầu đoạn"],[126,93,0.9696969985961914,16,1,16,0,15," Phương pháp ngữ cố định Các ngữ cố định có đặc điểm thống kê rất tốt","Phương pháp ngữ cố định Các ngữ cố định có đặc điểm thống kê rất tốt"],[123,91,0.9811320900917053,26,1,26,0,25," Minh họa - Chú thích (Comments): Trong các câu chú thích, câu minh họa cho ảnh hay đồ thị thường chứa các thông tin quan trọng","Minh họa - Chú thích (Comments): Trong các câu chú thích, câu minh họa cho ảnh hay đồ thị thường chứa các thông tin quan trọng"],[125,92,0.7714285850524902,27,12,38,4,30,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 19 này thường chỉ được dùng để đánh giá độ quan trọng của các câu khác liên quan, chứ không được chọn làm đầu vào cho pha tiếp","Tuy nhiên, các câu này thường chỉ được dùng để đánh giá độ quan trọng của các câu khác liên quan, chứ không được chọn làm đầu vào cho pha tiếp"],[122,90,1,17,0,16,0,16,"Ngoài ra, các đoạn đầu và cuối trong văn bản cũng quan trọng hơn các đoạn giữa","Ngoài ra, các đoạn đầu và cuối trong văn bản cũng quan trọng hơn các đoạn giữa"],[127,94,1,17,0,16,0,16,"Sau các ngữ này thường là các câu hay từ có độ quan trọng là xác định","Sau các ngữ này thường là các câu hay từ có độ quan trọng là xác định"],[131,98,1,24,0,23,0,23,"Các kỹ thuật như TF.IPF hay Tập thuật ngữ thường xuyên (Frequent Item Set) dùng cho công việc xác định tần suất của từ","Các kỹ thuật như TF.IPF hay Tập thuật ngữ thường xuyên (Frequent Item Set) dùng cho công việc xác định tần suất của từ"],[334,292,1,37,0,36,0,36,"Giai đoạn hiển thị Ở bước này, văn bản tóm tắt sẽ được tạo ra bằng cách ghép các câu được chọn theo thứ tự trong văn bản, đó chính là phương pháp hiển thị phân đoạn","Giai đoạn hiển thị Ở bước này, văn bản tóm tắt sẽ được tạo ra bằng cách ghép các câu được chọn theo thứ tự trong văn bản, đó chính là phương pháp hiển thị phân đoạn"],[333,291,0.9166666865348816,22,0,24,0,22,"Khi đó, véc tơ trọng tâm của tập câu được tính theo công thức: 1 m i i cen v V m   1.2","Khi đó, véc tơ trọng tâm của tập câu được tính theo công thức: 1 m i i cen v V m 1.2"],[327,286,0.8941176533699036,76,12,90,0,78,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 33 Giải thuật loại bỏ câu trùng lặp như sau: Bước 1: xét câu si, tính độ tương đồng với các câu sau nó sj Bước 2: với mỗi câu sj, nếu độ tương đồng Ωij>α thì loại bỏ câu sj Bước 3: nếu hết văn bản thì dừng lại, không thì tăng i lên 1 và quay lại bước 1 Qua thực nghiệm trên một số văn bản, cho thấy ngưỡng α=0.8 cho kết quả tương đối chính xác","Giải thuật loại bỏ câu trùng lặp như sau: Bước 1: xét câu si, tính độ tương đồng với các câu sau nó sj Bước 2: với mỗi câu sj, nếu độ tương đồng ij> thì loại bỏ câu sj Bước 3: nếu hết văn bản thì dừng lại, không thì tăng i lên 1 và quay lại bước 1 Qua thực nghiệm trên một số văn bản, cho thấy ngưỡng =0.8 cho kết quả tương đối chính xác"],[325,285,1,41,0,40,0,40,"Độ đo sử dụng để loại bỏ câu trùng lặp và chọn câu phù hợp tạo tóm tắt là độ đo cosin đã trình bày ở trên, nhưng hai vector được tính toán bây giờ là biểu diễn cho hai câu","Độ đo sử dụng để loại bỏ câu trùng lặp và chọn câu phù hợp tạo tóm tắt là độ đo cosin đã trình bày ở trên, nhưng hai vector được tính toán bây giờ là biểu diễn cho hai câu"],[324,284,1,47,0,46,0,46,"Để hạn chế hiện tượng trùng lặp thông tin trong kết quả tóm tắt, trước khi đưa vào lựa chọn, các câu sẽ được so sánh với nhau để tìm các câu gần tương tự nhau, và loại bỏ câu có vị trí xa tiêu đề hơn","Để hạn chế hiện tượng trùng lặp thông tin trong kết quả tóm tắt, trước khi đưa vào lựa chọn, các câu sẽ được so sánh với nhau để tìm các câu gần tương tự nhau, và loại bỏ câu có vị trí xa tiêu đề hơn"],[323,283,1,27,0,26,0,26,"Chọn câu phù hợp tạo tóm tắt Bước này sẽ áp dụng các giải thuật đánh giá câu quan trọng để đưa vào kết quả tóm tắt","Chọn câu phù hợp tạo tóm tắt Bước này sẽ áp dụng các giải thuật đánh giá câu quan trọng để đưa vào kết quả tóm tắt"],[330,289,0.761904776096344,64,0,66,0,64,"Giải thuật chọn câu theo các bước sau: Bước 1: khởi tạo tâm là truy vấn Bước 2: tính độ tương đồng Ω của các câu trong văn bản với tâm Bước 3: chọn câu có Ω lớn nhất, kết hợp vào tâm, xóa câu đó khỏi văn bản Bước 4: kiểm tra độ dài, nếu chưa đủ, tính toán lại tâm và quay lại bước 2","Giải thuật chọn câu theo các bước sau: Bước 1: khởi tạo tâm là truy vấn Bước 2: tính độ tương đồng của các câu trong văn bản với tâm Bước 3: chọn câu có lớn nhất, kết hợp vào tâm, xóa câu đó khỏi văn bản Bước 4: kiểm tra độ dài, nếu chưa đủ, tính toán lại tâm và quay lại bước 2 Tâm của tóm tắt sẽ được tính toán lại dựa trên công thức tính vector trọng tâm của nhóm, và độ tương tự của 1 câu với tâm sẽ là độ tương tự với vector đó"],[329,288,0.96875,62,0,63,0,63,"Quá trình chọn câu quan trọng sẽ thực hiện như hình dưới đây Hình 4: Minh họa quá trình chọn câu quan trọng Sau khi chuyển biểu diễn các câu về mô hình không gian vector, mỗi câu sẽ là một vector, văn bản là danh sách các vector, độ tương đồng giữa các câu sẽ được tính toán sử dụng độ đo cosin","Quá trình chọn câu quan trọng sẽ thực hiện như hình dưới đây Hinh 4: Minh họa quá trình chọn câu quan trọng Sau khi chuyển biểu diễn các câu về mô hình không gian vector, mỗi câu sẽ là một vector, văn bản là danh sách các vector, độ tương đồng giữa các câu sẽ được tính toán sử dụng độ đo cosin"],[328,287,1,35,0,34,0,34,"Do đó trong bước này sẽ thực hiện loại bỏ một câu nếu có độ tương tự lớn hơn 0.8 với câu nào đó đứng trước nó, theo thứ tự vị trí trong văn bản","Do đó trong bước này sẽ thực hiện loại bỏ một câu nếu có độ tương tự lớn hơn 0.8 với câu nào đó đứng trước nó, theo thứ tự vị trí trong văn bản"],[332,290,0.9032257795333862,28,0,30,0,30,"*) Véc tơ trọng tâm của nhóm Giả sử có một tập câu = {s1, s2, …, sm} có lần lượt các véc tơ biểu diễn là v1, v2, …, vm","*) Véc tơ trọng tâm của nhóm Giả sử có một tập câu = {s1, s2, ., sm} có lần lượt các véc tơ biểu diễn là v1, v2, ., vm"],[51,20,0.9756097793579102,20,1,20,0,19," Hỗ trợ tóm lược nội dung cuộc họp, website, chương trình phát thanh và truyền hình, sổ tay công việc","Hỗ trợ tóm lược nội dung cuộc họp, website, chương trình phát thanh và truyền hình, sổ tay công việc"],[47,16,0.95652174949646,11,1,11,0,10," Trợ giúp thông minh việc đọc và khai thác thông tin","Trợ giúp thông minh việc đọc và khai thác thông tin"],[48,17,0.9523809552192688,10,1,10,0,9," Tóm lược danh sách tìm kiếm từ các Search Engine","Tóm lược danh sách tìm kiếm từ các Search Engine"],[49,18,0.9599999785423279,12,1,12,0,11," Giản lược nội dung trình bày cho các thiết bị cầm tay","Giản lược nội dung trình bày cho các thiết bị cầm tay"],[50,19,0.95652174949646,11,1,11,0,10," Sinh tự động chủ đề, tiêu đề, dẫn đường văn bản","Sinh tự động chủ đề, tiêu đề, dẫn đường văn bản"],[46,15,0.9589040875434875,35,0,36,0,35,"Ứng dụng của tóm tắt văn bản Tóm tắt văn bản có nhiều ứng dụng trong thực tế, một số ứng dụng nổi bật như:  Tóm tắt tự động các tin tức trên báo điện tử","Ứng dụng của tóm tắt văn bản Tóm tắt văn bản có nhiều ứng dụng trong thực tế, một số ứng dụng nổi bật như: Tóm tắt tự động các tin tức trên báo điện tử"],[347,304,1,45,0,44,0,44,"Chức năng chính là quản lý các văn bản mẫu bao gồm văn bản gốc và bản tóm tắt thủ công, được tích hợp chức năng tách từ, tách câu của VNTokenizer nên việc tạo văn bản mẫu sẽ chính xác và hiệu quả hơn","Chức năng chính là quản lý các văn bản mẫu bao gồm văn bản gốc và bản tóm tắt thủ công, được tích hợp chức năng tách từ, tách câu của VNTokenizer nên việc tạo văn bản mẫu sẽ chính xác và hiệu quả hơn"],[348,305,1,32,0,31,0,31,"Ngoài ra còn có chức năng phát hiện ra các văn bản lỗi font, các văn bản này không thể sử dụng trong các công cụ đi kèm nên cần loại bỏ","Ngoài ra còn có chức năng phát hiện ra các văn bản lỗi font, các văn bản này không thể sử dụng trong các công cụ đi kèm nên cần loại bỏ"],[344,301,1,42,0,41,0,41,"Đầu vào của chương trình là văn bản gốc, truy vấn, và độ rút gọn, đầu ra sẽ là văn bản tóm tắt, có thể xem chi tiết một số bước xử lý ở chức năng Note góc dưới trái giao diện","Đầu vào của chương trình là văn bản gốc, truy vấn, và độ rút gọn, đầu ra sẽ là văn bản tóm tắt, có thể xem chi tiết một số bước xử lý ở chức năng Note góc dưới trái giao diện"],[343,300,1,16,0,15,0,15,"Chi tiết các chức năng đã ghi chú đầy đủ trên ảnh giao diện chương trình","Chi tiết các chức năng đã ghi chú đầy đủ trên ảnh giao diện chương trình"],[342,299,1,24,0,23,0,23,"Chương trình tóm tắt Đây là chương trình thực hiện tóm tắt một văn bản dựa trên giải thuật đã phân tích ở trên","Chương trình tóm tắt Đây là chương trình thực hiện tóm tắt một văn bản dựa trên giải thuật đã phân tích ở trên"],[341,298,1,7,0,6,0,6,"Các công cụ đã xây dựng 2.1.1.1","Các công cụ đã xây dựng 2.1.1.1"],[346,303,1,19,0,18,0,18,"Công cụ tạo tập mẫu Công cụ này hỗ trợ, tạo, chỉnh sửa các bản tóm tắt thủ công","Công cụ tạo tập mẫu Công cụ này hỗ trợ, tạo, chỉnh sửa các bản tóm tắt thủ công"],[345,302,0.625,5,1,7,1,7,"Hình 5: Giao diện chương trình demo 2.1.1.2","Hinh 5: Giao diện chương trinh demo 2.1.1.2"],[135,102,1,32,0,31,0,31,"Việc đánh giá các mối quan hệ sẽ dựa trên các mạng ngữ nghĩa, các quan hệ cú pháp hoặc thông qua các phương pháp xác định độ liên quan truyền thống","Việc đánh giá các mối quan hệ sẽ dựa trên các mạng ngữ nghĩa, các quan hệ cú pháp hoặc thông qua các phương pháp xác định độ liên quan truyền thống"],[140,107,0.6470588445663452,11,0,15,0,15,"Ví dụ “cây” là một loại “thực vật”, có bộ phận là “lá”, chất liệu là “gỗ”","Ví dụ cây là một loại thực vật, có bộ phận là lá, chất liệu là gỗ"],[139,106,0.98591548204422,35,1,35,0,34," Phương pháp liên kết từ vựng: Phương pháp liên kết từ vựng sử dụng các từ điển quan hệ từ vựng đế xây dựng các chuỗi từ liên kết với nhau vể mặt ngữ nghĩa","Phương pháp liên kết từ vựng: Phương pháp liên kết từ vựng sử dụng các từ điển quan hệ từ vựng đế xây dựng các chuỗi từ liên kết với nhau vể mặt ngữ nghĩa"],[137,104,1,26,0,25,0,25,"Các đoạn (câu) trong văn bản nguồn được tính toán độ liên quan lẫn nhau sử dụng các kỹ thuật như Cosine, TF.IPF hay N-gram Overlap","Các đoạn (câu) trong văn bản nguồn được tính toán độ liên quan lẫn nhau sử dụng các kỹ thuật như Cosine, TF.IPF hay N-gram Overlap"],[138,105,1,12,0,11,0,11,"Sau đó chọn ra đoạn (câu) có độ liên quan lớn nhất","Sau đó chọn ra đoạn (câu) có độ liên quan lớn nhất"],[136,103,0.9876543283462524,40,1,40,0,39," Phương pháp quan hệ lẫn nhau: Phương pháp này xác định mối quan hệ giữa các đoạn trong văn bản hay các câu trong đoạn với nhau thông qua các kỹ thuật thu thập thông tin ở mức văn bản","Phương pháp quan hệ lẫn nhau: Phương pháp này xác định mối quan hệ giữa các đoạn trong văn bản hay các câu trong đoạn với nhau thông qua các kỹ thuật thu thập thông tin ở mức văn bản"],[133,100,1,32,0,31,0,31,"Phương pháp cấu trúc Là các phương pháp sử dụng các mối liên hệ cấu trúc - ngữ pháp - ngữ nghĩa để xác định các đơn vị ngữ liệu quan trọng","Phương pháp cấu trúc Là các phương pháp sử dụng các mối liên hệ cấu trúc - ngữ pháp - ngữ nghĩa để xác định các đơn vị ngữ liệu quan trọng"],[134,101,1,34,0,33,0,33,"Tư tưởng chính của các phương pháp này là những đơn vị ngữ liệu nào có chứa các thành phần liên kết nhiều với các thành phần khác sẽ có độ quan trọng lớn","Tư tưởng chính của các phương pháp này là những đơn vị ngữ liệu nào có chứa các thành phần liên kết nhiều với các thành phần khác sẽ có độ quan trọng lớn"],[143,110,0.9795918464660645,24,1,24,0,23," Phương pháp Liên kết tham chiếu: Phương pháp liên kết tham chiếu còn được gọi là phương pháp trích chọn trùng lặp (Anaphora-based Method)","Phương pháp Liên kết tham chiếu: Phương pháp liên kết tham chiếu còn được gọi là phương pháp trích chọn trùng lặp (Anaphora-based Method)"],[142,109,1,22,0,21,0,21,"Sau khi xây dựng được các chuỗi từ này, đánh giá độ mạnh của chúng và có những trích chọn phù hợp","Sau khi xây dựng được các chuỗi từ này, đánh giá độ mạnh của chúng và có những trích chọn phù hợp"],[148,114,0.9863013625144958,36,1,36,0,35," Phương pháp quan hệ câu: Dựa trên các từ thể hiện mối quan hệ giữa các câu chúng ta cấu trúc hóa đoạn văn bản từ các đơn vị thành phần như ngữ, mệnh đề, câu..","Phương pháp quan hệ câu: Dựa trên các từ thể hiện mối quan hệ giữa các câu chúng ta cấu trúc hóa đoạn văn bản từ các đơn vị thành phần như ngữ, mệnh đề, câu.."],[146,112,1,23,0,22,0,22,"Sau khi phân tách các cụm trùng lặp, chúng ta tạo chuỗi các từ tham chiếu đến cùng một từ được tham chiếu","Sau khi phân tách các cụm trùng lặp, chúng ta tạo chuỗi các từ tham chiếu đến cùng một từ được tham chiếu"],[145,111,0.7796609997749329,23,12,34,1,23,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 20 phương pháp này, các cụm trùng lặp được chọn ra, phân rã xem đâu là từ tham chiếu và từ được tham chiếu","Theo phương pháp này, các cụm trùng lặp được chọn ra, phân rã xem đâu là từ tham chiếu và từ được tham chiếu"],[147,113,1,30,0,29,0,29,"Chuỗi dài nhất sẽ được coi là trọng tâm của đoạn, các câu chứa các từ trong chuỗi này có một độ ưu tiên nào đó khi xét trích chọn","Chuỗi dài nhất sẽ được coi là trọng tâm của đoạn, các câu chứa các từ trong chuỗi này có một độ ưu tiên nào đó khi xét trích chọn"],[149,115,1,13,0,12,0,12,"Sau đó đơn vị được coi như trung tâm sẽ được trích chọn","Sau đó đơn vị được coi như trung tâm sẽ được trích chọn"],[107,75,1,33,0,32,0,32,"Một hệ Tóm lược (Abstraction) bao gồm tất cả các pha trên, tuy nhiên một hệ Trích rút (Extraction) chỉ gồm pha Phân tích và Pha Hiển thị, không có pha biến đổi","Một hệ Tóm lược (Abstraction) bao gồm tất cả các pha trên, tuy nhiên một hệ Trích rút (Extraction) chỉ gồm pha Phân tích và Pha Hiển thị, không có pha biến đổi"],[110,77,0.7356321811676025,32,13,44,10,41,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 18 Hình 2: Mô hình tóm tắt văn bản trích rút Như vậy một hệ Trích rút tiến hành ít bước hơn, các phương pháp thường dùng là thống kê, học trên ngữ liệu","Phân tích (Analysis) Biến đổi (Transform) Hiển thị (Generation) Hinh 2: Mô hình tóm tắt văn bản trích rút Như vậy một hệ Trích rút tiến hành ít bước hơn, các phương pháp thường dùng là thống kê, học trên ngữ liệu"],[113,80,1,24,0,23,0,23,"Trong mỗi pha có thể áp dụng nhiều kỹ thuật xử lý khác nhau, chi tiết sẽ được trình bày ở phần tiếp theo","Trong mỗi pha có thể áp dụng nhiều kỹ thuật xử lý khác nhau, chi tiết sẽ được trình bày ở phần tiếp theo"],[112,79,1,29,0,28,0,28,"Vì vậy, kết quả của các hệ Tóm lược thường thuyết phục hơn (về mặt dễ đọc, dễ hiểu, liên kết ngôn ngữ tốt, gần gũi với con người)","Vì vậy, kết quả của các hệ Tóm lược thường thuyết phục hơn (về mặt dễ đọc, dễ hiểu, liên kết ngôn ngữ tốt, gần gũi với con người)"],[111,78,1,20,0,19,0,19,"Còn hệ Tóm lược thì phức tạp, do kết hợp các phương pháp của xử lý ngôn ngữ tự nhiên","Còn hệ Tóm lược thì phức tạp, do kết hợp các phương pháp của xử lý ngôn ngữ tự nhiên"],[108,76,1,19,0,18,0,18,"Thậm chí trong các pha phân tích và hiển thị, chỉ có một số công đoạn được sử dụng","Thậm chí trong các pha phân tích và hiển thị, chỉ có một số công đoạn được sử dụng"],[106,74,0.9876543283462524,40,1,40,0,39," Hiển thị (Generation): Từ các đơn vị ngữ liệu đã tóm tắt, liên kết chúng lại thành đoạn theo một thứ tự nào đó hoặc theo cấu kết ngữ pháp rồi hiển thị phù hợp với yêu cầu người dùng","Hiển thị (Generation): Từ các đơn vị ngữ liệu đã tóm tắt, liên kết chúng lại thành đoạn theo một thứ tự nào đó hoặc theo cấu kết ngữ pháp rồi hiển thị phù hợp với yêu cầu người dùng"],[104,72,0.9659863710403442,71,0,73,0,72,"Mô hình tóm tắt văn bản Hình 1: Mô hình chung của tóm tắt văn bản Một mô hình tóm tắt văn bản tổng quát gồm các pha sau:  Phân tích (Analysis): Phân tích văn bản đầu vào để đưa ra những mô tả bao gồm các thông tin dùng để tìm kiếm, đánh giá các đơn vị ngữ liệu quan trọng cũng như các tham số đầu vào cho việc tóm tắt","Mô hình tóm tắt văn bản Hinh 1: Mô hình chung của tóm tắt văn bản Một mô hình tóm tắt văn bản tổng quát gồm các pha sau: Phân tích (Analysis): Phân tích văn bản đầu vào để đưa ra những mô tả bao gồm các thông tin dùng để tìm kiếm, đánh giá các đơn vị ngữ liệu quan trọng cũng như các tham số đầu vào cho việc tóm tắt"],[105,73,0.9841269850730896,31,1,31,0,30," Biến đổi (Transformation): Lựa chọn các thông tin trích chọn được, biến đổi để giản lược và thống nhất, kết quả là các đơn vị ngữ liệu đã được tóm tắt","Biến đổi (Transformation): Lựa chọn các thông tin trích chọn được, biến đổi để giản lược và thống nhất, kết quả là các đơn vị ngữ liệu đã được tóm tắt"],[218,182,1,10,0,9,0,9,"BÀI TOÁN TÓM TẮT VĂN BẢN HƯỚNG TRUY VẤN 3.1","BÀI TOÁN TÓM TẮT VĂN BẢN HƯỚNG TRUY VẤN 3.1"],[219,183,1,52,0,51,0,51,"Định nghĩa Theo định nghĩa ở trên, tóm tắt văn bản hướng truy vấn là một dạng tóm tắt văn bản (khi phân chia theo mục đích tóm tắt), điểm đặc trưng là ở giai đoạn tiền xử lý, việc tính toán sẽ phụ thuộc một phần vào truy vấn người dùng","Định nghĩa Theo định nghĩa ở trên, tóm tắt văn bản hướng truy vấn là một dạng tóm tắt văn bản (khi phân chia theo mục đích tóm tắt), điểm đặc trưng là ở giai đoạn tiền xử lý, việc tính toán sẽ phụ thuộc một phần vào truy vấn người dùng"],[59,28,1,30,0,29,0,29,"Theo đầu ra hệ thống Tóm tắt trích rút là quá trình thu gọn văn bản mà trong kết quả ra chứa các đơn vị ngữ liệu văn bản nguồn","Theo đầu ra hệ thống Tóm tắt trích rút là quá trình thu gọn văn bản mà trong kết quả ra chứa các đơn vị ngữ liệu văn bản nguồn"],[60,29,1,37,0,36,0,36,"Tóm tắt tóm lược là quá trình thu gọn văn bản mà trong kết quả ra có một số các đơn vị ngữ liệu mới được sinh ra từ các đơn vị ngữ liệu văn bản nguồn","Tóm tắt tóm lược là quá trình thu gọn văn bản mà trong kết quả ra có một số các đơn vị ngữ liệu mới được sinh ra từ các đơn vị ngữ liệu văn bản nguồn"],[119,86,0.9832402467727661,88,0,89,0,88,"Phương pháp thống kê Phương pháp này sử dụng các số liệu thống kê về độ quan trọng của từ, câu hay đoạn, nhận được từ các nghiên cứu về ngôn ngữ học hay thông qua các phương pháp học máy dựa trên tập mẫu để trích rút ra các đơn vị ngữ liệu quan trọng  Phương pháp vị trí Phương pháp vị trí bao gồm các phương pháp xác định độ quan trọng dựa trên thống kê về vị trí của từ, ngữ hay câu trong văn bản","Phương pháp thống kê Phương pháp này sử dụng các số liệu thống kê về độ quan trọng của từ, câu hay đoạn, nhận được từ các nghiên cứu về ngôn ngữ học hay thông qua các phương pháp học máy dựa trên tập mẫu để trích rút ra các đơn vị ngữ liệu quan trọng Phương pháp vị trí Phương pháp vị trí bao gồm các phương pháp xác định độ quan trọng dựa trên thống kê về vị trí của từ, ngữ hay câu trong văn bản"],[170,137,1,44,0,43,0,43,"Các đơn vị ngữ liệu được trích rút hay giản lược từ các pha trước được liên kết lại thành đoạn theo thứ tự tiền định của chúng, không thêm bớt từ nối và cũng không sắp xếp lại các đơn vị ngữ liệu","Các đơn vị ngữ liệu được trích rút hay giản lược từ các pha trước được liên kết lại thành đoạn theo thứ tự tiền định của chúng, không thêm bớt từ nối và cũng không sắp xếp lại các đơn vị ngữ liệu"],[169,136,1,13,0,12,0,12,"Phương pháp hiển thị phân đoạn Đây là phương pháp đơn giản nhất","Phương pháp hiển thị phân đoạn Đây là phương pháp đơn giản nhất"],[171,138,1,50,0,49,0,49,"Văn bản kết quả của phương pháp này có độ dễ đọc dễ hiểu kém, thậm chí lủng củng về nghĩa vì các đơn vị ngữ liệu được trích rút mắc phải một số lỗi như mập mờ tham chiếu, không có từ nối hoặc là thừa từ và ngữ","Văn bản kết quả của phương pháp này có độ dễ đọc dễ hiểu kém, thậm chí lủng củng về nghĩa vì các đơn vị ngữ liệu được trích rút mắc phải một số lỗi như mập mờ tham chiếu, không có từ nối hoặc là thừa từ và ngữ"],[173,140,1,85,0,84,0,84,"Phương pháp hiển thị liên kết Việc hiển thị liên kết là tiếp nhận các đơn vị ngữ liệu đã được trích rút và giản lược từ các pha trước đó, phân tích mối quan hệ về nghĩa của các câu rồi thêm bớt các từ nối, từ dẫn và sắp xếp theo một thứ tự mới dựa vào những gì đã thu thập sao cho thỏa mãn yêu cầu về hiển thị và yêu cầu về độ dễ đọc, dễ hiểu của người dùng","Phương pháp hiển thị liên kết Việc hiển thị liên kết là tiếp nhận các đơn vị ngữ liệu đã được trích rút và giản lược từ các pha trước đó, phân tích mối quan hệ về nghĩa của các câu rồi thêm bớt các từ nối, từ dẫn và sắp xếp theo một thứ tự mới dựa vào những gì đã thu thập sao cho thỏa mãn yêu cầu về hiển thị và yêu cầu về độ dễ đọc, dễ hiểu của người dùng"],[232,196,1,36,0,35,0,35,"Có 3 giải thuật có thể áp dụng: - Dựa trên tâm các đồ thị: một đồ thị trung tâm cho tất cả văn bản được xây dựng, tích hợp thêm đồ thị của truy vấn","Có 3 giải thuật có thể áp dụng: - Dựa trên tâm các đồ thị: một đồ thị trung tâm cho tất cả văn bản được xây dựng, tích hợp thêm đồ thị của truy vấn"],[234,197,0.7234042286872864,68,12,79,40,107,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 25 - Dựa trên việc kết hợp câu đã chọn: giống bước trên nhưng sau khi chọn được mỗi câu thì kết hợp câu đó vào tâm tạo thành tâm mới Phương pháp này cho kết quả tương đối chính xác nhưng phụ thuộc chủ yếu vào giải đoạn phân tích cú pháp để tìm các cụm danh từ, do đó cần bộ phân tích cú pháp chính xác","Sau đó các câu có đồ thị tương đồng với tâm lớn nhất sẽ được chọn - Dựa trên đồ thị truy vấn: các câu có đồ thị tương đồng với đồ thị truy vấn lớn nhất sẽ được chọn - Dựa trên việc kết hợp câu đã chọn: giống bước trên nhưng sau khi chọn được mỗi câu thì kết hợp câu đó vào tâm tạo thành tâm mới Phương pháp này cho kết quả tương đối chính xác nhưng phụ thuộc chủ yếu vào giải đoạn phân tích cú pháp để tìm các cụm danh từ, do đó cần bộ phân tích cú pháp chính xác"],[221,185,1,36,0,35,0,35,"Ứng dụng của bài toán Tóm tắt hướng truy vấn thường sử dụng trong việc tóm tắt kết quả trả về của máy tìm kiếm thông tin, hoặc trong các hệ thống hỏi đáp tự động","Ứng dụng của bài toán Tóm tắt hướng truy vấn thường sử dụng trong việc tóm tắt kết quả trả về của máy tìm kiếm thông tin, hoặc trong các hệ thống hỏi đáp tự động"],[228,192,1,50,0,49,0,49,"Đồ thị của văn bản sẽ được xây dựng dựa trên việc phân tích các câu trong đó để tìm ra các cụm danh từ(noun phrases), sau đó phân tích các cụm danh từ này để tìm ra mối quan hệ giữa các danh từ sử dụng các hàm heuristic","Đồ thị của văn bản sẽ được xây dựng dựa trên việc phân tích các câu trong đó để tìm ra các cụm danh từ(noun phrases), sau đó phân tích các cụm danh từ này để tìm ra mối quan hệ giữa các danh từ sử dụng các hàm heuristic"],[229,193,1,38,0,37,0,37,"Đồ thị thu được sẽ bao gồm 2 dạng nút, nút thành phần(là các danh từ trích rút từ văn bản) và nút liên kết, có 2 loại nút liên kết là isa(là một) và related_to(liên quan với)","Đồ thị thu được sẽ bao gồm 2 dạng nút, nút thành phần(là các danh từ trích rút từ văn bản) và nút liên kết, có 2 loại nút liên kết là isa(là một) và related_to(liên quan với)"],[230,194,1,22,0,21,0,21,"Sau khi xây dựng đồ thị cho mỗi câu, chúng sẽ được kết hợp để tạo đồ thị cho toàn văn bản","Sau khi xây dựng đồ thị cho mỗi câu, chúng sẽ được kết hợp để tạo đồ thị cho toàn văn bản"],[231,195,1,19,0,18,0,18,"Một thuật toán tìm kiếm sẽ được sử dụng để tìm các câu quan trọng đưa vào tóm tắt","Một thuật toán tìm kiếm sẽ được sử dụng để tìm các câu quan trọng đưa vào tóm tắt"],[227,191,1,26,0,25,0,25,"Dựa trên đồ thị Phương pháp này được đưa ra bởi [3] Jagadeesh và đồng sự, áp dụng cho tóm tắt trích rút đa văn bản","Dựa trên đồ thị Phương pháp này được đưa ra bởi [3] Jagadeesh và đồng sự, áp dụng cho tóm tắt trích rút đa văn bản"],[225,189,1,49,0,48,0,48,"Tóm lại, tóm tắt hướng truy vấn thường được tích hợp ở giai đoạn xử lý kết quả của hệ thống tìm kiếm thông tin và hỏi đáp tự động, mục đích là thêm thông tin để kết quả rõ ràng và dễ hiểu hơn với người dùng 3.3","Tóm lại, tóm tắt hướng truy vấn thường được tích hợp ở giai đoạn xử lý kết quả của hệ thống tìm kiếm thông tin và hỏi đáp tự động, mục đích là thêm thông tin để kết quả rõ ràng và dễ hiểu hơn với người dùng 3.3"],[223,187,1,31,0,30,0,30,"Sau khi xác định được văn bản phù hợp, văn bản đó sẽ được tóm tắt lại theo truy vấn người dùng để đưa ra hiển thị kèm với kết quả","Sau khi xác định được văn bản phù hợp, văn bản đó sẽ được tóm tắt lại theo truy vấn người dùng để đưa ra hiển thị kèm với kết quả"],[224,188,1,75,0,74,0,74,"Đối với hệ thống hỏi đáp tự động, hệ thống sẽ tiến hành phân loại câu hỏi và thực hiện so khớp hoặc tính tương đồng với câu hỏi trong cơ sở dữ liệu để xác định câu trả lời phù hợp nhất, sau đó tóm tắt văn bản chứa câu trả lời, sử dụng câu trả lời như truy vấn, và hiển thị kèm với câu trả lời, có đánh dấu câu trả lời","Đối với hệ thống hỏi đáp tự động, hệ thống sẽ tiến hành phân loại câu hỏi và thực hiện so khớp hoặc tính tương đồng với câu hỏi trong cơ sở dữ liệu để xác định câu trả lời phù hợp nhất, sau đó tóm tắt văn bản chứa câu trả lời, sử dụng câu trả lời như truy vấn, và hiển thị kèm với câu trả lời, có đánh dấu câu trả lời"],[222,186,1,44,0,43,0,43,"Hiện nay, đối với máy tìm kiếm, hệ thống sẽ tóm tắt văn bản theo tóm tắt đơn văn bản thông thường, lưu vào cơ sở dữ liệu, và thực hiện tìm kiếm trên bản tóm tắt đó để giảm thời gian tìm kiếm","Hiện nay, đối với máy tìm kiếm, hệ thống sẽ tóm tắt văn bản theo tóm tắt đơn văn bản thông thường, lưu vào cơ sở dữ liệu, và thực hiện tìm kiếm trên bản tóm tắt đó để giảm thời gian tìm kiếm"],[226,190,1,8,0,7,0,7,"Một số hướng tiếp cận phổ biến 3.3.1","Một số hướng tiếp cận phổ biến 3.3.1"],[72,40,1,13,0,12,0,12,"Trong đó wi là trọng số của term ti trong văn bản D","Trong đó wi là trọng số của term ti trong văn bản D"],[76,44,0.9285714030265808,26,0,28,0,26,"Độ liên quan này chỉ có thể mang hai giá trị : 0 – văn bản không phù hợp với truy vấn và 1 – văn bản phù hợp","Độ liên quan này chỉ có thể mang hai giá trị : 0 văn bản không phù hợp với truy vấn và 1 văn bản phù hợp"],[74,42,1,24,0,23,0,23,"Câu truy vấn có thể biểu diễn thành dạng vector với các thành phần liên kết và các phép toán quan hệ cơ bản","Câu truy vấn có thể biểu diễn thành dạng vector với các thành phần liên kết và các phép toán quan hệ cơ bản"],[73,41,1,43,0,42,0,42,"Đối với vấn đề truy vấn, trong mô hình này câu truy vấn bao gồm các văn bản tìm kiếm liên hệ với nhau thông qua các phép đại số quan hệ cơ bản như NOT (phủ định), AND (và) hay OR (hoặc)","Đối với vấn đề truy vấn, trong mô hình này câu truy vấn bao gồm các văn bản tìm kiếm liên hệ với nhau thông qua các phép đại số quan hệ cơ bản như NOT (phủ định), AND (và) hay OR (hoặc)"],[75,43,1,22,0,21,0,21,"Từ đây, độ liên quan giữa một văn bản và truy vấn được xác định thông qua các thành phần liên kết","Từ đây, độ liên quan giữa một văn bản và truy vấn được xác định thông qua các thành phần liên kết"],[77,45,1,61,0,60,0,60,"Do vậy có thể thấy rằng hạn chế lớn nhất của mô hình này đó là việc đánh giá độ liên quan chỉ trả về hai kết quả, hoặc phù hợp hoặc không, như vậy yêu cầu của hệ thống khi cần sắp xếp và chọn lựa các văn bản theo mức độ liên quan đến truy vấn sẽ không đạt","Do vậy có thể thấy rằng hạn chế lớn nhất của mô hình này đó là việc đánh giá độ liên quan chỉ trả về hai kết quả, hoặc phù hợp hoặc không, như vậy yêu cầu của hệ thống khi cần sắp xếp và chọn lựa các văn bản theo mức độ liên quan đến truy vấn sẽ không đạt"],[78,46,1,41,0,40,0,40,"Độ liên quan của mô hình này không thể phân chia thành các mức khác nhau, do vậy không phản ánh được thực tế là việc liên quan giữa văn bản và truy vấn có thể là mờ, không chắn chắn","Độ liên quan của mô hình này không thể phân chia thành các mức khác nhau, do vậy không phản ánh được thực tế là việc liên quan giữa văn bản và truy vấn có thể là mờ, không chắn chắn"],[79,47,0.9333333373069763,21,0,22,0,21,"Hạn chế này được loại bỏ khi ta sử dụng một mô hình tổng quát hơn – Mô hình không gian vector (VSM)","Hạn chế này được loại bỏ khi ta sử dụng một mô hình tổng quát hơn Mô hình không gian vector (VSM)"],[71,39,1,39,0,38,0,38,"Trọng số của từng term - dùng để đánh giá độ quan trọng của chúng - trong mô hình này chỉ mang hai giá trị 0 và 1, tùy theo sự xuất hiện của term đó trong văn bản","Trọng số của từng term - dùng để đánh giá độ quan trọng của chúng - trong mô hình này chỉ mang hai giá trị 0 và 1, tùy theo sự xuất hiện của term đó trong văn bản"],[70,38,1,31,0,30,0,30,"Mô hình boolean Trong mô hình boolean, văn bản, vốn là tập hợp của các term (thuật ngữ), được biểu diễn bởi chỉ số từng term và trọng số của chúng","Mô hình boolean Trong mô hình boolean, văn bản, vốn là tập hợp của các term (thuật ngữ), được biểu diễn bởi chỉ số từng term và trọng số của chúng"],[68,36,1,23,0,22,0,22,"Các cấu trúc này phải có khả năng thao tác bằng các phép toán cơ bản như cộng, nhân, đại số quan hệ..","Các cấu trúc này phải có khả năng thao tác bằng các phép toán cơ bản như cộng, nhân, đại số quan hệ.."],[69,37,1,15,0,14,0,14,"Có ba mô hình thỏa mãn yêu cầu đó thường được sử dụng là: 2.5.1","Có ba mô hình thỏa mãn yêu cầu đó thường được sử dụng là: 2.5.1"],[67,35,1,33,0,32,0,32,"Mô hình biểu diễn văn bản Văn bản thông thường là dạng dữ liệu phi cấu trúc, do vậy muốn xử lý chúng trước hết phải biểu diễn thành dạng có cấu trúc","Mô hình biểu diễn văn bản Văn bản thông thường là dạng dữ liệu phi cấu trúc, do vậy muốn xử lý chúng trước hết phải biểu diễn thành dạng có cấu trúc"],[338,295,1,46,0,45,0,45,"Chương trình thử nghiệm Để thực hiện thử nghiệm em đã xây dựng một số công cụ phục vụ tóm tắt 1 văn bản, công cụ tạo mẫu và công cụ kiểm thử trên mẫu: - Môi trường cài đặt: Java JDK 7u17, Windows 7 32bit","Chương trình thử nghiệm Để thực hiện thử nghiệm em đã xây dựng một số công cụ phục vụ tóm tắt 1 văn bản, công cụ tạo mẫu và công cụ kiểm thử trên mẫu: - Môi trường cài đặt: Java JDK 7u17, Windows 7 32bit"],[339,296,1,7,0,6,0,6,"- Công cụ lập trình Netbeans 7.3","- Công cụ lập trình Netbeans 7.3"],[82,50,1,39,0,38,0,38,"Các văn bản được biểu diễn thành các vector nhiều chiều, với trọng số không chỉ mang hai giá trị là 0 hay 1 mà có thể mang các giá trị khác tùy theo cách đánh giá, tính toán","Các văn bản được biểu diễn thành các vector nhiều chiều, với trọng số không chỉ mang hai giá trị là 0 hay 1 mà có thể mang các giá trị khác tùy theo cách đánh giá, tính toán"],[81,49,1,24,0,23,0,23,"Mô hình không gian vector Như trên đã đề cập, mô hình không gian vector là mô hình tổng quát hơn mô hình Boolean","Mô hình không gian vector Như trên đã đề cập, mô hình không gian vector là mô hình tổng quát hơn mô hình Boolean"],[83,51,1,21,0,20,0,20,"Một khác biệt nữa so với mô hình boolean là các phép toán cơ bản của mô hình không gian vector","Một khác biệt nữa so với mô hình boolean là các phép toán cơ bản của mô hình không gian vector"],[154,120,1,33,0,32,0,32,"Giản lược về cấu trúc câu Giản lược về cấu trúc câu là việc lược bỏ trong câu các phần thừa, ít mang giá trị, làm cho cấu trúc câu thu gọn lại","Giản lược về cấu trúc câu Giản lược về cấu trúc câu là việc lược bỏ trong câu các phần thừa, ít mang giá trị, làm cho cấu trúc câu thu gọn lại"],[155,121,1,15,0,14,0,14,"Công việc này thường dựa trên phân tích cú pháp các thành phần trong câu","Công việc này thường dựa trên phân tích cú pháp các thành phần trong câu"],[152,118,1,35,0,34,0,34,"Các phương pháp trong pha này không làm tăng thêm độ chính xác mà chỉ giúp cho văn bản kết quả ngắn gọn hơn mà vẫn sát nghĩa và thuật toán thưởng rất phức tạp","Các phương pháp trong pha này không làm tăng thêm độ chính xác mà chỉ giúp cho văn bản kết quả ngắn gọn hơn mà vẫn sát nghĩa và thuật toán thưởng rất phức tạp"],[153,119,1,7,0,6,0,6,"Có thể chia làm 2 loại: 2.7.2.1","Có thể chia làm 2 loại: 2.7.2.1"],[151,117,1,27,0,26,0,26,"Pha Biến đổi Ở pha này, các câu sẽ được biến đổi, làm gọn lại hoặc kết hợp nhiều câu tạo thành câu mới ngắn gọn hơn","Pha Biến đổi Ở pha này, các câu sẽ được biến đổi, làm gọn lại hoặc kết hợp nhiều câu tạo thành câu mới ngắn gọn hơn"],[299,259,1,21,0,20,0,20,"Trong giải thuật này chủ yếu dựa trên trọng số từ nên việc loại bỏ từ dừng là rất cần thiết","Trong giải thuật này chủ yếu dựa trên trọng số từ nên việc loại bỏ từ dừng là rất cần thiết"],[298,258,0.7272727489471436,36,27,62,0,35,"Loại bỏ từ dừng Từ dừng (StopWord) là những từ thường xuất hiện nhiều trong các tài liệu nhưng thường chỉ mang ý nhấn mạnh, bổ nghĩa… nó có ý nghĩa lớn trong một số phương pháp dựa trên dấu hiệu đặc biệt, nhưng trong phương pháp dựa trên tần số từ đang xét thì các từ này làm giảm độ chính xác","nó có ý nghĩa lớn trong một số phương pháp dựa trên dấu hiệu đặc biệt, nhưng trong phương pháp dựa trên tần số từ đang xét thì các từ này làm giảm độ chính xác"],[300,260,1,35,0,34,0,34,"Từ dừng sẽ được loại bỏ nhờ một danh sách từ dừng xây dựng sẵn, tham khảo tại [7], sau khi tách từ, các từ xuất hiện trong từ điển từ dừng sẽ bị xóa","Từ dừng sẽ được loại bỏ nhờ một danh sách từ dừng xây dựng sẵn, tham khảo tại [7], sau khi tách từ, các từ xuất hiện trong từ điển từ dừng sẽ bị xóa"],[301,261,1,13,0,12,0,12,"Dưới đây là một số từ dừng trích trong file sẽ sử dụng","Dưới đây là một số từ dừng trích trong file sẽ sử dụng"],[303,262,0.7735849022865295,41,12,62,0,42,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 31 thậm chí vì vậy tuy nhiên thật ra với lại thế là trước kia đáng lẽ sau cùng tuy vậy ắt hẳn quả thật Bảng 1: Ví dụ một số từ dừng Ngoài ra ở bước này, các dấu câu, dấu phảy cũng bị xóa vì nó cũng giống từ dừng","thậm chí vì vậy tuy nhiên thật ra với lại thế là trước kia đáng lẽ sau cùng tuy vậy ắt hẳn quả thật Ngoài ra ở bước này, các dấu câu, dấu phảy cũng bị xóa vì nó cũng giống từ dừng"],[32,1,1,80,0,79,0,79,"Cụ thể bài toán cần giải quyết được phát biểu như sau: Đầu vào: Văn bản, truy vấn, độ rút gọn Đầu ra: Bản tóm tắt của văn bản đầu vào xoay quanh vấn đề nêu trong truy vấn Để giải quyết được bài toán này, việc trước hết là tìm hiểu cơ sở lý thuyết về tóm tắt văn bản, tóm tắt hướng truy vấn, từ đó xác định hướng giải quyết và thực hiện cài đặt thử nghiệm","Cụ thể bài toán cần giải quyết được phát biểu như sau: Đầu vào: Văn bản, truy vấn, độ rút gọn Đầu ra: Bản tóm tắt của văn bản đầu vào xoay quanh vấn đề nêu trong truy vấn Để giải quyết được bài toán này, việc trước hết là tìm hiểu cơ sở lý thuyết về tóm tắt văn bản, tóm tắt hướng truy vấn, từ đó xác định hướng giải quyết và thực hiện cài đặt thử nghiệm"],[44,13,0.8631578683853149,41,13,53,0,40,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 14  Độ dễ đọc hiểu (Reading Comprehence): một người được giao việc đọc văn bản kết quả, sau đó trả lời các câu hỏi, hệ thống sẽ phải cho điểm và từ đó đưa ra phần trăm những câu trả lời đúng","Độ dễ đọc hiểu (Reading Comprehence): một người được giao việc đọc văn bản kết quả, sau đó trả lời các câu hỏi, hệ thống sẽ phải cho điểm và từ đó đưa ra phần trăm những câu trả lời đúng"],[42,12,0.9830508232116699,29,1,29,0,28," Độ liên quan (Relevance): xác định mức độ phù hợp của văn bản tóm tắt với chủ đề cho trước (chủ đề có thể là một câu truy vấn)","Độ liên quan (Relevance): xác định mức độ phù hợp của văn bản tóm tắt với chủ đề cho trước (chủ đề có thể là một câu truy vấn)"],[102,70,1,46,0,45,0,45,"Lý thuyết tập thô được các nhà nghiên cứu Trí tuệ nhân tạo phát triển và ngày càng thể hiện được tính ưu việt không chỉ trong việc biểu diễn và thao tác văn bản mà còn trong các vấn đề khác của lĩnh vực này","Lý thuyết tập thô được các nhà nghiên cứu Trí tuệ nhân tạo phát triển và ngày càng thể hiện được tính ưu việt không chỉ trong việc biểu diễn và thao tác văn bản mà còn trong các vấn đề khác của lĩnh vực này"],[101,69,1,36,0,35,0,35,"Nhóm tác giả Hồ Tú Bảo, Saori Kawasaki, Nguyễn Ngọc Bình đã đề xuất ra mô hình tập thô dung sai trong đó bỏ đi tính chất bắc cầu trong quá trình xử lý văn bản","Nhóm tác giả Hồ Tú Bảo, Saori Kawasaki, Nguyễn Ngọc Bình đã đề xuất ra mô hình tập thô dung sai trong đó bỏ đi tính chất bắc cầu trong quá trình xử lý văn bản"],[100,68,0.6944444179534912,25,22,46,0,24,"Mô hình tập thô gần đây được sử dụng nhiều cho các bài toán tìm kiếm cũng như phân nhóm văn bản… Tuy nhiên khi áp dụng mô hình tập thô cho quá trình xử lý văn bản thì tính chất bắc cầu không còn phù hợp","Tuy nhiên khi áp dụng mô hình tập thô cho quá trình xử lý văn bản thì tính chất bắc cầu không còn phù hợp"],[351,307,1,52,0,51,0,51,"Công cụ kiểm thử Công cụ này được xây dựng dựa trên việc tích hợp giải thuật đã đề xuất ở trên và tích hợp thêm hai giải thuật để so sánh, việc so sánh dựa trên độ đo BLEUS, chi tiết về cách thực hiện sẽ trình bày ở phần sau","Công cụ kiểm thử Công cụ này được xây dựng dựa trên việc tích hợp giải thuật đã đề xuất ở trên và tích hợp thêm hai giải thuật để so sánh, việc so sánh dựa trên độ đo BLEUS, chi tiết về cách thực hiện sẽ trình bày ở phần sau"],[305,264,0.936170220375061,22,0,23,0,22,"Xử lý từ đồng nghĩa Có 3 loại từ đồng nghĩa cần xét đến:  Từ có nghĩa giống nhau hoặc gần giống nhau","Xử lý từ đồng nghĩa Có 3 loại từ đồng nghĩa cần xét đến: Từ có nghĩa giống nhau hoặc gần giống nhau"],[65,33,1,27,0,26,0,26,"Tóm tắt hướng truy vấn được cài đặt và áp dụng nhiều hơn nhưng trong lĩnh vực hẹp hơn, đi sâu vào các chuyên ngành cụ thể","Tóm tắt hướng truy vấn được cài đặt và áp dụng nhiều hơn nhưng trong lĩnh vực hẹp hơn, đi sâu vào các chuyên ngành cụ thể"],[63,32,0.782608687877655,18,0,17,0,17,"Tóm tắt hướng truy vấn là tóm tắt theo quan điểm mong muốn của người dùng ứng dụng","Tóm tắt hướng truy vấn là tóm tắt theo quan điểm mong muốn của người dùng ứng dụng thông qua các tham số truyền vào câu truy vấn"],[62,31,1,22,0,21,0,21,"Theo mục đích tóm tắt Tóm tắt chung là tóm tắt theo quan điểm ban đầu của tác giả văn bản gốc","Theo mục đích tóm tắt Tóm tắt chung là tóm tắt theo quan điểm ban đầu của tác giả văn bản gốc"],[272,232,0.8695651888847351,10,1,10,1,10,"Hình 3: Mô hình tóm tắt văn bản hướng truy vấn","Hinh 3: Mô hình tóm tắt văn bản hướng truy vấn 1.1"],[271,231,1,48,0,47,0,47,"PHÂN TÍCH MÔ HÌNH THỰC HIỆN BÀI TOÁN Dựa vào các kiến thức về tóm tắt văn bản đã trình bày ở trên, trong phần này em sẽ trình bày chi tiết các kỹ thuật áp dụng trong từng bước của mô hình xử lý đã đề xuất","PHÂN TÍCH MÔ HÌNH THỰC HIỆN BÀI TOÁN Dựa vào các kiến thức về tóm tắt văn bản đã trình bày ở trên, trong phần này em sẽ trình bày chi tiết các kỹ thuật áp dụng trong từng bước của mô hình xử lý đã đề xuất"],[116,83,1,50,0,49,0,49,"Pha Phân tích Ở pha này văn bản nguồn sẽ được tách thành các đoạn, câu, từ, kết hợp với các thông số đầu vào và áp dụng một số thuật toán cụ thể để chọn ra các đoạn hoặc câu phù hợp làm đầu vào cho pha tiếp theo","Pha Phân tích Ở pha này văn bản nguồn sẽ được tách thành các đoạn, câu, từ, kết hợp với các thông số đầu vào và áp dụng một số thuật toán cụ thể để chọn ra các đoạn hoặc câu phù hợp làm đầu vào cho pha tiếp theo"],[115,82,1,9,0,8,0,8,"Các phương pháp áp dụng trong các pha 2.7.1","Các phương pháp áp dụng trong các pha 2.7.1"],[117,84,1,23,0,22,0,22,"Các phương pháp áp dụng trong pha Phân tích được chia thành hai loại: Phương pháp thống kê và Phương pháp cấu trúc","Các phương pháp áp dụng trong pha Phân tích được chia thành hai loại: Phương pháp thống kê và Phương pháp cấu trúc"],[242,205,1,39,0,38,0,38,"Trước tiên các văn bản sẽ được biểu diễn trong mô hình không gian vector, mỗi câu được tính khoảng cách với câu truy vấn, sau đó sử dụng thuật toán phân cụm, chia các câu vào các cụm","Trước tiên các văn bản sẽ được biểu diễn trong mô hình không gian vector, mỗi câu được tính khoảng cách với câu truy vấn, sau đó sử dụng thuật toán phân cụm, chia các câu vào các cụm"],[243,206,1,40,0,39,0,39,"Mỗi câu được tính điểm số vị trí và điểm số độ quan trọng trong cụm, sau đó từ các cụm có điểm số cao nhất, trích rút ra các câu có điểm số cao nhất tạo thành tóm tắt","Mỗi câu được tính điểm số vị trí và điểm số độ quan trọng trong cụm, sau đó từ các cụm có điểm số cao nhất, trích rút ra các câu có điểm số cao nhất tạo thành tóm tắt"],[241,204,1,32,0,31,0,31,"Dựa trên tần số từ và độ tương đồng câu Phương pháp này trình bày bởi Siva kumar và đồng sự [5] áp dụng cho tóm tắt trích rút đa văn bản","Dựa trên tần số từ và độ tương đồng câu Phương pháp này trình bày bởi Siva kumar và đồng sự [5] áp dụng cho tóm tắt trích rút đa văn bản"]],"t":"\n \r\nNhư đã nêu ở trên, mục tiêu cụ thể của đồ án là đề xuất và thử nghiệm một hướng \r\ntiếp cận cho bài toán tóm tắt hướng truy vấn đơn văn bản áp dụng được cho tiếng \r\nViệt. Cụ thể bài toán cần giải quyết được phát biểu như sau: \r\nĐầu vào: Văn bản, truy vấn, độ rút gọn \r\nĐầu ra: Bản tóm tắt của văn bản đầu vào xoay quanh vấn đề nêu trong truy vấn \r\nĐể giải quyết được bài toán này, việc trước hết là tìm hiểu cơ sở lý thuyết về tóm \r\ntắt văn bản, tóm tắt hướng truy vấn, từ đó xác định hướng giải quyết và thực hiện cài \r\nđặt thử nghiệm. \r\nII. TỔNG QUAN VỀ TÓM TẮT VĂN BẢN TỰ ĐỘNG \r\n2.1. Định nghĩa \r\nTóm tắt văn bản là quá trình làm giảm độ dài, độ phức tạp của văn bản mà vẫn \r\ngiữ lại được nội dung quan trọng của văn bản đó. Công việc tóm tắt văn bản đã xuất \r\nhiện từ rất lâu đời, và nó được làm thủ công, do con người đọc, rút ra các ý chính rồi \r\ntrình bày lại một cách ngắn gọn, dễ hiểu. Mục đích là giúp người sử dụng có cái nhìn \r\ntổng quan về nội dung trình bày trong văn bản, để quyết định sử dụng văn bản đó hợp \r\nlý. Tuy nhiên với lượng văn bản nhiều và dài thì việc làm thủ công vô cùng tốn thời \r\ngian, công sức. \r\nNgày nay, thời đại công nghệ thông tin phát triển mạnh, tóm tắt văn bản tự động \r\n(gọi tắt là tóm tắt văn bản) được nghiên cứu phát triển nhằm mục đích làm thay con \r\nngười công việc nặng nhọc đó. Đã có rất nhiều định nghĩa được đưa ra, tuy nhiên có \r\nthể sử dụng định nghĩa ngắn gọn sau: \r\nTóm tắt văn bản là quá trình rút ra những thông tin quan trọng nhất từ một hay \r\nnhiều nguồn văn bản để tạo ra một văn bản gọn hơn phục vụ cho một số nhiệm vụ \r\nhay người dùng cụ thể \r\n2.2. Các tiêu chí đánh giá \r\n Độ mạch lạc (Coherence): đánh giá mức độ rõ ràng của văn bản tóm tắt, tính \r\nsúc tích, khả năng có thể đọc và hiểu được của bài viết. \r\n Độ hàm chứa thông tin (Informationess): tỉ lệ thông tin của văn bản gốc trong \r\nvăn bản tóm tắt. \r\n Độ liên quan (Relevance): xác định mức độ phù hợp của văn bản tóm tắt với \r\nchủ đề cho trước (chủ đề có thể là một câu truy vấn). \r\n\r\n  \r\n\r\n   \r\n Độ dễ đọc hiểu (Reading Comprehence): một người được giao việc đọc văn \r\nbản kết quả, sau đó trả lời các câu hỏi, hệ thống sẽ phải cho điểm và từ đó đưa ra \r\nphần trăm những câu trả lời đúng. \r\n2.3. Ứng dụng của tóm tắt văn bản \r\nTóm tắt văn bản có nhiều ứng dụng trong thực tế, một số ứng dụng nổi bật như: \r\n Tóm tắt tự động các tin tức trên báo điện tử. \r\n Trợ giúp thông minh việc đọc và khai thác thông tin. \r\n Tóm lược danh sách tìm kiếm từ các Search Engine. \r\n Giản lược nội dung trình bày cho các thiết bị cầm tay. \r\n Sinh tự động chủ đề, tiêu đề, dẫn đường văn bản. \r\n Hỗ trợ tóm lược nội dung cuộc họp, website, chương trình phát thanh và \r\ntruyền hình, sổ tay công việc. \r\n2.4. Phân loại tóm tắt văn bản \r\nCó nhiều cách phân loại tóm tắt, phụ thuộc vào tiêu chí sử dụng để phân loại, sau \r\nđây là một số cách phân loại cần quan tâm: \r\n2.4.1. Theo đầu vào hệ thống \r\nTóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn gọn của văn bản \r\nđó. Ngược lại, tóm tắt đa văn bản là từ nhiều văn bản nguồn cũng chỉ cho ra một \r\nđoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng \r\nthời cho nhiều văn bản khác nhau. Rõ ràng, tóm tắt đa văn bản thì khó hơn, vì ngoài \r\nnhững công việc của tóm tắt đơn văn bản, tóm tắt đa văn bản còn phải thực hiện các \r\ncông việc như tiền xử lý trích rút, tích hợp thống nhất khuôn dạng và hiển thị kết quả \r\ntheo cách riêng. Ngoài ra, tóm tắt đa văn bản còn phải đối mặt với các vấn đề như dư \r\nthừa trùng lặp dữ liệu giữa các văn bản nguồn, nội dung các văn bản nguồn phân tán, \r\nđộ rút gọn yêu cầu cao, thời gian xử lý cần phải nhanh trong khi sự phức tạp trong xử \r\nlý lớn. \r\n2.4.2. Theo đầu ra hệ thống \r\nTóm tắt trích rút là quá trình thu gọn văn bản mà trong kết quả ra chứa các đơn \r\nvị ngữ liệu văn bản nguồn. Tóm tắt tóm lược là quá trình thu gọn văn bản mà trong \r\nkết quả ra có một số các đơn vị ngữ liệu mới được sinh ra từ các đơn vị ngữ liệu văn \r\nbản nguồn. \r\n2.4.3. Theo mục đích tóm tắt \r\nTóm tắt chung là tóm tắt theo quan điểm ban đầu của tác giả văn bản gốc. Tóm \r\ntắt hướng truy vấn là tóm tắt theo quan điểm mong muốn của người dùng ứng dụng \r\n\r\n  \r\n\r\n   \r\nthông qua các tham số truyền vào câu truy vấn. Tóm tắt hướng truy vấn được cài đặt \r\nvà áp dụng nhiều hơn nhưng trong lĩnh vực hẹp hơn, đi sâu vào các chuyên ngành cụ \r\nthể. \r\n2.5. Mô hình biểu diễn văn bản \r\nVăn bản thông thường là dạng dữ liệu phi cấu trúc, do vậy muốn xử lý chúng \r\ntrước hết phải biểu diễn thành dạng có cấu trúc. Các cấu trúc này phải có khả năng \r\nthao tác bằng các phép toán cơ bản như cộng, nhân, đại số quan hệ... Có ba mô hình \r\nthỏa mãn yêu cầu đó thường được sử dụng là: \r\n2.5.1. Mô hình boolean \r\nTrong mô hình boolean, văn bản, vốn là tập hợp của các term (thuật ngữ), được \r\nbiểu diễn bởi chỉ số từng term và trọng số của chúng. Trọng số của từng term - dùng \r\nđể đánh giá độ quan trọng của chúng - trong mô hình này chỉ mang hai giá trị 0 và 1, \r\ntùy theo sự xuất hiện của term đó trong văn bản. \r\n \r\nTrong đó wi là trọng số của term ti trong văn bản D. \r\nĐối với vấn đề truy vấn, trong mô hình này câu truy vấn bao gồm các văn bản \r\ntìm kiếm liên hệ với nhau thông qua các phép đại số quan hệ cơ bản như NOT (phủ \r\nđịnh), AND (và) hay OR (hoặc). Câu truy vấn có thể biểu diễn thành dạng vector với \r\ncác thành phần liên kết và các phép toán quan hệ cơ bản. Từ đây, độ liên quan giữa \r\nmột văn bản và truy vấn được xác định thông qua các thành phần liên kết. Độ liên \r\nquan này chỉ có thể mang hai giá trị : 0  văn bản không phù hợp với truy vấn và 1  \r\nvăn bản phù hợp. \r\nDo vậy có thể thấy rằng hạn chế lớn nhất của mô hình này đó là việc đánh giá độ \r\nliên quan chỉ trả về hai kết quả, hoặc phù hợp hoặc không, như vậy yêu cầu của hệ \r\nthống khi cần sắp xếp và chọn lựa các văn bản theo mức độ liên quan đến truy vấn sẽ \r\nkhông đạt. Độ liên quan của mô hình này không thể phân chia thành các mức khác \r\nnhau, do vậy không phản ánh được thực tế là việc liên quan giữa văn bản và truy vấn \r\ncó thể là mờ, không chắn chắn. Hạn chế này được loại bỏ khi ta sử dụng một mô hình \r\ntổng quát hơn  Mô hình không gian vector (VSM). \r\n2.5.2. Mô hình không gian vector \r\nNhư trên đã đề cập, mô hình không gian vector là mô hình tổng quát hơn mô hình \r\nBoolean. Các văn bản được biểu diễn thành các vector nhiều chiều, với trọng số không \r\nchỉ mang hai giá trị là 0 hay 1 mà có thể mang các giá trị khác tùy theo cách đánh giá, \r\ntính toán. Một khác biệt nữa so với mô hình boolean là các phép toán cơ bản của mô \r\nhình không gian vector. Các phép toán đại số quan hệ dĩ nhiên không phù hợp nữa, \r\n\r\n  \r\n\r\n   \r\nthay vào đó là các phép toán vector như cộng hai vector, nhân hai vector, tích vô \r\nhướng. \r\nKhi biểu diễn văn bản thành các vector, vấn đề về truy vấn và xác định độ liên \r\nquan hoàn toàn được giải quyết. Truy vấn là kết quả của các phép toán vector giữa \r\ncác vector biểu diễn cho những văn bản cấu thành nên truy vấn, như vậy, truy vấn \r\ntrong trường hợp này cũng là một văn bản đặc biệt. Việc xác định độ liên quan giữa \r\ntruy vấn và văn bản được quy thành độ liên quan giữa văn bản và văn bản. Hai văn \r\nbản là hai vector, vậy khoảng cách hay góc giữa chúng đều có thể đại diện cho sự liên \r\nquan giữa hai văn bản này. Tất nhiên, để áp dụng được các phép toán vector cơ bản, \r\nhai vector cần chuẩn hóa về số chiều (độ dài). \r\nCác chỉ số sử dụng trong phương pháp này: \r\n Tần suất thuật ngữ của một từ w trong một văn bản d, ký hiệu TF(w,d), có \r\nthể sử dụng các công thức sau, với fij là số lần xuất hiện của từ wi trong văn bản dj:  \r\n \r\n Tần suất văn bản của một từ w, ký hiệu DF(w) là số lượng văn bản mà từ w \r\ncó xuất hiện. Nghịch đảo của tần suất văn bản của một từ w, ký hiệu IDF(w) được \r\ncho bởi công thức: \r\n \r\nTrong đó: m là tổng số văn bản,, h là số văn bản chứa từ w \r\n Tần suất TF-IDF là kết hợp của hai loại tần suất nói trên: \r\nTF-IDF(w,d) = TF(w,d) * IDF(w) \r\nTheo mô hình này, mỗi văn bản sẽ được biểu diễn dưới dạng D(t1, t2,.,tn) với n \r\nlà tổng số thuật ngữ xuất hiện, mỗi thuật ngữ sẽ được đánh index, ti là trọng số của \r\nthuật ngữ thứ i(trong danh sách thuật ngữ) trong văn bản D. Khi đó độ liên quan giữa \r\nhai văn bản biểu diễn bởi 2 vector X(x1, x2, ., xn) và Y(y1, y2,.,yn) được tính bằng \r\ncông thức Cosin: \r\n \r\n\r\n  \r\n\r\n   \r\n2.5.3. Mô hình tập thô dung sai \r\n Mô hình tập thô dung sai (Tolerance Rough Set Model) là một mô hình mới, \r\ntiên tiến dựa trên lý thuyết về logic mờ và tập mờ (Fuzzy Set). Điều cốt lõi của lý \r\nthuyết này là việc xác định chính xác một giả thiết nào đó (ví dụ như hai văn bản này \r\ncó phù hợp, có giống nhau không...) là một điều rất khó. Tuy nhiên chúng ta có thể \r\nchỉ ra một cặp xấp xỉ trên và xấp xỉ dưới để khẳng định được giả thiết đó là đúng. Sử \r\ndụng các suy diễn hợp lý để xác định và làm đẹp các ngưỡng này. Các phép toán \r\ncơ bản trong mô hình tập thô dựa trên các quan hệ tương đương các tính chất như đối \r\nxứng, phản xạ, bắc cầu... Lý thuyết logic mờ đã và đang được ứng dụng rất mạnh mẽ \r\ntrong lĩnh vực Trí tuệ nhân tạo. \r\nMô hình tập thô gần đây được sử dụng nhiều cho các bài toán tìm kiếm cũng như \r\nphân nhóm văn bản. Tuy nhiên khi áp dụng mô hình tập thô cho quá trình xử lý văn \r\nbản thì tính chất bắc cầu không còn phù hợp. Nhóm tác giả Hồ Tú Bảo, Saori \r\nKawasaki, Nguyễn Ngọc Bình đã đề xuất ra mô hình tập thô dung sai trong đó bỏ đi \r\ntính chất bắc cầu trong quá trình xử lý văn bản. Lý thuyết tập thô được các nhà nghiên \r\ncứu Trí tuệ nhân tạo phát triển và ngày càng thể hiện được tính ưu việt không chỉ \r\ntrong  việc biểu diễn và thao tác văn bản mà còn trong các vấn đề khác của lĩnh vực \r\nnày. \r\n2.6. Mô hình tóm tắt văn bản \r\n \r\nHinh 1: Mô hình chung của tóm tắt văn bản \r\nMột mô hình tóm tắt văn bản tổng quát gồm các pha sau: \r\n Phân tích (Analysis): Phân tích văn bản đầu vào để đưa ra những mô tả bao \r\ngồm các thông tin dùng để tìm kiếm, đánh giá các đơn vị ngữ liệu quan trọng cũng \r\nnhư các tham số đầu vào cho việc tóm tắt. \r\n Biến đổi (Transformation): Lựa chọn các thông tin trích chọn được, biến đổi \r\nđể giản lược và thống nhất, kết quả là các đơn vị ngữ liệu đã được tóm tắt. \r\n Hiển thị (Generation): Từ các đơn vị ngữ liệu đã tóm tắt, liên kết chúng lại \r\nthành đoạn theo một thứ tự nào đó hoặc theo cấu kết ngữ pháp rồi hiển thị phù hợp \r\nvới yêu cầu người dùng. \r\nMột hệ Tóm lược (Abstraction) bao gồm tất cả các pha trên, tuy nhiên một hệ \r\nTrích rút (Extraction) chỉ gồm pha Phân tích và Pha Hiển thị, không có pha biến đổi. \r\nThậm chí trong các pha phân tích và hiển thị, chỉ có một số công đoạn được sử dụng. \r\nPhân tích \r\n(Analysis)\r\nBiến đổi \r\n(Transform)\r\nHiển thị \r\n(Generation)\r\n\r\n  \r\n\r\n   \r\n \r\nHinh 2: Mô hình tóm tắt văn bản trích rút \r\nNhư vậy một hệ Trích rút tiến hành ít bước hơn, các phương pháp thường dùng \r\nlà thống kê, học trên ngữ liệu. Còn hệ Tóm lược thì phức tạp, do kết hợp các phương \r\npháp của xử lý ngôn ngữ tự nhiên. Vì vậy, kết quả của các hệ Tóm lược thường thuyết \r\nphục hơn (về mặt dễ đọc, dễ hiểu, liên kết ngôn ngữ tốt, gần gũi với con người). \r\nTrong mỗi pha có thể áp dụng nhiều kỹ thuật xử lý khác nhau, chi tiết sẽ được \r\ntrình bày ở phần tiếp theo. \r\n2.7. Các phương pháp áp dụng trong các pha \r\n2.7.1. Pha Phân tích \r\nỞ pha này văn bản nguồn sẽ được tách thành các đoạn, câu, từ, kết hợp với các \r\nthông số đầu vào và áp dụng một số thuật toán cụ thể để chọn ra các đoạn hoặc câu \r\nphù hợp làm đầu vào cho pha tiếp theo. \r\nCác phương pháp áp dụng trong pha Phân tích được chia thành hai loại: Phương \r\npháp thống kê và Phương pháp cấu trúc. \r\n2.7.1.1. Phương pháp thống kê \r\nPhương pháp này sử dụng các số liệu thống kê về độ quan trọng của từ, câu hay \r\nđoạn, nhận được từ các nghiên cứu về ngôn ngữ học hay thông qua các phương pháp \r\nhọc máy dựa trên tập mẫu để trích rút ra các đơn vị ngữ liệu quan trọng  \r\n Phương pháp vị trí \r\nPhương pháp vị trí bao gồm các phương pháp xác định độ quan trọng dựa trên \r\nthống kê về vị trí của từ, ngữ hay câu trong văn bản. Các thống kê này tất nhiên phụ \r\nthuộc vào thể loại văn bản. \r\n Chủ đề - Tiêu đề (Title-based): Chủ đề các đoạn văn bản hay tiêu đề các bảng \r\nthường chứa các từ và ngữ quan trọng, nên trích rút thông tin từ đây. \r\n Đầu - cuối đoạn (First - Last Sentence): Xác suất câu đầu đoạn hay câu cuối \r\nđoạn chứa ý chính của cả đoạn là rất lớn, đặc biệt là câu đầu đoạn. Ngoài ra, \r\ncác đoạn đầu và cuối trong văn bản cũng quan trọng hơn các đoạn giữa. \r\n Minh họa - Chú thích (Comments): Trong các câu chú thích, câu minh họa \r\ncho ảnh hay đồ thị thường chứa các thông tin quan trọng. Tuy nhiên, các câu \r\n\r\n  \r\n\r\n   \r\nnày thường chỉ được dùng để đánh giá độ quan trọng của các câu khác liên \r\nquan, chứ không được chọn làm đầu vào cho pha tiếp. \r\n Phương pháp ngữ cố định \r\nCác ngữ cố định có đặc điểm thống kê rất tốt. Sau các ngữ này thường là các câu \r\nhay từ có độ quan trọng là xác định. Người ta chia thành hai loại ngữ cố định, một \r\nloại mang lại độ quan trọng cho thành phần đi sau, được gọi là ngữ nhấn mạnh, một \r\nloại giúp ta loại bỏ, không xét đến những thành phần đi sau vì nó không có nhiều giá \r\ntrị trong việc trích rút, được gọi là ngữ dư thừa: \r\n Ngữ nhấn mạnh (Bonus phrase - Emphasizer): Ngữ nhấn mạnh gồm các ngữ \r\nnhư nói chung là., đặc biệt là., cuối cùng thì., trong bài viết này \r\ntôi muốn chỉ ra., bài viết nói về., nội dung gồm.,..v..v... \r\n Ngữ dư thừa (Stigma phrases): Một số ngữ dư thừa: hiếm khi mà., bài \r\nnày không nói đến., Không thể nào., ..v..v... \r\n Phương pháp thống kê tần suất từ \r\nĐộ quan trọng của từ phụ thuộc vào số lần xuất hiện của từ đó trong các văn bản \r\nliên quan. Các kỹ thuật như TF.IPF hay Tập thuật ngữ thường xuyên (Frequent Item \r\nSet) dùng cho công việc xác định tần suất của từ. \r\n2.7.1.2. Phương pháp cấu trúc \r\nLà các phương pháp sử dụng các mối liên hệ cấu trúc - ngữ pháp - ngữ nghĩa để \r\nxác định các đơn vị ngữ liệu quan trọng. Tư tưởng chính của các phương pháp này là \r\nnhững đơn vị ngữ liệu nào có chứa các thành phần liên kết nhiều với các thành phần \r\nkhác sẽ có độ quan trọng lớn. Việc đánh giá các mối quan hệ sẽ dựa trên các mạng \r\nngữ nghĩa, các quan hệ cú pháp hoặc thông qua các phương pháp xác định độ liên \r\nquan truyền thống. \r\n Phương pháp quan hệ lẫn nhau: Phương pháp này xác định mối quan hệ \r\ngiữa các đoạn trong văn bản hay các câu trong đoạn với nhau thông qua các kỹ thuật \r\nthu thập thông tin ở mức văn bản. Các đoạn (câu) trong văn bản nguồn được tính toán \r\nđộ liên quan lẫn nhau sử dụng các kỹ thuật như Cosine, TF.IPF hay N-gram Overlap. \r\nSau đó chọn ra đoạn (câu) có độ liên quan lớn nhất. \r\n Phương pháp liên kết từ vựng: Phương pháp liên kết từ vựng sử dụng các từ \r\nđiển quan hệ từ vựng đế xây dựng các chuỗi từ liên kết với nhau vể mặt ngữ nghĩa. \r\nVí dụ cây là một loại thực vật, có bộ phận là lá, chất liệu là gỗ. Các từ cây, \r\nthực vật, lá, gỗ có quan hệ ngữ nghĩa nào đó với nhau. Sau khi xây dựng được \r\ncác chuỗi từ này, đánh giá độ mạnh của chúng và có những trích chọn phù hợp. \r\n Phương pháp Liên kết tham chiếu: Phương pháp liên kết tham chiếu còn \r\nđược gọi là phương pháp trích chọn trùng lặp (Anaphora-based Method). Theo \r\n\r\n  \r\n\r\n   \r\nphương pháp này, các cụm trùng lặp được chọn ra, phân rã xem đâu là từ tham chiếu \r\nvà từ được tham chiếu. Sau khi phân tách các cụm trùng lặp, chúng ta tạo chuỗi các \r\ntừ tham chiếu đến cùng một từ được tham chiếu. Chuỗi dài nhất sẽ được coi là trọng \r\ntâm của đoạn, các câu chứa các từ trong chuỗi này có một độ ưu tiên nào đó khi xét \r\ntrích chọn. \r\n Phương pháp quan hệ câu: Dựa trên các từ thể hiện mối quan hệ giữa các \r\ncâu chúng ta cấu trúc hóa đoạn văn bản từ các đơn vị thành phần như ngữ, mệnh đề, \r\ncâu... Sau đó đơn vị được coi như trung tâm sẽ được trích chọn. \r\n2.7.2. Pha Biến đổi \r\nỞ pha này, các câu sẽ được biến đổi, làm gọn lại hoặc kết hợp nhiều câu tạo thành \r\ncâu mới ngắn gọn hơn. Các phương pháp trong pha này không làm tăng thêm độ \r\nchính xác mà chỉ giúp cho văn bản kết quả ngắn gọn hơn mà vẫn sát nghĩa và thuật \r\ntoán thưởng rất phức tạp. Có thể chia làm 2 loại: \r\n2.7.2.1. Giản lược về cấu trúc câu \r\nGiản lược về cấu trúc câu là việc lược bỏ trong câu các phần thừa, ít mang giá trị, \r\nlàm cho cấu trúc câu thu gọn lại. Công việc này thường dựa trên phân tích cú pháp \r\ncác thành phần trong câu. \r\n2.7.2.2. Giản lược về mặt ngữ nghĩa \r\n Phương pháp trừu tượng hóa khái niệm \r\nTư tưởng của phương pháp này là từ các khái niệm cụ thể thay thế bằng khái niệm \r\nchung. \r\nVí dụ: Tôi ăn dâu, táo và đào => Tôi ăn trái cây \r\n Phương pháp thay thế bộ phận \r\nTư tưởng của phương pháp này là từ các khái niệm bộ phận thay thế bằng khái \r\nniệm toàn bộ. \r\nVí dụ: Xích, líp, ghi đông, bàn đạp . => Cái xe đạp.. \r\n Phương pháp thay thế ngữ tương đương \r\nTư tưởng của phương pháp này là các ngữ đóng vai trò như nhau trong câu được \r\nthay bằng một ngữ chung. \r\nVí dụ: Anh ấy bước vào, ngồi xuống ghế, xem thực đơn, gọi món, ăn, trả tiền và \r\nra về => Anh ấy đi ăn tiệm. \r\n Phương pháp thay thế từ, ngữ đồng nghĩa ngắn hơn \r\n\r\n  \r\n\r\n   \r\nMột phương pháp khác khá dễ hiểu đấy là việc thay thế một từ, ngữ bằng một từ, \r\nngữ khác đồng nghĩa hoặc gần nghĩa nhưng có độ dài ngắn hơn. Điều này thường \r\nthông qua một từ điển các từ đồng nghĩa (Thesaurus). \r\n Phương pháp thay thế bởi đại diện \r\nTư tưởng của phương pháp này là thay thế một ngữ bằng một ngữ khác có ý nghĩa \r\nđại diện cho ngữ ban đầu. \r\nVí dụ: Người phát ngôn viên của chính phủ Hoa Kỳ thông báo. => \r\nWashington thông báo.. \r\n2.7.3. Pha Hiển thị \r\n2.7.3.1. Phương pháp hiển thị phân đoạn \r\nĐây là phương pháp đơn giản nhất. Các đơn vị ngữ liệu được trích rút hay giản \r\nlược từ các pha trước được liên kết lại thành đoạn theo thứ tự tiền định của chúng, \r\nkhông thêm bớt từ nối và cũng không sắp xếp lại các đơn vị ngữ liệu. Văn bản kết \r\nquả của phương pháp này có độ dễ đọc dễ hiểu kém, thậm chí lủng củng về nghĩa vì \r\ncác đơn vị ngữ liệu được trích rút mắc phải một số lỗi như mập mờ tham chiếu, không \r\ncó từ nối hoặc là thừa từ và ngữ. \r\n2.7.3.2. Phương pháp hiển thị liên kết \r\nViệc hiển thị liên kết là tiếp nhận các đơn vị ngữ liệu đã được trích rút và giản \r\nlược từ các pha trước đó, phân tích mối quan hệ về nghĩa của các câu rồi thêm bớt \r\ncác từ nối, từ dẫn và sắp xếp theo một thứ tự mới dựa vào những gì đã thu thập sao \r\ncho thỏa mãn yêu cầu về hiển thị và yêu cầu về độ dễ đọc, dễ hiểu của người dùng. \r\n2.8. Đánh giá kết quả tóm tắt \r\nĐánh giá một bản tóm tắt là một công việc khó bởi không tồn tại một bản tóm tắt \r\nlý tưởng cho một (hoặc một tập) văn bản đưa ra. Hơn nữa, việc đánh giá nội dung \r\ntóm tắt cũng rất khó khăn. Trường hợp kết quả là một câu trả lời cho một câu hỏi, ta \r\ncó thể xác định được câu trả lời đó đúng hay sai, nhưng trong các trường hợp khác, \r\nthật khó trả lời liệu đầu ra là phải một kết quả đúng hay không? Thực tế luôn có khả \r\nnăng một hệ thống sinh ra một bản tóm tắt tốt nhưng lại sai khác với bản tóm tắt do \r\nngười thực hiện. Bên cạnh đó, khi việc đánh giá được thực hiện bởi con người thì chi \r\nphí đánh giá sẽ rất cao. Mặt khác, tóm tắt văn bản còn liên quan đến tỉ lệ nén văn bản, \r\ndo đó, việc đánh giá bản tóm tắt cần phải quan tâm đến vấn đề này, khi đó độ phức \r\ntạp và chi phí đánh giá sẽ tăng cao. \r\nDưới đây là hai phương pháp đánh giá tự động thường sử dụng: \r\n\r\n  \r\n\r\n   \r\n2.8.1. Sử dụng so khớp n-gram \r\nPhương pháp này được Lin và Hovy đưa ra năm 2002 dựa trên mô hình n-gram \r\ncủa độ đo BLEU (Bilingual Evaluation Understudy [1], độ đo đánh giá kết quả dịch \r\nmáy). Ý tưởng của phương pháp này là so khớp n-gram liên tiếp của bản tóm tắt thủ \r\ncông và tóm tắt tự động, theo công thức sau: \r\nScore=1*Score1+ 2*Score2+ 3*Score3+ 4*Score4 \r\nTrong đó: \r\nScorei = Số i-gram trùng nhau/Tổng số i-gram của bản tóm tắt thủ công \r\n   i là hệ số đánh giá độ quan trọng của các Scorei \r\n2.8.2. Sử dụng các độ đo ROUGE \r\nROUGE(Recall-Oriented Understudy of Gisting Evaluation [2]) cũng được đưa \r\nra bởi Lin, vào năm 2009, đây là tập hợp các độ đo dựa trên mô hình n-gram của \r\nBLEU với nhiều cách tính khác nhau. Thường sử dụng nhất là độ đo ROUGE-N, với \r\nn là giá trị của mô hình n-gram, n={1,2,3,4}. \r\nCông thức của độ đo ROUGE-N như sau: Cho R=(r1, r2, ., rn) là tập các tóm tắt \r\nmẫu, s là tóm tắt tự động, n(d) là vector biểu diễn mô hình n-gram của văn bản d. \r\n \r\nĐộ đo ROUGE được sử dụng làm độ đo chính thức của các hội nghị DUC 2004-\r\n2007 và TAC 2008-2012. \r\n2.9. Một số hệ thống tóm tắt văn bản tiêu biểu \r\nHiện tại, trên thế giới đã có rất nhiều nghiên cứu và dự án xây dựng các ứng dụng \r\ntóm tắt văn bản. Các ứng dụng này có thể đáp ứng rất nhiều các mục đích khác nhau. \r\nCó thể kể ra một số ứng dụng Tóm tắt văn bản tiêu biểu như sau: \r\n SUMMARIST: Một hệ thống Trích rút văn bản năm thứ tiếng (tiếng Anh, \r\ntiếng Nhật, tiếng Tây Ban Nha, tiếng Ả-rập và tiếng Hàn Quốc). Hiện tại \r\nSUMMARIST đang nghiên cứu để cải tiến trở thành một hệ thống Tóm lược \r\nvăn bản và hỗ trợ nhiều ngôn ngữ hơn như tiếng Pháp và Indonesia. \r\n SweSUM: Ứng dụng Tóm tắt văn bản đa ngôn ngữ của Học viện công nghệ \r\nhoàng gia Thụy Điển. SweSUM có thể tóm tắt các văn bản có ngôn ngữ vùng \r\nScandinavi như Thụy Điển, Đan Mạch, Na Uy và các ngôn ngữ khác như tiếng \r\nAnh, Pháp, Đức, Tây Ban Nha và cả tiếng Iran. \r\n\r\n  \r\n\r\n   \r\n SumUM: Hệ thống Tóm lược văn bản kỹ thuật của nhóm nghiên cứu xử lý \r\nngôn ngữ tự nhiên trường Đại học Montréal, Canada. SumUM có thể thực hiện \r\ncả chức năng tóm tắt chỉ định và tóm tắt thông tin rất tốt.. \r\n FJCL: Hệ thống Rút trích văn bản tiếng Nhật được phát triển trong phòng \r\nnghiên cứu Ikeda của trường đại học Gifu. Đây là một hệ thống sử dụng các \r\nphương pháp áp dụng cho hệ ngôn ngữ đơn âm tiết (monosyllabic language \r\nsystem) như tiếng Nhật, Hàn Quốc, Trung Quốc và Việt Nam. \r\n Pertinence Summarizer: Hệ thống tóm tắt tin tức đa ngôn ngữ trực tuyến nổi \r\ntiếng. Hiện tại để thử nghiệm khả năng của mình, Pertinence đã được tích hợp \r\nvới Google và tóm tắt tự động danh sách tìm kiếm trả về từ Google thông qua \r\ncâu truy vấn đưa vào. Chúng ta có thể thử nghiệm hệ thống này trên trang web: \r\nwww.pertinence.net. \r\n MEAD: Nền tảng cho các hệ thống Tóm tắt nhiều văn bản và đa ngôn ngữ. \r\nĐây là một bộ công cụ xây dựng trên nền Linux và Solaris, sử dụng ngôn ngữ \r\nPerl - Một ngôn ngữ có khả năng xử lý văn bản rất linh hoạt và mạnh mẽ. \r\nMEAD biểu diễn, lưu trữ dữ liệu ở dạng XML, cung tấp cho chúng ta khung \r\nứng dụng để cài đặt các ứng dụng Tóm tắt văn bản cho ngôn ngữ mà ta muốn. \r\nNgoài ra MEAD cũng cung cấp các công cụ để xây dựng các ứng dụng đánh \r\ngiá hệ thống tóm tắt theo các tiêu chí và các tập mẫu nổi tiếng. MEAD được \r\nxây dựng bởi các chuyên gia nổi tiếng về Xử lý ngôn ngữ ở khắp nơi trên thế \r\ngiới dưới sự tài trợ của Chương trình Nghiên cứu Công nghệ thông tin của Tổ \r\nchức Khoa học quốc gia Mỹ. MEAD được cung cấp ở dạng mã nguồn mở để \r\nnghiên cứu và kế thừa. Hiện tại phiên bản mới nhất của MEAD là MEAD \r\nv3.07. \r\n Microsoft Word AutoSummary: Microsoft cũng cài đặt chức năng Trích rút \r\nvà sinh tiêu đề trong Microsoft Word từ phiên bản Word '97. Chúng ta có thể \r\nthử bằng cách chọn Tools - AutoSummarize trên thanh công cụ (có thể khác \r\ntùy vào phiên bản). Công cụ này cho phép chúng ta chọn thông số về độ rút \r\ngọn, trích rút hay sinh tiêu đề... \r\nNgoài ra còn các hệ thống Tóm tắt văn bản nổi tiếng khác như ANES hay \r\nSUMMONS. Tuy nhiên tại Việt Nam hiện nay chưa có một nghiên cứu và ứng dụng \r\nTóm tắt văn bản chính thức nào. \r\n  \r\n\r\n  \r\n\r\n   \r\nIII. BÀI TOÁN TÓM TẮT VĂN BẢN HƯỚNG TRUY VẤN \r\n3.1. Định nghĩa \r\nTheo định nghĩa ở trên, tóm tắt văn bản hướng truy vấn là một dạng tóm tắt văn \r\nbản (khi phân chia theo mục đích tóm tắt), điểm đặc trưng là ở giai đoạn tiền xử lý, \r\nviệc tính toán sẽ phụ thuộc một phần vào truy vấn người dùng. \r\n3.2. Ứng dụng của bài toán \r\nTóm tắt hướng truy vấn thường sử dụng trong việc tóm tắt kết quả trả về của máy \r\ntìm kiếm thông tin, hoặc trong các hệ thống hỏi đáp tự động. \r\nHiện nay, đối với máy tìm kiếm, hệ thống sẽ tóm tắt văn bản theo tóm tắt đơn văn \r\nbản thông thường, lưu vào cơ sở dữ liệu, và thực hiện tìm kiếm trên bản tóm tắt đó \r\nđể giảm thời gian tìm kiếm. Sau khi xác định được văn bản phù hợp, văn bản đó sẽ \r\nđược tóm tắt lại theo truy vấn người dùng để đưa ra hiển thị kèm với kết quả. Đối với \r\nhệ thống hỏi đáp tự động, hệ thống sẽ tiến hành phân loại câu hỏi và thực hiện so \r\nkhớp hoặc tính tương đồng với câu hỏi trong cơ sở dữ liệu để xác định câu trả lời phù \r\nhợp nhất, sau đó tóm tắt văn bản chứa câu trả lời, sử dụng câu trả lời như truy vấn, \r\nvà hiển thị kèm với câu trả lời, có đánh dấu câu trả lời. \r\nTóm lại, tóm tắt hướng truy vấn thường được tích hợp ở giai đoạn xử lý kết quả \r\ncủa hệ thống tìm kiếm thông tin và hỏi đáp tự động, mục đích là thêm thông tin để \r\nkết quả rõ ràng và dễ hiểu hơn với người dùng \r\n3.3. Một số hướng tiếp cận phổ biến \r\n3.3.1. Dựa trên đồ thị \r\nPhương pháp này được đưa ra bởi [3] Jagadeesh và đồng sự, áp dụng cho tóm tắt \r\ntrích rút đa văn bản. Đồ thị của văn bản sẽ được xây dựng dựa trên việc phân tích các \r\ncâu trong đó để tìm ra các cụm danh từ(noun phrases), sau đó phân tích các cụm danh \r\ntừ này để tìm ra mối quan hệ giữa các danh từ sử dụng các hàm heuristic. Đồ thị thu \r\nđược sẽ bao gồm 2 dạng nút, nút thành phần(là các danh từ trích rút từ văn bản) và \r\nnút liên kết, có 2 loại nút liên kết là isa(là một) và related_to(liên quan với). \r\nSau khi xây dựng đồ thị cho mỗi câu, chúng sẽ được kết hợp để tạo đồ thị cho \r\ntoàn văn bản. Một thuật toán tìm kiếm sẽ được sử dụng để tìm các câu quan trọng đưa \r\nvào tóm tắt. Có 3 giải thuật có thể áp dụng: \r\n- Dựa trên tâm các đồ thị: một đồ thị trung tâm cho tất cả văn bản được xây \r\ndựng, tích hợp thêm đồ thị của truy vấn. Sau đó các câu có đồ thị tương \r\nđồng với tâm lớn nhất sẽ được chọn \r\n- Dựa trên đồ thị truy vấn: các câu có đồ thị tương đồng với đồ thị truy vấn \r\nlớn nhất sẽ được chọn \r\n\r\n  \r\n\r\n   \r\n- Dựa trên việc kết hợp câu đã chọn: giống bước trên nhưng sau khi chọn \r\nđược mỗi câu thì kết hợp câu đó vào tâm tạo thành tâm mới \r\nPhương pháp này cho kết quả tương đối chính xác nhưng phụ thuộc chủ yếu vào \r\ngiải đoạn phân tích cú pháp để tìm các cụm danh từ, do đó cần bộ phân tích cú pháp \r\nchính xác. \r\n3.3.2. Dựa trên cấu trúc diễn ngôn \r\nPhương pháp này được trình bày bởi W. Bosma [4], mục đích là tạo ra bản tóm \r\ntắt ngắn gọn chứa câu trả lời để đưa ra kết quả trong hệ thống hỏi đáp tự động. Trong \r\nđó mỗi văn bản được biểu diễn bởi đồ thị có trọng số dựa trên lý thuyết diễn ngôn, \r\nmỗi đỉnh đại diện cho một câu, trọng số trên mỗi cạnh là khoảng cách giữa hai câu. \r\nMột thuật toán tìm kiếm đồ thị sẽ được sử dụng để chọn ra các câu có tổng trọng số \r\ntrên đường đi tới câu trả lời(vai trò như truy vấn) nhỏ nhất. \r\n3.3.3. Dựa trên tần số từ và độ tương đồng câu \r\nPhương pháp này trình bày bởi Siva kumar và đồng sự [5] áp dụng cho tóm tắt \r\ntrích rút đa văn bản. Trước tiên các văn bản sẽ được biểu diễn trong mô hình không \r\ngian vector, mỗi câu được tính khoảng cách với câu truy vấn, sau đó sử dụng thuật \r\ntoán phân cụm, chia các câu vào các cụm. Mỗi câu được tính điểm số vị trí và điểm \r\nsố độ quan trọng trong cụm, sau đó từ các cụm có điểm số cao nhất, trích rút ra các \r\ncâu có điểm số cao nhất tạo thành tóm tắt. \r\n3.4. Đề xuất hướng giải quyết cho tiếng Việt \r\nQua tìm hiểu về các vấn đề liên quan trong tóm tắt và đặc trưng của tiếng Việt, \r\ndễ nhận thấy rằng việc tiếp cận ở mức cú pháp và ngữ nghĩa là khá khó khăn, một \r\nphần là vì công cụ và dữ liệu hỗ trợ, tuy đã có một số công cụ gán nhãn từ vựng và \r\nphân tích cú pháp cho độ chính xác cao nhưng thường chỉ áp dụng cho lĩnh vực hẹp, \r\nvà còn ở mức nghiên cứu, chưa được công bố chính thức. Mặt khác, do đặc trưng về \r\nngữ pháp nên các hướng tiếp cận đó thường không chính xác với tiếng Việt. \r\nDo đó em xin đề xuất mô hình trích rút các câu quan trọng cho bài toán tóm tắt \r\nhướng truy vấn dựa trên tần số từ và độ tương đồng câu, áp dụng cho tóm tắt đơn \r\nvăn bản. Mô tả sơ lược như sau: Đầu tiên sử dụng câu truy vấn làm tâm tóm tắt, sau \r\nđó tìm câu có độ tương đồng với tâm lớn nhất, mỗi câu được chọn sẽ kết hợp với tâm \r\ntạo nên tâm mới. Sau khi kết thúc sẽ loại bỏ câu truy vấn khỏi kết quả. Phương pháp \r\nnày dựa theo ý tưởng ở giải thuật thứ 2 trong hướng tiếp cận dựa trên đồ thị đã nêu ở \r\ntrên, nhưng các câu ở đây biểu diễn theo mô hình không gian vector và độ tương đồng \r\nsử dụng độ đo cosin. \r\nPhạm vi ứng dụng hướng tới của mô hình là tích hợp vào modul trả kết quả của \r\nbộ máy tìm kiếm văn bản(search engine), thực hiện tóm tắt văn bản kết quả theo tập \r\n\r\n  \r\n\r\n   \r\ntừ khóa đã tìm kiếm(chính là truy vấn người dùng). Do đó có một số ràng buộc với \r\ndữ liệu đầu vào. \r\nVì văn bản đã được máy tìm kiếm lựa chọn nên nội dung của văn bản và truy vấn \r\nsẽ liên quan với nhau. Do đó các câu chứa nhiều từ khóa trong truy vấn, hay trong \r\ntrường hợp này là độ tương đồng lớn, sẽ mang các thông tin quan trọng liên quan đến \r\ntruy vấn mà người dùng quan tâm. Tuy nhiên trong vấn đề tìm kiếm, phần lớn người \r\ndùng thường không nắm rõ được nội dung mình muốn biết nên mới sử dụng tìm kiếm, \r\nmà chỉ biết các từ khóa liên quan tới vấn đề đó. Ví dụ như tìm kiếm thông tin về giá \r\nvàng, người ta không biết giá vàng tăng hay giảm, có biến động gì gần đây. Hoặc tìm \r\ncách sửa một lỗi máy tính thì người dùng sẽ đưa ra các thông tin về lỗi đó, sau khi \r\nxem bản tóm tắt của các kết quả từ máy tìm kiếm, sẽ biết được kết quả nào phù hợp \r\nđể quyết định đọc hay không. \r\nTrong giải thuật chọn câu, các câu được chọn sẽ được thêm vào truy vấn, với mục \r\nđích làm thêm từ khóa liên quan đến truy vấn. Nhưng không phải từ nào trong các \r\ncâu đó cũng đều quan trọng nên các từ xuất hiện trong truy vấn gốc được nhân lên \r\nmột trọng số . Do đó kết quả tóm tắt sẽ ưu tiên các từ khóa trong truy vấn, và các từ \r\nkhóa xuất hiện nhiều trong các câu được chọn. Theo đó thì bản tóm tắt sẽ dễ hiểu hơn \r\nvì bao gồm các thông tin liên quan tới truy vấn. \r\nTổng quan về modul đó như sau: \r\n Đầu vào \r\n- Văn bản: văn bản đầu vào sử dụng bộ mã Unicode utf-8, chỉ chứa text, chính \r\nxác về chính tả, dấu câu, không quá ngắn(5 câu trở lên), nội dung phải liên \r\nquan tới truy vấn. \r\n- Truy vấn: sử dụng bộ mã như văn bản, là một đoạn văn bản chứa các từ khóa \r\ncần tìm kiếm, nếu cần chính xác thì dùng dấu phảy để ngăn cách các từ khóa \r\n- Độ rút gọn: có thể là số lượng từ (100-150 từ) hoặc phần trăm văn bản nguồn \r\n(10-20%). \r\n Thực hiện tóm tắt \r\nBước này áp dụng mô hình tóm tắt đã đề xuất để tạo kết quả \r\n- Chuẩn hóa: bước này sẽ thực hiện xử lý tiêu đề, các đoạn văn trong ngoặc đơn  \r\n- Tách câu, tách từ: thực hiện tách câu, tách từ sử dụng công cụ VNTokenizer \r\n- Loại bỏ từ dừng: tìm kiếm và loại bỏ các từ dừng dựa trên danh sách có sẵn \r\n- Xử lý từ đồng nghĩa: đồng bộ các từ đồng nghĩa về cùng 1 dạng  \r\n- Mô hinh hóa văn bản: tính TF.IDF và chuyển các câu về dạng vector \r\n\r\n  \r\n\r\n   \r\n- Trích rút câu, tạo tóm tắt: đây là giải thuật đã đề xuất, thực hiện tính toán độ \r\ntương đồng sử dụng độ đo cosin và một số phép toán trên vector để tìm kiếm \r\ncác câu phù hợp đưa vào kết quả tóm tắt, và được ghép lại theo phương pháp \r\nhiển thị phân đoạn. \r\n Đầu ra: văn bản tóm tắt \r\n Chi tiết các kỹ thuật sử dụng trong các bước sẽ trình bày ở phần sau. \r\n  \r\n\r\n  \r\n\r\n   \r\nPHẦN 2. GIẢI QUYẾT VẤN ĐỀ \r\nI.  PHÂN TÍCH MÔ HÌNH THỰC HIỆN BÀI TOÁN \r\nDựa vào các kiến thức về tóm tắt văn bản đã trình bày ở trên, trong phần này em \r\nsẽ trình bày chi tiết các kỹ thuật áp dụng trong từng bước của mô hình xử lý đã đề \r\nxuất. \r\n \r\nHinh 3: Mô hình tóm tắt văn bản hướng truy vấn \r\n\r\n  \r\n\r\n   \r\n1.1. Giai đoạn phân tích \r\n1.1.1. Chuẩn hóa \r\n Xử lý câu tiêu đề \r\nCâu tiêu đề của một văn bản (nếu có) thường mang nội dung chính trình bày trong \r\nvăn bản, do đó các từ khóa trong đó cũng được dùng để phát hiện tóm tắt (một số giải \r\nthuật còn tăng trọng số cho những từ xuất hiện trong tiêu đề), nhưng không đưa câu \r\ntiêu đề vào kết quả tóm tắt, nên cần phát hiện để loại bỏ khỏi kết quả. Việc phát hiện \r\ncâu tiêu đề có thể dựa vào dấu hiệu câu tiêu đề là câu duy nhất của đoạn đầu tiên. \r\nTrong giải thuật này chỉ sử dụng câu tiêu đề như câu thông thường, sau đó loại khỏi \r\nkết quả (nếu nó được chọn vào kết quả). \r\n Xử lý các cụm từ trong ngoặc \r\nCác cụm từ trong ngoặc có thể là chú thích hoặc viết tắt của cụm từ nào đó, nếu \r\nlà chú thích thì có thể bỏ qua còn từ viết tắt thì khá quan trọng, nhất là đối với tóm \r\ntắt hướng truy vấn. \r\nVí dụ: Sinh viên tình nguyện(SVTN) đi đến các vùng sâu để giúp đỡ đồng bào \r\nCác câu sau câu này sẽ sử dụng cụm từ SVTN, nếu truy vấn có từ khóa sinh viên \r\ntình nguyện thì các câu sử dụng từ viết tắt sẽ không được quan tâm. \r\nViệc xử lý từ viết tắt không đơn giản là phát hiện các từ trong ngoặc, tùy từng \r\nloại văn bản của chuyên ngành nào đó, các từ viết tắt vẫn được sử dụng mà không \r\ngây hiểu lầm cho người đọc, vì trong các lĩnh vực ấy nó chỉ có thể thay thế cho cụm \r\ntừ cố định nào đó, hoặc do thói quen, sử dụng nhiều thì mọi người đều biết. \r\nVí dụ: UBND thường được dùng thay thế cho Ủy ban nhân dân \r\nTrong giải thuật này chỉ xử lý các cụm từ viết tắt chữ đầu trong ngoặc đơn, còn \r\ncác trường hợp khác do chưa xây dựng được bộ dữ liệu cụ thể nên không xét đến. \r\nCác cụm từ trong ngoặc đơn khác sẽ bị xóa đi. \r\n1.1.2. Tách câu, tách từ \r\nTrong tiếng Việt, dấu cách (space) không được sử dụng như 1 kí hiệu phân tách \r\ntừ, nó chỉ có ý nghĩa phân tách các âm tiết với nhau, có khoảng 70% các từ gồm 2 âm \r\ntiết, và 14% các từ gồm 3 âm tiết, còn lại là 1 âm tiết. Hơn nữa, việc kết hợp các âm \r\ntiết có nhiều cách, mỗi cách cho một nghĩa khác nhau. Vì thế, để xử lý tiếng Việt, bài \r\ntoán tách từ (word segmentation) là 1 trong những bài toán cơ bản và quan trọng bậc \r\nnhất. Ngoài tiếng Việt, có khá nhiều các ngôn ngữ châu Á khác cũng cần bước tách \r\ntừ, ví dụ như: tiếng Nhật, tiếng Trung, tiếng Hàn,. do đó vấn đề này nhận được sự \r\nquan tâm rộng rãi và có nhiều hướng tiếp cận khác nhau. \r\nMột số phương pháp có thể áp dụng: \r\n\r\n  \r\n\r\n   \r\no So khớp từ dài nhất (Longest Matching) \r\no So khớp cực đại (Maximum Matching) \r\no Mô hình Markov ẩn (Hidden Markov Models- HMM) \r\no Học dựa trên sự cải biến (Transformation-based Learning  TBL) \r\no Chuyển đổi trạng thái trọng số hữu hạn(Weighted Finite State Transducer) \r\no Độ hỗn loạn cực đại (Maximum Entropy  ME) \r\no Máy học sử dụng vectơ hỗ trợ (Support Vector Machines) \r\no Trường xác xuất có điều kiện (CRFs) \r\nBài toán tách từ khá phức tạp, do đó việc tách từ trong bước này sẽ sử dụng công \r\ncụ VNTokenizer, được phát triển bởi nhóm tác giả Lê Hồng Phương. \r\nĐây là công cụ tách từ tự động cho tiếng Việt, mã nguồn mở, được viết bằng ngôn \r\nngữ Java. Phiên bản cũ nhất là phiên bản vnTokenizer 2.0 được xây dựng vào năm \r\n2005 khi đó nó mới là một ứng dụng đơn với giao diện đơn giản. Để sử dụng trong \r\nchương trình lần này, phiên bản mới nhất 4.1.1c, mã nguồn của công cụ được tải tại \r\nwebsite của dự án VLSP [6]. \r\nCông cụ này được xây dựng sử dụng kết hợp từ điển (từ điển tiếng Việt được lấy \r\ntừ đề tài VLSP) và ngram, trong đó mô hình ngram được huấn luyện sử dụng treebank \r\ntiếng Việt (70,000 câu đã được tách từ), treebank là kho ngữ liệu câu được chú giải \r\nngữ pháp. \r\nVới độ chính xác xấp xỉ 97% (theo thống kê của tác giả trên website) là kết quả \r\nrất cao so với công cụ tách từ hiện nay. \r\nNgoài ra việc tách câu khá đơn giản nhưng cần xử lý các trường hợp nhập nhằng \r\ndấu chấm câu và dấu chấm trong từ(trong email, số thập phân, địa chỉ web). Do đó \r\nđể tiết kiệm thời gian, việc tách câu trong phần này sử dụng luôn modul tách câu \r\ntrong công cụ VNTokenizer. \r\n1.1.3. Loại bỏ từ dừng \r\nTừ dừng (StopWord) là những từ thường xuất hiện nhiều trong các tài liệu nhưng \r\nthường chỉ mang ý nhấn mạnh, bổ nghĩa. nó có ý nghĩa lớn trong một số phương \r\npháp dựa trên dấu hiệu đặc biệt, nhưng trong phương pháp dựa trên tần số từ đang \r\nxét thì các từ này làm giảm độ chính xác. Trong giải thuật này chủ yếu dựa trên trọng \r\nsố từ nên việc loại bỏ từ dừng là rất cần thiết. \r\nTừ dừng sẽ được loại bỏ nhờ một danh sách từ dừng xây dựng sẵn, tham khảo tại \r\n[7], sau khi tách từ, các từ xuất hiện trong từ điển từ dừng sẽ bị xóa. Dưới đây là một \r\nsố từ dừng trích trong file sẽ sử dụng. \r\n\r\n  \r\n\r\n   \r\nthậm chí vì vậy tuy nhiên \r\nthật ra với lại thế là \r\ntrước kia đáng lẽ sau cùng \r\ntuy vậy ắt hẳn quả thật \r\nNgoài ra ở bước này, các dấu câu, dấu phảy cũng bị xóa vì nó cũng giống từ dừng. \r\n1.1.4. Xử lý từ đồng nghĩa \r\nCó 3 loại từ đồng nghĩa cần xét đến: \r\n Từ có nghĩa giống nhau hoặc gần giống nhau. \r\nVí dụ: siêng năng, chăm chỉ, cần cù, . \r\n Từ đồng nghĩa hoàn toàn \r\nVí dụ: hổ, cọp, hùm, . \r\n Từ đồng nghĩa không hoàn toàn \r\nVí dụ:  \r\nĂn, xơi, chén, .(biểu thị thái độ, tình cảm khác nhau đối với người đối \r\nthoại hoặc điều được nói đến). \r\nMang, khiêng, vác, .(biểu thị những cách thức hành động khác nhau). \r\nVới loại 1 và loại 2 thì các từ đồng nghĩa có thể thay thế cho nhau. Còn loại 3 thì \r\nphải xét đến ngữ nghĩa của từ trong ngữ cảnh của văn bản, đây có thể coi là bài toán \r\nphức tạp nhất trong xử lý ngôn ngữ, hiện nay chưa có nhiều nghiên cứu. \r\nViệc xử lý từ đồng nghĩa là rất quan trọng, nhất là trong bài toán tóm tắt hướng \r\ntruy vấn. Trong mô hình lần này, do chỉ xử lý ở mức nông, nên không xét đến các \r\nvấn đề ở mức cú pháp và ngữ nghĩa, nhưng để tăng độ chính xác, bài toán sẽ sử dụng \r\nviệc đồng nhất các từ đồng nghĩa(xử lý chung cho cả 3 loại trên) dựa trên từ điển \r\nđồng nghĩa thô xây dựng sẵn, bộ từ điển này gồm gần 2800 mục, xây dựng bằng cách \r\ndùng công cụ tải các trang của từ điển Việt  Việt tại trang tratu.soha.vn, sau đó tách \r\nthẻ có chứa các từ đồng nghĩa rồi ghép lại. Mỗi mục gồm các từ gần nghĩa hoặc đồng \r\nnghĩa với nhau về mặt nào đó, và mỗi từ chỉ xuất hiện trong một mục, trên thực tế có \r\nnhững từ có thể ở nhiều mục, nhưng số lượng các từ đó không nhiều nên trong bộ từ \r\nđiển này sẽ sử dụng nghĩa phổ biến nhất của các từ đó. Tuy chưa được đầy đủ và xử \r\nlý đơn giản nhưng cũng góp phần tăng độ chính xác cho việc tóm tắt. Dưới đây là \r\nmột số mục từ trong bộ từ đồng nghĩa sẽ sử dụng. \r\n \r\nhttp://tratu.soha.vn/\r\n\r\n  \r\n\r\n   \r\nlãnh thổ, bờ cõi, biên thuỳ, biên giới,biên cương \r\nrỗi rãi, rỗi, rảnh rỗi, rảnh rang, rảnh \r\nthương nhân, nhà buôn, thương gia, doanh nhân, doanh gia \r\nquả cảm, gan góc, dũng cảm, gan dạ, dũng mãnh, can đảm, anh dũng \r\ntả, mô tả, miêu tả, diễn tả, diễn đạt, biểu đạt \r\nSau bước tách từ và loại bỏ từ dừng, các câu sẽ được xử lý theo theo cách duyệt \r\ntất cả các từ, với mỗi từ, tìm từ đó trong từ điển đồng nghĩa, nếu có thì thực hiện thay \r\nthế từ đó bằng từ đầu tiên trong mục từ chứa nó. \r\n1.1.5. Mô hình hóa văn bản \r\nViệc cuối cùng trong giai đoạn tiền xử lý là mô hình hóa văn bản, sử dụng mô \r\nhình không gian vector. Tương tự các công thức dùng để mô hình hóa văn bản ở trên, \r\nđể mô hình hóa câu, ta sử dụng công thức sau TF.ISF, công thức này tương tự như \r\nTF.IDF nhưng các thông số ở trong phạm vi câu và văn bản. Cụ thể mỗi từ tần số của \r\nmỗi từ wi trong câu sj  được tính như sau: \r\n \r\nTrong đó: \r\nfij là số lần xuất hiện của từ ti trong câu sj, \r\nm là tổng số câu trong văn bản \r\nhi là tổng số câu mà từ ti xuất hiện. \r\n là hệ số đánh giá độ quan trọng của từ, nếu từ xuất hiện trong truy \r\nvấn thì >1, còn lại thì =1 \r\nVới hệ số  cho từ xuất hiện trong truy vấn, trong quá trình kiểm thử trên tập mẫu \r\nthì =4  cho kết quả tốt nhất. \r\n1.1.6. Chọn câu phù hợp tạo tóm tắt \r\nBước này sẽ áp dụng các giải thuật đánh giá câu quan trọng để đưa vào kết quả \r\ntóm tắt. Để hạn chế hiện tượng trùng lặp thông tin trong kết quả tóm tắt, trước khi \r\nđưa vào lựa chọn, các câu sẽ được so sánh với nhau để tìm các câu gần tương tự nhau, \r\nvà loại bỏ câu có vị trí xa tiêu đề hơn. Độ đo sử dụng để loại bỏ câu trùng lặp và chọn \r\ncâu phù hợp tạo tóm tắt là độ đo cosin đã trình bày ở trên, nhưng hai vector được tính \r\ntoán bây giờ là biểu diễn cho hai câu. \r\n\r\n  \r\n\r\n   \r\nGiải thuật loại bỏ câu trùng lặp như sau: \r\nBước 1: xét câu si, tính độ tương đồng với các câu sau nó sj \r\nBước 2: với mỗi câu sj, nếu độ tương đồng ij> thì loại bỏ câu sj \r\nBước 3: nếu hết văn bản thì dừng lại, không thì tăng i lên 1 và quay lại bước 1 \r\nQua thực nghiệm trên một số văn bản, cho thấy ngưỡng =0.8 cho kết quả tương \r\nđối chính xác. Do đó trong bước này sẽ thực hiện loại bỏ một câu nếu có độ tương tự \r\nlớn hơn 0.8 với câu nào đó đứng trước nó, theo thứ tự vị trí trong văn bản. \r\nQuá trình chọn câu quan trọng sẽ thực hiện như hình dưới đây \r\n \r\nHinh 4: Minh họa quá trình chọn câu quan trọng \r\nSau khi chuyển biểu diễn các câu về mô hình không gian vector, mỗi câu sẽ là \r\nmột vector, văn bản là danh sách các vector, độ tương đồng giữa các câu sẽ được tính \r\ntoán sử dụng độ đo cosin.  \r\nGiải thuật chọn câu theo các bước sau: \r\nBước 1: khởi tạo tâm là truy vấn \r\nBước 2: tính độ tương đồng  của các câu trong văn bản với tâm \r\nBước 3: chọn câu có  lớn nhất, kết hợp vào tâm, xóa câu đó khỏi văn bản \r\nBước 4: kiểm tra độ dài, nếu chưa đủ, tính toán lại tâm và quay lại bước 2 \r\n\r\n  \r\n\r\n   \r\nTâm của tóm tắt sẽ được tính toán lại dựa trên công thức tính vector trọng tâm \r\ncủa nhóm, và độ tương tự của 1 câu với tâm sẽ là độ tương tự với vector đó. \r\n*) Véc tơ trọng tâm của nhóm \r\nGiả sử có một tập câu = {s1, s2, ., sm} có lần lượt các véc tơ biểu diễn là v1, v2, \r\n., vm. Khi đó, véc tơ trọng tâm của tập câu được tính theo công thức: \r\n1\r\nm\r\ni\r\ni\r\ncen\r\nv\r\nV\r\nm\r\n\r\n\r\n \r\n \r\n1.2. Giai đoạn hiển thị \r\nỞ bước này, văn bản tóm tắt sẽ được tạo ra bằng cách ghép các câu được chọn \r\ntheo thứ tự trong văn bản, đó chính là phương pháp hiển thị phân đoạn. \r\n  \r\n\r\n  \r\n\r\n   \r\nII. CÀI ĐẶT THỬ NGHIỆM \r\n2.1. Chương trình thử nghiệm \r\nĐể thực hiện thử nghiệm em đã xây dựng một số công cụ phục vụ tóm tắt 1 văn \r\nbản, công cụ tạo mẫu và công cụ kiểm thử trên mẫu: \r\n- Môi trường cài đặt: Java JDK 7u17, Windows 7 32bit. \r\n- Công cụ lập trình Netbeans 7.3. \r\n2.1.1. Các công cụ đã xây dựng \r\n2.1.1.1. Chương trình tóm tắt \r\nĐây là chương trình thực hiện tóm tắt một văn bản dựa trên giải thuật đã phân \r\ntích ở trên. Chi tiết các chức năng đã ghi chú đầy đủ trên ảnh giao diện chương trình. \r\nĐầu vào của chương trình là văn bản gốc, truy vấn, và độ rút gọn, đầu ra sẽ là văn \r\nbản tóm tắt, có thể xem chi tiết một số bước xử lý ở chức năng Note góc dưới trái \r\ngiao diện. \r\n \r\nHinh 5: Giao diện chương trinh demo \r\n2.1.1.2. Công cụ tạo tập mẫu \r\nCông cụ này hỗ trợ, tạo, chỉnh sửa các bản tóm tắt thủ công. Chức năng chính là \r\nquản lý các văn bản mẫu bao gồm văn bản gốc và bản tóm tắt thủ công, được tích \r\nhợp chức năng tách từ, tách câu của VNTokenizer nên việc tạo văn bản mẫu sẽ chính \r\nxác và hiệu quả hơn. Ngoài ra còn có chức năng phát hiện ra các văn bản lỗi font, các \r\nvăn bản này không thể sử dụng trong các công cụ đi kèm nên cần loại bỏ. \r\n \r\n\r\n  \r\n\r\n   \r\n \r\nHinh 6: Chương trinh quản lý tập mẫu \r\n2.1.1.3. Công cụ kiểm thử \r\nCông cụ này được xây dựng dựa trên việc tích hợp giải thuật đã đề xuất ở trên và \r\ntích hợp thêm hai giải thuật để so sánh, việc so sánh dựa trên độ đo BLEUS, chi tiết \r\nvề cách thực hiện sẽ trình bày ở phần sau. \r\n \r\nHinh 7: Giao diện chương trinh kiểm thử \r\n\r\n  \r\n\r\n   \r\n2.2. Thử nghiệm một văn bản \r\nPhần này em sử dụng công cụ tóm tắt đã xây dựng để thử nghiệm một văn bản. \r\nKết quả thực hiện thu được như sau: \r\n2.2.1. Đầu vào \r\n Văn bản: \r\nBảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình{1} \r\nChiều ngày 26-4, Chủ tịch nước Trương Tấn Sang và Tổ Đại biểu Quốc hội \r\n(ĐBQH) số 1, Đoàn ĐBQH TP Hồ Chí Minh tiếp tục có buổi tiếp xúc với gần 400 cử \r\ntri của quận 1{2}. Ghi nhận các ý kiến của cử tri, Chủ tịch nước đánh giá cao tinh \r\nthần đóng góp ý kiến của mọi người, nhất là vấn đề sửa đổi Hiến Pháp và các đạo \r\nluật{3}. Trả lời câu hỏi được đông đảo cử tri quan tâm về chủ trương bảo vệ chủ \r\nquyền lãnh thổ, củng cố quốc phòng - an ninh, Chủ tịch nước Trương Tấn Sang khẳng \r\nđịnh chủ trương của Đảng, Nhà nước trước sau như một là kiên quyết bảo vệ vững \r\nchắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình, theo hệ thống luật pháp \r\nquốc tế{4}. Tuy nhiên, Chủ tịch nước cũng khẳng định không bao giờ bảo vệ chủ \r\nquyền bằng nói miệng; chủ trương hòa hiếu không có nghĩa là không làm gi{5}. \r\nNước ta cũng mua sắm trang bị vũ khí, nhưng không phải để gây chiến tranh, chạy \r\nđua vũ trang mà là tăng cường phòng thủ, bảo vệ chủ quyền lãnh thổ{6}. Chủ tịch \r\nnước cho biết, chủ trương hòa hiếu luôn được các nước bạn bè trên thế giới ủng \r\nhộ{7}. \r\nĐề cập đến tình hình biển, đảo, Chủ tịch nước bày tỏ thông cảm với những lo \r\nlắng, bức xúc của cử tri, mong cử tri phải binh tĩnh, không nghe những lời kích động \r\ncủa kẻ xấu{8}. Những mâu thuẫn trên Biển Đông là có, nhưng biện pháp hòa hiếu \r\ncủa nước ta đã có kết quả tốt, Nhà nước luôn hỗ trợ ngư dân ra khơi, số lượng tàu \r\ncá đánh bắt xa bờ ngày càng tăng{9}. Nước ta phấn đấu đến năm 2020 sẽ phát triển \r\nkinh tế biển đạt 52%-53% GDP, trong đó, dầu khí, vận tải biển, đánh bắt hải sản là \r\nthế mạnh lớn{10}. Mục tiêu cuối cùng của nước ta là chủ quyền lãnh thổ vững chắc, \r\nquốc phòng - an ninh ổn định, kinh tế phát triển{11}. \r\nLiên quan đến các vấn đề kinh tế - xã hội, Chủ tịch nước Trương Tấn Sang cho \r\nbiết kinh tế nước nhà có những phát triển đáng kể, nông nghiệp đạt nhiều thắng lợi, \r\ncác ngành thuộc về dầu khí tăng trưởng khá{12}. Tuy nhiên, Chủ tịch nước mong cử \r\ntri hiểu kinh tế Việt Nam dùng chủ yếu là tiền","u":"http://202.191.57.85:8000/InternetData/Data/LVTN/9.txt","downloaded":false,"m":[-1,-1],"n":"9.txt","o":"http://202.191.57.85:8000/InternetData/Data/LVTN/9.pdf\r"},{"saved_path":"/home/huong/InternetData/Data/LVTN/48.txt","r":0.1685274839401245,"s":[[53,15,0.6274510025978088,16,0,11,0,15,"Phân loại tóm tắt văn bản Có nhiều cách phân loại tóm tắt, phụ thuộc vào tiêu chí sử dụng để phân loại, sau đây là một số cách phân loại cần quan tâm: 2.4.1","Phân loại tóm tắt văn bản: Có rất nhiều cách phân loại tóm tắt văn bản"]],"t":"\n VÀ ĐỊNH HƯỚNG GIẢI PHÁP\r\n\r\nMô tả bài toán và các vấn đề cần giải quyết.\r\nMô tả bài toán.\r\nBài toán tóm tắt văn bản hướng truy vấn có thể được tóm tắt như sau: Với một văn bản đã xác định, và một yêu cầu từ người dùng (thể hiện qua câu truy vấn), xây dựng một hệ thống tóm tắt văn bản cung cấp cho người dùng một bản tóm tắt chung nêu được các thông tin nổi bật nhất trong văn bản đáp ứng phù hợp với câu truy vấn (tìm câu trả lời phù hợp nhất với câu truy vấn từ người dùng).\r\nVấn đề cần giải quyết: Một trong những vấn đề thử thách của bài toán này là việc sinh bản tóm tắt lấy người dùng làm trung tâm dựa trên một câu truy vấn. \r\nĐịnh hướng giải quyết vấn đề đặt ra.\r\nĐể giải quyết vấn đề đã nêu ra ở trên tôi tập trung vào nghiên cứu các phương pháp tóm tắt văn bản, đặc biệt là phương pháp tóm tắt văn bản dựa vào độ tương đồng ngữ nghĩa  giữa 2 câu, cụ thể trong bài toán này dựa vào độ tương đồng ngữ nghĩa giữa các câu trong văn bản với truy vấn từ người dùng.\r\nCơ sở lý thuyết.\r\nTổng quan về tóm tắt văn bản.\r\nTóm tắt văn bản là gì?\r\nTrước tiên, chúng ta phải tìm hiểu khái niệm Tóm tắt văn bản là gì?: Đó là cách thức trình bày lại nội dung của văn bản gốc, loại bỏ các thông tin không cần thiết theo mục đích đã định, chỉ giữ lại các thông tin mà chúng ta đang quan tâm. \r\nNhư vậy tóm tắt văn bản cần phải đảm bảo các yêu cầu: luôn ngắn hơn nhiều so với văn bản gốc, không chứa thông tin không cần thiết với mục đích tóm tắt, phản ánh trung thực nội dung của văn bản gốc. \r\nCác lĩnh vực ứng dụng tóm tắt văn bản: Tóm tắt văn bản được áp dụng rất rộng rãi trên nhiều lĩnh vực khác nhau: Kinh tế, chính trị, văn hóa, thể thao, du lịch. với các ứng dụng như: \r\nTóm tắt tin tức trên các báo điện tử.\r\nGiảm dung lượng văn bản cho các thiết bị cầm tay.\r\nTrợ giúp việc lọc thông tin từ các công cụ tìm kiếm.\r\n\r\n\r\nPhân loại tóm tắt văn bản: \r\nCó rất nhiều cách phân loại tóm tắt văn bản. tùy vào mục đích và yêu cầu cụ thể sẽ có các phân loại khác nhau. \r\nPhân loại theo số lượng văn bản đầu vào: Tùy thuộc vào số lượng vănn bản đầu vào ta có thể phân loại thành tóm tắt đơn văn bản (đầu vào chỉ có một văn bản) hay đa văn bản (dữ liệu đầu vào nhiều hơn 1 văn bản). \r\n-  Tóm tắt đơn văn bản: Ưu điểm của loại tóm tắt này là là dễ thực hiện do không xuất hiện những nhập nhằng về mặt thời gian. Các văn bản đầu vào coi như đã đảm bảo về mặt trật tự, trật tự này do người tạo văn bản tạo ra. Tuy nhiên nhược điểm của loại tóm tắt này là phạm vi tóm tắt hẹp, chỉ áp dụng cục bộ cho 1 văn bản.\r\n-  Tóm tắt đa văn bản: đây là loại tóm tắt mở rộng của tóm tắt đơn văn bản. Ưu điểm của loại tóm tắt này là xử lý được thông tin trên nhiều văn bản có liên quan tới nhau. Tuy nhiên có nhược điểm là phải xử lý nhiều nhập nhằng giữa các văn bản như: nhập nhằng về trật tự thời gian, nhập nhằng đại từ, dư thừa thông tin.\r\nPhân loại theo nội dung đầu ra của bản tóm tắt: Với cách phân loại này thì ta có 2 loại tóm tắt văn bản là tóm tắt theo trích xuất (Extract) và tóm tắt tóm lược (Abstract).\r\n-  Tóm tắt theo trích xuất câu: theo cách tóm tắt này, bản tóm tắt được xâ dựng bằng cách rút ra các câu quan trọng và sắp xếp chúng theo thứ tự xuất hiện trong văn bản gốc. Ưu điểm của loại tóm tắt này là dễ thực hiện, không cần tri thức bổ sung, nhưng có nhược điểm là các câu trong tóm tắt rời rạc, không có sự gắn kết với nhau.\r\n-  Tóm tắt tóm lược : Ngoài việc đảm bảo nội dung của văn bản gốc thì các câu văn trong bản tóm tắt phải liền mạch, dễ đọc. Vì vậy phải cần thêm nhiều tri thức bổ sung để tạo thành câu có thể gắn kết với nhau từ các từ, các thành phần câu lấy ra từ văn bản gốc.\r\nPhân loại theo mục đích tóm tắt: Theo cách phân loại này thì mục có thể phân thành 2 loại tóm tắt là tóm tắt chung (general) và tóm tắt hướng truy vấn(Query-based).\r\n- Tóm tắt chung: mục đích chính là tìm ra bản tóm tắt cho toàn bộ văn bản mà sẽ tổng hợp được tất cả nội dung của văn bản đó. Cách tóm tắt này dựa trên quan điểm của người tạo ra văn bản, chứ không tóm tắt theo nhu cầu của người đọc.\r\n-Tóm tắt hướng truy vấn: loại tóm tắt này thường được sử dụng trong quá trình tóm tắt các kết quả trả về từ máy tìm kiếm. nội dung của bản tóm tắt sẽ dựa vào truy vấn từ người dùng, thể hiện nhu cầu của người dùng.\r\nNgoài ra, có nhiều cách khác để phân loại tóm tắt văn bản như: Dựa vào ngôn ngữ (tóm tắt đơn ngôn ngữ, đa ngôn ngữ, xuyên ngôn ngữ), dựa vào đối tượng đọc (tóm tắt cho chuyên gia, tóm tắt cho người đọc bình thường), dựa vào định dạng văn bản (tóm tắt văn bản không theo khuôn mẫu, tóm tắt văn bản có cấu trúc.) .\r\n\r\nQuy trình thực hiện tóm tắt văn bản.\r\nMô hình hệ thống tóm tắt văn bản tổng quát bao gồm 3 quá trình: Quá trình tiền xử lý, Quá trình xử lý, Quá trình tổng hợp.\r\nQuá trình tiền xử lý(phân tích): Xây dựng một biểu diễn có cấu trúc của văn bản.\r\nQuá trình xử lý (chuyển đổi): Bao gồm các giải thuật, tính toán chuyển đổi biểu diễn văn bản có cấu trúc sang một dạng biểu diễn có cấu trúc khác - biểu diễn cho tóm tắt. hoặc sàng lọc ra dữ liệu tốt nhất cho tóm tắt.\r\nQuá trình tổng hợp(sinh kết quả):  Tạo bản tóm tắt bằng cách dựa vào biểu diễn cho tóm tắt.\r\n\r\nII.1.3.1. Quá trình tiền xử lý.\r\nTiền xử lý văn bản nói chung là quá trình thực hiện đọc văn bản và chuyển đổi văn bản đó sang một dạng biểu diễn có cấu trúc. Mô hình biểu diễn này có vai trò rất quan trọng đến hiệu quả, hiệu suất của phương án giải quyết bài toán.\r\nMột số mô hình biểu diễn văn bản:\r\n Mô hình không gian vector : Mỗi văn bản hay thành phần của văn bản được biểu diễn thành một vector. Mỗi thành phần của vector là một thuật ngữ riêng biệt trong tập văn bản gốc và được gán một giá trị trọng số w đã được tính toán. Đặc điểm quan trọng của mô hình này là độ tương tự của 2 văn bản / 2 thành phần của văn bản có thể được tính qua độ tương tự giữa 2 vector đại diện chúng. Do tính đơn giản và hiệu quả của nó mà mô hình này được sử dụng rất rộng rãi.\r\n Mô hình dựa trên tập mờ : Chủ yếu xoay quanh bài toán biểu diễn văn bản về việc lưu trữ trên tập mờ, lưu trữ và xử lý các khái niệm thay vì làm việc trên các thuật ngữ.\r\nTiền xử lý đóng vai trò rất quan trọng trong các bài toán khai thác văn bản. Nó làm giảm thiểu phần dữ liệu thừa phải tính toán, làm giảm kích thước của bài toán. Một số phương pháp có thể áp dụng trong tiền xử lý văn bản : Case Folding (chuyển đổi tất cả các kí tự trong văn bản về cùng một dạng format), Stopword( loại bỏ từ dừng  những từ xuất hiện nhiều nhưng ít mang thông tin liên quan đến nội dung của văn bản).\r\nII.1.3.2. Quá trình xử lý.\r\nQuá trình này áp dụng các giải thuật để biến các giá trị biểu diễn của văn bản thành các giá trị biểu diễn khả năng xây dựng tóm tắt. các giá trị sau khi biến đổi được dùng làm đầu vào cho quá trình sinh kết quả. Không có một mô hình biểu diễn chung nào cho các giá trị này như ở giai đoạn tiền xử lý mà nó phụ thuộc vào giải thuật chuyển đổi và vào cách đánh giá để sinh kết quả.\r\nII.1.3.3. Quá trình tổng hợp sinh kết quả.\r\nBước cuối cùng của hệ thống nhằm đưa ra bản tóm tắt cho văn bản gốc. Đây thường là bước đơn giản nhất, tuy nhiêu độ phức tạp của nó cũng phụ thuộc vào quá trình xử lý ở trên.\r\nCác hướng tiếp cận tóm tắt văn bản.\r\nTrong phạm vi của đồ án chỉ nghiên cứu bài toán có đầu vào là 1 văn bản nên phần này chỉ đưa ra các hướng tiếp cận cho tóm tắt đơn văn bản.\r\nPhương pháp thống kê.\r\nHầu hết các nghiên cứu đầu tiên cho tóm tắt đơn văn bản đều tập trung trên những văn bản kỹ thuật (các bài báo khoa học).  Các phương pháp cổ điển thường tập trung vào các đặc trưng hình thái để tính điểm cho các câu và rút trích các câu quan trọng để đưa vào tóm tắt.\r\nÝ tưởng chính của hướng tiếp cận :\r\n Thu tập ngữ liệu.\r\n Tạo các bản tóm tắt thủ công.\r\n Thiết kế các công thức toán hay logic để tính điểm cho các câu.\r\nLặp cho đến khi tóm tắt tự động đạt được tính tương đương với tóm tắt thủ công :\r\n+   Tính điểm cho từng câu để tạo ra bản tóm tắt cho từng văn bản trong ngữ liệu dựa vào các đặc trưng về hình thái.\r\n+   So sánh tóm tắt được tạo tự động với tóm tắt được tạo thủ công.\r\n+   Cải thiện lại phương thức tính điểm cho câu.\r\n\r\nPhương pháp thống kê trên TF.ISF.\r\nPhương pháp này còn gọi là mô hình túi từ (bag-of-words), sử dụng mô hình trọng số TF.IDF (term frequency và inverse sentence frequence). Ở mô hình này, giá trị IDF được tính trên câu. Trong đó, TF là số lần xuất hiện của term trong 1 câu. Và DF là số câu có chứa term.\r\nCùng với phương pháp tính độ đo TF.IDF và phương pháp biểu diễn văn bản bằng vector không gian sử dụng Vector Space Model (Saton 1975).\r\nTuy nhiên, phương pháp dùng độ đo TF.IDF không được dùng độc lập, mà thường được kết hợp với các phương pháp khác như máy học, đồ thị. để đạt được hiệu quả cao hơn.\r\nPhương pháp học máy.\r\nNăm 1990, với sự phát triển của nhiều kỹ thuật máy học trong xử lý ngôn ngữ, một số nhà nghiên cứu đã ứng dụng các kỹ thuật này vào trong tóm tắt văn bản tự động.\r\n Một số nghiên cứu điển hiển của phương phát này là : Naive-Bayes, Decision Tree, Hidden Makov Model, Log-Linear, Neural Network, SVM.\r\nPhương pháp phân tích ngôn ngữ tự nhiên.\r\nPhương pháp tiếp theo xử dụng các kỹ thuật phân tích ngôn ngữ tự nhiên phức tạp. Không phải tất cả các phương pháp phân tích ngôn ngữ tự nhiên đều xử dụng máy học, đôi khi phương pháp chỉ sử dụng một số các heuristic để tạo rút trích. \r\nHầu hết các phương pháp này đều dựa trên cấu trúc diễn ngôn (discourse tructure) hay cấu trúc diễn đạt (thể hiện) của văn bản, như : cấu trúc các section của văn bản, liên kết ngữ pháp (trùng lặp, tĩnh lược, liên hợp), liên kết từ vựng (đồng nghĩa, bao hàm, lặp lại), cấu trúc chính phụ.\r\nĐánh giá hệ thống tóm tắt văn bản.\r\nViệc đánh giá kết quả tóm tắt văn bản là một việc khó khăn trong thời điểm hiện tại vì không tồn tại một tóm tắt lý tưởng cho một văn bản hay một tập văn bản. Việc sử dụng ý kiến đánh giá của các chuyên gia ngôn ngữ được xem là cách đánh giá tốt nhất, tuy nhiên, cách làm này lại tốn rất nhiều chi phí. Bên cạnh các phương pháp đánh giá thủ công do các chuyên gia thực hiện, vấn đề đánh giá tự động kết quả tóm tắt cũng nhận được nhiều sự quan tâm hiện nay. Từ năm 2000, hội nghị DUC đã được tổchức mỗi năm một lần để thực hiện việc đánh giá với quy mô lớn các hệ thống tóm tắt văn bản. Việc đánh giá tự động này nhằm mục đích là tìm ra được một độ đo đánh giá tóm tắt gần với những đánh giá của con người nhất.\r\nĐánh giá thủ công.\r\nCác chuyên gia của DUC ban đầu đã thực hiện đánh giá thủ công dựa trên cách đánh giá hệ thống tìm kiếm thông tin. Các chuyên gia đánh giá của DUC phải sử dung một chương trình phần mềm để đánh dấu từng đơn vị thông tin của tóm tắt tự động trùng khớp với đơn vị thông tin của tóm tắt chuẩn. Việc đánh dấu các đơn vị thông tin cũng được cho điểm dưới 4 mức độ : đầy đủ(điểm 4), gần đầy đủ (điểm 3), một vài (điểm 2), ít (điểm 1). Sau khi đánh dấu các đơn vị thông tin, 2 độ đo pricision và recall được lựa chọn để đánh giá. \r\n\r\n\r\n\r\n\r\n\r\nTrong đó: t là ngưỡng đánh giá các đơn vị thông tin (1,2,3,4) tương ứng với các giá trị (đầy đủ, gần đầy đủ, một vài, ít).\r\nViệc đánh giá thủ công cho kết quả tốt nhưng chi phí về thời gian quá lớn. Các chuyên gia về NIST đã tốn gần 3000 giờ để đánh giá hết 15 hệ thống tóm tắt năm 2011.\r\nĐánh giá tự động.\r\nNăm 2002, Lin và Hovy đã giới thiệu phương pháp đánh giá tự động đầu tiên dựa vào mô hình n-gram của độ đo BLUE của cộng đồng dịch máy. Phương pháp sử dụng điểm so khớp n- gram.\r\nNAMS = a1NAM1 + a2NAM2 + a3NAM3 + a4NAM4 \r\nTrong đó, NAMn là tỉ lệ trùng khớp n_gram.\r\n\r\n\r\n\r\nĐến 2004, Lin đã giới thiệu một tập các độ đo hướng Recal có tên là Recall- Orented  Understudy Of Gistion Evaluation (ROUGE). Tập độ đo này gồm nhiều độ đo khác nhau dựa trên mô hình n-gram của độ đo BLUE nhưng với nhiều cách thức tính khác nhau. Tiêu biểu nhất là độ đo ROUGE- N, vói n là giá trị của mô hình n-gram được sử dụng, thường n = {1,2,3,4}.\r\nROUGE là một hệ thống đánh giá tóm tắt tự động mà dựa trên tỉ lệ tóm tắt dựa trên đặc điểm của sự gắn kết và hàm lượng thông tin chứa trong bản tóm tắt tự động. Nó nhận bản tóm tắt như đầu vào.\r\nROUGE được sử dụng như một tiêu chuẩn để so sánh hiệu suất của tóm tắt đề xuất với các bản tóm tắt của các hệ thống khác trên cùng một tập tập tài liệu. Việc đánh giá được thực hiện dựa trên các điểm sau:\r\nROUGE- 1.n : Sử dụng n gram trùng lạp giữa tóm tắt của hệ thống và tóm tắt đề xuất.\r\nROUGE  L : (Longest) Chuỗi con chung lớn nhất (trùng lặp giữa tóm tắt do con người tạo và tóm tắt do máy tạo).\r\nROUGE-W: Dãy con chung dài nhất được đánh trọng số mà quyết định độ dài của dãy từ liên tiếp. \r\nROUGE không phải là một công cụ đánh giá bao hàm toàn diện. ROUGE-n, ROUGE-L, ROUGE-W, ROUGE SU4 tốt cho tóm tắt đơn văn bản trong khi ROUGE-1 làm việc tốt cho tóm tắt đa văn bản.\r\n\r\nĐộ tương đồng câu và các phương pháp tính độ tương đồng câu.\r\nĐộ tương đồng là một đại lượng được sử dụng để đo mối liên hệ giữa 2 đối tượng hoặc 2 đặc trưng. Giá trị này thường nằm trong khoảng (-1;1) hoặc (0;1). Thông thường giá trị này càng lớn thì 2 đối tượng hay 2 đặc trưng đó càng giống nhau. \r\nViệc đo độ tương đồng giữa 2 đối tượng, 2 đặc trưng chính là việc xác định 1 hàm ánh xạ mối quan hệ giữa 2 đối tượng, 2 đặc trưng đó sang một dạng số .\r\nVí dụ : trong mô hình không gian vector, độ đo cosin được sử dụng để tính độ tương đồng giữa 2 văn bản hoặc 2 câu trong văn bản. Mỗi văn bản/ câu trong văn bản được biểu diễn thông qua một vector.\r\n\r\nĐộ tương đồng câu.\r\nBài toán tính độ tương đồng câu được phát biểu như sau: trong một văng bản d có n câu (s1, s2, s3.sn). \r\nMục tiêu của bài toán là tìm ra một hàm S(si,sj) với i,j = 1,.,n sao cho S nằm trong khoảng (0,1). Hàm S(si,sj) được gọi là độ đo tương đồng giữa 2 câu si, sj. Giá trị này càng cao thì sự giống nhau về ngữ nghĩa càng nhiều. \r\nĐộ tương đồng ngữ nghĩa là một giá trị tin cậy phản ánh mối quan hệ ngữ nghĩa giữa 2 câu. Tuy nhiên, trên thực tế khó có thể lấy một giá trị có độ chính xác cao bởi ngữ nghĩa của một câu chỉ có thể được hiểu đầy đủ trong một ngữ cảnh cụ thể.\r\nCác phương pháp tính độ tương đồng câu.\r\nHiện nay có nhiều phương pháp để đo độ tương đồng giữa 2 câu, tuy nhiên có thể đưa về 2 nhóm phương pháp chính : phương pháp thống kê (độ đo cosin, độ đo euclid.) và phương pháp xử lý ngôn ngữ tự nhiên(Sử dụng phân tích cú pháp, sử dụng mạng ngữ nghĩa đối với từ: wordnet corpus, Brown corpus,Penn Treebank.).\r\nPhương pháp thống kê: Phương pháp này độ chính xác chưa cao do việc thống kê sẽ không đảm bảo được sự tương đồng về ngữ ngữ. Ngữ nghĩa của một câu hay một từ phải dựa vào hoàn cảnh cụ thể mới có thể xác định chính xác. Tuy nhiên phương pháp này xử lý nhanh, tốn ít chi phí, có nhiều kết quả khả quan.\r\nPhương pháp xử lý ngôn ngữ tự nhiên: Các phương pháp thuộc nhóm này sử dụng các tập dữ liệu chuẩn về ngôn ngữ để tìm ra mối quan hệ giữa các từ: Wordnet , Brown corpus, Penn Treebank. Phương pháp này cho kết quả cao, tuy nhiên khó khăn của phương pháp này gặp phải là việc xây dựng kho dữ liệu đòi hỏi sự tốn kém về mặt chi phí, nhân lực và thời gian. Đối với ngôn ngữ tiếng việt hiện tại chưa có corpus để sử dụng, vì vậy nhiều phương pháp được đề xuất thay thế Wordnet như : sử dụng phân tích chủ đề ẩn, sử dụng mạng ngữ nghĩa Wikipiedia. Các phương pháp này tập trung vào việc bổ sung các thành phần ngữ nghĩa hỗ trợ cho độ đo tương đồng Cosine.\r\nII.4.2.1. Phương pháp tính độ tương đồng câu sử dụng độ đo cosine.\r\nTrong phương pháp tính độ này, các câu sẽ được biểu diễn theo một mô hình không gian vector. Mỗi thành phần trong vector chỉ đến một từ tương ứng trong danh sách mục từ chính. Danh sách  từ chính thu được từ quá trình tiền xử lý văn bản đầu vào, các bước tiền xử lý gồm: tách câu, tách từ, gán nhãn từ loại, loại bỏ những câu không hợp lệ(không phải là câu thực sự) và biểu diễn câu trên không gian vectơ.\r\nKhông gian vector có kích thước bằng số từ trong danh sách từ chính mỗi tọa độ của vector là độ quan trọng của từ đó trong câu.\r\nĐộ quan trọng của từ thứ j trong câu có thể được tính bằng TF (Term frequency), ISF(Inverse sentence frequency), hoặc kết hợp TF-ISF.\r\n\r\n\r\n\r\n\r\n\r\nTrong đó: tfi,j : là tần suất xuất hiện từ i trong câu j( sự phổ biến của từ i trong câu j).\r\n\tisfi: tần số nghịch đảo câu trong văn bản(thể hiện độ hiếm của từ đó trong văn bản)\r\n\tViệc lấy maxlfreql,j để hạn chế sự ảnh hưởng của chiều dài câu đến giá trị tfi,j vì nếu ta tính tần suất xuất từ i trong câu theo công thức xác suất thông thường thì với những câu dài, số lượng từ trong câu sẽ lớn như vậy sẽ ảnh hưởng đến giá trị của tần số xuất hiện từ.\r\nFreqi,j:  số lần xuất hiện từ i trong câu j.\r\n\tN: Số câu trong văn bản.\r\n\tni: Số câu chứa từ i trong văn bản.\r\nĐộ quan trọng của từ trong câu:\r\n\r\nWi,j = tfi,j*isfi\r\n\r\nPhương pháp trọng số tf-isf đánh giá mức độ quan trọng của từ xét về mặt toàn cục kết hợp với trọng số cục bộ của cụm từ trong tài liệu. Những từ thường xuất hiện trong một câu nhưng ít xuất hiện trong toàn bộ tài liệu thì có trọng số cao.\r\nVới không gian biểu diễn văn bản là không gian vector , độ tương đồng giữa 2 câu được chọn là cosine góc giữa 2 vector tương ứng của 2 câu. Vector biểu diễn 2 câu có dạng \r\nSm =  <w1,m,.,wt,m>  \r\nSn  =  <w1,n,.,wt,n> \r\nĐộ tương đồng giữa 2 câu được tính theo công thức.\r\n\r\n\r\nLưu ý: Trước khi áp dụng công thức tính độ tương đồng ở trên phải tiến hành xét quan hệ ngữ nghĩa giữa các từ để đảm bảo độ chính xác của kết quả như  : xét từ đồng nghĩa, từ đồng âm.\r\nTrong  phương pháp tính độ tương đồng câu người ta còn sử dụng một đặc trưng khác là vị trí từ trong câu để tính tương đồng.\r\nVí dụ :  An đẩy Nam xuống sông.\r\n\tNam đẩy An xuống sông. \r\nNếu như xét độ tương đồng của câu dựa trên tần suất xuất hiện từ trong câu thì 2 câu này hoàn toàn tương đồng. Nhưng xét về ngữ nghĩa thì 2 câu trên hoàn toàn không giống nhau. Để hạn chế vấn đề này thì một đặc trưng khác của câu là vị trí từ trong câu đã được xem xét.\r\nCác ước lượng độ tương đồng về thứ tự từ trong mỗi câu được xác định như sau: \r\nNếu từ trong tập từ chung mà có trong câu thì từ đó sẽ có cùng thứ tự với từ trong câu đó.\r\nNgược lại, nếu từ trong tập từ chung mà không giống với từ nào trong câu thì thứ tự của nó sẽ bằng 0.\r\nÁp dụng với 2 câu trên ta có vector vị trí từ như sau :\r\nR1 = <1,2,3,4,5>\r\nR2 = <3,2,1,4,5>\r\nCông thức tính độ tương đồng vị trí từ trong câu: \r\n\r\n\r\n\r\nThường dùng kết hợp 2 độ đo trên để tính độ tương đồng cho toàn bộ câu\r\n\r\n\r\n\r\n\r\nII.4.2.2. Phương pháp tính độ tương đồng câu sử dụng Wordnet corpus\r\nPhương pháp này được thực hiện dựa trên ngữ nghĩa và cú pháp của các từ trong câu.\r\nPhương pháp này cho kết quả cao, tuy nhiên khó khăn của phương pháp này gặp phải là việc xây dựng kho dữ liệu đòi hỏi sự tốn kém về mặt chi phí, nhân lực và thời gian. Đối với ngôn ngữ tiếng việt hiện tại chưa có corpus để sử dụng.\r\nMô hình của phương pháp: Mô hình dựa trên mô hình được đề xuất để tính toán độ tương đồng câu trong tiếng anh. \r\n\r\n\r\n\r\n\r\nPhần II: CÁC KẾT QUẢ ĐẠT ĐƯỢC\r\n\r\nPhân tích và thiết kế hệ thống.\r\nGiải pháp giải quyết bài toán.\r\nDựa vào cơ sở lý thuyết đã trình bày ở trên, Đồ án đề xuất giải quyết bài toán tóm tắt văn bản hướng truy vấn theo phương pháp tính độ tương đồng giữa các câu trong văn bản với câu truy vấn sử dụng độ đo cosine.\r\nQuy trình thực hiện của hệ thống tóm tắt diễn ra theo 3 quá trình: Tiền xử lý, Xử lý, Sinh tóm tắt. Cụ thể các quá trình sẽ được trình bày trong phần dưới. \r\nMô hình xử lý chi tiết.\r\n\r\n\r\n\r\n\r\n\r\nQuá trình tiền xử lý:\r\nTrong quá trình này, hệ thống sẽ tiến hành xử lý văn bản đầu vào : tách câu , tách từ, loại bỏ từ dừng, vector hóa các câu trong văn bản. \r\nTách từ.\r\nTrong tiếng Việt, dấu cách không mang ý nghĩa phân tách các từ mà chỉ mang ý nghĩa phân tách các âm tiết với nhau, vì vậy để làm việc với tiếng Việt thì bài toán tách từ là một trong những bài toán cơ bản và quan trọng bậc nhất.\r\nSau khi tách câu tôi sử dụng mã nguồn công cụ tách từ vnTokenizer 4.1.1c (04/08/2010) của nhóm tác giả Lê Hồng Phương[] để tách nội dung của văn bản và câu truy vấn thành các đơn vị từ. (Mã nguồn của chương trình được public trên trang  ).\r\nTìm danh từ riêng.\r\nCác danh từ riêng trong văn bản thường rất quan trọng không thể bỏ đi ở các câu. Tuy nhiên khi nói tới một danh từ riêng người ta không xét tới ngữ nghĩa của danh từ đó. Vì thế, rất có thể danh từ riêng sẽ được nhận dạng nhầm trong bước loại bỏ từ dừng ( sẽ được trình bày ở phần ngay sau). Do đó trước khi loại bỏ các từ dừng trong văn bản thì phải thực hiện bước phát hiện danh từ riêng trước để tránh loại bỏ từ có ý nghĩa quan trọng.\r\nThêm nữa, ngôn ngữ tiếng Việt rất đa dạng, hiện tượng các từ đồng âm nhưng khác nhau về ý nghĩa rất phổ biến. Việc phát hiện danh từ riêng sẽ tránh được việc đồng nhất các từ này với các từ không phải danh từ riêng nhưng đồng âm với nó. Từ đấy việc tính toán trọng số từ trong câu sẽ chính xác hơn.\r\nÝ tưởng xác định danh từ riêng:\r\nTên riêng được xác định trong văn bản là từ có chữ cái đầu viết hoa. Như vậy thuật toán xác định tên riêng có thể được đề xuất như sau:\r\nĐầu vào : Danh sách câu đã được tách từ, danh sách danh từ riêng (ban đầu rỗng).\r\nĐầu ra: Danh sách tên riêng có trong văn bản.\r\nThuật toán:\r\nB1: Khởi tạo danh sách chứa tên riêng trong văn bản.\r\nB2: Duyệt tất cả các từ trong văn bản.\r\n\tNếu gặp từ có viết hoa đầu câu thì xét vị trí của từ đó có phải ở đầu câu hay không.\r\n\tNếu không ở đầu câu thì thêm vào danh sách tên riêng,đánh dấu từ đó là tên riêng, ở đầu câu thì bỏ qua.\r\n(Ở bước này ta không xét các từ viết hoa đầu câu).\r\nB3: Duyệt lại văn bản từ đầu( Chỉ xét các từ đầu câu).\r\n\tNếu từ đang xét nằm trong danh sách tên riêng đã tìm được ở bước trước thì đánh dấu từ đó là tên riêng.\r\n\tNếu không nằm trong danh sách thì xét từ đó có nhiều hơn 1 âm tiết hay không.\r\n\tNếu từ đó nhiều hơn 1 âm tiết thì xét đến âm tiết thứ 2 trong từ có viết hoa đầu hay không\r\n(Các danh từ riêng thì các âm tiết đều viết hoa chữ cái đầu.)\r\nB4: Lặp lại cho đến khi xét hết các từ trong văn bản.\r\n\r\nHình :Sơ đồ quá trình tìm danh từ riêng\r\n\r\n\r\nLoại bỏ từ dừng.\r\nTừ dừng là từ thường xuất hiện nhiều trong văn bản, tuy nhiên không có nhiều ý nghĩa đối với nội dung của văn bản hiện tại \r\nVí dụ : a lô, a ha, bao lâu, bây giờ, bấy giờ.\r\nỞ bước này, từ danh sách câu, các từ đã được tách ta tiến hành loại bỏ từ dừng. cách loại bỏ từ dừng chỉ đơn giản là tiến hành so khớp các từ trong văn bản với các từ lấy ra từ bộ từ điển từ dừng. Như vậy vấn đề gặp phải ở bước này là việc xây dựng bộ từ điển từ dừng.\r\nBộ từ điển từ dừng tôi đã sử dụng cho chương trình được lấy từ trang . Bộ từ điển này gồm 570 từ. Từ điển được lưu trong file text, mỗi dòng xác định một từ dừng sắp xếp theo thứ tự bảng chữ cái tiếng việt.\r\nMột số từ dừng trong từ điển.\r\n\r\n\r\nBảng : Mộ số từ dừng trong tiếng Việt\r\n\r\n\r\n\r\nQuá trình loại bỏ từ dừng: Thuật toán áp dụng loại bỏ từ dừng trên từng câu.\r\nĐầu vào: Câu S (đã được tách từ) cần loại bỏ từ dừng, file từ điển lưu trữ các từ dừng\r\nĐâu ra:  Câu S đã được loại bỏ hết các từ dừng.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nHình : Sơ đồ quá trình loại bỏ từ dừng\r\n\r\nXử lý từ đồng nghĩa.\r\nCác ngôn ngữ nói chung, tiếng Việt nói riêng, có rất nhiều từ phát âm khác nhau nhưng có ngữ nghĩa giống nhau, cùng nói về một sự vật hiện tượng nào đó, các từ này có thể quy về cùng một từ trong văn bản.  Như vậy nếu ta không xử lý các từ đồng nghĩa thì các này sẽ ảnh hưởng đến độ quan trọng của từ trong câu. Các từ đồng nghĩa sẽ được tính là nhiều từ, do vậy độ quan trọng của từ sẽ giảm, kết quả tính toán sẽ bị sai lệch  không như mong muốn.\r\nPhương pháp xác định từ đồng nghĩa cũng gặp nhiều khó khăn, do từ đồng nghĩa không phải là những từ trùng nhau hoàn toàn về nghĩa. Chúng sẽ có những dị biệt nào đó bên cạnh sự tương đồng. những từ đồng nghĩa với nhau không nhất thiết phải tương đương với nhau về số lượng nghĩa, tức là các từ trong một nhóm đồng nghĩa không nhất thiết phải có số lượng nghĩa bằng nhau từ này có thể có một hoặc hai nghĩa, từ khác có thể có ít hoặc nhiều nghĩa hơn. Các từ đồng nghĩa chỉ tương đồng ở một nghĩa nào đó của chúng .\r\nVới khó khăn nêu trên, để tìm các từ đồng nghĩa trong văn bản và câu truy vấn, hệ thống sử dụng bộ từ điển đồng nghĩa. Bộ từ điển đồng nghĩa này gồm 7734 nhóm từ đồng nghĩa được thu thập từ trang tra từ điển  . từ điển được lưu trong file text mỗi dòng trong file có 3 nội dung: từ đang xét, nhóm từ từ đồng nghĩa với từ đang xét, nhóm từ trái nghĩa. Mỗi nhóm từ trong 1 dòng được phân cách bởi dấu  ; . \r\nMột số từ đồng nghĩa tiếng việt.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nGiải thuật tìm từ đồng nghĩa\r\nĐầu vào: chuỗi đã được tách từ.\r\nĐầu ra: Danh sách câu với các từ đã được đánh dấu vào các nhóm từ tương đồng(các từ cùng nhóm sẽ có cùng 1 chỉ số đánh dấu từ đồng nghĩa).\r\nSau bước này sẽ thu được danh sách các từ đã được đồng nhất.Như vậy việc tính toán độ tương đồng giữa các câu trong văn bản và câu truy vấn sẽ trở nên dễ dàng và chính xác hơn. \r\n\r\n\r\nVector hóa các câu trong văn bản.\r\nQua các bước xử lý ở trên ta đã có danh sách câu đã loại bỏ từ dừng và đồng bộ hóa các từ đồng nghĩa trong văn bản với từ trong câu tuy vấn.Tiếp theo ta phải tiến hành vector hóa các câu trong văn bản, mỗi câu trong văn bản được biểu diễn dưới dạng vector. Mỗi vector có số chiều chính là số từ trong văn bản và câu truy vấn, tại vị trí mà từ của câu không xuất hiện trong danh sách từ chung thì sẽ là bằng 0, còn lại là trọng số của từ được tính theo công thức tính trọng số từ đã được nêu ở trên.\r\nVí dụ: Một đoạn (đại diện cho văn bản) gồm 2 câu: Con đường nào không thể tiếp tục thì hãy từ bỏ. Có nhiều con đường để chúng ta bước tiếp.\r\nTập từ chung trong văn bản : Con đường, nào, không thể, tiếp tục, thì hãy, từ bỏ, có nhiều, để , chúng ta, bước.\r\nNhư vậy vector của câu 1 Con đường nào không thể tiếp tục thì hãy từ bỏ\r\n{x,x,x,x,x,x,0,0,0,0}\r\n\tVector của câu 2 Có nhiều con đường để chúng ta bước tiếp\r\n\t\t\t\t{x,0,0,x,0,0,x,x,x,x}\r\n\tỞ đó : x là từ trong câu đó.\r\nQuá trình xử lý.\r\nTrong quá trình này hệ thống sẽ tiến hành tính toán các trọng số từ, độ tương đồng giữa các câu để làm cơ sở cho bước việc sinh văn bản tóm tắt.\r\nTính trọng số từ.\r\nViệc tính trọng số của từ là rất quan trọng trong bài toán này vì trọng số của từ chính là độ quan trọng của từ đó trong văn bản.\r\nỞ đây, trọng số của một từ trong câu được tính toán thông qua sự kết hợp 2 độ đo tf, isf\r\n\r\nWi,j = tfi,j* isfi\r\n\r\nTrong đó : wi,j là trọng số của từ thứ i trong câu j.\r\n\ttfi,j: tần số xuất hiện từ thứ i trong câu j (độ phổ biến của từ thứ i trong câu j).\t\r\n\r\n\r\n\tisfi: tần suất xuất hiện nghịch đảo của từ thứ I trong văn bản( độ hiếm của từ thứ i trong văn bản).\r\n\r\nNhư vậy, theo công thức trên thì một từ được cho là quan trọng nếu nó xuất hiện nhiều trong câu nhưng lại xuất hiện ít trong văn bản.\r\nThuật toán tính trọng số của một từ (calWeight(word,S,Ls))\r\nĐầu vào : từ cần tính trọng số, câu chứa từ đang xét, danh sách câu trong văn bản.\r\nĐầu ra : trọng số của từ.\r\n\r\n\r\n\r\n\r\n\r\nTính trọng số của tất cả các từ trong văn bản.\r\nĐầu vào: danh sách câu trong văn bản (Ls).\r\nKết quả: tất cả các từ trong văn bản đều được tính trọng số.\r\n\r\n\r\n\r\n\r\n\t\r\n\r\n\r\nTính độ tương đồng giữa với câu truy vấn.\r\n\r\nSau khi tiền xử lý, các câu trong văn bản sẽ được biểu diễn dưới dạng vector, nên ta sẽ dùng độ đo cosine để tính độ tương đồng giữa 2 câu. Đặc biệt là câu trong văn bản với câu truy vấn.\r\nĐể dễ thực hiện ta xem câu truy vấn là 1 câu trong văn bản. câu này sẽ ở vị trí bắt đầu văn bản. Vì trong kết quả tóm tắt không chứa những câu có ý nghĩa giống nhau, nên để loại bỏ các câu giống nhau trong văn bản tóm tắt cũng phải sử dụng độ tương đồng giữa các câu đó. Do vậy ở bước này ta sẽ tính độ tương đồng giữa tất cả các câu với nhau.\r\n\r\n\r\n\r\n\r\n\r\nSơ đồ giải thuật tính độ tương đồng giữa 2 câu.\r\n\r\nĐầu vào: các vector trọng số của 2 câu, kích thước vector.\r\nĐầu ra: độ tương tự giữa 2 câu.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nNgoài ra, Đặc trưng vị trí từ trong câu cũng là 1 khía cạnh để đánh giá độ tương đồng giữa 2 câu\r\nKhi đó, độ tương đồng giữa 2 câu được tính theo công thức.\r\n\r\nSim(S1,S2) = Ss + (1-) Sr\r\n\r\nSs : độ tương đồng giữa 2 câu theo độ đo cosine\r\nSr: độ tương đồng giữa 2 câu theo vị trí từ.\r\n\r\nQuá trình sinh kết quả.\r\nSau quá trình xử lý, độ tương đồng giữa các câu trong văn bản với câu truy vấn, và độ tương tự giữa các câu trong văn bản với nhau đã được xác định. Từ đó ta sẽ xác định các câu để đưa vào bản tóm tắt dựa trên kết quả đó.\r\nYêu cầu của bản tóm tắt: \r\nNội dung tóm tắt phải phù hợp với truy vấn.\r\nCác câu trong tóm tắt không được trùng nhau.\r\nĐộ dài bản tóm giới hạn.\r\nNhư vậy, để đảm bảo yêu cầu của bản tóm tắt thì ta phải xác định các ngưỡng để lựa chọn các câu vào văn bản tóm tắt: \r\n : Ngưỡng để xác định độ tương đồng tối thiểu của câu truy vấn với các câu trong văn bản gốc. Các câu trong văn bản gốc có độ tương đồng với câu truy vấn phải lớn hơn  mới phù hợp để đưa vào văn bản tóm tắt.\r\n : Ngưỡng xác định độ tương đồng lớn nhất giữa các câu trong văn bản tóm tắt. 2 câu trong văn bản tóm tắt được coi là trùng nhau nếu độ tương đồng giữa chúng lớn hơn hoặc bằng .\r\nn : Ngưỡng xác định kích thước văn bản tóm tắt. có nhiều tiêu chí để lựa chọn  giá trị của n, Ở đây tôi chọn n là số từ tối đa trong bản tóm tắt. Một câu sẽ được đưa vào bản tóm tắt nếu như sau khi thêm câu đó vào số từ trong bản tóm tắt không vượt quá n.\r\nÝ tưởng chung để xác định các câu đưa vào bản tóm tắt.\r\nSắp xếp các câu trong văn bản theo thứ tự giảm dần độ tương đồng với câu truy vấn.\r\nLấy các câu theo thứ tự từ  trên xuống dưới sao cho đảm bảo các yêu cầu của bản tóm tắt.\r\nSắp xếp lại các câu trong bản tóm tắt theo thứ tự xuất hiện của nó trong văn bản gốc.\r\n\r\n\r\nTuy nhiên việc lựa chọn câu theo quy trình trên chưa thực sự cho kết quả chính xác vì trong trường hợp có nhiều câu tương tự cùng có độ đo lớn với câu truy vấn mà có 1 câu nói lên nội dung chính còn các câu còn lại là diễn giải cho câu đó thì sẽ xảy ra trường hợp câu diễn giải có độ tương đồng với câu truy vấn cao hơn câu  có nội dung chính. Như vậy khi lấy câu theo quy trình trên câu có nội dung chính sẽ bị loại bỏ do có độ tương đồng cao với câu đã có trong tóm tắt. \r\nVí dụ :\r\n Truy vấn từ người dùng là Món ăn truyền thống của dân tộc Mường\r\nTrong văn bản gốc có 2 câu tương tự có độ tương đồng cao với truy vấn là \r\nMón ăn có vị đắng là món ăn người Mường rất ưa thích\r\nMăng đắng, hoa, lá, quả đu đủ không chỉ là món ăn thường ngày của người Mường mà còn là món ăn để thờ phụng.\r\nNhư vậy câu thứ 2 được lựa chọn sẽ không tóm tắt được hết ý.\r\nĐể hạn chế được trường hợp trên thì trong đồ án áp dụng một thay đổi là trước khi chọn câu vào bản tóm tắt ta sẽ tiến hành gom nhóm cho các câu. Mỗi nhóm bao gồm các câu có độ tương đồng cao với nhau. Sắp xếp các câu trong nhóm theo thứ tự xuất hiện của nó trong văn bản. Khi chọn câu vào văn bản sẽ chọn mỗi duyệt lần lượt trong các nhóm, mỗi nhóm lấy 1 câu . Lặp lại cho đến khi số lượng từ trong văn bản thỏa mãn. (Ý tưởng của phương pháp này dựa trên ý tưởng diễn dịch. Câu mang ý chính của một đoạn văn bản diễn dịch sẽ nằm ở đầu đoạn). \r\n\r\nChi tiết kết quả thực hiện, cài đặt và thử nghiệm.\r\nGiả thiết ban đầu.\r\nNội dung của văn bản đầu vào phải phù hợp với câu truy vấn.\r\nVăn bản gốc được lưu dưới dạng file text (.txt), mã hóa unicode.\r\nTruy vấn từ người dùng trọng tâm đến nội dung tóm tắt, hạn chế các từ không. mang nhiều ý nghĩa.\r\nMục tiêu: Đưa ra nội dung tóm tắt của văn bản theo hướng truy vấn từ người dùng.\r\nCông cụ lựa chọn để giải quyết vấn đề.\r\nCông cụ xây dựng chương trình demo:\r\nNgôn ngữ sử dụng (Java): Java là ngôn ngữ lập trình mới do một nhóm nhà khoa học của hãng Sun Microsytem tạo nên. Làm việc với Java sẽ rất thuận tiện do các ưu điểm của ngôn ngữ này.\r\nJava đơn giản nên thời gian tìm hiểu ngắn.\r\nJava hướng đối tượng nên chương trình rất linh hoạt và có thể tái sử dụng nhiều lần.\r\nJava rất mạnh: bộ nhớ được giải phóng một cách tự động nhờ đó có thể tránh được những hư hỏng về bộ nhớ và đảm bảo tính toàn vẹn dữ liệu.\r\nJava có tính độc lập với cấu trúc, vì vậy không phụ thuộc vào hệ máy và ( loại máy và hệ điều hành).\r\nLý do đặc biệt khi chọn Java làm ngôn ngữ xây dựng chương trình demo là có nhiều mã nguồn có thể tái sử dụng cho việc tiền xử lý tiếng việt. Ví dụ chương trình tách từ tiếng Việt.\r\nIDE: netbean.\r\nIDE phổ biến để viết chương trình bằng ngôn ngữ Java, thân thiện, dễ sử dụng.\r\n\r\nKết quả thực nghiệm.\r\nPhần này sẽ trình bày kết quả thực nghiệm của chương trình với một đoạn văn bản ngắn, và đưa ra các kết quả tính toán là giải thích tại sao cách chương trình đưa ra kết quả cuối cùng, đưa ra kết quả của văn bản mẫu.\r\nGiao diện chương trình.\r\nChương trình gồm 3 giao diện : giao diện chính, giao diện hiển thị kết quả đánh giá và giao diện hiển thị song song nội dung của bản tóm tắt tay và nội dung của bản tóm tắt tự động sinh ra bởi hệ thống\r\n\r\nGiao diện chính của chương trình.\r\n\r\n\r\nDữ liệu vào\r\n1: cung cấp câu truy vấn từ người dùng. Dữ liệu này không được để trống.\r\n2: đường dẫn đền file gốc cần tóm tắt.\r\n3: Nội dung văn bản cần tóm tắt.\r\nChức năng và kết quả xử lý. \r\n4: Chức năng xử lý văn bản đầu vào đưa ra bản tóm tắt hiển thị ở 8.\r\n5: Lưu văn bản tóm tắt(tên bản tóm tắt trùng với tên của văn bản gốc nhưng được đặt ở thư mục tóm tắt.)\r\n6: Xem kết quả đánh giá: chức năng này sẽ mở giao diện đánh các kết quả tóm tắt đã thực hiện.\r\n7: Số lượng từ giới hạn trong bản tóm tắt.\r\n8: Lưu kết quả tóm tắt chương trình thực hiện tóm tắt văn bản gốc.\r\n\r\nGiao diện đánh giá kết quả tóm tắt \r\n\r\n\r\n\r\nViệc đánh giá kết quả tóm tắt dựa trên độ đo ROUGE với các tiêu chí Recall (R),  Precision(P), Fscore(F). Chỉ các văn bản (trong thư mục document) có đầy đủ bản tóm tắt tự động(trong thư mục auto_summation) và tóm tắt tay (trong thư mục hand_summation) mới có kết quả đánh giá hiển thị trên giao diện.\r\nGiao diện hiển thị song song nội dung tóm tắt tay và tóm tắt tự động\r\nThông qua giao diện này người dùng có thể nhìn thấy trực quan nội dung của văn bản tóm tắt tự động và nội dung của văn bản tóm tắt tay.\r\n\r\n\r\nCách sử dụng:\r\nKhi giao diện chính được mở: người dùng sẽ chọn file cần tóm tắt thông qua nút Open file và tìm ra 1 file bất kì có định dạng phần mở rộng .txt, nội dung của file sẽ được tải lên khu vực File content làm nội dung tóm tắt. Hoặc người dùng có thể patse trực tiếp đoạn văn bản cần tóm tắt vào khu vực File content (Tuy nhiên, trong trường hợp này người dùng sẽ không lưu được văn bản vào file vì không có file gốc để so sánh).\r\nSau khi chọn file cần tóm tắt người dùng phải nhập yêu cầu nội dung quan tâm vào phần Query. Nội dung query càng sát với yêu cầu người dùng thì kết quả tóm tắt càng phù hợp với mong muốn của người dùng.\r\nKhi đã đảm bảo các yêu cầu cơ bản query, file content đã có nội dùng người dùng sẽ tạo tóm tắt thông qua nút chức năng Sumarize. Kết quả tóm tắt sẽ hiển thị ở khu vực Sumary. Có thể thay đổi độ dài bản tóm tắt bằng cách lựa chọn số từ.\r\nChức năng Save được sử dụng khi người dùng muốn lưu lại bản tóm tắt vừa tạo (tên file tóm tắt được tạo mặc định là tên file gốc và lưu tại thư mục auto_summation).\r\nChức năng Evaluation để xem đánh giá của bản tóm tắt đã tạo. Để sử dụng chức năng này người dùng phải tạo bản tóm tắt tay của văn bản gốc vừa tóm tắt (tên file trùng với tên văn bản gốc) và đặt tại thư mục hand_summation.\r\n\r\nKết quả ví dụ.\r\nSau đây là kết quả tóm tắt 1 ví dụ (đơn giản) mẫu và giải thích cách chương trình tạo ra văn bản tóm tắt\r\nVăn bản gốc: Bất cứ ngôi đình nào cũng thờ Thành hoàng của làng - đây là yếu tố bắt buộc. Ngoài thành hoàng làng, tùy theo mỗi ngôi đình làng có thể thờ các vị thần, thánh khác do mỗi làng tôn thờ, hoặc việc thờ cúng các vị thần theo sắc phong của Nhà vua, tất cả được rước vào đình thành một tập thể siêu thần, thành một sức mạnh vô hình, tạo niềm tin, niềm hy vọng của làng xã Việt Nam. Việc vinh danh, tôn thờ những người có công to lớn đối với làng cùng với vị trí của nơi đặt đình làng và cách thức bày biện nội thất ngôi đình đã làm toát lên vai trò đây là nơi quan trọng bảo vệ, che chở cho mỗi làng trước các biến cố của tự nhiên và đời sống xã hội. Vào ngày lễ tết, nhân dân trong làng tới đình thắp hương tế lễ, cầu mong thành hoàng làng và trời đất phù giúp mưa thuận gió hoà để mùa màng gặt hái thuận tiện và có nhiều phúc lành. Đây cũng là dịp để tưởng niệm công tích của các vị thần và dịp này người ta tổ chức hội đình. Hầu hết các làng, xóm của người Mường đều có Đình, đình thờ thành hoàng vị thánh được người Mường tôn vinh đó là người có công khai phá ruộng nương, chỉ bảo cho người dân làm ăn. Bên cạnh đó người Mường thường thờ Thánh Tản Viên, họ tôn kính coi Thánh Tản Viên là người có thể đi mây về gió, ban phúc trừ tà. Trong 82 di tích đình của tỉnh Hòa Bình có tới 20 đình thờ Tản Viên Sơn Thánh, 36 đình không rõ tên các vị thần được thờ (do nhiều nguyên nhân), 31 đình còn lại là thờ thành hoàng địa phương và các thiên thần, nhân thần được các đời vua phong sắc. Đình làng ở Hòa Bình có thể được chia ra làm 3 loại cơ bản: Đình của người Mường, Đình của người Kinh và Đình giao thoa giữa hai dân tộc.\r\nTruy vấn từ người dùng:   Nét văn hóa đình làng Hòa Bình. \r\n\r\n\r\nTrọng số của các từ trong truy vấn.\r\n\r\nĐộ tương đồng của các câu với câu truy vấn\r\n\r\nTheo kết quả độ tương đồng với câu truy vấn ở trên 4 câu bị loại bỏ (do độ tương đồng với câu truy vấn < 0.3). Như vậy có 5 câu 8,7,1,5,2 thỏa mãn độ tương đồng với câu truy vấn >0.3.\r\nCác câu này được gom thành 2 nhóm:\r\nNhóm 1 gồm các câu 7,8.\r\nNhóm 2 gồm các câu 1,2,5.\r\nThực hiện việc chọn câu bằng cách duyệt các nhóm mỗi lần duyệt lấy 1 câu trong nhóm và thực hiện lặp lại cho tới khi đủ số từ trong bản tóm tắt. Việc lựa chọn kết quả vào tóm tắt sẽ dựa trên độ tương đồng với câu truy vấn mà đã được tính toán ở trên. 1 câu được lựa chọn vào bản tóm tắt phải thỏa mãn : độ tương đồng nhỏ nhất với câu truy vấn (ở đây được lựa chọn là >0.2), độ tương đồng lớn nhất với các câu đã có trong bản tóm tắt (<0.9), số lượng từ trong bản tóm tắt phải nhỏ hơn ngưỡng đã chọn (<120 từ).\r\nDựa vào các tiêu chí trên hệ thống lựa chọn được câu đưa vào bản tóm tắt\r\nKết quả tóm tắt: Bất cứ ngôi đình nào cũng thờ Thành hoàng của làng - đây là yếu tố bắt buộc .. Ngoài thành hoàng làng , tùy theo mỗi ngôi đình làng có thể thờ các vị thần , thánh khác do mỗi làng tôn thờ , hoặc việc thờ cúng các vị thần theo sắc phong của Nhà vua , tất cả được rước vào đình thành một tập thể siêu thần , thành một sức mạnh vô hình , tạo niềm tin , niềm hy vọng của làng xã Việt Nam .. Trong 82 di tích đình của tỉnh Hòa Bình có tới 20 đình thờ Tản Viên Sơn Thánh , 36 đình không rõ tên các vị thần được thờ , 31 đình còn lại là thờ thành hoàng địa phương và các thiên thần , nhân thần được các đời vua phong sắc .. Đình làng ở Hòa Bình có thể được chia ra làm 3 loại cơ bản : Đình của người Mường , Đình của người Kinh và Đình giao thoa giữa hai dân tộc ..\r\n\r\nĐánh giá.\r\nMô tả bộ dữ liệu.\r\nBộ dữ liệu gồm 50 tài liệu mẫu là các bài báo  được thu thập từ các trang web tin tức bởi các bạn trong nhóm đồ án thu thập và tạo văn bản tóm tắt tay. Tên các bản tóm tắt được đặt trùng với tên văn bản gốc. Độ dài các văn bản từ 400-1200 từ. các văn bản tóm tắt tay có độ dài xấp xỉ 120 từ.\r\nCâu truy vấn mặc định được lấy từ tiêu đề bài báo.\r\nĐộ đo ROUGE.\r\nĐồ án sử dụng độ đo Rouge để đánh giá độ chính xác của tóm tắt. ROUGE là một hệ thống đánh giá tóm tắt tự động mà dựa trên tỉ lệ tóm tắt dựa trên đặc điểm của sự gắn kết và hàm lượng thông tin chứa trong bản tóm tắt tự động. Nó nhận bản tóm tắt như đầu vào.\r\nĐộ đo ROUGE được xác nhận là một công cụ đánh giá tốt cho tóm tắt đa văn bản với sự tập trung vào nội dung trùng lặp. ROUGE không phải là một công cụ đánh giá bao hàm toàn diện. ROUGE-2, ROUGE-L, ROUGE-W, ROUGE SU4 tốt cho tóm tắt đơn van bản trong khi ROUGE-1 làm việc tốt cho tóm tắt đa văn bản.\r\nKết quả đánh giá.\r\nChất lượng của bản tóm tắt sinh ra từ hệ thống được đánh giá qua độ đo ROUGE với số GRAM n =4, với ngưỡng độ dài yêu cầu của bản tóm tắt là 120 từ,Kết quả đánh giá nằm trong khoảng từ 0.3 đến 0.8. Độ chính xác của hệ thống càng cao khi số từ giới trong bản tóm tắt càng cao.\r\nBản đánh giá kết quả khi không thực hiện gom nhóm trong quá trình sinh tóm tắt.\r\n\r\n\r\n\r\n\r\n\r\nBảng đánh giá kết quả khi thực hiện gom nhóm \r\n\r\n\r\n\r\nTừ kết quả thực nghiệm, có thể thấy rằng mô hình tóm tắt sử dụng cho kết quả khả quan mặc dù các câu trả về vẫn chưa thể hiện ngữ nghĩa, chưa có sự gắn kết giữa các câu trong tóm tắt. Theo 2 kết quả trên ta thấy việc áp dụng gom nhóm câu trong khi tạo kết quả tóm tắt mang lại hiệu quả tốt hơn cho hệ thống.\r\nKết quả đánh giá trung bình khi thực hiện với 50 văn bản gốc\r\n\r\n\r\n\r\n\r\nPhần III: KẾT LUẬN\r\n\r\nĐánh giá ưu nhược điểm và khả năng ứng dụng của hệ thống.\r\nƯu điểm.\r\nHệ thống cho kết quả tương đối chính xác, thời gian xử lý nhanh, không mất thời gian xây dựng kho dữ liệu từ điển.\r\nNhược điểm.\r\nHệ thống chưa xử lý được về mặt ngữ nghĩa.\r\nChưa giải quyết được tính dễ đọc của kết quả đầu ra, kết quả đầu ra không liền mạch, các câu chưa có sự liên kết với nhau\r\nĐộ chính xác của kết quả phụ thuộc nhiều vào việc xác định câu truy vấn, độ dài văn bản.\r\nKhả năng ứng dụng.\r\nHệ thống có thể áp dụng tóm tắt các văn bản ngắn, trung bình như: các bài báo, tin tức trên internet. Nội dung của văn bản gốc ko tập trung theo từng đoạn của văn bản.\r\nHệ thống được xây dựng để hỗ trợ các bộ máy tìm kiếm thông tin mà có kết quả trả về dưới dạng văn bản.\r\nĐánh giá công việc.\r\nĐồ án nghiên cứu giải quyết bài toán tóm tắt hướng truy vấn trên phạm vi đơn văn bản bằng phương pháp tính độ tương đồng với câu truy vấn. và nâng cao mức độ chính xác cho phương pháp bằng cách gom nhóm các câu tương đồng trong văn bản. Việc gom nhóm đã tránh được sự dư thừa trong bản tóm tắt. Kết quả thử nghiệm cho thấy khi hệ thống đưa ra tóm tắt bằng cách gom nhóm các câu tương đồng trong văn bản đạt kết quả cao hơn so với khi chỉ sử dụng độ tương đồng với câu truy vấn. \r\nTuy nhiên, hệ thống vẫn còn những hạn chế chưa khắc phục được \r\nChưa áp dụng được ngữ nghĩa. Bản tóm tắt chưa thật phù hợp với câu truy vấn về mặt ngữ nghĩa.\r\nChưa giải quyết được tính dễ đọc của bản tóm tắt.Nội dung của bản tóm tắt còn rời rạc , chưa liên kết giữa các câu với nhau, đôi khi còn tồn tại những câu không rõ nghĩa.\r\n\r\n\r\nĐịnh hướng phát triển và hoàn thiện các kết quả đạt được.\r\nXử lý đồng tham chiếu(đặc biệt là đồng tham chiếu đại từ) để xác định được chính xác các đại từ trong câu tóm tắt.\r\nXây dựng bộ từ điển corpus tiếng việt, từ đó có thể tăng ngữ nghĩa cho bản tóm tắt.\r\nÁp dụng các kĩ thuật phân tích xử lý văn bản tiếng việt nhằm nâng cao chất lượng hệ thống: gán nhãn từ loại, phân tích cú pháp,.\r\n\r\n\r\n\r\n\r\n\r\n\r\nTài  liệu tham khảo.\r\n\r\nA. P. Siva kumar, Dr. P. Premchand,Dr. A. Govardhan. \"Query-Based Summarizer Based on Similarity of Sentences and Word Frequency.\" Department of Computer Science Engineering, Osmania University, Hyderabad,  India.\r\nAhmed A. Mohamed, Sanguthevar Rajasekaran. \"Query-Based Summarization Based on Document Graphs .\" Department of Computer Science & Engineering, University of Connecticut.\r\nĐỗ Thị Thanh Nga. \"Tính toán độ tương tự ngữ nghĩa văn bản dựa vào độ tương tự giữa từ với từ.\" Luận văn thạc sĩ, Đại học Quốc Gia Hà Nội - Trường đại học Công Nghệ, 2010.\r\nHoàng Minh Hiền. \"Độ tương đồng ngữ nghĩa giữa 2 câu và ứng dụng trong tóm tắt văn bản.\" Khóa luận tốt nghiệp, Đại học Quốc Gia Hà Nội, 2008.\r\nLapalme, Olga Feiguina and Guy. \"Query-based summarization of customer reviews.\" Departement dinformatique et de recherche operationnelle, Universite de Montreal.\r\nLin, Chin- Yew. \"ROUGE: A Package for Automatic Evaluation of Summaries.\" Information Sciences Institute, University of Southern California.\r\nMariana Damova, Ivan Koychev. \"Query-Based Summarization: A survey.\" Faculty of Mathematics and Informatics, University of Sofia, Bulgaria. \r\nLưu Tuấn Anh. \"Kiến thức cơ bản về xử lý ngôn ngữ tự nhiên.\" http://viet.jnlp.org/kien-thuc-co-ban-ve-xu-ly-ngon-ngu-tu-nhien, 25/03/2013.\r\nNguyễn Minh Thành, \"Text  Summarization.\"  https://sites.google.com/site/trangmonhocitc/text-summarization,    15/03/2013.","u":"http://202.191.57.85:8000/InternetData/Data/LVTN/48.txt","downloaded":false,"m":[-1,-1],"n":"48.txt","o":"http://202.191.57.85:8000/InternetData/Data/LVTN/48.docx\r"},{"saved_path":"/home/huong/InternetData/Data/DATN/20130150_Nguyen_Nam_Anh_1527526468353.txt","r":0.333812952041626,"s":[[55,113,0.930232584476471,40,0,42,0,42,"Ngược lại, tóm tắt đa văn bản là từ nhiều văn bản nguồn cũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng thời cho nhiều văn bản khác nhau","Ngược lại tóm tắt đa văn bản là từ một văn bản nguồn cũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng thời cho nhiều văn bản khác nhau"],[54,112,0.800000011920929,18,5,24,0,19,"Theo đầu vào hệ thống Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn gọn của văn bản đó","Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn ngọn của văn bản đó"]],"t":"\n\r\nTrường Đại học Bách Khoa Hà Nội  \r\n\r\nViện Công nghệ Thông Tin và Truyền Thông \r\n\r\n \r\n\r\n \r\n\r\nĐồ án Tốt nghiệp Đại học \r\n\r\n \r\n\r\n \r\n\r\nTóm tắt văn bản bằng \r\n\r\nDeep Learning và Áp dụng \r\n\r\nxây dựng ứng dụng Android \r\n \r\n\r\n \r\n\r\nNguyễn Nam Anh  \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\nHà Nội, 06/2018\r\n\r\n\r\n\r\nTrường Đại học Bách Khoa Hà Nội \r\n\r\nViện Công nghệ Thông Tin và Truyền Thông \r\n\r\n \r\n\r\n \r\n\r\nĐồ án Tốt nghiệp Đại học \r\n\r\n \r\n\r\n \r\n\r\nTóm tắt văn bản bằng \r\n\r\nDeep Learning và Áp dụng \r\n\r\nxây dựng ứng dụng Android \r\n \r\n\r\n \r\n\r\n\r\nNgười hướng dẫn ThS. Hoàng Anh Việt \r\n\r\n \r\n\r\n \r\n\r\nHà Nội, 06/2018\r\n\r\n\r\n\r\n \r\niii \r\n\r\nHọ và tên sinh viên :  Nguyễn Nam Anh           \r\n\r\nĐiện thoại liên lạc:     0978 322 456   Email: namanh11611@gmail.com \r\n\r\nLớp:   CNTT 2.01  K58       Hệ đào tạo: Chính quy \r\n\r\n \r\n\r\nTôi  Nguyễn Nam Anh  cam kết Đồ án Tốt nghiệp (ĐATN) là công trình nghiên \r\n\r\ncứu của bản thân tôi dưới sự hướng dẫn của ThS. Hoàng Anh Việt. Các kết quả nêu \r\n\r\ntrong ĐATN là trung thực, là thành quả của riêng tôi, không sao chép theo bất kỳ \r\n\r\ncông trình nào khác. Tất cả những tham khảo trong ĐATN  bao gồm hình ảnh, bảng \r\n\r\nbiểu, số liệu, và các câu từ trích dẫn  đều được ghi rõ ràng và đầy đủ nguồn gốc \r\n\r\ntrong danh mục tài liệu tham khảo. Tôi xin hoàn toàn chịu trách nhiệm với dù chỉ một \r\n\r\nsao chép vi phạm quy chế của nhà trường. \r\n\r\n      Hà Nội, ngày 28 tháng 5 năm 2018 \r\n\r\n Tác giả ĐATN \r\n\r\n \r\n\r\n \r\n\r\nNguyễn Nam Anh \r\n\r\nLời cam kết \r\n\r\n\r\n\r\n \r\niv \r\n\r\nNăm tháng trôi đi tựa như một cơn gió lướt qua tuổi thanh xuân. Năm năm gắn với \r\n\r\nBách Khoa, tuy không dài nhưng cũng không phải là ngắn, khoảng thời gian đó sẽ \r\n\r\nmãi là ký ức về một thời tuổi trẻ khao khát và dại khờ. Không phải ngẫu nhiên mà \r\n\r\ncon đường phía bên kia cổng Parabol được đặt tên là Giải Phóng. Trải qua chín kỳ \r\n\r\nthi và một kỳ đồ án, ai cũng mòn mỏi chờ đợi đến ngày mình trưởng thành, đủ năng \r\n\r\nlực và bản lĩnh để bước chân qua cánh cổng Parabol. Thế nhưng, nếu được chọn lại \r\n\r\nmột lần nữa, chúng tôi vẫn sẽ chọn Bách Khoa. \r\n\r\nEm xin gửi lời cảm ơn chân thành tới các thầy cô trường đại học Bách Khoa Hà Nội \r\n\r\nnói chung và viện Công nghệ Thông tin và Truyền thông nói riêng, đặc biệt là thầy \r\n\r\nThS. Hoàng Anh Việt đã tận tình dạy dỗ, truyền đạt cho chúng em những kiến thức \r\n\r\nbổ ích suốt năm năm đại học. Thầy cô không chỉ giảng dạy những bài học về chuyên \r\n\r\nmôn mà còn truyền cho chúng em cả chất Bách Khoa đã được hun đúc qua bao \r\n\r\nnhiêu thế hệ. \r\n\r\nCảm ơn những người anh, người em đã luôn ở bên đồng hành cùng tôi trong những \r\n\r\nkhoảnh khắc khó khăn nhất. Mỗi người các bạn là một mảnh ghép tạo nên bức tranh \r\n\r\nvề thời sinh viên Bách Khoa gian khó nhưng cũng đầy ắp kỷ niệm của tôi. Và cảm \r\n\r\nơn em, người tôi từng thương, đã giúp tôi nhận ra phải biết trân trọng những người ở \r\n\r\nbên cạnh mình đến nhường nào. \r\n\r\nCuối cùng, con xin được gửi lời cảm ơn chân thành tới gia đình đã luôn ở bên cạnh \r\n\r\nyêu thương, động viên và tạo mọi điều kiện tốt nhất cho con trong suốt năm năm qua. \r\n\r\nQua mỗi lần tưởng chừng như gục ngã, bố mẹ và em gái luôn là nguồn động lực lớn \r\n\r\nnhất để giúp con đứng dậy mạnh mẽ hơn. \r\n\r\nLời cảm ơn \r\n\r\n\r\n\r\n \r\nv \r\n\r\nTrong thời đại công nghệ số, lượng thông tin trên mạng Internet đang tăng trưởng \r\n\r\ntừng giây theo cấp số mũ. Trong đó, đa phần nội dung số được biểu diễn dưới dạng \r\n\r\ncác văn bản thuần tuý. Để có thể nắm bắt được lượng thông tin lớn nhất trong thời \r\n\r\ngian nhanh nhất, cần thiết có một phương pháp tóm tắt văn bản chính xác và hiệu \r\n\r\nquả. Bên cạnh đó, để cải tiến phương thức tương tác giữa con người và máy tính, cần \r\n\r\nthiết có một công cụ để chuyển văn bản thành giọng nói, giúp người dùng dễ dàng \r\n\r\ntiếp nhận thông tin từ các thiết bị hơn. \r\n\r\nĐã có nhiều giải pháp tóm tắt văn bản được đưa ra, nhưng mỗi phương pháp đều có \r\n\r\nnhững nhược điểm chưa khắc phục được về vấn đề xử lý ngữ nghĩa. Gần đây, với sự \r\n\r\nphát triển của công nghệ Machine Learning nói chung và Deep Learning nói riêng, \r\n\r\nbài toán tóm tắt văn bản đã được giải quyết một cách tối ưu hơn nhiều so với các \r\n\r\nphương pháp cũ. Để giải quyết bài toán, người viết đồ án lựa chọn mô hình sequence \r\n\r\nto sequence kết hợp với kỹ thuật attention. Mô hình được thực hiện dựa trên việc xây \r\n\r\ndựng mạng neural LSTM  một dạng đặc biệt của mạng neural hồi quy. Đi kèm với \r\n\r\nđó là công nghệ text-to-speech trên nền tảng Android đã được phát triển bởi Google \r\n\r\nđể giúp truyền đạt thông tin tới người dùng qua giọng nói thay vì dạng văn bản thông \r\n\r\nthường. Tất cả các công nghệ trên sẽ được tích hợp trên một ứng dụng di động \r\n\r\nAndroid hoàn chỉnh. \r\n\r\nNội dung đồ án sẽ khái quát những kiến thức về phương pháp tóm tắt văn bản bằng \r\n\r\ncông nghệ Deep Learning và công nghệ text-to-speech. Cùng với đó là quy trình phát \r\n\r\ntriển ứng dụng trên nền tảng Android với hai chức năng chính áp dụng các công nghệ \r\n\r\nđã trình bày. \r\n\r\nTóm tắt \r\n\r\n\r\n\r\n \r\nvi \r\n\r\nMục lục \r\n\r\n\r\n\r\n \r\nvii \r\n\r\nviii \r\n\r\nix \r\n\r\nx \r\n\r\nxi \r\n\r\nDanh mục hình vẽ \r\n\r\n\r\n\r\n \r\nxii \r\n\r\nxiii \r\n\r\nDanh mục bảng \r\n\r\n\r\n\r\n \r\nxiv \r\n\r\nDanh mục công thức  \r\n\r\n\r\n\r\n \r\nxv \r\n\r\nAI \r\nArtificial Intelligence \r\n\r\nTrí tuệ nhân tạo \r\n\r\nML \r\nMachine Learning \r\n\r\nHọc Máy \r\n\r\nDL \r\nDeep Learning \r\n\r\nHọc sâu \r\n\r\nRNN \r\nRecurrent Neural Network \r\n\r\nMạng nơ-ron hồi quy \r\n\r\nbiRNN \r\nBidirectional RNN \r\n\r\nMạng nơ-ron hồi quy 2 chiều \r\n\r\nLSTM \r\nLong Short-Term Memory \r\n\r\nMạng bộ nhớ dài-ngắn \r\n\r\nTTS \r\nText-to-Speech \r\n\r\nChuyển văn bản thành giọng nói \r\n\r\nDanh mục các từ viết tắt \r\n\r\n\r\n\r\n \r\nxvi \r\n\r\nSeq2Seq Sequence to Sequence \r\n\r\nAPI \r\nApplication Programming Interface \r\n\r\nGiao diện lập trình ứng dụng \r\n\r\nMVC Model  View  Controller \r\n\r\n \r\n\r\n\r\n\r\n \r\nxvii \r\n\r\nExtractive Text \r\n\r\nSummarization \r\n\r\nPhương pháp tóm tắt trích xuất văn bản \r\n\r\nAbstractive Text \r\n\r\nSummarization \r\n\r\nPhương pháp tóm tắt tóm lược văn bản \r\n\r\nNeural Network Mạng nơ-ron \r\n\r\nWord Empeddings Kỹ thuật ánh xạ từ với các vec-tơ số thực \r\n\r\nAttention Kỹ thuật chú ý từ \r\n\r\nEncoder Bộ mã hoá \r\n\r\nDecoder Bộ giải mã \r\n\r\n \r\n\r\nDanh mục thuật ngữ \r\n\r\n\r\n\r\n \r\n1 \r\n\r\n1.1 Đặt vấn đề \r\n\r\nCùng với sự phát triển của Internet, lượng kiến thức và thông tin của nhân loại là vô \r\n\r\ncùng lớn và gia tăng nhanh chóng theo thời gian. Con người bị choáng ngợp trước \r\n\r\nlượng thông tin vô cùng lớn này. Nhu cầu nắm bắt các thông tin chính ngày càng lớn. \r\n\r\nDo đó, tầm quan trọng của việc tóm tắt văn bản ngày càng được nâng cao. Việc tóm \r\n\r\ntắt giúp cho người đọc dễ dàng nắm bắt được thông tin quan trọng một cách nhanh \r\n\r\nchóng. \r\n\r\nVậy tóm tắt văn bản là gì? Tóm tắt văn bản là quá trình lấy các thông tin quan trọng \r\n\r\nnhất từ một hoặc nhiều văn bản để tạo ra một văn bản ngắn gọn nhưng vẫn mang đầy \r\n\r\nđủ các thông tin của phiên bản gốc và đảm bảo tính đúng về ngữ pháp. Bản tóm tắt \r\n\r\nphải chứa những thông tin chính và ý nghĩa tổng thể của văn bản gốc. Đồng thời nội \r\n\r\ndung của bản tóm tắt phải trung thực. Độ dài của bản tóm tắt nhỏ độ dài của bản gốc. \r\n\r\nTóm tắt văn bản tự động là quá trình tóm tắt văn bản bằng phần mềm.  \r\n\r\nTóm tắt văn bản tự động là một thách thức rất lớn, bởi vì khi chúng ta tóm tắt một \r\n\r\nđoạn văn, chúng ta thường hay đọc nó để hiểu nội dung của nó sau đó ghi những điểm \r\n\r\nchính của nó. Vì máy tính thiếu kiến thức về ngôn ngữ và khả năng ngôn ngữ nên \r\n\r\ntổng hợp văn bản tự động trở thành một việc không dễ dàng. Chính vì thế, đã có nhiều \r\n\r\nkỹ thuật được sử dụng để trích xuất các nội dung quan trọng từ vản bản để mô tả tóm \r\n\r\nlược tài liệu. Mục đích của tóm tắt văn bản tự động là để tạo ra một văn bản trình bày \r\n\r\nngắn hơn văn bản gốc, loại bỏ đi các thông tin không quan trọng và vẫn giữ được \r\n\r\nnhững nội dung cốt lõi. Qua đó, giúp con người tiết kiệm công sức và thời gian trong \r\n\r\nviệc nắm bắt các thông tin quan trọng. \r\n\r\nChương 1 Giới thiệu đề tài \r\n\r\n\r\n\r\n \r\n2 \r\n\r\n1.2 Mục tiêu và phạm vi đề tài \r\n\r\n1.2.1 Lịch sử nghiên cứu về tóm tắt văn bản \r\n\r\nTóm tắt văn bản bắt đầu từ những năm cuối thập kỉ 1950 với nghiên cứu của Luhn \r\n\r\n(1958) dựa trên tần số từ. Ý tưởng cơ bản của phương pháp tần số từ dựa trên kiến \r\n\r\nthức cho rằng tần số của từng từ trong văn bản là một độ đo hữu dụng để đánh giá \r\n\r\ntầm quan trọng của chúng. \r\n\r\nTiếp theo đó là phương pháp tóm tắt dựa trên vị trí của các câu trong văn bản của \r\n\r\nBaxendale (1958) và những nghiên cứu của Edmundson (1969) về vị trí của các câu \r\n\r\ntrong văn bản và các từ/cụm từ mang ý nghĩa tổng quát. Theo đó, những câu bắt đầu \r\n\r\nvà kết thúc của đoạn văn, bài viết hay những câu chứa những từ như important \r\n\r\n(quan trọng), result are (kết quả là). là những câu có ý nghĩa quan trọng. \r\n\r\nĐầu những năm 1970, tiếp tục có những nghiên cứu với hướng tiếp cận ngoài (sử \r\n\r\ndụng các cụm từ dấu hiệu) và được ứng dụng trong các phần mềm thương mại. \r\n\r\nNhững năm 1980, phát triển nhiều nghiên cứu với nhiều hướng khác nhau, đặc biệt \r\n\r\nlà hướng tiếp cận mức thực thể dựa trên trí tuệ nhân tạo như sử dụng script (Lehnert \r\n\r\n1981), các luật sản xuất mạng và logic (Fum 1985), mạng ngữ nghĩa (Reimer và Hahn \r\n\r\n1988) cũng như các hướng tiếp cận kết hợp (Rau 1989) hay (Aretoulaki 1994). \r\n\r\nWillam B. Cavnar (1994) biểu diễn văn bản dựa trên n-gram thay cho cách biểu diễn \r\n\r\ntruyền thống bằng từ khoá. \r\n\r\nJaine Carbonell (1998) đã tóm tắt văn bản bằng cách xếp hạng các câu trội (câu chứa \r\n\r\ncác ý chính của văn bản) và rút ra các câu trội. \r\n\r\nJade Goldstein (1999) phân loại tóm tắt dựa trên độ đo liên quan, phương pháp sử \r\n\r\ndụng kết hợp giữa ngữ học, thống kê. Một câu được đặc trưng bằng các đặc tính ngữ \r\n\r\nhọc và độ đo thống kê. \r\n\r\n\r\n\r\n \r\n3 \r\n\r\nJ.Larocca Neto (2000) đã tạo tóm tắt văn bản dựa trên các dãy từ trong câu được chọn \r\n\r\ntheo hệ số tf, sau đó dùng kỹ thuật gom cụm (clustering) để tạo tóm tắt. \r\n\r\nYoshio (2001) đã tạo tóm tắt văn bản tiếng Nhật. Có 2 phương pháp là rút câu dựa \r\n\r\ntrên từ khoá và rút câu dựa trên kiến trúc ngữ nghĩa trong đó có xây dựng độ đo mối \r\n\r\nliên kiết giữa hai từ. \r\n\r\nHiện nay, một số nghiên cứu về xử lý ngôn ngữ tự nhiên cũng bước đầu được áp dụng \r\n\r\ntrong tóm tắt văn bản. Mặt khác, các nghiên cứu về tóm tắt đa văn bản, đa ngôn ngữ \r\n\r\nvà tóm tắt đa phương tiện cũng bắt đầu phát triển. \r\n\r\n1.2.2 Phân loại phương pháp tóm tắt văn bản \r\n\r\n1.2.2.1 Phương pháp tóm tắt trích xuất \r\n\r\nPhương pháp tóm tắt trích xuất (Extractive Text Summarization) bao gồm việc lựa \r\n\r\nchọn đơn vị của văn bản (câu hay đoạn văn), được coi là có chứa lượng thông tin cốt \r\n\r\ntử của văn bản (informative content, informativity), và kết nối các đơn vị này theo \r\n\r\nmột trình tự thích hợp. Một trích xuất là sự lắp ghép các đoạn được trích rút ra từ văn \r\n\r\nbản nguồn. Mục tiêu của trích xuất là cung cấp một cái nhìn tổng quan về nội dung \r\n\r\ncủa văn bản gốc. Độ dài của văn bản tóm tắt bằng trích xuất có thể được xác định bởi \r\n\r\ntỉ lệ nén, hay nói cách khác Văn bản tóm tắt ngắn hơn bao nhiêu so với văn bản \r\n\r\ngốc. \r\n\r\nThuật toán tóm tắt tự động bằng trích xuất có thể chia ra làm 3 mức: surfacelevel \r\n\r\n(mức bề mặt), intermediate-level (mức trung bình) và deep parsing techniques (các \r\n\r\nkĩ thuật phân tích sâu). \r\n\r\nTóm tắt trích rút xuất phát từ ý tưởng: Một tài liệu được chia nhỏ thành các đơn vị \r\n\r\nngữ pháp (các câu văn), sau đó được đánh trọng số theo kinh nghiệm (heuristic); Các \r\n\r\nđơn vị ngữ pháp có điểm cao nhất sẽ được trích rút và liên kết với nhau để tạo nên \r\n\r\nvăn bản tóm tắt. \r\n\r\n\r\n\r\n \r\n4 \r\n\r\n1.2.2.2 Phương pháp tóm tắt tóm lược \r\n\r\nTuy tóm tắt bằng trích rút đã thành công trong việc xác định câu nào trong văn bản \r\n\r\nđầu vào mang nội dung quan trọng nhưng dường như những phương pháp này rất xa \r\n\r\nvới việc tạo ra một bản tóm tắt tối ưu theo nghĩa cả về nội dung và chất lượng trong \r\n\r\nngôn ngữ học. Trong khi đó, hệ thống tạo ra văn bản tóm tắt bằng phương pháp tóm \r\n\r\nlược (Abstractive Text Summarization) dựa trên việc hiểu văn bản gốc và đạt tới việc \r\n\r\nsinh ra một văn bản mới một cách chính xác về ngữ pháp, súc tích và mạch lạc về nội \r\n\r\ndung, bằng cách sinh ra văn bản tóm tắt bằng những từ vựng không xuất hiện trong \r\n\r\nvăn bản gốc. Trong tóm lược, việc diễn giải, viết lại các câu phức tạp sẽ nhằm mục \r\n\r\nđích tạo ra phiên bản súc tích của nội dung ban đầu. Mặc dù con người có thể tái sử \r\n\r\ndụng một phần văn bản gốc nhưng không phải sử dụng toàn bộ nó, sử dụng các đoạn \r\n\r\nhay một phần của câu thay vì sử dụng toàn bộ câu. \r\n\r\nTuy đã có nhiều nghiên cứu trong lĩnh vực tóm tắt văn bản, nhưng việc ứng dụng các \r\n\r\nkết quả vào thực tế vẫn đang còn hạn chế. Như vậy, mục tiêu của đề tài là nghiên cứu \r\n\r\nvề phương pháp tóm tắt văn bản bằng Deep Learning, sau đó áp dụng kết quả vào \r\n\r\nứng dụng thực tế, cụ thể là ứng dụng di động trên nền tảng Android. \r\n\r\n1.3 Định hướng giải pháp \r\n\r\nHầu hết các phương pháp tóm tắt văn bản hiện nay là trích xuất. Mục đích của tóm \r\n\r\ntắt tự động là tạo ra những văn bản giống với tóm tắt của con người, mà con người \r\n\r\nthường không tóm tắt theo kiểu trích xuất. Thực tế cho thấy, các phương pháp tóm \r\n\r\ntắt tóm lược gần với cách tóm tắt của con người hơn so với các phương pháp trích \r\n\r\nxuất.  \r\n\r\nVới sự tiến bộ trong lĩnh vực Machine Learning (Học máy) nói chung và Deep \r\n\r\nLearning (Học sâu) nói riêng, có rất nhiều phương pháp đã chứng minh được tính \r\n\r\nhiệu quả trong việc giải quyết những bài toán phức tạp mà các cách tiếp cận truyền \r\n\r\nthống chưa thể giải quyết triệt để được.  \r\n\r\n\r\n\r\n \r\n5 \r\n\r\nTrong phạm vi khóa luận, sinh viên tập trung nghiên cứu các bài toán tóm tắt đơn văn \r\n\r\nbản, theo phương pháp tóm tắt tóm lược (Abstractive Summarization) sử dụng công \r\n\r\nnghệ Deep Learning. Cụ thể, sinh viên sử dụng mô hình đang phổ biến hiện nay là \r\n\r\nSequence to Sequence cùng với kĩ thuật attention. Mô hình được xây dựng dựa trên \r\n\r\nmạng neural LSTM và kỹ thuật word embeddings. \r\n\r\nVề ứng dụng di động, sinh viên xây dựng trên nền tảng Android, vì đây là hệ điều \r\n\r\nhành chiếm thị phần lớn nhất của thị trường điện thoại di động. Như vậy, ứng dụng \r\n\r\ncó thể dễ dàng tiếp cận với lượng lớn người dùng. Kết quả tóm tắt văn bản sẽ xử lý \r\n\r\ntrên server được xây dựng bằng Django. \r\n\r\n1.4 Bố cục đồ án \r\n\r\nPhần còn lại của báo cáo đồ án tốt nghiệp này được tổ chức như sau.  \r\n\r\nChương 2 trình bày tình hình các nghiên cứu về tóm tắt văn bản tự động theo hai \r\n\r\nhướng tiếp cận chính là đơn văn bản và đa văn bản. Trong đó, mỗi phương pháp tóm \r\n\r\ntắt mô tả tổng quan về cách thực hiện, bộ dữ liệu sử dụng, các kết quả đạt được và độ \r\n\r\nchính xác. Cùng với đó là phân tích tổng quan về yêu cầu của phần mềm. \r\n\r\nTrong Chương 3, sinh viên giới thiệu về các lý thuyết nền tảng của phương pháp tóm \r\n\r\ntắt văn bản bằng Deep Learning. Chúng ta sẽ tìm hiểu về các khái niệm Machine \r\n\r\nLearning, Deep Learning, mạng neural nhân tạo, mạng RNN, mạng LSTM. Sau đó \r\n\r\nlà trình bày về mô hình sequence to sequence, kỹ thuật attention và word embeddings. \r\n\r\nSau khi đã tìm hiểu về các phương pháp tóm tắt văn bản, cơ sở lý thuyết của tóm tắt \r\n\r\nvăn bản bằng Deep Learning, Chương 4 trình bày quá trình triển khai model tóm tắt \r\n\r\nvăn bản và các kết quả đạt được. Nội dung gồm hai phần chính, trong đó phần 4.1 \r\n\r\nmô tả model được xây dựng dựa trên thư viện TensorFlow, và phần 4.2 mô tả ứng \r\n\r\ndụng di động Android với chức năng chính là tóm tắt văn bản. \r\n\r\n\r\n\r\n \r\n6 \r\n\r\nChương 5 nêu các đóng góp chính của sinh viên trong đồ án. Cụ thể, nội dung chương \r\n\r\nnày trình bày về việc cải tiến word embedding, quá trình xây dựng server và ứng dụng \r\n\r\ndi động Android. \r\n\r\nKết luận và hướng phát triển của đồ án được trình bày trong Chương 6. Trong đó, \r\n\r\nsinh viên tổng kết lại những kết quả đã đạt được và những gì cần cải tiến trong tương \r\n\r\nlai của đồ án này. \r\n\r\n\r\n\r\n \r\n7 \r\n\r\nChương 2 sẽ trình bày tổng quan về các kết quả nghiên cứu liên quan đến tóm tắt văn \r\n\r\nbản tự động. Với mục đích là một đồ án nghiên cứu, chúng ta cần nắm được lịch sử \r\n\r\ncác phương pháp tóm tắt văn bản đã được xây dựng và phát triển. Sinh viên sẽ trình \r\n\r\nbày từ những nghiên cứu về cách trích xuất văn bản cơ bản cho đến các phương pháp \r\n\r\ntóm lược phức tạp ngày nay áp dụng Deep Learning. Nhìn chung, mỗi phương pháp \r\n\r\nđều có ưu, nhược điểm riêng, tính hiệu quả của nó thể hiện qua các kết quả được đo \r\n\r\nđạc, đánh giá cụ thể. \r\n\r\nCùng với đó, nội dung Chương 2 cũng trình bày tóm tắt về các chức năng của ứng \r\n\r\ndụng Android. Trong đó chú trọng về chức năng Tóm tắt văn bản. \r\n\r\n2.1 Khảo sát hiện trạng \r\n\r\nTóm tắt văn bản tự động là một bài toán kinh điển trong lĩnh vực xử lý dữ liệu văn \r\n\r\nbản. Hiện nay trên thế giới, nhiều nhà khoa học và các công ty tỏ ra rất quan tâm đến \r\n\r\nbài toán này. Tại các hội nghị nổi tiếng như: DUC 2001 - 2007, TAC 2008 - 2011, \r\n\r\nACL 2001-2015, tóm tắt văn bản tự động đã được đề cập đến nhiều trong các bài báo. \r\n\r\nNgoài ra, có nhiều hệ thống tóm tắt văn bản độc lập hoặc tích hợp được phát triển \r\n\r\nnhư: MEAD, LexRank. \r\n\r\nCác kết quả nghiên cứu của tóm tắt văn bản được ứng dụng trong nhiều lĩnh vực như: \r\n\r\n Tóm tắt tin tức trong lĩnh vực báo chí \r\n\r\nChương 2 Khảo sát và \r\n\r\nphân tích yêu cầu \r\n\r\n\r\n\r\n \r\n8 \r\n\r\n Tóm tắt kết quả tìm kiếm trong các search engine \r\n\r\n Thu thập dữ liệu thông minh \r\n\r\n Tóm tắt bài báo khoa học \r\n\r\n Tóm tắt nội dung cuộc họp, hội nghị \r\n\r\n Hệ thống trả lời tự động \r\n\r\nMặc dù có 2 dạng tóm tắt là tóm tắt trích xuất (Extractive Text Summarization) và \r\n\r\ntóm tắt tóm lược (Abstractive Text Summarization), tuy nhiên để thực hiện tóm lược \r\n\r\ncần có một lượng tri thức đầy đủ về lĩnh vực cần tóm tắt. Điều này hiện nay vẫn còn \r\n\r\nhạn chế nhiều, do đó các hướng tiếp cận đa số tập trung vào dạng tóm tắt trích xuất. \r\n\r\nMột trong những cách phân chia của bài toán tóm tắt là: tóm tắt đơn văn bản và tóm \r\n\r\ntắt đa văn bản. Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn ngọn \r\n\r\ncủa văn bản đó. Ngược lại tóm tắt đa văn bản là từ một văn bản nguồn cũng chỉ cho \r\n\r\nra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản \r\n\r\nđồng thời cho nhiều văn bản khác nhau. \r\n\r\n2.2 Tình hình nghiên cứu hiện nay \r\n\r\n2.2.1 Hướng tiếp cận cho tóm tắt đơn văn bản \r\n\r\n2.2.1.1 Phương pháp thống kê \r\n\r\nHầu hết các nghiên cứu đầu tiên cho tóm tắt đơn văn bản đều tập trung trên những \r\n\r\nvăn bản kỹ thuật (các bài báo khoa học). Các phương pháp cổ điển thường tập trung \r\n\r\nvào các đặc trưng hình thái để tính điểm cho các câu và trích rút các câu quan trọng \r\n\r\nđể đưa vào tóm tắt. \r\n\r\nÝ tưởng chính của hướng tiếp cận gồm các bước (i) thu thập dữ liệu, (ii) tạo các văn \r\n\r\nbản tóm tắt thủ công, (iii) thiết kế các công thức toán học hay logic để tính điểm cho \r\n\r\ncác câu, (iv) tính điểm cho từng câu để tạo ra bản tóm tắt cho từng văn bản trong dữ \r\n\r\nliệu dựa vào các đặc trưng về hình thái, (v) so sánh tóm tắt được tạo tự động với tóm \r\n\r\n\r\n\r\n \r\n9 \r\n\r\ntắt được tạo thủ công, và (vi) cải thiện lại phương thức tính điểm. Các bước (iv), (v) \r\n\r\nvà (vi) sẽ được lặp lại cho đến khi tóm tắt tự động đạt được tính tương đương với tóm \r\n\r\ntắt thủ công. \r\n\r\nCác nghiên cứu đại diện cho phương pháp này gồm: \r\n\r\n Luhn (1958): dùng phương pháp so khớp từng ký tự để giải quyết stemming; \r\n\r\nsử dụng các đặc trưng như word frequency, stop words, word distance. \r\n\r\n Baxendale (1958): phương pháp khá chính xác nhưng mang tính chủ quan và \r\n\r\nđơn giản, được sử dụng khá nhiều vào các hệ thống học máy sau này; sử dụng \r\n\r\ncác đặc trưng như sentence position. Thử nghiệm 200 đoạn văn, 85% các câu \r\n\r\nđầu là câu chính và 7% các câu cuối và câu chính. \r\n\r\n Edmundson (1969): điển hình nhất trong các phương pháp cổ điển; sử dụng \r\n\r\nphương pháp kết nối tuyến tính để kết hợp các điểm đặc trưng lại với nhau; sử \r\n\r\ndụng các đặc trưng như: word frequency, stop words, position, cue words, \r\n\r\ntitle; đã được thử nghiệm với 400 văn bản kỹ thuật và kết quả đạt 44%. \r\n\r\n2.2.1.2 Phương pháp thống kê trên TF.IDF \r\n\r\nPhương pháp này còn gọi là mô hình túi từ (bag-of-words), sử dụng mô hình trọng \r\n\r\nsố TF.IDF (term frequency và inverse sentence frequence). Ở mô hình này, giá trị \r\n\r\nIDF được tính trên câu. Trong đó, TF là số lần xuất hiện của term trong 1 câu. Và DF \r\n\r\nlà số câu có chứa term. \r\n\r\nCùng với phương pháp tính độ đo TF.IDF và phương pháp biểu diễn văn bản bằng \r\n\r\nvector không gian sử dụng Vector Space Model (Saton 1975). \r\n\r\nTuy nhiên, phương pháp dùng độ đo TF.IDF không được dùng độc lập, mà thường \r\n\r\nđược kết hợp với các phương pháp khác như máy học, đồ thị. để đạt được hiệu quả \r\n\r\ncao hơn. \r\n\r\n\r\n\r\n \r\n10 \r\n\r\n2.2.1.3 Phương pháp Nave-Bayes \r\n\r\nCác hướng tiếp cận theo phương pháp này giả định rằng các đặc trưng của văn bản \r\n\r\nđộc lập nhau. Sử dụng bộ phân lớp Nave-Bayes để xác định câu nào thuộc về tóm \r\n\r\ntắt và ngược lại. Tính xác suất các câu thuộc về tóm tắt, n câu có xác suất cao nhất sẽ \r\n\r\nđược trích rút. \r\n\r\nCác nghiên cứu đại điện cho phương pháp này: \r\n\r\n Kupiec (1995): các đặc trưng sử dụng gồm word frequency, location, cue \r\n\r\nword, title & leading, sentence length, uppercase words. Ngữ liệu: 188 cặp văn \r\n\r\nbản khoa học và tóm tắt. Tổng số câu:  568 câu. Số câu khớp trực tiếp với tóm \r\n\r\ntắt 451 (79%). \r\n\r\n Aone (1999): kết hợp thêm nhiều đặc trưng phong phú hơn: TF.IDF (single \r\n\r\nword, two-noun word, named-entities), discourse (cohension) (sử dụng \r\n\r\nWordNet và kỹ thuật sử lý ngôn ngữ tự nhiên để phân tích sự tham chiếu đối \r\n\r\nvới các thực thể). Ngữ liệu được sử dụng của TREC. Hệ thống được xây dựng \r\n\r\nmang tên DimSum. \r\n\r\n2.2.1.4 Phương pháp Decision Tree \r\n\r\nLin & Hovy (1999) đại diện của phương pháp này giả định rằng, các đặc trưng không \r\n\r\nđộc lập với nhau. Tác giả đã kiểm tra nhiều đặc trưng và ảnh hưởng của chúng lên \r\n\r\nquá trình rút trích. Hệ thống tóm tắt của Lin là loại tóm tắt hướng về truy vấn (query-\r\n\r\nbased). \r\n\r\nCác đặc trưng: position (OOP), numeric data, proper name, pronoun & adjective, \r\n\r\nweekday hoặc month. Cùng với 2 đăc trưng mới: query signature (số từ truy vấn có \r\n\r\ntrong câu) và IR signature (những từ nổi bật, quan trọng ~ tf*idf). \r\n\r\nHệ thống Summarist của Lin và Hovy sử dụng thuật toán C4.5 để huấn luyện cây \r\n\r\nquyết định. Hệ thống sử dụng tập ngữ liệu của TIPSTER-SUMMAC. \r\n\r\n\r\n\r\n \r\n11 \r\n\r\n2.2.1.5 Phương pháp Hidden Makov Model \r\n\r\nNhững hướng tiếp cận trước đều dựa trên những đặc trưng và không tuần tự. Conroy \r\n\r\nvà Oleary (2001) đã đưa ra hướng tiếp cận dựa trên mô hình HMM với ý tưởng cơ \r\n\r\nbản là sử dụng một chuỗi tuần tự các câu. Tác giả đưa ra khái niệm về sự phụ thuộc \r\n\r\ncục bộ (local dependencies) giữa các câu và sử dụng mô hình HMM để xác định sự \r\n\r\nphụ thuộc này. \r\n\r\nCác đặc trưng sử dụng: position, number of term, likelihood of sentence. \r\n\r\nMô hình HMM bao gồm 2s + 1 trạng thái, trong đó s là số trạng thái tóm tắt (câu \r\n\r\nthuộc tóm tắt) và s+1 là câu không thuộc tóm tắt. \r\n\r\nMô hình HMM xây dựng ma trận chuyển vị M, coi các đặc trưng là đa biến và tính \r\n\r\nxác suất của các câu qua từng trạng thái. \r\n\r\nSử dụng tập ngữ liệu của TREC và được đánh giá với 2 hệ thống khác là DimSum và \r\n\r\nQR, kết quả đều cho độ đo Precision cao hơn. \r\n\r\n2.2.1.6 Phương pháp Log-Linear \r\n\r\nOsborne (2002) đại diện cho mô hình này cũng coi các đặc trưng là không độc lập \r\n\r\nvới nhau và sử dụng mô hình Log-Linear khắc phục giả định này. \r\n\r\nCác đặc trưng sử dụng: word pair, sentence length, sentence position và discourse \r\n\r\nfeatures (nằm trong introduction, hay conclusion). \r\n\r\n2.2.1.7 Phương pháp mạng neural \r\n\r\nDUC 2002 đã đưa ra một baseline rất mạnh cho tóm tắt đơn văn bản bằng phương \r\n\r\npháp rút trích n câu đầu tiên của các báo tin tức và dường như kết thúc hướng nghiên \r\n\r\ncứu này. \r\n\r\nNhưng Svore (2007) đã đưa ra một hướng tiếp cận mới sử dụng mạng neural để huấn \r\n\r\nluyện, kết quả cho thấy đã vượt qua baseline của DUC 2002. \r\n\r\n\r\n\r\n \r\n12 \r\n\r\nCác đặc trưng sử dụng: position, n-grams frequency. Ngoài ra, còn sử dụng thêm nhật \r\n\r\nký truy vấn của bộ máy tìm kiếm Microsoft và WordNet. Tác giả cho rằng, những \r\n\r\ncâu có chứa từ khoá trong các các câu truy vấn thì sẽ có kết quả tốt hơn, và tìm từ \r\n\r\nkhoá đó trên WordNet. \r\n\r\nMô hình được huấn luyện từ các đặc trưng và các nhãn trong các bài báo. Sau đó \r\n\r\nđược xếp hạng bằng hệ thống RankNet. Ngữ liệu được lấy từ CNN.com và được đánh \r\n\r\ngiá bằng độ đo ROUGE-1 và ROUGE-2 (hai độ đo phổ biến hiện tại cho tóm tắt văn \r\n\r\nbản). \r\n\r\n2.2.1.8 Phương pháp phân tích ngôn ngữ tự nhiên \r\n\r\nPhương pháp tiếp theo sử dụng các kỹ thuật phân tích ngôn ngữ tự nhiên phức tạp. \r\n\r\nKhông phải tất cả các phương pháp phân tích ngôn ngữ tự nhiên đều sử dụng máy \r\n\r\nhọc, đôi khi phương pháp chỉ sử dụng một số các heuristic để tạo trích rút. \r\n\r\nHầu hết các phương pháp này đều dựa trên cấu trúc diễn ngôn (discourse tructure) \r\n\r\nhay cấu trúc diễn đạt (thể hiện) của văn bản, như: cấu trúc các section của văn bản, \r\n\r\nliên kết ngữ pháp (trùng lặp, tĩnh lược, liên hợp), liên kết từ vựng (đồng nghĩa, bao \r\n\r\nhàm, lặp lại), cấu trúc chính phụ. \r\n\r\nCác nghiên cứu đại điện cho phương pháp này: \r\n\r\n Ono (1994) xây dựng một thủ tục để rút trích các cấu trúc chính phụ (rhetorical \r\n\r\nstructure) từ các văn bản tiếng Nhật, và xây dựng một cây nhị phân để thể \r\n\r\nhiện. Các bước để trích rút cấu trúc: phân tích câu, trích rút một quan hệ chính \r\n\r\nphụ, phân đoạn, tạo ứng viên và đánh giá độ ưu tiên. Sau khi xây dựng cây sẽ \r\n\r\nthực hiện tỉa nhánh để giảm bớt câu và tạo tóm tắt. Kết quả đạt được 51% các \r\n\r\ncâu chính được xác định, và 74% các câu quan trọng nhất được xác định. \r\n\r\n Barzilay và Elhadad (1997): hai tác giả cũng đã sử dụng một lượng đáng kể \r\n\r\nnhững phân tích ngôn ngữ trong tóm tắt văn bản dựa trên chuỗi từ vựng \r\n\r\n(lexical chain). Chuỗi từ vựng là chuỗi các từ liên quan trong văn bản. Các \r\n\r\nbước thực hiện: phân đoạn văn bản, xác định các chuỗi từ vựng và sử dụng \r\n\r\n\r\n\r\n \r\n13 \r\n\r\ncác chuỗi từ vựng tốt nhất để xác định câu được chèn vào tóm tắt. Để tìm các \r\n\r\nchuỗi từ vựng, tác giả sử dụng WordNet. Các từ có liên quan với nhau sẽ được \r\n\r\nđưa vào chuỗi. Sự liên quan được tính bằng khoảng cách trong WordNet. \r\n\r\nChuỗi sẽ được tính điểm dựa vào chiều dài và sự đồng nhất của nó. Kết quả \r\n\r\nđạt được tốt hơn hệ thống tóm tắt của Microsoft. Với độ precious là 61 và độ \r\n\r\nrecall 67 (Microsoft là 33 và 27). Hạn chế: không thể kiểm được chiều dài và \r\n\r\nmức độ chi tiết của tóm tắt do số chuỗi còn ít. Tóm tắt thiếu sự kết dính và \r\n\r\nchưa chi tiết do chọn cả câu. \r\n\r\n Marcu (1998): sử dụng các heuristic dựa trên cấu trúc diễn đạt với các đặc \r\n\r\ntrưng truyền thống. Lý thuyết về cấu trúc diễn đạt được tác giả thể hiện thông \r\n\r\nqua lý thuyết cấu trúc chính phụ (Rhetorical Structure Theory). Lý thuyết cho \r\n\r\nrằng hai khoảng văn bản không trùng lặp có quan hệ trung tâm (nucleus) và \r\n\r\nvệ tinh (satellite). Trong đó trung tâm quan trọng hơn vệ tinh và độc lập hoàn \r\n\r\ntoàn trong cấu trúc chính phụ. Cấu trúc trọng tâm và vệ tinh được biểu diễn \r\n\r\nthành cây nhị phân. Để tính điểm cho các cấu trúc, tác giả sử dụng nhiều độ \r\n\r\nđo khác nhau như: clustering based metric, marker based metric, rhetorical \r\n\r\nclustering based technique, shape based metric, title based metric, position \r\n\r\nbased metric, connectedness based metric và sử dụng phương pháp kết hợp \r\n\r\ntuyến tính. Lấy ra n câu chứa cấu trúc có điểm cao nhất. Hệ thống đat được \r\n\r\nkết quả độ đo F 75.42% cao hơn 3.5% so với baseline bằng phương pháp lấy \r\n\r\nn câu đầu. Ngữ liệu được sử dụng là từ TREC. \r\n\r\n2.2.2 Hướng tiếp cận cho tóm tắt đa văn bản \r\n\r\nCác vấn đề phát sinh trong tóm tắt đa văn bản là tính trùng lặp và bổ sung thông tin \r\n\r\ntrong các nguồn văn bản. Do đó, nhiệm vụ trong tóm tắt đa văn bản không chỉ bao \r\n\r\ngồm việc sao chép dữ liệu từ những văn bản gốc sang bản tóm tắt mà còn đảm bảo \r\n\r\ntính mới, không dư thừa của thông tin, cũng như đảm bảo tóm tắt có tính kết dính và \r\n\r\nhoàn chỉnh. \r\n\r\n\r\n\r\n \r\n14 \r\n\r\n2.2.2.1 Phương pháp dùng template \r\n\r\nMcKeown và Radev (1995, 1998) đã xây dựng hệ thống SUMMONS dựa trên hướng \r\n\r\ntiếp cận dùng template cho tóm tắt đa văn bản. \r\n\r\nHệ thống đọc trong CSDL các tập mẫu được xây dựng sẵn bởi một hệ thống khác. \r\n\r\nTrước tiên, hệ thống sẽ điền vào các chỗ trống trong template các thông tin từ các \r\n\r\nvăn bản nguồn. Sau dó, hệ thống tổng hợp thành một bản tóm tắt và cho ra kết quả. \r\n\r\nHệ thống SUMMONS bao gồm 2 thành phần chính: content planner (lập nội dung) \r\n\r\nvà linguistic generator (tạo ngôn ngữ). Tuy nhiên, hệ thống chỉ có thể phục vụ cho \r\n\r\nmột miền dữ liệu nhỏ. \r\n\r\n2.2.2.2 Phương pháp gom cụm chủ đề và hợp nhất thông tin \r\n\r\nMcKeown (1999) đã cải tiến hệ thống SUMMONS cũng như Barzilay (1999) bằng \r\n\r\nmột hướng tiếp cận dựa trên gom cụm và hợp nhất thông tin. \r\n\r\nHướng tiếp cận mới bao gồm 2 giai đoạn: \r\n\r\n Gom cụm các đơn vị văn bản (clustering): các đơn vị văn bản được biểu diễn \r\n\r\nbằng vector với các đặc trưng như TF-IDF, noun-phrase, proper noun, synset \r\n\r\n(tập đồng nghĩa từ Wordnet). Từng cặp đơn vị văn bản sẽ được tính độ tương \r\n\r\nđồng với nhau để phân loại cho các các cụm theo từng chủ đề (themes). \r\n\r\n Hợp nhất thông tin: sau khi phân cụm, các cụm sẽ được so sánh với nhau bằng \r\n\r\nmột giải thuật để tìm sự trùng lặp thông tin. Sau cùng hệ thống trích rút câu \r\n\r\nnổi bật trong từng cụm để làm tóm tắt, nếu trùng lặp thì câu xuất hiện ở văn \r\n\r\nbản mới hơn sẽ được trích rút. Giải thuật để tìm sự trùng lặp là sử dụng bộ \r\n\r\nphân tích thống kê của Collin (1999) xây dựng cây phụ thuộc (dependency \r\n\r\ntree). \r\n\r\n\r\n\r\n \r\n15 \r\n\r\n2.2.2.3 Phương pháp gom cụm (cluster-based) với MMR \r\n\r\nCác văn bản thường được viết để giải quyết nhiều chủ đề khác nhau, mỗi chủ đề sẽ \r\n\r\nđược viết sau chủ đề khác theo một cách có tổ chức. Mỗi chủ đề cũng có thể được \r\n\r\nviết vào những phần riêng biệt hoặc không. Các chủ đề này cũng cần được viết vào \r\n\r\ntóm tắt theo thứ tự như trong văn bản. Vấn đề đặt ra là làm thế nào xác định được các \r\n\r\ncụm chủ đề của văn bản. \r\n\r\nPhương pháp gom cụm là nhằm phân loại các câu vào các cụm theo từng chủ đề mà \r\n\r\nchúng nói đến. Có nhiều phương pháp gom cụm khác nhau. Một trong số đó là \r\n\r\nphương pháp MMR (Maximal Marginal Relevance) của Carbonell và Jade Goldstein \r\n\r\n(1998). \r\n\r\nMô hình MMR đã được áp dụng cho Text Summarization bởi Ganapathiraju (2002). \r\n\r\nHệ thống tóm tắt với MMR bao gồm các chức năng (i) phân đoạn văn bản thành các \r\n\r\ncâu, (ii) phân cụm các câu, và (iii) tính điểm MMR cho các câu để chọn câu thích \r\n\r\nhợp được đưa vào tóm tắt. Tập dữ liệu huấn luyện được lấy từ DUC 2002. \r\n\r\n2.2.2.4 Phương pháp gom cụm với lý thuyết đồ thị \r\n\r\nVấn đề chủ yếu của tóm tắt đa văn bản là gom cụm các câu để tránh sự dư thừa trong \r\n\r\ntóm tắt. Một hướng tiếp cận mới là ứng dụng lý thuyết đồ thị. Sau khi đã tiền xử lý \r\n\r\nvăn bản như: loại bỏ stopword, xử lý dẫn suất (stemming), các câu được thể hiện \r\n\r\nthành các node trong một đồ thị vô hướng. Mỗi câu một node. Hai câu có những từ \r\n\r\nchung sẽ được nối một cạnh. Hoặc sử dụng độ đo cosin, tính độ tương đồng giữa 2 \r\n\r\ncâu, nếu lớn hơn một ngưỡng Q thì sẽ có một cạnh nối giữa 2 node. \r\n\r\nSau khi biểu diễn thành đồ thị, đồ thị sẽ được phân hoạch thành các đồ thị con dựa \r\n\r\nvào các cạnh nối. Nếu tóm tắt cần tạo là tóm tắt dựa vào truy vấn, thì đồ thị nào gần \r\n\r\nvới truy vấn nhất sẽ được dùng để tạo tóm tắt. Nếu tóm tắt là chung, thì tất cả các đồ \r\n\r\nthị con đều tham gia vào tóm tắt. \r\n\r\n\r\n\r\n \r\n16 \r\n\r\nĐể tạo tóm tắt, mỗi đồ thị con sẽ đưa ra các node (câu) ứng viên cao nhất (các node \r\n\r\ncó nhiều cạnh nối nhất) để include vào truy vấn. \r\n\r\n2.2.2.5 Phương pháp kích hoạt lan truyền trên đồ thị \r\n\r\nMani và Bloedorn (1997) đã đề xuất một framework cho tóm tắt văn bản dựa trên đồ \r\n\r\nthị để tìm sự tương đồng hoặc không tương đồng giữa các cặp văn bản. Phương pháp \r\n\r\nnày không tạo ra văn bản tóm tắt nhưng highlight thông tin trên văn bản gốc. \r\n\r\nVăn bản được thể hiện thành đồ thị như sau: mỗi node biểu diễn sự xuất hiện của một \r\n\r\ntừ đơn trong văn bản, mỗi node có nhiều loại liên kết với các node khác như: SAME, \r\n\r\nALPHA, PHRASE, NAME, COREF. \r\n\r\nSau khi tạo đồ thị, các node chủ đề sẽ được xác định bằng phương pháp phân tích dẫn \r\n\r\nxuất (stemming) và trở thành entry node. Các node sẽ được đánh trọng số bằng \r\n\r\nphương pháp TF*IDF.  Một sự tìm kiếm văn bản liên quan ngữ nghĩa giữa các node \r\n\r\nsẽ được lan truyền. Trọng số của các node sẽ được thay đổi trong quá trình lan truyền. \r\n\r\nCác cặp đồ thị (các văn bản) sẽ được so sánh với nhau để tìm những node chung dựa \r\n\r\nvào dẫn xuất cũng như đồng ngữ nghĩa. Điểm của các node chung cũng sẽ được tính \r\n\r\nlại. Quá trình lan truyền lại tiếp tục cho đến khi không còn cập nhật trọng số điểm \r\n\r\ncho các node. \r\n\r\nSau cùng những câu chứa các node có điểm chung và riêng cao sẽ được đánh dấu. \r\n\r\n2.2.2.6 Phương pháp dựa trên trọng tâm \r\n\r\nRadev (2004) đã đề xuất phương pháp sử dụng các trọng tâm của cụm đề làm trung \r\n\r\ntâm cho tóm tắt. Hướng tiếp cận này đã được phát triển trong hệ thống MEAD. \r\n\r\nCác văn bản trong hướng tiếp cận này sử dụng mô hình túi từ. Bao gồm 2 giai đoạn: \r\n\r\n Giai đoạn xác định chủ đề: Các văn bản được biểu diễn dưới vector và một \r\n\r\nthuật toán gom cụm tích tụ (an agglomerative clustering) được sử dụng để thực \r\n\r\n\r\n\r\n \r\n17 \r\n\r\nhiện nhiệm vụ này. Văn bản liên quan nhất với trọng tâm cluster sẽ được thêm \r\n\r\nvào, và cluster sẽ được tính lại trọng tâm. \r\n\r\n Giai đoạn chọn câu: Trong mỗi cluster, chọn các câu là trung tâm của chủ đề \r\n\r\ntrong cụm. Hai độ đo tương tự MMR là cluster-based relative utility (CBRU) \r\n\r\nand cross-sentence informational subsumption (CSIS) được sử dụng để độ liên \r\n\r\nquan của câu với chủ đề của cụm và độ dư thừa giữa các câu. Tuy nhiên, hai \r\n\r\nđộ đo này không phụ thuộc truy vấn như MMR. Để tính độ tương đồng, mỗi \r\n\r\ncâu được biểu diễn bởi các đặc trưng: centroid value, positional value, first-\r\n\r\nsentence overlap. \r\n\r\n2.3 Phân tích yêu cầu phần mềm \r\n\r\n2.3.1 Biểu đồ use case tổng quan \r\n\r\n \r\n\r\n\r\n \r\n\r\n\r\n\r\n \r\n18 \r\n\r\nPhần mềm có một tác nhân chính là Người dùng, người có thể tương tác với phần \r\n\r\nmềm. Ban đầu, người dùng có thể chọn toàn bộ văn bản xuất hiện trên màn hình hoặc \r\n\r\nchỉ chọn một phần văn bản mà mình muốn. Phần văn bản đã chọn sẽ được đọc bằng \r\n\r\ntext-to-speech. \r\n\r\nTrong trường hợp chọn một phần văn bản, người dùng có thể tuỳ chọn tóm tắt phần \r\n\r\nvăn bản mà mình đã chọn. Kết quả tóm tắt sẽ được xử lý trên server và hiển thị trên \r\n\r\nmàn hình. \r\n\r\n2.3.2 Đặc tả chức năng \r\n\r\n2.3.2.1 Đặc tả use case TTS toàn bộ văn bản \r\n\r\n\r\nMã use case UC001 Tên use case TTS toàn bộ văn bản \r\n\r\nTác nhân Người dùng \r\n\r\nTiền điều kiện Người dùng đã mở giao diện tương tác  \r\n\r\nLuồng sự kiện \r\n\r\nchính (Thành \r\n\r\ncông) \r\n\r\nSTT Tác nhân Hành động \r\n\r\n1 Người dùng Chọn chức năng TTS toàn bộ văn bản \r\n\r\n2 Hệ thống Lấy dữ liệu toàn bộ văn bản đang hiển thị \r\n\r\ntrên màn hình, thực hiện TTS \r\n\r\n \r\n\r\nLuồng sự kiện \r\n\r\nthay thế \r\n\r\nSTT Tác nhân Hành động \r\n\r\n2a Hệ thống Hệ thống thông báo không có văn bản \r\n\r\n \r\n\r\nHậu điều kiện Không \r\n\r\n\r\n\r\n \r\n19 \r\n\r\n \r\n\r\n2.3.2.2 Đặc tả use case TTS văn bản được chọn \r\n\r\n\r\nMã use case UC002 Tên use case TTS văn bản được chọn \r\n\r\nTác nhân Người dùng \r\n\r\nTiền điều kiện Người dùng đã mở giao diện tương tác  \r\n\r\nLuồng sự kiện \r\n\r\nchính (Thành \r\n\r\ncông) \r\n\r\nSTT Tác nhân Hành động \r\n\r\n1 Người dùng Chọn chức năng TTS văn bản được chọn \r\n\r\n2 Người dùng Vẽ trên màn hình để chọn văn bản \r\n\r\n3 Hệ thống Lấy dữ liệu văn bản trong vùng được chọn \r\n\r\ntrên màn hình, thực hiện TTS \r\n\r\n \r\n\r\nLuồng sự kiện \r\n\r\nthay thế \r\n\r\nSTT Tác nhân Hành động \r\n\r\n3a Hệ thống Hệ thống thông báo không có văn bản nào \r\n\r\nđược chọn \r\n\r\n \r\n\r\nHậu điều kiện Không \r\n\r\n \r\n\r\n\r\n\r\n \r\n20 \r\n\r\n2.3.2.3 Đặc tả use case Tóm tắt văn bản \r\n\r\n\r\nMã use case UC003 Tên use case Tóm tắt văn bản \r\n\r\nTác nhân Người dùng \r\n\r\nTiền điều kiện Người dùng đã chọn một vùng văn bản \r\n\r\nLuồng sự kiện \r\n\r\nchính (Thành \r\n\r\ncông) \r\n\r\nSTT Tác nhân Hành động \r\n\r\n1 Người dùng Chọn chức năng Tóm tắt văn bản \r\n\r\n2 Hệ thống Thực hiện tóm tắt văn bản và trả về kết quả \r\n\r\nhiển thị trên màn hình \r\n\r\n3 Người dùng Xác nhận kết quả trả về \r\n\r\n \r\n\r\nLuồng sự kiện \r\n\r\nthay thế \r\n\r\nSTT Tác nhân Hành động \r\n\r\n2a Hệ thống Hệ thống thông báo không có văn bản được \r\n\r\nchọn \r\n\r\n2b Hệ thống Hệ thống thông báo không có kết nối \r\n\r\nInternet \r\n\r\n \r\n\r\nHậu điều kiện Không \r\n\r\n \r\n\r\n\r\n\r\n \r\n21 \r\n\r\n\r\nSTT Trường \r\n\r\ndữ liệu \r\n\r\nMô tả Bắt buộc Điều kiện \r\n\r\nhợp lệ \r\n\r\nVí dụ \r\n\r\n1 Văn bản Nội dung văn bản cần \r\n\r\ntóm tắt \r\n\r\nCó Dạng text Hello \r\n\r\nWorld \r\n\r\n \r\n\r\n\r\nSTT Trường \r\n\r\ndữ liệu \r\n\r\nMô tả Bắt buộc Điều kiện \r\n\r\nhợp lệ \r\n\r\nVí dụ \r\n\r\n1 Văn bản Nội dung văn bản đã \r\n\r\nđược tóm tắt \r\n\r\nCó Dạng text Hello \r\n\r\nWorld \r\n\r\n \r\n\r\n2.3.3 Yêu cầu phi chức năng \r\n\r\nVề hiệu năng, hệ thống phải đảm bảo hoạt động liên tục 24/24, giúp người dùng có \r\n\r\nthể tương tác bất cứ lúc nào. Hệ thống cũng phải đảm bảo tính dễ dùng, giúp người \r\n\r\ndùng nhận biết được hệ thống đã lấy được dữ liệu hay chưa, thao tác thành công hay \r\n\r\nkhông. \r\n\r\n \r\n\r\n \r\n\r\nNhư vậy, Chương 2 cho chúng ta cái nhìn tổng quan về các phương pháp tóm tắt văn \r\n\r\nbản cũng như ưu, nhược điểm của chúng. Có thể nhận thấy rằng, tóm tắt văn bản \r\n\r\nbằng Deep Learning đang là phương pháp tiên tiến nhất hiện nay. Để tìm hiểu về \r\n\r\n\r\n\r\n \r\n22 \r\n\r\nphương pháp này, Chương 3 sẽ trình bày về các lý thuyết nền tảng mà chúng ta cần \r\n\r\nnắm rõ. \r\n\r\nNgoài ra, chúng ta cũng đã làm rõ những yêu cầu tổng quan cũng như đặc tả các use \r\n\r\ncase của phần mềm. Đây là tiền đề để sinh viên xây dựng ứng dụng di động Android. \r\n\r\n\r\n\r\n \r\n23 \r\n\r\nTrải qua nhiều tiến bộ của khoa học máy tính, Deep Learning đang nổi lên như là một \r\n\r\ncông nghệ tiên tiến giúp con người giải quyết nhiều bài toán phức tạp với độ chính \r\n\r\nxác cao. Theo như những gì đã trình bày ở Chương 2, Deep Learning cũng đã được \r\n\r\nứng dụng trong bài toán tóm tắt văn bản và đạt được những kết quả khả quan. Chương \r\n\r\nnày sẽ đi sâu vào trình bày các khái niệm liên quan đến công nghệ tóm tắt văn bản \r\n\r\nbằng Deep Learning. \r\n\r\n3.1 Công nghệ Deep Learning \r\n\r\n3.1.1 Machine Learning \r\n\r\n \r\n\r\n\r\nChương 3 Cơ sở lý thuyết  \r\n\r\n\r\n\r\n \r\n24 \r\n\r\nNhững năm gần đây, AI - Artificial Intelligence (Trí Tuệ Nhân Tạo), và cụ thể hơn \r\n\r\nlà Machine Learning (Học Máy) nổi lên như một bằng chứng của cuộc cách mạng \r\n\r\ncông nghiệp lần thứ tư. Trí Tuệ Nhân Tạo đang len lỏi vào mọi lĩnh vực trong đời \r\n\r\nsống mà có thể chúng ta không nhận ra. Xe tự hành của Google và Tesla, hệ thống tự \r\n\r\ntag khuôn mặt trong ảnh của Facebook, trợ lý ảo Siri của Apple, hệ thống gợi ý sản \r\n\r\nphẩm của Amazon, hệ thống gợi ý phim của Netflix, máy chơi cờ vây AlphaGo của \r\n\r\nGoogle DeepMind. chỉ là một vài trong vô vàn những ứng dụng của AI/Machine \r\n\r\nLearning. \r\n\r\nMachine Learning là một tập con của AI. Nói đơn giản, Machine Learning là một \r\n\r\nlĩnh vực nhỏ của Khoa Học Máy Tính, nó có khả năng tự học hỏi dựa trên dữ liệu \r\n\r\nđưa vào mà không cần phải được lập trình cụ thể. \r\n\r\nNhững năm gần đây, khi mà khả năng tính toán của các máy tính được nâng lên một \r\n\r\ntầm cao mới và lượng dữ liệu khổng lồ được thu thập bởi các hãng công nghệ lớn, \r\n\r\nMachine Learning đã tiến thêm một bước dài và một lĩnh vực mới được ra đời gọi là \r\n\r\nDeep Learning. Deep Learning đã giúp máy tính thực thi những việc tưởng chừng \r\n\r\nnhư không thể vào 10 năm trước: phân loại cả ngàn vật thể khác nhau trong các bức \r\n\r\nảnh, tự tạo chú thích cho ảnh, bắt chước giọng nói và chữ viết của con người, giao \r\n\r\ntiếp với con người, hay thậm chí cả sáng tác văn hay âm nhạc. \r\n\r\nNgược dòng lịch sử, Machine Learning đã xuất hiện từ rất lâu trước khi mạng Internet \r\n\r\nra đời. Một trong những thuật toán Machine Learning đầu tiên là thuật toán \r\n\r\nPerceptron được phát minh ra bởi Frank Rosenblatt vào năm 1957. Đây là một thuật \r\n\r\ntoán kinh điển dùng để phân loại hai khái niệm. Một ví dụ đơn giản là phân loại thư \r\n\r\nrác và thư bình thường. Perceptron là một thuật toán supervised learning: ta đưa cho \r\n\r\nmáy tính hàng loạt các ví dụ cùng câu trả lời mẫu với hy vọng máy tính sẽ tìm được \r\n\r\nnhững đặc điểm cần thiết để đưa ra dự đoán cho những ví dụ khác chưa có câu trả lời \r\n\r\ntrong tương lai. Ngoài ra, cũng có những thuật toán Machine Learning không cần câu \r\n\r\ntrả lời mẫu, được gọi là unsupervised learning. Trong trường hợp này, máy tính cố \r\n\r\ngắng khai thác ra cấu trúc ẩn của một tập dữ liệu mà không cần câu trả lời mẫu. Một \r\n\r\nloại Machine Learning khác được gọi là reinforcement learning. Trong dạng này, \r\n\r\n\r\n\r\n \r\n25 \r\n\r\ncũng không hề có câu trả lời mẫu, nhưng thay vì đó máy tính nhận được phản hồi cho \r\n\r\nmỗi hành động. Dựa vào phản hồi tích cực hay tiêu cực mà máy tính sẽ điều chỉnh \r\n\r\nhoạt động cho phù hợp. \r\n\r\n3.1.2 Deep Learning \r\n\r\nNếu coi ta Machine Learning là công nghệ tiên tiến nhất, thì Deep Learning là \"tiên \r\n\r\ntiến của tiên tiến\". Machine Learning lấy một vài ý tưởng cốt lõi của trí tuệ nhân tạo \r\n\r\nvà tập trung vào việc giải quyết các vấn đề thế giới thực với các mạng thần kinh được \r\n\r\nthiết kế để bắt chước khả năng đưa ra quyết định của chúng ta. Deep Learning, đúng \r\n\r\nnhư tên gọi của nó, đi sâu hơn nữa vào một tập hợp các công cụ và kỹ thuật học máy, \r\n\r\ntừ đó áp dụng chúng để giải quyết bất kỳ vấn đề nào đòi hỏi \"khả năng tư duy\"  con \r\n\r\nngười hay nhân tạo. \r\n\r\nVề cơ bản, Deep Learning là cho một hệ thống máy tính \"ăn\" rất nhiều dữ liệu, để \r\n\r\nchúng có thể sử dụng và đưa ra các quyết định về những dữ liệu khác. Dữ liệu này \r\n\r\nđược nạp thông qua các mạng thần kinh, tương tự như học máy. Những mạng lưới \r\n\r\nnày  các cấu trúc logic yêu cầu một loạt các câu hỏi đúng/sai, hoặc trích xuất một \r\n\r\ngiá trị số, của mỗi bit dữ liệu đi qua chúng và phân loại theo các câu trả lời nhận được. \r\n\r\nVì công việc của Deep Learning là tập trung phát triển những mạng lưới này, chúng \r\n\r\nđã trở thành \"mạng thần kinh sâu\" (Deep Neural Network)  những mạng logic phức \r\n\r\ntạp cần thiết để xử lý các bộ dữ liệu lớn, như thư viện hình ảnh của Google hay \r\n\r\nInstagram. \r\n\r\nVới các bộ dữ liệu toàn diện như vậy, và các mạng logic phức tạp để xử lý phân loại \r\n\r\nchúng, việc một chiếc máy tính lấy một hình ảnh và nhận dạng với độ chính xác cao \r\n\r\ntrở nên \"quá đỗi bình thường\". \r\n\r\nCác hình ảnh là ví dụ tuyệt vời nhất về cách thức hoạt động của Deep Learning, vì \r\n\r\nchúng có chứa nhiều yếu tố khác nhau và để hiểu rõ được làm thế nào để máy tính, \r\n\r\nvới não bộ một chiều chủ yếu dựa trên sự tính toán, có thể học cách giải thích chúng \r\n\r\ngiống như con người. Tuy vậy, Deep Learning có thể được áp dụng cho bất kỳ hình \r\n\r\n\r\n\r\n \r\n26 \r\n\r\nthức dữ liệu nào  âm thanh, video, lời nói, chữ viết...  để đưa ra những kết luận như \r\n\r\nthể do con người thực hiện với tốc độ rất nhanh. Chúng ta hãy thử xem xét một số ví \r\n\r\ndụ thực tiễn. \r\n\r\nGiả sử một hệ thống được thiết kế để tự động ghi nhận và báo cáo có bao nhiêu chiếc \r\n\r\nxe của một mẫu xe nhất định đã đi ngang qua một con đường. Trước tiên, nó sẽ được \r\n\r\nquyền truy cập vào một cơ sở dữ liệu khổng lồ về các loại xe, bao gồm hình dáng, \r\n\r\nkích thước và thậm chí là tiếng của động cơ. Điều này có thể được biên soạn theo \r\n\r\ncách thủ công hoặc, trong các điều kiện tiên tiến hơn, được thu thập tự động bởi hệ \r\n\r\nthống nếu như nó được lập trình để tìm kiếm trên internet và lấy dữ liệu mà nó tìm \r\n\r\nthấy ở đó. Tiếp theo, nó sẽ lấy dữ liệu cần được xử lý  dữ liệu trong thế giới thực có \r\n\r\nchứa thông tin chi tiết cần nắm bắt, trong trường hợp này là bởi các camera và \r\n\r\nmicrophone bên đường. Bằng cách so sánh dữ liệu từ cảm biến với những dữ liệu mà \r\n\r\nnó đã \"học được\", nó có thể phân loại, với một độ chính xác nhất định, từng loại xe \r\n\r\nđã đi qua con đường đó. \r\n\r\nTrên đây là một ví dụ cụ thể, ngoài ra Deep Learning còn có thể ứng dụng ở trong rất \r\n\r\nnhiều các lĩnh vực khác như:  \r\n\r\n Cung cấp khả năng điều hướng cho xe tự lái: Với hệ thống cảm biến và phần \r\n\r\nmềm phân tích trên buồng lái, các xe tự lái có thể học cách nhận dạng những \r\n\r\nchướng ngại vật có trên đường và có giải pháp xử lý thích hợp bằng cách sử \r\n\r\ndụng Deep Learning. \r\n\r\n Phục chế màu cho ảnh đen trắng: thông qua việc dạy cho máy tính cách nhận \r\n\r\nbiết các vật thể và cách mà mắt người nhìn chúng, các hình ảnh và video đen \r\n\r\ntrắng sẽ có thể được tái hiện lại với đầy đủ các màu sắc phù hợp. \r\n\r\n Dự đoán kết quả của các thủ tục pháp lý: Một nhóm các nhà nghiên cứu người \r\n\r\nAnh và Mỹ đã có thể dự đoán chính xác kết quả của một phiên tòa, sau khi hệ \r\n\r\nthống máy tính của họ được nạp sẵn những thông tin cơ bản của vụ án. \r\n\r\n Thuốc đặc trị: Các kỹ thuật Deep Learning hiện đang được dùng để phát triển \r\n\r\ncác loại thuốc đã được chỉnh sửa sao cho phù hợp với bộ gen của bệnh nhân. \r\n\r\n\r\n\r\n \r\n27 \r\n\r\n Phân tích và báo cáo tự động: Các hệ thống có thể phân tích dữ liệu và báo \r\n\r\ncáo những thông tin chi tiết của chúng dưới dạng âm thanh tự nhiên hoặc ngôn \r\n\r\nngữ của con người. \r\n\r\n Chơi trò chơi: Các hệ thống Deep Learning đã và đang được dạy cách chơi (và \r\n\r\ngiành chiến thắng) các trò chơi như cờ vây, Breakout của Atari hay Starcraft. \r\n\r\n3.2 Neural Network \r\n\r\n3.2.1 Mạng neural nhân tạo \r\n\r\nMạng neural nhân tạo (Artificial Neurol Network - ANN) là mạng các neural kết nối \r\n\r\nvới nhau. Mỗi neural là một mô hình tính toán và NN là một hệ thống tính toán. Đầu \r\n\r\nra của mỗi neural lại là đầu vào của một neural khác. Kiến trúc của mạng được quyết \r\n\r\nđịnh bởi sự kết nối của các neural trong mạng.  \r\n\r\nMột trong những yếu tố chính của mạng neural là khả năng học hỏi. Mạng neural \r\n\r\nkhông chỉ là một hệ thống phức tạp, mà còn là một hệ thống thích nghi phức tạp, có \r\n\r\nnghĩa là nó có thể thay đổi cấu trúc nội bộ của nó trong quá trình huấn luyện. Thông \r\n\r\nthường, việc huấn luyện là việc thay đổi các trọng số. \r\n\r\nHai kiến trúc mạng phổ biến: \r\n\r\n Mạng truyền thẳng (feed-forward network) \r\n\r\n \r\n\r\n\r\n\r\n\r\n \r\n28 \r\n\r\n Mạng phản hồi (feed-back network hay recurrent neural network) \r\n\r\n \r\n\r\n\r\nThuật toán được sử dụng phổ biến để huấn luyện mạng neural là thuật toán lan truyền \r\n\r\nngược (backpropagation algorithm). Thuật toán này sẽ sử dụng tập giá trị đầu ra và \r\n\r\ntập giá trị mong muốn để tìm ra các trọng số của mạng làm cực tiểu hàm lỗi. Sai số \r\n\r\ncủa mạng trên một bộ dữ liệu huấn luyện được tính tổng bình phương của độ sai lệch \r\n\r\ngiữa các đầu ra của mạng và các giá trị mong muốn. Hàm lỗi tổng bình phương trên \r\n\r\ntoàn tập dữ liệu sẽ được tính bằng tổng hàm lỗi trên mỗi bộ dữ liệu của tập dữ liệu. \r\n\r\nTa cần tìm trọng số của mạng sao cho hàm tổng bình phương lỗi đạt giá trị nhỏ nhất. \r\n\r\nBackpropagation được xây dựng dựa trên thuật toán lặp là kĩ thuật gradient descent. \r\n\r\nTheo kĩ thuật này, vector trọng số của lần lặp này sẽ được điều chỉnh dựa vào vector \r\n\r\ntrọng số ở lần lặp trước, tỷ lệ học (learning rate) và vector gradient (vector các đạo \r\n\r\nhàm riêng) của hàm lỗi tại đó. Theo đó, đạo hàm riêng của một tầng được tính dựa \r\n\r\nvào tầng trước đó theo hướng đầu ra ngược về đầu vào. Đạo hàm riêng của hàm lỗi \r\n\r\ntrên toàn tập dữ liệu bằng tổng đạo hàm riêng của hàm lỗi trên từng bộ dữ liệu của \r\n\r\ntoàn tập dữ liệu. Đạo hàm riêng của hàm lỗi theo trọng số của đường truyền từ neural \r\n\r\ni tới neural j bằng tích của của sai số tại neural j với đầu ra tại i, trong đó sai số ở \r\n\r\nneural j là đạo hàm riêng của của hàm lỗi theo tổng trọng số của neural j. Sai số ở \r\n\r\nneural j lại được tính dựa trên sự sai khác của đầu ra tại neural này và giá trị đầu ra \r\n\r\nmong muốn. Tóm lại, thuật toán lan truyền ngược gồm giai đoạn: giai đoạn đầu các \r\n\r\nthông tin được truyền theo thẳng qua mạng để tìm tổng trọng số đầu vào và đầu ra, \r\n\r\ngiai đoạn tiếp theo các sai sẽ được tính và truyền ngược lại. \r\n\r\n\r\n\r\n \r\n29 \r\n\r\n3.2.2 Mạng RNN \r\n\r\nMô hình mạng neural hồi quy (Recurrent Neural Networks) được sử dụng phổ biến \r\n\r\ntrong các bài toán xử lí ngôn ngữ tự nhiên, mô hình hóa được bản chất của của ngôn \r\n\r\nngữ tự nhiên. Dữ liệu trong NLP có sự phụ thuộc lẫn nhau giữa các thành phần trong \r\n\r\ndữ liệu và chúng thường ở dạng chuỗi.  RNN thường được sử dụng cho các bài toán \r\n\r\nNLP vì chúng là mô hình mạng sử dụng đầu vào là thông tin dạng chuỗi.   \r\n\r\nMột số mạng neural truyền thống được giả định rằng các đầu vào độc lập với nhau, \r\n\r\ncác mô hình không phù hợp với nhiều bài toán. Ví dụ với bào toán dự đoán từ, ta phải \r\n\r\nbiết được các từ trước đó thì mới có thể dự đoán được từ tiếp theo. Mạng RNN có \r\n\r\nkhả năng nhớ các thông tin trước đó dựa vào việc thực hiện cùng một tác vụ tính toán \r\n\r\ncho mỗi phần tử của chuỗi đầu vào. Trên lí thuyết, RNN có thể nhớ tất cả các thông \r\n\r\ntin trước đó, có khả năng sử dụng một đoạn văn bản rất dài. Tuy nhiên, mạng chỉ có \r\n\r\nthể nhớ được trong vài bước tính toán ban đầu, thông tin được tính toán trước đó dần \r\n\r\nmất trong quá trình truyền. Một mạng neural được duỗi ra giống như một chuỗi tuần \r\n\r\ntự. Ví dụ đầu vào là một chuỗi gồm năm từ, mạng sẽ duỗi ra với năm tầng mạng, mỗi \r\n\r\ntầng cho một từ. Mỗi tầng thể hiện mạng tại một thời điểm gọi là bước thời gian \r\n\r\n(time-step).  Mạng RNN khi được duỗi ra thường có mô hình dạng sau: \r\n\r\n \r\n\r\n\r\n \r\n\r\n\r\n\r\n \r\n30 \r\n\r\nViệc tính toán bên trong RNN sẽ được thực hiện như sau:  \r\n\r\n t là đầu vào tại bước thời gian thứ t. Ví dụ 1 là one-hot vector biểu diễn từ \r\n\r\nthứ hai trong câu. \r\n\r\n t là trạng thái ẩn tại bước thời gian thứ t. Nó được coi là bộ nhớ của mạng. t \r\n\r\nđược tính dựa trên các trạng thái ẩn trước đó và đầu vào hiện tại theo công \r\n\r\nthức:  = ( + 1). Hàm f thường là hàm sigmoid hoặc ReLU. Để tính \r\n\r\ntrạng thái ẩn cho mạng ở phần tử đầu tiên, ta cần khởi tạo một giá trị -1. -1 \r\n\r\nthường được khởi tạo là -1. \r\n\r\n t là đầu ra tại bước thời gian thứ t. Thông thường được tính theo hàm softmax. \r\n\r\nVí dụ, ta muốn dự đoán một từ có xuất hiện không thì t là vector xác suất \r\n\r\ntrong tập từ điển của ta:  = (  ). \r\n\r\nTrạng thái ẩn như là bộ nhớ của mạng. Thu thập thông tin về những gì đã xảy ra trong \r\n\r\ntất cả các bước thời gian trước đó. Đầu ra ở bước được tính toán chỉ dựa trên bộ nhớ \r\n\r\nvào thời gian. Tuy nhiên, mạng không thể nhớ được nhiều thông tin. Thông tin đồng \r\n\r\nthời bị mất dần qua các bước thời gian.  \r\n\r\nKhông giống như mạng thần kinh sâu truyền thống, sử dụng các tham số khác nhau \r\n\r\nở mỗi lớp, một RNN chia sẻ các tham số giống nhau qua tất cả các bước. Tức là, ta \r\n\r\nđang thực hiện cùng một công việc ở từng bước, chỉ với các đầu vào khác nhau. Điều \r\n\r\nnày làm giảm tổng số các tham số chúng ta cần phải học.  \r\n\r\nSơ đồ trên có đầu ra ở mỗi bước thời gian, nhưng tùy thuộc vào các bài toán khác \r\n\r\nnhau mà đầu ra này có thể không cần thiết. Ví dụ, khi dự đoán tình cảm của một câu \r\n\r\nchúng ta chỉ có thể quan tâm đến kết quả cuối cùng chứ không phải tình cảm sau mỗi \r\n\r\ntừ. Tương tự như vậy, chúng ta có thể không cần đầu vào ở từng thời điểm. Các tính \r\n\r\nnăng chính của một RNN là trạng thái ẩn của nó, trong đó nắm bắt một số thông tin \r\n\r\nvề một chuỗi.  \r\n\r\nHuấn luyện mạng RNN tương tự như mạng neural thông thường. Mạng vẫn sử dụng \r\n\r\nthuật toán lan truyền ngược nhưng có chút thay đổi. Đạo hàm tại mỗi đầu ra sẽ được \r\n\r\n\r\n\r\n \r\n31 \r\n\r\ntính dựa trên tất cả cả bước thời gian vì tham số được sử dụng chung cho toàn mạng. \r\n\r\nĐạo hàm tại đầu ra được tính bằng tổng của các bước trước đó. Giải thuật này còn \r\n\r\nđược gọi là lan truyền ngược liên hồi (Backpropagation Through Time BPTT).  \r\n\r\nQua nhiều năm nghiên cứu và phát triển, một số loại mạng RNN được sinh ra để khác \r\n\r\nphục các nhược điểm của RNN truyền thống. Một số mô hình tiêu biểu:  \r\n\r\n RNN hai chiều (Bidirectional RNNs) dựa trên ý tưởng rằng tại mỗi bước thời \r\n\r\ngian, trạng thái ẩn không chỉ phụ thuộc vào các yếu tố trước đó trong chuỗi, \r\n\r\nmà còn các yếu tố trong tương lai. Ví dụ: để dự đoán một từ bị thiếu trong một \r\n\r\nchuỗi ta phải biết cả ngữ cảnh trái và phải. RNN hai chiều khá đơn giản. Họ \r\n\r\nchỉ là hai RNN xếp chồng lên nhau. Đầu ra sau đó được tính dựa trên trạng \r\n\r\nthái ẩn của cả hai RNN. Đầu vào của của mạng tại timestep thứ i bao gồm cả \r\n\r\ntrạng thái ẩn tại bước thời gian thứ i  1 cùng RNN và trạng thái ẩn của bước \r\n\r\nthời gian thứ i + 1 của RNN chồng lên nó. Nhờ đó, tại mỗi bước thời gian sẽ \r\n\r\nnhớ được thông tin toàn mạng. \r\n\r\n \r\n\r\n\r\n RNN sâu (Deep (Bidirectional) RNN) tương tự như mạng RNN hai chiều, \r\n\r\nnhưng tại mỗi bước thời gian thay vì có một trạng thái ẩn thì mạng lại có nhiều \r\n\r\ntrạng thái ẩn. Nhờ có nhiều trạng thái ẩn mà khả năng học của mạng cũng cao \r\n\r\nhơn. \r\n\r\n\r\n\r\n \r\n32 \r\n\r\n \r\n\r\n\r\n LSTM (Long short term memory networks) có kiến trúc giống với RNN thông \r\n\r\nthường. Nhưng chúng sử dụng nhiều hàm tính toán khác ở trạng thái ẩn. Điểm \r\n\r\nnổi bật của mạng là nó khắc phục được các vấn đề phụ thuộc xa (long-term \r\n\r\ndependency problem) của RNN. \r\n\r\n3.2.3 Mạng LSTM \r\n\r\nMạng bộ nhớ dài-ngắn (Long Short Term Memory networks), thường được gọi là \r\n\r\nLSTM - là một dạng đặc biệt của RNN, nó có khả năng học được các phụ thuộc xa. \r\n\r\nLSTM được giới thiệu bởi Hochreiter & Schmidhuber (1997), và sau đó đã được cải \r\n\r\ntiến và phổ biến bởi rất nhiều người trong ngành. Chúng hoạt động cực kì hiệu quả \r\n\r\ntrên nhiều bài toán khác nhau nên dần đã trở nên phổ biến như hiện nay. \r\n\r\nLSTM được thiết kế để tránh được vấn đề phụ thuộc xa (long-term dependency). Việc \r\n\r\nnhớ thông tin trong suốt thời gian dài là đặc tính mặc định của chúng, chứ ta không \r\n\r\ncần phải huấn luyện nó để có thể nhớ được. Tức là ngay nội tại của nó đã có thể ghi \r\n\r\nnhớ được mà không cần bất kì can thiệp nào. \r\n\r\n\r\n\r\n \r\n33 \r\n\r\nMọi mạng hồi quy đều có dạng là một chuỗi các mô-đun lặp đi lặp lại của mạng \r\n\r\nneural. Với mạng RNN chuẩn, các mô-dun này có cấu trúc rất đơn giản, thường là \r\n\r\nmột tầng tanh. \r\n\r\n \r\n\r\n\r\nLSTM cũng có kiến trúc dạng chuỗi như vậy, nhưng các mô-đun trong nó có cấu trúc \r\n\r\nkhác với mạng RNN chuẩn. Thay vì chỉ có một tầng mạng neural, chúng có tới 4 tầng \r\n\r\ntương tác với nhau một cách rất đặc biệt. \r\n\r\n \r\n\r\n\r\nỞ sơ đồ trên, mỗi một đường mang một véc-tơ từ đầu ra của một nút tới đầu vào của \r\n\r\nmột nút khác. Các hình trong màu hồng biểu diễn các phép toán như phép cộng véc-\r\n\r\ntơ chẳng hạn, còn các ô màu vàng được sử dụng để học trong các từng mạng neural. \r\n\r\nCác đường hợp nhau kí hiệu việc kết hợp, còn các đường rẽ nhánh ám chỉ nội dung \r\n\r\ncủa nó được sao chép và chuyển tới các nơi khác nhau. \r\n\r\n\r\n\r\n \r\n34 \r\n\r\n3.3 Mô hình tóm tắt văn bản \r\n\r\n3.3.1 Mô hình Sequence to Sequence \r\n\r\nMô hình sequence to sequence hay encoder-decoder (seq2seq) là mô hình sinh ra để \r\n\r\ngiải quyết các bài toán sinh chuỗi đầu ra từ câu đầu vào cho trước. Mô hình seq2seq \r\n\r\ngồm một bộ mã hóa (encoder) và một bộ giải mã (decoder). Mô hình mã hóa một dãy \r\n\r\ncó độ dài biến đổi thành một biểu diễn vector chiều dài cố định và để giải mã một sự \r\n\r\nbiểu diễn cố định trở lại thành một dãy có độ dài biến đổi. Từ góc độ xác suất, mô \r\n\r\nhình mới này là một phương pháp tổng quát để tìm hiểu sự phân bố có điều kiện đối \r\n\r\nvới một dãy có độ dài thay đổi theo một dãy có độ dài thay đổi khác.   \r\n\r\nBộ mã hóa là một RNN đọc mỗi từ của một chuỗi đầu vào x tuần tự. Khi nó đọc từng \r\n\r\ntừ, trạng thái ẩn của RNN thay đổi. Sau khi đọc kết thúc chuỗi (được đánh dấu bởi \r\n\r\nmột ký hiệu cuối của chuỗi), trạng thái ẩn của một RNN là một vector cố định c được \r\n\r\ntổng hợp từ chuỗi đầu vào. C được dùng như ngữ cảnh cho bộ gải mã. Nhờ có vector \r\n\r\nngữ cảnh bộ giải mã có thể xác định đầu ra chính xác hơn. \r\n\r\nVí dụ với một mô hình dự đoán từ, khi gặp từ hạ ta sẽ không thể biết đó là từ chỉ \r\n\r\nmùa trong năm hay là động từ mang nghĩa hạ xuống, nhưng nếu có một ngữ cảnh cụ \r\n\r\nthể thì bộ giải mã của ta có thể xác định được từ đó có nghĩa là gì. Bộ giải mã của mô \r\n\r\nhình được đề xuất là một RNN khác được huấn luyện để tạo chuỗi đầu ra bằng cách \r\n\r\ndự đoán từ  tiếp theo với trạng thái ẩn . Tuy nhiên, không giống như RNN thông \r\n\r\nthường, cả  và  cùng bị điều khiển bởi 1 và vector ngữ cảnh c của dãy đầu \r\n\r\nvào.  \r\n\r\nDo đó, trạng thái ẩn của bộ giải mã tại thời điểm t được tính như sau: \r\n\r\n = (1, 1, ) \r\n\r\nCông thức 1 Trạng thái ẩn của bộ giải mã tại thời điểm t \r\n\r\n \r\n\r\n\r\n\r\n \r\n35 \r\n\r\nTương tự, xác xuất phân bố của từ tiếp theo là:  \r\n\r\n(| 1, 2, . ,  , ) = ( , 1, ) \r\n\r\nCông thức 2 Xác suất phân bố từ tiếp theo \r\n\r\nTrong đó, f, g là các hàm tính xác suất (thường là hàm softmax)  \r\n\r\nVí dụ:  = (1, . ,   | 1, . , ), trong đó độ dài các chuỗi đầu vào và đầu ra T, T \r\n\r\ncó thể khác nhau.  \r\n\r\nBộ mã hóa và giải mã được huấn luyện đồng thời và kiểm tra hàm mất mát ở bộ giải \r\n\r\nmã.  \r\n\r\nKhi bộ RNN Encoder-Decoder được đào tạo, mô hình có thể được sử dụng theo hai \r\n\r\ncách. Một cách là sử dụng mô hình để tạo một chuỗi đích từ chuỗi đầu vào. Mặt khác, \r\n\r\nmô hình có thể được sử dụng để tính điểm cho cặp chuỗi đầu vào và chuỗi đầu ra \r\n\r\ntheo xác suất (\r\n\r\n\r\n\r\n),  là tập tham số của mô hình. \r\n\r\n3.3.2 Kỹ thuật Attention \r\n\r\nKhi sử dụng mô hình seq2seq ta thấy có các vấn đề:  \r\n\r\n Mô hình yêu cầu phải sử dụng toàn bộ thông tin chuỗi đầu để bộ mã hóa tạo \r\n\r\nra vectơ c dù cho chuỗi đầu vào dài hay ngắn. Việc này không hợp lí vì trong \r\n\r\nmột số trường hợp nhất định ta chỉ cần thông tin của một thành phần của chuỗi. \r\n\r\nVí dụ như việc dịch một từ thì ta chỉ cần quan tâm tới ngữ cảnh của các từ \r\n\r\nxung quanh nó trong câu. \r\n\r\n Yêu cầu bộ giải mã phải trích xuất được thông tin từ vector vì tất cả các đầu \r\n\r\nra của bộ giải mã đều sử dụng chung một vector ngữ cảnh c. \r\n\r\n Vector ngữ cảnh c phải chứa đầy đủ thông tin cho bộ giải mã. \r\n\r\n\r\n\r\n \r\n36 \r\n\r\nTrong thực tế, con người chúng ta tiếp nhận rất nhiều thông tin. Nhưng chỉ những \r\n\r\nthông tin quan trọng và cần thiết được sử dụng để đưa ra quyết định nào đó. Kĩ thuật \r\n\r\nattention dựa trên ý tưởng này để giải quyết các vấn đề của mô hình seq2seq.  \r\n\r\nKĩ thuật này được được đề xuất lần đầu tiên bởi Bahdanau và cộng sự vào năm 2014 \r\n\r\nlấy cảm hứng từ mô hình visual attention trong ngành công nghiệp computer vision. \r\n\r\nVới kĩ thuật này, thay vì mã hóa toàn bộ chuỗi đầu vào thành một vector ngữ cảnh \r\n\r\nduy nhất bằng một dãy vector. Dãy vector này được tính trung bình và là đầu vào của \r\n\r\ncác thành phần trong bộ giải mã. Bộ mã hóa, giải mã và cơ chế attention được huấn \r\n\r\nluyện đồng thời cùng nhau (join training). Chuỗi đầu vào được mã hóa bằng RNN \r\n\r\nhai chiều (bidirectional RNN) và sinh ra một chuỗi các vector. Tại mỗi thời điểm, bộ \r\n\r\ngiải mã sẽ chọn một thành phần trong chuỗi vector để tập trung vào và sinh ra một \r\n\r\nvector ngữ cảnh để sinh ra đầu ra tại thời điểm đó. \r\n\r\n3.3.3 Word vector \r\n\r\nWord vector là vector có trọng số, số chiều nhất định và được sử dụng để biểu diễn \r\n\r\nmột từ. Đầu vào khi sử dụng học sâu cho NLP là vector chứa giá trị số. Tùy theo cách \r\n\r\nchọn đơn vị đầu vào mà có các cách biểu diễn khác nhau. \r\n\r\nĐơn vị đầu vào thường được chia làm hai loại: ký tự (character) và từ (token). \r\n\r\nBiểu diễn dưới dạng ký tự (character) là một cách biểu diễn đơn giản vì số lượng kí \r\n\r\ntự không lớn, có giới hạn. Do đó, số chiều của vector biểu diễn cũng nhỏ, không sợ \r\n\r\ncác vấn đề về lưu trữ và xử lí. Giữa các kí tự không có mối quan hệ về ngữ nghĩa, \r\n\r\nnên hai kí tự khác nhau thì chỉ cần hai vector khác nhau là có thể biểu diễn được.  \r\n\r\nKhi cần biểu diễn một kí tự chúng ta có thể biểu diễn bằng một one-hot vector. Số \r\n\r\nchiều của one-hot vector phụ thuộc vào số lượng phần tử có trong tập hợp mà chúng \r\n\r\nta cần biểu diễn. Ví dụ chúng ta cần biểu diễn cho 102 kí tự trên bàn phím thì chúng \r\n\r\nta cần vector 102 chiều. \r\n\r\n \r\n\r\n\r\n\r\n \r\n37 \r\n\r\nTuy nhiên, chúng ta có thể sử dụng nhiều cách để biểu diễn một từ (token).  \r\n\r\n Sử dụng một số nguyên để biểu diễn: cách này đơn giản nhưng không hiệu \r\n\r\nquả vì nó không biểu diễn được mối quan giữa các từ và đầu vào là một vector. \r\n\r\n Sử dụng one-hot vector: Giống với cách biểu diễn kí tự, ta coi mỗi token là \r\n\r\nmột phần tử và một triệu từ được coi là một triệu phần tử trong tập hợp. Khi \r\n\r\nđó, mỗi từ sẽ đc biểu diễn bằng một vector một triệu chiều. Do đó, khi phải \r\n\r\nlưu một triệu phần tử thì chúng ta cần phải sử dụng một ma trận \r\n\r\n1.000.000x1000.000 để biểu diễn. Điều này dẫn đến những vẫn đề về lưu trữ \r\n\r\nvà xử lí. Mặt khác, việc dùng one-hot vector cũng không thể biểu diễn được \r\n\r\nmối quan hệ giữa các từ. \r\n\r\n Sử dụng các vector random: khắc phục được nhược điểm về số chiều của \r\n\r\nvector. Mỗi từ được coi là một điểm trong không gian với số chiều nhất định. \r\n\r\nTuy nhiên, cách này vẫn không biểu diễn được mối quan hệ giữa các từ. \r\n\r\n Sử dụng word embeddings: Đây được xem là cách biểu diễn hiệu quả nhất với \r\n\r\nsố chiều biểu diễn một từ thấp và biểu diễn được mối quan hệ giữa các từ với \r\n\r\nnhau. \r\n\r\n3.3.4 Word Empeddings \r\n\r\nWord embeddings là một trong những phương diện nghiên cứu thú vị nhất của \r\n\r\nphương pháp Deep Learning trong xử lý ngôn ngữ tự nhiên. Một word embeddings \r\n\r\nlà một hàm ánh xạ từ thành các vector nhiều chiều (200 đến 500 chiều). \r\n\r\nVí dụ như: \r\n\r\nW(cat) = (0.2, -0.4, 0.7, .) \r\n\r\nW(mat) = (0.0, 0.6, -0.1, .)  \r\n\r\nThường thì hàm W sẽ là một bảng tra cứu, lưu trữ dưới dạng một ma trận , với \r\n\r\n() = .  W khởi tạo một vector random cho mỗi từ, vector này được thay đổi \r\n\r\nsao cho nó biểu diễn được mối quan hệ với những từ khác liên quan.  \r\n\r\n\r\n\r\n \r\n38 \r\n\r\nCác vector có tính chất (i) số lượng chiều không lớn (200 đến 500 chiều, nhỏ so với \r\n\r\ntập từ vựng), (ii) các từ có nghĩa gần nhau sẽ gần nhau trong không gian, và (iii) mối \r\n\r\nquan hệ tương đồng ngữ nghĩa sẽ được chuyển thành mối quan hệ giống nhau giữa \r\n\r\ncác vector. \r\n\r\nVí dụ việc huấn luyện mạng phát hiện ra cụm 5-gram (chuỗi 5 từ) có hợp lệ hay \r\n\r\nkhông. Hàm W ánh xạ mỗi từ tới một vector, các vector này được đưa vào một hàm \r\n\r\nkhác là R. R sẽ xác định cụm năm từ đó có hợp lệ hay không. \r\n\r\nR(W(cat), W(sat), W(on), W(the), W(mat)) = 1  \r\n\r\nR(W(cat), W(sat), W(song), W(the), W(mat)) = 0 \r\n\r\nBằng cách đổi từ có cùng lớp nghĩa, chúng ta sẽ sinh ra được các câu không hợp lệ \r\n\r\nvà các câu có cùng lớp nghĩa (the wall is blue  the wall is red). Hơn thế, chúng \r\n\r\nta có thể thay đổi nhiều từ. Bằng cách này chúng ta sẽ dịch được vector các từ nghĩa \r\n\r\ngần nhau tới gần nhau hơn và mối liên hệ giữa các từ cũng dần được mã hóa. Ví dụ \r\n\r\nvề sự khác biệt giữa man và woman:  \r\n\r\nW(man)  W(woman)  W(uncle)  W(aunt)  \r\n\r\nW(man)  W(woman)  W(king)  W(queen) \r\n\r\n \r\n\r\n \r\n\r\n\r\n\r\n\r\n \r\n39 \r\n\r\nNhững mối quan hệ phức tạp hơn cũng được mã hóa theo cách này. \r\n\r\n \r\n\r\n\r\nTrong đồ án, sinh viên sử dụng word empedding là ConceptNet Numberbatch, nội \r\n\r\ndung sẽ được trình bày chi tiết trong phần 5.1. \r\n\r\n3.4 Text-to-Speech \r\n\r\nTrên máy tính, Text-to-Speech (TTS) là việc tạo ra giọng nói của người từ đầu vào \r\n\r\nlà văn bản hay các mã hóa việc phát âm. Tuy rằng không phải hệ thống text-to-speech \r\n\r\nnào cũng có đầu vào là văn bản (nhiều hệ thống thu nhận mã hóa cách phát âm, ví dụ \r\n\r\nmã IPA). Hệ thống thực hiện việc này còn gọi là máy tổng hợp giọng nói (text-to-\r\n\r\nspeech engine), có thể là hệ thống phần mềm hoặc phần cứng. \r\n\r\nCác hệ thống TTS có nhiều ứng dụng. Ví dụ như có thể giúp người có thị lực kém \r\n\r\n(hoặc khiếm thị) nghe được máy đọc ra văn bản, đặc biệt là các văn bản có thể xử lý \r\n\r\ntrên máy tính. Hệ thống có thể lắp đặt trong phần mềm xử lý văn bản hay trình duyệt \r\n\r\nmạng. \r\n\r\nHai tính chất quan trọng của chất lượng hệ thống tổng hợp giọng nói là mức độ tự \r\n\r\nnhiên và mức độ dễ nghe. Mức độ tự nhiên của giọng nói tổng hợp chính là sự giống \r\n\r\nnhau giữa giọng tổng hợp và giọng nói tự nhiên của người thật. Mức độ dễ nghe chỉ \r\n\r\n\r\n\r\n \r\n40 \r\n\r\nđến việc câu phát âm có thể hiểu được dễ dàng không. Một hệ thống TTS lý tưởng \r\n\r\ncần vừa tự nhiên vừa dễ nghe, và mục tiêu xây dựng hệ thống TTS là làm tăng tối đa \r\n\r\nhai tính chất này. Một số hệ thống TTS có thể thiên về mức độ dễ nghe hơn, hoặc \r\n\r\nmức độ tự nhiên hơn; tùy thuộc vào mục đích mà công nghệ được lựa chọn. Có hai \r\n\r\ncông nghệ chính được dùng là tổng hợp ghép nối và tổng hợp cộng hưởng tần số; \r\n\r\nngoài ra cũng có một số công nghệ khác. \r\n\r\nTổng hợp ghép nối dựa trên việc nối vào nhau các đoạn của một giọng nói đã được \r\n\r\nghi âm. Thông thường, tổng hợp ghép nối tạo ra giọng nói tương đối tự nhiên. Tuy \r\n\r\nnhiên, giọng nói tự nhiên được ghi âm có sự thay đổi từ lần phát âm này sang lần phát \r\n\r\nâm khác, và công nghệ tự động hóa việc ghép nối các đoạn của sóng âm thỉnh thoảng \r\n\r\ntạo ra những tiếng cọ xát không tự nhiên ở phần ghép nối. \r\n\r\nTổng hợp cộng hưởng tần số không sử dụng bất cứ mẫu giọng thật nào khi chạy. Thay \r\n\r\nvào đó, tín hiệu âm thanh cho ra dựa trên một mô hình âm thanh. Các thông số như \r\n\r\ntần số cơ bản, sự phát âm, và mức độ tiếng ồn được thay đổi theo thời gian để tạo ra \r\n\r\ndạng sóng cho giọng nói nhân tạo. Phương pháp này đôi khi còn được gọi là tổng hợp \r\n\r\ndựa trên quy tắc, dù cho nhiều hệ thống ghép nối mẫu âm thanh thật cũng có dùng \r\n\r\ncác thành phần dựa trên quy tắc. \r\n\r\nNhiều hệ thống dựa trên tổng hợp cộng hưởng tần số tạo ra giọng nói nhân tạo, như \r\n\r\ngiọng robot. Giọng nói nhân tạo thường không tự nhiên, và có thể phân biệt rõ ràng \r\n\r\nvới giọng người thật. Tuy nhiên độ tự nhiên cao không phải lúc nào cũng là mục đích \r\n\r\ncủa hệ thống và hệ thống này cũng có các ưu điểm riêng của nó. \r\n\r\nHệ thống tổng hợp giọng nói nhân tạo nói khá dễ nghe, ngay cả ở tốc độ cao, không \r\n\r\ncó tiếng cọ xát do ghép âm tạo ra. Các hệ thống này hoạt động ở tốc độ cao, có thể \r\n\r\nhướng dẫn người khiếm thị nhanh chóng dò dẫm trên máy tính, bằng cách đọc to \r\n\r\nnhững gì hiện ra trên màn hình. Các hệ thống này cũng nhỏ gọn hơn các hệ thống \r\n\r\nghép nối âm, vì không phải chứa cơ sở dữ liệu mẫu âm thanh lớn. Nó có thể dùng \r\n\r\ntrong các hệ thống nhúng khi bộ nhớ và tốc độ xử lý có hạn. Hệ thống này cũng có \r\n\r\nkhả năng điều khiển mọi khía cạnh của tín hiệu âm thanh đi ra, nó cho ra một dải rộng \r\n\r\n\r\n\r\n \r\n41 \r\n\r\ncác lời văn và ngữ điệu, và không chỉ thể hiện được câu nói thường hay câu hỏi, mà \r\n\r\ncả các trạng thái tình cảm thông qua âm điệu của giọng nói. \r\n\r\n3.5 Android \r\n\r\nAndroid là một hệ điều hành dựa trên nền tảng Linux được thiết kế dành cho các thiết \r\n\r\nbị di động có màn hình cảm ứng như điện thoại thông minh và máy tính bảng. Ban \r\n\r\nđầu, Android được phát triển bởi Tổng công ty Android, với sự hỗ trợ tài chính từ \r\n\r\nGoogle và sau này được chính Google mua lại vào năm 2005. Android ra mắt vào \r\n\r\nnăm 2007 cùng với tuyên bố thành lập Liên minh thiết bị cầm tay mở: một hiệp hội \r\n\r\ngồm các công ty phần cứng, phần mềm, và viễn thông với mục tiêu đẩy mạnh các \r\n\r\ntiêu chuẩn mở cho các thiết bị di động. Chiếc điện thoại đầu tiên chạy Android được \r\n\r\nbán vào năm 2008. \r\n\r\nAndroid có mã nguồn mở và Google phát hành mã nguồn theo Giấy phép Apache. \r\n\r\nChính mã nguồn mở cùng với một giấy phép không có nhiều ràng buộc đã cho phép \r\n\r\ncác nhà phát triển thiết bị, mạng di động và các lập trình viên nhiệt huyết được điều \r\n\r\nchỉnh và phân phối Android một cách tự do. Ngoài ra, Android còn có một cộng đồng \r\n\r\nlập trình viên đông đảo chuyên viết các ứng dụng để mở rộng chức năng của thiết bị, \r\n\r\nbằng một loại ngôn ngữ lập trình Java có sửa đổi. Vào tháng 10 năm 2012, có khoảng \r\n\r\n700.000 ứng dụng trên Android, và số lượt tải ứng dụng từ Google Play, cửa hàng \r\n\r\nứng dụng chính của Android, ước tính khoảng 25 tỷ lượt. \r\n\r\nAndroid chiếm 87,7% thị phần điện thoại thông minh trên toàn thế giới vào thời điểm \r\n\r\nquý 2 năm 2017, với tổng cộng 2 tỷ thiết bị đã được kích hoạt và 1,3 triệu lượt kích \r\n\r\nhoạt mỗi ngày. Sự thành công của hệ điều hành cũng khiến nó trở thành mục tiêu \r\n\r\ntrong các vụ kiện liên quan đến bằng phát minh, góp mặt trong cái gọi là \"cuộc chiến \r\n\r\nđiện thoại thông minh\" giữa các công ty công nghệ. \r\n\r\nCác ứng dụng cho Android được phát triển bằng ngôn ngữ Java sử dụng Bộ phát triển \r\n\r\nphần mềm Android (SDK). SDK bao gồm một bộ đầy đủ các công cụ dùng để phát \r\n\r\ntriển, gồm có công cụ gỡ lỗi, thư viện phần mềm, bộ giả lập điện thoại dựa trên \r\n\r\n\r\n\r\n \r\n42 \r\n\r\nQEMU, tài liệu hướng dẫn, mã nguồn mẫu, và hướng dẫn từng bước. Môi trường \r\n\r\nphát triển tích hợp (IDE) được hỗ trợ chính thức là Eclipse sử dụng phần bổ sung \r\n\r\nAndroid Development Tools (ADT). Các công cụ phát triển khác cũng có sẵn, gồm \r\n\r\ncó Bộ phát triển gốcdành cho các ứng dụng hoặc phần mở rộng viết bằng C hoặc \r\n\r\nC++, Google App Inventor, một môi trường đồ họa cho những nhà lập trình mới bắt \r\n\r\nđầu, và nhiều nền tảng ứng dụng web di động đa nền tảng phong phú. \r\n\r\nAndroid có một hạt nhân dựa trên nhân Linux phiên bản 2.6, kể từ Android 4.0 Ice \r\n\r\nCream Sandwich trở về sau, là phiên bản 3.x, với middleware, thư viện và API viết \r\n\r\nbằng C, còn phần mềm ứng dụng chạy trên một nền tảng ứng dụng gồm các thư viện \r\n\r\ntương thích với Java dựa trên Apache Harmony. Android sử dụng máy ảo Dalvik với \r\n\r\nmột trình biên dịch động để chạy 'mã dex' (Dalvik Executable) của Dalvik, thường \r\n\r\nđược biên dịch sang Java bytecode. Nền tảng phần cứng chính của Android là kiến \r\n\r\ntrúc ARM. Người ta cũng hỗ trợ x86 thông qua dự án Android x86, và Google TV \r\n\r\ncũng sử dụng một phiên bản x86 đặc biệt của Android. \r\n\r\n \r\n\r\n \r\n\r\nTổng kết lại, Chương 3 đã trình bày về các kiến thức cơ bản của phương pháp tóm \r\n\r\ntắt văn bản bằng Deep Learning và kiến thức liên quan đến nền tảng Android cũng \r\n\r\nnhư công nghệ Text-to-Speech. Trong chương tiếp theo, người viết đồ án sẽ mô tả \r\n\r\nquy trình xây dựng và phát triển sản phẩm. \r\n\r\n\r\n\r\n \r\n43 \r\n\r\nYếu tố quan trọng nhất trong phương pháp tóm tắt văn bản bằng Deep Learning là \r\n\r\nxây dựng thành công model đã được huấn luyện với một tập dữ liệu tốt. Chương 4 sẽ \r\n\r\ntrình bày quy trình xây dựng và huấn luyện model, cùng với đó là trình bày về ứng \r\n\r\ndụng di động Android tích hợp chức năng tóm tắt văn bản và công nghệ text-to-\r\n\r\nspeech. \r\n\r\n4.1 Mô hình tóm tắt văn bản \r\n\r\n4.1.1 Tiền xử lý dữ liệu \r\n\r\nTập dữ liệu được sử dụng bao gồm các review về thức ăn trên Amazon được thu thập \r\n\r\ntừ tháng 10/1999 đến tháng 10/2012. Có tổng cộng 568.454 bản review về 74.258 \r\n\r\nsản phẩm được đánh giá từ 256.059 người dùng. Mỗi bản review bao gồm thông tin \r\n\r\nvề sản phẩm, người dùng, xếp hạng, tiêu đề và nội dung đánh giá. Tuy nhiên, trong \r\n\r\nphạm vi đồ án này, chúng ta chỉ chú ý đến hai trường dữ liệu là tiêu đề (summary) và \r\n\r\nnội dung đánh giá (text). \r\n\r\nTrước tiên, dữ liệu được xử lý theo các bước (i) chuyển chữ viết hoa thành chữ \r\n\r\nthường, (ii) thay thế các cụm từ viết tắt về dạng chuẩn của nó (ví dụ như cant thành \r\n\r\ncannot), (iii) xoá bỏ các ký tự không cần thiết, và (iv) xoá bỏ stop words để tiết \r\n\r\nkiệm bộ nhớ và tăng tốc độ xử lý (stop words là các từ trong tiếng Anh có nghĩa \r\n\r\nkhông ảnh hưởng đến nội dung tóm tắt văn bản, ví dụ như mạo từ the). \r\n\r\nChương 4 Phát triển và \r\n\r\ntriển khai ứng dụng \r\n\r\n\r\n\r\n \r\n44 \r\n\r\nChúng ta sẽ sử dụng ConceptNet Numberbatch (CN) như đã được giới thiệu. Trong \r\n\r\nđó, mỗi token từ sẽ được chuyển sang thành vector 300 chiều. \r\n\r\nVới các từ không có trong CN mà có tần suất xuất hiện lớn hơn 20 lần, chúng ta sẽ \r\n\r\ntạo một vector 300 chiều với các giá trị ngẫu nhiên trong khoảng [-1, 1], sau đó thêm \r\n\r\nnó vào word empeddings. Ngoài ra, token <UNK> dùng để đánh dấu các từ chưa \r\n\r\nbiết, token <EOS> dùng để đánh dấu kết thúc câu. \r\n\r\nĐể huấn luyện model nhanh hơn, các đoạn review sẽ được sắp xếp theo độ dài từ nhỏ \r\n\r\nđến lớn. Các review có nhiều hơn 1 token <UNK> sẽ bị loại bỏ để đảm bảo model \r\n\r\nđược huấn luyện với tập dữ liệu tốt. \r\n\r\n4.1.2 Kiến trúc Encoder-Decoder \r\n\r\nĐể xây dựng mô hình seq2seq, kiến trúc Encoder-Decoder với mạng RNN là một \r\n\r\nphương thức tiếp cận hiệu quả và tiêu chuẩn, gồm 2 phần chính là bộ mã hoá \r\n\r\n(encoder) và bộ giải mã (decoder). \r\n\r\n \r\n\r\n\r\nMỗi từ đầu vào sẽ được đánh số theo hai từ điển là vocab_to_int và int_to_vocab để \r\n\r\ntương ứng với một số nguyên, giúp cho việc truy xuất dữ liệu nhanh hơn. Sau đó, từ \r\n\r\nđược đưa vào word_embedding_matrix, mỗi từ được biểu diễn dưới dạng vector 300 \r\n\r\nchiều. Vector đi lần lượt qua các lớp ẩn, kết hợp với lớp ẩn sinh ra từ token trước đó. \r\n\r\nSau khi nhận layer ẩn cuối cùng, bộ giải mã kết hợp với token <EOS> để làm đầu \r\n\r\nvào. Sử dụng lớp softmax và kĩ thuật attention, bộ giải mã sẽ sinh lần lượt từng từ \r\n\r\ncho output. Quá trình dừng lại khi sinh đến kí tự <EOS>. \r\n\r\n\r\n\r\n \r\n45 \r\n\r\nTrong quá trình xử lý dữ liệu, những từ không nằm trong CN hoặc có tần suất xuất \r\n\r\nhiện dưới 20 lần sẽ bị gán nhãn <UNK> sẽ bị loại bỏ sẽ gây mất mát thông tin. \r\n\r\nThường những từ này là tên riêng. Tuy nhiên tỷ lệ rất nhỏ, chỉ chiếm 0.7%, nên sẽ \r\n\r\nkhông ảnh hưởng nhiều đến kết quả tóm tắt văn bản, vậy nên chúng ta có thể bỏ qua. \r\n\r\nChúng ta sử dụng mạng LSTM với 2 lớp ẩn. Mỗi lớp ẩn có kích thước là 256 units. \r\n\r\nCác trọng số trong mô hình được khởi tạo giá trị trong khoảng [-0.1;0.1]. Learning \r\n\r\nrate là 0.005. \r\n\r\n4.1.3 Kỹ thuật attention \r\n\r\nKĩ thuật attention là một cơ chế giúp giải quyết hạn chế của kiến trúc Encoder-\r\n\r\nDecoder trên các chuỗi dài, cụ thể nó sẽ tăng tốc độ học và nâng cao kỹ năng của mô \r\n\r\nhình trong việc dự đoán từ tiếp theo. Nó giúp cho mạng neural có thể chú ý hơn vào \r\n\r\nnhững nội dung quan trọng. Chuỗi đầu vào 1: được mã hoá bằng mạng RNN 2 \r\n\r\nchiều, sinh ra n vector 1:. \r\n\r\n1: = (1:) =   (1:) \r\n\r\nCông thức 3 Mã hoá chuỗi đầu vào bằng biRNN \r\n\r\nTại mỗi bước , decoder sẽ chọn ra những phần nào trong 1: để tập trung vào, sinh \r\n\r\nra vector ngữ cảnh  để dùng cho bước dự đoán thứ . \r\n\r\n(+1 = |1: , 1:) = ((+1))  \r\n\r\n+1 = ( , [; \r\n]) \r\n\r\n = (1:, 1:) \r\n\r\n  ~ (|1:1, 1:) \r\n\r\nCông thức 4 Sinh vector ngữ cảnh \r\n\r\n\r\n\r\n \r\n46 \r\n\r\n4.2 Ứng dụng di động Android \r\n\r\n4.2.1 Thiết kế kiến trúc \r\n\r\nTổng quan, ứng dụng được thiết kế theo mô hình Client - Server. Các thiết bị đóng \r\n\r\nvai trò máy khách gửi yêu cầu (request) tới máy chủ, máy chủ xử lý và gửi phản hồi \r\n\r\n(response) trở lại cho máy khách. \r\n\r\n \r\n\r\n\r\nCả phía Client và Server đều được xây dựng theo mô hình MVC. MVC là viết tắt của \r\n\r\nModel  View  Controller, trong đó Model chứa các đối tượng mô tả dữ liệu, View \r\n\r\nđảm nhận việc hiển thị thông tin, tương tác người dùng, còn Controller giữ nhiệm vụ \r\n\r\nnhận điều hướng các yêu cầu từ người dùng và gọi những phương thức xử lý chúng. \r\n\r\nĐối với ứng dụng phía client, phần View là các Activity và View hiển thị đối với \r\n\r\nngười dùng, phần Controller xử lý các thao tác, điều khiển các luồng sự kiện, còn \r\n\r\nModel lưu trữ thông tin đối tượng của hệ thống. \r\n\r\n\r\n\r\n \r\n47 \r\n\r\nThiết kế tổng quan: \r\n\r\n \r\n\r\n\r\nTổng quan, phần mềm được chia thành 4 package lớn là Service, Controller, View và \r\n\r\nModel. Trong đó, nhiệm vụ của mỗi package được phân tách rõ ràng. \r\n\r\nGói Service là gói chính của ứng dụng, giúp người dùng thực hiện các tác vụ ngay cả \r\n\r\nkhi không mở ứng dụng. \r\n\r\nGói Controller điều khiển các luồng, thực hiện các hành động chính của ứng dụng \r\n\r\nkhi người dùng thao tác. \r\n\r\nGói View để người dùng có thể vẽ custom view khi chọn vùng văn bản, gồm 2 class \r\n\r\nlà DrawLayout.java và CustomView.java. \r\n\r\nGói Model chứa các lớp lưu trữ dữ liệu. \r\n\r\n\r\n\r\n \r\n48 \r\n\r\n4.2.2 Thiết kế giao diện \r\n\r\nGiao diện chương trình: \r\n\r\n \r\n\r\n\r\nKhi ở giao diện chính, chúng ta có thể chọn toàn bộ các văn bản xuất hiện trên màn \r\n\r\nhình hoặc chọn một vùng văn bản. Nội dung văn bản đã được chọn sẽ được đọc bằng \r\n\r\ncông cụ text-to-speech. \r\n\r\nNếu chọn một vùng văn bản, layout được chuyển qua giao diện tóm tắt văn bản. \r\n\r\n \r\n\r\n\r\n\r\n\r\n \r\n49 \r\n\r\nỞ giao diện này, người dùng có thể chọn chức năng tóm tắt. Dữ liệu sẽ được gửi tới \r\n\r\nserver, sau đó trả về kết quả là một đoạn văn bản đã được tóm tắt hiển thị trên Dialog. \r\n\r\n \r\n\r\n\r\n4.3 Xây dựng ứng dụng \r\n\r\n4.3.1 Thư viện và công cụ sử dụng \r\n\r\nCác công cụ, ngôn ngữ lập trình, API, thư viện, IDE được sử dụng để phát triển ứng \r\n\r\ndụng. \r\n\r\n\r\nMục đích Công cụ Địa chỉ URL \r\n\r\nNgôn ngữ lập trình Python 3.6 64-bit https://www.python.org/ \r\n\r\nIDE lập trình PyCharm 2017.3.4 https://www.jetbrains.com/pycharm/ \r\n\r\nIDE lập trình Android Studio 2.3.3 https://developer.android.com/studio/ \r\n\r\nThư viện           \r\n\r\nDeep Learning \r\n\r\nTensorFlow 1.7.0 https://www.tensorflow.org/ \r\n\r\nFramework  Django 2.0.4 https://www.djangoproject.com/ \r\n\r\n4.3.2 Kết quả đạt được \r\n\r\nĐể đánh giá kết quả của model tóm tắt văn bản, người viết đồ án lựa chọn phương \r\n\r\npháp Rouge làm thước đo. Recall Oriented Understudy (ROUGE) là một phương \r\n\r\n\r\n\r\n \r\n50 \r\n\r\npháp do Lin và Hovy đưa ra vào năm 2003 cũng dựa trên các khái niệm tương tự. \r\n\r\nPhương pháp này sử dụng n-gram để đánh giá sự tương quan giữa các kết qủa của \r\n\r\nmô hình tóm tắt và tập dữ liệu đánh giá. Phương pháp này đã cho ra kết quả khả quan \r\n\r\nvà được sự đánh giá cao của cộng đồng nghiên cứu tóm tắt văn bản. ROUGE-N là \r\n\r\nmột thu hồi n-gram (n-gram recall) giữa một bản tóm tắt tự động và một tập các tài \r\n\r\nliệu tóm tắt tham chiếu (ReferenceSummaries). ROUGE-N được tính như sau: \r\n\r\n   =  \r\n  ()    {}\r\n\r\n  ()    {}\r\n \r\n\r\nCông thức 5 Công thức tính ROUGE-N \r\n\r\nTrong đó: \r\n\r\n n là chiều dài của n-gram \r\n\r\n () là số lượng tối đa n-gram có thể xảy ra đồng thời trong \r\n\r\nbản tóm tắt tự động và bản tóm tắt tham chiếu \r\n\r\nROUGE-N là một độ đo liên quan đến độ recall bởi vì mẫu số của vế phải trong công \r\n\r\nthức trên là tổng số n-gram xảy ra ở phía bản tóm tắt tham chiếu. Cũng có một lưu ý \r\n\r\nrằng, số lượng n-gram ở mẫu số trong công thức tính ROUGE-N sẽ tăng lên khi chúng \r\n\r\nta cho thêm nhiều tham chiếu. Điều này hoàn toàn trực quan và hợp lí bởi vì có thể \r\n\r\ntồn tại nhiều bản tóm tắt tốt. \r\n\r\nMỗi khi chúng ta thêm một tham chiếu vào tập các văn bản tham chiếu, chúng ta đã \r\n\r\nmở rộng không gian các văn bản tóm tắt thay thế (alternative summaries). Bằng cách \r\n\r\nđiều khiển các kiểu tham chiếu mà ta thêm vào tập văn bản tham chiếu, chúng ta có \r\n\r\nthể thiết kế các đánh giá tập trung vào các khía cạnh khác nhau của việc tóm tắt. \r\n\r\nNgoài ra, tổng tử số lớn hơn tổng số số bản tóm tắt tham chiếu. Điều này hiệu quả vì \r\n\r\ncung cấp thêm nhiều trọng số để matching các n-grams xảy ra trong đa tham chiếu. \r\n\r\nDo đó, một bản tóm tắt tự động càng chứa nhiều những từ được xuất hiện trong nhiều \r\n\r\nbản tóm tắt tham chiếu thì sẽ dành được điểm ROUGE-N càng cao. Điều này một lần \r\n\r\nnữa lại rất trực quan và hợp lí bởi vì chúng ta thường ưu tiên các bản tóm tắt tự động \r\n\r\n\r\n\r\n \r\n51 \r\n\r\ncàng có nhiều nét giống với các điểm giống nhau giữa các bản tóm tắt tham chiếu \r\n\r\ncàng tốt. \r\n\r\nKhi sử dụng đa tham chiếu, chúng ta tính ROUGE-N theo từng cặp, giữa bản tóm tắt \r\n\r\ntự động s và từng bản tóm tắt tham chiếu ri trong tập các văn bản tóm tắt tham chiếu. \r\n\r\nSau đó, kết quả điểm ROUGE-N cuối cùng trong đa tham chiếu sẽ là điểm ROUGE-\r\n\r\nN cao nhất trong tất cả các cặp được tính. Điều này có thể được thể hiện theo công \r\n\r\nthức sau: \r\n\r\n   =   ( , ) \r\n\r\nCông thức 6 Công thức tính ROUGE-N cuối cùng trong đa tham chiếu \r\n\r\nKết quả của model đạt được như sau: \r\n\r\n ROUGE-1: 26.86% \r\n\r\n ROUGE-2: 6.71% \r\n\r\nChúng ta sẽ so sánh kết quả với một số các model tóm tắt văn bản khác đã được công \r\n\r\nbố kết quả: \r\n\r\n\r\nModel ROUGE-1 ROUGE-2 \r\n\r\nModel Lead-3 (Nallapati) [3] 21.90% 7.20% \r\n\r\nModel SummaRuNNer (Nallapati) [5] 26.20% 10.80% \r\n\r\nModel Cheng et al  16 [5] 22.70% 8.50% \r\n\r\nModel ABS+ [5] 26.67% 6.72% \r\n\r\nModel of Sumit Chopra, Michael Auli [6] 26.90% 6.57% \r\n\r\n \r\n\r\n\r\n\r\n \r\n52 \r\n\r\nThông thường, các phương pháp tóm tắt trích xuất sẽ đạt kết quả ROUGE cao hơn \r\n\r\ncác phương pháp tóm tắt tóm lược. Bởi vì, phương pháp trích xuất sử dụng các từ \r\n\r\nxuất hiện trong văn bản để tạo ra bản tóm tắt, còn phương pháp tóm lược thì viết lại \r\n\r\ncâu theo ý hiểu của máy. \r\n\r\nNhư vậy, so với các model tóm tắt văn bản bằng Deep Learning khác, model của hệ \r\n\r\nthống đạt được kết quả gần tương đương. Trong đó kết quả ROUGE-1 gần bằng các \r\n\r\nmodel khác, còn kết quả ROUGE-2 vẫn khá thấp vì ảnh hưởng bởi tập dữ liệu không \r\n\r\nđược xử lý tốt. \r\n\r\nMột số kết quả thực nghiệm của model tóm tắt văn bản: \r\n\r\n\r\nVăn bản đầu vào Tóm tắt \r\n\r\nThe coffee tasted great and was at such a good price! I highly \r\n\r\nrecommend this to everyone! \r\n\r\ngreat coffee great \r\n\r\nprice \r\n\r\nThis saltwater taffy had great flavors and was very soft and \r\n\r\nchewy. Each candy was individually wrapped well. None of the \r\n\r\ncandies were stuck together, which did happen in the expensive \r\n\r\nversion, Fralinger's. Would highly recommend this candy! I \r\n\r\nserved it at a beach-themed party and everyone loved it! \r\n\r\ngreat candy \r\n\r\nRight now I'm mostly just sprouting this so my cats can eat the \r\n\r\ngrass. They love it. I rotate it around with Wheatgrass and Rye \r\n\r\ntoo. \r\n\r\ncats love it \r\n\r\nThis is a very healthy dog food. Good for their digestion. Also \r\n\r\ngood for small puppies. My dog eats her required amount at \r\n\r\nevery feeding. \r\n\r\nhealthy dog food \r\n\r\n\r\n\r\n \r\n53 \r\n\r\nGood flavor! These came securely packed. They were fresh and \r\n\r\ndelicious! I love these Twizzlers! \r\n\r\nfresh and \r\n\r\ndelicious \r\n\r\nGood oatmeal. I like the apple cinnamon the best. Though I \r\n\r\nwouldn't follow the directions on the package since it always \r\n\r\ncomes out too soupy for my taste.  That could just be me since \r\n\r\nI like my oatmeal really thick to add some milk on top of. \r\n\r\ngood oatmeal \r\n\r\nDeal was awesome!  Arrived before Halloween as indicated \r\n\r\nand was enough to satisfy trick or treaters.  I love the quality of \r\n\r\nthis product and it was much less expensive than the local \r\n\r\nstore's candy. \r\n\r\ngreat deal \r\n\r\nThis product serves me well as a source of electrolytes during \r\n\r\nand after a long run or bike ride. I have tried all of the flavors \r\n\r\nbut really do like the grapefruit flavor... no after-taste and I \r\n\r\nactually like the slight carbonation. I use other Hammer \r\n\r\nproducts and really like their whole product line. \r\n\r\ngreat flavor \r\n\r\nThese taste really good. I have been purchasing a different \r\n\r\nbrand and these are very similar in taste and texture. I agree \r\n\r\nwith the other reviewer regarding ordering in the summer. \r\n\r\nThere is no insulating packaging with ice packs so they will \r\n\r\nmelt in warm weather like all chocolate food items. Order in \r\n\r\ncold weather and buy enough to last!!! \r\n\r\ngreat taste \r\n\r\nWe have three dogs and all of them love this food!  We bought \r\n\r\nit specifically for one of our dogs who has food allergies and it \r\n\r\nworks great for him, no more hot spots or tummy problems. I \r\n\r\nlove that it ships right to our door with free shipping. \r\n\r\ndogs love it \r\n\r\n\r\n\r\n \r\n54 \r\n\r\nDon't buy just a few of these!  I order these by the case.  I can't \r\n\r\neven remember the first time I tasted an anchovy stuffed olive \r\n\r\nbut I have tried several of the brands online and this brand is \r\n\r\nmy favorite. \r\n\r\nbest olives ever \r\n\r\nFresh, a great way to get a little chocolate in my life without a \r\n\r\nmillion calories. They taste just like chocolate pudding. \r\n\r\nfresh tasting \r\n\r\nThis is the worst cheese that I have ever bought! I will never \r\n\r\nbuy it again and I hope you wont either! \r\n\r\nworst cheese ever \r\n\r\n4.4 Kiểm thử \r\n\r\nĐể kiểm thử ứng dụng Android, người viết đồ án sử dụng kỹ thuật Kiểm thử hộp đen \r\n\r\nvà Kiểm thử hộp trắng. \r\n\r\n4.4.1 Kiểm thử hộp đen \r\n\r\nKiểm thử hộp đen đối với chức năng Tóm tắt văn bản. Chức năng được kiểm thử \r\n\r\ntrong các test-case: không chọn văn bản, chọn vùng không có văn bản, chọn vùng \r\n\r\nvăn bản khi không có kết nối và có kết nối Internet. \r\n\r\n \r\n\r\n\r\n\r\n\r\n \r\n55 \r\n\r\n4.4.2 Kiểm thử hộp trắng \r\n\r\n \r\n\r\n\r\n \r\n\r\nĐồ thị nút của chương trình được thể hiện như sau: \r\n\r\n \r\n\r\n\r\nCác đường độc lập: \r\n\r\n 1  2  4 \r\n\r\n 1  3  4 \r\n\r\n\r\n\r\n \r\n56 \r\n\r\nTest-case cho đường 1: textSummary =   \r\n\r\nKết quả mong đợi: hiển thị thông báo No text to summarize. \r\n\r\nTest-case cho đường 2: textSummary = Hello World \r\n\r\nKết quả mong đợi: phương thức trả về chuỗi Hello World. \r\n\r\n4.5 Triển khai \r\n\r\nChương trình được xây dựng và thử nghiệm trên máy tính cá nhân có cấu hình và các \r\n\r\nphần mềm cần thiết như sau:  \r\n\r\n Ram: 8Gb \r\n\r\n Vi xử lý: Intel Core i7 CPU 2.60 GHz \r\n\r\n Hệ điều hành: Window 7 \r\n\r\n Phần mềm phát triển: PyCharm, Android Studio \r\n\r\n Ngôn ngữ sử dụng: Python, Java \r\n\r\n Card đồ họa: Nvidia geforce 920MX \r\n\r\n Thư viện: TensorFlow \r\n\r\n \r\n\r\n \r\n\r\nNhư vậy, Chương 4 đã trình bày quy trình triển khai mô hình tóm tắt văn bản và ứng \r\n\r\ndụng di động Android. Có thể nhận thấy, kết quả nghiên cứu khi áp dụng vào bài toán \r\n\r\nthực tế đã đạt được kết quả khả quan. \r\n\r\n\r\n\r\n \r\n57 \r\n\r\nĐể xây dựng nên sản phẩm hoàn chỉnh, trong quá trình làm đồ án, người viết đồ án \r\n\r\nđã lựa chọn các công nghệ hoặc phương pháp thực hiện phù hợp nhất đảm bảo sản \r\n\r\nphẩm có thể đạt được kết quả tốt, đồng thời chạy ổn định. Chương 5 trình bày về các \r\n\r\ncải tiến hoặc vấn đề mà sinh viên thấy tâm đắc nhất trong quá trình xây dựng đồ án. \r\n\r\n5.1 Cải tiến word embedding \r\n\r\nHiện tại, các hệ thống tóm tắt văn bản bằng Deep Learning thường sử dụng \r\n\r\nWord2Vec, một trong các công cụ sử dụng word embedding phổ biến nhất. Word2vec \r\n\r\nsử dụng một tầng ẩn, các neural ở tầng này đều là các neural tuyến tính. Các neural ở \r\n\r\ntầng đầu vào có số neural tương ứng với số từ trong tập từ điển để huấn luyện. Kích \r\n\r\nthước của tầng đầu ra bằng với kích thước tầng đầu vào.   \r\n\r\nGiả sử ta có tập từ điển để huấn luyện có V từ và N là số chiều của vector từ tương \r\n\r\nứng. Dữ liệu đầu vào đi từ tầng đầu vào đến tầng ẩn thì đi qua một ma trận WI có \r\n\r\nkích thước VxN với mỗi hàng đại diện cho một từ vựng. Tương tự, khi đi từ tầng ẩn \r\n\r\nđến đầu ra, dữ liệu sẽ đi qua một ma trận WO có kích thước NxV. Đầu vào của mạng \r\n\r\nlà một one-hot vector.  \r\n\r\nTrong khóa luận này, sinh viên sử dụng ConceptNet Numberbatch là công cụ chuyển \r\n\r\ntừ sang vector. ConceptNet Numberbatch bao gồm các vector ngữ nghĩa tiên tiến có \r\n\r\nthể được sử dụng trực tiếp như là một biểu diễn ý nghĩa của từ hoặc là điểm xuất phát \r\n\r\nChương 5 Các giải pháp và \r\n\r\nđóng góp nổi bật \r\n\r\n\r\n\r\n \r\n58 \r\n\r\ncho việc học máy tiếp theo. ConceptNet Numberbatch là một phần của dự án dữ liệu \r\n\r\nmở ConceptNet. ConceptNet cung cấp nhiều cách để tính toán với ý nghĩa từ, một \r\n\r\ntrong số đó là từ embeddings. ConceptNet Numberbatch là một bản chụp chỉ những \r\n\r\ntừ nhúng.  \r\n\r\nNó được xây dựng bằng cách sử dụng một tổ hợp kết hợp dữ liệu từ ConceptNet, \r\n\r\nWord2Vec, GloVe, và OpenSubtitles 2016, sử dụng một biến thể cho việc trang bị \r\n\r\nthêm.  \r\n\r\nDữ liệu được xây dựng dựa trên:  \r\n\r\n ConceptNet 5.5 bao gồm dữ liệu từ Wiktionary, WordNet, và nhiều người \r\n\r\nđóng góp cho dự án Open Mind Common Sense, do Rob Speer biên soạn. \r\n\r\n Glove bởi Jeffrey Pennington, Richard Socher và Christopher Manning. \r\n\r\n Word2Vec bởi Tomas Mikolov và nghiên cứu của Google. \r\n\r\n Văn bản song song từ OpenSubtitles 2016 của Pierre Lison và Jrg Tiedemann \r\n\r\nđã phân tích sử dụng fastText của Piotr Bojanowski, Edouard Grave, Armand \r\n\r\nJoulin và Tomas Mikolov. \r\n\r\nDữ liệu đa ngôn ngữ trong ConceptNet Numberbatch thể hiện 78 mã ngôn ngữ khác \r\n\r\nnhau, trong đó có cả tiếng Việt. \r\n\r\n5.2 Xây dựng server với Django \r\n\r\nTrong quá trình xây dựng đồ án, để tối ưu dung lượng cho ứng dụng bên phía người \r\n\r\ndùng, người viết đồ án đã xây dựng server để lưu model và thực hiện công việc tóm \r\n\r\ntắt văn bản. Ứng dụng bên phía client sẽ nhận nhiệm vụ gửi request là đoạn text cần \r\n\r\ntóm tắt và nhận về response là đoạn summary đã được tóm tắt. \r\n\r\nTrong đó, Django là một web framework nổi tiếng được viết hoàn toàn bằng ngôn \r\n\r\nngữ Python. Nó có nhiều ưu điểm như (i) nhanh và linh hoạt, (ii) đầy đủ các thư viện, \r\n\r\nmodule hỗ trợ, (iii) đảm bảo tính bảo mật, và (iv) khả năng mở rộng tốt. \r\n\r\n\r\n\r\n \r\n59 \r\n\r\nBên cạnh việc phát triển web nhanh, Django là một framework hỗ trợ việc phát triển \r\n\r\ncác API nhanh chóng, cấu trúc MVC rất rõ ràng. Django cho phép tạo các URL của \r\n\r\nAPI một cách dễ dàng, đồng thời Django có thể dễ dàng thêm các gói phần mềm để \r\n\r\nkết nối tới các hệ thống, cơ sở dữ liệu khác. \r\n\r\n \r\n\r\n \r\n\r\n\r\nỞ đây, chúng ta xây dựng một app đặt tên là api_textsum, thực hiện chức năng tóm \r\n\r\ntắt văn bản trên server. Kiến trúc của app cũng được thiết kế theo mô hình MVC, \r\n\r\ntrong đó file views.py để tương tác với người dùng. \r\n\r\nTuy nhiên, khả năng web host dường như là chướng ngại lớn nhất khi làm đồ án với \r\n\r\nDjango. Đối với PHP, số lượng host rất nhiều và khá rẻ. Về Django, chúng ta vẫn có \r\n\r\nnhiều sự lựa chọn như Heroku hoặc Pythonanywhere. Vậy nhưng, Heroku vẫn còn \r\n\r\n\r\n\r\n \r\n60 \r\n\r\nthiếu tính ổn định đối với host free, còn Pythonanywhere thì hạn chế về mặt dung \r\n\r\nlượng file được phép tải lên. Để đảm bảo ứng dụng được chạy ổn định, hiện tại hệ \r\n\r\nthống vẫn sử dụng localhost. \r\n\r\n5.3 Xây dựng ứng dụng Android \r\n\r\nTrong quá trình xây dựng ứng dụng Android, một trong những vấn đề sinh viên gặp \r\n\r\nphải đó là phương thức để người dùng chọn một vùng văn bản. Phương thức chọn \r\n\r\nvăn bản cần dễ thực hiện và quen thuộc với người dùng. \r\n\r\nCanvas trong Android đã cung cấp cho chúng ta các phương thức để vẽ tất cả các đối \r\n\r\ntượng hình học cơ bản như điểm, đường hoặc hình đa giác. Chính vì vậy, sinh viên \r\n\r\nđã dùng canvas để tạo một view tuỳ chỉnh theo hình vẽ từ thao tác của người dùng. \r\n\r\nNhững thành phần mà chúng ta vẽ đều sẽ được xử lý trong phương thức \r\n\r\nonDraw(Canvas canvas) của class View. \r\n\r\nTrong Java, Paint dùng để định nghĩa size, color, kiểu nét vẽ mà chúng ta sẽ sử dụng \r\n\r\nđể vẽ bởi canvas. Paint gồm một số phương thức đặc trưng như: \r\n\r\n setColor(int color): cài đặt màu cho nét vẽ. \r\n\r\n setStyle(Style style): cài đặt style cho nét vẽ, có thể chỉ vẽ đường, chỉ tô đối \r\n\r\ntượng hoặc kết hợp cả hai. \r\n\r\n setStrokeWidth(float width): cài đặt giá trị độ rộng cho nét vẽ. \r\n\r\nSau khi đã truyền tham số cho Paint xong, chúng ta vẽ các đối tượng hình học bởi \r\n\r\nphương thức canvas.drawPoint (vẽ điểm), canvas.drawLine (vẽ đường), \r\n\r\ncan","u":"http://202.191.57.85:8000/InternetData/Data/DATN/20130150_Nguyen_Nam_Anh_1527526468353.txt","downloaded":false,"m":[-1,-1],"n":"20130150_Nguyen_Nam_Anh_1527526468353.txt","o":"http://storage.googleapis.com/soict-projects/cnpm/dhcq/20130150_Nguyen_Nam_Anh_1527526468353.pdf\r"},{"saved_path":"/home/huong/InternetData/Data/tailieu.vn/docview/tailieu/2014/20140421/nguyenthuan9191/baocaodatn_8451.txt","r":4.1063232421875,"s":[[41,435,0.9189189076423645,51,0,54,1,55,"Các tiêu chí đánh giá  Độ mạch lạc (Coherence): đánh giá mức độ rõ ràng của văn bản tóm tắt, tính súc tích, khả năng có thể đọc và hiểu được của bài viết…  Độ hàm chứa thông tin (Informationess): tỉ lệ thông tin của văn bản gốc trong văn bản tóm tắt","10 Các tiêu chí đánh giá: - Độ mạch lạc (Coherence): đánh giá mức độ rõ ràng của văn bản tóm tắt, tính súc tích, khả năng có thể đọc và hiểu được của bài viết… - Độ hàm chứa thông tin (Informationess): tỉ lệ thông tin của văn bản gốc trong văn bản tóm tắt"],[44,437,0.8541666865348816,41,13,53,1,41,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 14  Độ dễ đọc hiểu (Reading Comprehence): một người được giao việc đọc văn bản kết quả, sau đó trả lời các câu hỏi, hệ thống sẽ phải cho điểm và từ đó đưa ra phần trăm những câu trả lời đúng","- Độ dễ đọc hiểu (Reading Comprehence): một người được giao việc đọc văn bản kết quả, sau đó trả lời các câu hỏi, hệ thống sẽ phải cho điểm và từ đó đưa ra phần trăm những câu trả lời đúng"],[42,436,0.9666666388511658,29,1,29,1,29," Độ liên quan (Relevance): xác định mức độ phù hợp của văn bản tóm tắt với chủ đề cho trước (chủ đề có thể là một câu truy vấn)","- Độ liên quan (Relevance): xác định mức độ phù hợp của văn bản tóm tắt với chủ đề cho trước (chủ đề có thể là một câu truy vấn)"],[175,425,0.8450704216957092,30,1,35,4,34,"Đánh giá kết quả tóm tắt Đánh giá một bản tóm tắt là một công việc khó bởi không tồn tại một bản tóm tắt lý tưởng cho một (hoặc một tập) văn bản đưa ra","Các phương pháp đánh giá Đánh giá một bản tóm tắt là một công việc khó bởi không tồn tại một bản tóm tắt lý tưởng cho một (hoặc một tập) văn bản đưa ra"],[176,426,1,13,0,12,0,12,"Hơn nữa, việc đánh giá nội dung tóm tắt cũng rất khó khăn","Hơn nữa, việc đánh giá nội dung tóm tắt cũng rất khó khăn"],[179,429,1,21,0,20,0,20,"Bên cạnh đó, khi việc đánh giá được thực hiện bởi con người thì chi phí đánh giá sẽ rất cao","Bên cạnh đó, khi việc đánh giá được thực hiện bởi con người thì chi phí đánh giá sẽ rất cao"],[178,428,1,28,0,27,0,27,"Thực tế luôn có khả năng một hệ thống sinh ra một bản tóm tắt tốt nhưng lại sai khác với bản tóm tắt do người thực hiện","Thực tế luôn có khả năng một hệ thống sinh ra một bản tóm tắt tốt nhưng lại sai khác với bản tóm tắt do người thực hiện"],[177,427,1,47,0,46,0,46,"Trường hợp kết quả là một câu trả lời cho một câu hỏi, ta có thể xác định được câu trả lời đó đúng hay sai, nhưng trong các trường hợp khác, thật khó trả lời liệu đầu ra là phải một kết quả đúng hay không","Trường hợp kết quả là một câu trả lời cho một câu hỏi, ta có thể xác định được câu trả lời đó đúng hay sai, nhưng trong các trường hợp khác, thật khó trả lời liệu đầu ra là phải một kết quả đúng hay không"],[180,430,1,44,0,43,0,43,"Mặt khác, tóm tắt văn bản còn liên quan đến tỉ lệ nén văn bản, do đó, việc đánh giá bản tóm tắt cần phải quan tâm đến vấn đề này, khi đó độ phức tạp và chi phí đánh giá sẽ tăng cao","Mặt khác, tóm tắt văn bản còn liên quan đến tỉ lệ nén văn bản, do đó, việc đánh giá bản tóm tắt cần phải quan tâm đến vấn đề này, khi đó độ phức tạp và chi phí đánh giá sẽ tăng cao"],[34,86,0.6666666865348816,7,0,6,3,9,"TỔNG QUAN VỀ TÓM TẮT VĂN BẢN TỰ ĐỘNG 2.1","2 CHƯƠNG 1: TỔNG QUAN VỀ TÓM TẮT VĂN BẢN ........................................"],[134,390,0.8985507488250732,31,0,32,0,33,"Tư tưởng chính của các phương pháp này là những đơn vị ngữ liệu nào có chứa các thành phần liên kết nhiều với các thành phần khác sẽ có độ quan trọng lớn","Tư tưởng chính của các phương pháp này là những đơn vị ngữ liệu nào có chứa các thành phần liên quan nhiều với các thành phần khác sẽ có mức độ quan trọng cao"],[136,392,0.6265060305595398,26,1,38,1,36," Phương pháp quan hệ lẫn nhau: Phương pháp này xác định mối quan hệ giữa các đoạn trong văn bản hay các câu trong đoạn với nhau thông qua các kỹ thuật thu thập thông tin ở mức văn bản","- Phương pháp sử dụng quan hệ giữa câu, đoạn Phương pháp này xác định mối quan hệ giữa các đoạn trong văn bản hay các câu trong đoạn với nhau thông qua việc tính toán mức độ liên quan giữa chúng"],[135,391,0.692307710647583,18,0,19,0,19,"Việc đánh giá các mối quan hệ sẽ dựa trên các mạng ngữ nghĩa, các quan hệ cú pháp hoặc thông qua các phương pháp xác định độ liên quan truyền thống","Việc đánh giá các mối quan hệ sẽ dựa trên các mạng ngữ nghĩa hoặc các quan hệ cú pháp"],[133,389,0.892307698726654,29,0,31,1,32,"Phương pháp cấu trúc Là các phương pháp sử dụng các mối liên hệ cấu trúc - ngữ pháp - ngữ nghĩa để xác định các đơn vị ngữ liệu quan trọng","b) Phương pháp cấu trúc Các phương pháp này sử dụng các mối liên hệ cấu trúc - ngữ pháp - ngữ nghĩa để xác định các đơn vị ngữ liệu quan trọng"],[155,412,0.7428571581840515,13,0,14,0,19,"Công việc này thường dựa trên phân tích cú pháp các thành phần trong câu","Công việc này thường dựa trên phân tích cú pháp và phân tích ngữ nghĩa các thành phần trong câu"],[123,383,0.6538461446762085,17,1,26,1,24," Minh họa - Chú thích (Comments): Trong các câu chú thích, câu minh họa cho ảnh hay đồ thị thường chứa các thông tin quan trọng","+ Minh hoạ, chú thích: trong các câu chú thích, câu minh hoạ cho ảnh hay đồ thị thường chứa các thông tin quan trọng"],[121,381,0.6769230961799622,22,3,32,6,31," Đầu - cuối đoạn (First - Last Sentence): Xác suất câu đầu đoạn hay câu cuối đoạn chứa ý chính của cả đoạn là rất lớn, đặc biệt là câu đầu đoạn","7 + Câu ở đầu hoặc cuối đoạn: xác suất câu đầu đoạn hay câu cuối đoạn chứa ý chính của cả đoạn là rất lớn, đặc biệt là câu đầu đoạn"],[122,382,0.8484848737716675,14,0,16,0,15,"Ngoài ra, các đoạn đầu và cuối trong văn bản cũng quan trọng hơn các đoạn giữa","Ngoài ra các đoạn đầu và cuối văn bản cũng quan trọng hơn các đoạn giữa"],[170,420,0.6399999856948853,32,0,38,16,55,"Các đơn vị ngữ liệu được trích rút hay giản lược từ các pha trước được liên kết lại thành đoạn theo thứ tự tiền định của chúng, không thêm bớt từ nối và cũng không sắp xếp lại các đơn vị ngữ liệu","Các phương pháp trong pha tổng hợp kết quả a) Phương pháp hiển thị phân đoạn Các đơn vị ngữ liệu được trích xuất hay giản lược từ các pha trước được liên kết lại thành đoạn theo đúng thứ tự trong văn bản gốc, không thêm bớt từ nối và cũng không sắp xếp lại"],[171,421,0.7555555701255798,34,0,48,0,39,"Văn bản kết quả của phương pháp này có độ dễ đọc dễ hiểu kém, thậm chí lủng củng về nghĩa vì các đơn vị ngữ liệu được trích rút mắc phải một số lỗi như mập mờ tham chiếu, không có từ nối hoặc là thừa từ và ngữ","Văn bản kết quả của phương pháp này có độ dễ đọc và dễ hiểu kém, thậm chí lủng củng vì các đơn vị ngữ liệu có thể bị mập mờ tham chiếu, không có từ nối hoặc thừa từ"],[115,101,0.6666666865348816,6,0,7,0,6,"Các phương pháp áp dụng trong các pha 2.7.1","Các phương pháp áp dụng trong pha phân tích"],[115,104,0.6315789222717285,6,0,7,0,6,"Các phương pháp áp dụng trong các pha 2.7.1","Các phương pháp áp dụng trong pha biến đổi ........................................"],[115,375,0.6666666865348816,6,0,7,0,6,"Các phương pháp áp dụng trong các pha 2.7.1","Các phương pháp áp dụng trong pha phân tích"],[145,401,0.6984127163887024,22,12,34,1,27,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 20 phương pháp này, các cụm trùng lặp được chọn ra, phân rã xem đâu là từ tham chiếu và từ được tham chiếu","Theo phương pháp này, các cụm trùng lặp được chọn ra, phân rã xem đâu là từ (cụm từ) tham chiếu và từ (cụm từ) được tham chiếu"],[146,402,0.9166666865348816,22,0,22,0,24,"Sau khi phân tách các cụm trùng lặp, chúng ta tạo chuỗi các từ tham chiếu đến cùng một từ được tham chiếu","Sau khi phân tách các cụm trùng lặp, chúng ta tạo chuỗi các từ (cụm từ) tham chiếu đến cùng một từ được tham chiếu"],[147,403,0.8666666746139526,26,0,29,0,29,"Chuỗi dài nhất sẽ được coi là trọng tâm của đoạn, các câu chứa các từ trong chuỗi này có một độ ưu tiên nào đó khi xét trích chọn","Chuỗi dài nhất sẽ được coi là trọng tâm của đoạn, các câu chứa các từ trong chuỗi này có một độ ưu tiên nào đó thì sẽ được chọn"],[139,395,0.767123281955719,28,1,35,1,36," Phương pháp liên kết từ vựng: Phương pháp liên kết từ vựng sử dụng các từ điển quan hệ từ vựng đế xây dựng các chuỗi từ liên kết với nhau vể mặt ngữ nghĩa","+ Phương pháp chuỗi từ vựng (lexical chains) Phương pháp liên kết từ vựng sử dụng các từ điển quan hệ từ vựng để xây dựng các chuỗi từ liên kết với nhau về mặt ngữ nghĩa"],[138,394,0.692307710647583,9,0,11,0,13,"Sau đó chọn ra đoạn (câu) có độ liên quan lớn nhất","Sau đó, ta chọn ra đoạn hay câu có độ liên quan lớn nhất"],[272,99,0.6666666865348816,6,2,7,0,5,"Hình 3: Mô hình tóm tắt văn bản hướng truy vấn","Mô hình tóm tắt văn bản .............................................................................."],[127,385,0.6666666865348816,10,0,13,0,12,"Sau các ngữ này thường là các câu hay từ có độ quan trọng là xác định","Sau các cụm từ này thường là các từ hay câu quan trọng"],[142,398,0.6341463327407837,13,5,21,1,18,"Sau khi xây dựng được các chuỗi từ này, đánh giá độ mạnh của chúng và có những trích chọn phù hợp","8 các từ vựng này, ta đánh giá độ mạnh của chúng và chọn ra những câu phù hợp"]],"t":"\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\nTRƯỜNG ĐẠI HỌC SPKT HƯNG YÊN CỘNG HÒA XÃ HỘI CHỦ NGHĨA VIỆT NAM \n\nKHOA CÔNG NGHỆ THÔNG TIN Độc lập – Tự do – Hạnh phúc \n\nĐỀ TÀI TỐT NGHIỆP ĐẠI HỌC \n\n \n\n \n\nHọ và tên sinh viên: \n\n1. Nguyễn Văn Thuấn  25/01/1991 TK7.2 \n\n2. Trần Quang Vinh 21/06/1990 TK7.2 \n\n    \n\nNgành đào tạo: Công Nghệ Thông Tin \n\nChuyên ngành: Mạng máy tính và Truyền thông \n\nKhóa học:   2009-2013 \n\nTên đề tài: TÓM TẮT VĂN BẢN DỰA VÀO TRÍCH XUẤT CÂU VÀ XÂY \n\nDỰNG ỨNG DỤNG MINH HỌA \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\nMục tiêu đề tài:  \n\n- Tìm hiểu cơ sở lý thuyết của phương pháp tóm tắt văn bản dựa vào trích xuất câu \n\nbao gồm: Tổng quan về tóm tắt văn bản, các mô hình tóm tắt, đặc điểm Tiếng Việt, \n\nphương pháp sử dụng trong tóm tắt văn bản. \n\n- Xây dựng được phần mềm tóm tắt văn bản dựa vào trích xuất các câu quan trọng \n\ntrong văn bản theo một tỷ lệ nén nhất định. \n\nNội dung cần hoàn thành: \n\n1. Phần thuyết minh: \n\n- Cuốn báo cáo Đồ án tốt nghiệp được trình bày theo đúng quy định. Báo \n\ncáo được trình bày được ý tưởng và cách giải quyết các bài toán trong \n\nquá trình thực hiện đề tài, các phương pháp đánh giá văn bản tóm tắt với \n\ncác phương pháp tóm tắt khác. \n\n- Báo các được trình bày gồm 3 phần:  \n\nPhần 1: Mở đầu \n\n- Lý do chọn đề tài. \n\n- Mục đích nghiên cứu. \n\n- Nhiệm vụ nghiên cứu. \n\n- Phươn pháp nghiên cứu. \n\n Phần 2: Nội dung \n\n- Tổng quan về tóm tắt văn bản. \n\n- Bài toán tóm tắt văn bản tiếng việt. \n\n- Ứng dụng phương pháp cấu trúc để tóm tắt văn bản Tiếng Việt. \n\n- Xây dựng ứng dụng minh họa. \n\n- Thực nghiệm và đánh giá. \n\nPhần 3: Kết luận. \n\n- Kết quả đạt được. \n\n- Những hạn chế của đề tài. \n\n- Hướng phát triển của đề tài. \n\n2. Phần thực hành, cài đặt: \n\n- Xây dựng phần mềm giải quyết được bài toán trong tóm tắt văn bản áp \n\ndụng phương pháp trích xuất câu. \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\n- Cài đặt các công cự hỗ trợ tách từ tách câu. \n\n- Trích xuất ra được văn bản tóm tắt theo tỉ lệ % tùy chọn với độ chính xác \n\nvà đáng tin cậy cao. \n\n3. Sản phẩm chính: \n\n- Phần mềm Tóm tắt văn bản áp dụng phương pháp trích xuất câu hoàn \n\nchỉnh. \n\nDự kiến kính phí:  \n\nThời gian thực hiện:  Ngày giao:...../...../..........., ngày hoàn \n\nthành ....../....../.......... \n\nNgười hướng dẫn: \n\n- Thứ nhất: Nguyễn Thị Thanh Huệ                Ký xác \n\nnhận:.............................. \n\n- Thứ hai:........................................................Ký xác \n\nnhận:.............................. \n\nĐề tài đã được Hội đồng Khoa học và Đào tạo Khoa thông qua. \n\n \nTRƯỞNG KHOA \n\n(Ký, ghi rõ họ và tên) \n\nHưng Yên, ngày .... tháng .... năm ........ \nTRƯỞNG BỘ MÔN \n(Ký, ghi rõ họ và tên) \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\n \n\nMỞ ĐẦU \n\n \n\nNgày nay, với sự phát triển như vũ bão của công nghệ thông tin, \n\nInternet cũng như các dịch vụ trực tuyến, ngày càng có nhiều thông tin được \n\ntạo ra. Ta có thể truy cập các thông tin đó qua sách, báo, Internet và các \n\nphương tiện truyền thông. Hơn nữa, nhu cầu đọc, tìm kiếm và lưu trữ thông \n\ntin của con người cũng ngày càng tăng lên. Tuy nhiên, với một lượng lớn \n\nthông tin như vậy thì người ta không thể nào có đủ thời gian và sức lực để \n\nđọc hết được chúng. Giải pháp là tóm tắt lại các văn bản đó, từ đó giúp tiết \n\nkiệm thời gian và công sức nhưng vẫn có thể đọc và xử lý được nhiều văn \n\nbản.  \n\nTóm tắt văn bản tự động đã bắt đầu được nghiên cứu từ những năm 50 \n\ncủa thế kỉ trước. Đã có nhiều công trình nghiên cứu về lĩnh vực này và có \n\nđược những kết quả đáng kể. Tóm tắt văn bản đã được sử dụng trong các \n\nphần mềm xử lý văn bản (Microsoft Office Word…), trong khai phá cơ sở \n\ndữ liệu văn bản (Oracle…), trong các ứng dụng tìm kiếm thông tin trực tuyến \n\n(hệ thống tìm kiếm Google, Yahoo…) và đều thu được những kết quả rất \n\nđáng khích lệ . Vì vậy, chúng em chọn đề tài: “Tóm tắt văn bản dựa vào \n\ntrích xuất câu và xây dựng ứng dụng minh họa” nhằm nghiên cứu những \n\nvấn đề tổng quan về xử lý ngôn ngữ tự nhiên và một số phương pháp tóm tắt \n\nvăn bản. Với sự hướng dẫn của cô Nguyễn Thị Thanh Huệ. \n\n \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\nLỜI CẢM ƠN \n\n \n\nSau một thời gian tìm hiểu và thực hiện đến nay đề tài “TÓM TẮT VĂN \n\nBẢN DỰA VÀO TRÍCH XUẤT CÂU VÀ XÂY DỰNG ỨNG DỤNG MINH \n\nHỌA” đã hoàn thành. Trong suốt quá trình thực hiện đề tài, chúng em đã nhận \n\nđược rất nhiều sự giúp đỡ nhiệt tình. \n\nChúng em xin chân thành cảm ơn các thầy các cô đã trang bị những kiến thức \n\nquý báu cho chúng em trong suốt quá trình học tập tại trường Đại học Sư phạm Kỹ \n\nthuật Hưng Yên. Đặc biệt là các thầy các cô trong khoa Công nghệ thông tinđã tận \n\ntình giảng dạy, chỉ bảo, trang bị cho chúng em những kiến thức cần thiết nhất trong \n\nsuốt quá trình học tập và nghiên cứu tại khoa, đã tạo mọi điều kiện thuận lợi giúp \n\nchúng em thực hiện đề tài này.  \n\nChúng em xin cảm ơn cô Nguyễn Thị Thanh Huệ đã tận tình hướng dẫn, chỉ \n\nbảo chúng em trong suốt thời gian thực hiện đề tài, giúp chúng em có thể hoàn \n\nthành đề tài này. \n\nMặc dù đã cố gắng nỗ lực thực hiện đề tài với quyết tâm cao nhưng chắc hẳn \n\nđề tài không thể tránh khỏi thiếu sót, kính mong sự đóng góp và hướng dẫn của các \n\nthầy cô. \n\n \n\n                                                        Chúng em xin chân thành cảm ơn! \n\n                                                            Hưng Yên, tháng 08 năm 2013 \n\n                                                               Nhóm sinh viên thực hiện \n\n                                                 Nguyễn Văn Thuấn \n\n                                                               Trần Quang Vinh \n\n  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\nNHẬN XÉT CỦA GIẢNG VIÊN HƯỚNG DẪN \n\n \n\n \n\n………………………………………………………………………………………\n\n………………………………………………………………………………………\n\n………………………………………………………………………………………\n\n………………………………………………………………………………………\n\n………………………………………………………………………………………\n\n………………………………………………………………………………………\n\n………………………………………………………………………………………\n\n………………………………………………………………………………………\n\n………………………………………………………………………………………\n\n………………………………………………………………………..………………\n\n………………………………………………………………………………………\n\n………………………………………………………………………………………\n\n………………………………………………………………………………………\n\n………………………………………………………………………………………\n\n……………..…………………………………………………………………………\n\n………………………………………………………………………………………\n\n………………………………………………………………………………………\n\n………………………………………………………………………………………\n\n…………………………………………..……………………………………………\n\n………………………………………………………………………………………\n\n………………………………………………………………………………………\n\n………………………………………………………………………………………\n\n………………………………………………………………………..………………\n\n………………………………………………………………………………………\n\n………………………………………………………………………………………\n\n………………………………………………………………………………………\n\n………………………………………………………………………………………\n\n…………….…………………………………………………………………………\n\n…………………..……………………………………………………………………\n\n……………………………………………………………………  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\nNHẬN XÉT CỦA GIẢNG VIÊN PHẢN BIỆN \n\n \n\n \n\n …………………………………………………………………………………….. \n\n……………………………………………………………………………………… \n\n……………………………………………………………………………………… \n\n……………………………………………………………………………………… \n\n……………………………………………………………………………………… \n\n……………………………………………………………………………………… \n\n……………………………………………………………………………………… \n\n……………………………………………………………………………………… \n\n……………………………………………………………………………………… \n\n……………………………………………………………………………………… \n\n……………………………………………………………………………………… \n\n……………………………………………… \n\n  \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\nNHẬN XÉT CỦA GIẢNG VIÊN PHẢN BIỆN \n\n \n\n \n\n …………………………………………………………………………………….. \n\n……………………………………………………………………………………… \n\n……………………………………………………………………………………… \n\n……………………………………………………………………………………… \n\n……………………………………………………………………………………… \n\n……………………………………………………………………………………… \n\n……………………………………………………………………………………… \n\n……………………………………………………………………………………… \n\n……………………………………………………………………………………… \n\n……………………………………………………………………………………… \n\n……………………………………………………………………………………… \n\n……………………………………………… \n\n  \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\nMỤC LỤC \n\nPHẦN 1: MỞ ĐẦU ................................................................................................. 1 \n\n1. Lý do chọn đề tài. ........................................................................................ 1 \n\n2. Khách thể và đối tượng nghiên cứu .................................................................. 1 \n\n3. Giới hạn và phạm vi nghiên cứu ...................................................................... 1 \n\n4. Mục đích nghiên cứu ....................................................................................... 1 \n\n5. Nhiệm vụ nghiên cứu ....................................................................................... 1 \n\n6. Phương pháp nghiên cứu ................................................................................. 1 \n\n7. Ý nghĩa lý luận và thực tiễn của đề tài ............................................................. 1 \n\nPHẦN 2: NỘI DUNG ............................................................................................. 2 \n\nCHƯƠNG 1: TỔNG QUAN VỀ TÓM TẮT VĂN BẢN ......................................... 2 \n\n1.1. Tổng quan. .................................................................................................... 2 \n\n1.1.1. Khái niệm. ............................................................................................. 2 \n\n1.1.2. Lịch sử phát triển của tóm tắt văn bản .................................................... 2 \n\n1.1.3. Phân loại các phương pháp tóm tắt văn bản. ........................................... 4 \n\n1.2. Mô hình tóm tắt văn bản ............................................................................... 6 \n\n1.2.1. Các phương pháp áp dụng trong pha phân tích. ...................................... 6 \n\n1.2.2. Các phương pháp áp dụng trong pha biến đổi ......................................... 8 \n\n1.2.3. Các phương pháp trong pha tổng hợp kết quả......................................... 9 \n\n1.3. Các phương pháp đánh giá ............................................................................ 9 \n\n1.3.1. Các phương pháp đánh giá trong .......................................................... 10 \n\n1.3.2. Các phương pháp đánh giá ngoài ......................................................... 11 \n\n1.4. Kết luận ...................................................................................................... 12 \n\nCHƯƠNG 2 : BÀI TOÁN TÓM TẮT VĂN BẢN  TIẾNG VIỆT ..................... 13 \n\n2.1. Một số hướng tiếp cận bài toán tóm tắt văn bản .......................................... 13 \n\n2.2. Đặc điểm tiếng Việt .................................................................................... 13 \n\n2.2.1. Đặc điểm chung ................................................................................... 14 \n\n2.2.2. Yếu tố ngoại lai trong từ tiếng Việt ...................................................... 15 \n\n2.2.3. Từ dừng. .............................................................................................. 15 \n\n2.2.4. Từ đồng nghĩa. ..................................................................................... 15 \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\n2.2.5. Đặc điểm chính tả ................................................................................ 17 \n\n2.3. Phương pháp cho bài toán tóm tắt văn bản tiếng Việt. ................................. 18 \n\n2.4. Kết luận. ..................................................................................................... 20 \n\nCHƯƠNG 3: ỨNG DỤNG PHƯƠNG PHÁP CẤU TRÚC ĐỂ TÓM TẮT VĂN \n\nBẢN TIẾNG VIỆT ............................................................................................... 22 \n\n3.1. Mô hình tóm tắt sử dụng phương pháp cấu trúc .......................................... 22 \n\n3.2. Tiền xử lý văn bản ...................................................................................... 23 \n\n3.3. Xử lý từ ...................................................................................................... 24 \n\n3.4. Xây dựng đồ thị liên kết. ............................................................................. 25 \n\n3.5. Sinh văn bản tóm tắt. .................................................................................. 28 \n\n3.6. Kết luận. ..................................................................................................... 34 \n\nCHƯƠNG 4: XÂY DỰNG ỨNG DỤNG MINH HỌA ......................................... 35 \n\n4.1. Một số giao diện chính của hệ thống. .......................................................... 35 \n\n4.1.1. Giao diện chính của chương trình. ........................................................ 35 \n\n4.1.2. Giao diện form quản lý từ điển từ dừng, từ đồng nghĩa. ....................... 35 \n\n4.1.3. Giao diện form tách từ, tách câu. .......................................................... 36 \n\n4.1.4. Giao diện form loại từ dừng, từ đồng nghĩa. ......................................... 36 \n\n4.1.5. Giao diện form xây dựng đồ thị liên kết. .............................................. 37 \n\n4.1.6. Giao diện form tóm tắt văn bản. ........................................................... 37 \n\n4.1.7. Giao diện form đánh giá độ chính xác. ................................................. 38 \n\n4.2. Một số module chính của chương trình. ...................................................... 38 \n\n4.2.1. Module tóm tắt văn bản. ....................................................................... 38 \n\n4.2.2. Module quản lý từ dừng, từ đồng nghĩa ................................................ 39 \n\n4.2.3. Module đánh giá hệ thống tóm tắt. ....................................................... 39 \n\n4.3. Kết luận. ..................................................................................................... 39 \n\nCHƯƠNG 5: THỰC NGHIỆM VÀ ĐÁNH GIÁ ............................................... 40 \n\n5.1. Môi trường thử nghiệm. .............................................................................. 40 \n\n5.2. Dữ liệu thử nghiệm ..................................................................................... 40 \n\n5.3. Phương pháp đánh giá. ................................................................................ 40 \n\n5.4. Kết quả thực nghiệm. .................................................................................. 43 \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\n5.4.1. Thử nghiệm xác định ngưỡng. .............................................................. 43 \n\n5.4.2. Đánh giá kết quả thử nghiệm đối với từng phiên bản. ........................... 44 \n\n5.5. Kết luận. ..................................................................................................... 48 \n\nPHẦN 3: KẾT LUẬN ........................................................................................... 49 \n\n1. Kết quả đạt được. ....................................................................................... 49 \n\n2. Những hạn chế của đề tài. .......................................................................... 49 \n\n3. Hướng phát triển của đề tài. ....................................................................... 49 \n\nTÀI LIỆU THAM KHẢO ..................................................................................... 51 \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\nDANH MỤC CÁC TỪ VIẾT TẮT \n\n \n\nTừ viết tắt Viết đầy đủ Ý nghĩa \n\nCSDL Cơ sở dữ liệu  \n\nIR Information Retrieval Trích xuất thông tin \n\nISF \nInverse sentence \n\nfrequency \n\nNghịch đảo tần số câu \n\nLRMM \nLeft Right Maximum \n\nMatching \n\nPhương pháp so khớp \n\ncực đại \n\nTF \nTerm frequency Tần số từ khóa \n\n \n\nWFST \n\nWeighted Finite State \n\nTransducer \n\nPhương pháp sử dụng \n\nbộ chuyển trạng thái \n\nhữu hạn có trọng số \n\n \n\n \n\n \n\n  \n\n \n\n \n\n \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\nDANH MỤC BẢNG BIỂU \n\nBảng 3.1: Bậc của các đỉnh sắp xếp theo thứ tự giảm dần của văn bản input1.txt... 30 \n\nBảng 3.2: Phân chia đoạn của văn bản input1.txt ................................................... 33 \n\nBảng 5.1: Đánh giá sự liên quan của văn bản tóm tắt và văn bản đối sánh. ............ 41 \n\nBảng 5.2: Kết quả đánh giá thử nghiệm với các ngưỡng khác nhau. ...................... 43 \n\nBảng 5.3: Đánh giá kết quả tóm tắt của Microsoft office 2007............................... 45 \n\nBảng 5.4: Kết quả thử nghiệm phiên bản 1. ........................................................... 45 \n\nBảng 5.5:  Kết quả thử nghiệm phiên bản 2. .......................................................... 46 \n\nBảng 5.6: Kết quả thử nghiệm phiên bản 3 ............................................................ 47 \n\nBảng 5.7: Bảng so sánh kết quả giữa MS Office 2007 với các phiên bản ............... 47 \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\nDANH MỤC HÌNH ẢNH \n\nHình 1.1  Kiến trúc của hệ thống tóm tắt văn bản tự động ....................................... 6 \n\nHình  2.1  Đồ thị liên kết các câu trong văn bản. .................................................... 20 \n\nHình 3.1  Mô hình tóm tắt văn bản sử dụng phương pháp cấu trúc ........................ 22 \n\nHinh 3.2: Đồ thị liên kết của văn bản input1.txt ..................................................... 28 \n\nHình 4.1: Giao diện chính của chương trình. ......................................................... 35 \n\nHình 4.2: Giao diện quản lý từ dừng. ..................................................................... 35 \n\nHình 4.3: Giao diện tách từ tách câu ...................................................................... 36 \n\nHình 4.4: Loại bỏ từ dừng, từ đồng nghĩa trong văn bản ........................................ 36 \n\nHình 4.5: Giao diện form xây dựng đồ thị liên kết cho văn bản. ............................ 37 \n\nHình 4.6: Giao diện tóm tắt văn bản. ..................................................................... 37 \n\nHình 4.7: Đánh giá độ chính xác của văn bản tóm tắt ............................................ 38 \n\nHình 5.1: Tóm tắt văn bản input1.txt bởi con người. .............................................. 42 \n\nHình 5.2: Đồ thị hàm điều hòa với các ngưỡng. ..................................................... 44 \n\nHình 5.3: Đồ thị so sánh hàm điều hòa của MS Office 2007 với các phiên bản ...... 48 \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n1 \n\n \n\nPHẦN 1: MỞ ĐẦU \n\n1. Lý do chọn đề tài. \n\nNgày nay, với sự phát triển như vũ bão của công nghệ thông tin, Internet \n\ncũng như các dịch vụ trực tuyến, ngày càng có nhiều thông tin được tạo ra. Ta có \n\nthể truy cập các thông tin đó qua sách, báo, Internet và các phương tiện truyền \n\nthông. Hơn nữa, nhu cầu đọc, tìm kiếm và lưu trữ thông tin của con người cũng \n\nngày càng tăng lên. Tuy nhiên, với một lượng lớn thông tin như vậy thì người ta \n\nkhông thể nào có đủ thời gian và sức lực để đọc hết được chúng. Giải pháp là tóm \n\ntắt lại các văn bản đó, từ đó giúp tiết kiệm thời gian và công sức nhưng vẫn có thể \n\nđọc và xử lý được nhiều văn bản.  \n\nTóm tắt văn bản tự động đã bắt đầu được nghiên cứu từ những năm 50 của \n\nthế kỉ trước. Đã có nhiều công trình nghiên cứu về lĩnh vực này và có được những \n\nkết quả đáng kể. Tóm tắt văn bản đã được sử dụng trong các phần mềm xử lý văn \n\nbản (Microsoft Office Word…), trong khai phá cơ sở dữ liệu văn bản (Oracle…), \n\ntrong các ứng dụng tìm kiếm thông tin trực tuyến (hệ thống tìm kiếm Google, \n\nYahoo…) và đều thu được những kết quả rất đáng khích lệ . Vì vậy, chúng tôi chọn \n\nđề tài: “Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa” \n\nnhằm nghiên cứu những vấn đề tổng quan về xử lý ngôn ngữ tự nhiên và một số \n\nphương pháp tóm tắt văn bản.  \n\n2. Khách thể và đối tượng nghiên cứu \n\nCác văn bản, các kỹ thuật tóm tắt văn bản, các phương pháp tóm tắt văn bản. \n\n3. Giới hạn và phạm vi nghiên cứu \n\nNghiên cứu các kỹ thuật tóm tắt văn bản dựa vào trích xuất câu. \n\nTóm tắt văn bản trên ngôn ngữ Tiếng Việt \n\n4. Mục đích nghiên cứu \n\nVới đề tài “Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng \n\nminh họa” sẽ trích xuất được các nội dung chính của văn bản mà người dùng nhập \n\nvào, giảm thời gian tìm kiếm thông tin trên đoạn văn bản dài của người đọc. \n\n5. Nhiệm vụ nghiên cứu\n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n1 \n\n \n\n \n\nVận dụng các kiến thức về tóm tắt văn bản để xây dựng ứng dụng minh họa \n\ntóm tắt văn bản. \n\n6. Phương pháp nghiên cứu \n\n- Nghiên cứu tài liệu trên internet, các kĩ thuật tóm tắt văn bản đã có. \n\n- Tham khảo ý kiến của các thầy cô trong trường. \n\n7. Ý nghĩa lý luận và thực tiễn của đề tài   \n\n- Ý nghĩa lý luận của đề tài \n\nChương trình cùng với lý thuyết tổng quan về Tóm tắt văn bản sẽ trở thành một \n\ntài liệu nghiên cứu, tham khảo nhanh, dễ hiểu, thiết thực cho người đọc. \n\n- Ý nghĩa thực tiễn của đề tài \n\nVề mặt ứng dụng sẽ cung cấp cho người dùng một phần mềm giúp cho người \n\nđọc có thể tóm tắt nội dung chính của văn bản một cách nhanh chóng, dễ dàng \n\nkhông tốn thời gian cần đọc cả đoạn văn bản dài. \n\n \n\n \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n2 \n\n \n\nPHẦN 2: NỘI DUNG \n\nCHƯƠNG 1: TỔNG QUAN VỀ TÓM TẮT VĂN BẢN \n\n1.1.  Tổng quan. \n\n1.1.1.  Khái niệm.  \n\nTóm tắt văn bản là một lĩnh vực của xử lý ngôn ngữ tự nhiên, đã được bắt \n\nđầu nghiên cứu từ những năm 50 của thế kỉ trước. Có nhiều định nghĩa về tóm tắt \n\nvăn bản:  \n\nĐịnh nghĩa tóm tắt văn bản là quá trình rút trích ra các thông tin quan trọng \n\ntừ một hoặc nhiều văn bản để tạo ra văn bản ngắn gọn cho mỗi hoặc nhóm người \n\ndùng, cho từng tác vụ hay nhiều tác vụ khác nhau. \n\nĐịnh nghĩa hệ thống tóm tắt văn bản là hệ thống đưa ra dạng biểu diễn ngắn \n\ngọn của thông tin đầu vào căn cứ theo yêu cầu của người dùng. \n\n Radev (2002) định nghĩa văn bản tóm tắt là văn bản được tạo từ một hoặc \n\nnhiều văn bản khác mà truyền tải được những thông tin quan trọng trong văn bản \n\ngốc nhưng có độ dài không quá ½ văn bản gốc (thường ngắn hơn đáng kể). \n\nTheo Partha Lal (2002)  thì tóm tắt văn bản là việc thể hiện nội dung văn bản dưới \n\ndạng giản lược một cách tự động nhằm đáp ứng yêu cầu nào đó từ phía người dùng.  \n\nĐỗ Phúc, Hoàng Kiếm (2006)  định nghĩa tóm tắt văn bản tự động là việc tìm \n\ncác ý chính của văn bản. Tựu chung lại, có ba đặc điểm quan trọng cần phải xem \n\nxét trong hệ thống tóm tắt văn bản:  \n\n1) Bản tóm tắt có thể được tạo ra từ một hoặc nhiều văn bản. \n\n2) Bản tóm tắt cần truyền tải các thông tin quan trọng.  \n\n3) Bản tóm tắt cần phải ngắn.  \n\n1.1.2. Lịch sử phát triển của tóm tắt văn bản  \n\nTóm tắt văn bản bắt đầu từ những năm cuối thập kỉ 1950 với nghiên cứu của \n\nLuhn (1958)  dựa trên tần số từ. Ý tưởng cơ bản của phương pháp tần số từ dựa trên \n\nkiến thức cho rằng tần số của từng từ trong văn bản là một độ đo hữu dụng để đánh \n\ngiá tầm quan trọng của chúng.  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n3 \n\n \n\nTiếp theo đó là phương pháp tóm tắt dựa trên vị trí của các câu trong văn bản \n\ncủa Baxendale (1958), và những nghiên cứu của Edmundson (1969)  về vị trí của \n\ncác câu trong văn bản và các từ/cụm từ mang ý nghĩa tổng quát (từ/cụm từ dấu hiệu). \n\nTheo đó, những câu bắt đầu và kết thúc của đoạn văn/bài viết hay những câu chứa \n\nnhững từ như “important” (đặc biệt), “result are” (kết quả là), “paper introduce” \n\n(bài báo giới thiệu về)… là những câu có ý nghĩa quan trọng.  \n\nĐầu những năm 1970, tiếp tục có những nghiên cứu với hướng tiếp cận \n\nngoài (sử dụng các cụm từ dấu hiệu) và được ứng dụng trong các phần mềm thương \n\nmại (Pollock và Zamora). \n\n Những năm 1980, phát triển nhiều nghiên cứu với nhiều hướng khác nhau, \n\nđặc biệt là hướng tiếp cận mức thực thể dựa trên trí tuệ nhân tạo như sử dụng script \n\n(Lehnert 1981), (DeJong 1982), các luật sản xuất và logic (Fum 1985), mạng ngữ \n\nnghĩa (Reimer và Hahn 1988), cũng như các hướng tiếp cận kết hợp (Rau 1989) hay \n\n(Aretoulaki 1994). Willam B. Cavnar (1994): biểu diễn văn bản dựa trên n-gram \n\nthay cho cách biểu diễn truyền thống bằng từ khoá.  \n\nChinatsu Anoe (1997) đã phát triển hệ DimSum để tóm tắt văn bản sử dụng \n\nxử lý ngôn ngữ tự nhiên và kĩ thuật thống kê dựa trên hệ thống tf-idf, sử dụng \n\nWordNet để xem xét ngữ nghĩa của từ và đề xuất một số kĩ thuật lượng giá.  \n\nJaine Carbonell (1998) đã tóm tắt văn bản bằng cách xếp hạng các câu trội \n\n(câu chứa các ý chính của văn bản) và rút ra các câu trội.  \n\nJade Goldstein (1999): phân loại tóm tắt dựa trên độ đo liên quan, phương \n\npháp sử dụng kết hợp giữa ngữ học, thống kê. Mỗi câu được đặc trưng bằng các đặc \n\ntính ngữ học và độ đo thống kê.  \n\nJ.Larocca Neto (2000) đã tạo tóm tắt văn bản dựa trên các dãy từ trong câu \n\nđược chọn theo hệ số tf, sau đó dùng kỹ thuật gom cụm (clustering) để tạo tóm tắt. \n\n Yoshio (2001) đã tạo tóm tắt văn bản tiếng Nhật. Có 2 phương pháp là rút \n\ncâu dựa trên từ khoá và rút câu dựa trên kiến trúc ngữ nghĩa trong đó có xây dựng \n\nđộ đo mối liên kết giữa hai từ.  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n4 \n\n \n\nHiện nay, một số nghiên cứu về xử lý ngôn ngữ tự nhiên cũng bước đầu \n\nđược áp dụng trong tóm tắt văn bản. Mặt khác, các nghiên cứu về tóm tắt đa văn \n\nbản, đa ngôn ngữ và tóm tắt đa phương tiện cũng bắt đầu phát triển. \n\n1.1.3. Phân loại các phương pháp tóm tắt văn bản. \n\n Có nhiều tiêu chí để phân loại các phương pháp tóm tắt văn bản, sau đây là \n\nmột số cách phân loại tiêu biểu:  \n\nCăn cứ vào dạng tóm tắt, ta có thể chia thành:  \n\n- Trích xuất (extract): bản tóm tắt hoàn toàn chứa các “dãy từ” được sao chép \n\nnguyên dạng từ văn bản nguồn. “Dãy từ” ở đây có thể là cụm từ, câu hoặc đoạn văn. \n\nTuy nhiên, với dạng trích xuất thì văn bản tóm tắt thiếu cấu kết cần thiết, các câu \n\nđược trích ra có thể không phản ánh nội dung. Nói chung văn bản tóm tắt không \n\nđược “trơn” do được “lắp ghép” từ các câu, đoạn văn được trích ra. \n\n - Tóm tắt (abstracts): văn bản tóm tắt nói chung là không chứa các “dãy từ” \n\ntrong văn bản nguồn mà là được “viết lại” một cách tự động. Với dạng này, người ta \n\ncần nhiều kĩ thuật xử lý ngôn ngữ. Hiện tại, đây vẫn là vấn đề khó, chưa thể giải \n\nquyết được một cách triệt để. \n\n Căn cứ vào mức độ xử lý, có thể chia thành 2 dạng:  \n\n- Tiếp cận mức ngoài (surface-level): thông tin được miêu tả dưới dạng khái \n\nniệm về các đặc trưng nông (shallow feature). Các đặc trưng nông bao gồm các \n\nthuật ngữ (term) quan trọng qua thống kê (dựa vào tần số của các thuật ngữ trong \n\nvăn bản), các thuật ngữ quan trọng dựa vào vị trí, các thuật ngữ trong các cụm từ \n\ndấu hiệu hay các thuật ngữ trong câu truy vấn của người dùng. Kết quả là một bản \n\ntóm tắt dạng trích xuất (extract). \n\n - Tiếp cận mức sâu (deeper-level): ở mức này, bản tóm tắt có thể là dạng \n\ntrích xuất hoặc dạng tóm tắt (abstract) và cần phải sử dụng đến sinh tổng hợp ngôn \n\nngữ tự nhiên. Với dạng tiếp cận này, phải cần đến những phân tích về mặt ngữ \n\nnghĩa, chẳng hạn sử dụng hướng tiếp cận thực thể để xây dựng dạng biểu diễn của \n\ncác thực thể văn bản (đơn vị văn bản) và mối quan hệ giữa các thực thể rồi từ đó tìm \n\nra phần quan trọng. Mối quan hệ giữa các thực thể gồm quan hệ ngữ nghĩa như: \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n5 \n\n \n\nđồng nghĩa, trái nghĩa, nghĩa hẹp, nghĩa rộng…, quan hệ cú pháp: dựa trên cây phân \n\ntích cú pháp và các mối quan hệ khác.  \n\nCăn cứ vào mục đích của bản tóm tắt, có thể chia làm 3 dạng: \n\n - Trình bày sơ lược (indicative): Đưa ra những thông tin ngắn gọn về chủ đề \n\nchính của văn bản. Dạng tóm tắt này thường được sử dụng trong các hệ thống tìm \n\nkiếm thông tin. Thông thường, độ dài của văn bản tóm tắt loại này chỉ từ 5 đến 10% \n\nđộ dài của toàn bộ văn bản.  \n\n- Tóm tắt cung cấp tin tức (Informative): Cung cấp các chủ đề con của toàn \n\nbộ văn bản, kiểu tóm tắt này có độ dài từ 20-30% văn bản gốc.  \n\n- Phê bình và đánh giá: Văn bản tóm tắt đưa ra những quan điểm của người \n\ntóm tắt về chủ đề được đưa ra. Tuy nhiên, kiểu tóm tắt này dường như vượt quá tầm \n\ncủa các hệ thống tóm tắt tự động hiện nay.  \n\nViệc phân loại tóm tắt dựa theo mục đích như trên không loại trừ lẫn nhau, \n\ncó thể một bản tóm tắt vừa có chức năng cung cấp tin tức lại vừa là kiểu trình bày \n\nsơ lược.  \n\nCăn cứ vào người sử dụng, có thể chia thành các dạng: \n\n- Tóm tắt chung: với kiểu tóm tắt này thì mọi chủ đề chính trong văn bản đều \n\ncó tầm quan trọng như nhau, văn bản tóm tắt hướng đến một cộng đồng đông đảo \n\nngười đọc. \n\n - Tóm tắt dựa trên câu truy vấn: kết quả trả về dựa trên câu truy vấn của \n\nngười dùng.  \n\n- Tóm tắt hướng đến người dùng hoặc chủ đề: văn bản tóm tắt đáp ứng nhu \n\ncầu của người dùng cụ thể hoặc chủ đề cụ thể nào đó.  \n\nCăn cứ vào số lượng văn bản tóm tắt:  \n\nTóm tắt đơn văn bản: thực hiện tóm tắt trên một văn bản hoặc tóm tắt đa văn \n\nbản: thực hiện tóm tắt trên nhiều văn bản khác nhau.  \n\nCăn cứ vào ngôn ngữ tóm tắt:  \n\nTóm tắt trên một ngôn ngữ hoặc tóm tắt trên nhiều ngôn ngữ khác nhau. \n\n \n\n  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n6 \n\n \n\n1.2.  Mô hình tóm tắt văn bản       \n\n \n\n \n\n                                        \n\n \n\n \n\n \n\n \n\nHình 1.1  Kiến trúc của hệ thống tóm tắt văn bản tự động  \n\nĐầu vào của hệ thống có thể là một hoặc nhiều tài liệu, văn bản hay các \n\nthông tin đa phương tiện như ảnh, âm thanh, video. Hệ thống tóm tắt hiện nay \n\nthường tập trung vào việc xử lý đầu là văn bản (có thể mở rộng cho các thông tin \n\ndạng khác). Điều quan trọng trong việc tóm tắt văn bản là mức độ nén, tức là tỉ lệ \n\ngiữa độ dài của văn bản tóm tắt so với văn bản gốc. Thông thường, tỉ lệ nén được \n\ntính dựa trên độ dài của văn bản, hoặc có thể tính bằng nội dung thông tin. Tỉ lệ nén \n\ncó thể dao động từ 10% đến 50% hoặc lớn hơn, nếu tỉ lệ nén giảm thì thông tin sẽ bị \n\nmất nhiều hơn. Văn bản tóm tắt có thể là văn bản liền mạch hoặc văn bản rời rạc. \n\nQuá trình tóm tắt có thể chia thành 3 pha: phân tích văn bản đầu vào, biến đổi, tổng \n\nhợp chỉnh sửa cho phù hợp với yêu cầu đầu ra. \n\n1.2.1. Các phương pháp áp dụng trong pha phân tích. \n\nTrong pha này, văn bản nguồn được phân tích để xác định các đơn vị ngữ liệu \n\nvà các đặc trưng của chúng, kết quả của pha này là đầu vào cho pha biến đổi. Các \n\nphương pháp áp dụng trong pha này bao gồm: \n\na) Phương pháp thống kê  \n\nCác phương pháp thuộc loại này sử dụng các số liệu thống kê về độ quan trọng \n\ncủa các từ, cụm từ, câu hoặc đoạn văn. Các phương pháp thống kê gồm: \n\n - Dựa vào vị trí:  \n\n+ Chủ đề, tiêu đề: tiêu đề hay chủ đề của các đoạn văn thường chứa các từ và \n\nngữ quan trọng. \n\n \n\nP\nhân tích\n\n \n\nB\niến đổi \n\nT\nổng h\n\nợ\np \n\nVăn bản được \n\ntóm tắt Văn bản gốc \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n7 \n\n \n\n + Câu ở đầu hoặc cuối đoạn: xác suất câu đầu đoạn hay câu cuối đoạn chứa \n\ný chính của cả đoạn là rất lớn, đặc biệt là câu đầu đoạn. Ngoài ra các đoạn đầu và \n\ncuối văn bản cũng quan trọng hơn các đoạn giữa.  \n\n+ Minh hoạ, chú thích: trong các câu chú thích, câu minh hoạ cho ảnh hay đồ \n\nthị thường chứa các thông tin quan trọng.  \n\n- Dựa vào cụm từ dấu hiệu: Các cụm từ dấu hiệu có đặc điểm thống kê rất tốt. \n\nSau các cụm từ này thường là các từ hay câu quan trọng. Có hai loại cụm từ dấu \n\nhiệu : thứ nhất là các cụm từ mang ý nhấn mạnh, sau cụm từ này đoạn văn quan \n\ntrọng; chẳng hạn “nói chung là”, “đặc biệt là”, “tóm lại”, “cuối cùng thì”, “trong \n\nbài viết này tôi muốn chỉ ra”, “bài viết nói về”, “nội dung gồm”... Thứ hai là các \n\ncụm từ không quan trọng, sau cụm từ này là các thành phần không có nhiều giá trị \n\ntrong việc tóm tắt, chẳng hạn: “hiếm khi mà”, “bài này không nói đến”, “không thể \n\nnào…”  \n\n- Dựa vào thống kê tần suất từ: Độ quan trọng của từ phụ thuộc vào số lần \n\nxuất hiện của từ đó trong văn bản. Có thể dùng các kĩ thuật như tf-idf, tập thuật ngữ \n\nthường xuyên (frequent item set) để xác định tần suất từ. \n\nb) Phương pháp cấu trúc  \n\nCác phương pháp này sử dụng các mối liên hệ cấu trúc - ngữ pháp - ngữ \n\nnghĩa để xác định các đơn vị ngữ liệu quan trọng. Tư tưởng chính của các phương \n\npháp này là những đơn vị ngữ liệu nào có chứa các thành phần liên quan nhiều với \n\ncác thành phần khác sẽ có mức độ quan trọng cao. Việc đánh giá các mối quan hệ \n\nsẽ dựa trên các mạng ngữ nghĩa hoặc các quan hệ cú pháp.  \n\n- Phương pháp sử dụng quan hệ giữa câu, đoạn  \n\nPhương pháp này xác định mối quan hệ giữa các đoạn trong văn bản hay các \n\ncâu trong đoạn với nhau thông qua việc tính toán mức độ liên quan giữa chúng. Các \n\nđộ Cosine, Jaccard… được chọn để xác định độ tương đồng giữa các câu hay đoạn \n\nvăn bản đó. Sau đó, ta chọn ra đoạn hay câu có độ liên quan lớn nhất.  \n\n+ Phương pháp chuỗi từ vựng (lexical chains) \n\n Phương pháp liên kết từ vựng sử dụng các từ điển quan hệ từ vựng để xây \n\ndựng các chuỗi từ liên kết với nhau về mặt ngữ nghĩa. Sau khi xây dựng được chuỗi \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n8 \n\n \n\ncác từ vựng này, ta đánh giá độ mạnh của chúng và chọn ra những câu phù hợp. \n\nMorris và Hirst (1991) là những người đưa ra mô hình tính chuỗi từ vựng đầu tiên. \n\nChuỗi từ vựng không những chỉ dùng trong tóm tắt văn bản mà còn được coi là lý \n\nthuyết tổng quát của vấn đề ngữ nghĩa trong xử lý ngôn ngữ tự nhiên  \n\n+ Phương pháp liên kết tham chiếu (word coreferences) Phương pháp này \n\ngọi là phương pháp trích chọn trùng lặp (anaphora-based method). Theo phương \n\npháp này, các cụm trùng lặp được chọn ra, phân rã xem đâu là từ (cụm từ) tham \n\nchiếu và từ (cụm từ) được tham chiếu. Sau khi phân tách các cụm trùng lặp, chúng \n\nta tạo chuỗi các từ (cụm từ) tham chiếu đến cùng một từ được tham chiếu. Chuỗi dài \n\nnhất sẽ được coi là trọng tâm của đoạn, các câu chứa các từ trong chuỗi này có một \n\nđộ ưu tiên nào đó thì sẽ được chọn.  \n\nKết thúc pha phân tích sẽ là việc tổng hợp các chỉ số đánh giá độ quan trọng \n\ncủa các đơn vị ngữ liệu và thực hiện việc chọn các đơn vị ngữ liệu nào có độ quan \n\ntrọng lớn làm đầu vào cho pha sau. Có thể nhận thấy các phương pháp thống kê dễ \n\ncài đặt hơn các phương pháp cấu trúc. Việc cài đặt các phương pháp thống kê đơn \n\nthuần chỉ là các công thức toán học, còn để cài đặt các phương pháp cấu trúc thì lại \n\ncần thực hiện rất nhiều kĩ thuật về cấu trúc dữ liệu và thậm chí là các kĩ thuật trong \n\nlĩnh vực trí tuệ nhân tạo. \n\n1.2.2.  Các phương pháp áp dụng trong pha biến đổi \n\n Pha biến đổi có nhiệm vụ biến đổi đơn vị ngữ liệu được trích xuất trong pha phân \n\ntích như cụm từ, câu, đoạn văn. Thông thường pha biến đổi thực hiện rút gọn bản \n\nthân bên trong một câu, rồi có thể rút gọn đoạn mà không gây ảnh hưởng đến độ \n\nchính xác. Các phương pháp trong pha biến đổi gồm:  \n\na) Giản lược về cấu trúc câu. \n\n Lược bỏ các thành phần thừa, ít mang ý nghĩa trong câu, giúp cấu trúc câu \n\nđược thu gọn lại. Công việc này thường dựa trên phân tích cú pháp và phân tích ngữ \n\nnghĩa các thành phần trong câu. Áp dụng phân tích cú pháp chúng ta được các cấu \n\ntrúc của câu, qua đó ta có thể thay thế thành phần bằng những thành phần tương \n\nđương, ghép thành phần có nghĩa tương đương theo một luật nào đó. Phương pháp \n\nnày có thể làm câu ngắn gọn hơn, tuy nhiên khó bảo toàn được văn phong.  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n9 \n\n \n\nb) Giản lược về mặt ngữ nghĩa \n\nThay thế hoặc loại bỏ các từ, cụm từ có ý nghĩa cụ thể bằng những từ, cụm \n\ntừ ý nghĩa lúc này sẽ tổng quát, điển hình là: - Trừu trượng hoá khái niệm: thay thế \n\ncác khái niệm cụ thể bằng khái niệm chung. - Thay thế ngữ tương đương: thay thế \n\ncác ngữ đóng vai trò như nhau trong câu bằng một ngữ chung.  \n\n1.2.3.  Các phương pháp trong pha tổng hợp kết quả  \n\na) Phương pháp hiển thị phân đoạn  \n\nCác đơn vị ngữ liệu được trích xuất hay giản lược từ các pha trước được liên kết \n\nlại thành đoạn theo đúng thứ tự trong văn bản gốc, không thêm bớt từ nối và cũng \n\nkhông sắp xếp lại. Văn bản kết quả của phương pháp này có độ dễ đọc và dễ hiểu \n\nkém, thậm chí lủng củng vì các đơn vị ngữ liệu có thể bị mập mờ tham chiếu, không \n\ncó từ nối hoặc thừa từ.  \n\nb) Phương pháp hiển thị liên kết \n\n  Với phương pháp này, ta sẽ đưa thêm các thông tin bổ sung vào văn bản tóm \n\ntắt. Hai phương pháp thường được áp dụng trong sử dụng mẫu (template) ngữ liệu \n\nhuấn luyện (corpus).  \n\n1.3.  Các phương pháp đánh giá \n\n Đánh giá một bản tóm tắt là một công việc khó bởi không tồn tại một bản \n\ntóm tắt lý tưởng cho một (hoặc một tập) văn bản đưa ra. Hơn nữa, việc đánh giá nội \n\ndung tóm tắt cũng rất khó khăn. Trường hợp kết quả là một câu trả lời cho một câu \n\nhỏi, ta có thể xác định được câu trả lời đó đúng hay sai, nhưng trong các trường hợp \n\nkhác, thật khó trả lời liệu đầu ra là phải một kết quả đúng hay không? Thực tế luôn \n\ncó khả năng một hệ thống sinh ra một bản tóm tắt tốt nhưng lại sai khác với bản tóm \n\ntắt do người thực hiện. Bên cạnh đó, khi việc đánh giá được thực hiện bởi con người \n\nthì chi phí đánh giá sẽ rất cao. Mặt khác, tóm tắt văn bản còn liên quan đến tỉ lệ nén \n\nvăn bản, do đó, việc đánh giá bản tóm tắt cần phải quan tâm đến vấn đề này, khi đó \n\nđộ phức tạp và chi phí đánh giá sẽ tăng cao. Có nhiều kiểu đánh giá khác nhau tuỳ \n\nthuộc vào kiểu tóm tắt của hệ thống. Có thể là đánh giá trong (intrinsic) – tập trung \n\nvào chất lượng bản tóm tắt và đánh giá ngoài (extrinsic) – tập trung vào nhiệm vụ \n\n(McKeown 1998).  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n10 \n\n \n\nCác tiêu chí đánh giá:  \n\n- Độ mạch lạc (Coherence): đánh giá mức độ rõ ràng của văn bản tóm tắt, \n\ntính súc tích, khả năng có thể đọc và hiểu được của bài viết… \n\n- Độ hàm chứa thông tin (Informationess): tỉ lệ thông tin của văn bản gốc \n\ntrong văn bản tóm tắt.  \n\n- Độ liên quan (Relevance): xác định mức độ phù hợp của văn bản tóm tắt \n\nvới chủ đề cho trước (chủ đề có thể là một câu truy vấn).  \n\n- Độ dễ đọc hiểu (Reading Comprehence): một người được giao việc đọc văn \n\nbản kết quả, sau đó trả lời các câu hỏi, hệ thống sẽ phải cho điểm và từ đó đưa ra \n\nphần trăm những câu trả lời đúng. \n\n1.3.1.   Các phương pháp đánh giá trong  \n\na) So sánh với văn bản tóm tắt khác \n\n Ý tưởng cơ bản của phương pháp này là đem văn bản do hệ thống tóm tắt so \n\nsánh với các bản tóm tắt khác (có thể do hệ thống tóm tắt khác thực hiện hoặc do \n\ncon người thực hiện). Thông thường là đem so sánh với văn bản tóm tắt do con \n\nngười thực hiện. Việc so sánh giữa các bản tóm tắt này có thể do con người thực \n\nhiện hoặc có thể thực hiện tự động. Khi so sánh, có thể sử dụng một số độ đo sau: \n\n - Độ chính xác (Precision) và độ bao phủ (Recall). Tuy nhiên, 2 độ đo này \n\nchưa đủ để phân biệt các bản tóm tắt, các bản tóm tắt khác nội dung nhưng vẫn có \n\ncùng độ đo.  \n\n - Độ đo hạng câu (Sentence Rank): thay thế cho độ bao phủ, khi đó, một bản \n\ntóm tắt được đặc trưng bởi hạng của các câu trong các bản tóm tắt thích hợp. Hạng \n\ncủa các câu trong bản tóm tắt do hệ thống thực hiện và trong các bản tóm tắt dùng \n\nđể so sánh có thể tính bằng độ đo tương quan. Độ do này áp dụng đối với hệ thống \n\ntóm tắt dạng trích xuất. \n\n- Độ đo dựa trên nội dung (Content-Based): dựa trên sự tương tự về mặt từ \n\nvựng, và có thể áp dụng đối với cả 2 dạng tóm tắt. Tuy nhiên, độ đo này hữu dụng \n\nvới các bản tóm tắt trích xuất, hoặc với các bản tóm tắt dạng abstract nhưng có mức \n\nđộ cắt-dán cao (tức là văn bản tóm tắt được tạo bởi nhiều từ, cụm từ, câu nguyên \n\ndạng trong văn bản nguồn).  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n11 \n\n \n\nb) So sánh với văn bản nguồn \n\n Với phương pháp này, ta đem so sánh văn bản tóm tắt với văn bản nguồn để \n\nxác định mức độ hàm chứa thông tin của văn bản tóm tắt. Các độ đo dựa trên nội \n\ndung như trên có thể sử dụng để đánh giá. Paice và Jones (1993) đã đưa ra phương \n\npháp sử dụng thống kê để xác định mỗi thuật ngữ có phải là thuật ngữ trung tâm hay \n\nkhông phải thuật ngữ trung tâm. Tiếp đó, phân loại vào các nhóm Chính xác \n\n(Correct), không chính xác (Incorrect) và thiếu (Missing). \n\nHệ thống tóm tắt TIPSTER SUMMAC đánh giá các bản tóm tắt dạng Q&A \n\n(Question and Answer – Hỏi và trả lời) (Mani, Firmin, House, Chrzanowski, Klein, \n\nHirschman, Sundhem, Obrst (1998). Hệ thống này thay vì biểu diễn các khái niệm ở \n\nmức sâu thì chỉ xác định xem trong văn bản tóm tắt có hay không những khái niệm \n\nthen chốt trong văn bản nguồn. Theo phương pháp tóm tắt này thì ta đưa vào một \n\nvăn bản nguồn và một chủ đề, rồi thực hiện tóm tắt dựa trên chủ đề đó để trả lời cho \n\ncâu hỏi. Khi đó, ta có thể xác định xem câu trả lời có Chính xác (chứa câu trả lời \n\nđúng), hoặc Đúng một phần (chứa một phần câu trả lời) hay Thiếu (không chứa câu \n\ntrả lời). \n\n1.3.2.  Các phương pháp đánh giá ngoài \n\n Ý tưởng cơ bản của các phương pháp đánh giá ngoài là đánh giá tác dụng \n\ncủa bản tóm tắt với các nhiệm vụ khác nhau.  \n\n- Đánh giá mức độ liên quan (relevance): ý tưởng của phương pháp này là \n\nđưa ra một văn bản và một chủ đề, đánh giá xem mức độ liên quan của văn bản với \n\nchủ đề đó.  \n\n - Đánh giá mức độ đọc hiểu: trước tiên, một người được đọc các văn bản \n\ntóm tắt từ một hoặc nhiều văn bản, sau đó trả lời các câu hỏi kiểm tra. Hệ thống tự \n\nđộng tính điểm các câu trả lời và đánh giá tỉ lệ trả lời đúng. Nếu bản tóm tắt cho \n\nphép trả lời các câu hỏi giống như khi đọc toàn bộ văn bản nguồn thì bản tóm tắt đó \n\ncó khả năng cung cấp thông tin cao.  \n\nHovey và Marcu (1998) thực hiện đo mức độ cung cấp thông tin dựa trên \n\nviệc người ta có thể khôi phục lại các thông tin quan trọng trong văn bản khi đọc \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n12 \n\n \n\nbản tóm tắt của văn bản đó. Bằng thực nghiệm, tác giả tiến hành dựng lại văn bản \n\ngốc dựa trên việc đọc văn bản tóm tắt kết hợp phỏng đoán. \n\n1.4. Kết luận \n\nTrong chương này nhóm đồ án đã trình bày tổng quan về tóm tắt văn bản, \n\nđưa ra mô hình tóm tắt văn bản, các phương pháp sử dụng trong các pha của mô \n\nhình tóm tắt, các phương pháp đánh giá. \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n13 \n\n \n\nCHƯƠNG 2 : BÀI TOÁN TÓM TẮT VĂN BẢN  TIẾNG VIỆT \n\n2.1.  Một số hướng tiếp cận bài toán tóm tắt văn bản  \n\nTại Việt Nam hiện nay, lĩnh vực xử lý ngôn ngữ tự nhiên đã có được thành \n\ntích trong các bài toán phân tách từ, phân lớp và phân nhóm văn bản. Tuy nhiên bài \n\ntoán tóm tắt văn bản chưa có nhiều nghiên cứu và đa phần các công trình nghiên \n\ncứu đều sử dụng hoặc cải tiến các phương pháp dựa trên thống kê. \n\nCó thể kể đến một số công trình nghiên cứu như:  \n\nĐỗ Phúc, Hoàng Kiếm (2006) đã sử dụng cây hậu tố để phát hiện các dãy từ \n\nphổ biến trong các câu của văn bản, dùng từ điển đồng nghĩa và WordNet tiếng Việt \n\nđể giải quyết vấn đề nghĩa của từ, rồi dùng kĩ thuật gom cụm để gom các câu trong \n\nvăn bản (vector đặc trưng cho câu) và hình thành các vector đặc trưng cụm, sau đó \n\nrút ra câu chứa nhiều thành phần của các vector đặc trưng cụm.  \n\nVương Toàn (2007) đã đề xuất quy trình tóm tắt văn bản khoa học. Theo đó, \n\nđầu tiên cho máy đọc lướt văn bản và tìm xem có sẵn những đoạn văn mang tính \n\nchất “tóm tắt” hay không; tiếp theo là định chủ đề, xác định 4-5 tiêu đề đề mục hoặc \n\ntừ khoá để máy tự động chọn lưu tất cả những câu có các từ khoá đó.  \n\nCông trình nghiên cứu của Nguyễn Trọng Phúc, Lê Thanh Hương (2008) lại \n\nsử dụng cấu trúc diễn ngôn để tóm tắt văn bản. Theo đó, xây dựng cây cấu trúc diễn \n\nngôn biểu diễn mỗi quan hệ diễn ngôn giữa các đoạn văn bản (như các quan hệ \n\nnhân-quả, liệt kê, diễn giải,…), rồi từ cây cấu trúc diễn ngôn này đánh giá được độ \n\nquan trọng của các đoạn văn bản và tiến hành trích xuất tạo ra tóm tắt nội dung cho \n\nvăn bản.  \n\nVới hướng tiếp cận tóm tắt đa văn bản dựa vào trích xuất câu, Trần Mai Vũ \n\n(2009) đã xây dựng đồ thị quan hệ thực thể để tăng cường tính ngữ nghĩa cho độ \n\ntương đồng câu để áp dụng cho tóm tắt đa văn bản tiếng Việt.  \n\nNguyễn Việt Cường (2007) đã sử dụng phương pháp phân đoạn văn bản dựa \n\ntrên chuỗi từ vựng kết hợp với phương pháp sinh tiêu đề dựa trên chủ đề của câu \n\nchủ đề nhằm thực hiện sinh tự động mục lục cho văn bản. \n\n2.2. Đặc điểm tiếng Việt  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n14 \n\n \n\n2.2.1. Đặc điểm chung  \n\nTiếng Việt là ngôn ngữ không biến hình từ và âm tiết tính tức là mỗi một \n\ntiếng (âm tiết) được phát âm tách rời nhau và được thể hiện bằng một chữ viết. Hai \n\nđặc trưng này chi phối toàn bộ tổ chức bên trong của hệ thống ngôn ngữ Việt và cần \n\nđược chú ý khi xử lý tiếng Việt trên máy tính.  \n\nTiếng là đơn vị cơ sở của cấu tạo ngữ pháp Việt Nam. Tiếng có thể có nghĩa, \n\nphai nghĩa và không có nghĩa; hơn nữa giữa 3 hiện tượng này có thể xuất hiện sự \n\nchuyển hoá lẫn nhau. Tiếng tham gia vào hệ thống ngôn ngữ với tư cách một thành \n\ntố trong các cơ chế cấu tạo từ (từ đơn, từ láy, từ ghép…). Theo Từ điển tiếng Việt – \n\nHoàng Phê (1998) thì tiếng Việt hiện đại sử dụng 6718 âm tiết.  \n\nHiện nay, có nhiều tranh luận khi định nghĩa từ trong tiếng Việt. Theo Ngữ \n\npháp tiếng Việt thì xét ở phương diện ngữ pháp có thể định nghĩa từ là đơn vị nhỏ \n\nnhất mà có nghĩa và có thể hoạt động tự do (trong câu), từ là đơn vị trung tâm của \n\nngữ pháp Việt Nam, chi phối toàn bộ cú pháp tiếng Việt, đảm nhận và san sẻ các \n\nchức năng năng cú pháp trong câu và góp phần đưa câu vào các cấu tạo ngôn ngữ \n\nlớn hơn câu. Từ đây trở đi, khái niệm từ được dùng với nghĩa trên khi nói về tiếng \n\nViệt, còn đối với các ngôn ngữ châu Âu (ví dụ tiếng Anh), từ (word) vẫn được hiểu \n\ntheo nghĩa là “cụm kí tự được ngăn cách bởi một hoặc nhiều dấu cách”.  \n\nCụm từ là những kiến trúc gồm hai từ trở lên kết hợp “tự do” với nhau theo \n\nnhững quan hệ ngữ pháp hiển hiện nhất định và không chứa kết từ ở đầu. Cụm từ \n\nhoạt động trong câu mới mọi chức vụ ngữ pháp nhất định. Câu là sự tổng hợp của \n\ncác từ biểu thị một tư tưởng trọn vẹn. Ví dụ: Từ ‘học’ là một từ gồm một tiếng Từ \n\n‘đại học’ là một từ gồm hai tiếng Cụm từ ‘khoa học máy tính’ gồm 2 từ hay 4 tiếng \n\nTrong các hệ thống xử lý ngôn ngữ trên các tiếng châu Âu, để xác định các từ đặc \n\ntrưng cho văn bản người ta có thể đơn giản lấy khoảng trắng làm ranh giới phân \n\ntách từ. Đối với tiếng Việt thì ta lại không thể làm tương tự bởi nếu ta chỉ dựa vào \n\nkhoảng trắng để phân tách thì kết quả ta chỉ có được các “tiếng” vô nghĩa và do đó \n\nđộ chính xác của hệ thống có thể sẽ rất thấp. Theo Ngữ pháp tiếng Việt - Nguyễn \n\nHữu Quỳnh (2001) thì tiếng Việt có đến 80% là các từ 2 tiếng. Từ tiếng Việt không \n\ncó hiện tượng biến hình (ngôn ngữ đơn lập) bằng những phụ tố mang ý nghĩa ngữ \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n15 \n\n \n\npháp bên trong từ như các ngôn ngữ Ấn – Âu. Dĩ nhiên, tiếng Việt cũng có một số \n\nhình thức biến hình như trường hợp thêm tiếng “sự  trước một động từ để biến nó \n\nthành danh từ tương đương, ví dụ như động từ “lựa chọn” và danh từ “sự lựa chọn” \n\nhay thêm tiếng “hoá” sau một danh từ để biến nó thành động từ tương đương như \n\ndanh từ “tin học” và động từ “tin học hoá”. Phụ tố cấu tạo từ tồn tại hiển nhiên hơn \n\nở cơ chế láy với những quy tắc ngữ âm khái quát chứ không hẳn là những dạng thức \n\ncụ thể đồng loạt (ở những từ láy có phần gốc là yếu tố còn rõ nghĩa, phần láy là yếu \n\ntố không rõ nghĩa).   \n\n2.2.2. Yếu tố ngoại lai trong từ tiếng Việt \n\n Tiếng Việt có các yếu tố ngoại lai thuộc gốc Hán, gốc Pháp, Anh trong đó \n\nyếu tố Hán vừa chiếm đa số vừa giữ vai trò khá quan trọng trong vốn từ và trong \n\ncấu tạo từ Việt.  Các yếu tố gốc Ấn – Âu đi vào tiếng Việt phải chịu áp lực rất mạnh \n\ncủa sự âm tiết hoá theo kiểu tiếng Việt. Sự Việt hoá về mặt âm tiết: − Cắt từ nhiều \n\nâm tiết thành những âm tiết rời; − Âm tiết hoá các tổ hợp phụ âm; − Mỗi âm tiết \n\nnhận một thanh điệu thích hợp; − Cấu tạo lại âm tiết theo các âm của tiếng Việt \n\n(như không chấp nhận l, h, s… ở cuối âm tiết).  \n\nNgoài ra, khi Việt hoá các từ ngoại lai Ấn – Âu có sự đơn tố hoá từ nhiều \n\nhình vị (từ tố), tức là một số từ vốn là đa tố ở ngôn ngữ Ấn – Âu vào tiếng Việt \n\nđược coi như từ đơn tố, ví dụ: sulơ, xuyết vôn tơ, mát xa…; và có sự giản hoá về \n\nphát âm như sứ (đại sứ quán), lốp (vỏ bánh xe) từ enveloppe… \n\n2.2.3. Từ dừng. \n\nTừ dừng (stop-words) là các từ xuất hiện nhiều trong các văn bản mà thường \n\nthì không giúp ích trong việc phân biệt nội dung của các tài liệu. Do đó, khi xây \n\ndựng chương trình tóm tắt, cần tìm ra các từ dừng trong văn bản và loại bỏ chúng. \n\nViệc xác định các từ dừng trong văn bản được thông qua một từ điển từ dừng. Từ \n\ndừng bao gồm một số liên từ như: và, thì, là... \n\n2.2.4. Từ đồng nghĩa.  \n\nTheo Cơ sở ngôn ngữ học và tiếng Việt - Mai Ngọc Chừ (1997) từ đồng \n\nnghĩa là những từ tương đồng với nhau về nghĩa, khác nhau về âm thanh và có phân \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n16 \n\n \n\nbiệt với nhau về một vài sắc thái ngữ nghĩa hoặc sắc thái phong cách,... nào đó, \n\nhoặc đồng thời cả hai. Những từ đồng nghĩa với nhau tập hợp thành một nhóm gọi \n\nlà nhóm đồng nghĩa. Ví dụ: dễ, dễ dàng, dễ dãi là những nhóm từ đồng nghĩa. Thực \n\nra, từ đồng nghĩa không phải là những từ trùng nhau hoàn toàn về nghĩa. Chúng \n\nnhất định có những dị biệt nào đó bên cạnh sự tương đồng (mặc dù phát hiện sự dị \n\nbiệt đó không phải lúc nào cũng dễ dàng). Những từ đồng nghĩa với nhau không \n\nnhất thiết phải tương đương với nhau về số lượng nghĩa, tức là các từ trong một \n\nnhóm đồng nghĩa không nhất thiết phải có dung lượng nghĩa bằng nhau: Từ này có \n\nthể có một hoặc hai nghĩa, nhưng từ kia có thể có tới dăm bảy nghĩa. Thông thường, \n\ncác từ chỉ đồng nghĩa ở một nghĩa nào đó. Chính vì thế nên một từ đa nghĩa có thể \n\ntham gia vào nhiều nhóm đồng nghĩa khác nhau: Ở nhóm này nó tham gia với nghĩa \n\nnày, ở nhóm khác nó tham gia với nghĩa khác. Ví dụ: Từ “coi” trong tiếng Việt là \n\nmột từ đa nghĩa. Tuỳ theo từng nghĩa được nêu lên để tập hợp các từ, mà “coi” có \n\nthể tham gia vào các nhóm như: + coi – xem: coi hát – xem hát + coi – giữ: coi nhà \n\n– giữ nhà Trong mỗi nhóm từ đồng nghĩa thường có một từ mang nghĩa chung, \n\nđược dùng phổ biến và trung hoà về mặt phong cách, được lấy làm cơ sở để tập hợp \n\nvà so sánh, phân tích các từ khác. Từ đó gọi là từ trung tâm của nhóm. Ví dụ: Trong \n\nnhóm từ  “yếu, yếu đuối, yếu ớt”, từ “yếu” được gọi là từ trung tâm.  \n\nTuy nhiên, việc xác định từ trung tâm của nhóm không phải lúc nào cũng dễ \n\nvà đối với nhóm nào cũng làm được. Nhiều khi ta không thể xác định một cách dứt \n\nkhoát được theo những tiêu chí vừa nêu trên, mà phải dựa vào những tiêu chí phụ \n\nnhư: tần số xuất hiện cao (hay được sử dụng) hoặc khả năng kết hợp rộng. Chẳng \n\nhạn, trong các nhóm từ đồng nghĩa tiếng Việt như: hồi, thuở, thời; hoặc chờ, đợi; \n\nhoặc chỗ, nơi, chốn,... rất khó xác định từ nào là trung tâm. Với bài toán tóm tắt văn \n\nbản thì từ đồng nghĩa cũng có một ý nghĩa khá quan trọng bởi trong các câu, đoạn \n\nvăn trong văn bản có các từ đồng nghĩa hoặc gần nghĩa nhau và việc sử dụng từ \n\nđồng nghĩa sẽ làm nâng cao tính chính xác khi so sánh về độ tương đồng ngữ nghĩa \n\ngiữa các đơn vị văn bản.  \n\n \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n17 \n\n \n\n2.2.5.  Đặc điểm chính tả  \n\nĐặc điểm chính tả tiếng Việt có ý nghĩa quan trọng tiền xử lý dữ liệu văn bản. \n\nMột số đặc điểm chính tả tiếng Việt cần quan tâm như:  \n\n− Các tiếng đồng âm: như kĩ/kỹ, lí, lý… thường bị sử dụng lẫn nhau như: lý \n\nluận, lí luận, kĩ thuật, kỹ thuật…  \n\n− Các từ địa phương: một số từ địa phương sử dụng thay cho các từ phổ \n\nthông, chẳng hạn: cây kiểng/cây cảnh, đờn/đàn, đậu phộng/lạc…  \n\n− Vị trí dấu thanh: theo quy định đánh dấu tiếng Việt, dấu được đặt trên \n\nnguyên âm có ưu tiên cao nhất. Tuy nhiên, khi viết văn bản nhiều bộ gõ văn bản \n\nkhông tuân thủ theo đúng nguyên tắc trên nên xảy ra hiện tượng dấu được đặt ở các \n\nvị trí khác nhau, chẳng hạn: toán, tóan, thuý, thúy…  \n\n− Cách viết hoa: theo quy định, chữ cái đầu câu và tên riêng phải viết hoa, \n\ntuy nhiên vẫn tồn tại một số cách viết tuỳ tiện.  \n\n− Phiên âm tiếng nước ngoài: hiện nay, vẫn còn nhiều tranh cãi giữa việc \n\nphiên âm tiếng nước ngoài thành tiếng Việt (Việt hoá), nên tồn tại nhiều cách viết \n\n(giữ nguyên gốc tiếng nước ngoài, phiên âm ra tiếng Việt), ví dụ: \n\nSingapore/Xin−ga−po. \n\n − Từ gạch nối: do cách viết dấu gạch nối tuỳ tiện, không phân biệt được \n\ngiữa nối tên riêng hay chú thích. − Kí tự ngắt câu: các kí tự đặc biệt như “.”, “;”, “!”, \n\n“?”, “…” ngăn cách giữa các câu hoặc các vế câu trong câu ghép.  \n\nTóm tại, tiếng Việt là ngôn ngữ không biến hình từ và âm tiết tính, do đó, \n\nviệc phân loại từ (danh từ, động từ, tính từ…) và ý nghĩa từ là vấn đề khó, cần có \n\nnhiều  nghiên cứu thêm. Do vậy, tiền xử lý văn bản (tách từ, tách đoạn, tách câu…) \n\ntrở nên rất phức tạp với việc xử lý các hư từ, phụ từ, từ láy…; hơn nữa, phương \n\nthức ngữ pháp chủ yếu là trật tự từ nên nếu áp dụng phương pháp tính xác suất xuất \n\nhiện của từ có thể không chính xác như mong đợi. Mặt khác, ranh giới xác định từ \n\nkhông phải là khoảng trắng, khiến cho việc tách từ trở nên khó khăn, dẫn đến khó \n\nkhăn cho các giai đoạn tiếp theo như kiểm lỗi chính tả, gán nhãn từ loại, thống kê \n\ntần suất từ… Như thế, các phương pháp xử lý ngôn ngữ đang áp dụng cho tiếng \n\nAnh không thể áp dụng trực tiếp cho tiếng Việt mà cần có sự thay đổi cho phù hợp.  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n18 \n\n \n\n2.3.  Phương pháp cho bài toán tóm tắt văn bản tiếng Việt. \n\n Trong IR, mỗi văn bản được biểu diễn dưới dạng vector, chẳng hạn như Di=(di1, \n\ndi2, …, din) trong đó dik biểu diễn trọng số của từ Tk trong tài liệu Di. Tính toán độ \n\ntương tự giữa hai văn bản Di và Dj là Sim(Di, Dj) – theo các công thức tính độ tương \n\ntự. Nếu độ tương tự này đạt đến một ngưỡng đủ lớn thì ta nói rằng chúng có “liên \n\nquan về mặt ngữ nghĩa”, và ta có thể thiết lập một liên kết giữa hai văn bản này. Áp \n\ndụng phương pháp này vào việc tóm tắt văn bản tự động, thay vì tìm liên kết giữa \n\ncác văn bản, ta sẽ tìm liên kết trong nội bộ văn bản (liên kết giữa các câu trong văn \n\nbản). Sau khi xây dựng được đồ thị quan hệ, ta có được hình vẽ trực quan cấu trúc \n\ncủa văn bản. Từ cấu trúc này, ta có thể xây dựng văn bản tóm tắt bằng cách trích \n\nxuất ra các câu phù hợp. Trong việc xác định ngưỡng để quyết định hai câu trong \n\nvăn bản có quan hệ với nhau về mặt ngữ nghĩa hay không có một ý nghĩa quan \n\ntrọng, bởi lẽ ngưỡng này có thể là tốt cho một dạng văn bản nào đó nhưng lại không \n\ntốt cho văn bản khác.  Như vậy, trong quá trình xây dựng và đánh giá kết quả của \n\nchương trình tóm tắt văn bản, cần phải thực nghiệm với nhiều ngưỡng khác nhau để \n\nchọn ra một ngưỡng thích hợp. Khi áp dụng phương pháp cấu trúc văn bản này đối \n\nvới văn bản tiếng Việt do có những khác biệt đối với văn bản tiếng Anh nên cần \n\nphải có một số cải tiến để nâng cao độ chính xác. \n\nTrước hết, đối với việc phân tách từ vựng tiếng Việt. Có thể sử dụng các phương \n\npháp như:   \n\n+ Phương pháp so khớp cực đại hay còn gọi là phương pháp Left Right \n\nMaximum Matching (LRMM).  Theo đó, ta thực hiện duyệt một ngữ hoặc một câu \n\ntừ trái sang phải và chọn từ có nhiều âm tiết có mặt trong từ điển, rồi cứ thế tiếp tục \n\ncho đến khi hết câu.  \n\n+ Phương pháp sử dụng bộ chuyển trạng thái hữu hạn có trọng số WFST \n\n(Weighted Finite State Transducer) kết hợp với mạng Neural do Đinh Điền (2001) \n\nđưa ra. Với ý tưởng cơ bản là áp dụng WFST kết hợp với trọng số là xác suất xuất \n\nhiện của mỗi từ trong ngữ liệu. Dùng WFST để duyệt qua câu cần xét. Cách duyệt \n\ncó trọng số lớn nhất sẽ là cách từ được chọn. Ngoài ra sử dụng mạng Neural để khử \n\nnhập nhằng nếu có. Do việc xây dựng bộ tách từ khá phức tạp và nằm ngoài phạm \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n19 \n\n \n\nvi của luận văn này nên chúng tôi sử dụng bộ tách từ đã được viết sẵn và cung cấp \n\nmiễn phí để thực hiện bước tiền xử lý các văn bản.  \n\nTiếp theo đó là cần loại bỏ các từ dừng. Từ dừng (stop-words) là các từ xuất \n\nhiện nhiều trong các văn bản mà thường thì không giúp ích trong việc phân biệt nội \n\ndung của các tài liệu. Do đó, khi xây dựng chương trình tóm tắt, cần tìm ra các từ \n\ndừng trong văn bản và loại bỏ chúng. Việc xác định các từ dừng trong văn bản được \n\nthông qua một từ điển từ dừng. \n\nKhi đã loại bỏ các từ dừng, cần phải xác định tiếp các từ đồng nghĩa trong văn \n\nbản. Đối với tiếng Việt, do có một số lượng lớn các từ đồng nghĩa nên khi thực hiện \n\nđo độ tương tự giữa các câu trong văn bản, ta sử dụng thêm một từ điển đồng nghĩa \n\nđể xác định các từ có ý nghĩa tương đồng giữa các câu, để có thể nâng cao phần nào \n\nđộ chính xác. Trong chương tiếp theo, chúng tôi sẽ trình bày chi tiết việc xây dựng \n\nứng dụng tóm tắt văn bản và kĩ thuật sử dụng từ điển đồng nghĩa này. Ngoài ra, \n\ntrong bước tiền xử lý, các vấn đề như bảng mã, chính tả, dấu câu… cũng cần được \n\nxử lý để đảm bảo tính khách quan và chính xác cho các bước tiếp theo. Hình vẽ \n\ndưới đây mô tả một đồ thị quan hệ của các câu trong văn bản “Hỗ trợ 400 USD cho \n\nsinh viên mua laptop”, bỏ qua các liên kết có độ tương tự dưới 0,2. \n\nSau khi đã có được đồ thị quan hệ giữa các câu trong văn bản, tiến hành duyệt \n\nđồ thị và chọn ra các câu quan trọng theo một số phương pháp sau:  \n\nCách 1. Dựa vào bậc của các nút trên đồ thị  \n\nBậc của một nút trên đồ thị là số lượng liên kết tới các nút khác. Khi một nút có \n\nbậc lớn thì câu tương ứng nút đó sẽ phủ một lượng lớn từ vựng  và có thể chứa chủ \n\nđề của nhiều câu khác.  \n\n+ Chọn n nút có bậc cao nhất trong đồ thị (với n là số câu cần chọn trong văn \n\nbản tóm tắt).  \n\n+ Sắp xếp các câu được chọn ra theo thứ tự xuất hiện trong văn bản gốc. \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n20 \n\n \n\n \n\nHình  2.1  Đồ thị liên kết các câu trong văn bản. \n\nCách 2. Duyệt theo chiều sâu \n\n + Chọn một nút quan trọng (thường chọn nút đầu tiên hoặc nút có bậc cao). \n\n+ Chọn nút tiếp theo tương tự nhất với nút trước đó, và cứ như thế. Khi đã duyệt \n\nhết mà vẫn chưa đủ số câu mong muốn, ta sử dụng tiếp cách 1 với các câu còn lại.  \n\nCách 3. Phân đoạn văn bản  \n\n+ Chia văn bản thành từng đoạn.  \n\n+ Áp dụng cách 1 cho mỗi đoạn, số đoạn của văn bản được chia phải đảm bảo \n\nđể chọn được ít nhất một câu trong mỗi đoạn. Trong chương này, chúng tôi đã trình \n\nbày về những hướng tiếp cận với bài toán tóm tắt văn bản tiếng Việt, đồng thời \n\ncũng nêu ra những đặc trưng cần chú ý của tiếng Việt và cuối cùng đưa ra cách tiếp \n\ncận của chúng tôi về việc sử dụng phương pháp cấu trúc để tóm tắt văn bản. \n\n2.4. Kết luận. \n\nTrong chương này nhóm đồ án đã trình bày về một số hướng tiếp cận bài \n\ntoán tóm tắt văn bản tiếng Việt. Đồng thời cũng đưa ra những đặc trưng quan trọng \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n21 \n\n \n\ncần chú ý của tiếng Việt dưới góc độ của lĩnh vực xử lý ngôn ngữ tự nhiên, từ đó \n\nlựa chọn phương pháp cho bài toán tóm tắt văn bản tiếng Việt. \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n22 \n\n \n\nCHƯƠNG 3: ỨNG DỤNG PHƯƠNG PHÁP CẤU TRÚC ĐỂ TÓM TẮT \n\nVĂN BẢN TIẾNG VIỆT \n\n3.1.  Mô hình tóm tắt sử dụng phương pháp cấu trúc \n\n \n\nHình 3.1  Mô hình tóm tắt văn bản sử dụng phương pháp cấu trúc \n\nTrong mô hình này, đầu vào là các văn bản tiếng Việt thuộc nhiều thể loại \n\nkhác nhau, và để cho đơn giản thì chúng tôi chi sử dụng các văn bản thuần. Các văn \n\nbản được xử lý qua 4 giai đoạn. \n\n1. Tiền xử lý  \n\nGiai đoạn này nhằm chuẩn hoá văn bản về bảng mã, các lỗi chính tả, các lỗi \n\nvề dấu câu, v.v… ; sau đó, sử dụng bộ tách từ để tách ra các từ và các câu.  \n\n2. Xử lý từ \n\nPha này nhằm mục đích loại bỏ các từ dừng dựa trên một từ điển từ dừng có \n\ntrước ; sau đó với mỗi từ trong câu, căn cứ vào từ điển đồng nghĩa để lập ra danh \n\nsách các từ đồng nghĩa.  \n\n3. Xây dựng đồ thị liên kết  \n\nTrong pha này, chúng tôi sử dụng kỹ thuật tf-idf để tính toán và vector hoá \n\ncác câu của văn bản, sau đó tính toán độ tương đồng giữa các vector này. Nếu độ \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n23 \n\n \n\ntương đồng giữa hai vector đạt đến một ngưỡng nào đó thì 2 câu sẽ được đưa vào đồ \n\nthị liên kết. Giá trị của ngưỡng này cũng sẽ được chúng tôi thử nghiệm và đánh giá \n\nhiệu lực.  \n\n4. Sinh văn bản tóm tắt \n\nTrong pha này, chúng tôi sử dụng 3 kỹ thuật ở mục 2.3 để tạo ra văn bản tóm \n\ntắt. Như vậy, mỗi văn bản đầu vào sẽ có 3 văn bản tóm tắt tương ứng với từng kỹ \n\nthuật sau đây: \n\n + Dựa vào bậc của các nút trên đồ thị. \n\n + Duyệt theo chiều sâu.  \n\n+ Phân đoạn văn bản. \n\n3.2. Tiền xử lý văn bản \n\n Nội dung của mỗi văn bản được lưu trữ trong một file text và được mã hoá \n\nbằng mã Unicode UTF-8.  \n\nTiếp đó, công cụ JvnTextPro-v.2.0  được sử dụng để phân tách ra các từ và \n\ncác câu. Kết quả ta sẽ thu được 2 file: một file chứa các từ được phân tách (dấu “ ” \n\nđược sử dụng để ngăn cách giữa các từ, các từ ghép được nối với nhau bằng dấu \n\ngạch dưới “_”), và một file chứa các câu (Các câu được phân cách bởi dấu “ .”)  \n\nVí dụ: Đoạn văn bản sau: \n\n Trong thời gian gần đây, các diễn đàn công nghệ trên toàn thế giới luôn xôn \n\nxao vì lỗi ăng-ten của iPhone 4 cùng những hệ lụy xung quanh nó. Hàng loạt khách \n\nhàng đã phàn nàn, thậm chí đâm đơn kiện Quả táo vì bán sản phẩm lỗi. Không \n\nnhững vậy, tạp chí tiêu dùng uy tín Consumer Reports của Mỹ còn lên tiếng chê bai \n\niPhone 4 và khuyến cáo người dùng không nên mua sản phẩm này. Lỗi ăng-ten của \n\niPhone 4 khiến chủ tịch Steve Jobs mất ăn mất ngủ trong thời gian vừa qua. \n\n Khi tách từ xong ta sẽ được kết quả: \n\nTrong thời_gian gần_đây , các diễn_đàn công_nghệ trên toàn thế_giới luôn \n\nxôn_xao vì lỗi ăng - ten của iPhone 4 cùng những hệ_lụy xung_quanh nó . \n\nHàng_loạt khách_hàng đã phàn_nàn , thậm_chí đâm_đơn_kiện Quả táo vì \n\nbán sản_phẩm lỗi .Không những vậy , tạp_chí tiêu_dùng uy_tín Consumer Reports \n\ncủa Mỹ còn lên_tiếng chê_bai iPhone 4 và khuyến_cáo người_dùng không nên mua \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n24 \n\n \n\nsản_phẩm này .Lỗi ăng - ten của iPhone 4 khiến chủ_tịch Steve Jobs mất ăn \n\nmất_ngủ trong thời_gian vừa qua \n\nVà danh sách các câu: \n\nTrong thời gian gần đây, các diễn đàn công nghệ trên toàn thế giới luôn xôn \n\nxao vì lỗi ăng-ten của iPhone 4 cùng những hệ lụy xung quanh nó . \n\nHàng loạt khách hàng đã phàn nàn, thậm chí đâm đơn kiện Quả táo vì bán \n\nsản phẩm lỗi . \n\nKhông những vậy, tạp chí tiêu dùng uy tín Consumer Reports của Mỹ còn \n\nlên tiếng chê bai iPhone 4 và khuyến cáo người dùng không nên mua sản phẩm này . \n\nLỗi ăng-ten của iPhone 4 khiến chủ tịch Steve Jobs mất ăn mất ngủ trong \n\nthời gian vừa qua . \n\nKết quả của bước tiền xử lý này sẽ là đầu vào cho bước xử lý từ tiếp theo.  \n\n3.3. Xử lý từ \n\nPha này có đầu vào là tập tin văn bản đã được thêm dấu phân tách từ ở bước \n\ntrên và có nhiệm vụ xác định các câu. Ranh giới để phân định các câu là các dấu kết \n\nthúc câu bao gồm: dấu chấm câu (.), dấu hỏi chấm (?), dấu chấm than (!) và dấu ba \n\nchấm (...). Đồng thời, chương trình có nhiệm vụ xác định các từ, ranh giới để xác \n\nđịnh là dấu “ ”. Thuật toán dưới đây thể hiện việc chọn ra các từ, các câu, các từ \n\nđồng nghĩa và loại bỏ các từ dừng. \n\nThuật toán 1 \n\n Input: Tập tin văn bản đã tách từ.  \n\nOutput: Tập các từ T, Tập các câu Cau.  \n\n            1. Mở tập tin văn bản \n\n                ST=Nội dung file \n            2. Tách ra các câu \n\n                n=0; //Đếm số lượng câu \n                k=1; \n                while k<length(st) \n                { \n                    if(ST(k)=Dấu kết thúc câu) \n                    { \n                        n=n+1; \n                        cau()=câu kết thúc tại vị trí k; \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n25 \n\n \n\n                    } \n                    k++; \n                } \n            3. Tách ra các từ \n\n                k=1; \n                while k<length(st)  \n                { \n                    if ST(k)= ' '  \n                    {   \n                        word=Chọn ra từ kết thúc tại k;   \n                        Chuẩn hoá word; {Loại bỏ dấu cách, các kí hiệu vô ích, chuyển về chữ \nthường} \n                        Đưa word Tập từ Term; \n                        Else Đưa word vào Tập từ T; \n                    } \n                    k=k+1; \n                } \n            4. return T, Cau; \n\n3.4. Xây dựng đồ thị liên kết. \n\nPha này có nhiệm vụ xây dựng đồ thị liên kết giữa các câu trong văn bản với \n\nđầu vào là danh sách các câu và các từ đã được xử lý ở pha trước đó. Ta thực hiện \n\nvector hoá các câu trong văn bản và thực hiện tính toán độ tương đồng giữa 2 câu \n\nbất kì trong văn bản. Trong mô hình không gian vector, ta coi mỗi văn bản như một \n\nvector (hay một điểm) trong không gian Euclide nhiều chiều, trong đó mỗi chiều là \n\ntừ. Có 3 cách để biểu diễn vector tuỳ thuộc vào kiểu của các thành phần trong \n\nvector: nhị phân, tần số từ tf, và tf-isf. \n\nGiả sử văn bản cần tóm tắt có n câu được đánh số là cau1, cau2,…, caun và m \n\ntừ t1, t2,…, tm gọi nij là số lần xuất hiện của từ ti trong câu cauj. Trong phương pháp \n\nnày sẽ sử dụng cách biểu diễn tf-idf để biểu diễn các vector văn bản. \n\n Mỗi thành phần thứ i của vector văn bản cauj được tính bằng: \n\n \n\nTrong đó: -  , j=  \n\n- Giá trị TF(ti , cauj) được tính bằng nhiều cách: \n\n                 + Tính bằng tổng số lần xuất hiện của các từ trong tài liệu: \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n26 \n\n \n\n                  TF(ti ,cauj)=          (1) \n\n       + Tính bằng số lần xuất hiện lớn nhất của các từ. \n\n                   TF(ti ,cauj)=              (2) \n\n                  + Tính bằng ln số lần xuất hiện số từ: \n\n                  TF(ti ,cauj )=        (3) \n\nTrong cài đặt thử nghiệm, công thức (3) được sử dụng để tính giá trị  TF(ti,cauj). \n\n- Với mỗi từ ti giá trị ISF(ti) được tính bằng tỉ lệ thức của các câu mà xuất \n\nhiện từ ti với tổng số câu có được. \n\nGọi S là tập hợp các câu Sti là tập hợp các câu có chứa từ ti. \n\nS=  \n\nSti ={cau j | nij >0} \n\nGiá trị ISF(ti) có thể tính theo một số cách: \n\n+ Tính bằng thương số của |S| và | Sti |: \n\n                                               \n\n+ Tính bằng hàm logarit: \n\n                                               \n\nSau khi vector hoá các câu trong văn bản, ta tính độ tương quan giữa từng cặp câu \n\nvới nhau theo công thức tính độ tương đồng Cosine đã nêu ở trên. Khi đó, độ tương \n\nđồng giữa 2 câu caui và cauj bất kì được tính bằng:  \n\n \n\nTrong đó: sim(caui,cauj) là độ tương tự của 2 câu caui và cauj. \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n27 \n\n \n\n m: là số từ của 1 câu trong văn bản. \n\nTiếp đó ta xây dựng đồ thị liên kết giữa các câu trong văn bản. Đồ thị được biểu \n\ndiễn bằng một ma trậ D như sau:  \n\n \n\nTrong đó: ngưỡng là một ngưỡng được cho trước và được tính toán bằng thực \n\nnghiệm đối với các loại văn bản. Trong thử nghiệm này của chúng tôi chọn ngưỡng \n\nbằng 0,4. \n\nThuật toán 2: Xây dựng đồ thị liên kết. \n\nInput: Tập từ T, số lượng từ m, tập các câu Cau, số lượng câu n. \n\nOutput: Đồ thị liên kết các câu. D(i,j), i=1..m, j=1..n \n\n1.{Tính tf-isf}  \n\nfor i = 1 to m  \n\n     for j = 1 to n    \n\nif T(i)=T(j) then N(i,j) = N(i,j) + 1;  \n\n{Tính TF}  \n\nfor i = 1 to m   \n\n     for j = 1 to n begin   \n\n tf(i,j) = 0;   \n\n if N(i,j) > 0 then tf(i,j) = 1 + ln(1+ln(N(i,j)))   \n\n     end;  \n\n{Tính ISF}  \n\nfor i = 1 to m begin  \n\ncount = 0; \n\nfor j = 1 to n   \n\n      if N(i,j) > 0 then count = count + 1;  \n\n isf(i) = ln((1+n)/count) \n\n end;  \n\n2.{Tính toán độ tương đồng}  \n\nfor i = 1 to m   \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n28 \n\n \n\nfor j = 1 to n begin    \n\n        sim = cos(caui, cauj)   \n\n         if  sim > threshold then D(i,j) = sim;  \n\n return D(i,j) \n\n \n\nHinh 3.2: Đồ thị liên kết của văn bản input1.txt \n\n \n\n3.5.  Sinh văn bản tóm tắt. \n\nGiả sử văn bản cần tóm tắt có độ dài là p% độ dài của văn bản gốc. \n\nChúng tôi xây dựng thủ tục duyệt đồ thị để chọn ra những câu quan trọng theo 3 \n\nphương pháp: \n\na) Phương pháp 1. Dựa vào bậc của các nút trên đồ thị.  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n29 \n\n \n\nBước 1: Tính bậc của mỗi nút trong đồ thị (bậc được tính bằng số liên kết của nút \n\nvới các nút khác).  \n\nBước 2: Sắp xếp các nút theo thứ tự bậc giảm dần.  \n\nBước 3: Chọn ra các nút có bậc cao nhất, ngừng chọn khi số câu đủ yêu cầu.  \n\nThuật toán 3 \n\nInput: Đồ thị liên kết D(i,j), tỉ lệ nén p%, số câu n. \n\nOutput: Tập các câu được chọn Selection.  \n\n1. {Tính số câu cần chọn}  \n\nNumberOfSent = Round(n * p);  \n\n2. {Tính bậc của các nút}  \n\nfor i = 1 to n begin   \n\nDegree(i) = 0;   \n\nfor j = 1 to n    \n\n if D(i,j) <> 0 then Degree(i) = Degree(i) + 1; \n\nend;  \n\n3. Sắp xếp Degree(i), i = 1..n theo chiều giảm dần  \n\n4. {Chọn ra các câu}  \n\nfor i = 1 to NumberOfSent  \n\n selection(i) = Số thứ tự của câu tương ứng;  \n\n5. Sắp xếp selection theo chiều tăng dần; \n\n6. return selection; \n\nVí dụ: Với văn bản input1.txt, tỉ lệ nén được chọn là 20%, số câu cần chọn ra là 5. \n\nTheo thuật toán 3, thứ tự của các nút được sắp xếp theo bậc giảm dần là (bỏ qua các \n\nnút có bậc bằng 0: \n\n \n\n \n\n \n\n \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n30 \n\n \n\nĐỉnh Bậc  Đỉnh Bậc \n\n \n\nĐỉnh Bậc \n\n \n\nĐỉnh Bậc \n\n11 14 17 9 9 4 7 2 \n\n8 13 23 9 18 4 14 2 \n\n10 13 12 8 21 4 15 2 \n\n1 12 22 8 6 3 24 1 \n\n4 12 20 7 13 3 \n\n 2 10 0 6 16 3 \n\n3 10 5 5 19 3 \n\nBảng 3.1: Bậc của các đỉnh sắp xếp theo thứ tự giảm dần của văn bản input1.txt \n\nKết quả các câu được chọn ra là: 11, 8, 10, 1, 4 \n\nVăn bản tóm tắt là:  \n\n[1]Những người này khuyến cáo Quả táo cần nhanh chóng đưa ra biện pháp khắc \n\nphục hậu quả để lấy lại lòng tin từ khách hàng, cho dù chi phí bỏ ra sẽ rất lớn. \n\n[4]Không những vậy, tạp chí tiêu dùng uy tín Consumer Reports của Mỹ còn lên \n\ntiếng chê bai iPhone 4 và khuyến cáo người dùng không nên mua sản phẩm này. \n\n[8]Tuy nhiên, ít lâu sau, \"Quả táo\" lại khẳng định lỗi sóng yếu là do phần cứng và \n\nsẽ mất rất nhiều thời gian để khắc phục khi mà hãng đã bán ra một số lượng lớn sản \n\nphẩm. \n\n[10]Không những thế, họ còn buộc Quả táo phải bồi thường chi phí mua điện thoại, \n\nkể cả những tổn thất phát sinh khác mà khách hàng phải gánh chịu. \n\n[11]Từ khi xảy ra lỗi mất sóng trên iPhone 4, các chuyên gia quốc tế cùng nhiều \n\ntrang công nghệ lớn như Engadget, Cnet… đã vào cuộc nhằm tìm ra nguyện nhân \n\nsự việc. \n\nb) Phương pháp 2. Duyệt theo chiều sâu  \n\nBước 1: Chọn nút bắt đầu là nút đầu tiên (theo thứ tự xuất hiện trong văn bản).  \n\nBước 2: Duyệt đồ thị theo chiều sâu bắt đầu từ nút xuất phát, chọn các nút theo số \n\nbậc cao nhất. Quá trình duyệt dừng lại khi nút cuối cùng được chọn không liên kết \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n31 \n\n \n\nvới nút nào về sau.                                                                                                                         \n\nBước 3: Nếu vẫn chưa đủ số câu cần thiết, thực hiện phương pháp 1 đối với các câu \n\ncòn lại chưa được chọn.  \n\nThuật toán 4 \n\nInput: Đồ thị liên kết D(i,j), tỉ lệ nén p%, số câu n.  \n\nOutput: Tập các câu được chọn Selection.  \n\n1. Tính số câu cần chọn;  \n\n2. Tính bậc của các nút;  \n\n3. {Chọn nút đầu tiên}  \n\nCount = 1; selected = 1;  \n\nSelection(count) = selected;  \n\n4. {Tạo danh sách kề với nút được chọn}  \n\nfor i = 1 to n   \n\nif (D(selected,i) > 0 then Đưa i vào danh sách kề;  \n\n5. {Chọn nút có bậc cao nhất trong danh sách kề}  \n\nSelected = nút có bậc cao nhất trong danh sách kề;  \n\nCount = Count + 1;  \n\nQuay lại bước 4.  \n\n6. {Nếu chưa đủ số câu} \n\n If count < NumberOfSent then begin   \n\nfor i = 1 to n    \n\nif sent(i) chưa được chọn then Đưa i vào Danh sách còn lại;   \n\nChọn (NumberOfSent – count) câu trong Danh sách còn lại;  \n\n7. Sắp xếp selection theo chiều tăng dần;  \n\n8. return selection; \n\nVới ví dụ tệp input1.txt áp dụng thuật toán 4 các câu được chọn là: 11, 8, 10, 4, 1 \n\nVăn bản được tóm tắt: \n\n[1]Những người này khuyến cáo Quả táo cần nhanh chóng đưa ra biện pháp khắc \n\nphục hậu quả để lấy lại lòng tin từ khách hàng, cho dù chi phí bỏ ra sẽ rất lớn. \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n32 \n\n \n\n[4]Không những vậy, tạp chí tiêu dùng uy tín Consumer Reports của Mỹ còn lên \n\ntiếng chê bai iPhone 4 và khuyến cáo người dùng không nên mua sản phẩm này. \n\n[8]Tuy nhiên, ít lâu sau, \"Quả táo\" lại khẳng định lỗi sóng yếu là do phần cứng và \n\nsẽ mất rất nhiều thời gian để khắc phục khi mà hãng đã bán ra một số lượng lớn sản \n\nphẩm. \n\n[10]Không những thế, họ còn buộc Quả táo phải bồi thường chi phí mua điện thoại, \n\nkể cả những tổn thất phát sinh khác mà khách hàng phải gánh chịu. \n\n[11]Từ khi xảy ra lỗi mất sóng trên iPhone 4, các chuyên gia quốc tế cùng nhiều \n\ntrang công nghệ lớn như Engadget, Cnet… đã vào cuộc nhằm tìm ra nguyện nhân \n\nsự việc. \n\nc) Phương pháp 3. Phân đoạn văn bản  \n\nBước 1: Tách văn bản thành những phân đoạn, căn cứ vào độ dài của văn bản và tỉ \n\nlệ nén p%.  \n\nBước 2: Áp dụng phương pháp 1 đối với từng phân đoạn, ở mỗi phân đoạn chọn ít \n\nnhất một câu. Các câu còn lại được chọn là các nút có bậc cao trong các phân đoạn. \n\nQuá trình chọn sẽ dừng lại khi đạt đủ số câu cần thiết.  \n\nThuật toán 5  \n\nInput: Đồ thị liên kết D(i,j), tỉ lệ nén p%, số câu n.  \n\nOutput: Tập các câu được chọn Selection.  \n\n1. Tính số câu cần chọn;  \n\n2. Tính bậc của các nút;  \n\n3. {Tính toán số đoạn, số câu chọn mỗi đoạn}  \n\nSố_câu = 1;  \n\nSố_đoạn = n/ Số_câu; \n\nwhile NumberOfSeg > số_đoạn begin                 \n\n Số_câu = Số_câu + 1                  \n\nSố_câu = n/ Số_câu  \n\nend;  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n33 \n\n \n\nsố_câu_mỗi_đoạn = số_đoạn / Số_câu \n\n4. {Chọn ra các câu trong từng đoạn} \n\n First = 1; Last = Số_câu;  \n\nwhile last < n begin \n\nSắp xếp bậc của các nút trong đoạn [First, Last];   \n\nfor i = 1 to SelectSentPerSeg chọn câu có bậc lớn nhất;  \n\n First = Last + 1;   \n\nLast = Last + Số_câu;  \n\nend;  \n\n5. Sắp xếp selection theo chiều tăng dần;  \n\n6. return selection; \n\nVới văn bản input1.txt có 25 câu, với tỷ lệ nén là 20% số câu cần trích xuất ra là 5. \n\nVì vậy văn bản sẽ được chia làm 5 đoạn nhỏ. Ta chọn trong mỗi đoạn 1 câu có số \n\nbậc lớn nhất. \n\nĐoạn 1  Đoạn 2  Đoạn 3  Đoạn 4  Đoạn 5 \n\nĐỉnh Bậc  Đỉnh Bậc  Đỉnh Bậc \n\n \n\nĐỉnh Bậc \n\n \n\nĐỉnh Bậc \n\n0 6 5 5 10 13 15 2 20 7 \n\n1 12 6 3 11 14 16 3 21 4 \n\n2 10 7 2 12 8 17 9 22 8 \n\n3 10 8 13 13 3 18 4 23 9 \n\n4 12 9 4 14 2 19 3 24 1 \n\n Bảng 3.2: Phân chia đoạn của văn bản input1.txt \n\nThứ tự các câu sau khi phân đoạn là: 1, 8, 11, 17, 23 \n\n[1]Những người này khuyến cáo Quả táo cần nhanh chóng đưa ra biện pháp khắc \n\nphục hậu quả để lấy lại lòng tin từ khách hàng, cho dù chi phí bỏ ra sẽ rất lớn. \n\n[8]Tuy nhiên, ít lâu sau, \"Quả táo\" lại khẳng định lỗi sóng yếu là do phần cứng và \n\nsẽ mất rất nhiều thời gian để khắc phục khi mà hãng đã bán ra một số lượng lớn sản \n\nphẩm.                                                                                                                       \n\n[11]Từ khi xảy ra lỗi mất sóng trên iPhone 4, các chuyên gia quốc tế cùng nhiều \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n34 \n\n \n\ntrang công nghệ lớn như Engadget, Cnet… đã vào cuộc nhằm tìm ra nguyện nhân \n\nsự việc. \n\n[17]Tuy nhiên chính điều đó mới thể hiện Quả táo là một tập đoàn đẳng cấp và luôn \n\nđặt chất lượng sản phẩm lên hàng đầu. \n\n[23]Trên thực tế, nếu giải pháp này được thực hiện, Apple sẽ chỉ thiệt hại 1 \n\nUSD/chiếc. \n\n3.6. Kết luận. \n\nTrong chương này, chúng tôi đã giới thiệu mô hình tóm tắt văn bản sử dụng \n\nphương pháp cấu trúc và trình bày chi tiết về việc xây dựng chương trình tóm tắt \n\nvăn bản. Nhằm mục đích kiểm nghiệm tác dụng của bộ tách từ tiếng Việt, từ điển \n\nđồng nghĩa, chúng tôi đã cài đặt 3 phiên bản cho ứng dụng này. \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n35 \n\n \n\nCHƯƠNG 4: XÂY DỰNG ỨNG DỤNG MINH HỌA \n\n4.1. Một số giao diện chính của hệ thống. \n\n4.1.1. Giao diện chính của chương trình. \n\n \n\nHình 4.1: Giao diện chính của chương trình. \n\n4.1.2. Giao diện form quản lý từ điển từ dừng, từ đồng nghĩa. \n\n \n\nHình 4.2: Giao diện quản lý từ dừng. \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n36 \n\n \n\n4.1.3. Giao diện form tách từ, tách câu. \n\n \n\nHình 4.3: Giao diện tách từ tách câu \n\n4.1.4. Giao diện form loại từ dừng, từ đồng nghĩa. \n\n \n\nHình 4.4: Loại bỏ từ dừng, từ đồng nghĩa trong văn bản \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n37 \n\n \n\n4.1.5. Giao diện form xây dựng đồ thị liên kết. \n\n \n\nHình 4.5: Giao diện form xây dựng đồ thị liên kết cho văn bản. \n\n4.1.6. Giao diện form tóm tắt văn bản. \n\n \n\nHình 4.6: Giao diện tóm tắt văn bản. \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n38 \n\n \n\n4.1.7. Giao diện form đánh giá độ chính xác. \n\n \n\nHình 4.7: Đánh giá độ chính xác của văn bản tóm tắt \n\n4.2. Một số module chính của chương trình. \n\n4.2.1. Module tóm tắt văn bản. \n\nĐầu vào: đầu vào của module là một văn bản dạng tệp text được công cụ \n\nJvnTextPro tách thành 2 file một file chứa các câu được ngăn cách bởi dấu chấm (.) \n\nvà một file lưu tập các từ với các từ ghép được ghép lại với nhau bởi dấu gạch dưới. \n\nĐầu ra: một đoạn văn ngắn gọn được tóm tắt từ tệp văn bản đầu vào với một tỷ lệ \n\nnén nhất định. \n\nQuá trình xử lý: \n\n- Đối với phiên bản 1: không sử dụng bộ tách từ tách câu, không sử dụng \n\ntừ điển từ dừng, từ đồng nghĩa. Từ tệp văn bản gốc tách ra các từ dựa vào \n\nkhoảng trắng. Tách tập các câu dựa vào dấu chấm. Sau đó tính tần số xuất \n\nhiện của các từ trong văn bản, tính độ tương tự của các câu và cho vào đồ \n\nthị liên kết. Tính bậc của các câu để tìm ra câu quan trọng, tùy vào tỷ lệ \n\nnén là bao nhiêu phần trăm để lấy ra số câu tương ứng. \n\n- Đối với phiên bản 2: sử dụng bộ tách từ tách câu. Chọn đầu vào là tệp \n\nvăn bản .txt dùng công cụ JvnTextPro để tách ra tập các từ và các câu. \n\nTính tần số của các từ, vector từ của mỗi câu, tính độ tương tự của mỗi \n\ncâu trong văn bản để cho vào đồ thị liên kết. Căn cứ vào số câu lấy ra ta \n\nchọn trong CSDL những câu có bậc lớp nhất. \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n39 \n\n \n\n- Đối với phiên bản 3: sử dụng bộ tách từ, tách câu, sử dụng từ điển từ \n\ndừng, từ đồng nghĩa. Từ tệp văn bản đầu vào tiến hành tách từ, tách câu \n\ndựa vào công cụ JVnTextPro, loại bỏ từ dừng, từ đồng nghĩa của văn bản. \n\nTính tần số xuất hiện của mỗi từ trong câu, tính vector từ của văn bản. \n\nTính toán độ tương tự của các câu, so sánh với ngưỡng để đưa câu vào đồ \n\nthị liên kết. Dựa vào số câu lấy ra để chọn ra những câu có bậc lớn trong \n\nCSDL. \n\n4.2.2. Module quản lý từ dừng, từ đồng nghĩa \n\nĐầu vào: Dữ liệu đầu vào là các từ dừng, từ đồng nghĩa. \n\nĐầu ra: Từ được lưu vào trong CSDL hoặc được sửa đổi, xóa bỏ khỏi CSDL \n\nQuá trình xử lý: Kết nối đến cơ sở dữ liệu nhập đầy đủ dữ liệu vào các ô Textbox \n\nsau đó ấn Thêm để thể thêm vào CSDL, sửa để cập nhật các từ hoặc ấn Xóa để loại \n\nbỏ các từ dừng, từ đồng nghĩa. Cập nhật các thay đổi vào trong CSDL, báo cho \n\nngười dùng biết kết quả. \n\n4.2.3. Module đánh giá hệ thống tóm tắt. \n\nĐầu vào: Nhập các câu mà phần mềm tóm tắt ra vào ô textbox thứ nhất. Nhập số \n\ncâu của ghệ thống tóm tắt đối sánh vào ô textbox thứ 2 sau đó nhấn nút để kiểm tra \n\nđể thực hiện đánh giá. \n\nĐầu ra: Đầu ra của module là các thong số độ chính xác, độ bao phủ, hàm điều hòa \n\ncủa hệ thống tóm tắt so với hệ thống tóm tắt đối sánh. \n\nQuá trình xử lý: Nhập các câu mà hệ thống tóm tắt sinh ra và ô textbox thứ nhất. \n\nNhập các câu mà hệ thống đối sánh sinh ra và nhấp nút đánh giá. Hệ thống sẽ tiến \n\nhành lựa chọn các câu giống nhau của 2 hệ thống, tính toán kết quả và trả ra các \n\nthong số tương ứng. \n\n4.3. Kết luận. \n\nTrong chương này nhóm đồ án đã trình bày một số giao diện chính của hệ thống và \n\nmô tả một số module của chương trình. \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n40 \n\n \n\nCHƯƠNG 5: THỰC NGHIỆM VÀ ĐÁNH GIÁ \n\n5.1. Môi trường thử nghiệm.  \n\nChương trình được xây dựng và thử nghiệm trên máy tính cá nhân có cấu hình và \n\ncác phần mềm cần thiết như sau:  \n\n- Vi xử lý: Intel Dual Core T2390 1.86GHz  \n\n- Bộ nhớ: 2GB  \n\n- Hệ điều hành: Windows 7.  \n\n- Phần mềm phát triển: Microsoft Visual Studio 2008 \n\n - Bộ công cụ JVnTextPro-v.2.0 của tác giả Nguyễn Cẩm Tú – Phan Xuân Hiếu \n\nnhằm thực hiện tách từ, tách câu của văn bản đầu vào. \n\n5.2. Dữ liệu thử nghiệm  \n\na) Tập văn bản thử nghiệm  \n\nGồm 20 văn bản có nội dung với nhiều lĩnh vực khác nhau, phần lớn được lấy từ \n\nwebsite vnexpress, dantri.com và một số bài báo khoa học khác. Mỗi văn bản được \n\nlưu trong một tập tin được đặt tên theo thứ tự từ  input1.txt đến Text20.txt. Văn bản \n\ncó kích thước lớn nhất là 27KB với 179 câu, văn bản có kích thước nhỏ nhất là \n\n1,45KB với 9 câu. \n\nb) Từ điển  \n\n- Từ điển từ dừng gồm 235 từ. \n\n- Từ điển đồng nghĩa gồm 1000 mục từ. \n\n5.3. Phương pháp đánh giá. \n\nNhư trên đã trình bày, có nhiều phương pháp khác nhau để đánh giá kết quả \n\ncủa một hệ thống tóm tắt. Trong đó, phương pháp so sánh văn bản của hệ thống tóm \n\ntắt với văn bản do con người thực hiện được sử dụng nhiều. Trong thử nghiệm của \n\nchúng tôi, phương pháp này cũng được sử dụng để đánh giá độ chính xác của hệ \n\nthống tóm tắt. \n\nGọi hệ thống tóm tắt cần đánh giá là S, hệ thống tóm tắt đối sánh là CS thì ta \n\ncó bảng đánh giá mức độ liên quan của S và CS như sau: \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n41 \n\n \n\n \n\n \n\n                       Hệ thống S \n\nHệ thống CS \nHệ thống S chọn Hệ thống S không chọn \n\nHệ thống CS chọn A B \n\nHệ thống CS không chọn C D \n\nBảng 5.1: Đánh giá sự liên quan của văn bản tóm tắt và văn bản đối sánh. \n\nTrong đó: \n\n A là tổng số câu được cả 2 hệ thống tóm tắt chọn. \n\nB là tổng số câu S không chọn nhưng CS chọn. \n\nC là tổng số câu S chọn nhưng CS không chọn. \n\nD  là tổng số câu mà cả 2 hệ thống đều không chọn. \n\nKhi đó, độ chính xác Precision (P) được tính bằng:  \n\n \n\nĐộ chính xác P cho biết tỉ lệ giữa các câu S chọn ra chính xác so với tổng số những \n\ncâu có trong văn bản tóm tắt do S thực hiện.  \n\nĐộ bao phủ Recall (R) được tính bằng:  \n\n \n\nĐộ bao phủ R cho biết tỉ lệ giữa các S chọn ra chính xác so với tổng số câu trong \n\nvăn bản do CS thực hiện.  \n\nĐộ đo F: là tiêu chí đánh giá chung cho kết quả tóm tắt của hệ thống, độ đo này là \n\nhàm điều hoà của độ chính xác và độ hồi quy và được tính bằng:  \n\n \n\nNhư trên đã trình bày, tỉ lệ nén của văn bản tóm tắt là tỉ lệ giữa tổng số câu do hệ \n\nthống tóm tắt lựa chọn so với tổng số câu của văn bản ban đầu. Chúng tôi thử \n\nnghiệm hệ thống tóm tắt với 3 mức độ nén: 10%, 20% và 30%.  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n42 \n\n \n\nTập văn bản thử nghiệm trên được tóm tắt bởi con người, mỗi văn bản được tóm tắt \n\nthành 3 văn bản với mức độ nén lần lượt là 10%, 20% và 30%. Các văn bản được \n\nchuyển cho người tóm tắt để chọn ra các câu có ý nghĩa quan trọng. Việc lựa chọn \n\ncác câu sẽ là chọn ra số thứ tự của câu đó trong văn bản gốc. Mỗi câu được chọn sẽ \n\nđược ghi trên một dòng. \n\nChẳng hạn, với văn bản input1.txt trong tập văn bản thử nghiệm, văn bản này có 25 \n\ncâu. Giả sử, với tỉ lệ nén là 10% thì người tóm tắt sẽ thực hiện chọn ra 3 câu, các \n\ncâu được chọn được ghi trong một tập tin văn bản viết theo dạng: \n\n \n\nHình 5.1: Tóm tắt văn bản input1.txt bởi con người. \n\nVăn bản tóm tắt của input1.txt \n\n[8]Tuy nhiên, ít lâu sau, \"Quả táo\" lại khẳng định lỗi sóng yếu là do phần cứng và \n\nsẽ mất rất nhiều thời gian để khắc phục khi mà hãng đã bán ra một số lượng lớn sản \n\nphẩm. \n\n[10]Không những thế, họ còn buộc Quả táo phải bồi thường chi phí mua điện thoại, \n\nkể cả những tổn thất phát sinh khác mà khách hàng phải gánh chịu. \n\n[11]Từ khi xảy ra lỗi mất sóng trên iPhone 4, các chuyên gia quốc tế cùng nhiều \n\ntrang công nghệ lớn như Engadget, Cnet… đã vào cuộc nhằm tìm ra nguyện nhân \n\nsự việc. \n\nĐồng thời, để so sánh kết quả tóm tắt của hệ thống với các hệ thống khác, nhóm đồ \n\nán lựa chọn Microsoft Office Word 2007 làm hệ tóm tắt đối sánh. Sử dụng công cụ \n\nAuto Summarize trong Microsoft Office để tóm tắt văn bản, Auto Summarize tóm \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n43 \n\n \n\ntắt theo nguyên tắc tính điểm cho các câu chứa từ được lặp lại nhiều lần. Những câu \n\nđược nhiều điểm nhất sẽ được đưa vào văn bản tóm tắt. \n\n5.4. Kết quả thực nghiệm. \n\n5.4.1. Thử nghiệm xác định ngưỡng. \n\n Ngưỡng là giá trị dùng để quyết định xem 2 câu của văn bản có được đưa vào đồ \n\nthị liên kết hay không? Nếu độ tương tự giữa hai câu đạt đến ngưỡng thì 2 câu đó \n\nđược đưa vào đồ thị. Nhóm đồ án đã tiến hành thử nghiệm các phiên bản với những \n\nngưỡng khác nhau để chọn ra một ngưỡng phù hợp. \n\nĐơn vị: % \n\nNgưỡng \n\nPhiên bản 1 Phiên bản 2 Phiên bản 3 \n\nĐộ \n\nchính \n\nxác \n\nĐộ \n\nbao \n\nphủ \n\nHàm \n\nđiều \n\nhòa \n\nĐộ \n\nchính \n\nxác \n\nĐộ \n\nbao \n\nphủ \n\nHàm \n\nđiều \n\nhòa \n\nĐộ \n\nchính \n\nxác \n\nĐộ \n\nbao \n\nphủ \n\nHàm \n\nđiều \n\nhòa \n\n0.1 36.94 47.61 41.48 30.27 37.61 33.33 34.44 44.04 38.33 \n\n0.2 30.27 41.66 34.95 34.44 42.38 37.72 41.11 43.44 42.22 \n\n0.3 39.06 50 43.69 36.94 40.27 38.42 41.11 43.49 42.22 \n\n0.4 38.61 43.25 40.73 41.11 43.44 42.22 44.44 46.82 45.55 \n\n0.5 30.27 32.06 31.11 41.11 41.11 41.11 41.11 41.11 41.11 \n\nBảng 5.2: Kết quả đánh giá thử nghiệm với các ngưỡng khác nhau. \n\nĐồ thị dưới đây mô tả giá trị hàm điều hoà trong việc thử nghiệm các ngưỡng đối \n\nvới từng phiên bản \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n44 \n\n \n\n \n\n0\n\n5\n\n10\n\n15\n\n20\n\n25\n\n30\n\n35\n\n40\n\n45\n\n50\n\n0.1 0.2 0.3 0.4 0.5\n\nPhiên b n 1\n\nPhiên b n 2\n\nPhiên b n 3\n\n \n\nHình 5.2: Đồ thị hàm điều hòa với các ngưỡng. \n\nQua kết quả này, ta có thể nhận thấy, với ngưỡng 0.2, 0.3, 0.4 thì chương trình tóm \n\ntắt cho kết quả khả quan nhất. Khi ngưỡng tăng dần thì giá trị hàm điều hoà lại giảm \n\nrất nhanh do khi độ tương tự giữa hai câu không đạt đến ngưỡng đó thì hai câu đó \n\nkhông thể được đưa vào đồ thị liên kết, từ đó hai câu này sẽ không được chọn vào \n\nvăn bản tóm tắt (mà rất có thể hai câu này chứa nội dung chính và sẽ được chọn). \n\nViệc xác định ngưỡng có một vị trí quan trọng trong chương trình tóm tắt. Bởi lẽ \n\nngưỡng còn phụ thuộc vào từng loại văn bản, một ngưỡng này có thể là tốt với loại \n\nvăn bản nhưng có thể lại không tốt với loại văn bản khác. Trong thử nghiệm kết quả \n\ntóm tắt đối với từng văn bản dưới đây chúng tôi sử dụng ngưỡng 0,4 để đánh giá. \n\n5.4.2. Đánh giá kết quả thử nghiệm đối với từng phiên bản. \n\na) Đánh giá chất lượng tóm tắt của Microsoft Word. \n\n Bảng dưới đây là kết quả đối sánh của các bản tóm tắt do Microsoft Word thực \n\nhiện. \n\n \n\n \n\n \n\nT\nỷ \n\nlệ\n p\n\nh\nần\n\n t\nră\n\nm\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n45 \n\n \n\nĐơn vị: % \n\nTỷ lệ nén Độ chính xác Độ bao phủ Hàm điều hòa \n\n10% 33.33 25 28.57 \n\n20% 40 33.33 36.36 \n\n30% 50 44.44 47.05 \n\nTrung bình 41.11 34.25 37.32 \n\nBảng 5.3: Đánh giá kết quả tóm tắt của Microsoft office 2007 \n\nb) Phiên bản 1 \n\nTrong phiên bản này, chúng tôi không sử dụng bộ tách từ mà chỉ sử dụng dấu trắng \n\nlàm dấu hiệu phân tách từ. Ngưỡng threshold được chọn đối với cả 3 phiên bản để \n\nđưa 2 câu vào đồ thị liên kết được chọn là 0,4. Dưới đây là kết quả đánh giá độ \n\nchính xác và độ bao phủ trun","u":"http://202.191.57.85:8000/InternetData/Data/tailieu.vn/docview/tailieu/2014/20140421/nguyenthuan9191/baocaodatn_8451.txt","downloaded":false,"m":[-1,-1],"n":"baocaodatn_8451.txt","o":"https://tailieu.vn/docview/tailieu/2014/20140421/nguyenthuan9191/baocaodatn_8451.pdf"},{"saved_path":"/home/huong/InternetData/Data/DATN/20131848_Duong_Viet_Hung_1514557567432.txt","r":0.3352988660335541,"s":[[55,29,0.930232584476471,40,0,42,0,42,"Ngược lại, tóm tắt đa văn bản là từ nhiều văn bản nguồn cũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng thời cho nhiều văn bản khác nhau","Ngược lại tóm tắt đa văn bản là từ một văn bản nguồn cũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng thời cho nhiều văn bản khác nhau"],[54,28,0.800000011920929,18,5,24,0,19,"Theo đầu vào hệ thống Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn gọn của văn bản đó","Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn ngọn của văn bản đó"]],"t":"\n \r\n \r\n1.1 Giới thiệu \r\n \r\n\r\nTrong kỉ nguyên công nghệ số như hiện nay, lượng kiến thức của nhân loại \r\nlà vô cùng lớn, hơn nữa sự gia tăng của lượng thông tin đó theo thời gian là vô cùng \r\nnhanh, và đa phần trong đó được biểu diễn dưới dạng các văn bản. Với sự tăng \r\ntrưởng đó tầm quan trọng của việc tóm lược thông tin ngày càng quan trọng. Làm \r\nsao ta có thể biết được điều gì là quan trọng trong một khoảng thời gian ngắn ? Việc \r\ntóm lược thông tin giúp ta có thể quyết định xem tiếp tục tập trung vào phần nào, \r\nnhất là trong các văn bản phức tạp như bài báo khoa học hay toàn bộ nội dung một \r\ncuốn sách. Ngoài ra nó còn có thể ứng dụng trong rất nhiều các lĩnh vực khác mà \r\ncon người cần phải tóm lược một lượng rất lớn các dữ liệu như tài chính, dữ liệu \r\nthuốc của bệnh nhân trong y học. \r\n\r\nBài toán tóm tắt văn bản là một trong những bài toán kinh điển trong lĩnh \r\nvực xử lý dữ liệu văn bản. Xử lý dữ liệu văn bản bao gồm: \r\n\r\n Kiểm tra lỗi chính tả (spelling-checker) \r\n Kiểm tra lỗi văn phạm (grammar-checker) \r\n Từ điển đồng nghĩa (thesaurus) \r\n Phân tích văn bản (text analyzer) \r\n Phân loại văn bản (text classification) \r\n Tóm tắt văn bản (text summarization) \r\n Tổng hợp tiếng  nói (speech synthesis) \r\n Nhận dạng giọng nói (speech recognization) \r\n Dịch tự động (automatic translation) \r\n . \r\n\r\nTóm tắt văn bản là công việc phân tích nội dung của văn bản và sau đó sinh \r\nra một văn bản tóm tắt có kích thước nhỏ hơn văn bản ban đầu, loại bỏ đi những \r\nthông tin không quan trọng nhưng vẫn đảm bảo giữ được những nội dung cốt lõi \r\ncủa văn bản. Do đó để công việc tóm tắt văn bản chính xác cần phải đáp ứng được \r\ncác yêu cầu sau: \r\n\r\n Các văn bản khi phân tích thì phải hiểu được nội dung để xác định \r\nđược các tiêu chuẩn trong văn bản. \r\n\r\n Các văn bản tóm tắt cần được kiểm tra bằng một thang đo tiêu chuẩn.  \r\n \r\n\r\n Rõ ràng việc tóm tắt văn bản chính là công việc khai phá dữ liệu văn bản \r\n(text data mining).  \r\n \r\n\r\n\r\n\r\n\r\n1.2 Lịch sử phát triển của tóm tắt văn bản \r\n \r\n Tóm tắt văn bản bắt đầu từ những năm cuối thập kỉ 1950 với nghiên cứu của \r\nLuhn(1958) dựa trên tần số từ. Ý tưởng cơ bản của phương pháp tần số từ dựa trên \r\nkiến thức cho rằng tần số của từng từ trong văn bản là một độ đo hữu dụng để đánh \r\ngiá tầm quan trọng của chúng. \r\n Tiếp theo đó là phương pháp tóm tắt dựa trên vị trí của các câu trong văn bản \r\ncủa Baxendale (1958) và những nghiên cứu của Edmundson(1969) về vị trí của các \r\ncâu trong văn bản và các từ/cụm từ mang ý nghĩa tổng quát. Theo đó, những câu bắt \r\nđầu và kết thúc của đoạn văn bài viết hay những câu chưa những từ như important \r\n(đặc biệt), result are (kết qủa là) . là những câu có ý nghĩa quan trọng. \r\n Đầu những năm 1970, tiếp tục có những nghiên cứu với hướng tiếp cận \r\nngoài (sử dụng các cụm từ dấu hiệu) và được ứng dụng trong các phần mềm thương \r\nmại \r\n Những năm 1980, phát triển nhiều nghiên cứu với nhiều hướng khác nhau, \r\nđặc biệt là hướng tiếp cận mức thực thể dựa trên trí tuệ nhân tạo  như sử dụng script \r\n(Lehnert 1981), các luật sản xuất mạng và logic (Fum 1985), mạng ngữ nghĩa \r\n(Reimer và Hahn 1988) cũng như các hướng tiếp cận kết hợp (Rau 1989) hay \r\n(Aretoulaki 1994). \r\n Willam B. Cavnar (1994) : biểu diễn văn bản dựa trên n-gram thay cho cách \r\nbiểu diễn truyền thống bằng từ khoá. \r\n Jaine Carbonell (1998) đã tóm tắt văn bản bằng cách xếp hạng các câu trội \r\n(câu chưa các ý chính của văn bản) và rút ra các câu trội. \r\n Jade Goldstein (1999) : phân loại tóm tắt dựa trên độ đo liên quan, phương \r\nphpas sử dụng kết hợp giữa ngữ học, thống kê. Một câu được đặc trưng bằng các \r\nđặc tính ngữ học và độ đo thống kê. \r\n J.Larocca Neto (2000) đã tạo tóm tắt văn bản dựa trên các dãy từ trong câu \r\nđược chọn theo hệ số tf, sau đó dùng kỹ thuật gom cụm (clustering) để tạo tóm tắt. \r\n Yoshio (2001) đã tạo tóm tắt văn bản tiếng Nhật. Có 2 phương pháp là rút \r\ncâu dựa trên từ khoá và rút câu dựa trên kiến trúc ngữ nghĩa trong đó có xây dựng \r\nđộ đo mối liên kiết giữa hai từ. \r\n Hiện nay, một số nghiên cứu về xử lý ngôn ngữ tự nhiên cũng bước đầu \r\nđược áp dụng trong tóm tắt văn bản. Mặt khác, các nghiên cứu về tóm tắt đa văn \r\nbản, đa ngôn ngữ và tóm tắt đa phương tiện cũng bắt đầu phát triển. \r\n \r\n1.3 Phân loại các phương pháp tóm tắt văn bản \r\n \r\n\r\nMột trong những cách phân chia của bài toán tóm tắt là: Tóm tắt đơn văn bản \r\nvà Tóm tắt đa văn bản. Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản \r\n\r\n\r\n\r\n\r\nngắn ngọn của văn bản đó. Ngược lại tóm tắt đa văn bản là từ một văn bản nguồn \r\ncũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm \r\ntắt một văn bản đồng thời cho nhiều văn bản khác nhau. \r\n\r\nTrong phạm vi đồ án, em sẽ tập trung nghiên cứu và áp dụng các kĩ thuật \r\ntóm tắt văn bản tự động vào bài toán tóm tắt đơn văn bản vì tính đặc trưng của các \r\nkĩ thuật áp dụng. Thuật toán cho bài toán tóm tắt đa văn bản được điều chỉnh cho \r\nphù hợp từ cơ sở bài toán tóm tắt đơn văn bản. \r\n\r\n \r\n1.3.1 Phân loại theo dạng tóm tắt \r\n\r\n1.3.1.1 Phương pháp tóm tắt trích xuất  Extractive text summarization \r\n \r\n\r\nPhương pháp trích xuất bao gồm việc lựa chọn đơn vị của văn bản (câu hay \r\nđoạn văn), được coi là có chứa lượng thông tin cốt tử của văn bản (informative \r\ncontent, informativity), và kết nối các đơn vị này theo một trình tự thích hợp. Một \r\ntrích xuất là sự lắp ghép các đoạn được trích rút ra từ văn bản nguồn. Mục tiêu của \r\ntrích xuất là cung cấp một cái nhìn tổng quan về nội dung của văn bản gốc. Độ dài \r\ncủa văn bản tóm tắt bằng trích xuất có thể được xác định bởi tỉ lệ nén, hay nói cách \r\nkhác Văn bản tóm tắt ngắn hơn bao nhiêu so với văn bản gốc. \r\n Thuật toán tóm tắt tự động bằng trích xuất có thể chia ra làm 3 mức: surface-\r\nlevel (mức bề mặt), intermediate-level (mức trung bình) và deep parsing techniques \r\n(các kĩ thuật phân tích sâu).  \r\n \r\n Tóm tắt trích rút xuất phát từ ý tưởng: Một tài liệu được chia nhỏ thành các \r\nđơn vị ngữ pháp (các câu văn), sau đó được đánh trọng số theo kinh nghiệm \r\n(heuristic); Các đơn vị ngữ pháp có điểm cao nhất sẽ được trích rút và liên kết với \r\nnhau để tạo nên văn bản tóm tắt.  \r\n \r\n\r\n Thuật toán tiếp cận ở mức bề mặt: Không đào sâu vào chiều sâu ngôn ngữ \r\ncủa văn bản, thay vào đó là sử dụng các phần tử ngôn ngữ nhất định để xác \r\nđịnh các đoạn có liên hệ với nhau trong văn bản. Kĩ thuật của mức bề mặt \r\ndựa vào sự xuất hiện của từ để đánh trọng số cho các câu. Một kĩ thuật khác \r\ndựa trên ý tưởng: Những từ được sử dụng trong tiêu đề của văn bản là quan \r\ntrọng. Trong khi đó, một số kĩ thuật dựa vào vị trí của các đoạn trong văn \r\nbản. Kĩ thuật này được áp dụng với nhưng văn bản có cấu trúc cố định, như \r\ntiêu đề, các mục và các đoạn,... Một số nghiên cứu còn chỉ ra rằng: Dòng đầu \r\ntiên luôn là dòng quan trọng nhất trong văn bản đối với các thể loại báo chí. \r\n\r\n Thuật toán tiếp cận mức trung bình: Sử dụng thông tin về ngôn ngữ học \r\nphức tạp hơn thuật toán tiếp cận mức bề mặt nhưng lại ít phức tạp hơn mức \r\n\r\n\r\n\r\n\r\nphân tích sâu. Một kĩ thuật của dạng này là phát hiện các chuỗi từ vựng. \r\nChuỗi từ vựng là một dãy các từ kết nối với nhau theo quan hệ về ngữ nghĩa. \r\nMột cách tổng quát, quá trình tóm tắt bao gồm 4 giai đoạn. \r\nBốn giai đoạn đó bao gồm:  \r\n\r\n Chia văn bản gốc thành các đoạn (segments). Xây dựng các chuỗi từ \r\nvựng  lexical chain. \r\n\r\n Xác định các strong chain  chuỗi từ mạnh \r\n Trích rút các câu chứa các strong chain \r\n Lắp ghép các câu được trích rút thành văn bản tóm tắt \r\n\r\n Thuật toán phân tích sâu: Dựa trên ý tưởng rằng sử dụng các kĩ thuật \r\nchuyên sâu về ngôn ngữ để phát hiện ra các cấu trúc rời rạc của văn bản.  \r\nNhững hệ thống tóm tắt văn bản tự động dựa trên phân tích diễn ngôn bắt \r\nnguồn từ ý tưởng: Văn bản được định nghĩa bởi cấu trúc trong của nó và các \r\nmối quan hệ diễn ngôn - phụ thuộc vào ngôn ngữ mà văn bản sử dụng. \r\nNhững hệ thống này cung cấp độ quan trọng nhiều hơn cho các thành phần \r\ncốt  tử của các quan hệ rời rạc.  \r\nSử dụng lý thuyết cấu trúc diễn ngôn (Rhetorical structure theory) chia văn \r\nbản thành các đơn vị rời rạc sử dụng tập các quan hệ tối thiểu (minimal set of \r\nrelations). Một khi các cấu trúc rời rạc được xác định, một thuật toán sẽ được \r\náp dụng để đánh trọng số và thứ tự cho mỗi phần tử trong cấu trúc tựa cây \r\nmột cách rời rạc. Và cuối cùng, các câu với trọng số cao nhất sẽ được lựa \r\nchọn để tạo nên văn bản tóm tắt. \r\n\r\n1.3.1.2 Phương pháp tóm tắt tóm lược  Abstractive summarization \r\n \r\n\r\nTuy tóm tắt bằng trích rút đã thành công trong việc xác định câu nào trong \r\nvăn bản đầu vào mang nội dung quan trọng nhưng dường như những phương pháp \r\nnày rất xa với việc tạo ra một bản tóm tắt tối ưu theo nghĩa cả về nội dung và chất \r\nlượng trong ngôn ngữ học. Trong khi đó, hệ thống tạo ra văn bản tóm tắt bằng tóm \r\nlược dựa trên việc hiểu văn bản gốc và đạt tới việc sinh ra một văn bản mới một \r\ncách chính xác về ngữ pháp, súc tích và mạch lạc về nội dung, bằng cách sinh ra \r\nvăn bản tóm tắt bằng những từ vựng không xuất hiện trong văn bản gốc. \r\n Trong tóm lược, việc diễn giải, viết lại các câu phức tạp sẽ nhằm mục đích \r\ntạo ra phiên bản súc tích của nội dung ban đầu. Mặc dù con người có thể tái sử dụng \r\nmột phần văn bản gốc nhưng không phải sử dụng toàn bộ nó; sử dụng các đoạn hay \r\nmột phần của câu thay vì sử dụng toàn bộ câu. \r\n \r\n1.3.2 Phân loại theo mức độ xử lý: \r\n\r\n \r\n\r\n\r\n\r\n\r\n Tiếp cận mức ngoài : thông tin được miêu tả dứoi dạng khái niệm về các \r\nđặc trưng nông (shallow feature). Các đặc trưng nông bao gồm các thuật \r\nngữ quan trọn gqua thống kê ( dựa vào tần số của các thuật ngữ trong văn \r\nbản), các thuật ngữ quan trọng dựa vào vị trí, các cụm từ dấu hiệu hay \r\ncác thuật ngữu trong câu truy vấn của ngừoi dùng. Kết quả là một bàn \r\ntóm tắt dạng trích xuất (extract). \r\n\r\n Tiếp cận mức sâu (deeper-level) : ở mức này bản tóm tắt có thể là dạng \r\ntrích xuất hoặc dạng tóm tắt (abstract) và cần phải sửu dụng đên sinh \r\ntổng hợp ngôn ngữu tự nhiên. Với dạng tiếp cận này phải cần đến những \r\nphân tích về mặt ngữ nghĩa, chẳng hạn sử dụng hướng tiếp cận thực thể \r\nđẻ xây dựng dạng biểu diễn của cấc thực thể văn bản và mối quan hệ \r\ngiữa các thực thể rồi từ đố tìm ra phần trái nghĩa, nghĩa hẹp, nghĩa \r\nrộng., quan hệ cú pháp dựa trên cây phân tích cú pháp và các mối quan \r\nhệ khác. \r\n \r\n\r\n1.3.3 Phân loại theo mục đích của bản tóm tắt: \r\n\r\n \r\n Trình bày sơ lược : Đưa ra những thông tin ngắn gọn về chủ đề chính của \r\n\r\nvăn bản. Dạng tóm tắt này thường được sử dụng trong các hệ thống tìm \r\nkiếm thông tin. Thông thường, độ dài của văn bản tóm tắt loại này chỉ \r\ntừu 5 đến 10% độ dài của toàn bộ văn bản \r\n\r\n Tóm tắt cung cấp tin tức: Cung cấp các chủ đề con của toàn bộ văn bản, \r\nkiểu tóm tắt này có độ dài từ 20-30% văn bản gốc. \r\n\r\n Phê bình và đánh giá: Văn bản tóm tắt đưa ra những quan điểm của \r\nngười tóm tắt về chủ đề được đưa ra. Tuy nhiên, kiểu tóm tắt này dường \r\nnhư vượt qua tầm của các hệ thống tóm tắt tự động hiện này. \r\n \r\n\r\n1.4 Những vấn đề trong bài toán tóm tắt văn bản \r\n \r\n\r\nTóm tắt văn bản có 2 dạng cơ bản là Extractive và Abtractive. Hầu hết các \r\ncông cụ tóm tắt hiện này đều là extractive. Đó là phương pháp tóm tắt giữa vào trích \r\nxuất các từ các câu tồn tại trong văn bản đầu vào sau đó dùng các giải thuật để đánh \r\ngiá xếp hạng chúng rồi sắp xếp lại thành văn bản tóm tắt. Nhưng con người chúng \r\nta thì suy nghĩ phức tạp hơn như vậy. Khi con người chúng ta tóm tắt não chúng ta \r\nkhởi tạo những đặc trưng ngữ nghĩa mà chúng ta đọc từ văn bản và từ đó tóm lược \r\nnội dung văn bản. Đó cũng chính là các phương thức abtractive hoạt động. Với \r\nnhững bước tiến về mặt sức mạnh phần cứng deeplearning có thể giúp ta thực hiện \r\nđiều này.  \r\n \r\n\r\n\r\n\r\n\r\n1.5 Giải pháp định hướng \r\nVới sự tiến bộ trong lĩnh vực Học máy (Machine learning) nói chung và học \r\n\r\nsâu (Deep learning) nói riêng có rất nhiều phương pháp đã chứng minh được tính \r\nhiệu quả trong việc giải quyết những bài toán phức tạp mà các cách tiếp cận truyền \r\nthống chưa thể giải quyết triệt để được. \r\n\r\nĐể giải quyết vấn đề khai phá, trích xuất những nội dung ngữ nghĩa được ẩn \r\nđi trong tài liệu(extractive), em đề xuất một thuật toán kết hợp các kĩ thuật phân tích \r\nvăn bản truyền thống. Từ đó, em sẽ thiết kế, xây dựng và đánh giá hệ thống tóm tắt \r\nvăn bản tự động dựa trên cách tiếp cận này. Cụ thể, nội dung đồ án sẽ tập trung \r\nnghiên cứu, tìm hiểu kĩ thuật phân tích ma trận NMF và trích suất đặc trưng.  \r\n Để giải quyết bài toàn tóm tắt văn bản bằng phương pháp abtractive, trích \r\nxuất nội dung ngữ nghĩa trong tài liệu em đề xuất sử dụng một mô hình được sử \r\ndụng phổ biết trong các bài toán dịch máy đó là mô hình sequence to sequence kết \r\nhợp cũng kĩ thuật attention, một kĩ thuật đang được áp dụng rất phổ biến gần đây \r\ncho các mô hình sequence to sequence nhằm tăng độ chính xác và giảm số lượng dữ \r\nliệu cần phải xử lý. Sau đó sẽ so sánh kết quả đạt được với phương pháp extractive \r\nsử dụng mà trận không âm NMF kết hợp với trích suất đặc trưng. \r\n \r\n \r\n\r\n\r\n\r\n\r\n \r\nCHƯƠNG 2 PHƯƠNG PHÁP PHÂN TÍCH MA TRẬN TRONG BÀI \r\n\r\nTOÁN TÓM TẮT  \r\n2.1 Cơ sở lý thuyết \r\n \r\n2.1.1 Kĩ thuật phân tích ma trận không âm \r\n\r\nPhân tích ma trận không âm - Non-negative matrix factorization là một nhóm \r\ncác thuật toán phân tích đa biến trong đại số tuyến tính. Ma trận A được phân tích \r\nthành 2 ma trận W và H với điều kiện là cả 3 ma trận này đều chỉ mang các thuộc \r\ntính không âm,  \r\n\r\n \r\n\r\n \r\nMa trận A được phân tích thành 2 ma trận W và H: \r\n\r\n ! = #$   \r\n \r\n\r\n Với A là một ma trận mxn, W là một ma trận mxk, và H là một ma trận kxn, \r\nk luôn được chọn nhỏ hơn m và n, do đó cả 2 ma trận W và H đều có size nhỏ hơn \r\nma trận A. \r\n Chúng ta sử dụng Frobenius norm như là hàm mục tiêu (objective function) \r\nđể thỏa mãn điều kiện xấp xỉ A  WH . Frobenius norm được chỉ ra trong công \r\nthức (Lee & Seung, 1999, 2001): \r\n \r\n\r\n! \",$  &-\"$ ()  *+,- \"+-$-,\r\n.\r\n\r\n-/0\r\n\r\n1\r\n\r\n,/0\r\n\r\n2\r\n\r\n+/0\r\n\r\n)\r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n \r\n Công thức này có cận dưới bằng 0, và rõ ràng tiến tới 0 khi và chỉ khi A = \r\nWH. W và H liên tục được cập nhật tới khi E(W,H) hội tụ dưới ngưỡng được \r\nđịnh nghĩa hoặc vượt quá số lần lặp. Luật cập nhật được chỉ ra dưới đây: \r\n !\"# \t \t!\"#\r\n\r\n%&' \"#\r\n%&%! \"#\r\n\r\n \r\n \r\n\r\n \r\n\r\n \r\n\r\n\r\n\r\n\r\n !\"# \t \t!\"#\r\n%&' \"#\r\n!&&' \"#\r\n\r\n \r\n \r\n\r\n \r\n\r\n \r\n Vec-tơ cột A tương ứng với câu thứ j, Aj, có thể được biểu diễn như là một \r\nsự kết hợp tuyến tính của vec-tơ đặc trưng ngữ nghĩa W*l và biến ngữ nghĩa Hlj như \r\ndưới đây: \r\n \r\n\r\n!*# = H&'(*)\r\n*\r\n\r\n)+,\r\n \r\n \r\n\r\n \r\n\r\n \r\n Ví dụ 1: Chúng ta sẽ lấy một ví dụ để minh họa cho thuật toán NMF: Cho  \r\nk = 2, số bước lặp là 50, và dung sai = 0.001 (tolerance). Các phần tử tại thời điểm \r\nban đầu của W và H băng 0.5, ma trận không âm A được phân tích thành 2 ma trận \r\nkhông âm W và H, được chỉ ra trong câu sử dụng NMF. Vec-tơ cột A*3 tương ứng với câu thứ 3 được biểu diễn như là sự \r\nkết hợp tuyến tính của vec-tơ đặc trưng ngữ nghĩa W*l và vec-tơ cột biến ngữ nghĩa \r\n(semantic variable column vector) H*3.  \r\n NMF phân tích một ma trận thưa thành hai ma trận thưa. Ở đây tỉ lệ phần tử \r\nbằng 0 (non-zero ratio) của ma trận có nghĩa là giá trị các phần tử khác 0 chia cho \r\ntổng số phần tử của ma trận. Ma trận không âm A là 1 ma trận vuông nxn, và giá trị \r\ncủa n được đặt bằng 100, 200, 300 và 400. Non-zero entries được chọn một cách \r\nngẫu nhiên. Số lượng đặc trưng nghĩa nghĩa, r, được chọn là 10% cuả n. Tỉ lệ non-\r\nzero cuả A được chọn lần lượt là 0.5%, 1%, 2%, 3%, 5%, 7%, 10%, 30%, 60% và \r\n99%. Hai ma trận W và H thu được bằng NMF. \r\n \r\n        A                            W                                       H                                              A \r\n\r\n1 2 3\r\n4 5 6\r\n7 8 9\r\n10 11 12\r\n\r\n\t\r\n0.1487 1.5998\r\n0.6610 0.9676\r\n1.1481 0.5727\r\n1.6129 0.4066\r\n\r\n 6.1136 6.6784 7.17840.0854 0.5923 1.2245 =\r\n1.0457 1.9420 3.0263\r\n4.1237 4.9813 5.9297\r\n7.0679 8.0071 8.9470\r\n9.8953 11.0127 12.0759\r\n\r\n \r\n\r\n \r\n               A*3      W*1       W*2                                  H*3                                                                        \r\n\r\n \r\n            A*3        H13         W*1             H23           W*2 \r\n\r\n3\r\n6\r\n9\r\n12\r\n\r\n 7.1784\r\n\r\n0.1487\r\n0.6610\r\n1.1481\r\n1.6129\r\n\r\n+ 1.2245\r\n1.5998\r\n0.9676\r\n0.5727\r\n0.4066\r\n\r\n \r\n\r\n \r\n \r\n\r\n \r\n\r\n\r\n\r\n\r\n2.1.2 Kĩ thuật tiếp cận dựa trên cấu trúc \r\n\r\nTrong các nghiên cứu gần đây có rất nhiều các đặc trưng hiệu quả của câu văn \r\nđược đề xuất để dùng cho tóm tắt trích rút, ví dụ như signature word, event hay \r\nsentence relevance. Mặc dù có nhiều kết quả đáng khích lệ nhưng hầu hết các đặc \r\ntrưng này được khảo sát một cách độc lập. Tuy nhiên, thực tế mỗi đặc trưng này lại \r\ncó đóng góp riêng của nó và sự kết hợp các đặc trưng đó lại với nhau có thể thu \r\nđược một kết quả tốt hơn trong các trường hợp riêng lẻ. Trong phần 2.5 của đồ án \r\nsẽ trình bày các kết quả thực nghiệm để đánh giá và chọn ra những bộ đặc trưng cho \r\nkết quả tốt nhất đáp ứng với bài toán tóm tắt văn bản. Trong mục này sẽ trình bày \r\nchi tiết các đặc trưng được xem xét. \r\n\r\n Surface Features  Đặc trưng bề mặt: Nhóm đặc trưng này xem xét đến \r\nđặc điểm cấu trúc của câu. Bao gồm: vị trí của câu trong văn bản - thông \r\nthường các câu đầu văn bản thường là các câu chứa đựng chủ đề khái quát \r\ncủa cả bài văn; số lượng từ trong câu - căn cứ vào các kiểu văn bản khác \r\nnhau, văn bản báo chí, xã luận, hay bài báo khoa học thì câu văn thường có \r\nmột độ dài trung bình nhất định, những câu văn có số lượng từ nhỏ hơn \r\nngưỡng đó sẽ là các câu không quan trọng; số lượng trích dẫn trong câu - \r\nmột câu chứa quá nhiều trích dẫn là câu không quan trọng. \r\n\r\n Relevance Features  Đặc trưng độ liên quan: Đặc trưng này được sử \r\ndụng để tìm ra mối liên hệ giữa các câu. Để làm được điều đó, ta đặt quy ước \r\nrằng: Giữa các câu luôn tồn tại mối liên hệ với nhau, sẽ có một số câu mang \r\nnội dung quan trọng hơn các câu khác và khi những câu khác liên quan đến \r\nnhững câu đó thì mức độ quan trọng cũng tăng lên. Tại thời điểm ban đầu, ta \r\ncó những câu đầu tiên của tài liệu và những câu đầu tiên của đoạn văn là \r\nquan trọng. Thước đo độ liên quan trong trường hợp này là độ tương đồng \r\ncosine. \r\n\r\n Content Features  Đặc trưng nội dung: Trong nhóm đặc trưng này, chọn \r\nđặc trưng Centroid, dựa vào đặc trưng centroid để xác định câu nào tập trung \r\nvào chủ đề của văn bản. \r\n \r\n\r\n2.2 Áp dụng phân tích ma trận không âm vào phân tích văn bản \r\n \r\n\r\nTourism in Greate Britain (Hoa 2005). \r\n\r\n \r\n \r\n \r\n \r\n\r\n\r\n\r\n\r\nMột số câu Câu văn \r\nS1 TOURIST arrivals to the UK in 1991 are forecast to recover \r\n\r\nsharply after the steep decline earlier this year cause by the Gufl \r\nwar. The British Tourist Authority said incoming tourist \r\nnumbers had already increased significantly after falling 18 \r\npercent in the first two months of this year from the levels of the \r\ncorresponding period of 1990 \r\n\r\nS2 The increases were achived in spite of a fall in the number of \r\nvisitors from western Europe rose 12 percent to 23 m  higher \r\nthan in any previous first quarter. A RECORD 185 m tourists \r\nvisited Britain in the 12 months to March, 8 percent more than \r\nthe previous year and the British Tourist Authority said \r\nyesterday that it was expecting even higher numbers this year \r\n\r\n. . \r\nS20 The increase were achieved in spite of a fall in the number of \r\n\r\nNorth American visitors Visits by North Americans fell 6 \r\npercent to 600,000 in the first quarter. However, the number of \r\nvisitors from western Europe rose 12 percent to 23 m  higher \r\nthan in any previous first quarter. A RECORD 185 m tourists \r\nvisited Britain in the 12 months to March, 8% more than the \r\nprevious year  and the British Tourist Authority said yesterday \r\nthat it was expecting even higher numbers this year \r\n\r\n. . \r\n \r\n\r\n \r\nThuật \r\n\r\nngữ \r\n S\r\n\r\n1 \r\nS\r\n2 \r\n\r\nS\r\n3 \r\n\r\nS\r\n4 \r\n\r\nS\r\n5 \r\n\r\nS\r\n6 \r\n\r\nS\r\n7 \r\n\r\nS\r\n8 \r\n\r\nS\r\n9 \r\n\r\nS \r\n10 \r\n\r\n. S \r\n20 \r\n\r\n. S \r\n57 \r\n\r\n1 Tourist 3 2 0 2 1 0 0 0 0 0 . 2 . 1 \r\n2 Arrival 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n3 UK 1 1 0 0 1 0 0 0 0 0 . 0 . 1 \r\n4 Forecast 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n5 Recover 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n6 Sharply 1 0 0 0 0 0 0 0 0 0  0 . 0 \r\n7 Steep 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n8 Decline 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n9 Earlier 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n\r\n10 Year 2 2 1 0 0 1 0 0 0 0 . 2 . 0 \r\n\r\n\r\n\r\n\r\n11 Cause 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n12 Gulf 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n13 War 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n14 British 1 2 0 1 1 0 0 0 0 0 . 1 . 0 \r\n15 Authority 1 1 0 1 1 0 0 0 0 0 . 1 . 1 \r\n16 Income 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n17 Increase 1 1 0 0 0 0 0 0 0 0 . 1 . 0 \r\n18 Significantly 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n. . . . . . . . . . . . . . . . \r\n\r\n396 Return 0 0 0 0 0 0 0 0 1 0 . 0  0 \r\n \r\n\r\n \r\n\r\nbộ tập các câu trong sentences. Dễ dàng nhận thấy trong là một ma trận rất thưa. \r\n\r\nThuật ngữ Đặc trưng ngữ nghĩa Câu S20 \r\nW*1 W*2 W*3 . W*10 Original !\"#$%*\"\r\n\r\n'$\r\n\r\n\"('\r\n \r\n \r\n\r\n. . . . . . . . .  \r\n13 War 0 0 0 . 0.04 0  0.11 \r\n14 British 0 0.68 0.44 . 0.13 1  0.89 \r\n15 authority 0 0.60 0 . 0 1  1.05 \r\n16 income 0 0 0.35 . 0.03 0  0.11 \r\n17 increase 0.07 0 0 . 0.76 1  1.01 \r\n. . . . . . . . .  \r\n\r\n396 Return 0 0 0 . 0.08 0  0.07 \r\nTrọng số Hj20  0 0.07 0 . 0    \r\n\r\n \r\n\r\n \r\n\r\nphân tích NMF đối với ma trận A, giá trị trọng số H1,20, ..., H10,20 của vec-tơ đặc \r\ntrưng ngữ nghĩa tương ứng với câu S20, vec-tơ câu ban đầu. Vec-tơ câu được tính \r\ntừ các giá trị trọng số và các vec-tơ ngữ nghĩa. Phương pháp NMF trích xuất câu có \r\ntrọng số lớn nhất theo nghĩa: câu đó phản ánh nhiều nhất tới chủ đề chính của tài \r\nliệu, điều đó được biểu diễn bởi các đặc trưng ngữ nghĩa. Do đó, phương pháp NMF \r\n\r\n\r\n\r\n\r\ncó likelihood tốt hơn trong việc trích xuất các câu quan trọng về mặt ngữ nghĩa so \r\nvới phương pháp LSA. \r\n\r\n \r\n2.3 Các vấn đề của NMF \r\n2.3.1 Ưu điểm \r\n\r\n Đối với việc số hóa một tài liệu sang dạng dữ liệu để máy tính  phiên bản số \r\ncủa tài liệu có thể thực hiện các phép toán cộng, trừ, nhân, chia,..., từ đó có thể thực \r\nhiện các công việc khai phá dữ liệu như phân loại văn bản (bài toán topic \r\nmodelling), tóm tắt văn bản (text summarizing),. thì việc sử dụng mô hình không \r\ngian vec-tơ mà cụ thể là phương pháp phân tích ma trận theo mô hình tần suất \r\ndường như là một cách làm mang tính tự nhiên nhất. Trong chương 2, đồ án đã đề \r\nxuất sử dụng một phương pháp không giám sát mới để sinh ra văn bản tóm tắt của \r\ntài liệu tương ứng sử dụng kĩ thuật phân tích ma trận không âm NMF. Phương pháp \r\nđược đề xuất có những ưu điểm sau đây: \r\n\r\n Thứ nhất, đây là phương pháp không giám sát (unsupervised) và \r\nkhông yêu cầu các tóm tắt mẫu cho bước tập huấn và cho bộ tóm tắt. \r\n\r\n Thứ hai, các vec-tơ đặc trưng ngữ nghĩa được trích rút từ NMF có thể \r\nđược thể hiện trực quan hơn là sử dụng các phương pháp liên quan \r\nđến LSA, bởi vì các thành phần trong phân tích NMF chỉ gồm các giá \r\ntrị không âm và chúng rất thưa trong khi cũng là các thành phần đó \r\nnhưng trong phương pháp LSA thì gồm cả giá trị âm và giá trị dương, \r\nngoài ra, còn có chứa một vài giá trị bằng 0.  \r\n\r\n Hơn nữa, một câu được có thể được biểu diễn như là sự kết hợp tuyến \r\ntính của những đặc trưng ngữ nghĩa một cách trực quan. \r\n\r\n Cuối cùng, phạm vi ngữ nghĩa của đặc trưng ngữ nghĩa là hẹp, bởi vì \r\nchúng rất thưa, theo đó, các chủ đề nhỏ (sub-topics) của tài liệu được \r\nxác định một cách dễ dàng và chính xác hơn. Do đó, khả năng trích \r\nrút được các câu quan trọng sẽ tốt hơn các phương pháp khác. \r\n \r\n\r\n2.3.2 Nhược điểm \r\n\r\n Tuy nhiên, nhược điểm của phương pháp nằm ở việc không thể phát hiện ra \r\ncác liên kết ẩn giữa các từ, các phần trong văn bản. Các liên kết này có thể tồn tại \r\ndưới nhiều dạng, đó có thể là quan hệ nguyên nhân  kết quả giữa các luận điểm, có \r\nthể là những phần được nhấn mạnh, quan trọng hơn những phần khác hay là sự thay \r\nđổi cách sử dụng ngôn từ diễn đạt, và có một số thuật ngữ, tuy khác nhau về hình \r\nthức nhưng lại mang những nét nghĩa giống nhau.  \r\n\r\n\r\n\r\n\r\n2.4 Mô hình đề xuất \r\n \r\n\r\nTrong phần này ta sẽ đi vào thiết kế hệ thống thực tế để giải quyết bài toán \r\ntóm tắt văn bản trong ngôn ngữ tiếng Anh và tiếng Việt sử dụng NMF và phân tích \r\nđặc trưng.  \r\n\r\n \r\n\r\n \r\n \r\n \r\n2.4.1 Khối tiền xử lý văn bản \r\n\r\n2.4.1.1 Khối tiền xử lý văn bản tiếng Việt \r\n \r\n\r\nQuá trình tiền xử lý văn bản đầu vào tiếp theo gồm các bước sau:  \r\n Chia văn bản thành các câu. \r\n Chia nhỏ từng câu thành các từ. \r\n Chuyển toàn bộ văn bản về dạng chữ thường \r\n Loại bỏ các kí tự đặc biệt, không có ý nghĩa \r\n\r\nPhần tách câu và tách từ sử dụng công cụ Vitk (Vietnamese Text Progressing \r\nToolkit)  của tác giả Lê Hồng Phương. Ví dụ câu Mỹ: hai tai nạn trên đường cao \r\ntốc, 11 người thiệt mạng sau khi qua tool sẽ được tách thành Mỹ : hai tai_nạn trên \r\nđường_cao_tốc , 11 người thiệt_mạng . \r\n\r\nCác kí tự đặc biệt như \"\\-;%()|+&=*%.,!?:#$@\\/ cũng sẽ bị loại bỏ khỏi văn \r\nbản. \r\n\r\n2.4.1.2 Khối tiền xử lý văn bản tiếng Anh \r\n \r\n Bước tiền xử lý gồm 2 hoạt động chính là Chuẩn hoá từ và Loại bỏ các cấu \r\ntrúc ngữ pháp của từ, đău về dạng nguyên thể trong tiếng Anh.  \r\n\r\n\r\n\r\n\r\nCả hai hoạt động này đều đóng vai trò quan trọng trong việc vec-tơ hóa tài liệu bởi \r\nvì nó sẽ làm giảm không gian biểu diễn của văn bản xuống, do đó làm giảm khối \r\nlượng cần tính toán. \r\n  \r\n\r\nCụ thể, quá trình tiền xử lí văn bản đầu vào bao gồm các công việc sau: \r\n Chia văn bản đầu vào thành tập các câu. \r\n Chia nhỏ câu thành các từ. \r\n Lọc stopwords \r\n Chuẩn hóa từ \r\n\r\n Lemmatizing \r\n Stemming \r\n \r\n\r\n Stemming  \r\n\r\n Là kĩ thuật hình thái từ dành cho khai phá thông tin (Information retrieval) \r\nđược ứng dụng rộng rãi nhất. Stemming là kĩ thuật dùng để biến đổi một từ về dạng \r\ngốc (được gọi là stem hoặc root form) bằng cách cực kì đơn giản là loại bỏ một số \r\nkí tự nằm ở cuối từ mà nó nghĩ rằng là biến thể của từ. Người ta gọi các bộ xử lí \r\nstemming là stemmer. Bởi vì nguyên tắc hoạt động của stemmer rất đơn giản nên \r\ntốc độ xử lí của nó rất nhanh nhưng đôi khi lại cho ra kết quả không như ý muốn. \r\n\r\n Ví dụ 4: Cách thực hiện của bộ stemmer \r\n\r\n Các từ walks, walked, walkingsau khi stemming, bỏ đi các hậu \r\ntố -s, -ed, -ing sẽ trở thành walk \r\n\r\n Từ gosesau stemming thành gos \r\n Không thể đưa các từ như spoke, went về dạng speak hay go \r\n\r\n Lemmatization   \r\n\r\n Lemmatization là một kĩ thuật chuẩn hóa từ khác: Không giống với \r\nStemming là xử lí bằng cách loại bỏ các kí tự cuối từ một cách kinh nghiệm \r\n(heuristic), Lemmatization sẽ xử lí thông minh hơn bằng một bộ từ điển hoặc \r\nontology (hệ thống nhãn ngữ nghĩa) nào đó. Điều này đảm bảo đưa chính xác các \r\ndạng biến thể của từ về nguyên gốc trong từ điển. Người ta gọi bộ xử lí \r\nlemmatization là lemmatizer \r\n\r\n Nhược điểm của lemmatization là tốc độ xử lí khá chậm vì phải thực hiện tra \r\ncứu từ trong cơ sở dữ liệu. Trong các ứng dụng xử lí ngôn ngữ tự nhiên mà cần độ \r\n\r\n\r\n\r\n\r\nchính xác cao hơn và thời gian không quan trọng, người ta có thể sử dụng \r\nLemmatization. \r\n\r\n Ví dụ 5: Cách thực hiện của Lemmatizer \r\n\r\n Các từ như gose, wentsẽ được đưa chính xác về go. \r\n Các danh từ như mouse, micecũng được đưa về cùng một dạng \r\n\r\nnhư nhau. \r\n\r\n Loại bỏ stopwords \r\n\r\n Trong quá trình tính toán, stopwords là những từ được lọc trước hoặc sau quá \r\ntrình xử lý dữ liệu ngôn ngữ tự nhiên (văn bản). Stopwords thường là những từ xuất \r\nhiện với tần suất lớn trong một ngôn ngữ, do đó không có một danh sách các \r\nstopwords thống nhất và được sử dụng bởi tất cả các công cụ xử lý ngôn ngữ tự \r\nnhiên. \r\n\r\n Một nhóm bất kì các từ có thể được chọn là một stopwords để thực hiện một \r\nmục đích nhất định. Đối với một search engine, có một số từ được xếp vào loại stop \r\nwords do sự xuất hiện thường xuyên trong các trường hợp tìm kiếm như: the, is, at, \r\nwhich và on. Trong trường hợp này, stopwords có thể là nguyên nhân gây ra vấn đề \r\nkhi tìm kiếm theo phrases mà bao gồm những function word này, đặc biệt là khi tìm \r\nkiếm một số tên như: The Who, The The, hoặc Take That. Ngoài ra, một số \r\nsearch engine loại bỏ các từ common words, bao gồm cả lexical words như want \r\nkhỏi câu truy vấn nhằm mục đích cải thiện hiệu suất của search engine. \r\n\r\n Sự phân biệt giữa function words và lexical words được đề xuất bởi C. Fries \r\nvào năm 1952 và có một tầm ảnh hưởng lớn đến việc dạy tiếng Anh. \r\n\r\n Function words: Còn gọi là functors là những từ có một chút lexical \r\nmeaning hoặc có sự nhập nhằng về nghĩa và chúng nhấn mạnh mối \r\nquan hệ ngữ pháp với các từ khác trong cùng một câu, một quan điểm \r\ncụ thể hay tâm trạng của người nói. Một số trường hợp của function \r\nwords: Pronouns  đại từ (he  him, she-her,.); conjunction  liên từ \r\nhoặc auxiliary verb - trợ động từ \r\n\r\n Lexical words: Từ thực, những từ mà không phải là function word. \r\nlexical word bao gôm: danh từ, động từ, tính từ và hầu hết trạng từ vì \r\ncó một số trạng từ là function word như: then, why. \r\n\r\n Từ điển có thể định nghĩa một cách cụ thể một lexical word, nhưng \r\nchỉ có thể miêu tả một cách sử dụng tổng quát của function word. \r\n\r\n\r\n\r\n\r\n Ngược lại, ngữ pháp có thể miêu tả cách sử dụng của function words \r\nmột cách chi tiết, nhưng lại chỉ có thể xem lexical words trong các \r\nthuật ngữ chung (general term). \r\n\r\n \r\n2.4.2 Độ tương đồng Cosine trong Không gian Vec-tơ \r\n\r\nTrong mục này, em sẽ trình bày những kiến thức cơ bản về thước đo cosine \r\nđược sử dụng để xác định độ tương đồng giữa 2 từ trong mô hình Word2Vec và ứng \r\ndụng trong phạm vi đồ án. \r\n\r\n \r\nTích vô hướng \r\n\r\n \r\n Chúng ta bắt đầu với định nghĩa về số học của tích vô hướng giữa hai vec-tơ: \r\n ! = !#, !%, !&, .    và ! = !#, !%, !&, .    với an và bn lần lượt là các thành phần \r\ncủa vec-tơ !   ,  !   và n là số chiều của các vec-tơ: \r\n \r\n !. # = !%#% = !&#& + !(#( + + !*#*\r\n\r\n*\r\n\r\n%+&\r\n \r\n \r\n\r\n \r\n\r\n \r\n Tuy nhiên, để thấy được hết ý nghĩa của phép nhân vô hướng giữa 2 vec-tơ, \r\nchúng ta phải xem xét đến định nghĩa hình học của nó: \r\n \r\n !\" = !\" cos (   \r\n\r\n \r\n Sử dụng tính chất giao hoán để sắp xếp lại vế phải của công thức trên ta có: \r\n \r\n !\" = \"! cos (   \r\n\r\n \r\n Trong lý thuyết hình học, phép nhân \" cos &   chính là phép chiếu của vect-\r\ntơ !   lên vec-tơ !   , \r\n \r\n\r\n\r\n\r\n\r\n \r\n\r\n \r\n Khi vec-tơ !   vuông góc với vec-tơ !   tích này trở thành: \r\n\r\n \r\n\r\n \r\n Khi 2 vec-tơ vuông góc, tích vô hướng của chúng bằng 0. Đây cũng là một \r\ncách để chúng ta kiểm tra 2 vec-tơ có quan hệ vuông góc hay không. Tuy nhiên, ví \r\ndụ trên mới chỉ dừng lại ở  không gian vec-tơ hai chiều, nhưng có một điều thú vị \r\nrằng, chúng ta cũng có thể tính toán góc và độ tương đồng giữa các vec-tơ trong \r\nkhông gian nhiều chiều, mà trong bài toán của chúng ta là Không gian vec-tơ 300 \r\nchiều. \r\n \r\n Độ tương đồng Cosine \r\n \r\n Độ tương đồng cosine giữa hai vec-tơ (hoặc 2 từ trong Không gian vec-tơ) là \r\nmột thước đo tính giá trị cosine của góc giữa chúng. Thước đo này là thước đo về \r\nhướng của 2 vec-tơ, không phải thước đo về độ lớn. \r\n Ta có: \r\n \r\n\r\ncos $ = &'\r\n&'\r\n\r\n \r\n \r\n\r\n \r\n\r\n Đây chính là công thức về độ tương đồng cosine. Độ tương đồng cosine sẽ \r\nsinh ra một số, số này sẽ cho chúng ta biết 2 từ liên quan đến nhau như thế nào \r\ntrong không gian bằng cách xem xét góc giữa chúng, thay vì so sánh về độ lớn. \r\n \r\n\r\n \r\n\r\n\r\n\r\n\r\n       a)  Cùng hướng                      b) Vuông góc                         c) Đối diện \r\n \r\n\r\n2.4.3 Khối tính điểm cho câu sử dụng NMF \r\n\r\nKhối tính điểm cho câu trong tài liệu là tổng hợp điểm đầu ra của 3 khối nhỏ \r\nhơn, trong đó: \r\n\r\n Sử dụng khối Word2Vec như một đặc trưng thứ nhất để xác định các \r\nngữ nghĩa ẩn trong bài toán tóm tắt. \r\n\r\n Sử dụng khối đặc trưng thứ hai để phân tích các đặc trưng cấu trúc \r\ncủa tài liệu. \r\n\r\n Sử dụng kết quả của kĩ thuật phân tích ma trận NMF.  \r\nỞ đây ta sẽ sử dụng một phương pháp mới để chọn câu dựa trên phân tích \r\n\r\nNMF và định nghĩa đại lượng Generic Relevance of a Sentence (GRS)  như sau: \r\n \t   \r\n\r\n\t\t\t\t\t\t\t\t\t\"#$#%&'\t(#)#*+$'#\t,-\t+\t./\t1#$/#$'# = \t 3457#&8/ 34*\r\n:\r\n\r\n4;<\r\n \r\n\r\n \r\n  \r\n !\"#$& '(* =\r\n\r\n'(+,+-.\r\n'/+,+-.0/-.\r\n\r\n \r\n \r\n\r\n \r\n\r\n \r\n Trong đó, trọng số weight(Hi*) là sự liên quan về quan hệ (relative \r\nrelevance) của đặc trưng ngữ nghĩa thứ i (W*i) với tất cả các đặc trưng ngữ nghĩa \r\ncòn lại. Một cách tổng quát, đại lượng thể hiện mức độ liên quan của một câu chính \r\nlà mức độ phản ánh của câu đó đối với chủ đề chính của tài liệu, và được biểu diễn \r\ndưới hình thức các đặc trưng ngữ nghĩa. \r\n2.4.4 Khối tính điểm đặc trưng cấu trúc \r\n\r\na. Đặc trưng bề mặt \r\n \r\n\r\nCác câu đầu đứng đầu hầu như mang nhiều nội dung tóm tắt hơn các câu \r\nphía sau. Do đó ta sẽ ưu tiên cho các câu này. Công thức tính điểm như sau: \r\n\r\n position = \r\n!\r\n\"#!    (  i là hệ số vị trí câu)  \r\n\r\nTrong đó:  \r\n i: là hệ số vị trí câu \r\n position: là kí hiệu điểm đặc trưng vị trí \r\n \r\n\r\n\r\n\r\n\r\nCác câu quá ngắn cũng không mang nhiều giá trị. Do vậy những câu độ dài \r\nnhỏ hơn 10 từ sẽ bị điểm trừ: \r\n\r\nlengthSent = !\"#$%&\t(\t)*)*     (  i là hệ số vị trí câu, !\"#$%&   là số từ xuất                    \r\nhiện trong câu thứ i) \r\n\r\n Trong đó: \r\n  i: là hệ số vị trí câu \r\n  !\"#$%&  : là số từ xuất hiện trong câu thứ i \r\n  lengthSent: là kí hiệu điểm đặc trưng đồ dài \r\n\r\nb. Đặc trưng nội dung \r\n \r\n\r\nChúng ta sẽ sử dụng 2 phương pháp centroid base và frequence word để tính \r\nđiểm đặc trưng nội dung. \r\nCentroid dựa trên độ tương đồng giữa các câu trong văn bản. Ở đây em sử \r\ndụng hàm cosin để tính độ tương đồng giữa câu với đầu vào là vectơ biểu \r\ndiễn từ sử dụng word2vec. \r\n !\" = $%&%'()%*+($\", $.)0.12     \r\nTrong đó: \r\n n: là tổng số câu trong văn bản \r\n i: là vị trí câu hiện tại \r\n !\"  : là kí hiệu điểm centroid của câu thứ i \r\n \r\nFrequence word lại tính điểm câu dựa trên tần suất xuất hiện các từ quan \r\ntrọng trong câu. Ở đây qua quá trình thực nghiệm em chọn ngưỡng 20% từ \r\nxuất hiện nhiều nhất trong văn bản đầu vào.  \r\n \r\n\r\n  Fi = !(#$)&(')\r\n(\r\n)            \r\n\r\n \r\n Trong đó:  \r\n\r\nf(!\"  ): tổng số lần xuất hiện của từ k trong cả văn bản \r\n  s(d): tổng số lần xuất hiện của tất cả các từ trong văn bản \r\n  Fi : là điểm Frequence của câu thứ i \r\n\r\nc. Đặc trưng độ liên quan \r\nỞ phương pháp tính theo đặc trưng độ liên quan em đề suất sử dụng 2 \r\nphương pháp đó là tính theo độ liên quan với câu đầu tiên FirstRel và \r\nphương pháp PageRank. PageRank là phương pháp khai thác liên quan giữa \r\n\r\n\r\n\r\n\r\ncác câu bằng việc xây dựng một bản đồ câu. Dựa trên bản đồ này thuật toán \r\nPageRank được áp dụng để đánh giá tầm quan trọng của một câu. \r\n !\" = $%&%'()%*+($\", $.)    ( độ tương đồng từng câu so với câu đầu tiên) \r\nTrong đó: \r\n !\"  : là vecto biểu diễn câu thứ i \r\n !\"  : là điểm FirstRel của câu thứ i \r\n \r\n\r\n2.4.5 Khối trích rút câu \r\n\r\n Kết hợp các phương pháp trên ta có công thức cuối cùng để tính điểm \r\ncho từng câu: \r\n \r\n! \" = \t!%&' +\t!)  \r\n \r\nTrong đó: \r\n\r\n ! \" \t  : Trọng số cuối cùng của câu s \r\n !\"#$   : Trọng số thu được từ phân tích ma trận NMF \r\n !\"  :  Trọng số thu được từ phân tích các đặc trưng cấu trúc của câu. \r\n\r\n \r\n!\" # = \t&'( # +\t&*+ # +\t&,-(#)  \r\n \r\nTrong đó: \r\n\r\n !\" # \t  : Trọng số đặc trưng cho câu s \r\n ! \" \t  Điểm đặc trưng nội dung (Content) \r\n ! \"   : Điểm đặc trưng bề mặt (Surface) \r\n !(#)  : Điểm đặc trưng độ liên quan (Relevance) \r\n !\", !$, !%\t  :  lần lượt là các trọng ứng với các đặc trưng về nội dung, bề \r\n\r\nmặt và liên quan được tính toán và điều chỉnh dựa trên kết quả thực \r\nnghiệm.  \r\n \r\n \r\n\r\n2.5 Thực nghiệm \r\n \r\n2.5.1 Môi trường thử nghiệm \r\n\r\n Chương trình được xây dựng và thử nghiệm trên máy tính cá nhân có cấu \r\nhình và các phần mềm cần thiết như sau:  \r\n\r\n- Vi xử lý: 2.2 GHz Quad-Core Intel Core i7 Crystalwell \r\n\r\n\r\n\r\n\r\n- Ram: 16Gb  \r\n- Hệ điều hành: MacOs Sierra \r\n- Phần mềm phát triển: PyCharm \r\n- Ngôn ngữ sử dụng: Python \r\n- Thư viện tách từ, xử lý từ tiếng Anh: nltk \r\n- Thư viện tách từ, tách câu tiếng Việt: vnTokenizer \r\n\r\n \r\n2.5.2 Phương pháp đánh giá \r\n\r\nĐánh giá kết quả tóm tắt văn bản là một việc làm khó khăn trong thời điểm \r\nhiện tại. Việc sử dụng ý kiến đánh giá của các chuyên gia ngôn ngữ được xem là \r\ncách đánh giá tốt nhất, tuy nhiên, cách làm này lại tốn rất nhiều chi phí. Bên cạnh \r\ncác phương pháp đánh giá thủ công do các chuyên gia thực hiện, vấn đề đánh giá tự \r\nđộng kết quả tóm tắt cũng nhận được nhiều sự chú ý hiện nay. NIST kể từ năm \r\n2000 đã tổ chức hội nghị DUC mỗi năm một lần để thực hiện việc đánh giá với quy \r\nmô lớn các hệ thống tóm tắt văn bản. Việc đánh giá tựu động này nhằm mục đích là \r\ntìm ra được một độ đo đánh giá tóm tắt gần với những đánh giá của con người \r\nnhất.Trong bài toán này em lựa chọn phương pháp Rouge để làm thước đo đánh giá \r\nđộ chính xác cho cả bài toán tóm tắt văn bản tiếng Anh lẫn tóm tắt văn bản tiếng \r\nViệt. \r\n\r\nRecall Oriented Understudy (ROUGE) là một phương pháp do Lin và Hovy \r\nđưa ra vào năm 2003 cũng dựa trên các khái niệm tương tự. Phương pháp này sử \r\ndụng n-gram để đánh giá sự tương quan giữa các kết qủa của mô hình tóm tắt và tập \r\ndữ liệu đánh giá. Phương pháp này đã cho ra kết quả khả quan và được sự đánh giá \r\ncao của cộng đồng nghiên cứu tóm tắt văn bản. \r\n\r\nROUGE-N là một thu hồi n-gram (n-gram recall) giữa một bản tóm tắt tự \r\nđộng và một tập các tài liệu tóm tắt tham chiếu (ReferenceSummaries). ROUGE-N \r\nđược tính như sau: \r\n   \r\n \r\n\r\n\t\t\t\t\t\t\"#$%&-( = \t *+,-./0123 456789:0/;=={?@A@:@82@=B//0:C@D} *+,-.(45678)9:0/;=={?@A@:@82@=B//0:C@D}\r\n \r\n \r\n\r\n \r\nTrong đó: \r\n\r\n n là chiều dài của n-gram \r\n Countmatch(gramn) là số lượng tối đa n-gram có thể xảy ra đồng thời \r\n\r\ntrong bản tóm tắt tự động và bản tóm tắt tham chiếu. \r\n\r\n\r\n\r\n\r\n Rõ ràng ROUGE-N là một độ đo liên quan đến độ recall bởi vì mẫu số của \r\nvế phải trong công thức trên là tổng số n-gram xảy ra ở phía bản tóm tắt tham \r\nchiếu. \r\n Cũng có một lưu ý rằng, số lượng n-gram ở mẫu số trong công thức tính \r\nROUGE-N sẽ tăng lên khi chúng ta cho thêm nhiều tham chiếu. Điều này hoàn toàn \r\ntrực quan và hợp lí bởi vì có thể tồn tại nhiều bản tóm tắt tốt. \r\n Mỗi khi chúng ta thêm một tham chiếu vào tập các văn bản tham chiếu, \r\nchúng ta đã mở rộng không gian các văn bản tóm tắt thay thế (alternative \r\nsummaries). Bằng cách điều khiển các kiểu tham chiếu mà ta thêm vào tập văn bản \r\ntham chiếu, chúng ta có thể thiết kế các đánh giá tập trung vào các khía cạnh khác \r\nnhau của việc tóm tắt. Ngoài ra, tổng tử số lớn hơn tổng số số bản tóm tắt tham \r\nchiếu. Điều này hiệu quả vì cung cấp thêm nhiều trọng số để matching các n-grams \r\nxảy ra trong đa tham chiếu. Do đó, một bản tóm tắt tự động càng chứa nhiều những \r\ntừ được xuất hiện trong nhiều bản tóm tắt tham chiếu thì sẽ dành được điểm \r\nROUGE-N càng cao. Điều này một lần nữa lại rất trực quan và hợp lí bởi vì chúng \r\nta thường ưu tiên các bản tóm tắt tự động càng có nhiều nét giống với các điểm \r\ngiống nhau giữa các bản tóm tắt tham chiếu càng tốt. \r\n Khi sử dụng đa tham chiếu, chúng ta tính ROUGE-N theo từng cặp, giữa bản \r\ntóm tắt tự động s và từng bản tóm tắt tham chiếu ri trong tập các văn bản tóm tắt \r\ntham chiếu. Sau đó, kết quả điểm ROUGE-N cuối cùng trong đa tham chiếu sẽ là \r\nđiểm ROUGE-N cao nhất trong tất cả các cặp được tính. Điều này có thể được thể \r\nhiện theo công thức sau: \r\n \r\n !\"#$%-' = )*+,)-.!\"#$%-' *., 0    \r\n\r\n \r\n Trong quá trình khởi tạo, thuật toán đánh giá sử dụng thủ tục Jackknifing. \r\nCho M tham chiếu, chúng ta tính điểm tốt nhất khi duyệt qua M tập tham chiếu M-\r\n1; điểm ROUGE-N cuối cùng là trung bình cộng của M điểm ROUGE-N đối với \r\ncác tham chiếu M-1. Thủ tục Jackknifing được chọn bởi chúng ta thường cần so \r\nsánh hiệu suất giữa con người và hệ thống và bản tóm tắt tham chiếu thường chỉ do \r\ncon người tóm tạo ra. \r\n Bằng cách áp dụng thủ tục này, chúng ta có thể ước lượng hiệu suất trung \r\nbình của con người bằng việc lấy trung bình cộng M điểm ROUGE-N của một bản \r\ntham chiếu với toàn bộ M-1 tham chiếu. \r\n\r\n \r\n \r\n\r\n\r\n\r\n\r\n2.5.3 Thực nghiệm trên dữ liệu văn bản tiếng Anh \r\n\r\n2.5.3.1  Dữ liệu thực nghiệm \r\nDữ liệu được sử dụng trong chương trình là bộ dữ liệu DUC2007. Đây là các \r\n\r\nbài báo tin cậy phủ rộng trong nhiều lĩnh vực. Bộ dữ liệu gồm 43 bản ghi, mỗi bản \r\nghi gồm khoảng 10 văn bản, ứng với mỗi bản ghi lại có 3 bản tóm tắt. \r\n\r\nĐồ án sử dụng tập dữ liẹu DUC2007 như là một tập dữ liệu để kiểm tra. \r\nDocument Understanding Conference (DUC) là một hội nghị quốc tế để đánh giá \r\nhiệu suất của hệ thống tóm tắt bằng cách so sánh bản tóm tắt bằng tay của các \r\nchuyên gia với bản tóm tắt tự động của máy tính. DUC2007 là bộ dữ liệu dùng cho \r\ntác vụ tóm tắt đa văn bản, gồm 50 bản ghi, mỗi bản ghi gồm nhiều văn bản có cùng \r\nchủ đề. Để phù hợp với bài toán đặt ra ta coi mỗi bản ghi đó là một đơn văn bản. \r\nBản tóm tắt cũng gồm 50 bản ghi, mỗi bản có độ dài 250 từ.  \r\n Trong quá trình tiền xử lý dữ liệu em sử dụng thư viện ntlk cho quá trình \r\ntách từ, loại bỏ stopword, lemmatized. Phần tách câu được bỏ qua do bộ dữ liêu đã \r\nchia câu sẵn trong các thẻ xml.  \r\n\r\n2.5.3.2 Kết quả thực nghiệm \r\n Đồ án tập trung vào việc nghiện cứu kết hợp phương pháp tóm tắt không \r\ngiám sát  đại diện là phương pháp phân tích ma trận NMF với phương pháp tóm \r\ntắt dựa trên các đặc trưng cấu trúc.  \r\n  \r\n\r\nRouge  \r\nFeature\t\r\n\r\nRouge-1 \r\n(%) \r\n\r\nRouge-2 \r\n(%) \r\n\r\nRelevance 41.92         10.48 \r\n\r\nSurface 39.04           9.29 \r\n\r\nContent 42.37 10.69 \r\n \r\n\r\n \r\n Từ bảng kết qủa trên cho chúng ta nhận xét trong 3 đặc trưng thì đặc trưng \r\nContent cho chất lượng văn bản tóm tắt tốt nhất, 42.37% với Rouge-1 và 10.69% \r\nvới Rogue-2. Đặc trưng Relevance có độ quan trọng thứ 2 với điểm số gần như \r\ntương tự 41.92% với Rouge-1 và 10.48% với Rouge-2 \r\n \r\n \r\n\r\n\r\n\r\n\r\nRouge  \r\nFeature\t\r\n\r\nRouge-1 \r\n(%) \r\n\r\nRouge-2 \r\n(%) \r\n\r\nNMF 41.67           9.99 \r\n\r\n3 features 41.56 10.42 \r\n\r\nNMF + 3 features 42.34 10.77 \r\n \r\n\r\n \r\nKhi kết hợp cả 2 phương pháp với nhau hệ thống cho kết qủa tốt nhất với điểm \r\nRouge-2 là 10.77% và Rouge-1 là 42.34%. Từ bản trên ta cũng có thể thấy phương \r\npháp NMF đơn thuần cho kết quả cao hơn với phương pháp đặc trưng cấu trúc \r\n41.67% với 41.56% \r\n Qua kết quả trên chúng ta có thể rút ra được nhận xét: \r\n\r\n Trong phạm vi nghiên cứu, đồ án đã chứng minh được phương pháp \r\nkết hợp cả 2 hướng tiếp cận NMF và cấu trúc mang kết qủa tốt hơn \r\nkhi sử dụng đơn lẻ từng phương pháp \r\n\r\n Do tính đặc trưng của ngôn ngữ học, sự kết hợp các đặc trưng cấu trúc \r\nkhông phải luôn tuân theo quy luật tỉ lệ thuận giữa điểm ROUGE-1 và \r\nROUGE-2. \r\n\r\n Việc kết hơp cả 3 phương pháp đặc trưng cấu trúc không hẳn là một \r\nlựa chọn tốt do làm giảm hiệu năng khi so sách với trường hợp sử \r\ndụng từng đặc trưng một. \r\n\r\n    \r\n2.5.4 Thực nghiệm trên dữ liệu văn bản tiếng Việt \r\n\r\n2.5.4.1  Dữ liệu thực nghiệm \r\n \r\n\r\nDữ liệu trong bài toán sử dụng là hơn một triệu văn bản từ Báo Mới. Sau đó \r\nchọn ra 100 văn bản để tóm tắt. Tách riêng phần lead + head của bài báo và coi đó \r\nlà văn bản tóm tắt đúng. Phần giữ lại chính là đầu vào của bài toán. \r\n\r\nĐồ án sử dụng tập dữ liệu được chọn ra từ hơn một triệu văn bản từ Báo \r\nMới. Bộ dữ liệu Báo Mới có dung lượng 3.64GB được chia thành 1000 bản ghi, \r\nmỗi bản ghi gồm hơn 1000 văn bản được chia cắt bởi kí tự #. Bản thân bộ dữ liệu \r\ncũng đã được tiền xử lý qua trước, 2 câu đầu tiên của mỗi văn bản là tiêu \r\nđề(heading) và phần miêu tả (description), từ câu thứ 3 trờ đi là phần nội dung của \r\nvăn bản. \r\n\r\n\r\n\r\n\r\n Bước đầu tiên của quá trình tiền xử lý là phải tách riêng từng văn bản từ tập \r\n1000 bản ghi, sau đó loại bỏ những văn bản trùng lặp. Chọn trong tập văn bản \r\nnhững văn bản thoả mãn điều kiện có số từ tổng cộng ở phần headline + description \r\ntrong khoảng 240-260 từ, phần này sau đó sẽ được tách ra để làm dữ liệu đánh giá \r\nkết qảu của chương trình. Phần nội dung văn bản cũng phải thoả mãn có độ dài \r\ntrung bình từ 1300 đến 1400 từ. Sau quá trình này thu được 140 văn bản từ tập hơn \r\n1 triệu văn bản thoả mãn yêu cầu. \r\n Trước khi đưa vào NMF 140 văn bản trên được tiền xử lý tiếp qua các bước \r\ntách câu, tách từ, lowercase, loại bỏ kí tự đặc biệt. Phần tách câu và tách từ em sử \r\ndụng công cụ vnTokenizer phiên bản 4.1.1 của Tiến sĩ Lê Hồng Phương. Bộ cung \r\ncụ được viết bằng java có các chức năng chính như tách từ, tách câu, gán nhãn từ \r\nloại với độ chính xác khoảng 98%.  Phần lowercase và loại bỏ kí tự đặc biệt được \r\nthực hiện qua phương thức clean_text \r\n \r\ndef clean_text(text):  \r\n    text = text.lower() \r\n    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE) \r\n    text = re.sub(r'\\<a href', ' ', text) \r\n    text = re.sub(r'&amp;', '', text) \r\n    text = re.sub(r'[\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text) \r\n    text = re.sub(r'<br />', ' ', text) \r\n    text = re.sub(r'\\'', ' ', text) \r\n \r\n    return text \r\n\r\n2.5.4.2 Kết quả thực nghiệm \r\n  \r\n\r\nRouge  \r\nFeature\t\r\n\r\nRouge-1 \r\n(%) \r\n\r\nRouge-2 \r\n(%) \r\n\r\nRelevance 53.33         10.35 \r\n\r\nSurface 53.98         10.58 \r\n\r\nContent 54.87 11.25 \r\n \r\n\r\n \r\n Đặc trưng Content vẫn cho kết quả tốt nhất như với bài toán tóm tắt văn bản \r\ncho tiếng Anh 54.87% với Rouge 1 và 11.25% đối với Rouge 2. Đặc trưng Surface \r\nvới bài toán tóm tắt tiếng Việt lại cho kết quả cao hơn so với đặc trưng Relevance \r\n0.65% cho Rouge 1 và 0.23% cho Rouge 2 trong khi bài toán tóm tắt với tiếng Anh \r\nđặc trưng Relevance lại cho kết qủa cao hơn so với Surface. Nguyên nhân có thể \r\nđược giải thích do tập dữ liệu đầu vào của 2 bài toán có cấu trúc khác nhau. Đối với \r\n\r\n\r\n\r\n\r\nbài toán tóm tắt văn bản cho tiếng Anh dữ liệu đầu vào là các văn bản có chung chủ \r\nđề được ghép lại với nhau còn dữ liệu cho bài toán tóm tắt bằng tiếng Việt chỉ có \r\nmột văn bản duy nhất.  \r\n  \r\n\r\nRouge  \r\nFeature\t\r\n\r\nRouge-1 \r\n(%) \r\n\r\nRouge-2 \r\n(%) \r\n\r\nNMF 53.23         10.33 \r\n\r\n3 features 54.07         10.31 \r\n\r\nNMF + 3 features 54.57 11.53 \r\n \r\n\r\n \r\n\r\nKhi kết hợp cả 2 phương pháp với nhau hệ thống cho kết qủa tốt nhất với điểm \r\nRouge-2 là 11.53% và Rouge-1 là 54.57%. Việc kết hợp 2 cách tiếp cận vẫn đem lại \r\nkết quả tốt hơn khi áp dụng đơn lẻ với từng phương pháp khi áp dụng cho ngôn ngữ \r\ntiếng Việt. Và việc kết hợp cả 3 phương pháp đặc trưng vẫn cho kết quả thấp hơn \r\nmột số đặc trưng đơn lẻ, việc này là do các trọng số từng đặc trưng vẫn chưa được \r\ntối ưu một cách tốt nhất. \r\n \r\n2.6 Tóm tắt chương \r\n \r\n Chương này đã đưa ra một cái nhìn tổng quan về các kĩ thuật: Phân tích ma \r\ntrận, các đặc trưng cấu trúc của văn bản trong vấn đề khai phá dữ liệu văn bản mà \r\ncụ thể là bài toán Tóm tắt văn bản tự động. Ứng dụng phương pháp này cho cả 2 \r\nngôn ngữ tiếng Anh và tiếng Việt. \r\n Đồ án đã đề suất một cách tiếp với bài toán tóm tắt văn bản dựa vào trích \r\nxuất bằng cách sử dụng ma trận không âm NMF kết hợp với trích suất đặc trưng và \r\nchứng minh được tính hiệu quả của phương pháp khi áp dụng trên cả 2 ngôn ngữ \r\ntiếng Việt và tiếng Anh. Các thí nghiệm của em được thực hiện với các kịch bản \r\nkhác nhau bằng bộ dữ liệu DUC2007 cho tiếng Anh và bộ dữ liệu Báo Mới cho \r\ntiếng Việt. Kết quả thí nghiệm cho thấy khi NMF được kết hợp với ba loại đặc \r\ntrưng câu (đặc trưng bề mặt, đặc trưng độ liên quan, đặc trưng nội dung). Các phép \r\nđo Rouge-1 và Rouge-2 của hệ thống tăng 0.67% và 0.78% so với NMF cơ bản khi \r\nthử nghiệm trên bộ dữ liệu tiếng Anh và 1.34% và 1.2% khi thử nghiệm trên bộ dữ \r\nliệu tiếng Anh. \r\n\r\n\r\n\r\n\r\n Kết quả của chương này đã được viết thành bài báo Enhancing extractive \r\nsummarization using non-negative matrix factorization with semantic aspects and \r\nsentence features và đã được accept ở hội nghị SoIct 2017[1] \r\n \r\n \r\n\r\n\r\n\r\n\r\nCHƯƠNG 3 PHƯƠNG PHÁP TÓM TẮT VĂN BẢN SỬ DỤNG DEEP \r\nLEARNING \r\n\r\n \r\n3.1 Giới thiệu công nghệ học sâu \r\n \r\n\r\nTrong những năm qua, thuật ngữ \"deep learning\" (học sâu) đã dần len lỏi trong \r\ncác cuộc hội thảo khi bàn về trí tuệ nhân tạo (AI), dữ liệu lớn (Big Data) và phân \r\ntích (Analytics). Đây là một cách tiếp cận đầy hứa hẹn tới AI khi phát triển các hệ \r\nthống tự trị, tự học, những thứ đang cách mạng hóa nhiều ngành công nghiệp. \r\n\r\n \r\n\r\n \r\nNếu coi ta học máy (machine learning) là công nghệ tiên tiến nhất, thì học sâu \r\n\r\nlà \"tiên tiến của tiên tiến\". Học máy lấy một vài ý tưởng cốt lõi của trí tuệ nhân tạo \r\nvà tập trung vào việc giải quyết các vấn đề thế giới thực với các mạng thần kinh \r\nđược thiết kế để bắt chước khả năng đưa ra quyết định của chúng ta. Học sâu, đúng \r\nnhư tên gọi của nó, đi sâu hơn nữa vào một tập hợp các công cụ và kỹ thuật học \r\nmáy, từ đó áp dụng chúng để giải quyết bất kỳ vấn đề nào đòi hỏi \"khả năng tư duy\" \r\n con người hay nhân tạo. \r\n\r\nVề cơ bản, học sâu là cho một hệ thống máy tính \"ăn\" rất nhiều dữ liệu, để \r\nchúng có thể sử dụng và đưa ra các quyết định về những dữ liệu khác. Dữ liệu này \r\nđược nạp thông qua các mạng thần kinh, tương tự như học máy. Những mạng lưới \r\nnày  các cấu trúc logic yêu cầu một loạt các câu hỏi đúng/sai, hoặc trích xuất một \r\ngiá trị số, của mỗi bit dữ liệu đi qua chúng và phân loại theo các câu trả lời nhận \r\nđược. \r\n\r\nVì công việc của học sâu là tập trung phát triển những mạng lưới này, chúng \r\nđã trở thành \"mạng thần kinh sâu\" (Deep Neural Network)  những mạng logic \r\n\r\n\r\n\r\n\r\nphức tạp cần thiết để xử lý các bộ dữ liệu lớn, như thư viện hình ảnh của Google \r\nhay Instagram. \r\n\r\nVới các bộ dữ liệu toàn diện như vậy, và các mạng logic phức tạp để xử lý \r\nphân loại chúng, việc một chiếc máy tính lấy một hình ảnh và nhận dạng với độ \r\nchính xác cao trở nên \"quá đỗi bình thường\". \r\n\r\nCác hình ảnh là ví dụ tuyệt vời nhất về cách thức hoạt động của học sâu, vì \r\nchúng có chứa nhiều yếu tố khác nhau và để hiểu rõ được làm thế nào để máy tính, \r\nvới não bộ một chiều chủ yếu dựa trên sự tính toán, có thể học cách giải thích chúng \r\ngiống như con người. Tuy vậy, học sâu có thể được áp dụng cho bất kỳ hình thức \r\ndữ liệu nào  âm thanh, video, lời nói, chữ viết,...  để đưa ra những kết luận như \r\nthể do con người thực hiện với tốc độ rất nhanh. Chúng ta hãy thử xem xét một số \r\nví dụ thực tiễn. \r\n\r\nGiả sử một hệ thống được thiết kế để tự động ghi nhận và báo cáo có bao nhiêu \r\nchiếc xe của một mẫu xe nhất định đã đi ngang qua một con đường. Trước tiên, nó \r\nsẽ được quyền truy cập vào một cơ sở dữ liệu khổng lồ về các loại xe, bao gồm hình \r\ndáng, kích thước và thậm chí là tiếng của động cơ. Điều này có thể được biên soạn \r\ntheo cách thủ công hoặc, trong các điều kiện tiên tiến hơn, được thu thập tự động \r\nbởi hệ thống nếu như nó được lập trình để tìm kiếm trên internet và lấy dữ liệu mà \r\nnó tìm thấy ở đó. Tiếp theo, nó sẽ lấy dữ liệu cần được xử lý  dữ liệu trong thế giới \r\nthực có chứa thông tin chi tiết cần nắm bắt, trong trường hợp này là bởi các camera \r\nvà microphone bên đường. Bằng cách so sánh dữ liệu từ cảm biến với những dữ liệu \r\nmà nó đã \"học được\", nó có thể phân loại, với một độ chính xác nhất định, từng loại \r\nxe đã đi qua con đường đó. \r\n\r\nTrên đây là một ví dụ cụ thể, ngoài ra học sâu còn có thể ứng dụng ở trong rất \r\nnhiều các lĩnh vực khác như:  \r\n\r\n Cung cấp khả năng điều hướng cho xe tự lái: Với hệ thống cảm biến và phần \r\nmềm phân tích trên buồng lái, các xe tự lái có thể học cách nhận dạng những \r\nchướng ngại vật có trên đường và có giải pháp xử lý thích hợp bằng cách sử \r\ndụng học sâu. \r\n\r\n Phục chế màu cho ảnh đen trắng: thông qua việc dạy cho máy tính cách nhận \r\nbiết các vật thể và cách mà mắt người nhìn chúng, các hình ảnh và video đen \r\ntrắng sẽ có thể được tái hiện lại với đầy đủ các màu sắc phù hợp. \r\n\r\n Dự đoán kết quả của các thủ tục pháp lý: Một nhóm các nhà nghiên cứu \r\nngười Anh và Mỹ đã có thể dự đoán chính xác kết quả của một phiên tòa, sau \r\nkhi hệ thống máy tính của họ được nạp sẵn những thông tin cơ bản của vụ \r\nán. \r\n\r\n Thuốc đặc trị: Các kỹ thuật học sâu hiện đang được dùng để phát triển các \r\nloại thuốc đã được chỉnh sửa sao cho phù hợp với bộ gen của bệnh nhân. \r\n\r\n\r\n\r\n\r\n Phân tích và báo cáo tự động: Các hệ thống có thể phân tích dữ liệu và báo \r\ncáo những thông tin chi tiết của chúng dưới dạng âm thanh tự nhiên hoặc \r\nngôn ngữ của con người. \r\n\r\n Chơi trò chơi: Các hệ thống học sâu đã và đang được dạy cách chơi (và \r\ngiành chiến thắng) các trò chơi như cờ vây, Breakout của Atari hay Starcraft. \r\n\r\n \r\n3.2  Cơ sở lý thuyết \r\n \r\n3.2.1 Mạng neural nhân tạo (Artificial neural network) \r\n\r\n Mạng Nơron nhân tạo (Artificial Neural Network- ANN) là mô hình xử lý \r\nthông tin được mô phỏng dựa trên hoạt động của hệ thống thần kinh của sinh vật, \r\nbao gồm số lượng lớn các Nơron được gắn kết để xử lý thông tin. ANN giống như \r\nbộ não con người, được học bởi kinh nghiệm (thông qua huấn luyện), có khả năng \r\nlưu giữ những kinh nghiệm hiểu biết (tri thức) và sử dụng những tri thức đó trong \r\nviệc dự đoán các dữ liệu chưa biết (unseen data). \r\n Kiến trúc chung của một mạng nơron nhân tạo (ANN) gồm 3 thành phần đó \r\nlà: Input Layer, Hidden Layer và Output Layer (Xem Trong đó, lớp ẩn (Hidden Layer) gồm các Nơron nhận dữ liệu input từ các Nơron ở \r\nlớp (Layer) trước đó và chuyển đổi các input này cho các lớp xử lý tiếp theo. Trong \r\nmột ANN có thể có nhiều lớp ẩn. \r\n \r\n\r\n \r\n\r\n \r\n\r\n\r\n\r\n\r\nTrong đó các Processing Elements (PE) của ANN gọi là Nơron, mỗi \r\nNơron nhận các dữ liệu vào (Inputs) xử lý chúng và cho ra một kết quả (Output) \r\nduy nhất. Kết quả xử lý của một Nơron có thể làm Input cho các Nơron khác. \r\n- Quá trình xử lý thông tin của một ANN: \r\n\r\n \r\n\r\n \r\n+ Inputs (dữ liệu vào): Mỗi Input tương ứng với 1 thuộc tính (attribute) của dữ liệu \r\n(patterns). Trong các mô hình mạng neural hiện tại x thường là một vecto được \r\nembedding từ dữ liệu đầu vào. \r\n+ Output (kết quả): Kết quả của một ANN là một giải pháp cho một vấn đề. \r\n+ Connection Weights (Trọng số liên kết): Đây là thành phần rất quan trọng của \r\nmột ANN, nó thể hiện mức độ quan trọng (độ mạnh) của dữ liệu đầu vào đối với \r\nquá trình xử lý thông tin (quá trình chuyển đổi dữ liệu từ Layer này sang layer \r\nkhác). Quá trình học (Learning Processing) của ANN thực ra là quá trình điều chỉnh \r\ncác trọng số (Weight) của các input data để có được kết quả mong muốn.  \r\n+ Summation Function (Hàm tổng): Tính tổng trọng số của tất cả các input được \r\nđưa vào mỗi Nơron (phần tử xử lý PE). Hàm tổng của một Nơron đối với n input \r\nđược tính theo công thức sau: \r\n\r\n! = \t $%&%\r\n'\r\n\r\n%()\r\n \r\n \r\n\r\n  \r\n+ Transfer Function (Hàm chuyển đổi): Hàm tổng (Summation Function) hay còn \r\ngọi là Activate Function của một Nơron cho biết khả năng kích hoạt (Activation) \r\ncủa Nơron đó còn gọi là kích hoạt bên trong (internal activation). Các Nơron này có \r\nthể sinh ra một output hoặc không trong ANN (nói cách khác rằng có thể output của \r\n1 Nơron có thể được chuyển đến layer tiếp trong mạng Nơron hoặc không). Mối \r\nquan hệ giữa Internal Activation và kết quả (output) được thể hiện bằng hàm \r\nchuyển đổi (Transfer Function).  \r\n\r\n\r\n\r\n\r\n \r\n+ Việc lựa chọn Transfer Function có tác động lớn đến kết quả của ANN. Một số \r\nhàm chuyển đổi phi tuyến hay được sử dụng trong ANN:  \r\n\r\n Linear g(a) = a \r\n\r\n Sigmoid g(a) = sigm(a) = \r\n!\r\n\r\n!\"\t$%&(-))   \r\n\r\n Tanh g(a) = tanh(a) = \r\n!\"# $ -\t'()\t(-$)\r\n!\"# $ ,\t!\"#(-$)    \r\n\r\n Rectified Linear g(a) = recline(a) = max (0, a)  \r\n Step \r\n Gaussian \r\n Softmax (hàm này rất hay được sử dụng ở layer cuối cùng) \r\n\r\n \r\nKết quả xử lý tại các Nơron (Output) đôi khi rất lớn, vì vậy transfer function \r\n\r\nđược sử dụng để xử lý output này trước khi chuyển đến layer tiếp theo. Đôi khi thay \r\nvì sử dụng Transfer Function người ta sử dụng giá trị ngưỡng (Threshold value) để \r\nkiểm soát các output của các Nơron tại một layer nào đó trước khi chuyển các \r\noutput này đến các Layer tiếp theo. Nếu output của một nơron nào đó nhỏ hơn giá \r\ntrị ngưỡng thì nó sẽ không được chuyển đến Layer tiếp theo. \r\n\r\nTrên kia là kiến trúc mạng ANN cơ bản. Để phục vụ những bài toán phức tạp ta \r\ncũng cần những kiến trúc mạng phức tạp hơn. Một số kiến trức mạng phổ biến hiện \r\nnay như:  \r\n\r\n Deep Neural Network (DNN) \r\n Deep Belief Network (DBN) \r\n Deep Boltzmann Machine (DBM) \r\n Recurrent Neural Network (RNN) \r\n Convolution Neural Network (CNN) \r\n Multi-modal/multi-tasking \r\n Deep Stacking Network (DSN)  \r\n\r\nTrong các kiến trúc trên em lựa chọn RNN cho bài toán tóm tắt văn bản, do các đặc \r\ntrưng đặc thù về chuỗi RNN phù hợp với các bài toán về xử lý ngôn ngữ tự nhiên sẽ \r\nđược nói rõ hơn ở phần 3.2.2 \r\n \r\n3.2.2 Giới thiệu mạng neural hồi quy RNN \r\n\r\nMô hình mạng neural hồi quy RNN là mô hình được áp dụng rất rộng rãi \r\ntrong các bài toán xử lý ngôn ngữ tự nhiên (NLP). Do mô hình RNN mô hình hoá \r\nđược bản chất dữ liệu trong NLP. Dữ liệu trong NLP có đặc tính chuỗi và có sự phụ \r\nthuộc lẫn nhau giữa các thành phần (trạng thái) trong dữ liệu. Năng lực tính toán \r\n\r\n\r\n\r\n\r\ncủa máy tính ngày càng mạnh nên đã thực hiện thực hoá được việc huấn luyện \r\nmạng neural hồi quy vốn yêu cầu nhiều bước tính toán hơn mạng neural thông \r\nthường. Việc áp dụng RNN có thể được coi là một bước đột phá trong NLP. \r\n\r\nÝ tưởng đằng sau RNN là sử dụng thông tin dạng chuỗi. Trong một mạng \r\nneural truyền thống chúng ta giả định rằng tất cả các đầu vào đều độc lập với nhau, \r\nnhưng mô hình này không phù hợp trong nhiều bài toán. Ví dụ nếu muốn đoán từ \r\ntiếp theo có thể xuất hiện trong một câu thì ta cũng cần biết các từ trước đố xuất \r\nhiện lần lượt thế nào? RNN được gọi là hồi quy bởi lẽ chúng thực hiện cùng một tác \r\nvụ cho tất cả các phần tửu của một chuỗi với đầu ra phụ thuộc vào cả các phép tính \r\ntrước đó. Nói các khác, RNN có khả năng nhớ các thông tin được tính toán trước \r\nđó. Trên lý thuyết RNN có thể sử dụng được thông tin của một văn bản rất dài, tuy \r\nnhiên thực tế thì nó chỉ có thể nhớ được một vài bước trước đó mà thôi. Về cơ bản \r\nmột mạng RNN sau khi phân tích ra sẽ có dạng như sau:  \r\n\r\n         \r\n\r\n \r\n Mô hình trên mô tả phép triển khai nội dung của một RNN. Triển khai ở đây \r\ncó thể hiểu đơn gỉản là ta vẽ ra một mạng nơ-ron chuỗi tuần tự. Ví dụ ta có một câu \r\ngồm 5 chữ Tôi yêu quê hương tôi, thì mạng nơ-ron được triển khai sẽ gồm 5 tầng \r\nnơ-ron tương ứng với mỗi chữ một tầng. Lúc đó việc tính toán bên trong RNN được \r\nthực hiện như sau: \r\n\r\n !\"   là đầu vào tại bước t. Ví dụ !\"   là một vec-tơ one-hot tương ứng với \r\ntừ thứ 2 của câu (yêu). \r\n\r\n !\"   là trạng thái ẩn tại bước t. Nó chính là bộ nhớ của mạng. !\"   được \r\ntính toán dựa trên cả các trạng thái ẩn phía trước và đầu vào tại bước \r\nđó: !\" = \t%('(\"   + !\"#$%  ) . Hàm f  thường là một hàm phi tuyến như \r\ntang, sigmoid hay ReLu. Để làm phép toán cho phần tử ẩn đầu tiên ta \r\ncần khởi tạo them !\"#  , thường giá trị khởi tạo được gắn bằng 0. \r\n\r\n\r\n\r\n\r\n !\"   là đầu ra tại bước t, Ví dụ, ta muốn dự đoán từ tiếp theo có thể xuất \r\nhiện trong câu thì !\"   chính là một vec-tơ xác xuất các từ trong danh \r\nsách từ vựng của ta: !\" = \t%!&'()*(,%\")    \r\n\r\n Vector đầu ra !\"   sẽ được sử dụng cho những dự đoán tiếp theo như dự \r\nđoán sentiment của một câu hay dự đáon từ loại của từng từ vựng \r\ntrong câu (PoS Tagging) \r\n\r\nViệc huấn luyện mạng neural hồi quy được thực hiện qua 2 bước:  \r\n Duỗi thẳng mạng neural hồi quy \r\n Sử dụng thuật toán backpropagation để tính đạo hàm một phần \r\n\r\n(gradient) của hàm mất mát ( giống như mạng neural thông thường ).  \r\n \r\n\r\nMột điểm nổi bật của RNN chính là ý tưởng kết nối các thông tin phía trước \r\nđể dự đoán cho hiện tại. Việc này tương tự như ta sử dụng các cảnh trước của bộ \r\nphim để hiểu được cảnh hiện thời. Đôi lúc ta chỉ cần xem lại thông tin vừa có thôi là \r\nđủ để biết được tình huống hiện tại. Ví dụ, ta có câu: Các đám mây trên bầu trời \r\nthì ta chỉ cần đọc tới các đám mây trên bầu là đủ biết được chữ tiếp theo là trời \r\nrồi. Trong tình huống này, khoảng cách tới thông tin có được cần để dự đoán là nhỏ, \r\nnên RNN hoàn toàn có thể học được. Nhưng trong nhiều tình huống ta buộc phải sử \r\ndụng nhiều ngữ cảnh hơn để suy luận. Ví dụ dự đoán chữ cuối cùng trong đoạn : I \r\ngrew up in France. I speak fluent French.. Rõ ràng là các thông tin gần (I speak \r\nfluent) chỉ có phép ta biết được đằng sau nó sẽ là tên của một ngôn ngữ nào đó, \r\ncòn không thể nào biết được đó là tiếng gì. Muốn biết là tiếng gì, thì ta cần phải có \r\nthêm ngữ cảnh I grew up in France nữa mới có thể suy luận được. Rõ ràng là \r\nkhoảng cách thông tin lúc này có thể đã khá xa rồi. \r\n\r\n \r\n    \r\nVề mặt lý thuyết, rõ ràng là RNN có khả năng xử lý các phụ thuộc xa (long-\r\nterm dependencies). Chúng ta có thể xem xét và cài đặt các tham số sao cho khéo là \r\ncó thể giải quyết được vấn đề này. Tuy nhiên, đáng tiếc trong thực tế RNN có vẻ \r\nkhông thể học được các tham số đó. Vấn đề này đã được khám phá khá sâu bởi \r\n\r\n\r\n\r\n\r\nHochreiter (1991) và Bengio, et al.(1994) trong các bài báo của mình, họ đã tìm \r\nđược nhưng lý do căn bản để giải thích tại sao RNN không thể học được. \r\n \r\n3.2.3 Mạng LSTM \r\n\r\nMạng bộ nhớ dài-ngắn (Long Short Term Memory networks), thường được \r\ngọi là LSTM - là một dạng đặc biệt của RNN, nó có khả năng học được các phụ \r\nthuộc xa. LSTM được giới thiệu bởi Hochreiter và Schmidhuber (1997), và sau đó \r\nđã được cải tiến và phổ biến bởi rất nhiều người trong ngành. Chúng hoạt động cực \r\nkì hiệu quả trên nhiều bài toán khác nhau nên dần đã trở nên phổ biến như hiện nay. \r\nLSTM được thiết kế để tránh được vấn đề phụ thuộc xa (long-term dependency). \r\nViệc nhớ thông tin trong suốt thời gian dài là đặc tính mặc định của chúng, chứ ta \r\nkhông cần phải huấn luyện nó để có thể nhớ được. Tức là ngay nội tại của nó đã có \r\nthể ghi nhớ được mà không cần bất kì can thiệp nào. \r\nMọi mạng hồi quy đều có dạng là một chuỗi các mô-đun lặp đi lặp lại của mạng nơ-\r\nron. Với mạng RNN chuẩn, các mô-dun này có cấu trúc rất đơn giản, thường là một \r\ntầng tanh. \r\n \r\n\r\n \r\n \r\nLSTM cũng có kiến trúc dạng chuỗi như vậy, nhưng các mô-đun trong nó có \r\ncấu trúc khác với mạng RNN chuẩn. Thay vì chỉ có một tầng mạng nơ-ron, chúng \r\ncó tới 4 tầng tương tác với nhau một cách rất đặc biệt. \r\n \r\n\r\n\r\n\r\n\r\n \r\n\r\n \r\nBước đầu tiên của LSTM là quyết định xem thông tin nào cần bỏ đi từ trạng \r\n\r\nthái tế bào. Quyết định này được đưa ra bởi tầng sigmoid - gọi là tầng cổng quên \r\n(forget gate layer). Nó sẽ lấy đầu vào là \"#$   và !\"   rồi đưa ra kết quả là một số \r\ntrong khoảng [0,1] cho mỗi số trong trạng thái tế bào !\"#$  . Đẩu ra là 1 thể hiện \r\nrằng nó giữ toàn bộ thông tin lại, còn 0 chỉ rằng toàn bộ thông tin sẽ bị bỏ đi. \r\n\r\nQuay trở lại với ví dụ mô hình ngôn ngữ dự đoán từ tiếp theo dựa trên tất cả \r\ncác từ trước đó, với những bài toán như vậy, thì trạng thái tế bào có thể sẽ mang \r\nthông tin về giới tính của một nhân vật nào đó giúp ta sử dụng được đại từ nhân \r\nxưng chuẩn xác. Tuy nhiên, khi đề cập tới một người khác thì ta sẽ không muốn \r\nnhớ tới giới tính của nhân vật nữa, vì nó không còn tác dụng gì với chủ thế mới này. \r\n\r\n \r\n\r\n \r\n\r\n \r\nBước tiếp theo là quyết định xem thông tin mới nào ta sẽ lưu vào trạng thái \r\n\r\ntế bào. Việc này gồm 2 phần. Đầu tiên là sử dụng một tầng sigmoid được gọi là \r\ntầng cổng vào (input gate layer) để quyết định giá trị nào ta sẽ cập nhập. Tiếp \r\ntheo là một tầng tanh tạo ra một véc-tơ cho giá trị mới !\"   nhằm thêm vào cho trạng \r\nthái. Trong bước tiếp theo, ta sẽ kết hợp 2 giá trị đó lại để tạo ra một cập nhập cho \r\ntrạng thái. \r\n\r\n\r\n\r\n\r\nChẳng hạn với ví dụ mô hình ngôn ngữ của ta, ta sẽ muốn thêm giới tính của nhân \r\nvật mới này vào trạng thái tế bào và thay thế giới tính của nhân vật trước đó. \r\n \r\n\r\n \r\n\r\nGiờ là lúc cập nhập trạng thái tế bào cũ !\"#$  thành trạng thái mới !\"   . Ở các \r\nbước trước đó đã quyết định những việc cần làm, nên giờ ta chỉ cần thực hiện là \r\nxong. \r\nTa sẽ nhân trạng thái cũ với !\"\t  để bỏ đi những thông tin ta quyết định quên lúc \r\ntrước. Sau đó cộng thêm !\"*$\"\t.\t  Trạng thái mơi thu được này phụ thuộc vào việc ta \r\nquyết định cập nhập mỗi giá trị trạng thái ra sao. \r\n\r\nVới bài toàn mô hình ngôn ngữ, chính là việc ta bỏ đi thông tin về giới tính \r\ncủa nhân vật cũ, và thêm thông tin về giới tính của nhân vật mới như ta đã quyết \r\nđịnh ở các bước trước đó. \r\n\r\n \r\n\r\n \r\nCuối cùng, ta cần quyết định xem ta muốn đầu ra là gì. Giá trị đầu ra sẽ dựa \r\n\r\nvào trạng thái tế bào, nhưng sẽ được tiếp tục sàng lọc. Đầu tiên, ta chạy một tầng \r\nsigmoid để quyết định phần nào của trạng thái tế bào ta muốn xuất ra. Sau đó, ta \r\nđưa nó trạng thái tế bảo qua một hàm tanh để co giá trị nó về khoảng [1,1], và \r\nnhân nó với đầu ra của cổng sigmoid để được giá trị đầu ra ta mong muốn. \r\n\r\nVới ví dụ về mô hình ngôn ngữ, chỉ cần xem chủ thể mà ta có thể đưa ra \r\nthông tin về một trạng từ đi sau đó. Ví dụ, nếu đầu ra của chủ thể là số ít hoặc số \r\nnhiều thì ta có thể biết được dạng của trạng từ đi theo sau nó phải như thế nào. \r\n\r\n\r\n\r\n\r\n \r\n\r\n \r\n \r\n\r\n3.2.4 Mô hình sequence to sequence \r\n\r\nMạng RNN được sử dụng như một mô hình ngôn ngữ để dự đoán các phần \r\ntử trong tương lai của chuỗi được cho trước. Tuy nhiên chúng ta vẫn thiếu các thành \r\nphần cần thiết để xây dựng các mô hình dịch bởi vì chúng ta mới chỉ xử lý trên một \r\nchuỗi duy nhất trong khi bản dịch cần phải xử lý trên cả 2 dãy chuỗi nhập và chuỗi \r\ndịch. \r\n Mô hình sequence to sequence được xây dựng bằng việc thêm một bước mã \r\nhoá (encoder) và một bước giải mã (decoder). Ở bước encoder mô hình sẽ chuyển \r\nđổi chuỗi đầu vào thành một biểu diễn cố định. Trong bước decoder, một mô hình \r\nngôn ngữ sẽ học từ cả chuỗi đầu ra (ví dụ như câu văn đã được dịch) và chuỗi biểu \r\ndiễn cố định sinh ra từ bước mã hoá. Do mô hình decoder nhìn thấy cả chuỗi biểu \r\ndiễn cố định sinh ra từ chuỗi đầu lẫn chuỗi dịch, nên nó có thể sinh ra những dự \r\nđoán thông minh hơn về các từ tương lai dựa trên từ hiện tại. Ví dụ, trong mô hình \r\nngôn ngữ cơ bản, chúng ta gặp từ đi nhưng không thể chắc rằng từ đó đang nói về \r\nmột hành động của con người là đi lại hay đang ám chỉ một người đã ra đi (đã chết). \r\nTuy nhiên nếu chúng được cho qua một ngữ cảnh mã hoá, lớp giải mã có nhận ra \r\nrằng chuỗi đầu vào đang ám chỉ việc người đã mất chứ không phải ám chỉ hành \r\nđộng đi lại. Với ngữ cảnh, bộ decoder có thể chọn từ kế tiếp thích hợp và cung cấp \r\nbản dịch chính xác hơn.  \r\n Bây giờ chúng ta cần phải hiểu cách thức hoạt động cơ bản của mô hình \r\nsequence to sequence, chúng ta sẽ nhắc lại về cách xây dựng một mô hình mạng \r\nneural cơ bản. Ở bước mã hoá (encoder) chúng ta sẽ sử dụng một mạng RNN. Mạng \r\nRNN này sẽ xử lý chuỗi đầu vào, sau đó sẽ chuyền đầu ra cho lớp giải mã (decoder) \r\nnhư là một biến ngữ cảnh. Lớp giải mã cũng là một mạng RNN. Nó có nhiệm vụ \r\nxem chuỗi đầu vào đã được dịch và từ đứng trước đó sau đó cố gắng dự đoán từ tiếp \r\ntheo trong chuỗi giải mã. Sau khi huấn luyện chúng ta có thể tạo ra bản dịch bằng \r\ncách mã hoá chuỗi đầu vào chúng ta muốn dịch và sau đó chạy mạng sinh chuỗi. \r\nMô hình mạng sequence to sequence được miêu tả như hình dưới:  \r\n\r\n\r\n\r\n\r\n \r\n\r\n \r\n\r\n  \r\n3.2.5 Kĩ thuật attention \r\n\r\nHãy bắt đầu với khái niệm chú ý (attention) trong thế giới thực. Mỗi ngày, \r\ncon người tiếp nhận rất nhiều dữ kiện đầu vào. Thật ngạc nhiên bộ não của chúng ta \r\ncó thể làm giảm lượng lớn dữ kiện đó đó thành những thông tin hữu dụng từ đó \r\nchúng ta có đưa ra các quyết định. Những nghiên cứu gần đây chỉ ra rằng các quy \r\ntrình tương tự được áp dụng trong mô hình mạng neural cho phép chúng ta tập trung \r\nvào những thông tin quan trọng trong khi có thể lọc được những dữ liệu không cần \r\nthiết. Kĩ thuật này được gọi là attention, nó giúp chúng ta xây dựng các mạng \r\nneural có thể giải quyết hiệu quả các thách thức trước đây với bài toán xử lý chuỗi \r\nnhư là dịch máy hay tóm tắt văn bản điều mà mô hình sequence to sequence bình \r\nthường không thực hiện được. \r\n\r\nMô hình sequence to sequence cho chúng ta khả năng xử lý các chuỗi đầu \r\nvào và đầu ra. Nhưng việc nén toàn bộ chuỗi đầu vào vào một vecto cố định duy \r\nnhất là khá khó khăn. Hơn nữa trạng thái cuối cùng của bộ mã hoá chưa phần lớn \r\nthông tin từ những phần tử cuối cùng của chuỗi mã hoá. Do đó nó có phần thiện vị \r\nvề phía cuối của chuỗi mã hoá và có thể bỏ lỡ mất những thông tin quan trọng ở \r\nphần đầu của chuỗi. \r\n\r\nThay vì nén toàn bộ chuỗi đầu vào thành một vectơ ngữ cảnh cố định chúng \r\nta có thể sử dụng kĩ thuật attention. Kĩ thuật này sẽ lưu giữ toàn bộ các trạng thái từ \r\nphần mã hoá và đưa cho từng phần tử của bộ giải mã giá trị trọng số trung bình của \r\ncác trạng thái mã hoá.  Ban đầu tất cả các trạng cuối cùng của chuỗi mã hoá đầu vào \r\nđều được giữ lại. Trong suốt quá trình giải mã chúng ta sẽ lấy trạng thái của mạng \r\n\r\n\r\n\r\n\r\ngiải mã kết hợp với trạng thái của bộ mã hoá và chuyền vào mạng feedforward. \r\nMạng này sẽ trả về danh sách các trọng số cho từng trạng thái encoder. Chúng ta sẽ \r\nnhân encoder input với các trọng số sau đó tính trung bình có trọng số của các \r\nencoder states. Kết quả ngữ cảnh này sau đó sẽ được chuyền đến lớp giải mã. Mạng \r\ndecoder của chúng ta bây giờ có thể sử dụng các phần khác nhau của chuỗi giải mã \r\ntrong quá trình sinh chuỗi decoder thay vì chỉ sử dụng một vecto ngữ cảnh cố định. \r\nĐiều này cho phép mạng tập trung vào những phần quan trọng nhất của chuỗi đầu \r\nvào thay vì toàn bộ chuỗi đầu vào, do đó tạo ra các dự đoán thông minh hơn cho từ \r\ntiếp theo trong chuỗi giải mã. Hình dưới sẽ mô tả cụ thể kĩ thuật này:  \r\n\r\n \r\n\r\n \r\n3.2.6 WordEmbedding \r\n\r\nWordEmbedding là một trong những phương diện nghiên cứu thú vị nhất của \r\nphương pháp học sâu trong xử lý ngôn ngữ tự nhiên. Một WordEmbedding là một \r\nhàm ánh xạ từ thành các vec-tơ nhiều chiều (200 đến 500 chiều). Ví dụ như: \r\n\r\nW(cat) = (0.2, -0.4, 0.7,.) \r\nW(mat) = (0.0, 0.6, -0.1,.) \r\n\r\n Thường thì hàm này sẽ là một bảng tra cứu, lưu trữ dưới dạng một ma trận , \r\nvới W(wn) = n . Các vec-tơ trong Word Embedding có các tính chất sau: \r\n\r\n Số lượng chiều không lớn (so với tập từ vựng) \r\n Các từ có chung nét ngữ nghĩa sẽ được về gần nhau trong không gian \r\n Mối quan hệ tương đồng ngữ nghĩa được chuyển thành mối quan hệ \r\n\r\ngiống nhau giữa các vec-tơ. \r\n \r\n\r\n\r\n\r\n\r\n \r\nTrong bài toán này em lựa Word2Vec là phương pháp cho bài khối \r\n\r\nWordEmbedding.Word2Vec là một phương pháp cụ thể của bài toán \r\nWordEmbedding. Không sử dụng một tác vụ để kiểm tra một cụm \"5-gram\" có hợp \r\nlệ hay không. Word2vec lựa chọn việc huấn luyện ra một mạng nơ-ron cho phép dự \r\nđoán từ (hoặc các từ) từ các từ lân cận cho trước (có thể gồm nhiều hoặc một từ) và \r\nngược lại. \r\n Về khối kết cấu, Word2Vec là 1 mạng nơ-ron cạn gồm 1 lớp ẩn. Có 2 kiến \r\ntrúc là hội tụ và phân kì từ xung quanh để tạo ra mô hình Word2vec là CBOW và \r\nSkip-gram. Ngoài ra, thực tế còn có các phương pháp cải tiến nhằm tối ưu hóa hiệu \r\nquả tính toán \r\n Một cách tổng quát về Word2Vec: \r\n\r\n Biểu diễn phân tán cho từ \r\n Học ra một vec-tơ giá trị thực (real-valued vector) cho  từng từ \r\n Đưa những từ có ý nghĩa giống nhau về gần nhau \r\n Một ứng dụng đơn giản của của mạng nơ-ron 2 lớp \r\n\r\n \r\n3.3 Các vấn đề của mô hình sequence to sequence và kĩ thuật attention \r\n\r\n Mạng RNN cơ bản chỉ đi theo một chiều duy nhất là từ đầu chuối đến cuối \r\nchuỗi. Ví dụ để dự đoán từ còn thiếu trong câu thì việc không thể chỉ xem xét \r\nphần trước mà phải xem xét cả các phần tử đứng đằng sau.  \r\n\r\n Kích thước tập từ điển rất lớn, nhất là khi dữ liệu train ngày càng tăng lên \r\nđến vài triệu bản. Việc chọn kích thước tập từ điển ảnh hưởng rất nhiều đến \r\nhiệu năng của mạng hơn nữa. Chọn kích thước quá lớn thì làm tăng thời gian \r\nhuấn luyện mạng lên rất nhiều, quá nhỏ thì lại không đủ độ chính xác cho bài \r\ntoán. Việc chọn những từ nào xuất hiện trong từ điển cũng là một bài toán \r\nnan giải. Số lượng trọng số trong mạng gần như tăng tuyến tính theo kích \r\nthước của tập từ điển (và \r\n Trong quá trình huấn luyện những từ nằm ngoài từ điển sẽ bị dán nhãn \r\n<unk> và nếu chỉ dùng mạng RNN đơn thuần thì chuỗi đầu ra sau khi sinh sẽ \r\nbị mất mát thông tin. Đôi khi những từ xuất hiện ít trong tập dữ liệu nhưng \r\nlại mang nhiều thông tin quan trọng như tên riêng, thời gian,.  \r\n\r\n Khác biệt lớn nhất giữa quá trình huấn luyện và dự đoán là việc dự đoán kí \r\ntự !\"   . Trong quá trình huấn luyện !\"\t  sẽ được sinh ra từ việc kết hợp với kí tự \r\n\r\nđứng trước nó là !\"#$   còn trong quá trình suy luận là từ kí tự !\"#$   được suy \r\n\r\nra từ mô hình. Mạng RNN (hay các biến thể như LSTM) thường được huấn \r\n\r\n\r\n\r\n\r\nluyện để tối đa hoá khả năng tạo ra các chuỗi đích từ chuỗi đầu vào, vì thế \r\nmô hình có thể sinh ra những dự đoán tồi do gặp phải những không gian mà \r\nnó chưa bao giờ nhìn thấy. \r\n\r\n Một vấn đề nữa ở kĩ thuật attention cơ bản đó là việc tính toán ngữ cảnh \r\ncũng như tính toán trọng số đều dùng chung một lớp ẩn đầu vào. Việc này sẽ \r\nlàm cho các trọng số không thể hiện được hoàn toàn vai trò của từng kí tự \r\ntrong chuỗi đầu vào. \r\n\r\n \r\n\r\n\r\n\r\n\r\n \r\n\r\n \r\n \r\n3.4 Mô hình đề xuất \r\n Lấy cảm hứng từ mô hình rất thành công trong mô hình dịch máy, em đã kết \r\nhợp mô hình mạng ngôn ngữ với một mô hình mã hoá ngữ cảnh. Hơn nữa bản chất \r\nmô hình sequence to sequence được cấu thành từ mạng RNN, mô hình mạng này rất \r\nphù hợp cho các bài toán về xử lý chuỗi tuần tự, có khả năng lưu trữ thông tin của \r\ntoàn bộ chuỗi đầu vào. Bộ mã hoá được áp dụng thêm kĩ thuật attention, kĩ thuật \r\nnày sẽ giúp tìm kiếm những sự liên kết tiềm ẩn trong văn bản đầu vào, giúp hệ \r\nthống có thể tập trung vào những dữ kiện quan trọng như tên riêng, số, .. qua đó \r\ngiúp giảm lượng thông tin cần ghi nhớ. Và để giải quyết một số vấn đề của mô hình \r\nattention encoder decoder như đã đề cập ở phần trên trong phần này cũng đề xuất \r\nmột số giải pháp để cải tiến chất lượng mô hình. \r\n\r\n\r\n\r\n\r\n \r\n\r\n \r\n\r\n3.4.1 Khối tiền xử lí dữ liệu \r\nDo muốn máy có thể học cách sử dụng ngôn ngữ như con người nên phần \r\n\r\nlowercase và loại bỏ các dấu câu như : ! ? , được bỏ qua. Chỉ sử dụng tách từ và \r\ntách câu sử dụng 2 công cụ giống như đã nêu ở phần 0  \r\n Từ điển được sử dụng trong mô hình có kích thước 40000 từ. Lớp mã hoá từ \r\ntoken từ sang vecto embedding có số chiều là 400. Để phục vụ cho các tác vụ phía \r\nsau từ điển cũng như các từ ngoài từ điển được sắp xếp theo thứ tự về số lần xuất \r\nhiện của chúng trong văn bản. Sau khi xử lý xong thì ta thu được tập từ có số lượng \r\nrất lớn lên đến 350 nghìn từ. 40000 từ có số lần xuất hiện nhiều nhất sẽ được chọn \r\nvào trong tập từ điển và được thay đổi theo từng batch-size. Ta cũng quy ước 2 kí tự \r\nđặc biệt empty và eos (kí tự báo hiệu kết thúc câu) là 2 kí tự đầu tiên trong từ điển. \r\n\r\n\r\n\r\n\r\n    \r\n\r\n \r\n  Vấn đề tiếp theo cần phải giải quyết đó là xử lý những từ nằm trong tập từ \r\nđiển của embedding nhưng lại không có trong tập từ điển của dữ liệu chúng ta. Đối \r\nvới những từ này ta sẽ tính giá trị trung bình của toàn bộ trọng số ebedding hiện tại \r\ngọi là scale, sau đó sinh vecto 400 chiều ngẫu nhiên tương ứng trong khoảng từ -\r\nscale đến scale. \r\n Ở bước tiền xử lý này chúng ta cũng lưu trữ tập các từ nằm ngoài từ điển \r\nnhưng có độ tương đồng cao với các từ có trong tập từ điển. Trong mô hình này em \r\nđề xuất ngưỡng tương đồng là 0.5 \r\n\r\n \r\n\r\n \r\n\r\n\r\n\r\n\r\n \r\n\r\n \r\n\r\n  \r\n\r\n3.4.2 Khối huấn luyện mô hình encoder-decoder \r\n \r\n Chúng ta sử dụng kiến trúc encoder-decoder như đã miêu tả ở phần 3.2.4. \r\nKiến trúc này gồm 2 phần bộ mã hoá (encoder) và bộ giải mã (decoder) . Cả 2 phần \r\nđều là các mạng RNN. \r\n \r\n\r\n  \r\n \r\n\r\n  \r\n Bộ mã hoá sẽ truyền vào từng từ một trong văn bản đầu vào. Mỗi từ sau đó \r\nsẽ được đi qua một lớp embedding để biểu diễn từ đó về dạng vecto số, trong bài \r\ntoán này em sử dụng embedding là w2v 400 chiều trên tập dữ liệu Báo Mới). Vecto \r\nnày sau đó sẽ được đi qua các lớp ẩn, ở mỗi lớp nó lại được kết hợp với những lớp \r\nẩn được sinh ra từ token phía trước, đối với từ đầu tiên thì tất cả các giá trị này đều \r\nbằng 0.  \r\n\r\n\r\n\r\n\r\n Bộ giải mã sẽ nhận layer ẩn cuối cùng của bộ mã hoá kết hợp với token \r\n<eos> (kí tự kết thúc câu) là đầu vào. Sau đó bộ giải mã sẽ sinh từng từ một sử dụng \r\nlớp softmax và kĩ thuật attention. Bộ giải mã sẽ dừng lại khi sinh đến kí tự <eos>.  \r\n Hàm mất mát em sử dụng trong bài toán là hàm log loss: \r\n \r\n\r\n-\"#$\t& '(, . . . , ',' .(, .. . . , ., = \t -\t \"#$\t& '0 '(, .. . . , '0-(, .(, . . .,\r\n,'\r\n\r\n01(\r\n \r\n \r\n\r\n \r\nTrong đó: \r\n\r\n x là chuỗi đầu vào  \r\n y là chuỗi đầu ra \r\nỞ đây xảy ra vấn đề mất kết nối giữa quá trình huấn luyện và kiểm thử khi \r\n\r\nmà trong quá trình giải mã ở huấn luyện từ tiếp theo được sinh ra sau khi truyền \r\nvào từ đứng trước nó trong headline gốc còn ở quá trình kiểm thử là từ được \r\nsinh ra từ mô hình. Để giải quyết vấn đề này em sử dụng kĩ thuật flip. Ta sẽ úp \r\nngẫu nhiên một số từ ở phần headline và thay nó bằng từ được dự đoán từ mô \r\nhình hiện tại. Tuy nhiên ở giai đoạn đầu huấn luyện mô hình chưa được tốt nên \r\nviệc này có thể làm chậm lại quá trình huấn luyện, nên kĩ thuật này sẽ được sử \r\ndụng sau khi mô hình đã tương đối tốt. Trong suốt quá trình kiểm thử chúng ta \r\nsử dụng giải thuật beam-search khi sinh từ một, ở mỗi bước sẽ sinh ra 10 chuỗi \r\ncó xác suất cao nhất. \r\n\r\n \r\nTrong quá trình xử lý dữ liệu đầu vào, có những từ ít xuất hiện nằm ngoài \r\n\r\nvocab sẽ bị dán nhãn <unk>, điều này làm có thể dẫn đến làm mất mát nhiều \r\nthông tin quan trọng. Trong mô hình này em xử lý vấn đề này bằng 2 cách. Nếu \r\ngặp phải một từ nằm ngoài tập từ điển đầu tiên sẽ kiểm tra xem nó có nằm trong \r\ntập các từ có độ tương đồng cao (đã được nêu trong phần 3.4.1) với các từ có \r\ntrong từ điển hay không, nếu có ta sẽ chọn từ có độ tương đồng cao nhất. Nếu \r\nkhông nằm trong tập này sẽ kiểm tra phân loại và gán nhãn cho từ này vào các \r\nthẻ <time> nếu token đó là định dạng thời gian, <url> nếu token là các đường \r\ndẫn, các trường hợp còn lại (hầu hết là tên riêng) được gán vào nhãn <oov>. Sau \r\nquá trình giải mã nếu trong mã giải có những token kia ta sẽ truy ngược lại văn \r\nbản đầu vào để khôi phục chúng theo nhãn được gán từ quá trình tiền xử lý. \r\n\r\n \r\nChúng ta sử dụng mạng 4 lớp LSTM ẩn. Mỗi lớp ẩn có kích thước là 512 \r\n\r\nunits. Các trọng số trong mô hình được khởi tạo giá trị trong khoảng [-0.1;0.1]. \r\nLearning rate là 0.01 và hàm optimize là giải thuật Adam  \r\n\r\n\r\n\r\n\r\n3.4.3 Kĩ thuật attention \r\nKĩ thuật attention giúp cho mạng neural có thể ghi nhớ chính xác những nội \r\n\r\ndung quan trọng một cách chính xác hơn. Khi sinh mỗi từ output kĩ thuât này sẽ tính \r\ntrọng số cho mỗi từ trong input phụ thuộc vào sự chú ý của từ đó đến từng từ trong \r\nchuỗi đầu vào. Cơ chế cụ thể đã được miêu tả trong phần 3.4.3. Trọng số attention \r\ncho input word ở bước thứ t được tính như sau:  \r\n   \r\n\r\n !\"#' % = \t\r\n()*(,-#. ,/#' )\r\n()*(,-#\r\n\r\n. ,/#' )\r\n.\r\n#\r\n\r\n   \r\n\r\nTrong đó \"#    đại diện cho layer cuối cùng được sinh ra sau khi truyền vào t từ , \"#'    \r\nđại diện cho layer cuối cùng của bước hiện tại của modul giải mã \r\n\r\nLưu ý rằng ở cách thông thường việc tính toán trọng số attention và tính \r\nvecto ngữ cảnh đều dùng chung các lớp ẩn (hidden units). Vì vậy em đề suất biến \r\nđổi kĩ thuật này một chút được gọi là simple attention. Với kĩ thuật này ta sẽ tách \r\nlayer cuối cùng ở mỗi input thành 2 phần. Phần đầu có kích thước 40 được sử dụng \r\nđể tính toán trọng số attention, phần còn lại được sử dụng để tính vecto ngữ cảnh. \r\nTương tự cho layer cuối cùng ở modul decoder. Ngoài những thay đổi công thức \r\ntính toán trọng số vẫn được giữ nguyên. \r\n\r\n  \r\n\r\n\r\n\r\n\r\n  \r\n \r\n\r\n  \r\n3.5 Thực nghiệm \r\n3.5.1 Môi trường thực nghiệm \r\n\r\n Chương trình được xây dựng và thử nghiệm trên máy tính cá nhân có cấu \r\nhình và các phần mềm cần thiết như sau:  \r\n\r\n- Vi xử lý: 2.2 GHz Quad-Core Intel Core i7 Crystalwell \r\n- Ram: 16Gb  \r\n- Hệ điều hành: MacOs Sierra \r\n- Phần mềm phát triển: PyCharm \r\n- Ngôn ngữ sử dụng: Python \r\n-    Card đồ hoạ: GeForce GTX 1060 6Gb Ram \r\n-    Bộ thư viện dùng cho quá trình huấn luyện model: Keras chạy trên nền \r\nthư viện TensorFlow \r\n-    Bộ công cụ tách từ tiếng Việt: pyvi của tác giả Trần Việt Trung \r\n\r\n \r\n3.5.2 Thư viện TensorFlow \r\n\r\n Tensorflow là một thư viện mã nguồn mở cung cấp khả năng xử lý tính toán \r\nsố học dựa trên biểu đồ mô tả sự thay đổi của dữ liệu. Tensor được sử dụng khi ta \r\ncần giải quyết các bài toán supervised learning. Tensorflow được Google phát triển \r\n\r\n\r\n\r\n\r\nvà phát hành tháng 10 năm 2015. Các mô hình deeplearning phát triển trên \r\nTensorFlow có thể được sử dụng trên nhiều các loại platform khác nhau (từ \r\nsmartphone tới distributed servers) và trên CPUs lẫn GPUs. \r\n \r\n\r\n                    \r\n\r\n \r\n Trong TensorFlow mọi kiểu dữ liệu đều được quy về một mối được gọi là \r\nTensor. Vậy nên có thể hiểu được phần nào tên gọi của thư viện TensorFlow là một \r\nthư viện mô tả, điều chỉnh dòng chảy của các Tensor. Tensor là một kiểu dữ liệu \r\ndạng mảng có nhiều chiều. Ví dụ Tensor = [[[1,1,1] ,[178,62,74]] ,[[45,2,2] \r\n,[19,0,17]] ,[[7,5,2],[0,11,4]],[[8,13,5],[1,6,7]]] . Mảng nhiều chiều này được đính \r\nkèm them một vài thuộc tính tham chiếu khác. Các thuộc tính của Tensor được mô \r\ntả trong tài liệu gồm:  \r\n\r\n device: Tên của thiết bị mà Tensor hiện tại sẽ được xuất bản. Có thể None. \r\n graph: Đồ thị chứa Tensor hiện tại. \r\n name: Tên của Tensor hiện tại. \r\n shape: Trả về TensorShape mô tả lại Shape của Tensor hiện tại. \r\n op: Operation được sử dụng để xuất bản Tensor hiện tại. \r\n dtype: Kiểu của các phần tử trong Tensor hiện tại. \r\n\r\n \r\n\r\n\r\n\r\n\r\n3.5.3 Thư viện Keras \r\n\r\n Keras là một API cấp cao được viết trên Python và có khả năng trên nền của \r\ncác thư viện khác như TensorFlow,CNTK hay Theano. Thư viện này giúp những ai \r\nmới nghiên cứu về mạng neural tiếp cận một cách dễ hơn và trực quan hơn. Keras \r\ncho phép chúng ta dễ dàng khởi tạo, cấu hình hay mở rộng các model, nó cũng hỗ \r\ntrợ rất tốt cho cả 2 mô hình CNN ( convolutional network ) và RNN (recurrent \r\nnetworks). \r\n \r\n3.5.4 Dữ liệu thực nghiệm \r\n\r\nMô hình sử dụng bộ dữ liệu gồm một triệu văn bản từ Báo Mới. Bộ \r\nword2vec đã được huận luyện cũng từ tập dữ liệu Báo Mới. Mỗi văn bản được tách \r\nthành 3 phần: Headline, Description và Content. Vì mô hình chưa có khả năng lưu \r\ntrữ một lượng thông tin đầu vào lớn nên sẽ chỉ tập trung vào việc sinh tiêu \r\nđề(headline) từ phần miêu tả(description). Do đó phần Headline và Description sẽ \r\nđược tách ra để phục vụ cho mục đích của bài toán. \r\n\r\nBộ dữ liệu Báo Mới có dung lượng 3.64GB được chia thành 1000 bản ghi, \r\nmỗi bản ghi gồm hơn 1000 văn bản được chia cắt bởi kí tự #. Bản thân bộ dữ liệu \r\ncũng đã được tiền xử lý qua trước, 2 câu đầu tiên của mỗi văn bản là tiêu \r\nđề(heading) và phần miêu tả (description), từ câu thứ 3 trờ đi là phần nội dung của \r\nvăn bản. \r\n\r\nPhần heading và description sẽ được giữ lại để làm dữ liệu huấn luyện và \r\ntest. Bước đầu tiên của quá trình tiền xử lý là phải tách riêng từng văn bản từ tập \r\n1000 bản ghi, sau đó loại bỏ những văn bản trùng lặp. Bộ dữ liệu ban đầu có tất cả \r\n1175154 văn bản, sau khi loại bỏ các văn bản trùng lặp dữ liệu còn lại 980204 văn \r\nbản. Sau đó lấy ngẫu nhiên 3000 văn bản ra để làm tập dữ liệu test validation Sau \r\nquá trình tiền xử lý như đã đề cập ở mục 3.3.2 dữ liệu sẽ được đóng gọi dưới đinh \r\ndạng .pkl.  \r\n\r\n \r\n3.5.5 Phương pháp đánh giá \r\n\r\nĐối với bài toán này em vẫn lựa chọn Rouge làm phương pháp đo độ chính \r\nxác. Phương pháp này đã được nêu chi tiết ở phần 2.5.2.2 \r\n \r\n3.5.6 Kết quả thực nghiệm  \r\n\r\n Đồ án sẽ tập trung vào việc so sánh 2 model: model attention encoder-\r\ndecoder gốc được tạo bởi Rush và đồng nghiệp với model đó sau khi đã được cải \r\ntiến bằng một số kĩ thuật đã được nêu ra ở mục 3.3.3 \r\n\r\n\r\n\r\n\r\nRouge  \r\nFeature\t\r\n\r\nRouge-1 \r\n(%) \r\n\r\nRouge-2 \r\n(%) \r\n\r\nModel gốc 28.32           6.66 \r\n\r\nModel cải tiến 33.60          12.21 \r\n\r\n \r\n Từ kết quả bảng trên ta có thể thấy việc áp dụng một số cải tiến vào mô hình \r\nhuấn luyện đã đem lại hiệu quả. Sau khi cải tiến model tăng 5.28% với Rouge1 và \r\n5.55% với Rouge2. Tuy nhiên điểm độ đo Rouge vẫn chưa thực cao, nguyên nhân \r\nlà do phép đo Rouge so khớp kí tự của bản do người tóm tắt với máy tóm tắt, mà \r\nđặc trưng của phương pháp tóm tăt abtract là không phải trích rút từ những câu \r\nnhững từ có sẵn trong văn bản đầu vào. \r\n Dưới đây là một số kết quả của model cuối cùng sau thời gian huấn luyện 1 \r\ntuần \r\n  \r\n\r\nVăn bản đầu vào Tiêu đề gốc Tiêu đề do máy dự \r\nđoán \r\n\r\nNgày 20/5 , Phái_đoàn thường_trực \r\nViệt_Nam bên cạnh Liên_hiệp quốc , \r\nTổ_chức Thương_mại Thế_giới ( \r\nWTO ) và các tổ_chức quốc_tế khác \r\ntại Geneva , Thụy_Sĩ , đã ra \r\nthông_cáo về những diễn_biến gần \r\nđây ở biển Đông và gửi đến \r\nVăn_phòng Liên_hiệp_quốc tại \r\nGeneva , các tổ_chức quốc_tế cùng \r\ncác cơ_quan báo_chí có trụ_sở tại \r\nGeneva . \r\n \r\n\r\nViệt_Nam gửi \r\nthông_cáo về biển \r\nĐông lên LHQ \r\n \r\n\r\nViệt_Nam gửi \r\nthông_cáo về \r\ntình_hình \r\nBiển_Đông \r\n \r\n\r\nNghị_quyết về mức giá các loại đất \r\nnăm 2011 vừa được HĐND TP \r\nthông_qua , áp_dụng từ ngày \r\n1.1.2011^ . Theo đó , giá đất nhiều \r\nkhu_vực trung_tâm thành_phố ( quận \r\nNinh_Kiều^ ) tăng gần gấp đôi so với \r\nnăm 2010 . \r\n \r\n\r\nGiá đất nhiều \r\nkhu_vực nội ô tăng \r\ngần gấp đôi \r\n \r\n\r\nGiá đất tại \r\nCần_Thơ tăng \r\n \r\n\r\n\r\n\r\n\r\nTrong lúc đang đánh_bắt hải_sản ở \r\nvùng đảo Hoàng_Sa , tàu \r\nTrung_Quốc bất_ngờ xuất_hiện và \r\ntấn_công tàu cá của ngư_dân \r\nQuảng_Ngãi . \r\n \r\n\r\nTàu cá \r\nQuảng_Ngãi \r\ntiếp_tục bị tàu \r\nTrung_Quốc \r\ntấn_công \r\n \r\n\r\nTàu cá ngư_dân \r\nTrung_Quốc \r\ntấn_công trên biển \r\n \r\n\r\nMột máy_bay của Hãng hàng không \r\nMalaysia mất_tích khi bay vào \r\nkhông_phận Việt_Nam  \r\n \r\n\r\nMáy_bay chở 227 \r\nhành_khách đã rơi \r\ncách đảo Thổ_Chu \r\n300 km \r\n \r\n\r\nMáy_bay Malaysia \r\nmất_tích : \r\nMáy_bay đã gặp \r\nnạn \r\n \r\n \r\n\r\nBáo Telegraph ( Anh ) rút ra năm \r\nbài_học từ trận Bayern_Munich ( B.M \r\n) hạ Manchester United ( M.U ) 3-1 ở \r\ntứ_kết lượt về Champions_League . \r\n \r\n\r\n5 bài_học từ trận \r\nM.U thua Bayern \r\n \r\n\r\nDavid_Moyes vẫn \r\nkhông được \r\nthất_bại \r\n \r\n\r\nNguyên_nhân của clip phụ_huynh \r\nhọc_sinh đánh nhau tại Hà_Nội khiến \r\nnhiều người bất_ngờ . Đó là từ câu \r\nnói \" xấu lại còn thích thể_hiện \" . \r\n \r\n\r\nNữ_sinh và \r\nphụ_huynh xô_xát \r\n: Từ lời chê xấu gái \r\ntrên mạng \r\n \r\n \r\n\r\nHọc_sinh \r\nphụ_huynh đánh \r\nnhau \r\n \r\n\r\nHai bảo_mẫu hành_hạ trẻ_em sẽ được \r\nxét_xử lưu_động ngày 20/1 tại \r\nHội_trường Nhà thiếu_nhi quận \r\nThủ_Đức . \r\n \r\n\r\nXét_xử lưu_động 2 \r\nbảo_mẫu hành_hạ \r\ntrẻ_em \r\n \r\n\r\nVụ bảo_mẫu \r\nhành_hạ trẻ trẻ \r\n \r\n\r\n\r\n\r\n\r\nThị_trường chứng_khoán Việt_Nam \r\nđã có một tuần giao_dịch khá \r\ntích_cực , chỉ_số VN-Index tăng 4,75 \r\n% , HNX-Index tăng 2,87^ % . \r\nĐồng_hành với nhà đầu_tư trong \r\nnước , tuần qua , thị_trường đã \r\nchứng_kiến những phiên giao_dịch \r\nghi đậm dấu_ấn của khối ngoại . \r\n  \r\n\r\nTuần từ 13 - 17/1 : \r\nKhối ngoại mua \r\nròng 738,27^ tỷ \r\nđồng trên HOSE \r\n \r\n\r\nVN-Index tiếp_tục \r\nhồi_phục \r\n \r\n\r\nNgày 31/3 , Cục Đăng_kiểm \r\nViệt_Nam cho biết , đã sửa_đổi \r\nThông_tư 56/2012^ nhằm","u":"http://202.191.57.85:8000/InternetData/Data/DATN/20131848_Duong_Viet_Hung_1514557567432.txt","downloaded":false,"m":[-1,-1],"n":"20131848_Duong_Viet_Hung_1514557567432.txt","o":"http://storage.googleapis.com/soict20171/cnpm/dhcq/20131848_Duong_Viet_Hung_1514557567432.pdf\r"}],"t":"\nTRƯỜNG ĐẠI HỌC BÁCH KHOA HÀ NỘI \n\nVIỆN CÔNG NGHỆ THÔNG TIN VÀ TRUYỀN THÔNG \n\n──────── * ──────── \n\n \n\n \n\nĐỒ ÁN \n\nTỐT NGHIỆP ĐẠI HỌC \nNGÀNH CÔNG NGHỆ THÔNG TIN \n\n \n\n \n\nTÓM TẮT VĂN BẢN HƯỚNG TRUY VẤN \n\n \n\n \n\n\nLớp       : HTTT-K53 \n\nGiáo viên hướng dẫn :  PGS.TS Lê Thanh Hương \n\n \n\n \n\n \n\n \n\n \n\n \n\nHÀ NỘI, 5-2013  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 2 \n\n   \n\nPHIẾU GIAO NHIỆM VỤ ĐỒ ÁN TỐT NGHIỆP \n\n1. Thông tin về sinh viên \n\nHọ và tên sinh viên: Hoàng Đức Thọ \n\nĐiện thoại liên lạc: 0988238277  Email: hoangtho2010@gmail.com \n\nLớp: Hệ thống thông tin K53   Hệ đào tạo: Kỹ sư \n\nĐồ án tốt nghiệp được thực hiện tại: Trường ĐHBK Hà Nội \n\nThời gian làm ĐATN: Từ ngày  01/01/2013  đến 01/05/2013 \n\n2. Mục đích nội dung của ĐATN \n\nĐề xuất và thử nghiệm phương pháp tóm tắt văn bản hướng truy vấn cho tiếng Việt, \n\náp dụng cho đơn văn bản. \n\n3. Các nhiệm vụ cụ thể của ĐATN \n\n- Tìm hiểu về tóm tắt văn bản tự động \n\n- Đề xuất và phân tích các bước thực hiện một mô hình tóm tắt văn bản hướng truy \n\nvấn cho tiếng Việt \n\n- Cài đặt chương trình thử nghiệm và đánh giá kết quả \n\n4. Lời cam đoan của sinh viên: \n\nTôi – Hoàng Đức Thọ - cam kết ĐATN là công trình nghiên cứu của bản thân tôi \n\ndưới sự hướng dẫn của PGS.TS Lê Thanh Hương. Các kết quả nêu trong ĐATN là trung \n\nthực, không phải là sao chép toàn văn của bất kỳ công trình nào khác. \n\nHà Nội, ngày 19 tháng 5 năm 2013 \n\n    Tác giả ĐATN   \n\n \n\nHoàng Đức Thọ   \n\n5. Xác nhận của giáo viên hướng dẫn về mức độ hoàn thành của ĐATN và cho phép \n\nbảo vệ: \n\n \n\n \n\n \n\nHà Nội, ngày     tháng     năm   \n\nGiáo viên hướng dẫn   \n\n \n\n  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 3 \n\n   \n\n \n\nLỜI CẢM ƠN \n\nTrong thời gian học tập tại trường Đại học Bách khoa Hà Nội, em đã học hỏi được \n\nrất nhiều kiến thức bổ ích từ các thầy cô giáo, đặc biệt là các thầy cô trong viện Công \n\nnghệ thông tin và Truyền thông. Thầy cô đã trang bị cho em rất nhiều kiến thức quý \n\nbáu, đó cũng như là hành trang và nền tảng để em vững bước hơn khi vào môi trường \n\nlàm việc đầy thử thách ngoài xã hội. \n\nEm xin gửi lời cảm ơn chân thành tới các thầy cô trong viện, đặc biệt là cô Lê \n\nThanh Hương, người đã tận tình hướng dẫn em trong thời gian thực hiện đồ án này.  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 4 \n\n   \n\nTÓM TẮT NỘI DUNG ĐỒ ÁN TỐT NGHIỆP \n\nNgày nay, việc truy cập thông tin qua mạng internet đã trở nên rất phổ biến. Tuy nhiên \n\nvới lượng thông tin khổng lồ và tăng lên nhanh chóng mỗi ngày, con người không đủ thời \n\ngian và sức lực đọc hết các tài liệu để tìm thông tin cần thiết cho mình. Tóm tắt văn bản \n\nhướng truy vấn là giải pháp cho vấn đề đó, đây là một dạng đặc biệt của bài toán tóm tắt văn \n\nbản tự động mà văn bản sẽ được tóm tắt theo mong muốn của người sử dụng. \n\nTrong đồ án này em đề xuất và thử nghiệm một phương pháp tóm tắt văn bản hướng \n\ntruy vấn dành cho các văn bản tiếng Việt dựa trên tần số từ và độ tương đồng câu. Nội dung \n\ncủa đồ án gồm 3 phần chính sau: \n\n- Phần 1. Đặt vấn đề và định hướng giải quyết: Mô tả bài toán, tìm hiểu tóm tắt \n\nvăn bản, tóm tắt hướng truy vấn, đề xuất hướng giải quyết cho tiếng Việt. \n\n- Phần 2: Giải quyết vấn đề: Phân tích chi tiết các bước thực hiện mô hình, xây \n\ndựng các công cụ và kiểm thử trên tập mẫu. \n\n- Phần 3: Kết luận và đề xuất: Đánh giá các phần đã làm được, các tồn tại, đề xuất \n\nhướng phát triển. \n\nKết quả kiểm thử cho thấy mô hình này cho kết quả tương đối chính xác, tốc độ xử lý \n\nnhanh, có thể cài đặt sử dụng trong thực tế. \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 5 \n\n   \n\nMục lục \n\nDANH MỤC CÁC BẢNG .......................................................................................... 8 \n\nDANH MỤC CÁC HÌNH VẼ..................................................................................... 9 \n\nDANH MỤC TỪ VIẾT TẮT .................................................................................... 10 \n\nMỞ ĐẦU ................................................................................................................... 11 \n\n1. Lý do chọn đề tài ........................................................................................... 11 \n\n2. Phạm vi nghiên cứu ....................................................................................... 11 \n\n3. Tóm tắt báo cáo ............................................................................................. 11 \n\nPHẦN 1. ĐẶT VẤN ĐỀ VÀ ĐỊNH HƯỚNG GIẢI QUYẾT ................................. 13 \n\nI. ĐẶT VẤN ĐỀ ................................................................................................... 13 \n\nII. TỔNG QUAN VỀ TÓM TẮT VĂN BẢN TỰ ĐỘNG .................................... 13 \n\n2.1. Định nghĩa ................................................................................................... 13 \n\n2.2. Các tiêu chí đánh giá ................................................................................... 13 \n\n2.3. Ứng dụng của tóm tắt văn bản ..................................................................... 14 \n\n2.4. Phân loại tóm tắt văn bản ............................................................................ 14 \n\n2.4.1. Theo đầu vào hệ thống ...................................................................... 14 \n\n2.4.2. Theo đầu ra hệ thống ......................................................................... 14 \n\n2.4.3. Theo mục đích tóm tắt ....................................................................... 14 \n\n2.5. Mô hình biểu diễn văn bản .......................................................................... 15 \n\n2.5.1. Mô hình boolean ................................................................................ 15 \n\n2.5.2. Mô hình không gian vector ............................................................... 15 \n\n2.5.3. Mô hình tập thô dung sai ................................................................... 17 \n\n2.6. Mô hình tóm tắt văn bản .............................................................................. 17 \n\n2.7. Các phương pháp áp dụng trong các pha .................................................... 18 \n\n2.7.1. Pha Phân tích ..................................................................................... 18 \n\n2.7.1.1. Phương pháp thống kê ................................................................... 18 \n\n2.7.1.2. Phương pháp cấu trúc .................................................................... 19 \n\n2.7.2. Pha Biến đổi ...................................................................................... 20 \n\n2.7.2.1. Giản lược về cấu trúc câu .............................................................. 20 \n\n2.7.2.2. Giản lược về mặt ngữ nghĩa .......................................................... 20 \n\n2.7.3. Pha Hiển thị ....................................................................................... 21 \n\n2.7.3.1. Phương pháp hiển thị phân đoạn ................................................... 21 \n\n2.7.3.2. Phương pháp hiển thị liên kết ........................................................ 21 \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 6 \n\n   \n\n2.8. Đánh giá kết quả tóm tắt .............................................................................. 21 \n\n2.8.1. Sử dụng so khớp n-gram ................................................................... 22 \n\n2.8.2. Sử dụng các độ đo ROUGE .............................................................. 22 \n\n2.9. Một số hệ thống tóm tắt văn bản tiêu biểu .................................................. 22 \n\nIII. BÀI TOÁN TÓM TẮT VĂN BẢN HƯỚNG TRUY VẤN ......................... 24 \n\n3.1. Định nghĩa ................................................................................................... 24 \n\n3.2. Ứng dụng của bài toán ................................................................................. 24 \n\n3.3. Một số hướng tiếp cận phổ biến .................................................................. 24 \n\n3.3.1. Dựa trên đồ thị ................................................................................... 24 \n\n3.3.2. Dựa trên cấu trúc diễn ngôn .............................................................. 25 \n\n3.3.3. Dựa trên tần số từ và độ tương đồng câu .......................................... 25 \n\n3.4. Đề xuất hướng giải quyết cho tiếng Việt ..................................................... 25 \n\nPHẦN 2. GIẢI QUYẾT VẤN ĐỀ ............................................................................ 28 \n\nI. PHÂN TÍCH MÔ HÌNH THỰC HIỆN BÀI TOÁN ........................................ 28 \n\n1.1. Giai đoạn phân tích ...................................................................................... 29 \n\n1.1.1. Chuẩn hóa .......................................................................................... 29 \n\n1.1.2. Tách câu, tách từ ................................................................................ 29 \n\n1.1.3. Loại bỏ từ dừng ................................................................................. 30 \n\n1.1.4. Xử lý từ đồng nghĩa ........................................................................... 31 \n\n1.1.5. Mô hình hóa văn bản ......................................................................... 32 \n\n1.1.6. Chọn câu phù hợp tạo tóm tắt............................................................ 32 \n\n1.2. Giai đoạn hiển thị ........................................................................................ 34 \n\nII. CÀI ĐẶT THỬ NGHIỆM ................................................................................ 35 \n\n2.1. Chương trình thử nghiệm ............................................................................ 35 \n\n2.1.1. Các công cụ đã xây dựng................................................................... 35 \n\n2.1.1.1. Chương trình tóm tắt ...................................................................... 35 \n\n2.1.1.2. Công cụ tạo tập mẫu ...................................................................... 35 \n\n2.1.1.3. Công cụ kiểm thử ........................................................................... 36 \n\n2.2. Thử nghiệm một văn bản ............................................................................. 37 \n\n2.2.1. Đầu vào .............................................................................................. 37 \n\n2.2.2. Kết quả tóm tắt .................................................................................. 38 \n\n2.2.3. Nhận xét............................................................................................. 38 \n\n2.3. Thử nghiệm trên tập mẫu ............................................................................. 38 \n\n2.3.1. Dữ liệu thử nghiệm ............................................................................ 38 \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 7 \n\n   \n\n2.3.2. Độ đo BLEUS ................................................................................... 39 \n\n2.3.3. Kết quả thử nghiệm ........................................................................... 40 \n\n2.3.4. Nhận xét, đánh giá mô hình............................................................... 41 \n\nPHẦN 3. KẾT LUẬN VÀ ĐỀ XUẤT ...................................................................... 42 \n\n1. Các công việc đã thực hiện được .................................................................. 42 \n\n2. Đề xuất hướng phát triển ............................................................................... 42 \n\nTÀI LIỆU THAM KHẢO ......................................................................................... 43 \n\n \n\n  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 8 \n\n   \n\nDANH MỤC CÁC BẢNG \n\n \n\nBảng 1: Ví dụ một số từ dừng ................................................................................... 31 \n\nBảng 2: Một số mục từ đồng nghĩa ........................................................................... 32 \n\nBảng 3: Thông tin tập mẫu sử dụng để đánh giá ...................................................... 39 \n\nBảng 4: Ví dụ về n-gram ........................................................................................... 39 \n\nBảng 5: Kết quả kiểm thử độ đo BLEUS của tập mẫu ............................................. 40 \n\n  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 9 \n\n   \n\nDANH MỤC CÁC HÌNH VẼ \n\n \n\nHình 1: Mô hình chung của tóm tắt văn bản ............................................................. 17 \n\nHình 2: Mô hình tóm tắt văn bản trích rút ................................................................ 18 \n\nHình 3: Mô hình tóm tắt văn bản hướng truy vấn ..................................................... 28 \n\nHình 4: Minh họa quá trình chọn câu quan trọng ..................................................... 33 \n\nHình 5: Giao diện chương trình demo ...................................................................... 35 \n\nHình 6: Chương trình quản lý tập mẫu ..................................................................... 36 \n\nHình 7: Giao diện chương trình kiểm thử ................................................................. 36 \n\n  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 10 \n\n   \n\nDANH MỤC TỪ VIẾT TẮT \n\n \n\nViết tắt Ý nghĩa \n\nVSM Vector Space Model \n\nTF.IDF Term Frequency. Inverse Document Frequyency \n\nTF.ISF Term Frequency. Inverse Sentence Frequyency \n\nDUC Document Understanding Conferences \n\nTAC Text Analysis Conference \n\n   \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 11 \n\n   \n\nMỞ ĐẦU \n\n1. Lý do chọn đề tài \n\nNgày nay, sự phát triển nhanh chóng của công nghệ thông tin cùng các thiết bị sử \n\ndụng, việc chia sẻ, truy cập thông tin qua internet đã trở nên rất phổ biến. Mỗi ngày, \n\nvô số thông tin về tình hình kinh tế, xã hội, kinh nghiệm sống, học tập, làm việc… \n\nđược chia sẻ trên các báo mạng, diễn đàn... Tuy nhiên do lượng thông tin rất lớn hơn \n\nnữa còn trùng lặp, dư thừa nhiều, nên con người không đủ thời gian và công sức duyệt \n\nhết các văn bản để tìm thông tin hữu ích cho mình. Do đó, cần các hệ thống tổng hợp \n\nthông tin một cách ngắn gọn, chính xác, liên quan đến vấn đề mà người dùng quan \n\ntâm. Giải pháp cho vấn đề này là bài toán Tóm tắt văn bản hướng truy vấn, một dạng \n\ncủa bài toán tóm tắt văn bản tự động. \n\nBài toán tóm tắt văn bản tự động vô cùng phức tạp nhưng rất hữu dụng, do đó đã \n\ncó nhiều công ty lớn, các nhà khoa học, nhóm nghiên cứu đầu tư thời gian và tiền bạc \n\nđể tìm ra các hướng giải quyết hiệu quả nhất. Các hội nghị nổi tiếng liên quan đến \n\ntóm tắt văn bản như: DUC(2001-2007), TAC(2008), ALC(2001-2007)… đã đưa ra \n\nrất nhiều kết quả phân tích và các giải pháp hữu ích. Một số hệ thống tóm tắt văn bản \n\nđã được ứng dụng vào thực tế và cho thấy lợi ích của nó như MEAD, LexRank, \n\nAutoSummarize trong Microsoft Office Word… Đối với tóm tắt hướng truy vấn, \n\ncũng có rất nhiều công trình nghiên cứu, ứng dụng, chủ yếu là sử dụng trong các máy \n\ntìm kiếm hoặc hệ thống hỏi đáp tự động. \n\nTuy nhiên các công trình đó phần lớn dành cho tiếng Anh, với tiếng Việt thì chưa \n\ncó nhiều nghiên cứu, vì thế trong đồ án này, em xin chọn đề tài “Tóm tắt văn bản \n\nhướng truy vấn”. Với mục đích tìm hiểu quy trình tóm tắt văn bản và các vấn đề liên \n\nquan, tổng hợp một số kỹ thuật sử thường sử dụng trong tóm tắt văn bản, dựa vào đó \n\nđề xuất, cài đặt thử nghiệm một hướng tiếp cận phù hợp với bài toán tóm tắt đơn văn \n\nbản hướng truy vấn cho tiếng Việt. \n\n2. Phạm vi nghiên cứu \n\n Các vấn đề xoay quan tóm tắt văn bản \n\n Một số hướng tiếp cận tóm tắt văn bản hướng truy vấn \n\n Thực hiện một phương pháp tóm tắt trích rút, đơn văn bản, hướng truy vấn \n\nphù hợp với tiếng Việt \n\n3. Tóm tắt báo cáo \n\nNội dung của báo cáo bao gồm các phần cụ thể như sau: \n\nPhần 1. Đặt vấn đề và định hướng giải quyết \n\nI. Đặt vấn đề: Nêu vấn đề cần giải quyết trong đồ án \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 12 \n\n   \n\nII. Tổng quan về tóm tắt văn bản tự động: Trình bày các định nghĩa, phân loại, \n\ncách biểu diễn văn bản, quy trình thực hiện bài toán tóm tắt văn bản, các kỹ thuật \n\nthường dùng, các tiêu chí và một số phương pháp đánh giá hệ thống tóm tắt. \n\nIII. Bài toán tóm tắt văn bản hướng truy vấn: Trình bày một số hướng tiếp cận \n\ncho bài toán tóm tắt hướng truy vấn và đề xuất một hướng tiếp cận phù hợp cho văn \n\nbản tiếng Việt.  \n\nPhần 2. Giải quyết vấn đề \n\nI.  Phân tích mô hình thực hiện bài toán: Đưa ra mô hình cụ thể, và phân tích \n\nchi tiết các bước thực hiện dựa trên hướng tiếp cận đã đề xuất. \n\nII. Cài đặt thử nghiệm: Xây dựng các công cụ và dữ liệu mẫu để thực hiện kiểm \n\nthử, đánh giá mô hình. Từ đó nhận xét ưu nhược điểm và khả năng ứng dụng. \n\nPhần 3. Kết luận và đề xuất: Trình bày các vấn đề đã giải quyết được trong đồ \n\nán, các vấn đề tồn tại và đề xuất hướng phát triển. \n\n  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 13 \n\n   \n\nPHẦN 1. ĐẶT VẤN ĐỀ VÀ ĐỊNH HƯỚNG GIẢI QUYẾT \n\nI. ĐẶT VẤN ĐỀ \n\nNhư đã nêu ở trên, mục tiêu cụ thể của đồ án là đề xuất và thử nghiệm một hướng \n\ntiếp cận cho bài toán tóm tắt hướng truy vấn đơn văn bản áp dụng được cho tiếng \n\nViệt. Cụ thể bài toán cần giải quyết được phát biểu như sau: \n\nĐầu vào: Văn bản, truy vấn, độ rút gọn \n\nĐầu ra: Bản tóm tắt của văn bản đầu vào xoay quanh vấn đề nêu trong truy vấn \n\nĐể giải quyết được bài toán này, việc trước hết là tìm hiểu cơ sở lý thuyết về tóm \n\ntắt văn bản, tóm tắt hướng truy vấn, từ đó xác định hướng giải quyết và thực hiện cài \n\nđặt thử nghiệm. \n\nII. TỔNG QUAN VỀ TÓM TẮT VĂN BẢN TỰ ĐỘNG \n\n2.1. Định nghĩa \n\nTóm tắt văn bản là quá trình làm giảm độ dài, độ phức tạp của văn bản mà vẫn \n\ngiữ lại được nội dung quan trọng của văn bản đó. Công việc tóm tắt văn bản đã xuất \n\nhiện từ rất lâu đời, và nó được làm thủ công, do con người đọc, rút ra các ý chính rồi \n\ntrình bày lại một cách ngắn gọn, dễ hiểu. Mục đích là giúp người sử dụng có cái nhìn \n\ntổng quan về nội dung trình bày trong văn bản, để quyết định sử dụng văn bản đó hợp \n\nlý. Tuy nhiên với lượng văn bản nhiều và dài thì việc làm thủ công vô cùng tốn thời \n\ngian, công sức. \n\nNgày nay, thời đại công nghệ thông tin phát triển mạnh, tóm tắt văn bản tự động \n\n(gọi tắt là tóm tắt văn bản) được nghiên cứu phát triển nhằm mục đích làm thay con \n\nngười công việc nặng nhọc đó. Đã có rất nhiều định nghĩa được đưa ra, tuy nhiên có \n\nthể sử dụng định nghĩa ngắn gọn sau: \n\n“Tóm tắt văn bản là quá trình rút ra những thông tin quan trọng nhất từ một hay \n\nnhiều nguồn văn bản để tạo ra một văn bản gọn hơn phục vụ cho một số nhiệm vụ \n\nhay người dùng cụ thể” \n\n2.2. Các tiêu chí đánh giá \n\n Độ mạch lạc (Coherence): đánh giá mức độ rõ ràng của văn bản tóm tắt, tính \n\nsúc tích, khả năng có thể đọc và hiểu được của bài viết… \n\n Độ hàm chứa thông tin (Informationess): tỉ lệ thông tin của văn bản gốc trong \n\nvăn bản tóm tắt. \n\n Độ liên quan (Relevance): xác định mức độ phù hợp của văn bản tóm tắt với \n\nchủ đề cho trước (chủ đề có thể là một câu truy vấn). \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 14 \n\n   \n\n Độ dễ đọc hiểu (Reading Comprehence): một người được giao việc đọc văn \n\nbản kết quả, sau đó trả lời các câu hỏi, hệ thống sẽ phải cho điểm và từ đó đưa ra \n\nphần trăm những câu trả lời đúng. \n\n2.3. Ứng dụng của tóm tắt văn bản \n\nTóm tắt văn bản có nhiều ứng dụng trong thực tế, một số ứng dụng nổi bật như: \n\n Tóm tắt tự động các tin tức trên báo điện tử. \n\n Trợ giúp thông minh việc đọc và khai thác thông tin. \n\n Tóm lược danh sách tìm kiếm từ các Search Engine. \n\n Giản lược nội dung trình bày cho các thiết bị cầm tay. \n\n Sinh tự động chủ đề, tiêu đề, dẫn đường văn bản. \n\n Hỗ trợ tóm lược nội dung cuộc họp, website, chương trình phát thanh và \n\ntruyền hình, sổ tay công việc. \n\n2.4. Phân loại tóm tắt văn bản \n\nCó nhiều cách phân loại tóm tắt, phụ thuộc vào tiêu chí sử dụng để phân loại, sau \n\nđây là một số cách phân loại cần quan tâm: \n\n2.4.1. Theo đầu vào hệ thống \n\nTóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn gọn của văn bản \n\nđó. Ngược lại, tóm tắt đa văn bản là từ nhiều văn bản nguồn cũng chỉ cho ra một \n\nđoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng \n\nthời cho nhiều văn bản khác nhau. Rõ ràng, tóm tắt đa văn bản thì khó hơn, vì ngoài \n\nnhững công việc của tóm tắt đơn văn bản, tóm tắt đa văn bản còn phải thực hiện các \n\ncông việc như tiền xử lý trích rút, tích hợp thống nhất khuôn dạng và hiển thị kết quả \n\ntheo cách riêng. Ngoài ra, tóm tắt đa văn bản còn phải đối mặt với các vấn đề như dư \n\nthừa trùng lặp dữ liệu giữa các văn bản nguồn, nội dung các văn bản nguồn phân tán, \n\nđộ rút gọn yêu cầu cao, thời gian xử lý cần phải nhanh trong khi sự phức tạp trong xử \n\nlý lớn. \n\n2.4.2. Theo đầu ra hệ thống \n\nTóm tắt trích rút là quá trình thu gọn văn bản mà trong kết quả ra chứa các đơn \n\nvị ngữ liệu văn bản nguồn. Tóm tắt tóm lược là quá trình thu gọn văn bản mà trong \n\nkết quả ra có một số các đơn vị ngữ liệu mới được sinh ra từ các đơn vị ngữ liệu văn \n\nbản nguồn. \n\n2.4.3. Theo mục đích tóm tắt \n\nTóm tắt chung là tóm tắt theo quan điểm ban đầu của tác giả văn bản gốc. Tóm \n\ntắt hướng truy vấn là tóm tắt theo quan điểm mong muốn của người dùng ứng dụng \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 15 \n\n   \n\nthông qua các tham số truyền vào câu truy vấn. Tóm tắt hướng truy vấn được cài đặt \n\nvà áp dụng nhiều hơn nhưng trong lĩnh vực hẹp hơn, đi sâu vào các chuyên ngành cụ \n\nthể. \n\n2.5. Mô hình biểu diễn văn bản \n\nVăn bản thông thường là dạng dữ liệu phi cấu trúc, do vậy muốn xử lý chúng \n\ntrước hết phải biểu diễn thành dạng có cấu trúc. Các cấu trúc này phải có khả năng \n\nthao tác bằng các phép toán cơ bản như cộng, nhân, đại số quan hệ... Có ba mô hình \n\nthỏa mãn yêu cầu đó thường được sử dụng là: \n\n2.5.1. Mô hình boolean \n\nTrong mô hình boolean, văn bản, vốn là tập hợp của các term (thuật ngữ), được \n\nbiểu diễn bởi chỉ số từng term và trọng số của chúng. Trọng số của từng term - dùng \n\nđể đánh giá độ quan trọng của chúng - trong mô hình này chỉ mang hai giá trị 0 và 1, \n\ntùy theo sự xuất hiện của term đó trong văn bản. \n\n \n\nTrong đó wi là trọng số của term ti trong văn bản D. \n\nĐối với vấn đề truy vấn, trong mô hình này câu truy vấn bao gồm các văn bản \n\ntìm kiếm liên hệ với nhau thông qua các phép đại số quan hệ cơ bản như NOT (phủ \n\nđịnh), AND (và) hay OR (hoặc). Câu truy vấn có thể biểu diễn thành dạng vector với \n\ncác thành phần liên kết và các phép toán quan hệ cơ bản. Từ đây, độ liên quan giữa \n\nmột văn bản và truy vấn được xác định thông qua các thành phần liên kết. Độ liên \n\nquan này chỉ có thể mang hai giá trị : 0 – văn bản không phù hợp với truy vấn và 1 – \n\nvăn bản phù hợp. \n\nDo vậy có thể thấy rằng hạn chế lớn nhất của mô hình này đó là việc đánh giá độ \n\nliên quan chỉ trả về hai kết quả, hoặc phù hợp hoặc không, như vậy yêu cầu của hệ \n\nthống khi cần sắp xếp và chọn lựa các văn bản theo mức độ liên quan đến truy vấn sẽ \n\nkhông đạt. Độ liên quan của mô hình này không thể phân chia thành các mức khác \n\nnhau, do vậy không phản ánh được thực tế là việc liên quan giữa văn bản và truy vấn \n\ncó thể là mờ, không chắn chắn. Hạn chế này được loại bỏ khi ta sử dụng một mô hình \n\ntổng quát hơn – Mô hình không gian vector (VSM). \n\n2.5.2. Mô hình không gian vector \n\nNhư trên đã đề cập, mô hình không gian vector là mô hình tổng quát hơn mô hình \n\nBoolean. Các văn bản được biểu diễn thành các vector nhiều chiều, với trọng số không \n\nchỉ mang hai giá trị là 0 hay 1 mà có thể mang các giá trị khác tùy theo cách đánh giá, \n\ntính toán. Một khác biệt nữa so với mô hình boolean là các phép toán cơ bản của mô \n\nhình không gian vector. Các phép toán đại số quan hệ dĩ nhiên không phù hợp nữa, \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 16 \n\n   \n\nthay vào đó là các phép toán vector như cộng hai vector, nhân hai vector, tích vô \n\nhướng… \n\nKhi biểu diễn văn bản thành các vector, vấn đề về truy vấn và xác định độ liên \n\nquan hoàn toàn được giải quyết. Truy vấn là kết quả của các phép toán vector giữa \n\ncác vector biểu diễn cho những văn bản cấu thành nên truy vấn, như vậy, truy vấn \n\ntrong trường hợp này cũng là một văn bản đặc biệt. Việc xác định độ liên quan giữa \n\ntruy vấn và văn bản được quy thành độ liên quan giữa văn bản và văn bản. Hai văn \n\nbản là hai vector, vậy khoảng cách hay góc giữa chúng đều có thể đại diện cho sự liên \n\nquan giữa hai văn bản này. Tất nhiên, để áp dụng được các phép toán vector cơ bản, \n\nhai vector cần chuẩn hóa về số chiều (độ dài). \n\nCác chỉ số sử dụng trong phương pháp này: \n\n Tần suất thuật ngữ của một từ w trong một văn bản d, ký hiệu TF(w,d), có \n\nthể sử dụng các công thức sau, với fij là số lần xuất hiện của từ wi trong văn bản dj:  \n\n \n\n Tần suất văn bản của một từ w, ký hiệu DF(w) là số lượng văn bản mà từ w \n\ncó xuất hiện. Nghịch đảo của tần suất văn bản của một từ w, ký hiệu IDF(w) được \n\ncho bởi công thức: \n\n \n\nTrong đó: m là tổng số văn bản,, h là số văn bản chứa từ w \n\n Tần suất TF-IDF là kết hợp của hai loại tần suất nói trên: \n\nTF-IDF(w,d) = TF(w,d) * IDF(w) \n\nTheo mô hình này, mỗi văn bản sẽ được biểu diễn dưới dạng D(t1, t2,…,tn) với n \n\nlà tổng số thuật ngữ xuất hiện, mỗi thuật ngữ sẽ được đánh index, ti là trọng số của \n\nthuật ngữ thứ i(trong danh sách thuật ngữ) trong văn bản D. Khi đó độ liên quan giữa \n\nhai văn bản biểu diễn bởi 2 vector X(x1, x2, …, xn) và Y(y1, y2,…,yn) được tính bằng \n\ncông thức Cosin: \n\n \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 17 \n\n   \n\n2.5.3. Mô hình tập thô dung sai \n\n Mô hình tập thô dung sai (Tolerance Rough Set Model) là một mô hình mới, \n\ntiên tiến dựa trên lý thuyết về logic mờ và tập mờ (Fuzzy Set). Điều cốt lõi của lý \n\nthuyết này là việc xác định chính xác một giả thiết nào đó (ví dụ như hai văn bản này \n\ncó phù hợp, có giống nhau không...) là một điều rất khó. Tuy nhiên chúng ta có thể \n\nchỉ ra một cặp xấp xỉ trên và xấp xỉ dưới để khẳng định được giả thiết đó là đúng. Sử \n\ndụng các suy diễn hợp lý để xác định và “làm đẹp” các ngưỡng này. Các phép toán \n\ncơ bản trong mô hình tập thô dựa trên các quan hệ tương đương các tính chất như đối \n\nxứng, phản xạ, bắc cầu... Lý thuyết logic mờ đã và đang được ứng dụng rất mạnh mẽ \n\ntrong lĩnh vực Trí tuệ nhân tạo. \n\nMô hình tập thô gần đây được sử dụng nhiều cho các bài toán tìm kiếm cũng như \n\nphân nhóm văn bản… Tuy nhiên khi áp dụng mô hình tập thô cho quá trình xử lý văn \n\nbản thì tính chất bắc cầu không còn phù hợp. Nhóm tác giả Hồ Tú Bảo, Saori \n\nKawasaki, Nguyễn Ngọc Bình đã đề xuất ra mô hình tập thô dung sai trong đó bỏ đi \n\ntính chất bắc cầu trong quá trình xử lý văn bản. Lý thuyết tập thô được các nhà nghiên \n\ncứu Trí tuệ nhân tạo phát triển và ngày càng thể hiện được tính ưu việt không chỉ \n\ntrong  việc biểu diễn và thao tác văn bản mà còn trong các vấn đề khác của lĩnh vực \n\nnày. \n\n2.6. Mô hình tóm tắt văn bản \n\n \n\nHình 1: Mô hình chung của tóm tắt văn bản \n\nMột mô hình tóm tắt văn bản tổng quát gồm các pha sau: \n\n Phân tích (Analysis): Phân tích văn bản đầu vào để đưa ra những mô tả bao \n\ngồm các thông tin dùng để tìm kiếm, đánh giá các đơn vị ngữ liệu quan trọng cũng \n\nnhư các tham số đầu vào cho việc tóm tắt. \n\n Biến đổi (Transformation): Lựa chọn các thông tin trích chọn được, biến đổi \n\nđể giản lược và thống nhất, kết quả là các đơn vị ngữ liệu đã được tóm tắt. \n\n Hiển thị (Generation): Từ các đơn vị ngữ liệu đã tóm tắt, liên kết chúng lại \n\nthành đoạn theo một thứ tự nào đó hoặc theo cấu kết ngữ pháp rồi hiển thị phù hợp \n\nvới yêu cầu người dùng. \n\nMột hệ Tóm lược (Abstraction) bao gồm tất cả các pha trên, tuy nhiên một hệ \n\nTrích rút (Extraction) chỉ gồm pha Phân tích và Pha Hiển thị, không có pha biến đổi. \n\nThậm chí trong các pha phân tích và hiển thị, chỉ có một số công đoạn được sử dụng. \n\nPhân tích \n\n(Analysis)\n\nBiến đổi \n\n(Transform)\n\nHiển thị \n\n(Generation)\n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 18 \n\n   \n\n \n\nHình 2: Mô hình tóm tắt văn bản trích rút \n\nNhư vậy một hệ Trích rút tiến hành ít bước hơn, các phương pháp thường dùng \n\nlà thống kê, học trên ngữ liệu. Còn hệ Tóm lược thì phức tạp, do kết hợp các phương \n\npháp của xử lý ngôn ngữ tự nhiên. Vì vậy, kết quả của các hệ Tóm lược thường thuyết \n\nphục hơn (về mặt dễ đọc, dễ hiểu, liên kết ngôn ngữ tốt, gần gũi với con người). \n\nTrong mỗi pha có thể áp dụng nhiều kỹ thuật xử lý khác nhau, chi tiết sẽ được \n\ntrình bày ở phần tiếp theo. \n\n2.7. Các phương pháp áp dụng trong các pha \n\n2.7.1. Pha Phân tích \n\nỞ pha này văn bản nguồn sẽ được tách thành các đoạn, câu, từ, kết hợp với các \n\nthông số đầu vào và áp dụng một số thuật toán cụ thể để chọn ra các đoạn hoặc câu \n\nphù hợp làm đầu vào cho pha tiếp theo. \n\nCác phương pháp áp dụng trong pha Phân tích được chia thành hai loại: Phương \n\npháp thống kê và Phương pháp cấu trúc. \n\n2.7.1.1. Phương pháp thống kê \n\nPhương pháp này sử dụng các số liệu thống kê về độ quan trọng của từ, câu hay \n\nđoạn, nhận được từ các nghiên cứu về ngôn ngữ học hay thông qua các phương pháp \n\nhọc máy dựa trên tập mẫu để trích rút ra các đơn vị ngữ liệu quan trọng  \n\n Phương pháp vị trí \n\nPhương pháp vị trí bao gồm các phương pháp xác định độ quan trọng dựa trên \n\nthống kê về vị trí của từ, ngữ hay câu trong văn bản. Các thống kê này tất nhiên phụ \n\nthuộc vào thể loại văn bản… \n\n Chủ đề - Tiêu đề (Title-based): Chủ đề các đoạn văn bản hay tiêu đề các bảng \n\nthường chứa các từ và ngữ quan trọng, nên trích rút thông tin từ đây. \n\n Đầu - cuối đoạn (First - Last Sentence): Xác suất câu đầu đoạn hay câu cuối \n\nđoạn chứa ý chính của cả đoạn là rất lớn, đặc biệt là câu đầu đoạn. Ngoài ra, \n\ncác đoạn đầu và cuối trong văn bản cũng quan trọng hơn các đoạn giữa. \n\n Minh họa - Chú thích (Comments): Trong các câu chú thích, câu minh họa \n\ncho ảnh hay đồ thị thường chứa các thông tin quan trọng. Tuy nhiên, các câu \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 19 \n\n   \n\nnày thường chỉ được dùng để đánh giá độ quan trọng của các câu khác liên \n\nquan, chứ không được chọn làm đầu vào cho pha tiếp. \n\n Phương pháp ngữ cố định \n\nCác ngữ cố định có đặc điểm thống kê rất tốt. Sau các ngữ này thường là các câu \n\nhay từ có độ quan trọng là xác định. Người ta chia thành hai loại ngữ cố định, một \n\nloại mang lại độ quan trọng cho thành phần đi sau, được gọi là ngữ nhấn mạnh, một \n\nloại giúp ta loại bỏ, không xét đến những thành phần đi sau vì nó không có nhiều giá \n\ntrị trong việc trích rút, được gọi là ngữ dư thừa: \n\n Ngữ nhấn mạnh (Bonus phrase - Emphasizer): Ngữ nhấn mạnh gồm các ngữ \n\nnhư “nói chung là…”, “đặc biệt là…”, “cuối cùng thì…”, “trong bài viết này \n\ntôi muốn chỉ ra…”, “bài viết nói về…”, “nội dung gồm…”,..v..v... \n\n Ngữ dư thừa (Stigma phrases): Một số ngữ dư thừa: “hiếm khi mà…”, “bài \n\nnày không nói đến…”, “Không thể nào…”, ..v..v... \n\n Phương pháp thống kê tần suất từ \n\nĐộ quan trọng của từ phụ thuộc vào số lần xuất hiện của từ đó trong các văn bản \n\nliên quan. Các kỹ thuật như TF.IPF hay Tập thuật ngữ thường xuyên (Frequent Item \n\nSet) dùng cho công việc xác định tần suất của từ. \n\n2.7.1.2. Phương pháp cấu trúc \n\nLà các phương pháp sử dụng các mối liên hệ cấu trúc - ngữ pháp - ngữ nghĩa để \n\nxác định các đơn vị ngữ liệu quan trọng. Tư tưởng chính của các phương pháp này là \n\nnhững đơn vị ngữ liệu nào có chứa các thành phần liên kết nhiều với các thành phần \n\nkhác sẽ có độ quan trọng lớn. Việc đánh giá các mối quan hệ sẽ dựa trên các mạng \n\nngữ nghĩa, các quan hệ cú pháp hoặc thông qua các phương pháp xác định độ liên \n\nquan truyền thống. \n\n Phương pháp quan hệ lẫn nhau: Phương pháp này xác định mối quan hệ \n\ngiữa các đoạn trong văn bản hay các câu trong đoạn với nhau thông qua các kỹ thuật \n\nthu thập thông tin ở mức văn bản. Các đoạn (câu) trong văn bản nguồn được tính toán \n\nđộ liên quan lẫn nhau sử dụng các kỹ thuật như Cosine, TF.IPF hay N-gram Overlap. \n\nSau đó chọn ra đoạn (câu) có độ liên quan lớn nhất. \n\n Phương pháp liên kết từ vựng: Phương pháp liên kết từ vựng sử dụng các từ \n\nđiển quan hệ từ vựng đế xây dựng các chuỗi từ liên kết với nhau vể mặt ngữ nghĩa. \n\nVí dụ “cây” là một loại “thực vật”, có bộ phận là “lá”, chất liệu là “gỗ”. Các từ “cây”, \n\n“thực vật”, “lá”, “gỗ” có quan hệ ngữ nghĩa nào đó với nhau. Sau khi xây dựng được \n\ncác chuỗi từ này, đánh giá độ mạnh của chúng và có những trích chọn phù hợp. \n\n Phương pháp Liên kết tham chiếu: Phương pháp liên kết tham chiếu còn \n\nđược gọi là phương pháp trích chọn trùng lặp (Anaphora-based Method). Theo \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 20 \n\n   \n\nphương pháp này, các cụm trùng lặp được chọn ra, phân rã xem đâu là từ tham chiếu \n\nvà từ được tham chiếu. Sau khi phân tách các cụm trùng lặp, chúng ta tạo chuỗi các \n\ntừ tham chiếu đến cùng một từ được tham chiếu. Chuỗi dài nhất sẽ được coi là trọng \n\ntâm của đoạn, các câu chứa các từ trong chuỗi này có một độ ưu tiên nào đó khi xét \n\ntrích chọn. \n\n Phương pháp quan hệ câu: Dựa trên các từ thể hiện mối quan hệ giữa các \n\ncâu chúng ta cấu trúc hóa đoạn văn bản từ các đơn vị thành phần như ngữ, mệnh đề, \n\ncâu... Sau đó đơn vị được coi như trung tâm sẽ được trích chọn. \n\n2.7.2. Pha Biến đổi \n\nỞ pha này, các câu sẽ được biến đổi, làm gọn lại hoặc kết hợp nhiều câu tạo thành \n\ncâu mới ngắn gọn hơn. Các phương pháp trong pha này không làm tăng thêm độ \n\nchính xác mà chỉ giúp cho văn bản kết quả ngắn gọn hơn mà vẫn sát nghĩa và thuật \n\ntoán thưởng rất phức tạp. Có thể chia làm 2 loại: \n\n2.7.2.1. Giản lược về cấu trúc câu \n\nGiản lược về cấu trúc câu là việc lược bỏ trong câu các phần thừa, ít mang giá trị, \n\nlàm cho cấu trúc câu thu gọn lại. Công việc này thường dựa trên phân tích cú pháp \n\ncác thành phần trong câu. \n\n2.7.2.2. Giản lược về mặt ngữ nghĩa \n\n Phương pháp trừu tượng hóa khái niệm \n\nTư tưởng của phương pháp này là từ các khái niệm cụ thể thay thế bằng khái niệm \n\nchung. \n\nVí dụ: “Tôi ăn dâu, táo và đào” => “Tôi ăn trái cây” \n\n Phương pháp thay thế bộ phận \n\nTư tưởng của phương pháp này là từ các khái niệm bộ phận thay thế bằng khái \n\nniệm toàn bộ. \n\nVí dụ: “Xích, líp, ghi đông, bàn đạp …” => “Cái xe đạp…”. \n\n Phương pháp thay thế ngữ tương đương \n\nTư tưởng của phương pháp này là các ngữ đóng vai trò như nhau trong câu được \n\nthay bằng một ngữ chung. \n\nVí dụ: “Anh ấy bước vào, ngồi xuống ghế, xem thực đơn, gọi món, ăn, trả tiền và \n\nra về” => “Anh ấy đi ăn tiệm”. \n\n Phương pháp thay thế từ, ngữ đồng nghĩa ngắn hơn \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 21 \n\n   \n\nMột phương pháp khác khá dễ hiểu đấy là việc thay thế một từ, ngữ bằng một từ, \n\nngữ khác đồng nghĩa hoặc gần nghĩa nhưng có độ dài ngắn hơn. Điều này thường \n\nthông qua một từ điển các từ đồng nghĩa (Thesaurus). \n\n Phương pháp thay thế bởi đại diện \n\nTư tưởng của phương pháp này là thay thế một ngữ bằng một ngữ khác có ý nghĩa \n\nđại diện cho ngữ ban đầu. \n\nVí dụ: “Người phát ngôn viên của chính phủ Hoa Kỳ thông báo…” => \n\n“Washington thông báo…”. \n\n2.7.3. Pha Hiển thị \n\n2.7.3.1. Phương pháp hiển thị phân đoạn \n\nĐây là phương pháp đơn giản nhất. Các đơn vị ngữ liệu được trích rút hay giản \n\nlược từ các pha trước được liên kết lại thành đoạn theo thứ tự tiền định của chúng, \n\nkhông thêm bớt từ nối và cũng không sắp xếp lại các đơn vị ngữ liệu. Văn bản kết \n\nquả của phương pháp này có độ dễ đọc dễ hiểu kém, thậm chí lủng củng về nghĩa vì \n\ncác đơn vị ngữ liệu được trích rút mắc phải một số lỗi như mập mờ tham chiếu, không \n\ncó từ nối hoặc là thừa từ và ngữ. \n\n2.7.3.2. Phương pháp hiển thị liên kết \n\nViệc hiển thị liên kết là tiếp nhận các đơn vị ngữ liệu đã được trích rút và giản \n\nlược từ các pha trước đó, phân tích mối quan hệ về nghĩa của các câu rồi thêm bớt \n\ncác từ nối, từ dẫn và sắp xếp theo một thứ tự mới dựa vào những gì đã thu thập sao \n\ncho thỏa mãn yêu cầu về hiển thị và yêu cầu về độ dễ đọc, dễ hiểu của người dùng. \n\n2.8. Đánh giá kết quả tóm tắt \n\nĐánh giá một bản tóm tắt là một công việc khó bởi không tồn tại một bản tóm tắt \n\nlý tưởng cho một (hoặc một tập) văn bản đưa ra. Hơn nữa, việc đánh giá nội dung \n\ntóm tắt cũng rất khó khăn. Trường hợp kết quả là một câu trả lời cho một câu hỏi, ta \n\ncó thể xác định được câu trả lời đó đúng hay sai, nhưng trong các trường hợp khác, \n\nthật khó trả lời liệu đầu ra là phải một kết quả đúng hay không? Thực tế luôn có khả \n\nnăng một hệ thống sinh ra một bản tóm tắt tốt nhưng lại sai khác với bản tóm tắt do \n\nngười thực hiện. Bên cạnh đó, khi việc đánh giá được thực hiện bởi con người thì chi \n\nphí đánh giá sẽ rất cao. Mặt khác, tóm tắt văn bản còn liên quan đến tỉ lệ nén văn bản, \n\ndo đó, việc đánh giá bản tóm tắt cần phải quan tâm đến vấn đề này, khi đó độ phức \n\ntạp và chi phí đánh giá sẽ tăng cao. \n\nDưới đây là hai phương pháp đánh giá tự động thường sử dụng: \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 22 \n\n   \n\n2.8.1. Sử dụng so khớp n-gram \n\nPhương pháp này được Lin và Hovy đưa ra năm 2002 dựa trên mô hình n-gram \n\ncủa độ đo BLEU (Bilingual Evaluation Understudy [1], độ đo đánh giá kết quả dịch \n\nmáy). Ý tưởng của phương pháp này là so khớp n-gram liên tiếp của bản tóm tắt thủ \n\ncông và tóm tắt tự động, theo công thức sau: \n\nScore=α1*Score1+ α2*Score2+ α3*Score3+ α4*Score4 \n\nTrong đó: \n\nScorei = Số i-gram trùng nhau/Tổng số i-gram của bản tóm tắt thủ công \n\n   αi là hệ số đánh giá độ quan trọng của các Scorei \n\n2.8.2. Sử dụng các độ đo ROUGE \n\nROUGE(Recall-Oriented Understudy of Gisting Evaluation [2]) cũng được đưa \n\nra bởi Lin, vào năm 2009, đây là tập hợp các độ đo dựa trên mô hình n-gram của \n\nBLEU với nhiều cách tính khác nhau. Thường sử dụng nhất là độ đo ROUGE-N, với \n\nn là giá trị của mô hình n-gram, n={1,2,3,4}. \n\nCông thức của độ đo ROUGE-N như sau: Cho R=(r1, r2, …, rn) là tập các tóm tắt \n\nmẫu, s là tóm tắt tự động, Ωn(d) là vector biểu diễn mô hình n-gram của văn bản d. \n\n \n\nĐộ đo ROUGE được sử dụng làm độ đo chính thức của các hội nghị DUC 2004-\n\n2007 và TAC 2008-2012. \n\n2.9. Một số hệ thống tóm tắt văn bản tiêu biểu \n\nHiện tại, trên thế giới đã có rất nhiều nghiên cứu và dự án xây dựng các ứng dụng \n\ntóm tắt văn bản. Các ứng dụng này có thể đáp ứng rất nhiều các mục đích khác nhau. \n\nCó thể kể ra một số ứng dụng Tóm tắt văn bản tiêu biểu như sau: \n\n SUMMARIST: Một hệ thống Trích rút văn bản năm thứ tiếng (tiếng Anh, \n\ntiếng Nhật, tiếng Tây Ban Nha, tiếng Ả-rập và tiếng Hàn Quốc). Hiện tại \n\nSUMMARIST đang nghiên cứu để cải tiến trở thành một hệ thống Tóm lược \n\nvăn bản và hỗ trợ nhiều ngôn ngữ hơn như tiếng Pháp và Indonesia. \n\n SweSUM: Ứng dụng Tóm tắt văn bản đa ngôn ngữ của Học viện công nghệ \n\nhoàng gia Thụy Điển. SweSUM có thể tóm tắt các văn bản có ngôn ngữ vùng \n\nScandinavi như Thụy Điển, Đan Mạch, Na Uy và các ngôn ngữ khác như tiếng \n\nAnh, Pháp, Đức, Tây Ban Nha và cả tiếng Iran. \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 23 \n\n   \n\n SumUM: Hệ thống Tóm lược văn bản kỹ thuật của nhóm nghiên cứu xử lý \n\nngôn ngữ tự nhiên trường Đại học Montréal, Canada. SumUM có thể thực hiện \n\ncả chức năng tóm tắt chỉ định và tóm tắt thông tin rất tốt.. \n\n FJCL: Hệ thống Rút trích văn bản tiếng Nhật được phát triển trong phòng \n\nnghiên cứu Ikeda của trường đại học Gifu. Đây là một hệ thống sử dụng các \n\nphương pháp áp dụng cho hệ ngôn ngữ đơn âm tiết (monosyllabic language \n\nsystem) như tiếng Nhật, Hàn Quốc, Trung Quốc và Việt Nam. \n\n Pertinence Summarizer: Hệ thống tóm tắt tin tức đa ngôn ngữ trực tuyến nổi \n\ntiếng. Hiện tại để thử nghiệm khả năng của mình, Pertinence đã được tích hợp \n\nvới Google và tóm tắt tự động danh sách tìm kiếm trả về từ Google thông qua \n\ncâu truy vấn đưa vào. Chúng ta có thể thử nghiệm hệ thống này trên trang web: \n\nwww.pertinence.net. \n\n MEAD: Nền tảng cho các hệ thống Tóm tắt nhiều văn bản và đa ngôn ngữ. \n\nĐây là một bộ công cụ xây dựng trên nền Linux và Solaris, sử dụng ngôn ngữ \n\nPerl - Một ngôn ngữ có khả năng xử lý văn bản rất linh hoạt và mạnh mẽ. \n\nMEAD biểu diễn, lưu trữ dữ liệu ở dạng XML, cung tấp cho chúng ta khung \n\nứng dụng để cài đặt các ứng dụng Tóm tắt văn bản cho ngôn ngữ mà ta muốn. \n\nNgoài ra MEAD cũng cung cấp các công cụ để xây dựng các ứng dụng đánh \n\ngiá hệ thống tóm tắt theo các tiêu chí và các tập mẫu nổi tiếng. MEAD được \n\nxây dựng bởi các chuyên gia nổi tiếng về Xử lý ngôn ngữ ở khắp nơi trên thế \n\ngiới dưới sự tài trợ của Chương trình Nghiên cứu Công nghệ thông tin của Tổ \n\nchức Khoa học quốc gia Mỹ. MEAD được cung cấp ở dạng mã nguồn mở để \n\nnghiên cứu và kế thừa. Hiện tại phiên bản mới nhất của MEAD là MEAD \n\nv3.07. \n\n Microsoft Word AutoSummary: Microsoft cũng cài đặt chức năng Trích rút \n\nvà sinh tiêu đề trong Microsoft Word từ phiên bản Word '97. Chúng ta có thể \n\nthử bằng cách chọn Tools - AutoSummarize trên thanh công cụ (có thể khác \n\ntùy vào phiên bản). Công cụ này cho phép chúng ta chọn thông số về độ rút \n\ngọn, trích rút hay sinh tiêu đề... \n\nNgoài ra còn các hệ thống Tóm tắt văn bản nổi tiếng khác như ANES hay \n\nSUMMONS. Tuy nhiên tại Việt Nam hiện nay chưa có một nghiên cứu và ứng dụng \n\nTóm tắt văn bản chính thức nào. \n\n  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 24 \n\n   \n\nIII. BÀI TOÁN TÓM TẮT VĂN BẢN HƯỚNG TRUY VẤN \n\n3.1. Định nghĩa \n\nTheo định nghĩa ở trên, tóm tắt văn bản hướng truy vấn là một dạng tóm tắt văn \n\nbản (khi phân chia theo mục đích tóm tắt), điểm đặc trưng là ở giai đoạn tiền xử lý, \n\nviệc tính toán sẽ phụ thuộc một phần vào truy vấn người dùng. \n\n3.2. Ứng dụng của bài toán \n\nTóm tắt hướng truy vấn thường sử dụng trong việc tóm tắt kết quả trả về của máy \n\ntìm kiếm thông tin, hoặc trong các hệ thống hỏi đáp tự động. \n\nHiện nay, đối với máy tìm kiếm, hệ thống sẽ tóm tắt văn bản theo tóm tắt đơn văn \n\nbản thông thường, lưu vào cơ sở dữ liệu, và thực hiện tìm kiếm trên bản tóm tắt đó \n\nđể giảm thời gian tìm kiếm. Sau khi xác định được văn bản phù hợp, văn bản đó sẽ \n\nđược tóm tắt lại theo truy vấn người dùng để đưa ra hiển thị kèm với kết quả. Đối với \n\nhệ thống hỏi đáp tự động, hệ thống sẽ tiến hành phân loại câu hỏi và thực hiện so \n\nkhớp hoặc tính tương đồng với câu hỏi trong cơ sở dữ liệu để xác định câu trả lời phù \n\nhợp nhất, sau đó tóm tắt văn bản chứa câu trả lời, sử dụng câu trả lời như truy vấn, \n\nvà hiển thị kèm với câu trả lời, có đánh dấu câu trả lời. \n\nTóm lại, tóm tắt hướng truy vấn thường được tích hợp ở giai đoạn xử lý kết quả \n\ncủa hệ thống tìm kiếm thông tin và hỏi đáp tự động, mục đích là thêm thông tin để \n\nkết quả rõ ràng và dễ hiểu hơn với người dùng \n\n3.3. Một số hướng tiếp cận phổ biến \n\n3.3.1. Dựa trên đồ thị \n\nPhương pháp này được đưa ra bởi [3] Jagadeesh và đồng sự, áp dụng cho tóm tắt \n\ntrích rút đa văn bản. Đồ thị của văn bản sẽ được xây dựng dựa trên việc phân tích các \n\ncâu trong đó để tìm ra các cụm danh từ(noun phrases), sau đó phân tích các cụm danh \n\ntừ này để tìm ra mối quan hệ giữa các danh từ sử dụng các hàm heuristic. Đồ thị thu \n\nđược sẽ bao gồm 2 dạng nút, nút thành phần(là các danh từ trích rút từ văn bản) và \n\nnút liên kết, có 2 loại nút liên kết là isa(là một) và related_to(liên quan với). \n\nSau khi xây dựng đồ thị cho mỗi câu, chúng sẽ được kết hợp để tạo đồ thị cho \n\ntoàn văn bản. Một thuật toán tìm kiếm sẽ được sử dụng để tìm các câu quan trọng đưa \n\nvào tóm tắt. Có 3 giải thuật có thể áp dụng: \n\n- Dựa trên tâm các đồ thị: một đồ thị trung tâm cho tất cả văn bản được xây \n\ndựng, tích hợp thêm đồ thị của truy vấn. Sau đó các câu có đồ thị tương \n\nđồng với tâm lớn nhất sẽ được chọn \n\n- Dựa trên đồ thị truy vấn: các câu có đồ thị tương đồng với đồ thị truy vấn \n\nlớn nhất sẽ được chọn \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 25 \n\n   \n\n- Dựa trên việc kết hợp câu đã chọn: giống bước trên nhưng sau khi chọn \n\nđược mỗi câu thì kết hợp câu đó vào tâm tạo thành tâm mới \n\nPhương pháp này cho kết quả tương đối chính xác nhưng phụ thuộc chủ yếu vào \n\ngiải đoạn phân tích cú pháp để tìm các cụm danh từ, do đó cần bộ phân tích cú pháp \n\nchính xác. \n\n3.3.2. Dựa trên cấu trúc diễn ngôn \n\nPhương pháp này được trình bày bởi W. Bosma [4], mục đích là tạo ra bản tóm \n\ntắt ngắn gọn chứa câu trả lời để đưa ra kết quả trong hệ thống hỏi đáp tự động. Trong \n\nđó mỗi văn bản được biểu diễn bởi đồ thị có trọng số dựa trên lý thuyết diễn ngôn, \n\nmỗi đỉnh đại diện cho một câu, trọng số trên mỗi cạnh là khoảng cách giữa hai câu. \n\nMột thuật toán tìm kiếm đồ thị sẽ được sử dụng để chọn ra các câu có tổng trọng số \n\ntrên đường đi tới câu trả lời(vai trò như truy vấn) nhỏ nhất. \n\n3.3.3. Dựa trên tần số từ và độ tương đồng câu \n\nPhương pháp này trình bày bởi Siva kumar và đồng sự [5] áp dụng cho tóm tắt \n\ntrích rút đa văn bản. Trước tiên các văn bản sẽ được biểu diễn trong mô hình không \n\ngian vector, mỗi câu được tính khoảng cách với câu truy vấn, sau đó sử dụng thuật \n\ntoán phân cụm, chia các câu vào các cụm. Mỗi câu được tính điểm số vị trí và điểm \n\nsố độ quan trọng trong cụm, sau đó từ các cụm có điểm số cao nhất, trích rút ra các \n\ncâu có điểm số cao nhất tạo thành tóm tắt. \n\n3.4. Đề xuất hướng giải quyết cho tiếng Việt \n\nQua tìm hiểu về các vấn đề liên quan trong tóm tắt và đặc trưng của tiếng Việt, \n\ndễ nhận thấy rằng việc tiếp cận ở mức cú pháp và ngữ nghĩa là khá khó khăn, một \n\nphần là vì công cụ và dữ liệu hỗ trợ, tuy đã có một số công cụ gán nhãn từ vựng và \n\nphân tích cú pháp cho độ chính xác cao nhưng thường chỉ áp dụng cho lĩnh vực hẹp, \n\nvà còn ở mức nghiên cứu, chưa được công bố chính thức. Mặt khác, do đặc trưng về \n\nngữ pháp nên các hướng tiếp cận đó thường không chính xác với tiếng Việt. \n\nDo đó em xin đề xuất mô hình trích rút các câu quan trọng cho bài toán tóm tắt \n\nhướng truy vấn dựa trên tần số từ và độ tương đồng câu, áp dụng cho tóm tắt đơn \n\nvăn bản. Mô tả sơ lược như sau: Đầu tiên sử dụng câu truy vấn làm tâm tóm tắt, sau \n\nđó tìm câu có độ tương đồng với tâm lớn nhất, mỗi câu được chọn sẽ kết hợp với tâm \n\ntạo nên tâm mới. Sau khi kết thúc sẽ loại bỏ câu truy vấn khỏi kết quả. Phương pháp \n\nnày dựa theo ý tưởng ở giải thuật thứ 2 trong hướng tiếp cận dựa trên đồ thị đã nêu ở \n\ntrên, nhưng các câu ở đây biểu diễn theo mô hình không gian vector và độ tương đồng \n\nsử dụng độ đo cosin. \n\nPhạm vi ứng dụng hướng tới của mô hình là tích hợp vào modul trả kết quả của \n\nbộ máy tìm kiếm văn bản(search engine), thực hiện tóm tắt văn bản kết quả theo tập \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 26 \n\n   \n\ntừ khóa đã tìm kiếm(chính là truy vấn người dùng). Do đó có một số ràng buộc với \n\ndữ liệu đầu vào. \n\nVì văn bản đã được máy tìm kiếm lựa chọn nên nội dung của văn bản và truy vấn \n\nsẽ liên quan với nhau. Do đó các câu chứa nhiều từ khóa trong truy vấn, hay trong \n\ntrường hợp này là độ tương đồng lớn, sẽ mang các thông tin quan trọng liên quan đến \n\ntruy vấn mà người dùng quan tâm. Tuy nhiên trong vấn đề tìm kiếm, phần lớn người \n\ndùng thường không nắm rõ được nội dung mình muốn biết nên mới sử dụng tìm kiếm, \n\nmà chỉ biết các từ khóa liên quan tới vấn đề đó. Ví dụ như tìm kiếm thông tin về giá \n\nvàng, người ta không biết giá vàng tăng hay giảm, có biến động gì gần đây. Hoặc tìm \n\ncách sửa một lỗi máy tính thì người dùng sẽ đưa ra các thông tin về lỗi đó, sau khi \n\nxem bản tóm tắt của các kết quả từ máy tìm kiếm, sẽ biết được kết quả nào phù hợp \n\nđể quyết định đọc hay không. \n\nTrong giải thuật chọn câu, các câu được chọn sẽ được thêm vào truy vấn, với mục \n\nđích làm thêm từ khóa liên quan đến truy vấn. Nhưng không phải từ nào trong các \n\ncâu đó cũng đều quan trọng nên các từ xuất hiện trong truy vấn gốc được nhân lên \n\nmột trọng số α. Do đó kết quả tóm tắt sẽ ưu tiên các từ khóa trong truy vấn, và các từ \n\nkhóa xuất hiện nhiều trong các câu được chọn. Theo đó thì bản tóm tắt sẽ dễ hiểu hơn \n\nvì bao gồm các thông tin liên quan tới truy vấn. \n\nTổng quan về modul đó như sau: \n\n Đầu vào \n\n- Văn bản: văn bản đầu vào sử dụng bộ mã Unicode utf-8, chỉ chứa text, chính \n\nxác về chính tả, dấu câu, không quá ngắn(5 câu trở lên), nội dung phải liên \n\nquan tới truy vấn. \n\n- Truy vấn: sử dụng bộ mã như văn bản, là một đoạn văn bản chứa các từ khóa \n\ncần tìm kiếm, nếu cần chính xác thì dùng dấu phảy để ngăn cách các từ khóa \n\n- Độ rút gọn: có thể là số lượng từ (100-150 từ) hoặc phần trăm văn bản nguồn \n\n(10-20%). \n\n Thực hiện tóm tắt \n\nBước này áp dụng mô hình tóm tắt đã đề xuất để tạo kết quả \n\n- Chuẩn hóa: bước này sẽ thực hiện xử lý tiêu đề, các đoạn văn trong ngoặc đơn  \n\n- Tách câu, tách từ: thực hiện tách câu, tách từ sử dụng công cụ VNTokenizer \n\n- Loại bỏ từ dừng: tìm kiếm và loại bỏ các từ dừng dựa trên danh sách có sẵn \n\n- Xử lý từ đồng nghĩa: đồng bộ các từ đồng nghĩa về cùng 1 dạng  \n\n- Mô hình hóa văn bản: tính TF.IDF và chuyển các câu về dạng vector \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 27 \n\n   \n\n- Trích rút câu, tạo tóm tắt: đây là giải thuật đã đề xuất, thực hiện tính toán độ \n\ntương đồng sử dụng độ đo cosin và một số phép toán trên vector để tìm kiếm \n\ncác câu phù hợp đưa vào kết quả tóm tắt, và được ghép lại theo phương pháp \n\nhiển thị phân đoạn. \n\n Đầu ra: văn bản tóm tắt \n\n Chi tiết các kỹ thuật sử dụng trong các bước sẽ trình bày ở phần sau. \n\n  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 28 \n\n   \n\nPHẦN 2. GIẢI QUYẾT VẤN ĐỀ \n\nI.  PHÂN TÍCH MÔ HÌNH THỰC HIỆN BÀI TOÁN \n\nDựa vào các kiến thức về tóm tắt văn bản đã trình bày ở trên, trong phần này em \n\nsẽ trình bày chi tiết các kỹ thuật áp dụng trong từng bước của mô hình xử lý đã đề \n\nxuất. \n\n \n\nHình 3: Mô hình tóm tắt văn bản hướng truy vấn \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 29 \n\n   \n\n1.1. Giai đoạn phân tích \n\n1.1.1. Chuẩn hóa \n\n Xử lý câu tiêu đề \n\nCâu tiêu đề của một văn bản (nếu có) thường mang nội dung chính trình bày trong \n\nvăn bản, do đó các từ khóa trong đó cũng được dùng để phát hiện tóm tắt (một số giải \n\nthuật còn tăng trọng số cho những từ xuất hiện trong tiêu đề), nhưng không đưa câu \n\ntiêu đề vào kết quả tóm tắt, nên cần phát hiện để loại bỏ khỏi kết quả. Việc phát hiện \n\ncâu tiêu đề có thể dựa vào dấu hiệu “câu tiêu đề là câu duy nhất của đoạn đầu tiên”. \n\nTrong giải thuật này chỉ sử dụng câu tiêu đề như câu thông thường, sau đó loại khỏi \n\nkết quả (nếu nó được chọn vào kết quả). \n\n Xử lý các cụm từ trong ngoặc \n\nCác cụm từ trong ngoặc có thể là chú thích hoặc viết tắt của cụm từ nào đó, nếu \n\nlà chú thích thì có thể bỏ qua còn từ viết tắt thì khá quan trọng, nhất là đối với tóm \n\ntắt hướng truy vấn. \n\nVí dụ: Sinh viên tình nguyện(SVTN) đi đến các vùng sâu để giúp đỡ đồng bào \n\nCác câu sau câu này sẽ sử dụng cụm từ SVTN, nếu truy vấn có từ khóa “sinh viên \n\ntình nguyện” thì các câu sử dụng từ viết tắt sẽ không được quan tâm. \n\nViệc xử lý từ viết tắt không đơn giản là phát hiện các từ trong ngoặc, tùy từng \n\nloại văn bản của chuyên ngành nào đó, các từ viết tắt vẫn được sử dụng mà không \n\ngây hiểu lầm cho người đọc, vì trong các lĩnh vực ấy nó chỉ có thể thay thế cho cụm \n\ntừ cố định nào đó, hoặc do thói quen, sử dụng nhiều thì mọi người đều biết. \n\nVí dụ: UBND thường được dùng thay thế cho “Ủy ban nhân dân” \n\nTrong giải thuật này chỉ xử lý các cụm từ viết tắt chữ đầu trong ngoặc đơn, còn \n\ncác trường hợp khác do chưa xây dựng được bộ dữ liệu cụ thể nên không xét đến. \n\nCác cụm từ trong ngoặc đơn khác sẽ bị xóa đi. \n\n1.1.2. Tách câu, tách từ \n\nTrong tiếng Việt, dấu cách (space) không được sử dụng như 1 kí hiệu phân tách \n\ntừ, nó chỉ có ý nghĩa phân tách các âm tiết với nhau, có khoảng 70% các từ gồm 2 âm \n\ntiết, và 14% các từ gồm 3 âm tiết, còn lại là 1 âm tiết. Hơn nữa, việc kết hợp các âm \n\ntiết có nhiều cách, mỗi cách cho một nghĩa khác nhau. Vì thế, để xử lý tiếng Việt, bài \n\ntoán tách từ (word segmentation) là 1 trong những bài toán cơ bản và quan trọng bậc \n\nnhất. Ngoài tiếng Việt, có khá nhiều các ngôn ngữ châu Á khác cũng cần bước tách \n\ntừ, ví dụ như: tiếng Nhật, tiếng Trung, tiếng Hàn,… do đó vấn đề này nhận được sự \n\nquan tâm rộng rãi và có nhiều hướng tiếp cận khác nhau. \n\nMột số phương pháp có thể áp dụng: \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 30 \n\n   \n\no So khớp từ dài nhất (Longest Matching) \n\no So khớp cực đại (Maximum Matching) \n\no Mô hình Markov ẩn (Hidden Markov Models- HMM) \n\no Học dựa trên sự cải biến (Transformation-based Learning – TBL) \n\no Chuyển đổi trạng thái trọng số hữu hạn(Weighted Finite State Transducer) \n\no Độ hỗn loạn cực đại (Maximum Entropy – ME) \n\no Máy học sử dụng vectơ hỗ trợ (Support Vector Machines) \n\no Trường xác xuất có điều kiện (CRFs) \n\nBài toán tách từ khá phức tạp, do đó việc tách từ trong bước này sẽ sử dụng công \n\ncụ VNTokenizer, được phát triển bởi nhóm tác giả Lê Hồng Phương. \n\nĐây là công cụ tách từ tự động cho tiếng Việt, mã nguồn mở, được viết bằng ngôn \n\nngữ Java. Phiên bản cũ nhất là phiên bản vnTokenizer 2.0 được xây dựng vào năm \n\n2005 khi đó nó mới là một ứng dụng đơn với giao diện đơn giản. Để sử dụng trong \n\nchương trình lần này, phiên bản mới nhất 4.1.1c, mã nguồn của công cụ được tải tại \n\nwebsite của dự án VLSP [6]. \n\nCông cụ này được xây dựng sử dụng kết hợp từ điển (từ điển tiếng Việt được lấy \n\ntừ đề tài VLSP) và ngram, trong đó mô hình ngram được huấn luyện sử dụng treebank \n\ntiếng Việt (70,000 câu đã được tách từ), treebank là kho ngữ liệu câu được chú giải \n\nngữ pháp. \n\nVới độ chính xác xấp xỉ 97% (theo thống kê của tác giả trên website) là kết quả \n\nrất cao so với công cụ tách từ hiện nay. \n\nNgoài ra việc tách câu khá đơn giản nhưng cần xử lý các trường hợp nhập nhằng \n\ndấu chấm câu và dấu chấm trong từ(trong email, số thập phân, địa chỉ web). Do đó \n\nđể tiết kiệm thời gian, việc tách câu trong phần này sử dụng luôn modul tách câu \n\ntrong công cụ VNTokenizer. \n\n1.1.3. Loại bỏ từ dừng \n\nTừ dừng (StopWord) là những từ thường xuất hiện nhiều trong các tài liệu nhưng \n\nthường chỉ mang ý nhấn mạnh, bổ nghĩa… nó có ý nghĩa lớn trong một số phương \n\npháp dựa trên dấu hiệu đặc biệt, nhưng trong phương pháp dựa trên tần số từ đang \n\nxét thì các từ này làm giảm độ chính xác. Trong giải thuật này chủ yếu dựa trên trọng \n\nsố từ nên việc loại bỏ từ dừng là rất cần thiết. \n\nTừ dừng sẽ được loại bỏ nhờ một danh sách từ dừng xây dựng sẵn, tham khảo tại \n\n[7], sau khi tách từ, các từ xuất hiện trong từ điển từ dừng sẽ bị xóa. Dưới đây là một \n\nsố từ dừng trích trong file sẽ sử dụng. \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 31 \n\n   \n\nthậm chí vì vậy tuy nhiên \n\nthật ra với lại thế là \n\ntrước kia đáng lẽ sau cùng \n\ntuy vậy ắt hẳn quả thật \n\nBảng 1: Ví dụ một số từ dừng \n\nNgoài ra ở bước này, các dấu câu, dấu phảy cũng bị xóa vì nó cũng giống từ dừng. \n\n1.1.4. Xử lý từ đồng nghĩa \n\nCó 3 loại từ đồng nghĩa cần xét đến: \n\n Từ có nghĩa giống nhau hoặc gần giống nhau. \n\nVí dụ: siêng năng, chăm chỉ, cần cù, … \n\n Từ đồng nghĩa hoàn toàn \n\nVí dụ: hổ, cọp, hùm, … \n\n Từ đồng nghĩa không hoàn toàn \n\nVí dụ:  \n\nĂn, xơi, chén, …(biểu thị thái độ, tình cảm khác nhau đối với người đối \n\nthoại hoặc điều được nói đến). \n\nMang, khiêng, vác, …(biểu thị những cách thức hành động khác nhau). \n\nVới loại 1 và loại 2 thì các từ đồng nghĩa có thể thay thế cho nhau. Còn loại 3 thì \n\nphải xét đến ngữ nghĩa của từ trong ngữ cảnh của văn bản, đây có thể coi là bài toán \n\nphức tạp nhất trong xử lý ngôn ngữ, hiện nay chưa có nhiều nghiên cứu. \n\nViệc xử lý từ đồng nghĩa là rất quan trọng, nhất là trong bài toán tóm tắt hướng \n\ntruy vấn. Trong mô hình lần này, do chỉ xử lý ở mức nông, nên không xét đến các \n\nvấn đề ở mức cú pháp và ngữ nghĩa, nhưng để tăng độ chính xác, bài toán sẽ sử dụng \n\nviệc đồng nhất các từ đồng nghĩa(xử lý chung cho cả 3 loại trên) dựa trên từ điển \n\nđồng nghĩa thô xây dựng sẵn, bộ từ điển này gồm gần 2800 mục, xây dựng bằng cách \n\ndùng công cụ tải các trang của từ điển Việt – Việt tại trang tratu.soha.vn, sau đó tách \n\nthẻ có chứa các từ đồng nghĩa rồi ghép lại. Mỗi mục gồm các từ gần nghĩa hoặc đồng \n\nnghĩa với nhau về mặt nào đó, và mỗi từ chỉ xuất hiện trong một mục, trên thực tế có \n\nnhững từ có thể ở nhiều mục, nhưng số lượng các từ đó không nhiều nên trong bộ từ \n\nđiển này sẽ sử dụng nghĩa phổ biến nhất của các từ đó. Tuy chưa được đầy đủ và xử \n\nlý đơn giản nhưng cũng góp phần tăng độ chính xác cho việc tóm tắt. Dưới đây là \n\nmột số mục từ trong bộ từ đồng nghĩa sẽ sử dụng. \n\n \n\nhttp://tratu.soha.vn/\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 32 \n\n   \n\nlãnh thổ, bờ cõi, biên thuỳ, biên giới,biên cương \n\nrỗi rãi, rỗi, rảnh rỗi, rảnh rang, rảnh \n\nthương nhân, nhà buôn, thương gia, doanh nhân, doanh gia \n\nquả cảm, gan góc, dũng cảm, gan dạ, dũng mãnh, can đảm, anh dũng \n\ntả, mô tả, miêu tả, diễn tả, diễn đạt, biểu đạt \n\nBảng 2: Một số mục từ đồng nghĩa \n\nSau bước tách từ và loại bỏ từ dừng, các câu sẽ được xử lý theo theo cách duyệt \n\ntất cả các từ, với mỗi từ, tìm từ đó trong từ điển đồng nghĩa, nếu có thì thực hiện thay \n\nthế từ đó bằng từ đầu tiên trong mục từ chứa nó. \n\n1.1.5. Mô hình hóa văn bản \n\nViệc cuối cùng trong giai đoạn tiền xử lý là mô hình hóa văn bản, sử dụng mô \n\nhình không gian vector. Tương tự các công thức dùng để mô hình hóa văn bản ở trên, \n\nđể mô hình hóa câu, ta sử dụng công thức sau TF.ISF, công thức này tương tự như \n\nTF.IDF nhưng các thông số ở trong phạm vi câu và văn bản. Cụ thể mỗi từ tần số của \n\nmỗi từ wi trong câu sj  được tính như sau: \n\n \n\nTrong đó: \n\nfij là số lần xuất hiện của từ ti trong câu sj, \n\nm là tổng số câu trong văn bản \n\nhi là tổng số câu mà từ ti xuất hiện. \n\nα là hệ số đánh giá độ quan trọng của từ, nếu từ xuất hiện trong truy \n\nvấn thì α>1, còn lại thì α=1 \n\nVới hệ số α cho từ xuất hiện trong truy vấn, trong quá trình kiểm thử trên tập mẫu \n\nthì α=4  cho kết quả tốt nhất. \n\n1.1.6. Chọn câu phù hợp tạo tóm tắt \n\nBước này sẽ áp dụng các giải thuật đánh giá câu quan trọng để đưa vào kết quả \n\ntóm tắt. Để hạn chế hiện tượng trùng lặp thông tin trong kết quả tóm tắt, trước khi \n\nđưa vào lựa chọn, các câu sẽ được so sánh với nhau để tìm các câu gần tương tự nhau, \n\nvà loại bỏ câu có vị trí xa tiêu đề hơn. Độ đo sử dụng để loại bỏ câu trùng lặp và chọn \n\ncâu phù hợp tạo tóm tắt là độ đo cosin đã trình bày ở trên, nhưng hai vector được tính \n\ntoán bây giờ là biểu diễn cho hai câu. \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 33 \n\n   \n\nGiải thuật loại bỏ câu trùng lặp như sau: \n\nBước 1: xét câu si, tính độ tương đồng với các câu sau nó sj \n\nBước 2: với mỗi câu sj, nếu độ tương đồng Ωij>α thì loại bỏ câu sj \n\nBước 3: nếu hết văn bản thì dừng lại, không thì tăng i lên 1 và quay lại bước 1 \n\nQua thực nghiệm trên một số văn bản, cho thấy ngưỡng α=0.8 cho kết quả tương \n\nđối chính xác. Do đó trong bước này sẽ thực hiện loại bỏ một câu nếu có độ tương tự \n\nlớn hơn 0.8 với câu nào đó đứng trước nó, theo thứ tự vị trí trong văn bản. \n\nQuá trình chọn câu quan trọng sẽ thực hiện như hình dưới đây \n\n \n\nHình 4: Minh họa quá trình chọn câu quan trọng \n\nSau khi chuyển biểu diễn các câu về mô hình không gian vector, mỗi câu sẽ là \n\nmột vector, văn bản là danh sách các vector, độ tương đồng giữa các câu sẽ được tính \n\ntoán sử dụng độ đo cosin.  \n\nGiải thuật chọn câu theo các bước sau: \n\nBước 1: khởi tạo tâm là truy vấn \n\nBước 2: tính độ tương đồng Ω của các câu trong văn bản với tâm \n\nBước 3: chọn câu có Ω lớn nhất, kết hợp vào tâm, xóa câu đó khỏi văn bản \n\nBước 4: kiểm tra độ dài, nếu chưa đủ, tính toán lại tâm và quay lại bước 2 \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 34 \n\n   \n\nTâm của tóm tắt sẽ được tính toán lại dựa trên công thức tính vector trọng tâm \n\ncủa nhóm, và độ tương tự của 1 câu với tâm sẽ là độ tương tự với vector đó. \n\n*) Véc tơ trọng tâm của nhóm \n\nGiả sử có một tập câu = {s1, s2, …, sm} có lần lượt các véc tơ biểu diễn là v1, v2, \n\n…, vm. Khi đó, véc tơ trọng tâm của tập câu được tính theo công thức: \n\n1\n\nm\n\ni\n\ni\ncen\n\nv\n\nV\nm\n\n\n\n\n \n\n \n\n1.2. Giai đoạn hiển thị \n\nỞ bước này, văn bản tóm tắt sẽ được tạo ra bằng cách ghép các câu được chọn \n\ntheo thứ tự trong văn bản, đó chính là phương pháp hiển thị phân đoạn. \n\n  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 35 \n\n   \n\nII. CÀI ĐẶT THỬ NGHIỆM \n\n2.1. Chương trình thử nghiệm \n\nĐể thực hiện thử nghiệm em đã xây dựng một số công cụ phục vụ tóm tắt 1 văn \n\nbản, công cụ tạo mẫu và công cụ kiểm thử trên mẫu: \n\n- Môi trường cài đặt: Java JDK 7u17, Windows 7 32bit. \n\n- Công cụ lập trình Netbeans 7.3. \n\n2.1.1. Các công cụ đã xây dựng \n\n2.1.1.1. Chương trình tóm tắt \n\nĐây là chương trình thực hiện tóm tắt một văn bản dựa trên giải thuật đã phân \n\ntích ở trên. Chi tiết các chức năng đã ghi chú đầy đủ trên ảnh giao diện chương trình. \n\nĐầu vào của chương trình là văn bản gốc, truy vấn, và độ rút gọn, đầu ra sẽ là văn \n\nbản tóm tắt, có thể xem chi tiết một số bước xử lý ở chức năng Note góc dưới trái \n\ngiao diện. \n\n \n\nHình 5: Giao diện chương trình demo \n\n2.1.1.2. Công cụ tạo tập mẫu \n\nCông cụ này hỗ trợ, tạo, chỉnh sửa các bản tóm tắt thủ công. Chức năng chính là \n\nquản lý các văn bản mẫu bao gồm văn bản gốc và bản tóm tắt thủ công, được tích \n\nhợp chức năng tách từ, tách câu của VNTokenizer nên việc tạo văn bản mẫu sẽ chính \n\nxác và hiệu quả hơn. Ngoài ra còn có chức năng phát hiện ra các văn bản lỗi font, các \n\nvăn bản này không thể sử dụng trong các công cụ đi kèm nên cần loại bỏ. \n\n \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 36 \n\n   \n\n \n\nHình 6: Chương trình quản lý tập mẫu \n\n2.1.1.3. Công cụ kiểm thử \n\nCông cụ này được xây dựng dựa trên việc tích hợp giải thuật đã đề xuất ở trên và \n\ntích hợp thêm hai giải thuật để so sánh, việc so sánh dựa trên độ đo BLEUS, chi tiết \n\nvề cách thực hiện sẽ trình bày ở phần sau. \n\n \n\nHình 7: Giao diện chương trình kiểm thử \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 37 \n\n   \n\n2.2. Thử nghiệm một văn bản \n\nPhần này em sử dụng công cụ tóm tắt đã xây dựng để thử nghiệm một văn bản. \n\nKết quả thực hiện thu được như sau: \n\n2.2.1. Đầu vào \n\n Văn bản: \n\nBảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình{1} \n\nChiều ngày 26-4, Chủ tịch nước Trương Tấn Sang và Tổ Đại biểu Quốc hội \n\n(ĐBQH) số 1, Đoàn ĐBQH TP Hồ Chí Minh tiếp tục có buổi tiếp xúc với gần 400 cử \n\ntri của quận 1{2}. Ghi nhận các ý kiến của cử tri, Chủ tịch nước đánh giá cao tinh \n\nthần đóng góp ý kiến của mọi người, nhất là vấn đề sửa đổi Hiến Pháp và các đạo \n\nluật{3}. Trả lời câu hỏi được đông đảo cử tri quan tâm về chủ trương bảo vệ chủ \n\nquyền lãnh thổ, củng cố quốc phòng - an ninh, Chủ tịch nước Trương Tấn Sang khẳng \n\nđịnh chủ trương của Đảng, Nhà nước trước sau như một là kiên quyết bảo vệ vững \n\nchắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình, theo hệ thống luật pháp \n\nquốc tế{4}. Tuy nhiên, Chủ tịch nước cũng khẳng định “không bao giờ bảo vệ chủ \n\nquyền bằng nói miệng”; chủ trương hòa hiếu không có nghĩa là không làm gì{5}. \n\nNước ta cũng mua sắm trang bị vũ khí, nhưng không phải để gây chiến tranh, chạy \n\nđua vũ trang mà là tăng cường phòng thủ, bảo vệ chủ quyền lãnh thổ{6}. Chủ tịch \n\nnước cho biết, chủ trương hòa hiếu luôn được các nước bạn bè trên thế giới ủng \n\nhộ{7}. \n\nĐề cập đến tình hình biển, đảo, Chủ tịch nước bày tỏ thông cảm với những lo \n\nlắng, bức xúc của cử tri, mong cử tri phải bình tĩnh, không nghe những lời kích động \n\ncủa kẻ xấu{8}. Những mâu thuẫn trên Biển Đông là có, nhưng biện pháp hòa hiếu \n\ncủa nước ta đã có kết quả tốt, Nhà nước luôn hỗ trợ ngư dân ra khơi, số lượng tàu \n\ncá đánh bắt xa bờ ngày càng tăng{9}. Nước ta phấn đấu đến năm 2020 sẽ phát triển \n\nkinh tế biển đạt 52%-53% GDP, trong đó, dầu khí, vận tải biển, đánh bắt hải sản là \n\nthế mạnh lớn{10}. Mục tiêu cuối cùng của nước ta là chủ quyền lãnh thổ vững chắc, \n\nquốc phòng - an ninh ổn định, kinh tế phát triển{11}. \n\nLiên quan đến các vấn đề kinh tế - xã hội, Chủ tịch nước Trương Tấn Sang cho \n\nbiết kinh tế nước nhà có những phát triển đáng kể, nông nghiệp đạt nhiều thắng lợi, \n\ncác ngành thuộc về dầu khí tăng trưởng khá{12}. Tuy nhiên, Chủ tịch nước mong cử \n\ntri hiểu kinh tế Việt Nam dùng chủ yếu là tiền mặt, nên sẽ có những hệ quả về giá cả \n\nthị trường, thu nhập người dân liên quan đến việc tăng lương, tăng giảm giá vàng, \n\ngiá xăng, dầu{13}. \n\nTổng số 259 từ / 13 câu \n\n Câu truy vấn: bảo vệ chủ quyền lãnh thổ \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 38 \n\n   \n\n Độ rút gọn: 100 từ \n\n2.2.2. Kết quả tóm tắt \n\nKết quả được chọn theo thứ tự 4, 11, 6, 5, 7, 9 tổng số 111 từ / 6 câu \n\n{4} Trả lời câu hỏi được đông đảo cử tri quan tâm về chủ trương bảo vệ chủ \n\nquyền lãnh thổ, củng cố quốc phòng - an ninh, Chủ tịch nước Trương Tấn Sang khẳng \n\nđịnh chủ trương của Đảng, Nhà nước trước sau như một là kiên quyết bảo vệ vững \n\nchắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình, theo hệ thống luật pháp \n\nquốc tế. \n\n{5} Tuy nhiên, Chủ tịch nước cũng khẳng định “không bao giờ bảo vệ chủ quyền \n\nbằng nói miệng”; chủ trương hòa hiếu không có nghĩa là không làm gì. \n\n{6} Nước ta cũng mua sắm trang bị vũ khí, nhưng không phải để gây chiến tranh, \n\nchạy đua vũ trang mà là tăng cường phòng thủ, bảo vệ chủ quyền lãnh thổ. \n\n{7} Chủ tịch nước cho biết, chủ trương hòa hiếu luôn được các nước bạn bè trên \n\nthế giới ủng hộ. \n\n{9} Những mâu thuẫn trên Biển Đông là có, nhưng biện pháp hòa hiếu của nước \n\nta đã có kết quả tốt, Nhà nước luôn hỗ trợ ngư dân ra khơi, số lượng tàu cá đánh bắt \n\nxa bờ ngày càng tăng. \n\n{11} Mục tiêu cuối cùng của nước ta là chủ quyền lãnh thổ vững chắc, quốc phòng \n\n- an ninh ổn định, kinh tế phát triển. \n\n2.2.3. Nhận xét \n\nSau khi chạy thử nghiệm trên một số văn bản, em nhận thấy kết quả tóm tắt khá \n\nchính xác, đã nêu lên được các vấn đề liên quan tới truy vấn mà trong văn bản trình \n\nbày. Để đánh giá chất lượng thực sự của mô hình, trong phần sau sẽ thực hiện kiểm \n\nthử trên lượng dữ liệu đủ lớn. \n\n2.3. Thử nghiệm trên tập mẫu \n\n2.3.1. Dữ liệu thử nghiệm \n\nCác mẫu trong thử nghiệm lần này được tạo ra bằng cách sử dụng công cụ hỗ trợ \n\nđã nêu ở trên với văn bản mẫu là các bài báo trên các báo điện tử: \n\no http://vnexpress.net/ \n\no http://laodong.com.vn/ \n\no http://dantri.com.vn/ \n\nCác bài báo sử dụng được lấy từ các chuyên mục: Văn hóa, Xã hội, Chính trị, \n\nPháp luật, Kinh tế. \n\nhttp://vnexpress.net/\nhttp://laodong.com.vn/\nhttp://dantri.com.vn/\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 39 \n\n   \n\nĐộ dài mỗi bản tóm tắt thủ công là xấp xỉ 120 từ. Bảng mã Unicode utf-8, định \n\ndạng .txt, số lượng 50 mẫu. \n\nThông tin độ dài của tập mẫu được trình bày ở bảng dưới đây: \n\n Lớn nhất Nhỏ nhất Trung bình \n\nĐộ dài văn bản theo từ (đã loại bỏ từ dừng) 823 180 371 \n\nĐộ dài văn bản theo câu 35 9 18 \n\nBảng 3: Thông tin tập mẫu sử dụng để đánh giá \n\n2.3.2. Độ đo BLEUS \n\nĐộ đo sẽ sử dụng trong phần đánh giá này là BLEUS, cải tiến của độ đo BLEU, \n\nsử dụng cho n-gram của từ. \n\n N-gram \n\nN-gram của từ là chuỗi gồm n từ, tập các n-gram của một văn bản được tạo nên \n\nbằng cách ghép n từ liên tiếp cho tới khi hết văn bản. \n\nN-gram Hôm_nay trời mưa to \n\nUnigram(1-gram) Hôm_nay, trời, mưa, to \n\nBigram(2-gram) Hôm_nay trời, trời mưa, mưa to \n\nTrigram(3-gram) Hôm_nay trời mưa, trời mưa to \n\nFourgram(4-gram) Hôm_nay trời mưa to \n\nBảng 4: Ví dụ về n-gram \n\n Độ đo BLEUS \n\nBLEU là độ đo dựa trên sự đồng hiện của các n-gram, bao gồm 1-gram, 2-gram, \n\n3-gram, 4-gram. \n\nCông thức của độ đo này như sau: \n\n \n\nTrong đó: \n\nD1 là bản tóm tắt tự động(do chương trình tạo ra) \n\nD2 là bản tóm tắt thủ công \n\nXk là số k-gram trùng nhau ở hai văn bản \n\nYk là số k-gram trong văn bản D1 \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 40 \n\n   \n\nβ là điểm phạt, được tính như sau: \n\n \n\n với a là số 1-gram trong D2, b là số 1-gram trong D1 \n\nNhược điểm của độ đo BLEU là sẽ trả về 0 nếu như hai văn bản không có 4-gram \n\nnào trùng nhau, do đó ta sẽ sử dụng một dạng khác của BLEU đó là BLEUS \n\n[11](Smooth BLEU). Độ đo này khắc phục nhược điểm của độ đo BLEU bằng cách \n\nthay Xk  = 0 thành 2-n, cụ thể như sau:  \n\n- Nếu k=2 thì X2=1/2, X3=1/4, X4=1/8  \n\n- Nếu k=3 thì X3=1/2, X4=1/4 \n\n- Nếu k=4 thì X4=1/2 \n\n2.3.3. Kết quả thử nghiệm \n\nĐể tính toán kết quả, mỗi mẫu sẽ được thực hiện để tạo bản tóm tắt và thực hiện \n\ntính điểm BLEUS, chi tiết như sau: \n\nBước 1: Tải văn bản gốc và văn bản tóm tắt tương ứng, tách tiêu đề của văn bản \n\ngốc làm truy vấn. \n\nBước 2: Gọi modul tóm tắt với đầu vào là văn bản gốc và độ rút gọn 120 từ. \n\nBước 3: Thực hiện tách từ (sử dụng công cụ vntokenizer) cho văn bản tóm tắt thủ \n\ncông và văn bản tóm tắt tự động. \n\nBước 4: Tính điểm số dựa vào độ đo BLEUS cho từng kết quả tóm tắt. \n\nBước 5: Hiển thị kết quả lên giao diện. \n\nSau khi thực hiện giải thuật đánh giá, kết quả thống kê thu được như sau: \n\n Lớn nhất Nhỏ nhất Trung bình \n\nĐiểm số 0.806 0.254 0.518 \n\nBảng 5: Kết quả kiểm thử độ đo BLEUS của tập mẫu \n\nMột số nhận xét về kết quả kiểm thử: \n\n- Tốc độ thực hiện nhanh (trung bình khoảng 60ms) \n\n- Theo Papineni và đồng sự [9], thì độ đo BLEU từ 0.3 là chấp nhận được, từ \n\n0.5 là tương đối tốt, như vậy thì điểm số trung bình của mẫu là tương đối tốt, \n\nmột số mẫu có điểm số nhỏ nhưng số lượng không đáng kể \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 41 \n\n   \n\n2.3.4. Nhận xét, đánh giá mô hình \n\n- Ưu điểm: tốc độ nhanh, kết quả tóm tắt tương đối tốt, không cần sử dụng dữ \n\nliệu học. \n\n- Nhược điểm: vẫn mang nhược điểm của phương pháp tóm tắt trích rút là đứt \n\nmạch, nhập nhằng tham chiếu \n\n- Khả năng ứng dụng: với tốc độ thực hiện nhanh, cài đặt đơn giản, tuy vẫn có \n\nnhược điểm của tóm tắt trích rút nhưng mô hình này hoàn toàn có thể cài đặt \n\nsử dụng trong thực tế, vì với máy tìm kiếm thì đưa ra thông tin quan trọng hơn \n\nsự liền mạch của văn bản tóm tắt. \n\n \n\n  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 42 \n\n   \n\nPHẦN 3. KẾT LUẬN VÀ ĐỀ XUẤT \n\n1. Các công việc đã thực hiện được \n\nVề cơ bản, đồ án đã thực hiện được các mục tiêu đề ra ban đầu: \n\n- Tìm hiểu về tóm tắt văn bản tự động \n\n- Đề xuất và phân tích các bước thực hiện một mô hình tóm tắt văn bản \n\nhướng truy vấn cho tiếng Việt \n\n- Cài đặt chương trình thử nghiệm và đánh giá kết quả \n\nTuy nhiên, do tài liệu tham khảo chưa nhiều và thời gian có hạn nên vẫn còn một \n\nsố việc chưa thực hiện hoặc chưa tốt: \n\n- Cơ sở lý thuyết trình bày còn sơ sài \n\n- Độ chính xác của dữ liệu thử nghiệm chưa cao và số lượng còn ít dẫn đến \n\nkết quả đánh giá chưa thật chính xác \n\n2. Đề xuất hướng phát triển \n\nNhằm tăng chất lượng của mô hình để đưa vào ứng dụng thực tế, em có một số \n\nđề xuất như sau: \n\n- Xử lý chi tiết các từ viết tắt \n\n- Tích hợp phân giải đồng tham chiếu \n\n- Có một giải thuật xác định từ dừng thay vì dùng danh sách có sẵn \n\n- Xây dựng từ điển đồng nghĩa đầy đủ và chính xác hơn \n\n- Có thêm modul xử lý các bảng mã khác nhau \n\n \n\n  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 43 \n\n   \n\nTÀI LIỆU THAM KHẢO \n\n \n\n Danh sách tài liệu \n\n[3]  Ahmed A. Mohamed; Sanguthevar Rajasekaran, \"Query-Based \n\nSummarization Based on Document Graphs,\" Author, Mansfield, Connecticut, US, \n\n2006. \n\n[4]  Wauter Bosma, \"Query-Based Summarization using Rhetorical Structure \n\nTheory,\" in Human Media Interaction, Enschede The Netherlands, 2003.  \n\n[5]  A. P. Siva kumar ; Dr. P. Premchand; Dr. A. Govardhan, Query-Based \n\nSummarizer Based on Similarity of Sentences and Word Frequency, JNTUACE \n\nAnantapur, India: International Journal of Data Mining & Knowledge Management \n\nProcess, 2011.  \n\n[8]  Chin-Yew Lin and Franz Josef Och, ORANGE: a Method for Evaluating \n\nAutomatic Evaluation Metrics for Machine Translation, Stroudsburg, PA, USA: \n\nAssociation for Computational Linguistics, 2004.  \n\n[9]  Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, \"BLEU: a \n\nMethod for Automatic Evaluation of Machine Translation,\" in 02 Proceedings of \n\nthe 40th Annual Meeting on Association for Computational Linguistics, \n\nStroudsburg, PA, USA, 2002.  \n\n[12]  Lê Quý Tài, \"Nghiên cứu các phương pháp xử lý tiếng Việt ứng dụng cho \n\ntóm tắt văn bản,\" Luận văn thạc sĩ, Hà Nội, 2011. \n\n \n\nDanh sách website \n\n[1]  \"BLEU - Wikipedia,\" Wikipedia, [Online]. Available: \n\nhttp://en.wikipedia.org/wiki/BLEU. [Accessed 10 05 2013]. \n\n[2]  Wikipedia, \"ROUGE Metric,\" Wikipedia, [Online]. Available: \n\nhttp://en.wikipedia.org/wiki/ROUGE_(metric). [Accessed 30 05 2013]. \n\n[6]  \"Xử lý văn bản,\" [Online]. Available: \n\nhttp://vlsp.vietlp.org:8080/demo/?page=resources. [Accessed 09 05 2013]. \n\n[7]  \"KLTN10-wiki,\" [Online]. Available: https://code.google.com/p/kltn10-\n\nwiki/source/browse/. [Accessed 18 5 2013]. \n\n[10]  \"N-Gram Wikipedia,\" [Online]. Available: http://en.wikipedia.org/wiki/N-\n\ngram. [Accessed 09 05 2013]. \n\n[11]  \"KantanMt.com,\" [Online]. Available: \n\nhttp://www.kantanmt.com/whatisbleuscore.php. [Accessed 10 05 2013]. \n\n\n","m":[13608,-1],"n":"9.pdf"}}