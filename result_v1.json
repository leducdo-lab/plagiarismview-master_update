{"highlight":{"page10":{},"page32":{"330":{"boxes":[[119.06,648.19264,204.53000000000003,14.346720000000005],[119.06,672.0726399999999,173.55,14.346720000000005],[119.06,696.0726399999999,343.04,14.346720000000005],[119.06,719.95264,394.04,14.346720000000005],[119.06,743.94864,386.96576000000005,14.346720000000005]],"refs":[[0,289,"Giải thuật chọn câu theo các bước sau: Bước 1: khởi tạo tâm là truy vấn Bước 2: tính độ tương đồng của các câu trong văn bản với tâm Bước 3: chọn câu có lớn nhất, kết hợp vào tâm, xóa câu đó khỏi văn bản Bước 4: kiểm tra độ dài, nếu chưa đủ, tính toán lại tâm và quay lại bước 2 Tâm của tóm tắt sẽ được tính toán lại dựa trên công thức tính vector trọng tâm của nhóm, và độ tương tự của 1 câu với tâm sẽ là độ tương tự với vector đó"]]},"width":595.32,"328":{"boxes":[[175.33520000000001,170.63263999999995,366.5648,14.346720000000005],[99.264,188.51263999999995,382.396,14.346720000000005]],"refs":[[0,287,"Do đó trong bước này sẽ thực hiện loại bỏ một câu nếu có độ tương tự lớn hơn 0.8 với câu nào đó đứng trước nó, theo thứ tự vị trí trong văn bản"]]},"height":841.92},"page11":{},"page33":{"332":{"boxes":[[119.06,98.75263999999996,159.63,14.346720000000005],[119.06,122.75263999999996,422.84,14.347680000000025],[99.264,140.63263999999995,32.66456000000001,14.347680000000025]],"refs":[[0,290,"*) Véc tơ trọng tâm của nhóm Giả sử có một tập câu = {s1, s2, ., sm} có lần lượt các véc tơ biểu diễn là v1, v2, ., vm"]]},"334":{"boxes":[[143.78,248.15263999999993,103.35,14.346719999999976],[119.06,271.82264,422.84,14.346720000000005],[99.264,289.70264,367.156,14.346720000000005]],"refs":[[0,292,"Giai đoạn hiển thị Ở bước này, văn bản tóm tắt sẽ được tạo ra bằng cách ghép các câu được chọn theo thứ tự trong văn bản, đó chính là phương pháp hiển thị phân đoạn"]]},"width":595.32,"height":841.92},"page30":{"310":{"boxes":[[119.06,521.20264,422.82368000000014,14.346720000000005],[99.264,539.20264,43.556,14.346720000000005]],"refs":[[0,271,"Việc xử lý từ đồng nghĩa là rất quan trọng, nhất là trong bài toán tóm tắt hướng truy vấn"]]},"311":{"boxes":[[150.11648,539.20264,391.75231999999994,14.346720000000005],[99.264,557.0826399999999,442.6360000000001,14.346720000000005],[99.264,575.08264,442.63599999999997,14.346720000000005],[99.264,592.96264,442.6254399999999,14.346720000000005],[99.264,610.96264,442.63648,14.346720000000005],[99.264,628.8726399999999,215.66888,14.346720000000005]],"refs":[[0,272,"Trong mô hình lần này, do chỉ xử lý ở mức nông, nên không xét đến các vấn đề ở mức cú pháp và ngữ nghĩa, nhưng để tăng độ chính xác, bài toán sẽ sử dụng việc đồng nhất các từ đồng nghĩa(xử lý chung cho cả 3 loại trên) dựa trên từ điển đồng nghĩa thô xây dựng sẵn, bộ từ điển này gồm gần 2800 mục, xây dựng bằng cách dùng công cụ tải các trang của từ điển Việt Việt tại trang tratu.soha.vn, sau đó tách thẻ có chứa các từ đồng nghĩa rồi ghép lại"]]},"312":{"boxes":[[321.16664000000003,628.8726399999999,220.73336000000006,14.346720000000005],[99.264,646.8726399999999,442.6268799999999,14.346720000000005],[99.264,664.7526399999999,442.63599999999997,14.346720000000005],[99.264,682.7526399999999,282.766,14.346720000000005]],"refs":[[0,273,"Mỗi mục gồm các từ gần nghĩa hoặc đồng nghĩa với nhau về mặt nào đó, và mỗi từ chỉ xuất hiện trong một mục, trên thực tế có những từ có thể ở nhiều mục, nhưng số lượng các từ đó không nhiều nên trong bộ từ điển này sẽ sử dụng nghĩa phổ biến nhất của các từ đó"]]},"313":{"boxes":[[388.61368000000004,682.7526399999999,153.28631999999993,14.346720000000005],[99.264,700.6326399999999,368.83888,14.346720000000005]],"refs":[[0,274,"Tuy chưa được đầy đủ và xử lý đơn giản nhưng cũng góp phần tăng độ chính xác cho việc tóm tắt"]]},"314":{"boxes":[[475.42,700.6326399999999,66.43680000000012,14.346720000000005],[99.264,718.6326399999999,255.526,14.346720000000005]],"refs":[[0,275,"Dưới đây là một số mục từ trong bộ từ đồng nghĩa sẽ sử dụng"]]},"305":{"boxes":[[152.3,204.47263999999998,114.26999999999998,14.346720000000005],[119.06,227.99263999999997,192.39,14.346720000000005],[117.26,252.17119999999997,266.32376000000005,14.528159999999986]],"refs":[[0,264,"Xử lý từ đồng nghĩa Có 3 loại từ đồng nghĩa cần xét đến: Từ có nghĩa giống nhau hoặc gần giống nhau"]]},"width":595.32,"306":{"boxes":[[119.06,275.9026399999999,208.01,14.346720000000005],[117.26,300.08119999999997,159.15000000000003,14.528159999999957],[119.06,323.78263999999996,123.87,14.346720000000005],[117.26,347.96119999999996,196.35000000000002,14.528159999999957],[119.06,371.66263999999995,38.640000000000015,14.346720000000005],[155.06,395.66263999999995,386.83988000000005,14.346720000000005],[155.06,413.54263999999995,156.72935999999999,14.346720000000005]],"refs":[[0,267,"Từ đồng nghĩa không hoàn toàn Ví dụ: Ăn, xơi, chén, .(biểu thị thái độ, tình cảm khác nhau đối với người đối thoại hoặc điều được nói đến)"]]},"307":{"boxes":[[155.06,437.56263999999993,368.08448000000016,14.346720000000005]],"refs":[[0,268,"Mang, khiêng, vác, .(biểu thị những cách thức hành động khác nhau)"]]},"308":{"boxes":[[119.06,461.4426399999999,342.03848000000005,14.346720000000005]],"refs":[[0,269,"Với loại 1 và loại 2 thì các từ đồng nghĩa có thể thay thế cho nhau"]]},"309":{"boxes":[[467.60704,461.4426399999999,74.27232000000026,14.346720000000005],[99.264,479.4426399999999,442.55920000000026,14.346720000000005],[99.264,497.3226399999999,372.196,14.346720000000005]],"refs":[[0,270,"Còn loại 3 thì phải xét đến ngữ nghĩa của từ trong ngữ cảnh của văn bản, đây có thể coi là bài toán phức tạp nhất trong xử lý ngôn ngữ, hiện nay chưa có nhiều nghiên cứu"]]},"height":841.92},"page31":{"320":{"boxes":[[413.34376000000003,342.3826399999999,128.55623999999995,14.346720000000005],[99.264,360.2626399999999,217.586,14.347680000000082],[460.66,418.9426399999999,3.240000000000009,14.346720000000005],[119.06,439.72263999999996,54.84,14.346720000000005],[171.26,463.72263999999996,223.49,14.347680000000025],[171.26,487.60263999999995,165.41000000000003,14.346720000000005],[171.26,511.60263999999995,178.97000000000003,14.347679999999968]],"refs":[[0,280,"Cụ thể mỗi từ tần số của mỗi từ wi trong câu sj được tính như sau: Trong đó: fij là số lần xuất hiện của từ ti trong câu sj, m là tổng số câu trong văn bản hi là tổng số câu mà từ ti xuất hiện"]]},"321":{"boxes":[[171.26,535.48264,370.5963200000002,14.346720000000005],[171.26,553.48264,148.97000000000003,14.346720000000005],[119.06,577.3626399999999,422.84,14.346720000000005],[99.264,595.3626399999999,148.10888,14.346720000000005]],"refs":[[0,281,"là hệ số đánh giá độ quan trọng của từ, nếu từ xuất hiện trong truy vấn thì >1, còn lại thì =1 Với hệ số cho từ xuất hiện trong truy vấn, trong quá trình kiểm thử trên tập mẫu thì =4 cho kết quả tốt nhất"]]},"323":{"boxes":[[152.3,619.6326399999999,170.08999999999997,14.346720000000005],[119.06,643.2726399999999,422.84,14.346720000000005],[99.264,661.1526399999999,37.19888000000002,14.346720000000005]],"refs":[[0,283,"Chọn câu phù hợp tạo tóm tắt Bước này sẽ áp dụng các giải thuật đánh giá câu quan trọng để đưa vào kết quả tóm tắt"]]},"324":{"boxes":[[143.77232000000004,661.1526399999999,398.09792000000004,14.346720000000005],[99.264,679.1526399999999,442.6105600000001,14.346720000000005],[99.264,697.0326399999999,190.00184000000002,14.346720000000005]],"refs":[[0,284,"Để hạn chế hiện tượng trùng lặp thông tin trong kết quả tóm tắt, trước khi đưa vào lựa chọn, các câu sẽ được so sánh với nhau để tìm các câu gần tương tự nhau, và loại bỏ câu có vị trí xa tiêu đề hơn"]]},"325":{"boxes":[[295.49,697.0326399999999,246.40999999999997,14.346720000000005],[99.264,715.0326399999999,442.64272000000005,14.346720000000005],[99.264,732.9086399999999,190.93543999999997,14.346720000000005]],"refs":[[0,285,"Độ đo sử dụng để loại bỏ câu trùng lặp và chọn câu phù hợp tạo tóm tắt là độ đo cosin đã trình bày ở trên, nhưng hai vector được tính toán bây giờ là biểu diễn cho hai câu"]]},"width":595.32,"318":{"boxes":[[152.3,264.98263999999995,121.82999999999998,14.346720000000005],[119.06,288.50263999999993,422.81936000000013,14.346720000000005],[99.264,306.50263999999993,119.12831999999993,14.346720000000005]],"refs":[[0,278,"Mô hình hóa văn bản Việc cuối cùng trong giai đoạn tiền xử lý là mô hình hóa văn bản, sử dụng mô hình không gian vector"]]},"319":{"boxes":[[224.62607999999994,306.50263999999993,317.2633600000001,14.346720000000005],[99.264,324.3826399999999,442.62880000000007,14.346720000000005],[99.264,342.3826399999999,307.846,14.346720000000005]],"refs":[[0,279,"Tương tự các công thức dùng để mô hình hóa văn bản ở trên, để mô hình hóa câu, ta sử dụng công thức sau TF.ISF, công thức này tương tự như TF.IDF nhưng các thông số ở trong phạm vi câu và văn bản"]]},"height":841.92},"page6":{},"page18":{"140":{"boxes":[[99.984,673.1526399999999,363.07024,14.346720000000005]],"refs":[[0,107,"Ví dụ cây là một loại thực vật, có bộ phận là lá, chất liệu là gỗ"]]},"130":{"boxes":[[117.26,320.3612,211.01,14.528159999999957],[119.06,344.06263999999993,422.84,14.346720000000005],[99.264,362.06263999999993,47.97791999999997,14.346720000000005]],"refs":[[0,97,"Phương pháp thống kê tần suất từ Độ quan trọng của từ phụ thuộc vào số lần xuất hiện của từ đó trong các văn bản liên quan"]]},"131":{"boxes":[[153.83855999999997,362.06263999999993,387.9541600000002,14.346720000000005],[99.264,379.9426399999999,251.87032,14.346720000000005]],"refs":[[0,98,"Các kỹ thuật như TF.IPF hay Tập thuật ngữ thường xuyên (Frequent Item Set) dùng cho công việc xác định tần suất của từ"]]},"142":{"boxes":[[418.5138400000001,691.0326399999999,123.3861599999999,14.346720000000005],[99.984,709.0326399999999,409.636,14.346720000000005]],"refs":[[0,109,"Sau khi xây dựng được các chuỗi từ này, đánh giá độ mạnh của chúng và có những trích chọn phù hợp"],[7,398,"8 các từ vựng này, ta đánh giá độ mạnh của chúng và chọn ra những câu phù hợp"]]},"143":{"boxes":[[119.78,732.7271999999999,422.09648000000004,14.528159999999957],[99.984,750.9086399999999,402.75064000000003,14.346720000000005]],"refs":[[0,110,"Phương pháp Liên kết tham chiếu: Phương pháp liên kết tham chiếu còn được gọi là phương pháp trích chọn trùng lặp (Anaphora-based Method)"]]},"133":{"boxes":[[178.82,404.30263999999994,127.71000000000004,14.346720000000005],[119.06,427.8226399999999,422.84,14.346720000000005],[99.264,445.84263999999996,205.346,14.346720000000005]],"refs":[[0,100,"Phương pháp cấu trúc Là các phương pháp sử dụng các mối liên hệ cấu trúc - ngữ pháp - ngữ nghĩa để xác định các đơn vị ngữ liệu quan trọng"],[7,389,"b) Phương pháp cấu trúc Các phương pháp này sử dụng các mối liên hệ cấu trúc - ngữ pháp - ngữ nghĩa để xác định các đơn vị ngữ liệu quan trọng"]]},"134":{"boxes":[[310.97336,445.84263999999996,230.84912000000014,14.346720000000005],[99.264,463.72263999999996,442.63599999999997,14.346720000000005],[99.264,481.72263999999996,153.14600000000002,14.346720000000005]],"refs":[[0,101,"Tư tưởng chính của các phương pháp này là những đơn vị ngữ liệu nào có chứa các thành phần liên kết nhiều với các thành phần khác sẽ có độ quan trọng lớn"],[7,390,"Tư tưởng chính của các phương pháp này là những đơn vị ngữ liệu nào có chứa các thành phần liên quan nhiều với các thành phần khác sẽ có mức độ quan trọng cao"]]},"135":{"boxes":[[259.47319999999996,481.72263999999996,282.4104800000002,14.346720000000005],[99.264,499.60263999999995,442.61968000000013,14.346720000000005],[99.264,517.60264,94.43599999999999,14.346720000000005]],"refs":[[0,102,"Việc đánh giá các mối quan hệ sẽ dựa trên các mạng ngữ nghĩa, các quan hệ cú pháp hoặc thông qua các phương pháp xác định độ liên quan truyền thống"],[7,391,"Việc đánh giá các mối quan hệ sẽ dựa trên các mạng ngữ nghĩa hoặc các quan hệ cú pháp"]]},"136":{"boxes":[[119.78,541.3012,422.12,14.528159999999957],[99.984,559.48264,441.916,14.346720000000005],[99.984,577.3626399999999,168.98600000000005,14.346720000000005]],"refs":[[0,103,"Phương pháp quan hệ lẫn nhau: Phương pháp này xác định mối quan hệ giữa các đoạn trong văn bản hay các câu trong đoạn với nhau thông qua các kỹ thuật thu thập thông tin ở mức văn bản"],[7,392,"- Phương pháp sử dụng quan hệ giữa câu, đoạn Phương pháp này xác định mối quan hệ giữa các đoạn trong văn bản hay các câu trong đoạn với nhau thông qua việc tính toán mức độ liên quan giữa chúng"]]},"126":{"boxes":[[117.26,98.93119999999996,165.51,14.528160000000014],[119.06,122.75263999999996,233.21288000000004,14.346720000000005]],"refs":[[0,93,"Phương pháp ngữ cố định Các ngữ cố định có đặc điểm thống kê rất tốt"]]},"137":{"boxes":[[275.07416000000006,577.3626399999999,266.80760000000015,14.346720000000005],[99.984,595.3626399999999,435.4033600000001,14.346720000000005]],"refs":[[0,104,"Các đoạn (câu) trong văn bản nguồn được tính toán độ liên quan lẫn nhau sử dụng các kỹ thuật như Cosine, TF.IPF hay N-gram Overlap"]]},"127":{"boxes":[[358.74424000000005,122.75263999999996,183.13032000000004,14.346720000000005],[99.264,140.63263999999995,189.26600000000002,14.346720000000005]],"refs":[[0,94,"Sau các ngữ này thường là các câu hay từ có độ quan trọng là xác định"],[7,385,"Sau các cụm từ này thường là các từ hay câu quan trọng"]]},"138":{"boxes":[[99.984,613.2726399999999,265.00888000000003,14.346720000000005]],"refs":[[0,105,"Sau đó chọn ra đoạn (câu) có độ liên quan lớn nhất"],[7,394,"Sau đó, ta chọn ra đoạn hay câu có độ liên quan lớn nhất"]]},"128":{"boxes":[[295.72280000000006,140.63263999999995,246.17708,14.346720000000005],[99.264,158.63263999999995,442.63599999999997,14.346720000000005],[99.264,176.51263999999995,442.6038400000002,14.346720000000005],[99.264,194.51263999999995,250.24599999999998,14.346720000000005],[117.26,218.21119999999993,424.64,14.528160000000014],[135.26,236.39263999999994,406.6140800000002,14.346720000000005],[135.26,254.27263999999994,341.918,14.346719999999976]],"refs":[[0,95,"Người ta chia thành hai loại ngữ cố định, một loại mang lại độ quan trọng cho thành phần đi sau, được gọi là ngữ nhấn mạnh, một loại giúp ta loại bỏ, không xét đến những thành phần đi sau vì nó không có nhiều giá trị trong việc trích rút, được gọi là ngữ dư thừa: Ngữ nhấn mạnh (Bonus phrase - Emphasizer): Ngữ nhấn mạnh gồm các ngữ như nói chung là., đặc biệt là., cuối cùng thì., trong bài viết này tôi muốn chỉ ra., bài viết nói về., nội dung gồm.,..v..v.."]]},"139":{"boxes":[[119.78,637.0912,422.12,14.528159999999957],[99.984,655.1526399999999,435.29680000000013,14.346720000000005]],"refs":[[0,106,"Phương pháp liên kết từ vựng: Phương pháp liên kết từ vựng sử dụng các từ điển quan hệ từ vựng đế xây dựng các chuỗi từ liên kết với nhau vể mặt ngữ nghĩa"],[7,395,"+ Phương pháp chuỗi từ vựng (lexical chains) Phương pháp liên kết từ vựng sử dụng các từ điển quan hệ từ vựng để xây dựng các chuỗi từ liên kết với nhau về mặt ngữ nghĩa"]]},"width":595.32,"129":{"boxes":[[117.26,278.12119999999993,424.6371200000001,14.528159999999957],[135.26,296.1826399999999,261.73880000000014,14.346720000000005]],"refs":[[0,96,"Ngữ dư thừa (Stigma phrases): Một số ngữ dư thừa: hiếm khi mà., bài này không nói đến., Không thể nào., ..v..v.."]]},"height":841.92},"page5":{},"page19":{"160":{"boxes":[[117.26,601.5412,239.57,14.528159999999957],[119.06,625.3926399999999,422.84023999999994,14.346720000000005],[99.264,643.2726399999999,132.72055999999998,14.346720000000005]],"refs":[[0,127,"Phương pháp thay thế ngữ tương đương Tư tưởng của phương pháp này là các ngữ đóng vai trò như nhau trong câu được thay bằng một ngữ chung"]]},"161":{"boxes":[[119.06,667.2726399999999,422.8116800000002,14.346720000000005],[99.264,685.1526399999999,157.22012,14.346720000000005]],"refs":[[0,128,"Ví dụ: Anh ấy bước vào, ngồi xuống ghế, xem thực đơn, gọi món, ăn, trả tiền và ra về => Anh ấy đi ăn tiệm"]]},"151":{"boxes":[[152.3,212.75263999999996,74.07,14.346720000000005],[119.06,236.39263999999994,422.8049600000001,14.346720000000005],[99.264,254.27263999999994,121.57447999999998,14.346719999999976]],"refs":[[0,117,"Pha Biến đổi Ở pha này, các câu sẽ được biến đổi, làm gọn lại hoặc kết hợp nhiều câu tạo thành câu mới ngắn gọn hơn"]]},"152":{"boxes":[[228.71816,254.27263999999994,313.18183999999997,14.346719999999976],[99.264,272.3026399999999,442.63588000000004,14.346720000000005],[99.264,290.1826399999999,127.82600000000001,14.346720000000005]],"refs":[[0,118,"Các phương pháp trong pha này không làm tăng thêm độ chính xác mà chỉ giúp cho văn bản kết quả ngắn gọn hơn mà vẫn sát nghĩa và thuật toán thưởng rất phức tạp"]]},"153":{"boxes":[[233.57000000000002,290.1826399999999,121.34,14.346720000000005],[124.82,314.5426399999999,35.639999999999986,14.346720000000005]],"refs":[[0,119,"Có thể chia làm 2 loại: 2.7.2.1"]]},"154":{"boxes":[[178.82,314.5426399999999,145.85000000000002,14.346720000000005],[119.06,338.06263999999993,422.84,14.346720000000005],[99.264,356.06263999999993,170.30888000000004,14.346720000000005]],"refs":[[0,120,"Giản lược về cấu trúc câu Giản lược về cấu trúc câu là việc lược bỏ trong câu các phần thừa, ít mang giá trị, làm cho cấu trúc câu thu gọn lại"]]},"155":{"boxes":[[276.63608000000005,356.06263999999993,265.15184000000005,14.346720000000005],[99.264,373.9426399999999,129.92336,14.346720000000005]],"refs":[[0,121,"Công việc này thường dựa trên phân tích cú pháp các thành phần trong câu"],[7,412,"Công việc này thường dựa trên phân tích cú pháp và phân tích ngữ nghĩa các thành phần trong câu"]]},"146":{"boxes":[[224.05064000000002,74.85263999999998,317.8152799999999,14.346720000000005],[99.984,92.75263999999996,249.526,14.346720000000005]],"refs":[[0,112,"Sau khi phân tách các cụm trùng lặp, chúng ta tạo chuỗi các từ tham chiếu đến cùng một từ được tham chiếu"],[7,402,"Sau khi phân tách các cụm trùng lặp, chúng ta tạo chuỗi các từ (cụm từ) tham chiếu đến cùng một từ được tham chiếu"]]},"157":{"boxes":[[178.82,398.30263999999994,157.97000000000003,14.346720000000005],[117.26,422.0012,237.89000000000004,14.528159999999957],[119.06,445.84263999999996,422.83988000000005,14.346720000000005],[99.264,463.72263999999996,31.697279999999992,14.346720000000005]],"refs":[[0,123,"Giản lược về mặt ngữ nghĩa Phương pháp trừu tượng hóa khái niệm Tư tưởng của phương pháp này là từ các khái niệm cụ thể thay thế bằng khái niệm chung"]]},"147":{"boxes":[[355.99,92.75263999999996,185.89368000000013,14.346720000000005],[99.984,110.75263999999996,441.91648000000015,14.346720000000005],[99.984,128.63263999999995,52.195999999999984,14.346720000000005]],"refs":[[0,113,"Chuỗi dài nhất sẽ được coi là trọng tâm của đoạn, các câu chứa các từ trong chuỗi này có một độ ưu tiên nào đó khi xét trích chọn"],[7,403,"Chuỗi dài nhất sẽ được coi là trọng tâm của đoạn, các câu chứa các từ trong chuỗi này có một độ ưu tiên nào đó thì sẽ được chọn"]]},"158":{"boxes":[[119.06,487.72263999999996,274.73,14.346720000000005],[117.26,511.7812,188.07,14.528159999999957],[119.06,535.60264,422.8136000000001,14.346720000000005],[99.264,553.48264,67.796,14.346720000000005]],"refs":[[0,124,"Ví dụ: Tôi ăn dâu, táo và đào => Tôi ăn trái cây Phương pháp thay thế bộ phận Tư tưởng của phương pháp này là từ các khái niệm bộ phận thay thế bằng khái niệm toàn bộ"]]},"148":{"boxes":[[119.78,152.45119999999994,422.0864,14.528160000000014],[99.984,170.51263999999995,441.916,14.346720000000005],[99.984,188.51263999999995,24.49152000000001,14.346720000000005]],"refs":[[0,114,"Phương pháp quan hệ câu: Dựa trên các từ thể hiện mối quan hệ giữa các câu chúng ta cấu trúc hóa đoạn văn bản từ các đơn vị thành phần như ngữ, mệnh đề, câu.."]]},"149":{"boxes":[[130.9728,188.51263999999995,296.7772,14.346720000000005]],"refs":[[0,115,"Sau đó đơn vị được coi như trung tâm sẽ được trích chọn"]]},"width":595.32,"height":841.92},"page4":{},"page16":{"99":{"boxes":[[231.15704000000002,206.39263999999994,310.7429599999999,14.346720000000005],[99.264,224.39263999999994,159.38599999999997,14.346720000000005]],"refs":[[0,66,"Lý thuyết logic mờ đã và đang được ứng dụng rất mạnh mẽ trong lĩnh vực Trí tuệ nhân tạo"]]},"100":{"boxes":[[119.06,248.27263999999994,422.81408000000016,14.346719999999976],[99.264,266.3026399999999,442.62688,14.346720000000005],[99.264,284.1826399999999,251.44600000000003,14.346720000000005]],"refs":[[0,68,"Tuy nhiên khi áp dụng mô hình tập thô cho quá trình xử lý văn bản thì tính chất bắc cầu không còn phù hợp"]]},"101":{"boxes":[[359.57464000000004,284.1826399999999,182.30856000000006,14.346720000000005],[99.264,302.1826399999999,442.6388800000001,14.346720000000005],[99.264,320.06263999999993,237.166,14.346720000000005]],"refs":[[0,69,"Nhóm tác giả Hồ Tú Bảo, Saori Kawasaki, Nguyễn Ngọc Bình đã đề xuất ra mô hình tập thô dung sai trong đó bỏ đi tính chất bắc cầu trong quá trình xử lý văn bản"]]},"102":{"boxes":[[342.53416000000004,320.06263999999993,199.35816,14.346720000000005],[99.264,338.06263999999993,442.63599999999997,14.346720000000005],[99.264,355.9426399999999,442.63599999999997,14.346720000000005],[99.264,373.9426399999999,18.830880000000008,14.346720000000005]],"refs":[[0,70,"Lý thuyết tập thô được các nhà nghiên cứu Trí tuệ nhân tạo phát triển và ngày càng thể hiện được tính ưu việt không chỉ trong việc biểu diễn và thao tác văn bản mà còn trong các vấn đề khác của lĩnh vực này"]]},"105":{"boxes":[[119.78,612.9712,422.12,14.528159999999957],[99.984,631.1526399999999,383.35888000000006,14.346720000000005]],"refs":[[0,73,"Biến đổi (Transformation): Lựa chọn các thông tin trích chọn được, biến đổi để giản lược và thống nhất, kết quả là các đơn vị ngữ liệu đã được tóm tắt"]]},"106":{"boxes":[[119.78,654.8512,422.1198800000001,14.528159999999957],[99.984,673.0326399999999,441.916,14.346720000000005],[99.984,690.9126399999999,123.35623999999997,14.346720000000005]],"refs":[[0,74,"Hiển thị (Generation): Từ các đơn vị ngữ liệu đã tóm tắt, liên kết chúng lại thành đoạn theo một thứ tự nào đó hoặc theo cấu kết ngữ pháp rồi hiển thị phù hợp với yêu cầu người dùng"]]},"width":595.32,"107":{"boxes":[[119.06,714.9126399999999,422.84,14.346720000000005],[99.264,732.78864,436.03888000000006,14.346720000000005]],"refs":[[0,75,"Một hệ Tóm lược (Abstraction) bao gồm tất cả các pha trên, tuy nhiên một hệ Trích rút (Extraction) chỉ gồm pha Phân tích và Pha Hiển thị, không có pha biến đổi"]]},"108":{"boxes":[[99.264,750.78864,436.1396800000001,14.346720000000005]],"refs":[[0,76,"Thậm chí trong các pha phân tích và hiển thị, chỉ có một số công đoạn được sử dụng"]]},"94":{"boxes":[[152.3,57.21263999999999,143.19,14.346720000000005],[119.06,80.87263999999996,422.82656000000014,14.346720000000005],[99.264,98.75263999999996,332.27127999999993,14.346720000000005]],"refs":[[0,61,"Mô hình tập thô dung sai Mô hình tập thô dung sai (Tolerance Rough Set Model) là một mô hình mới, tiên tiến dựa trên lý thuyết về logic mờ và tập mờ (Fuzzy Set)"]]},"95":{"boxes":[[438.84471999999994,98.75263999999996,103.02552000000014,14.346720000000005],[99.264,116.75263999999996,442.6009600000002,14.346720000000005],[99.264,134.63263999999995,294.51544000000007,14.346720000000005]],"refs":[[0,62,"Điều cốt lõi của lý thuyết này là việc xác định chính xác một giả thiết nào đó (ví dụ như hai văn bản này có phù hợp, có giống nhau không...) là một điều rất khó"]]},"96":{"boxes":[[400.7260000000001,134.63263999999995,141.17399999999986,14.346720000000005],[99.264,152.63263999999995,418.76272000000006,14.346720000000005]],"refs":[[0,63,"Tuy nhiên chúng ta có thể chỉ ra một cặp xấp xỉ trên và xấp xỉ dưới để khẳng định được giả thiết đó là đúng"]]},"97":{"boxes":[[524.4937600000002,152.63263999999995,17.406239999999798,14.346720000000005],[99.264,170.51263999999995,357.2600800000001,14.346720000000005]],"refs":[[0,64,"Sử dụng các suy diễn hợp lý để xác định và làm đẹp các ngưỡng này"]]},"height":841.92,"98":{"boxes":[[463.3410400000001,170.51263999999995,78.43392,14.346720000000005],[99.264,188.51263999999995,442.63588000000004,14.346720000000005],[99.264,206.39263999999994,125.52968,14.346720000000005]],"refs":[[0,65,"Các phép toán cơ bản trong mô hình tập thô dựa trên các quan hệ tương đương các tính chất như đối xứng, phản xạ, bắc cầu.."]]}},"page38":{},"page3":{},"page17":{"120":{"boxes":[[375.89368,571.72264,166.00631999999996,14.346720000000005],[99.264,589.72264,153.14600000000002,14.346720000000005],[117.26,613.4512,424.62368000000015,14.528159999999957],[135.26,631.6326399999999,353.70752,14.346720000000005]],"refs":[[0,88,"Chủ đề - Tiêu đề (Title-based): Chủ đề các đoạn văn bản hay tiêu đề các bảng thường chứa các từ và ngữ quan trọng, nên trích rút thông tin từ đây"]]},"121":{"boxes":[[117.26,655.3312,424.63988000000006,14.528159999999957],[135.26,673.5126399999999,347.72,14.346720000000005]],"refs":[[0,89,"Đầu - cuối đoạn (First - Last Sentence): Xác suất câu đầu đoạn hay câu cuối đoạn chứa ý chính của cả đoạn là rất lớn, đặc biệt là câu đầu đoạn"],[7,381,"7 + Câu ở đầu hoặc cuối đoạn: xác suất câu đầu đoạn hay câu cuối đoạn chứa ý chính của cả đoạn là rất lớn, đặc biệt là câu đầu đoạn"]]},"111":{"boxes":[[257.57336,194.75263999999996,284.3376800000002,14.346720000000005],[99.264,212.75263999999996,171.62311999999997,14.346720000000005]],"refs":[[0,78,"Còn hệ Tóm lược thì phức tạp, do kết hợp các phương pháp của xử lý ngôn ngữ tự nhiên"]]},"122":{"boxes":[[489.80992000000003,673.5126399999999,52.034400000000005,14.346720000000005],[135.26,691.3926399999999,370.03424,14.346720000000005]],"refs":[[0,90,"Ngoài ra, các đoạn đầu và cuối trong văn bản cũng quan trọng hơn các đoạn giữa"],[7,382,"Ngoài ra các đoạn đầu và cuối văn bản cũng quan trọng hơn các đoạn giữa"]]},"112":{"boxes":[[276.8876,212.75263999999996,265.01228000000003,14.346720000000005],[99.264,230.63263999999995,413.11168,14.346720000000005]],"refs":[[0,79,"Vì vậy, kết quả của các hệ Tóm lược thường thuyết phục hơn (về mặt dễ đọc, dễ hiểu, liên kết ngôn ngữ tốt, gần gũi với con người)"]]},"123":{"boxes":[[117.26,715.2112,424.64023999999995,14.528159999999957],[135.26,733.2686399999999,297.41,14.346720000000005]],"refs":[[0,91,"Minh họa - Chú thích (Comments): Trong các câu chú thích, câu minh họa cho ảnh hay đồ thị thường chứa các thông tin quan trọng"],[7,383,"+ Minh hoạ, chú thích: trong các câu chú thích, câu minh hoạ cho ảnh hay đồ thị thường chứa các thông tin quan trọng"]]},"113":{"boxes":[[119.06,254.63263999999995,422.84023999999994,14.346719999999976],[99.264,272.5426399999999,133.5668,14.346720000000005]],"refs":[[0,80,"Trong mỗi pha có thể áp dụng nhiều kỹ thuật xử lý khác nhau, chi tiết sẽ được trình bày ở phần tiếp theo"]]},"115":{"boxes":[[143.78,296.9026399999999,230.33,14.346720000000005],[116.3,320.78263999999996,25.92,14.346720000000005]],"refs":[[0,82,"Các phương pháp áp dụng trong các pha 2.7.1"],[7,101,"Các phương pháp áp dụng trong pha phân tích"],[7,104,"Các phương pháp áp dụng trong pha biến đổi ........................................"],[7,375,"Các phương pháp áp dụng trong pha phân tích"]]},"116":{"boxes":[[152.3,320.78263999999996,81.27000000000001,14.346720000000005],[119.06,344.42263999999994,422.80544000000003,14.346720000000005],[99.264,362.30263999999994,442.60864000000004,14.346720000000005],[99.264,380.30263999999994,201.72680000000008,14.346720000000005]],"refs":[[0,83,"Pha Phân tích Ở pha này văn bản nguồn sẽ được tách thành các đoạn, câu, từ, kết hợp với các thông số đầu vào và áp dụng một số thuật toán cụ thể để chọn ra các đoạn hoặc câu phù hợp làm đầu vào cho pha tiếp theo"]]},"117":{"boxes":[[119.06,404.18263999999994,422.78864000000016,14.346720000000005],[99.264,422.18263999999994,206.28248000000002,14.346720000000005]],"refs":[[0,84,"Các phương pháp áp dụng trong pha Phân tích được chia thành hai loại: Phương pháp thống kê và Phương pháp cấu trúc"]]},"width":595.32,"119":{"boxes":[[178.82,446.4426399999999,129.87,14.346720000000005],[119.06,470.0826399999999,422.80592000000007,14.346720000000005],[99.264,487.9626399999999,442.55176000000006,14.346720000000005],[99.264,505.96263999999996,377.836,14.346720000000005],[117.26,530.0212,126.99,14.528159999999957],[119.06,553.84264,422.8131200000001,14.346720000000005],[99.264,571.72264,270.046,14.346720000000005]],"refs":[[0,86,"Phương pháp thống kê Phương pháp này sử dụng các số liệu thống kê về độ quan trọng của từ, câu hay đoạn, nhận được từ các nghiên cứu về ngôn ngữ học hay thông qua các phương pháp học máy dựa trên tập mẫu để trích rút ra các đơn vị ngữ liệu quan trọng Phương pháp vị trí Phương pháp vị trí bao gồm các phương pháp xác định độ quan trọng dựa trên thống kê về vị trí của từ, ngữ hay câu trong văn bản"]]},"height":841.92},"page39":{},"page2":{},"page14":{"77":{"boxes":[[119.06,525.16264,422.84,14.346720000000005],[99.264,543.16264,442.63599999999997,14.346720000000005],[99.264,561.0426399999999,442.63599999999997,14.346720000000005],[99.264,579.0426399999999,52.07888000000001,14.346720000000005]],"refs":[[0,45,"Do vậy có thể thấy rằng hạn chế lớn nhất của mô hình này đó là việc đánh giá độ liên quan chỉ trả về hai kết quả, hoặc phù hợp hoặc không, như vậy yêu cầu của hệ thống khi cần sắp xếp và chọn lựa các văn bản theo mức độ liên quan đến truy vấn sẽ không đạt"]]},"67":{"boxes":[[143.78,117.11263999999997,152.43000000000004,14.346720000000005],[119.06,140.63263999999995,422.8131200000002,14.346720000000005],[99.264,158.63263999999995,249.60568,14.346720000000005]],"refs":[[0,35,"Mô hình biểu diễn văn bản Văn bản thông thường là dạng dữ liệu phi cấu trúc, do vậy muốn xử lý chúng trước hết phải biểu diễn thành dạng có cấu trúc"]]},"78":{"boxes":[[158.52272000000002,579.0426399999999,383.35615999999993,14.346720000000005],[99.264,596.92264,442.63599999999997,14.346720000000005],[99.264,614.95264,156.74599999999998,14.346720000000005]],"refs":[[0,46,"Độ liên quan của mô hình này không thể phân chia thành các mức khác nhau, do vậy không phản ánh được thực tế là việc liên quan giữa văn bản và truy vấn có thể là mờ, không chắn chắn"]]},"68":{"boxes":[[355.94584000000003,158.63263999999995,185.94504,14.346720000000005],[99.264,176.51263999999995,355.396,14.346720000000005]],"refs":[[0,36,"Các cấu trúc này phải có khả năng thao tác bằng các phép toán cơ bản như cộng, nhân, đại số quan hệ.."]]},"79":{"boxes":[[262.2308,614.95264,279.63608000000016,14.346720000000005],[99.264,632.83264,266.34080000000006,14.346720000000005]],"refs":[[0,47,"Hạn chế này được loại bỏ khi ta sử dụng một mô hình tổng quát hơn Mô hình không gian vector (VSM)"]]},"69":{"boxes":[[461.37328,176.51263999999995,80.46864000000016,14.346720000000005],[99.264,194.51263999999995,241.486,14.346720000000005],[116.3,218.75263999999996,25.92,14.346720000000005]],"refs":[[0,37,"Có ba mô hình thỏa mãn yêu cầu đó thường được sử dụng là: 2.5.1"]]},"width":595.32,"70":{"boxes":[[152.3,218.75263999999996,97.22999999999999,14.346720000000005],[119.06,242.39263999999994,422.84023999999994,14.346719999999976],[99.264,260.3026399999999,273.85480000000007,14.346720000000005]],"refs":[[0,38,"Mô hình boolean Trong mô hình boolean, văn bản, vốn là tập hợp của các term (thuật ngữ), được biểu diễn bởi chỉ số từng term và trọng số của chúng"]]},"81":{"boxes":[[152.3,657.19264,153.63,14.346720000000005],[119.06,680.71264,422.7389600000002,14.346720000000005],[99.264,698.71264,43.195680000000024,14.346720000000005]],"refs":[[0,49,"Mô hình không gian vector Như trên đã đề cập, mô hình không gian vector là mô hình tổng quát hơn mô hình Boolean"]]},"71":{"boxes":[[379.5988000000001,260.3026399999999,162.28488000000004,14.346720000000005],[99.264,278.3026399999999,442.61728000000005,14.346720000000005],[99.264,296.1826399999999,248.20600000000002,14.346720000000005]],"refs":[[0,39,"Trọng số của từng term - dùng để đánh giá độ quan trọng của chúng - trong mô hình này chỉ mang hai giá trị 0 và 1, tùy theo sự xuất hiện của term đó trong văn bản"]]},"82":{"boxes":[[148.22688000000005,698.71264,393.6568000000001,14.346720000000005],[99.264,716.59264,442.5277600000003,14.346720000000005],[99.264,734.5886399999999,45.69983999999998,14.346720000000005]],"refs":[[0,50,"Các văn bản được biểu diễn thành các vector nhiều chiều, với trọng số không chỉ mang hai giá trị là 0 hay 1 mà có thể mang các giá trị khác tùy theo cách đánh giá, tính toán"]]},"72":{"boxes":[[171.26,369.62263999999993,269.08712,14.347680000000025]],"refs":[[0,40,"Trong đó wi là trọng số của term ti trong văn bản D"]]},"83":{"boxes":[[151.56480000000002,734.5886399999999,390.31600000000014,14.346720000000005],[99.264,752.4686399999999,121.37039999999992,14.346720000000005]],"refs":[[0,51,"Một khác biệt nữa so với mô hình boolean là các phép toán cơ bản của mô hình không gian vector"]]},"73":{"boxes":[[119.06,393.62263999999993,422.84,14.346720000000005],[99.264,411.50263999999993,442.63599999999997,14.346720000000005],[99.264,429.50263999999993,165.13256,14.346720000000005]],"refs":[[0,41,"Đối với vấn đề truy vấn, trong mô hình này câu truy vấn bao gồm các văn bản tìm kiếm liên hệ với nhau thông qua các phép đại số quan hệ cơ bản như NOT (phủ định), AND (và) hay OR (hoặc)"]]},"74":{"boxes":[[270.64328000000006,429.50263999999993,271.2566,14.346720000000005],[99.264,447.4026399999999,296.56600000000003,14.346720000000005]],"refs":[[0,42,"Câu truy vấn có thể biểu diễn thành dạng vector với các thành phần liên kết và các phép toán quan hệ cơ bản"]]},"75":{"boxes":[[402.65992000000006,447.4026399999999,139.24007999999992,14.346720000000005],[99.264,465.4026399999999,392.59888,14.346720000000005]],"refs":[[0,43,"Từ đây, độ liên quan giữa một văn bản và truy vấn được xác định thông qua các thành phần liên kết"]]},"65":{"boxes":[[348.07,56.85263999999998,193.82999999999998,14.346720000000005],[99.264,74.85263999999998,442.63599999999997,14.346720000000005],[99.264,92.75263999999996,15.830240000000003,14.346720000000005]],"refs":[[0,33,"Tóm tắt hướng truy vấn được cài đặt và áp dụng nhiều hơn nhưng trong lĩnh vực hẹp hơn, đi sâu vào các chuyên ngành cụ thể"]]},"height":841.92,"76":{"boxes":[[499.15936000000005,465.4026399999999,42.72432000000009,14.346720000000005],[99.264,483.28263999999996,442.63599999999997,14.346720000000005],[99.264,501.2826399999999,86.516,14.346720000000005]],"refs":[[0,44,"Độ liên quan này chỉ có thể mang hai giá trị : 0 văn bản không phù hợp với truy vấn và 1 văn bản phù hợp"]]}},"page36":{"360":{"boxes":[[99.264,373.9426399999999,442.63623999999993,14.346720000000005],[99.264,391.9426399999999,387.0040000000001,14.346720000000005]],"refs":[[0,315,"Nước ta cũng mua sắm trang bị vũ khí, nhưng không phải để gây chiến tranh, chạy đua vũ trang mà là tăng cường phòng thủ, bảo vệ chủ quyền lãnh thổ{6}"]]},"361":{"boxes":[[493.4089600000001,391.9426399999999,48.48191999999983,14.346720000000005],[99.264,409.8226399999999,442.6360000000001,14.346720000000005],[99.264,427.8226399999999,29.804000000000016,14.346720000000005]],"refs":[[0,316,"Chủ tịch nước cho biết, chủ trương hòa hiếu luôn được các nước bạn bè trên thế giới ủng hộ{7}"]]},"363":{"boxes":[[180.46928,487.60263999999995,361.43071999999995,14.346720000000005],[99.264,505.60263999999995,442.5928000000001,14.346720000000005],[99.264,523.48264,193.85768000000007,14.346720000000005]],"refs":[[0,318,"Những mâu thuẫn trên Biển Đông là có, nhưng biện pháp hòa hiếu của nước ta đã có kết quả tốt, Nhà nước luôn hỗ trợ ngư dân ra khơi, số lượng tàu cá đánh bắt xa bờ ngày càng tăng{9}"]]},"364":{"boxes":[[299.65352000000007,523.48264,242.2464799999999,14.346720000000005],[99.264,541.48264,442.6321600000001,14.346720000000005],[99.264,559.3626399999999,91.68175999999998,14.346720000000005]],"refs":[[0,319,"Nước ta phấn đấu đến năm 2020 sẽ phát triển kinh tế biển đạt 52%-53% GDP, trong đó, dầu khí, vận tải biển, đánh bắt hải sản là thế mạnh lớn{10}"]]},"354":{"boxes":[[143.78,57.21263999999999,144.03,14.346720000000005],[119.06,80.87263999999996,416.24000000000007,14.346720000000005]],"refs":[[0,309,"Thử nghiệm một văn bản Phần này em sử dụng công cụ tóm tắt đã xây dựng để thử nghiệm một văn bản"]]},"365":{"boxes":[[197.42576,559.3626399999999,344.46511999999996,14.346720000000005],[99.264,577.3626399999999,272.8540000000001,14.346720000000005]],"refs":[[0,320,"Mục tiêu cuối cùng của nước ta là chủ quyền lãnh thổ vững chắc, quốc phòng - an ninh ổn định, kinh tế phát triển{11}"]]},"355":{"boxes":[[99.264,98.75263999999996,192.74599999999998,14.346720000000005],[110.66,123.11263999999997,25.919999999999987,14.346720000000005]],"refs":[[0,310,"Kết quả thực hiện thu được như sau: 2.2.1"]]},"366":{"boxes":[[119.06,601.2426399999999,422.8073600000001,14.346720000000005],[99.264,619.2726399999999,442.62256000000014,14.346720000000005],[99.264,637.1526399999999,252.87896000000012,14.346720000000005]],"refs":[[0,321,"Liên quan đến các vấn đề kinh tế - xã hội, Chủ tịch nước Trương Tấn Sang cho biết kinh tế nước nhà có những phát triển đáng kể, nông nghiệp đạt nhiều thắng lợi, các ngành thuộc về dầu khí tăng trưởng khá{12}"]]},"356":{"boxes":[[146.66,123.11263999999997,49.110000000000014,14.346720000000005],[137.06,146.45119999999994,70.71000000000001,14.528160000000014],[119.06,170.63263999999995,390.56,14.346720000000005],[119.06,194.51263999999995,422.83988000000005,14.346720000000005],[99.264,212.51263999999995,442.63599999999997,14.346720000000005],[99.264,230.39263999999994,91.78496,14.346720000000005]],"refs":[[0,311,"Đầu vào Văn bản: Bảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình{1} Chiều ngày 26-4, Chủ tịch nước Trương Tấn Sang và Tổ Đại biểu Quốc hội (ĐBQH) số 1, Đoàn ĐBQH TP Hồ Chí Minh tiếp tục có buổi tiếp xúc với gần 400 cử tri của quận 1{2}"]]},"357":{"boxes":[[198.08624,230.39263999999994,343.7136800000003,14.346720000000005],[99.264,248.39263999999994,442.63599999999997,14.346719999999976],[99.264,266.3026399999999,37.00687999999998,14.346720000000005]],"refs":[[0,312,"Ghi nhận các ý kiến của cử tri, Chủ tịch nước đánh giá cao tinh thần đóng góp ý kiến của mọi người, nhất là vấn đề sửa đổi Hiến Pháp và các đạo luật{3}"]]},"358":{"boxes":[[143.7488,266.3026399999999,398.1512,14.346720000000005],[99.264,284.3026399999999,442.6360000000001,14.346720000000005],[99.264,302.1826399999999,442.6360000000001,14.346720000000005],[99.264,320.18263999999994,442.6124800000001,14.346720000000005],[99.264,338.06263999999993,55.44176,14.346720000000005]],"refs":[[0,313,"Trả lời câu hỏi được đông đảo cử tri quan tâm về chủ trương bảo vệ chủ quyền lãnh thổ, củng cố quốc phòng - an ninh, Chủ tịch nước Trương Tấn Sang khẳng định chủ trương của Đảng, Nhà nước trước sau như một là kiên quyết bảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình, theo hệ thống luật pháp quốc tế{4}"]]},"width":595.32,"height":841.92},"page1":{},"page15":{"88":{"boxes":[[497.48656000000005,170.51263999999995,44.37504000000001,14.346720000000005],[99.264,188.51263999999995,442.62448000000006,14.346720000000005],[99.264,206.39263999999994,137.39384,14.346720000000005]],"refs":[[0,56,"Hai văn bản là hai vector, vậy khoảng cách hay góc giữa chúng đều có thể đại diện cho sự liên quan giữa hai văn bản này"]]},"89":{"boxes":[[243.09896,206.39263999999994,298.80104000000006,14.346720000000005],[99.264,224.39263999999994,234.96248000000003,14.346720000000005]],"refs":[[0,57,"Tất nhiên, để áp dụng được các phép toán vector cơ bản, hai vector cần chuẩn hóa về số chiều (độ dài)"]]},"90":{"boxes":[[119.06,248.27263999999994,229.97000000000003,14.346719999999976],[119.78,272.12119999999993,411.6344,14.528159999999957],[99.984,290.1826399999999,437.11600000000004,14.347680000000082],[382.63,353.30263999999994,3.240000000000009,14.346720000000005],[119.78,374.0012,422.12,14.528159999999957],[99.984,392.06263999999993,64.796,14.346720000000005]],"refs":[[0,58,"Các chỉ số sử dụng trong phương pháp này: Tần suất thuật ngữ của một từ w trong một văn bản d, ký hiệu TF(w,d), có thể sử dụng các công thức sau, với fij là số lần xuất hiện của từ wi trong văn bản dj: Tần suất văn bản của một từ w, ký hiệu DF(w) là số lượng văn bản mà từ w có xuất hiện"]]},"width":595.32,"91":{"boxes":[[171.9728,392.06263999999993,369.92719999999997,14.346720000000005],[99.984,410.06263999999993,100.58600000000003,14.346720000000005],[363.91,455.0826399999999,3.240000000000009,14.346720000000005],[171.26,475.9626399999999,311.84000000000003,14.346720000000005],[119.78,499.78119999999996,321.77,14.5281599999999],[240.29,523.84264,180.26000000000002,14.346720000000005],[119.06,547.84264,422.8102400000002,14.347679999999968],[99.264,565.72264,442.63623999999993,14.347680000000082],[99.264,583.72264,304.82056,14.346720000000005]],"refs":[[0,59,"Nghịch đảo của tần suất văn bản của một từ w, ký hiệu IDF(w) được cho bởi công thức: Trong đó: m là tổng số văn bản,, h là số văn bản chứa từ w Tần suất TF-IDF là kết hợp của hai loại tần suất nói trên: TF-IDF(w,d) = TF(w,d) * IDF(w) Theo mô hình này, mỗi văn bản sẽ được biểu diễn dưới dạng D(t1, t2,.,tn) với n là tổng số thuật ngữ xuất hiện, mỗi thuật ngữ sẽ được đánh index, ti là trọng số của thuật ngữ thứ i(trong danh sách thuật ngữ) trong văn bản D"]]},"92":{"boxes":[[410.33128000000005,583.72264,131.56871999999993,14.346720000000005],[99.264,601.60264,442.61968000000013,14.347679999999968],[99.264,619.6326399999999,88.54544,14.346720000000005]],"refs":[[0,60,"Khi đó độ liên quan giữa hai văn bản biểu diễn bởi 2 vector X(x1, x2, ., xn) và Y(y1, y2,.,yn) được tính bằng công thức Cosin: 2.5.3"]]},"86":{"boxes":[[273.25976,116.75263999999996,268.64023999999995,14.346720000000005],[99.264,134.63263999999995,442.63599999999997,14.346720000000005],[99.264,152.63263999999995,265.60888,14.346720000000005]],"refs":[[0,54,"Truy vấn là kết quả của các phép toán vector giữa các vector biểu diễn cho những văn bản cấu thành nên truy vấn, như vậy, truy vấn trong trường hợp này cũng là một văn bản đặc biệt"]]},"height":841.92,"87":{"boxes":[[371.57320000000004,152.63263999999995,170.32679999999993,14.346720000000005],[99.264,170.51263999999995,391.276,14.346720000000005]],"refs":[[0,55,"Việc xác định độ liên quan giữa truy vấn và văn bản được quy thành độ liên quan giữa văn bản và văn bản"]]}},"page37":{"374":{"boxes":[[119.06,350.06263999999993,422.84023999999994,14.346720000000005],[99.264,368.06263999999993,442.63588000000004,14.346720000000005],[99.264,385.9426399999999,112.18399999999993,14.346720000000005]],"refs":[[0,318,"Những mâu thuẫn trên Biển Đông là có, nhưng biện pháp hòa hiếu của nước ta đã có kết quả tốt, Nhà nước luôn hỗ trợ ngư dân ra khơi, số lượng tàu cá đánh bắt xa bờ ngày càng tăng{9}"]]},"375":{"boxes":[[119.06,409.9426399999999,422.82512000000014,14.346720000000005],[99.264,427.8226399999999,185.18600000000004,14.346720000000005]],"refs":[[0,320,"Mục tiêu cuối cùng của nước ta là chủ quyền lãnh thổ vững chắc, quốc phòng - an ninh ổn định, kinh tế phát triển{11}"]]},"width":595.32,"370":{"boxes":[[146.66,81.23263999999998,90.99000000000001,14.346720000000005],[119.06,104.75263999999996,358.88,14.346720000000005],[119.06,128.75263999999996,422.84,14.346720000000005],[99.264,146.63263999999995,442.6360000000001,14.346720000000005],[99.264,164.63263999999995,442.6360000000001,14.346720000000005],[99.264,182.51263999999995,442.6124800000001,14.346720000000005],[99.264,200.51263999999995,37.790240000000026,14.346720000000005]],"refs":[[0,313,"Trả lời câu hỏi được đông đảo cử tri quan tâm về chủ trương bảo vệ chủ quyền lãnh thổ, củng cố quốc phòng - an ninh, Chủ tịch nước Trương Tấn Sang khẳng định chủ trương của Đảng, Nhà nước trước sau như một là kiên quyết bảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình, theo hệ thống luật pháp quốc tế{4}"]]},"372":{"boxes":[[119.06,266.3026399999999,422.79248000000024,14.346720000000005],[99.264,284.3026399999999,388.156,14.346720000000005]],"refs":[[0,315,"Nước ta cũng mua sắm trang bị vũ khí, nhưng không phải để gây chiến tranh, chạy đua vũ trang mà là tăng cường phòng thủ, bảo vệ chủ quyền lãnh thổ{6}"]]},"height":841.92,"373":{"boxes":[[119.06,308.1826399999999,422.81984000000006,14.346720000000005],[99.264,326.18263999999994,78.716,14.346720000000005]],"refs":[[0,316,"Chủ tịch nước cho biết, chủ trương hòa hiếu luôn được các nước bạn bè trên thế giới ủng hộ{7}"]]}},"page0":{},"page12":{"34":{"boxes":[[140.9,275.18035999999995,318.11,15.542280000000005],[107.78,300.74263999999994,16.200000000000003,14.346720000000005]],"refs":[[0,3,"TỔNG QUAN VỀ TÓM TẮT VĂN BẢN TỰ ĐỘNG 2.1"],[7,86,"2 CHƯƠNG 1: TỔNG QUAN VỀ TÓM TẮT VĂN BẢN ........................................"]]},"35":{"boxes":[[143.78,300.74263999999994,65.07000000000002,14.346720000000005],[119.06,324.3826399999999,422.84,14.346720000000005],[99.264,342.2626399999999,253.95928000000004,14.346720000000005]],"refs":[[0,4,"Định nghĩa Tóm tắt văn bản là quá trình làm giảm độ dài, độ phức tạp của văn bản mà vẫn giữ lại được nội dung quan trọng của văn bản đó"]]},"36":{"boxes":[[359.80696000000006,342.2626399999999,182.09303999999992,14.346720000000005],[99.264,360.2626399999999,442.63588000000004,14.346720000000005],[99.264,378.1426399999999,207.38600000000002,14.346720000000005]],"refs":[[0,5,"Công việc tóm tắt văn bản đã xuất hiện từ rất lâu đời, và nó được làm thủ công, do con người đọc, rút ra các ý chính rồi trình bày lại một cách ngắn gọn, dễ hiểu"]]},"37":{"boxes":[[312.98744000000005,378.1426399999999,228.85928000000018,14.346720000000005],[99.264,396.1426399999999,442.63599999999997,14.346720000000005],[99.264,414.0226399999999,10.082880000000003,14.346720000000005]],"refs":[[0,6,"Mục đích là giúp người sử dụng có cái nhìn tổng quan về nội dung trình bày trong văn bản, để quyết định sử dụng văn bản đó hợp lý"]]},"38":{"boxes":[[116.04719999999999,414.0226399999999,425.8528,14.346720000000005],[99.264,432.0226399999999,75.23024000000002,14.346720000000005]],"refs":[[0,7,"Tuy nhiên với lượng văn bản nhiều và dài thì việc làm thủ công vô cùng tốn thời gian, công sức"]]},"39":{"boxes":[[119.06,455.92263999999994,422.8400000000001,14.346720000000005],[99.264,473.92263999999994,442.49656000000004,14.346720000000005],[99.264,491.80263999999994,157.57688000000002,14.346720000000005]],"refs":[[0,8,"Ngày nay, thời đại công nghệ thông tin phát triển mạnh, tóm tắt văn bản tự động (gọi tắt là tóm tắt văn bản) được nghiên cứu phát triển nhằm mục đích làm thay con người công việc nặng nhọc đó"]]},"width":595.32,"40":{"boxes":[[263.42456000000004,491.80263999999994,278.3326400000001,14.346720000000005],[99.264,509.8026399999999,197.786,14.346720000000005],[119.06,533.68264,422.82080000000013,14.346720000000005],[99.264,551.68264,442.63599999999997,14.346720000000005],[99.264,569.5626399999999,126.986,14.346720000000005],[107.78,593.92264,16.200000000000003,14.346720000000005]],"refs":[[0,9,"Đã có rất nhiều định nghĩa được đưa ra, tuy nhiên có thể sử dụng định nghĩa ngắn gọn sau: Tóm tắt văn bản là quá trình rút ra những thông tin quan trọng nhất từ một hay nhiều nguồn văn bản để tạo ra một văn bản gọn hơn phục vụ cho một số nhiệm vụ hay người dùng cụ thể 2.2"]]},"41":{"boxes":[[143.78,593.92264,120.27000000000001,14.346720000000005],[119.78,617.2912,422.09600000000023,14.528159999999957],[99.984,635.47264,300.526,14.346720000000005],[119.78,659.1712,422.0969600000002,14.528159999999957],[99.984,677.35264,80.39888,14.346720000000005]],"refs":[[0,10,"Các tiêu chí đánh giá Độ mạch lạc (Coherence): đánh giá mức độ rõ ràng của văn bản tóm tắt, tính súc tích, khả năng có thể đọc và hiểu được của bài viết"],[7,435,"10 Các tiêu chí đánh giá: - Độ mạch lạc (Coherence): đánh giá mức độ rõ ràng của văn bản tóm tắt, tính súc tích, khả năng có thể đọc và hiểu được của bài viết\u2026 - Độ hàm chứa thông tin (Informationess): tỉ lệ thông tin của văn bản gốc trong văn bản tóm tắt"]]},"42":{"boxes":[[119.78,701.0512,422.12,14.528159999999957],[99.984,719.23264,271.60168000000004,14.346720000000005]],"refs":[[0,12,"Độ liên quan (Relevance): xác định mức độ phù hợp của văn bản tóm tắt với chủ đề cho trước (chủ đề có thể là một câu truy vấn)"],[7,436,"- Độ liên quan (Relevance): xác định mức độ phù hợp của văn bản tóm tắt với chủ đề cho trước (chủ đề có thể là một câu truy vấn)"]]},"32":{"boxes":[[128.05424,143.39263999999994,286.85576000000003,14.346720000000005],[119.06,167.39263999999994,209.09000000000003,14.346720000000005],[119.06,191.27263999999994,418.88000000000005,14.346720000000005],[119.06,215.27263999999994,422.82944000000015,14.346720000000005],[99.264,233.15263999999993,442.6110400000001,14.346720000000005],[99.264,251.15263999999993,78.47887999999999,14.346719999999976]],"refs":[[0,1,"Cụ thể bài toán cần giải quyết được phát biểu như sau: Đầu vào: Văn bản, truy vấn, độ rút gọn Đầu ra: Bản tóm tắt của văn bản đầu vào xoay quanh vấn đề nêu trong truy vấn Để giải quyết được bài toán này, việc trước hết là tìm hiểu cơ sở lý thuyết về tóm tắt văn bản, tóm tắt hướng truy vấn, từ đó xác định hướng giải quyết và thực hiện cài đặt thử nghiệm"]]},"height":841.92},"page34":{"341":{"boxes":[[146.66,196.31264000000002,142.10999999999999,14.346720000000005],[113.42,220.19264,35.64,14.346720000000005]],"refs":[[0,298,"Các công cụ đã xây dựng 2.1.1.1"]]},"342":{"boxes":[[167.42,220.19264,123.39000000000001,14.346720000000005],[119.06,243.83264,422.7905600000001,14.346719999999976],[99.264,261.74263999999994,52.660160000000005,14.346720000000005]],"refs":[[0,299,"Chương trình tóm tắt Đây là chương trình thực hiện tóm tắt một văn bản dựa trên giải thuật đã phân tích ở trên"]]},"343":{"boxes":[[158.42000000000002,261.74263999999994,376.9851200000002,14.346720000000005]],"refs":[[0,300,"Chi tiết các chức năng đã ghi chú đầy đủ trên ảnh giao diện chương trình"]]},"344":{"boxes":[[99.264,279.74263999999994,442.6235200000001,14.346720000000005],[99.264,297.62263999999993,442.6273600000002,14.346720000000005],[99.264,315.62263999999993,47.87599999999999,14.346720000000005]],"refs":[[0,301,"Đầu vào của chương trình là văn bản gốc, truy vấn, và độ rút gọn, đầu ra sẽ là văn bản tóm tắt, có thể xem chi tiết một số bước xử lý ở chức năng Note góc dưới trái giao diện"]]},"346":{"boxes":[[167.42,628.0326399999999,118.83000000000001,14.346720000000005],[119.06,651.67264,311.20088000000004,14.346720000000005]],"refs":[[0,303,"Công cụ tạo tập mẫu Công cụ này hỗ trợ, tạo, chỉnh sửa các bản tóm tắt thủ công"]]},"347":{"boxes":[[436.84456000000006,651.67264,105.01704000000012,14.346720000000005],[99.264,669.5526399999999,442.61296000000004,14.346720000000005],[99.264,687.5526399999999,442.6168000000001,14.346720000000005],[99.264,705.43264,103.09183999999998,14.346720000000005]],"refs":[[0,304,"Chức năng chính là quản lý các văn bản mẫu bao gồm văn bản gốc và bản tóm tắt thủ công, được tích hợp chức năng tách từ, tách câu của VNTokenizer nên việc tạo văn bản mẫu sẽ chính xác và hiệu quả hơn"]]},"348":{"boxes":[[208.73,705.43264,333.16999999999996,14.346720000000005],[99.264,723.43264,378.916,14.346720000000005]],"refs":[[0,305,"Ngoài ra còn có chức năng phát hiện ra các văn bản lỗi font, các văn bản này không thể sử dụng trong các công cụ đi kèm nên cần loại bỏ"]]},"338":{"boxes":[[143.78,82.55263999999991,147.15,14.346720000000005],[119.06,106.19264000000001,422.7910400000001,14.346720000000005],[99.264,124.07264,276.046,14.346720000000005],[117.26,147.8912,297.5781600000004,14.528160000000014]],"refs":[[0,295,"Chương trình thử nghiệm Để thực hiện thử nghiệm em đã xây dựng một số công cụ phục vụ tóm tắt 1 văn bản, công cụ tạo mẫu và công cụ kiểm thử trên mẫu: - Môi trường cài đặt: Java JDK 7u17, Windows 7 32bit"]]},"width":595.32,"339":{"boxes":[[117.26,171.7712,179.63592000000006,14.528160000000014]],"refs":[[0,296,"- Công cụ lập trình Netbeans 7.3"]]},"height":841.92},"page13":{"55":{"boxes":[[119.65007999999999,433.9426399999999,422.24980000000005,14.346720000000005],[99.264,451.84263999999996,442.6393600000001,14.346720000000005],[99.264,469.84263999999996,175.67864000000003,14.346720000000005]],"refs":[[0,24,"Ngược lại, tóm tắt đa văn bản là từ nhiều văn bản nguồn cũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng thời cho nhiều văn bản khác nhau"],[4,113,"Ngược lại tóm tắt đa văn bản là từ một văn bản nguồn cũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng thời cho nhiều văn bản khác nhau"],[8,29,"Ngược lại tóm tắt đa văn bản là từ một văn bản nguồn cũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng thời cho nhiều văn bản khác nhau"]]},"56":{"boxes":[[281.65592000000004,469.84263999999996,260.1180800000003,14.346720000000005],[99.264,487.72263999999996,442.61199999999997,14.346720000000005],[99.264,505.72263999999996,442.63599999999997,14.346720000000005],[99.264,523.60264,78.95232,14.346720000000005]],"refs":[[0,25,"Rõ ràng, tóm tắt đa văn bản thì khó hơn, vì ngoài những công việc của tóm tắt đơn văn bản, tóm tắt đa văn bản còn phải thực hiện các công việc như tiền xử lý trích rút, tích hợp thống nhất khuôn dạng và hiển thị kết quả theo cách riêng"]]},"46":{"boxes":[[143.78,117.11263999999997,172.47,14.346720000000005],[117.26,140.63263999999995,417.9200000000001,14.346720000000005],[135.26,164.45119999999994,244.07432,14.528160000000014]],"refs":[[0,15,"Ứng dụng của tóm tắt văn bản Tóm tắt văn bản có nhiều ứng dụng trong thực tế, một số ứng dụng nổi bật như: Tóm tắt tự động các tin tức trên báo điện tử"]]},"57":{"boxes":[[184.57968000000002,523.60264,357.30639999999994,14.346720000000005],[99.264,541.60264,442.6081600000001,14.346720000000005],[99.264,559.48264,442.63599999999997,14.346720000000005],[99.264,577.48264,30.236000000000004,14.346720000000005]],"refs":[[0,26,"Ngoài ra, tóm tắt đa văn bản còn phải đối mặt với các vấn đề như dư thừa trùng lặp dữ liệu giữa các văn bản nguồn, nội dung các văn bản nguồn phân tán, độ rút gọn yêu cầu cao, thời gian xử lý cần phải nhanh trong khi sự phức tạp trong xử lý lớn"]]},"47":{"boxes":[[135.26,188.33119999999994,289.0725600000003,14.528160000000014]],"refs":[[0,16,"Trợ giúp thông minh việc đọc và khai thác thông tin"]]},"48":{"boxes":[[135.26,212.33119999999994,286.8188,14.528160000000014]],"refs":[[0,17,"Tóm lược danh sách tìm kiếm từ các Search Engine"]]},"59":{"boxes":[[152.3,601.72264,122.43,14.346720000000005],[119.06,625.3926399999999,422.78672,14.346720000000005],[99.264,643.2726399999999,137.426,14.346720000000005]],"refs":[[0,28,"Theo đầu ra hệ thống Tóm tắt trích rút là quá trình thu gọn văn bản mà trong kết quả ra chứa các đơn vị ngữ liệu văn bản nguồn"]]},"49":{"boxes":[[135.26,236.21119999999993,295.35032,14.528160000000014]],"refs":[[0,18,"Giản lược nội dung trình bày cho các thiết bị cầm tay"]]},"width":595.32,"60":{"boxes":[[243.53,643.2726399999999,298.3162400000002,14.346720000000005],[99.264,661.2726399999999,442.6105600000001,14.346720000000005],[99.264,679.1526399999999,54.35599999999998,14.346720000000005]],"refs":[[0,29,"Tóm tắt tóm lược là quá trình thu gọn văn bản mà trong kết quả ra có một số các đơn vị ngữ liệu mới được sinh ra từ các đơn vị ngữ liệu văn bản nguồn"]]},"50":{"boxes":[[135.26,260.24119999999994,270.17,14.528159999999957]],"refs":[[0,19,"Sinh tự động chủ đề, tiêu đề, dẫn đường văn bản"]]},"51":{"boxes":[[135.26,284.12119999999993,406.48424000000045,14.528159999999957],[153.26,302.3026399999999,150.14423999999997,14.346720000000005]],"refs":[[0,20,"Hỗ trợ tóm lược nội dung cuộc họp, website, chương trình phát thanh và truyền hình, sổ tay công việc"]]},"62":{"boxes":[[152.3,703.5126399999999,128.91000000000003,14.346720000000005],[119.06,727.0326399999999,388.15423999999996,14.346720000000005]],"refs":[[0,31,"Theo mục đích tóm tắt Tóm tắt chung là tóm tắt theo quan điểm ban đầu của tác giả văn bản gốc"]]},"63":{"boxes":[[514.06,727.0326399999999,27.825120000000084,14.346720000000005],[99.264,745.02864,439.3960000000001,14.346720000000005]],"refs":[[0,32,"Tóm tắt hướng truy vấn là tóm tắt theo quan điểm mong muốn của người dùng ứng dụng thông qua các tham số truyền vào câu truy vấn"]]},"53":{"boxes":[[143.78,326.54263999999995,146.67,14.346720000000005],[119.06,350.18263999999994,422.81264000000004,14.346720000000005],[99.264,368.06263999999993,227.44600000000003,14.346720000000005],[116.3,392.42263999999994,25.92,14.346720000000005]],"refs":[[0,22,"Phân loại tóm tắt văn bản Có nhiều cách phân loại tóm tắt, phụ thuộc vào tiêu chí sử dụng để phân loại, sau đây là một số cách phân loại cần quan tâm: 2.4.1"],[2,15,"Phân loại tóm tắt văn bản: Có rất nhiều cách phân loại tóm tắt văn bản"]]},"height":841.92,"54":{"boxes":[[152.3,392.42263999999994,129.63,14.346720000000005],[119.06,415.9426399999999,422.84,14.346720000000005],[99.264,433.9426399999999,12.960000000000008,14.346720000000005]],"refs":[[0,23,"Theo đầu vào hệ thống Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn gọn của văn bản đó"],[4,112,"Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn ngọn của văn bản đó"],[8,28,"Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn ngọn của văn bản đó"]]}},"page35":{"width":595.32,"351":{"boxes":[[167.42,361.22263999999996,102.39000000000001,14.346720000000005],[119.06,384.86263999999994,422.82368,14.346720000000005],[99.264,402.74263999999994,442.63599999999997,14.346720000000005],[99.264,420.74263999999994,214.10168000000004,14.346720000000005]],"refs":[[0,307,"Công cụ kiểm thử Công cụ này được xây dựng dựa trên việc tích hợp giải thuật đã đề xuất ở trên và tích hợp thêm hai giải thuật để so sánh, việc so sánh dựa trên độ đo BLEUS, chi tiết về cách thực hiện sẽ trình bày ở phần sau"]]},"height":841.92},"page9":{},"page8":{},"page7":{},"page21":{"190":{"boxes":[[143.78,486.7626399999999,234.77,14.346720000000005],[119.06,510.2826399999999,422.82368000000014,14.346720000000005],[99.264,528.2826399999999,79.91599999999998,14.346720000000005]],"refs":[[0,156,"Một số hệ thống tóm tắt văn bản tiêu biểu Hiện tại, trên thế giới đã có rất nhiều nghiên cứu và dự án xây dựng các ứng dụng tóm tắt văn bản"]]},"191":{"boxes":[[185.54336,528.2826399999999,349.75376000000006,14.346720000000005]],"refs":[[0,157,"Các ứng dụng này có thể đáp ứng rất nhiều các mục đích khác nhau"]]},"192":{"boxes":[[99.264,546.16264,341.206,14.346720000000005],[117.26,569.9812000000001,424.62944000000016,14.528159999999957],[135.26,588.0426399999999,351.54992,14.346720000000005]],"refs":[[0,158,"Có thể kể ra một số ứng dụng Tóm tắt văn bản tiêu biểu như sau: SUMMARIST: Một hệ thống Trích rút văn bản năm thứ tiếng (tiếng Anh, tiếng Nhật, tiếng Tây Ban Nha, tiếng Ả-rập và tiếng Hàn Quốc)"]]},"193":{"boxes":[[495.32464,588.0426399999999,46.57535999999999,14.346720000000005],[135.26,606.0426399999999,406.64023999999995,14.346720000000005],[135.26,623.95264,349.43672000000015,14.346720000000005]],"refs":[[0,159,"Hiện tại SUMMARIST đang nghiên cứu để cải tiến trở thành một hệ thống Tóm lược văn bản và hỗ trợ nhiều ngôn ngữ hơn như tiếng Pháp và Indonesia"]]},"183":{"boxes":[[152.3,57.21263999999999,141.02999999999997,14.346720000000005],[119.06,80.87263999999996,422.8131200000001,14.346720000000005],[99.264,98.75263999999996,442.64176,14.346720000000005],[99.264,116.75263999999996,26.51168,14.346720000000005]],"refs":[[0,149,"Sử dụng so khớp n-gram Phương pháp này được Lin và Hovy đưa ra năm 2002 dựa trên mô hình n-gram của độ đo BLEU (Bilingual Evaluation Understudy [1], độ đo đánh giá kết quả dịch máy)"]]},"194":{"boxes":[[117.26,647.7712,424.64,14.528159999999957],[135.26,665.83264,109.94999999999999,14.346720000000005]],"refs":[[0,160,"SweSUM: Ứng dụng Tóm tắt văn bản đa ngôn ngữ của Học viện công nghệ hoàng gia Thụy Điển"]]},"184":{"boxes":[[132.48368000000002,116.75263999999996,409.4163199999999,14.346720000000005],[99.264,134.63263999999995,234.64600000000002,14.346720000000005],[191.69,158.63263999999995,277.61,14.347680000000025],[119.06,182.51263999999995,54.84,14.346720000000005],[171.26,206.51263999999995,370.64,14.347680000000025],[119.06,230.39263999999994,309.98,14.347680000000025],[116.3,254.75263999999996,25.92,14.346719999999976]],"refs":[[0,150,"Ý tưởng của phương pháp này là so khớp n-gram liên tiếp của bản tóm tắt thủ công và tóm tắt tự động, theo công thức sau: Score=1*Score1+ 2*Score2+ 3*Score3+ 4*Score4 Trong đó: Scorei = Số i-gram trùng nhau/Tổng số i-gram của bản tóm tắt thủ công i là hệ số đánh giá độ quan trọng của các Scorei 2.8.2"]]},"195":{"boxes":[[251.89736,665.83264,290.0026400000001,14.346720000000005],[135.26,683.83264,406.6400000000001,14.346720000000005],[135.26,701.71264,243.15224000000006,14.346720000000005]],"refs":[[0,161,"SweSUM có thể tóm tắt các văn bản có ngôn ngữ vùng Scandinavi như Thụy Điển, Đan Mạch, Na Uy và các ngôn ngữ khác như tiếng Anh, Pháp, Đức, Tây Ban Nha và cả tiếng Iran"]]},"185":{"boxes":[[152.3,254.75263999999996,155.91000000000003,14.346719999999976],[119.06,278.3026399999999,422.80447999999996,14.346720000000005],[99.264,296.3026399999999,442.63623999999993,14.346720000000005],[99.264,314.1826399999999,192.11024000000003,14.346720000000005]],"refs":[[0,151,"Sử dụng các độ đo ROUGE ROUGE(Recall-Oriented Understudy of Gisting Evaluation [2]) cũng được đưa ra bởi Lin, vào năm 2009, đây là tập hợp các độ đo dựa trên mô hình n-gram của BLEU với nhiều cách tính khác nhau"]]},"186":{"boxes":[[297.73760000000004,314.1826399999999,244.16239999999993,14.346720000000005],[99.264,332.18263999999994,229.7924000000001,14.346720000000005]],"refs":[[0,152,"Thường sử dụng nhất là độ đo ROUGE-N, với n là giá trị của mô hình n-gram, n={1,2,3,4}"]]},"187":{"boxes":[[119.06,356.06263999999993,422.83988000000005,14.347680000000025],[99.264,374.06263999999993,427.0196800000001,14.347680000000025]],"refs":[[0,153,"Công thức của độ đo ROUGE-N như sau: Cho R=(r1, r2, ., rn) là tập các tóm tắt mẫu, s là tóm tắt tự động, n(d) là vector biểu diễn mô hình n-gram của văn bản d"]]},"width":595.32,"height":841.92},"page22":{"198":{"boxes":[[409.9474400000001,74.85263999999998,131.9525599999999,14.346720000000005],[135.26,92.75263999999996,295.83656,14.346720000000005]],"refs":[[0,163,"SumUM có thể thực hiện cả chức năng tóm tắt chỉ định và tóm tắt thông tin rất tốt."]]},"199":{"boxes":[[117.26,116.57119999999995,424.6001600000002,14.528160000000014],[135.26,134.63263999999995,221.4197600000001,14.346720000000005]],"refs":[[0,164,"FJCL: Hệ thống Rút trích văn bản tiếng Nhật được phát triển trong phòng nghiên cứu Ikeda của trường đại học Gifu"]]},"210":{"boxes":[[263.9228,469.60263999999995,277.916,14.346720000000005],[135.26,487.60263999999995,29.159999999999968,14.346720000000005]],"refs":[[0,175,"Hiện tại phiên bản mới nhất của MEAD là MEAD v3.07"]]},"200":{"boxes":[[363.62632000000013,134.63263999999995,178.24295999999975,14.346720000000005],[135.26,152.63263999999995,406.51256000000024,14.346720000000005],[135.26,170.51263999999995,320.54744000000005,14.346720000000005]],"refs":[[0,165,"Đây là một hệ thống sử dụng các phương pháp áp dụng cho hệ ngôn ngữ đơn âm tiết (monosyllabic language system) như tiếng Nhật, Hàn Quốc, Trung Quốc và Việt Nam"]]},"211":{"boxes":[[117.26,511.3012,424.6155200000003,14.528159999999957],[135.26,529.48264,314.31080000000003,14.346720000000005]],"refs":[[0,176,"Microsoft Word AutoSummary: Microsoft cũng cài đặt chức năng Trích rút và sinh tiêu đề trong Microsoft Word từ phiên bản Word '97"]]},"201":{"boxes":[[117.26,194.33119999999994,424.63988000000006,14.528160000000014],[135.26,212.39263999999994,25.919999999999987,14.346720000000005]],"refs":[[0,166,"Pertinence Summarizer: Hệ thống tóm tắt tin tức đa ngôn ngữ trực tuyến nổi tiếng"]]},"212":{"boxes":[[456.28408,529.48264,85.61591999999996,14.346720000000005],[135.26,547.3626399999999,406.62847999999997,14.346720000000005],[135.26,565.3626399999999,98.90568000000002,14.346720000000005]],"refs":[[0,177,"Chúng ta có thể thử bằng cách chọn Tools - AutoSummarize trên thanh công cụ (có thể khác tùy vào phiên bản)"]]},"202":{"boxes":[[167.41376,212.39263999999994,374.48623999999995,14.346720000000005],[135.26,230.39263999999994,406.61792000000014,14.346720000000005],[135.26,248.27263999999994,106.43304,14.346719999999976]],"refs":[[0,167,"Hiện tại để thử nghiệm khả năng của mình, Pertinence đã được tích hợp với Google và tóm tắt tự động danh sách tìm kiếm trả về từ Google thông qua câu truy vấn đưa vào"]]},"213":{"boxes":[[241.34552000000002,565.3626399999999,300.54968,14.346720000000005],[135.26,583.2426399999999,159.15000000000003,14.346720000000005]],"refs":[[0,178,"Công cụ này cho phép chúng ta chọn thông số về độ rút gọn, trích rút hay sinh tiêu đề.."]]},"203":{"boxes":[[247.69352,248.27263999999994,294.1232,14.346719999999976],[135.26,266.3026399999999,104.50656000000006,14.346720000000005]],"refs":[[0,168,"Chúng ta có thể thử nghiệm hệ thống này trên trang web: www.pertinence.net"]]},"214":{"boxes":[[119.06,607.2426399999999,422.7125600000002,14.346720000000005],[99.264,625.1526399999999,65.62944,14.346720000000005]],"refs":[[0,179,"Ngoài ra còn các hệ thống Tóm tắt văn bản nổi tiếng khác như ANES hay SUMMONS"]]},"204":{"boxes":[[117.26,290.0011999999999,417.98432,14.528159999999957]],"refs":[[0,169,"MEAD: Nền tảng cho các hệ thống Tóm tắt nhiều văn bản và đa ngôn ngữ"]]},"215":{"boxes":[[171.37344000000002,625.1526399999999,370.5299200000001,14.346720000000005],[99.264,643.1526399999999,165.15751999999998,14.346720000000005]],"refs":[[0,180,"Tuy nhiên tại Việt Nam hiện nay chưa có một nghiên cứu và ứng dụng Tóm tắt văn bản chính thức nào"]]},"205":{"boxes":[[135.26,308.1826399999999,406.64,14.346720000000005],[135.26,326.06263999999993,400.03423999999995,14.346720000000005]],"refs":[[0,170,"Đây là một bộ công cụ xây dựng trên nền Linux và Solaris, sử dụng ngôn ngữ Perl - Một ngôn ngữ có khả năng xử lý văn bản rất linh hoạt và mạnh mẽ"]]},"width":595.32,"206":{"boxes":[[135.26,344.06263999999993,406.53224000000034,14.346720000000005],[135.26,361.9426399999999,400.1600000000001,14.346720000000005]],"refs":[[0,171,"MEAD biểu diễn, lưu trữ dữ liệu ở dạng XML, cung tấp cho chúng ta khung ứng dụng để cài đặt các ứng dụng Tóm tắt văn bản cho ngôn ngữ mà ta muốn"]]},"207":{"boxes":[[135.26,379.9426399999999,406.6241600000001,14.346720000000005],[135.26,397.8226399999999,328.28000000000003,14.346720000000005]],"refs":[[0,172,"Ngoài ra MEAD cũng cung cấp các công cụ để xây dựng các ứng dụng đánh giá hệ thống tóm tắt theo các tiêu chí và các tập mẫu nổi tiếng"]]},"208":{"boxes":[[470.48656000000005,397.8226399999999,71.41367999999989,14.346720000000005],[135.26,415.8226399999999,406.64,14.346720000000005],[135.26,433.7026399999999,406.64,14.346720000000005],[135.26,451.72263999999996,148.47000000000003,14.346720000000005]],"refs":[[0,173,"MEAD được xây dựng bởi các chuyên gia nổi tiếng về Xử lý ngôn ngữ ở khắp nơi trên thế giới dưới sự tài trợ của Chương trình Nghiên cứu Công nghệ thông tin của Tổ chức Khoa học quốc gia Mỹ"]]},"209":{"boxes":[[290.17736,451.72263999999996,251.72263999999996,14.346720000000005],[135.26,469.60263999999995,120.74423999999999,14.346720000000005]],"refs":[[0,174,"MEAD được cung cấp ở dạng mã nguồn mở để nghiên cứu và kế thừa"]]},"height":841.92},"page41":{},"page20":{"180":{"boxes":[[220.24184000000002,637.2726399999999,321.65816000000007,14.346720000000005],[99.264,655.1526399999999,442.63623999999993,14.346720000000005],[99.264,673.1526399999999,178.91143999999997,14.346720000000005]],"refs":[[0,147,"Mặt khác, tóm tắt văn bản còn liên quan đến tỉ lệ nén văn bản, do đó, việc đánh giá bản tóm tắt cần phải quan tâm đến vấn đề này, khi đó độ phức tạp và chi phí đánh giá sẽ tăng cao"],[7,430,"Mặt khác, tóm tắt văn bản còn liên quan đến tỉ lệ nén văn bản, do đó, việc đánh giá bản tóm tắt cần phải quan tâm đến vấn đề này, khi đó độ phức tạp và chi phí đánh giá sẽ tăng cao"]]},"170":{"boxes":[[309.39608000000004,272.3026399999999,232.50391999999994,14.346720000000005],[99.264,290.3026399999999,442.61392,14.346720000000005],[99.264,308.1826399999999,367.996,14.346720000000005]],"refs":[[0,137,"Các đơn vị ngữ liệu được trích rút hay giản lược từ các pha trước được liên kết lại thành đoạn theo thứ tự tiền định của chúng, không thêm bớt từ nối và cũng không sắp xếp lại các đơn vị ngữ liệu"],[7,420,"Các phương pháp trong pha tổng hợp kết quả a) Phương pháp hiển thị phân đoạn Các đơn vị ngữ liệu được trích xuất hay giản lược từ các pha trước được liên kết lại thành đoạn theo đúng thứ tự trong văn bản gốc, không thêm bớt từ nối và cũng không sắp xếp lại"]]},"181":{"boxes":[[119.06,697.3926399999999,356.22992,14.346720000000005]],"refs":[[0,148,"Dưới đây là hai phương pháp đánh giá tự động thường sử dụng: 2.8.1"]]},"171":{"boxes":[[474.4528,308.1826399999999,67.44708000000003,14.346720000000005],[99.264,326.18263999999994,442.61296000000016,14.346720000000005],[99.264,344.06263999999993,442.62016000000017,14.346720000000005],[99.264,362.06263999999993,165.33031999999997,14.346720000000005]],"refs":[[0,138,"Văn bản kết quả của phương pháp này có độ dễ đọc dễ hiểu kém, thậm chí lủng củng về nghĩa vì các đơn vị ngữ liệu được trích rút mắc phải một số lỗi như mập mờ tham chiếu, không có từ nối hoặc là thừa từ và ngữ"],[7,421,"Văn bản kết quả của phương pháp này có độ dễ đọc và dễ hiểu kém, thậm chí lủng củng vì các đơn vị ngữ liệu có thể bị mập mờ tham chiếu, không có từ nối hoặc thừa từ"]]},"173":{"boxes":[[178.82,386.30263999999994,168.17000000000002,14.346720000000005],[119.06,409.9426399999999,422.84,14.346720000000005],[99.264,427.8226399999999,442.63588000000004,14.346720000000005],[99.264,445.84263999999996,442.60864000000004,14.346720000000005],[99.264,463.72263999999996,428.46256000000017,14.346720000000005]],"refs":[[0,140,"Phương pháp hiển thị liên kết Việc hiển thị liên kết là tiếp nhận các đơn vị ngữ liệu đã được trích rút và giản lược từ các pha trước đó, phân tích mối quan hệ về nghĩa của các câu rồi thêm bớt các từ nối, từ dẫn và sắp xếp theo một thứ tự mới dựa vào những gì đã thu thập sao cho thỏa mãn yêu cầu về hiển thị và yêu cầu về độ dễ đọc, dễ hiểu của người dùng"]]},"164":{"boxes":[[448.8124,74.85263999999998,93.08760000000007,14.346720000000005],[99.264,92.75263999999996,275.74040000000014,14.346720000000005]],"refs":[[0,130,"Điều này thường thông qua một từ điển các từ đồng nghĩa (Thesaurus)"]]},"175":{"boxes":[[143.78,488.0826399999999,141.51000000000002,14.346720000000005],[119.06,511.60263999999995,422.83988000000005,14.346720000000005],[99.264,529.60264,256.6618399999999,14.346720000000005]],"refs":[[0,142,"Đánh giá kết quả tóm tắt Đánh giá một bản tóm tắt là một công việc khó bởi không tồn tại một bản tóm tắt lý tưởng cho một (hoặc một tập) văn bản đưa ra"],[7,425,"Các phương pháp đánh giá Đánh giá một bản tóm tắt là một công việc khó bởi không tồn tại một bản tóm tắt lý tưởng cho một (hoặc một tập) văn bản đưa ra"]]},"165":{"boxes":[[117.26,116.93119999999996,207.77000000000004,14.528160000000014],[119.06,140.63263999999995,422.81792000000013,14.346720000000005],[99.264,158.63263999999995,130.82600000000002,14.346720000000005]],"refs":[[0,131,"Phương pháp thay thế bởi đại diện Tư tưởng của phương pháp này là thay thế một ngữ bằng một ngữ khác có ý nghĩa đại diện cho ngữ ban đầu"]]},"176":{"boxes":[[363.29944,529.60264,178.56024000000025,14.346720000000005],[99.264,547.48264,133.62079999999997,14.346720000000005]],"refs":[[0,143,"Hơn nữa, việc đánh giá nội dung tóm tắt cũng rất khó khăn"],[7,426,"Hơn nữa, việc đánh giá nội dung tóm tắt cũng rất khó khăn"]]},"166":{"boxes":[[119.06,182.51263999999995,422.7694400000001,14.346720000000005],[99.264,200.51263999999995,142.15823999999992,14.346720000000005]],"refs":[[0,132,"Ví dụ: Người phát ngôn viên của chính phủ Hoa Kỳ thông báo"]]},"177":{"boxes":[[239.48143999999996,547.48264,302.3859200000002,14.346720000000005],[99.264,565.48264,442.5913599999999,14.346720000000005],[99.264,583.3626399999999,325.8983200000002,14.346720000000005]],"refs":[[0,144,"Trường hợp kết quả là một câu trả lời cho một câu hỏi, ta có thể xác định được câu trả lời đó đúng hay sai, nhưng trong các trường hợp khác, thật khó trả lời liệu đầu ra là phải một kết quả đúng hay không"],[7,427,"Trường hợp kết quả là một câu trả lời cho một câu hỏi, ta có thể xác định được câu trả lời đó đúng hay sai, nhưng trong các trường hợp khác, thật khó trả lời liệu đầu ra là phải một kết quả đúng hay không"]]},"178":{"boxes":[[434.3768800000002,583.3626399999999,107.52311999999978,14.346720000000005],[99.264,601.3626399999999,442.62880000000007,14.346720000000005],[99.264,619.2726399999999,81.836,14.346720000000005]],"refs":[[0,145,"Thực tế luôn có khả năng một hệ thống sinh ra một bản tóm tắt tốt nhưng lại sai khác với bản tóm tắt do người thực hiện"],[7,428,"Thực tế luôn có khả năng một hệ thống sinh ra một bản tóm tắt tốt nhưng lại sai khác với bản tóm tắt do người thực hiện"]]},"179":{"boxes":[[187.33376,619.2726399999999,354.5235200000002,14.346720000000005],[99.264,637.2726399999999,114.73112000000002,14.346720000000005]],"refs":[[0,146,"Bên cạnh đó, khi việc đánh giá được thực hiện bởi con người thì chi phí đánh giá sẽ rất cao"],[7,429,"Bên cạnh đó, khi việc đánh giá được thực hiện bởi con người thì chi phí đánh giá sẽ rất cao"]]},"169":{"boxes":[[178.82,248.75263999999996,186.29000000000002,14.346719999999976],[119.06,272.3026399999999,183.27288000000004,14.346720000000005]],"refs":[[0,136,"Phương pháp hiển thị phân đoạn Đây là phương pháp đơn giản nhất"]]},"width":595.32,"height":841.92},"page42":{},"page40":{},"page29":{"290":{"boxes":[[119.06,290.3026399999999,422.81120000000004,14.346720000000005],[99.264,308.3026399999999,46.90592000000002,14.346720000000005]],"refs":[[0,249,"Đây là công cụ tách từ tự động cho tiếng Việt, mã nguồn mở, được viết bằng ngôn ngữ Java"]]},"291":{"boxes":[[153.36272000000002,308.3026399999999,388.50464000000005,14.346720000000005],[99.264,326.18263999999994,340.606,14.346720000000005]],"refs":[[0,250,"Phiên bản cũ nhất là phiên bản vnTokenizer 2.0 được xây dựng vào năm 2005 khi đó nó mới là một ứng dụng đơn với giao diện đơn giản"]]},"292":{"boxes":[[446.81656000000004,326.18263999999994,95.0685600000001,14.346720000000005],[99.264,344.18263999999994,442.63599999999997,14.346720000000005],[99.264,362.06263999999993,146.77399999999994,14.346720000000005]],"refs":[[0,251,"Để sử dụng trong chương trình lần này, phiên bản mới nhất 4.1.1c, mã nguồn của công cụ được tải tại website của dự án VLSP [6]"]]},"293":{"boxes":[[119.06,386.06263999999993,422.84,14.346720000000005],[99.264,403.9426399999999,442.62112000000013,14.346720000000005],[99.264,421.9426399999999,442.63599999999997,14.346720000000005],[99.264,439.84263999999996,48.470240000000004,14.346720000000005]],"refs":[[0,252,"Công cụ này được xây dựng sử dụng kết hợp từ điển (từ điển tiếng Việt được lấy từ đề tài VLSP) và ngram, trong đó mô hình ngram được huấn luyện sử dụng treebank tiếng Việt (70,000 câu đã được tách từ), treebank là kho ngữ liệu câu được chú giải ngữ pháp"]]},"294":{"boxes":[[119.06,463.84263999999996,422.84,14.346720000000005],[99.264,481.72263999999996,200.65352000000001,14.346720000000005]],"refs":[[0,253,"Với độ chính xác xấp xỉ 97% (theo thống kê của tác giả trên website) là kết quả rất cao so với công cụ tách từ hiện nay"]]},"295":{"boxes":[[119.06,505.72263999999996,422.8400000000001,14.346720000000005],[99.264,523.60264,399.66303999999997,14.346720000000005]],"refs":[[0,254,"Ngoài ra việc tách câu khá đơn giản nhưng cần xử lý các trường hợp nhập nhằng dấu chấm câu và dấu chấm trong từ(trong email, số thập phân, địa chỉ web)"]]},"296":{"boxes":[[506.0032,523.60264,35.873280000000136,14.346720000000005],[99.264,541.60264,442.51480000000015,14.346720000000005],[99.264,559.48264,146.12336,14.346720000000005]],"refs":[[0,255,"Do đó để tiết kiệm thời gian, việc tách câu trong phần này sử dụng luôn modul tách câu trong công cụ VNTokenizer"]]},"298":{"boxes":[[152.3,583.84264,92.91,14.346720000000005],[119.06,607.3626399999999,422.81696000000005,14.346720000000005],[99.264,625.3926399999999,442.60576000000015,14.346720000000005],[99.264,643.2726399999999,442.62688,14.346720000000005],[99.264,661.2726399999999,208.56200000000007,14.346720000000005]],"refs":[[0,258,"nó có ý nghĩa lớn trong một số phương pháp dựa trên dấu hiệu đặc biệt, nhưng trong phương pháp dựa trên tần số từ đang xét thì các từ này làm giảm độ chính xác"]]},"299":{"boxes":[[314.08376000000004,661.2726399999999,227.7999200000001,14.346720000000005],[99.264,679.1526399999999,232.24888000000004,14.346720000000005]],"refs":[[0,259,"Trong giải thuật này chủ yếu dựa trên trọng số từ nên việc loại bỏ từ dừng là rất cần thiết"]]},"300":{"boxes":[[119.06,703.1526399999999,422.84,14.346720000000005],[99.264,721.0326399999999,348.28024,14.346720000000005]],"refs":[[0,260,"Từ dừng sẽ được loại bỏ nhờ một danh sách từ dừng xây dựng sẵn, tham khảo tại [7], sau khi tách từ, các từ xuất hiện trong từ điển từ dừng sẽ bị xóa"]]},"301":{"boxes":[[454.06,721.0326399999999,87.83987999999994,14.346720000000005],[99.264,739.02864,192.14600000000002,14.346720000000005]],"refs":[[0,261,"Dưới đây là một số từ dừng trích trong file sẽ sử dụng"]]},"width":595.32,"height":841.92},"page27":{"width":595.32,"271":{"boxes":[[144.38,82.31035999999993,307.55,15.542279999999991],[119.06,107.51263999999995,422.8020800000001,14.346720000000005],[99.264,125.51263999999995,442.63599999999997,14.346720000000005],[99.264,143.39263999999994,22.318880000000007,14.346720000000005]],"refs":[[0,231,"PHÂN TÍCH MÔ HÌNH THỰC HIỆN BÀI TOÁN Dựa vào các kiến thức về tóm tắt văn bản đã trình bày ở trên, trong phần này em sẽ trình bày chi tiết các kỹ thuật áp dụng trong từng bước của mô hình xử lý đã đề xuất"]]},"height":841.92},"page28":{"280":{"boxes":[[119.06,409.9426399999999,422.82368000000014,14.346720000000005],[99.264,427.8226399999999,442.6153600000001,14.346720000000005],[99.264,445.84263999999996,442.63588000000004,14.346720000000005],[99.264,463.72263999999996,389.11888,14.346720000000005]],"refs":[[0,239,"Việc xử lý từ viết tắt không đơn giản là phát hiện các từ trong ngoặc, tùy từng loại văn bản của chuyên ngành nào đó, các từ viết tắt vẫn được sử dụng mà không gây hiểu lầm cho người đọc, vì trong các lĩnh vực ấy nó chỉ có thể thay thế cho cụm từ cố định nào đó, hoặc do thói quen, sử dụng nhiều thì mọi người đều biết"]]},"281":{"boxes":[[119.06,487.72263999999996,345.32,14.346720000000005],[119.06,511.60263999999995,422.80448000000007,14.346720000000005],[99.264,529.60264,436.03600000000006,14.346720000000005]],"refs":[[0,240,"Ví dụ: UBND thường được dùng thay thế cho Ủy ban nhân dân Trong giải thuật này chỉ xử lý các cụm từ viết tắt chữ đầu trong ngoặc đơn, còn các trường hợp khác do chưa xây dựng được bộ dữ liệu cụ thể nên không xét đến"]]},"282":{"boxes":[[99.264,547.48264,238.32680000000005,14.346720000000005]],"refs":[[0,241,"Các cụm từ trong ngoặc đơn khác sẽ bị xóa đi"]]},"284":{"boxes":[[152.3,571.84264,99.87,14.346720000000005],[119.06,595.3626399999999,422.80544000000003,14.346720000000005],[99.264,613.3926399999999,442.61055999999996,14.346720000000005],[99.264,631.2726399999999,276.52888,14.346720000000005]],"refs":[[0,243,"Tách câu, tách từ Trong tiếng Việt, dấu cách (space) không được sử dụng như 1 kí hiệu phân tách từ, nó chỉ có ý nghĩa phân tách các âm tiết với nhau, có khoảng 70% các từ gồm 2 âm tiết, và 14% các từ gồm 3 âm tiết, còn lại là 1 âm tiết"]]},"285":{"boxes":[[382.37656000000004,631.2726399999999,159.48023999999998,14.346720000000005],[99.264,649.2726399999999,276.48584000000017,14.346720000000005]],"refs":[[0,244,"Hơn nữa, việc kết hợp các âm tiết có nhiều cách, mỗi cách cho một nghĩa khác nhau"]]},"275":{"boxes":[[146.66,81.23263999999998,64.35000000000002,14.346720000000005],[117.26,104.93119999999996,112.11,14.528160000000014],[119.06,128.75263999999996,422.71256000000045,14.346720000000005],[99.264,146.63263999999995,442.63599999999997,14.346720000000005],[99.264,164.63263999999995,442.50088000000017,14.346720000000005],[99.264,182.51263999999995,357.07023999999996,14.346720000000005]],"refs":[[0,234,"Chuẩn hóa Xử lý câu tiêu đề Câu tiêu đề của một văn bản (nếu có) thường mang nội dung chính trình bày trong văn bản, do đó các từ khóa trong đó cũng được dùng để phát hiện tóm tắt (một số giải thuật còn tăng trọng số cho những từ xuất hiện trong tiêu đề), nhưng không đưa câu tiêu đề vào kết quả tóm tắt, nên cần phát hiện để loại bỏ khỏi kết quả"]]},"286":{"boxes":[[381.9965600000002,649.2726399999999,159.88088,14.346720000000005],[99.264,667.1526399999999,442.63599999999997,14.346720000000005],[99.264,685.1526399999999,22.318880000000007,14.346720000000005]],"refs":[[0,245,"Vì thế, để xử lý tiếng Việt, bài toán tách từ (word segmentation) là 1 trong những bài toán cơ bản và quan trọng bậc nhất"]]},"276":{"boxes":[[462.92368,182.51263999999995,78.97631999999999,14.346720000000005],[99.264,200.51263999999995,436.1272,14.346720000000005]],"refs":[[0,235,"Việc phát hiện câu tiêu đề có thể dựa vào dấu hiệu câu tiêu đề là câu duy nhất của đoạn đầu tiên"]]},"287":{"boxes":[[128.42,685.1526399999999,413.45216000000005,14.346720000000005],[99.264,703.0326399999999,442.63599999999997,14.346720000000005],[99.264,721.0326399999999,292.21240000000006,14.346720000000005]],"refs":[[0,247,"do đó vấn đề này nhận được sự quan tâm rộng rãi và có nhiều hướng tiếp cận khác nhau"],[0,246,"Ngoài tiếng Việt, có khá nhiều các ngôn ngữ châu Á khác cũng cần bước tách từ, ví dụ như: tiếng Nhật, tiếng Trung, tiếng Hàn,"]]},"277":{"boxes":[[99.264,218.39263999999994,442.63588000000004,14.346720000000005],[99.264,236.39263999999994,205.82167999999996,14.346720000000005]],"refs":[[0,236,"Trong giải thuật này chỉ sử dụng câu tiêu đề như câu thông thường, sau đó loại khỏi kết quả (nếu nó được chọn vào kết quả)"]]},"278":{"boxes":[[117.26,260.48119999999994,180.51,14.528159999999957],[119.06,284.3026399999999,422.84,14.346720000000005],[99.264,302.1826399999999,442.6148800000001,14.346720000000005],[99.264,320.18263999999994,95.75599999999999,14.346720000000005]],"refs":[[0,237,"Xử lý các cụm từ trong ngoặc Các cụm từ trong ngoặc có thể là chú thích hoặc viết tắt của cụm từ nào đó, nếu là chú thích thì có thể bỏ qua còn từ viết tắt thì khá quan trọng, nhất là đối với tóm tắt hướng truy vấn"]]},"279":{"boxes":[[119.06,344.06263999999993,412.04,14.346720000000005],[119.06,368.06263999999993,422.8044800000002,14.346720000000005],[99.264,385.9426399999999,354.38776000000007,14.346720000000005]],"refs":[[0,238,"Ví dụ: Sinh viên tình nguyện(SVTN) đi đến các vùng sâu để giúp đỡ đồng bào Các câu sau câu này sẽ sử dụng cụm từ SVTN, nếu truy vấn có từ khóa sinh viên tình nguyện thì các câu sử dụng từ viết tắt sẽ không được quan tâm"]]},"width":595.32,"height":841.92},"page25":{"260":{"boxes":[[349.62280000000004,302.1826399999999,192.22200000000004,14.346720000000005],[99.264,320.06263999999993,442.60720000000015,14.346720000000005],[99.264,338.06263999999993,75.30704000000001,14.346720000000005]],"refs":[[0,222,"Nhưng không phải từ nào trong các câu đó cũng đều quan trọng nên các từ xuất hiện trong truy vấn gốc được nhân lên một trọng số"]]},"261":{"boxes":[[180.97328000000005,338.06263999999993,360.92671999999993,14.346720000000005],[99.264,355.9426399999999,236.32600000000002,14.346720000000005]],"refs":[[0,223,"Do đó kết quả tóm tắt sẽ ưu tiên các từ khóa trong truy vấn, và các từ khóa xuất hiện nhiều trong các câu được chọn"]]},"262":{"boxes":[[341.81080000000003,355.9426399999999,200.05656000000005,14.346720000000005],[99.264,373.9426399999999,243.64600000000002,14.346720000000005]],"refs":[[0,224,"Theo đó thì bản tóm tắt sẽ dễ hiểu hơn vì bao gồm các thông tin liên quan tới truy vấn"]]},"263":{"boxes":[[119.06,397.8226399999999,174.99,14.346720000000005],[117.26,422.0012,66.36,14.528159999999957],[117.26,445.5412,424.58864000000017,14.528159999999957],[135.26,463.72263999999996,406.61264000000017,14.346720000000005],[135.26,481.60263999999995,88.71000000000001,14.346720000000005]],"refs":[[0,225,"Tổng quan về modul đó như sau: Đầu vào - Văn bản: văn bản đầu vào sử dụng bộ mã Unicode utf-8, chỉ chứa text, chính xác về chính tả, dấu câu, không quá ngắn(5 câu trở lên), nội dung phải liên quan tới truy vấn"]]},"253":{"boxes":[[374.3183200000001,56.85263999999998,167.5816799999999,14.346720000000005],[99.264,74.85263999999998,80.15023999999998,14.346720000000005]],"refs":[[0,215,"Do đó có một số ràng buộc với dữ liệu đầu vào"]]},"264":{"boxes":[[117.26,505.4212,424.6342400000001,14.528159999999957],[135.26,523.48264,402.20000000000005,14.346720000000005],[117.26,547.3012,424.64,14.528159999999957],[135.26,565.3626399999999,49.67135999999999,14.346720000000005]],"refs":[[0,226,"- Truy vấn: sử dụng bộ mã như văn bản, là một đoạn văn bản chứa các từ khóa cần tìm kiếm, nếu cần chính xác thì dùng dấu phảy để ngăn cách các từ khóa - Độ rút gọn: có thể là số lượng từ (100-150 từ) hoặc phần trăm văn bản nguồn (10-20%)"]]},"254":{"boxes":[[119.06,98.75263999999996,422.84,14.346720000000005],[99.264,116.75263999999996,113.59664,14.346720000000005]],"refs":[[0,216,"Vì văn bản đã được máy tìm kiếm lựa chọn nên nội dung của văn bản và truy vấn sẽ liên quan với nhau"]]},"255":{"boxes":[[220.17008,116.75263999999996,321.66272000000026,14.346720000000005],[99.264,134.63263999999995,442.63599999999997,14.346720000000005],[99.264,152.63263999999995,176.26711999999998,14.346720000000005]],"refs":[[0,217,"Do đó các câu chứa nhiều từ khóa trong truy vấn, hay trong trường hợp này là độ tương đồng lớn, sẽ mang các thông tin quan trọng liên quan đến truy vấn mà người dùng quan tâm"]]},"256":{"boxes":[[281.89448,152.63263999999995,260.00552,14.346720000000005],[99.264,170.51263999999995,442.6259200000002,14.346720000000005],[99.264,188.51263999999995,244.70968000000005,14.346720000000005]],"refs":[[0,218,"Tuy nhiên trong vấn đề tìm kiếm, phần lớn người dùng thường không nắm rõ được nội dung mình muốn biết nên mới sử dụng tìm kiếm, mà chỉ biết các từ khóa liên quan tới vấn đề đó"]]},"257":{"boxes":[[350.5573600000001,188.51263999999995,191.32344000000006,14.346720000000005],[99.264,206.39263999999994,385.61728,14.346720000000005]],"refs":[[0,219,"Ví dụ như tìm kiếm thông tin về giá vàng, người ta không biết giá vàng tăng hay giảm, có biến động gì gần đây"]]},"258":{"boxes":[[490.8688,206.39263999999994,51.01152000000019,14.346720000000005],[99.264,224.39263999999994,442.5673600000001,14.346720000000005],[99.264,242.27263999999994,442.63599999999997,14.346719999999976],[99.264,260.3026399999999,150.47095999999993,14.346720000000005]],"refs":[[0,220,"Hoặc tìm cách sửa một lỗi máy tính thì người dùng sẽ đưa ra các thông tin về lỗi đó, sau khi xem bản tóm tắt của các kết quả từ máy tìm kiếm, sẽ biết được kết quả nào phù hợp để quyết định đọc hay không"]]},"259":{"boxes":[[119.06,284.1826399999999,422.84,14.346720000000005],[99.264,302.1826399999999,243.166,14.346720000000005]],"refs":[[0,221,"Trong giải thuật chọn câu, các câu được chọn sẽ được thêm vào truy vấn, với mục đích làm thêm từ khóa liên quan đến truy vấn"]]},"width":595.32,"height":841.92},"page26":{"267":{"boxes":[[117.26,134.45119999999994,146.55,14.528160000000014],[104.9,158.63263999999995,366.1923200000001,14.346720000000005]],"refs":[[0,228,"Đầu ra: văn bản tóm tắt Chi tiết các kỹ thuật sử dụng trong các bước sẽ trình bày ở phần sau"]]},"width":595.32,"height":841.92},"page23":{"230":{"boxes":[[119.06,602.68264,422.8515200000001,14.346720000000005],[99.264,620.71264,65.396,14.346720000000005]],"refs":[[0,194,"Sau khi xây dựng đồ thị cho mỗi câu, chúng sẽ được kết hợp để tạo đồ thị cho toàn văn bản"]]},"231":{"boxes":[[170.76416,620.71264,371.11376,14.346720000000005],[99.264,638.59264,58.31887999999999,14.346720000000005]],"refs":[[0,195,"Một thuật toán tìm kiếm sẽ được sử dụng để tìm các câu quan trọng đưa vào tóm tắt"]]},"221":{"boxes":[[143.78,166.31264000000002,129.87000000000003,14.346720000000005],[119.06,189.95264,422.8347200000001,14.346720000000005],[99.264,207.83264,312.04600000000005,14.346720000000005]],"refs":[[0,185,"Ứng dụng của bài toán Tóm tắt hướng truy vấn thường sử dụng trong việc tóm tắt kết quả trả về của máy tìm kiếm thông tin, hoặc trong các hệ thống hỏi đáp tự động"]]},"232":{"boxes":[[164.16656,638.59264,163.38344,14.346720000000005],[135.26,662.4112,406.6188800000002,14.528159999999957],[153.26,680.47264,212.09000000000003,14.346720000000005]],"refs":[[0,196,"Có 3 giải thuật có thể áp dụng: - Dựa trên tâm các đồ thị: một đồ thị trung tâm cho tất cả văn bản được xây dựng, tích hợp thêm đồ thị của truy vấn"]]},"222":{"boxes":[[119.06,231.83264,422.83088000000004,14.346720000000005],[99.264,249.71264,442.5928000000001,14.346719999999976],[99.264,267.74263999999994,143.18887999999998,14.346720000000005]],"refs":[[0,186,"Hiện nay, đối với máy tìm kiếm, hệ thống sẽ tóm tắt văn bản theo tóm tắt đơn văn bản thông thường, lưu vào cơ sở dữ liệu, và thực hiện tìm kiếm trên bản tóm tắt đó để giảm thời gian tìm kiếm"]]},"223":{"boxes":[[249.2828,267.74263999999994,292.61719999999997,14.346720000000005],[99.264,285.62263999999993,393.67024,14.346720000000005]],"refs":[[0,187,"Sau khi xác định được văn bản phù hợp, văn bản đó sẽ được tóm tắt lại theo truy vấn người dùng để đưa ra hiển thị kèm với kết quả"]]},"224":{"boxes":[[499.17376,285.62263999999993,42.72623999999996,14.346720000000005],[99.264,303.62263999999993,442.62016000000006,14.346720000000005],[99.264,321.50263999999993,442.63264000000015,14.346720000000005],[99.264,339.50263999999993,442.6360000000001,14.346720000000005],[99.264,357.3826399999999,281.20888,14.346720000000005]],"refs":[[0,188,"Đối với hệ thống hỏi đáp tự động, hệ thống sẽ tiến hành phân loại câu hỏi và thực hiện so khớp hoặc tính tương đồng với câu hỏi trong cơ sở dữ liệu để xác định câu trả lời phù hợp nhất, sau đó tóm tắt văn bản chứa câu trả lời, sử dụng câu trả lời như truy vấn, và hiển thị kèm với câu trả lời, có đánh dấu câu trả lời"]]},"225":{"boxes":[[119.06,381.3826399999999,422.84,14.346720000000005],[99.264,399.2626399999999,442.63599999999997,14.346720000000005],[99.264,417.2626399999999,244.726,14.346720000000005],[107.78,441.5226399999999,16.200000000000003,14.346720000000005]],"refs":[[0,189,"Tóm lại, tóm tắt hướng truy vấn thường được tích hợp ở giai đoạn xử lý kết quả của hệ thống tìm kiếm thông tin và hỏi đáp tự động, mục đích là thêm thông tin để kết quả rõ ràng và dễ hiểu hơn với người dùng 3.3"]]},"226":{"boxes":[[143.78,441.5226399999999,178.73,14.346720000000005],[116.3,465.5226399999999,25.92,14.346720000000005]],"refs":[[0,190,"Một số hướng tiếp cận phổ biến 3.3.1"]]},"227":{"boxes":[[152.3,465.5226399999999,88.71000000000001,14.346720000000005],[119.06,489.04263999999995,422.83988000000005,14.346720000000005],[99.264,507.0426399999999,99.986,14.346720000000005]],"refs":[[0,191,"Dựa trên đồ thị Phương pháp này được đưa ra bởi [3] Jagadeesh và đồng sự, áp dụng cho tóm tắt trích rút đa văn bản"]]},"width":595.32,"228":{"boxes":[[205.58744000000002,507.0426399999999,336.30056000000013,14.346720000000005],[99.264,524.92264,442.63023999999996,14.346720000000005],[99.264,542.92264,379.7005600000001,14.346720000000005]],"refs":[[0,192,"Đồ thị của văn bản sẽ được xây dựng dựa trên việc phân tích các câu trong đó để tìm ra các cụm danh từ(noun phrases), sau đó phân tích các cụm danh từ này để tìm ra mối quan hệ giữa các danh từ sử dụng các hàm heuristic"]]},"218":{"boxes":[[140.9,56.97035999999991,343.06999999999994,15.542279999999998],[107.78,82.55263999999991,16.200000000000003,14.346720000000005]],"refs":[[0,182,"BÀI TOÁN TÓM TẮT VĂN BẢN HƯỚNG TRUY VẤN 3.1"]]},"229":{"boxes":[[485.54824000000013,542.92264,56.33832000000001,14.346720000000005],[99.264,560.8026399999999,442.60911999999996,14.346720000000005],[99.264,578.8026399999999,391.03168,14.346720000000005]],"refs":[[0,193,"Đồ thị thu được sẽ bao gồm 2 dạng nút, nút thành phần(là các danh từ trích rút từ văn bản) và nút liên kết, có 2 loại nút liên kết là isa(là một) và related_to(liên quan với)"]]},"219":{"boxes":[[143.78,82.55263999999991,65.07000000000002,14.346720000000005],[119.06,106.19264000000001,422.82368,14.346720000000005],[99.264,124.07264,442.62256000000014,14.346720000000005],[99.264,142.07264,322.9525600000001,14.346720000000005]],"refs":[[0,183,"Định nghĩa Theo định nghĩa ở trên, tóm tắt văn bản hướng truy vấn là một dạng tóm tắt văn bản (khi phân chia theo mục đích tóm tắt), điểm đặc trưng là ở giai đoạn tiền xử lý, việc tính toán sẽ phụ thuộc một phần vào truy vấn người dùng"]]},"height":841.92},"page24":{"250":{"boxes":[[469.42,643.1526399999999,72.44639999999998,14.346720000000005],[99.264,661.1526399999999,442.63599999999997,14.346720000000005],[99.264,679.0326399999999,442.61968000000013,14.346720000000005],[99.264,697.0326399999999,104.41760000000001,14.346720000000005]],"refs":[[0,213,"Phương pháp này dựa theo ý tưởng ở giải thuật thứ 2 trong hướng tiếp cận dựa trên đồ thị đã nêu ở trên, nhưng các câu ở đây biểu diễn theo mô hình không gian vector và độ tương đồng sử dụng độ đo cosin"]]},"251":{"boxes":[[119.06,720.9126399999999,422.84023999999994,14.346720000000005],[99.264,738.9086399999999,439.27599999999995,14.346720000000005]],"refs":[[0,214,"Phạm vi ứng dụng hướng tới của mô hình là tích hợp vào modul trả kết quả của bộ máy tìm kiếm văn bản(search engine), thực hiện tóm tắt văn bản kết quả theo tập từ khóa đã tìm kiếm(chính là truy vấn người dùng)"]]},"241":{"boxes":[[152.3,296.5426399999999,227.93,14.346720000000005],[119.06,320.18263999999994,422.83988000000005,14.346720000000005],[99.264,338.06263999999993,102.146,14.346720000000005]],"refs":[[0,204,"Dựa trên tần số từ và độ tương đồng câu Phương pháp này trình bày bởi Siva kumar và đồng sự [5] áp dụng cho tóm tắt trích rút đa văn bản"]]},"242":{"boxes":[[208.22696000000002,338.06263999999993,333.53888000000023,14.346720000000005],[99.264,356.06263999999993,442.63588000000004,14.346720000000005],[99.264,373.9426399999999,216.98888,14.346720000000005]],"refs":[[0,205,"Trước tiên các văn bản sẽ được biểu diễn trong mô hình không gian vector, mỗi câu được tính khoảng cách với câu truy vấn, sau đó sử dụng thuật toán phân cụm, chia các câu vào các cụm"]]},"243":{"boxes":[[323.11,373.9426399999999,218.79000000000008,14.346720000000005],[99.264,391.9426399999999,442.55536000000006,14.346720000000005],[99.264,409.8226399999999,215.42888,14.346720000000005]],"refs":[[0,206,"Mỗi câu được tính điểm số vị trí và điểm số độ quan trọng trong cụm, sau đó từ các cụm có điểm số cao nhất, trích rút ra các câu có điểm số cao nhất tạo thành tóm tắt"]]},"245":{"boxes":[[143.78,434.2026399999999,223.13000000000002,14.346720000000005],[119.06,457.72263999999996,422.82656000000014,14.346720000000005],[99.264,475.72263999999996,442.63588000000004,14.346720000000005],[99.264,493.60263999999995,442.6038400000001,14.346720000000005],[99.264,511.60263999999995,442.61968000000013,14.346720000000005],[99.264,529.48264,296.20023999999995,14.346720000000005]],"refs":[[0,208,"Đề xuất hướng giải quyết cho tiếng Việt Qua tìm hiểu về các vấn đề liên quan trong tóm tắt và đặc trưng của tiếng Việt, dễ nhận thấy rằng việc tiếp cận ở mức cú pháp và ngữ nghĩa là khá khó khăn, một phần là vì công cụ và dữ liệu hỗ trợ, tuy đã có một số công cụ gán nhãn từ vựng và phân tích cú pháp cho độ chính xác cao nhưng thường chỉ áp dụng cho lĩnh vực hẹp, và còn ở mức nghiên cứu, chưa được công bố chính thức"]]},"246":{"boxes":[[402.06088,529.48264,139.83911999999998,14.346720000000005],[99.264,547.48264,392.71888,14.346720000000005]],"refs":[[0,209,"Mặt khác, do đặc trưng về ngữ pháp nên các hướng tiếp cận đó thường không chính xác với tiếng Việt"]]},"236":{"boxes":[[152.3,158.99263999999997,160.23000000000002,14.346720000000005],[119.06,182.51263999999995,209.44423999999998,14.346720000000005]],"refs":[[0,199,"Dựa trên cấu trúc diễn ngôn Phương pháp này được trình bày bởi W"]]},"247":{"boxes":[[119.06,571.3626399999999,422.83988000000005,14.346720000000005],[99.264,589.3626399999999,442.63120000000015,14.346720000000005],[99.264,607.2426399999999,40.79600000000001,14.346720000000005]],"refs":[[0,210,"Do đó em xin đề xuất mô hình trích rút các câu quan trọng cho bài toán tóm tắt hướng truy vấn dựa trên tần số từ và độ tương đồng câu, áp dụng cho tóm tắt đơn văn bản"]]},"237":{"boxes":[[335.33416,182.51263999999995,206.54520000000014,14.346720000000005],[99.264,200.51263999999995,401.35600000000005,14.346720000000005]],"refs":[[0,200,"Bosma [4], mục đích là tạo ra bản tóm tắt ngắn gọn chứa câu trả lời để đưa ra kết quả trong hệ thống hỏi đáp tự động"]]},"248":{"boxes":[[146.74736000000001,607.2426399999999,395.1152,14.346720000000005],[99.264,625.2726399999999,442.61968000000024,14.346720000000005],[99.264,643.1526399999999,84.47887999999999,14.346720000000005]],"refs":[[0,211,"Mô tả sơ lược như sau: Đầu tiên sử dụng câu truy vấn làm tâm tóm tắt, sau đó tìm câu có độ tương đồng với tâm lớn nhất, mỗi câu được chọn sẽ kết hợp với tâm tạo nên tâm mới"]]},"238":{"boxes":[[506.98336000000006,200.51263999999995,34.91424000000006,14.346720000000005],[99.264,218.39263999999994,442.6192000000001,14.346720000000005],[99.264,236.39263999999994,435.97936000000004,14.346720000000005]],"refs":[[0,201,"Trong đó mỗi văn bản được biểu diễn bởi đồ thị có trọng số dựa trên lý thuyết diễn ngôn, mỗi đỉnh đại diện cho một câu, trọng số trên mỗi cạnh là khoảng cách giữa hai câu"]]},"249":{"boxes":[[190.22288,643.1526399999999,272.71136,14.346720000000005]],"refs":[[0,212,"Sau khi kết thúc sẽ loại bỏ câu truy vấn khỏi kết quả"]]},"width":595.32,"239":{"boxes":[[99.264,254.27263999999994,442.63599999999997,14.346719999999976],[99.264,272.3026399999999,303.40888,14.346720000000005]],"refs":[[0,202,"Một thuật toán tìm kiếm đồ thị sẽ được sử dụng để chọn ra các câu có tổng trọng số trên đường đi tới câu trả lời(vai trò như truy vấn) nhỏ nhất"]]},"height":841.92}},"res":{"r":63.84439468383789,"s":[{"saved_path":"temp/9.txt","r":96.11296081542969,"s":[[280,239,1,73,0,72,0,72,"Việc xử lý từ viết tắt không đơn giản là phát hiện các từ trong ngoặc, tùy từng loại văn bản của chuyên ngành nào đó, các từ viết tắt vẫn được sử dụng mà không gây hiểu lầm cho người đọc, vì trong các lĩnh vực ấy nó chỉ có thể thay thế cho cụm từ cố định nào đó, hoặc do thói quen, sử dụng nhiều thì mọi người đều biết","Việc xử lý từ viết tắt không đơn giản là phát hiện các từ trong ngoặc, tùy từng loại văn bản của chuyên ngành nào đó, các từ viết tắt vẫn được sử dụng mà không gây hiểu lầm cho người đọc, vì trong các lĩnh vực ấy nó chỉ có thể thay thế cho cụm từ cố định nào đó, hoặc do thói quen, sử dụng nhiều thì mọi người đều biết"],[366,321,1,44,0,43,0,43,"Liên quan đến các vấn đề kinh tế - xã hội, Chủ tịch nước Trương Tấn Sang cho biết kinh tế nước nhà có những phát triển đáng kể, nông nghiệp đạt nhiều thắng lợi, các ngành thuộc về dầu khí tăng trưởng khá{12}","Liên quan đến các vấn đề kinh tế - xã hội, Chủ tịch nước Trương Tấn Sang cho biết kinh tế nước nhà có những phát triển đáng kể, nông nghiệp đạt nhiều thắng lợi, các ngành thuộc về dầu khí tăng trưởng khá{12}"],[192,158,0.9638554453849792,40,0,41,0,40,"Có thể kể ra một số ứng dụng Tóm tắt văn bản tiêu biểu như sau:  SUMMARIST: Một hệ thống Trích rút văn bản năm thứ tiếng (tiếng Anh, tiếng Nhật, tiếng Tây Ban Nha, tiếng Ả-rập và tiếng Hàn Quốc)","Có thể kể ra một số ứng dụng Tóm tắt văn bản tiêu biểu như sau: SUMMARIST: Một hệ thống Trích rút văn bản năm thứ tiếng (tiếng Anh, tiếng Nhật, tiếng Tây Ban Nha, tiếng Ả-rập và tiếng Hàn Quốc)"],[193,159,1,30,0,29,0,29,"Hiện tại SUMMARIST đang nghiên cứu để cải tiến trở thành một hệ thống Tóm lược văn bản và hỗ trợ nhiều ngôn ngữ hơn như tiếng Pháp và Indonesia","Hiện tại SUMMARIST đang nghiên cứu để cải tiến trở thành một hệ thống Tóm lược văn bản và hỗ trợ nhiều ngôn ngữ hơn như tiếng Pháp và Indonesia"],[195,161,1,37,0,36,0,36,"SweSUM có thể tóm tắt các văn bản có ngôn ngữ vùng Scandinavi như Thụy Điển, Đan Mạch, Na Uy và các ngôn ngữ khác như tiếng Anh, Pháp, Đức, Tây Ban Nha và cả tiếng Iran","SweSUM có thể tóm tắt các văn bản có ngôn ngữ vùng Scandinavi như Thụy Điển, Đan Mạch, Na Uy và các ngôn ngữ khác như tiếng Anh, Pháp, Đức, Tây Ban Nha và cả tiếng Iran"],[90,58,0.9714285731315613,68,0,70,0,68,"Các chỉ số sử dụng trong phương pháp này:  Tần suất thuật ngữ của một từ w trong một văn bản d, ký hiệu TF(w,d), có thể sử dụng các công thức sau, với fij là số lần xuất hiện của từ wi trong văn bản dj:  Tần suất văn bản của một từ w, ký hiệu DF(w) là số lượng văn bản mà từ w có xuất hiện","Các chỉ số sử dụng trong phương pháp này: Tần suất thuật ngữ của một từ w trong một văn bản d, ký hiệu TF(w,d), có thể sử dụng các công thức sau, với fij là số lần xuất hiện của từ wi trong văn bản dj: Tần suất văn bản của một từ w, ký hiệu DF(w) là số lượng văn bản mà từ w có xuất hiện"],[320,280,1,49,0,48,0,48,"Cụ thể mỗi từ tần số của mỗi từ wi trong câu sj được tính như sau: Trong đó: fij là số lần xuất hiện của từ ti trong câu sj, m là tổng số câu trong văn bản hi là tổng số câu mà từ ti xuất hiện","Cụ thể mỗi từ tần số của mỗi từ wi trong câu sj được tính như sau: Trong đó: fij là số lần xuất hiện của từ ti trong câu sj, m là tổng số câu trong văn bản hi là tổng số câu mà từ ti xuất hiện"],[160,127,0.9830508232116699,29,1,29,0,28," Phương pháp thay thế ngữ tương đương Tư tưởng của phương pháp này là các ngữ đóng vai trò như nhau trong câu được thay bằng một ngữ chung","Phương pháp thay thế ngữ tương đương Tư tưởng của phương pháp này là các ngữ đóng vai trò như nhau trong câu được thay bằng một ngữ chung"],[239,202,1,33,0,32,0,32,"Một thuật toán tìm kiếm đồ thị sẽ được sử dụng để chọn ra các câu có tổng trọng số trên đường đi tới câu trả lời(vai trò như truy vấn) nhỏ nhất","Một thuật toán tìm kiếm đồ thị sẽ được sử dụng để chọn ra các câu có tổng trọng số trên đường đi tới câu trả lời(vai trò như truy vấn) nhỏ nhất"],[41,10,0.7191011309623718,32,0,33,0,32,"Các tiêu chí đánh giá  Độ mạch lạc (Coherence): đánh giá mức độ rõ ràng của văn bản tóm tắt, tính súc tích, khả năng có thể đọc và hiểu được của bài viết\u2026  Độ hàm chứa thông tin (Informationess): tỉ lệ thông tin của văn bản gốc trong văn bản tóm tắt","Các tiêu chí đánh giá Độ mạch lạc (Coherence): đánh giá mức độ rõ ràng của văn bản tóm tắt, tính súc tích, khả năng có thể đọc và hiểu được của bài viết"],[53,22,1,35,0,34,0,34,"Phân loại tóm tắt văn bản Có nhiều cách phân loại tóm tắt, phụ thuộc vào tiêu chí sử dụng để phân loại, sau đây là một số cách phân loại cần quan tâm: 2.4.1","Phân loại tóm tắt văn bản Có nhiều cách phân loại tóm tắt, phụ thuộc vào tiêu chí sử dụng để phân loại, sau đây là một số cách phân loại cần quan tâm: 2.4.1"],[207,172,1,31,0,30,0,30,"Ngoài ra MEAD cũng cung cấp các công cụ để xây dựng các ứng dụng đánh giá hệ thống tóm tắt theo các tiêu chí và các tập mẫu nổi tiếng","Ngoài ra MEAD cũng cung cấp các công cụ để xây dựng các ứng dụng đánh giá hệ thống tóm tắt theo các tiêu chí và các tập mẫu nổi tiếng"],[284,243,1,56,0,55,0,55,"Tách câu, tách từ Trong tiếng Việt, dấu cách (space) không được sử dụng như 1 kí hiệu phân tách từ, nó chỉ có ý nghĩa phân tách các âm tiết với nhau, có khoảng 70% các từ gồm 2 âm tiết, và 14% các từ gồm 3 âm tiết, còn lại là 1 âm tiết","Tách câu, tách từ Trong tiếng Việt, dấu cách (space) không được sử dụng như 1 kí hiệu phân tách từ, nó chỉ có ý nghĩa phân tách các âm tiết với nhau, có khoảng 70% các từ gồm 2 âm tiết, và 14% các từ gồm 3 âm tiết, còn lại là 1 âm tiết"],[285,244,1,18,0,17,0,17,"Hơn nữa, việc kết hợp các âm tiết có nhiều cách, mỗi cách cho một nghĩa khác nhau","Hơn nữa, việc kết hợp các âm tiết có nhiều cách, mỗi cách cho một nghĩa khác nhau"],[311,272,0.9850746393203735,99,0,100,0,99,"Trong mô hình lần này, do chỉ xử lý ở mức nông, nên không xét đến các vấn đề ở mức cú pháp và ngữ nghĩa, nhưng để tăng độ chính xác, bài toán sẽ sử dụng việc đồng nhất các từ đồng nghĩa(xử lý chung cho cả 3 loại trên) dựa trên từ điển đồng nghĩa thô xây dựng sẵn, bộ từ điển này gồm gần 2800 mục, xây dựng bằng cách dùng công cụ tải các trang của từ điển Việt \u2013 Việt tại trang tratu.soha.vn, sau đó tách thẻ có chứa các từ đồng nghĩa rồi ghép lại","Trong mô hình lần này, do chỉ xử lý ở mức nông, nên không xét đến các vấn đề ở mức cú pháp và ngữ nghĩa, nhưng để tăng độ chính xác, bài toán sẽ sử dụng việc đồng nhất các từ đồng nghĩa(xử lý chung cho cả 3 loại trên) dựa trên từ điển đồng nghĩa thô xây dựng sẵn, bộ từ điển này gồm gần 2800 mục, xây dựng bằng cách dùng công cụ tải các trang của từ điển Việt Việt tại trang tratu.soha.vn, sau đó tách thẻ có chứa các từ đồng nghĩa rồi ghép lại"],[199,164,0.9777777791023254,22,1,22,0,21," FJCL: Hệ thống Rút trích văn bản tiếng Nhật được phát triển trong phòng nghiên cứu Ikeda của trường đại học Gifu","FJCL: Hệ thống Rút trích văn bản tiếng Nhật được phát triển trong phòng nghiên cứu Ikeda của trường đại học Gifu"],[187,153,0.9189189076423645,34,0,36,0,36,"Công thức của độ đo ROUGE-N như sau: Cho R=(r1, r2, \u2026, rn) là tập các tóm tắt mẫu, s là tóm tắt tự động, Ωn(d) là vector biểu diễn mô hình n-gram của văn bản d","Công thức của độ đo ROUGE-N như sau: Cho R=(r1, r2, ., rn) là tập các tóm tắt mẫu, s là tóm tắt tự động, n(d) là vector biểu diễn mô hình n-gram của văn bản d"],[257,219,1,25,0,24,0,24,"Ví dụ như tìm kiếm thông tin về giá vàng, người ta không biết giá vàng tăng hay giảm, có biến động gì gần đây","Ví dụ như tìm kiếm thông tin về giá vàng, người ta không biết giá vàng tăng hay giảm, có biến động gì gần đây"],[158,124,0.8607594966888428,34,0,39,0,38,"Ví dụ: \u201cTôi ăn dâu, táo và đào\u201d => \u201cTôi ăn trái cây\u201d  Phương pháp thay thế bộ phận Tư tưởng của phương pháp này là từ các khái niệm bộ phận thay thế bằng khái niệm toàn bộ","Ví dụ: Tôi ăn dâu, táo và đào => Tôi ăn trái cây Phương pháp thay thế bộ phận Tư tưởng của phương pháp này là từ các khái niệm bộ phận thay thế bằng khái niệm toàn bộ"],[130,97,0.9824561476707458,28,1,28,0,27," Phương pháp thống kê tần suất từ Độ quan trọng của từ phụ thuộc vào số lần xuất hiện của từ đó trong các văn bản liên quan","Phương pháp thống kê tần suất từ Độ quan trọng của từ phụ thuộc vào số lần xuất hiện của từ đó trong các văn bản liên quan"],[292,251,1,27,0,26,0,26,"Để sử dụng trong chương trình lần này, phiên bản mới nhất 4.1.1c, mã nguồn của công cụ được tải tại website của dự án VLSP [6]","Để sử dụng trong chương trình lần này, phiên bản mới nhất 4.1.1c, mã nguồn của công cụ được tải tại website của dự án VLSP [6]"],[91,59,0.9753694534301758,99,0,101,0,100,"Nghịch đảo của tần suất văn bản của một từ w, ký hiệu IDF(w) được cho bởi công thức: Trong đó: m là tổng số văn bản,, h là số văn bản chứa từ w  Tần suất TF-IDF là kết hợp của hai loại tần suất nói trên: TF-IDF(w,d) = TF(w,d) * IDF(w) Theo mô hình này, mỗi văn bản sẽ được biểu diễn dưới dạng D(t1, t2,\u2026,tn) với n là tổng số thuật ngữ xuất hiện, mỗi thuật ngữ sẽ được đánh index, ti là trọng số của thuật ngữ thứ i(trong danh sách thuật ngữ) trong văn bản D","Nghịch đảo của tần suất văn bản của một từ w, ký hiệu IDF(w) được cho bởi công thức: Trong đó: m là tổng số văn bản,, h là số văn bản chứa từ w Tần suất TF-IDF là kết hợp của hai loại tần suất nói trên: TF-IDF(w,d) = TF(w,d) * IDF(w) Theo mô hình này, mỗi văn bản sẽ được biểu diễn dưới dạng D(t1, t2,.,tn) với n là tổng số thuật ngữ xuất hiện, mỗi thuật ngữ sẽ được đánh index, ti là trọng số của thuật ngữ thứ i(trong danh sách thuật ngữ) trong văn bản D"],[256,218,1,39,0,38,0,38,"Tuy nhiên trong vấn đề tìm kiếm, phần lớn người dùng thường không nắm rõ được nội dung mình muốn biết nên mới sử dụng tìm kiếm, mà chỉ biết các từ khóa liên quan tới vấn đề đó","Tuy nhiên trong vấn đề tìm kiếm, phần lớn người dùng thường không nắm rõ được nội dung mình muốn biết nên mới sử dụng tìm kiếm, mà chỉ biết các từ khóa liên quan tới vấn đề đó"],[334,292,1,37,0,36,0,36,"Giai đoạn hiển thị Ở bước này, văn bản tóm tắt sẽ được tạo ra bằng cách ghép các câu được chọn theo thứ tự trong văn bản, đó chính là phương pháp hiển thị phân đoạn","Giai đoạn hiển thị Ở bước này, văn bản tóm tắt sẽ được tạo ra bằng cách ghép các câu được chọn theo thứ tự trong văn bản, đó chính là phương pháp hiển thị phân đoạn"],[316,276,0.8908296823501587,102,12,123,1,104,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 32 lãnh thổ, bờ cõi, biên thuỳ, biên giới,biên cương rỗi rãi, rỗi, rảnh rỗi, rảnh rang, rảnh thương nhân, nhà buôn, thương gia, doanh nhân, doanh gia quả cảm, gan góc, dũng cảm, gan dạ, dũng mãnh, can đảm, anh dũng tả, mô tả, miêu tả, diễn tả, diễn đạt, biểu đạt Bảng 2: Một số mục từ đồng nghĩa Sau bước tách từ và loại bỏ từ dừng, các câu sẽ được xử lý theo theo cách duyệt tất cả các từ, với mỗi từ, tìm từ đó trong từ điển đồng nghĩa, nếu có thì thực hiện thay thế từ đó bằng từ đầu tiên trong mục từ chứa nó","http://tratu.soha.vn/ lãnh thổ, bờ cõi, biên thuỳ, biên giới,biên cương rỗi rãi, rỗi, rảnh rỗi, rảnh rang, rảnh thương nhân, nhà buôn, thương gia, doanh nhân, doanh gia quả cảm, gan góc, dũng cảm, gan dạ, dũng mãnh, can đảm, anh dũng tả, mô tả, miêu tả, diễn tả, diễn đạt, biểu đạt Sau bước tách từ và loại bỏ từ dừng, các câu sẽ được xử lý theo theo cách duyệt tất cả các từ, với mỗi từ, tìm từ đó trong từ điển đồng nghĩa, nếu có thì thực hiện thay thế từ đó bằng từ đầu tiên trong mục từ chứa nó"],[39,8,1,41,0,40,0,40,"Ngày nay, thời đại công nghệ thông tin phát triển mạnh, tóm tắt văn bản tự động (gọi tắt là tóm tắt văn bản) được nghiên cứu phát triển nhằm mục đích làm thay con người công việc nặng nhọc đó","Ngày nay, thời đại công nghệ thông tin phát triển mạnh, tóm tắt văn bản tự động (gọi tắt là tóm tắt văn bản) được nghiên cứu phát triển nhằm mục đích làm thay con người công việc nặng nhọc đó"],[51,20,0.9756097793579102,20,1,20,0,19," Hỗ trợ tóm lược nội dung cuộc họp, website, chương trình phát thanh và truyền hình, sổ tay công việc","Hỗ trợ tóm lược nội dung cuộc họp, website, chương trình phát thanh và truyền hình, sổ tay công việc"],[56,25,1,53,0,52,0,52,"Rõ ràng, tóm tắt đa văn bản thì khó hơn, vì ngoài những công việc của tóm tắt đơn văn bản, tóm tắt đa văn bản còn phải thực hiện các công việc như tiền xử lý trích rút, tích hợp thống nhất khuôn dạng và hiển thị kết quả theo cách riêng","Rõ ràng, tóm tắt đa văn bản thì khó hơn, vì ngoài những công việc của tóm tắt đơn văn bản, tóm tắt đa văn bản còn phải thực hiện các công việc như tiền xử lý trích rút, tích hợp thống nhất khuôn dạng và hiển thị kết quả theo cách riêng"],[131,98,1,24,0,23,0,23,"Các kỹ thuật như TF.IPF hay Tập thuật ngữ thường xuyên (Frequent Item Set) dùng cho công việc xác định tần suất của từ","Các kỹ thuật như TF.IPF hay Tập thuật ngữ thường xuyên (Frequent Item Set) dùng cho công việc xác định tần suất của từ"],[175,142,1,36,0,35,0,35,"Đánh giá kết quả tóm tắt Đánh giá một bản tóm tắt là một công việc khó bởi không tồn tại một bản tóm tắt lý tưởng cho một (hoặc một tập) văn bản đưa ra","Đánh giá kết quả tóm tắt Đánh giá một bản tóm tắt là một công việc khó bởi không tồn tại một bản tóm tắt lý tưởng cho một (hoặc một tập) văn bản đưa ra"],[265,227,0.7651515007019043,101,1,103,0,102," Thực hiện tóm tắt Bước này áp dụng mô hình tóm tắt đã đề xuất để tạo kết quả - Chuẩn hóa: bước này sẽ thực hiện xử lý tiêu đề, các đoạn văn trong ngoặc đơn - Tách câu, tách từ: thực hiện tách câu, tách từ sử dụng công cụ VNTokenizer - Loại bỏ từ dừng: tìm kiếm và loại bỏ các từ dừng dựa trên danh sách có sẵn - Xử lý từ đồng nghĩa: đồng bộ các từ đồng nghĩa về cùng 1 dạng - Mô hình hóa văn bản: tính TF.IDF và chuyển các câu về dạng vector","Thực hiện tóm tắt Bước này áp dụng mô hình tóm tắt đã đề xuất để tạo kết quả - Chuẩn hóa: bước này sẽ thực hiện xử lý tiêu đề, các đoạn văn trong ngoặc đơn - Tách câu, tách từ: thực hiện tách câu, tách từ sử dụng công cụ VNTokenizer - Loại bỏ từ dừng: tìm kiếm và loại bỏ các từ dừng dựa trên danh sách có sẵn - Xử lý từ đồng nghĩa: đồng bộ các từ đồng nghĩa về cùng 1 dạng - Mô hinh hóa văn bản: tính TF.IDF và chuyển các câu về dạng vector - Trích rút câu, tạo tóm tắt: đây là giải thuật đã đề xuất, thực hiện tính toán độ tương đồng sử dụng độ đo cosin và một số phép toán trên vector để tìm kiếm các câu phù hợp đưa vào kết quả tóm tắt, và được ghép lại theo phương pháp hiển thị phân đoạn"],[289,248,0.8965517282485962,104,12,118,8,112,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 30 o So khớp từ dài nhất (Longest Matching) o So khớp cực đại (Maximum Matching) o Mô hình Markov ẩn (Hidden Markov Models- HMM) o Học dựa trên sự cải biến (Transformation-based Learning \u2013 TBL) o Chuyển đổi trạng thái trọng số hữu hạn(Weighted Finite State Transducer) o Độ hỗn loạn cực đại (Maximum Entropy \u2013 ME) o Máy học sử dụng vectơ hỗ trợ (Support Vector Machines) o Trường xác xuất có điều kiện (CRFs) Bài toán tách từ khá phức tạp, do đó việc tách từ trong bước này sẽ sử dụng công cụ VNTokenizer, được phát triển bởi nhóm tác giả Lê Hồng Phương","Một số phương pháp có thể áp dụng: o So khớp từ dài nhất (Longest Matching) o So khớp cực đại (Maximum Matching) o Mô hình Markov ẩn (Hidden Markov Models- HMM) o Học dựa trên sự cải biến (Transformation-based Learning TBL) o Chuyển đổi trạng thái trọng số hữu hạn(Weighted Finite State Transducer) o Độ hỗn loạn cực đại (Maximum Entropy ME) o Máy học sử dụng vectơ hỗ trợ (Support Vector Machines) o Trường xác xuất có điều kiện (CRFs) Bài toán tách từ khá phức tạp, do đó việc tách từ trong bước này sẽ sử dụng công cụ VNTokenizer, được phát triển bởi nhóm tác giả Lê Hồng Phương"],[296,255,1,23,0,22,0,22,"Do đó để tiết kiệm thời gian, việc tách câu trong phần này sử dụng luôn modul tách câu trong công cụ VNTokenizer","Do đó để tiết kiệm thời gian, việc tách câu trong phần này sử dụng luôn modul tách câu trong công cụ VNTokenizer"],[347,304,1,45,0,44,0,44,"Chức năng chính là quản lý các văn bản mẫu bao gồm văn bản gốc và bản tóm tắt thủ công, được tích hợp chức năng tách từ, tách câu của VNTokenizer nên việc tạo văn bản mẫu sẽ chính xác và hiệu quả hơn","Chức năng chính là quản lý các văn bản mẫu bao gồm văn bản gốc và bản tóm tắt thủ công, được tích hợp chức năng tách từ, tách câu của VNTokenizer nên việc tạo văn bản mẫu sẽ chính xác và hiệu quả hơn"],[128,95,0.8393782377243042,81,0,95,0,94,"Người ta chia thành hai loại ngữ cố định, một loại mang lại độ quan trọng cho thành phần đi sau, được gọi là ngữ nhấn mạnh, một loại giúp ta loại bỏ, không xét đến những thành phần đi sau vì nó không có nhiều giá trị trong việc trích rút, được gọi là ngữ dư thừa:  Ngữ nhấn mạnh (Bonus phrase - Emphasizer): Ngữ nhấn mạnh gồm các ngữ như \u201cnói chung là\u2026\u201d, \u201cđặc biệt là\u2026\u201d, \u201ccuối cùng thì\u2026\u201d, \u201ctrong bài viết này tôi muốn chỉ ra\u2026\u201d, \u201cbài viết nói về\u2026\u201d, \u201cnội dung gồm\u2026\u201d,..v..v..","Người ta chia thành hai loại ngữ cố định, một loại mang lại độ quan trọng cho thành phần đi sau, được gọi là ngữ nhấn mạnh, một loại giúp ta loại bỏ, không xét đến những thành phần đi sau vì nó không có nhiều giá trị trong việc trích rút, được gọi là ngữ dư thừa: Ngữ nhấn mạnh (Bonus phrase - Emphasizer): Ngữ nhấn mạnh gồm các ngữ như nói chung là., đặc biệt là., cuối cùng thì., trong bài viết này tôi muốn chỉ ra., bài viết nói về., nội dung gồm.,..v..v.."],[135,102,1,32,0,31,0,31,"Việc đánh giá các mối quan hệ sẽ dựa trên các mạng ngữ nghĩa, các quan hệ cú pháp hoặc thông qua các phương pháp xác định độ liên quan truyền thống","Việc đánh giá các mối quan hệ sẽ dựa trên các mạng ngữ nghĩa, các quan hệ cú pháp hoặc thông qua các phương pháp xác định độ liên quan truyền thống"],[143,110,0.9795918464660645,24,1,24,0,23," Phương pháp Liên kết tham chiếu: Phương pháp liên kết tham chiếu còn được gọi là phương pháp trích chọn trùng lặp (Anaphora-based Method)","Phương pháp Liên kết tham chiếu: Phương pháp liên kết tham chiếu còn được gọi là phương pháp trích chọn trùng lặp (Anaphora-based Method)"],[95,62,1,37,0,36,0,36,"Điều cốt lõi của lý thuyết này là việc xác định chính xác một giả thiết nào đó (ví dụ như hai văn bản này có phù hợp, có giống nhau không...) là một điều rất khó","Điều cốt lõi của lý thuyết này là việc xác định chính xác một giả thiết nào đó (ví dụ như hai văn bản này có phù hợp, có giống nhau không...) là một điều rất khó"],[96,63,1,26,0,25,0,25,"Tuy nhiên chúng ta có thể chỉ ra một cặp xấp xỉ trên và xấp xỉ dưới để khẳng định được giả thiết đó là đúng","Tuy nhiên chúng ta có thể chỉ ra một cặp xấp xỉ trên và xấp xỉ dưới để khẳng định được giả thiết đó là đúng"],[107,75,1,33,0,32,0,32,"Một hệ Tóm lược (Abstraction) bao gồm tất cả các pha trên, tuy nhiên một hệ Trích rút (Extraction) chỉ gồm pha Phân tích và Pha Hiển thị, không có pha biến đổi","Một hệ Tóm lược (Abstraction) bao gồm tất cả các pha trên, tuy nhiên một hệ Trích rút (Extraction) chỉ gồm pha Phân tích và Pha Hiển thị, không có pha biến đổi"],[34,3,1,10,0,9,0,9,"TỔNG QUAN VỀ TÓM TẮT VĂN BẢN TỰ ĐỘNG 2.1","TỔNG QUAN VỀ TÓM TẮT VĂN BẢN TỰ ĐỘNG 2.1"],[218,182,1,10,0,9,0,9,"BÀI TOÁN TÓM TẮT VĂN BẢN HƯỚNG TRUY VẤN 3.1","BÀI TOÁN TÓM TẮT VĂN BẢN HƯỚNG TRUY VẤN 3.1"],[200,165,1,32,0,31,0,31,"Đây là một hệ thống sử dụng các phương pháp áp dụng cho hệ ngôn ngữ đơn âm tiết (monosyllabic language system) như tiếng Nhật, Hàn Quốc, Trung Quốc và Việt Nam","Đây là một hệ thống sử dụng các phương pháp áp dụng cho hệ ngôn ngữ đơn âm tiết (monosyllabic language system) như tiếng Nhật, Hàn Quốc, Trung Quốc và Việt Nam"],[120,88,0.8205128312110901,32,14,45,0,31,"Các thống kê này tất nhiên phụ thuộc vào thể loại văn bản\u2026  Chủ đề - Tiêu đề (Title-based): Chủ đề các đoạn văn bản hay tiêu đề các bảng thường chứa các từ và ngữ quan trọng, nên trích rút thông tin từ đây","Chủ đề - Tiêu đề (Title-based): Chủ đề các đoạn văn bản hay tiêu đề các bảng thường chứa các từ và ngữ quan trọng, nên trích rút thông tin từ đây"],[106,74,0.9876543283462524,40,1,40,0,39," Hiển thị (Generation): Từ các đơn vị ngữ liệu đã tóm tắt, liên kết chúng lại thành đoạn theo một thứ tự nào đó hoặc theo cấu kết ngữ pháp rồi hiển thị phù hợp với yêu cầu người dùng","Hiển thị (Generation): Từ các đơn vị ngữ liệu đã tóm tắt, liên kết chúng lại thành đoạn theo một thứ tự nào đó hoặc theo cấu kết ngữ pháp rồi hiển thị phù hợp với yêu cầu người dùng"],[59,28,1,30,0,29,0,29,"Theo đầu ra hệ thống Tóm tắt trích rút là quá trình thu gọn văn bản mà trong kết quả ra chứa các đơn vị ngữ liệu văn bản nguồn","Theo đầu ra hệ thống Tóm tắt trích rút là quá trình thu gọn văn bản mà trong kết quả ra chứa các đơn vị ngữ liệu văn bản nguồn"],[60,29,1,37,0,36,0,36,"Tóm tắt tóm lược là quá trình thu gọn văn bản mà trong kết quả ra có một số các đơn vị ngữ liệu mới được sinh ra từ các đơn vị ngữ liệu văn bản nguồn","Tóm tắt tóm lược là quá trình thu gọn văn bản mà trong kết quả ra có một số các đơn vị ngữ liệu mới được sinh ra từ các đơn vị ngữ liệu văn bản nguồn"],[104,72,0.9659863710403442,71,0,73,0,72,"Mô hình tóm tắt văn bản Hình 1: Mô hình chung của tóm tắt văn bản Một mô hình tóm tắt văn bản tổng quát gồm các pha sau:  Phân tích (Analysis): Phân tích văn bản đầu vào để đưa ra những mô tả bao gồm các thông tin dùng để tìm kiếm, đánh giá các đơn vị ngữ liệu quan trọng cũng như các tham số đầu vào cho việc tóm tắt","Mô hình tóm tắt văn bản Hinh 1: Mô hình chung của tóm tắt văn bản Một mô hình tóm tắt văn bản tổng quát gồm các pha sau: Phân tích (Analysis): Phân tích văn bản đầu vào để đưa ra những mô tả bao gồm các thông tin dùng để tìm kiếm, đánh giá các đơn vị ngữ liệu quan trọng cũng như các tham số đầu vào cho việc tóm tắt"],[105,73,0.9841269850730896,31,1,31,0,30," Biến đổi (Transformation): Lựa chọn các thông tin trích chọn được, biến đổi để giản lược và thống nhất, kết quả là các đơn vị ngữ liệu đã được tóm tắt","Biến đổi (Transformation): Lựa chọn các thông tin trích chọn được, biến đổi để giản lược và thống nhất, kết quả là các đơn vị ngữ liệu đã được tóm tắt"],[119,86,0.9832402467727661,88,0,89,0,88,"Phương pháp thống kê Phương pháp này sử dụng các số liệu thống kê về độ quan trọng của từ, câu hay đoạn, nhận được từ các nghiên cứu về ngôn ngữ học hay thông qua các phương pháp học máy dựa trên tập mẫu để trích rút ra các đơn vị ngữ liệu quan trọng  Phương pháp vị trí Phương pháp vị trí bao gồm các phương pháp xác định độ quan trọng dựa trên thống kê về vị trí của từ, ngữ hay câu trong văn bản","Phương pháp thống kê Phương pháp này sử dụng các số liệu thống kê về độ quan trọng của từ, câu hay đoạn, nhận được từ các nghiên cứu về ngôn ngữ học hay thông qua các phương pháp học máy dựa trên tập mẫu để trích rút ra các đơn vị ngữ liệu quan trọng Phương pháp vị trí Phương pháp vị trí bao gồm các phương pháp xác định độ quan trọng dựa trên thống kê về vị trí của từ, ngữ hay câu trong văn bản"],[133,100,1,32,0,31,0,31,"Phương pháp cấu trúc Là các phương pháp sử dụng các mối liên hệ cấu trúc - ngữ pháp - ngữ nghĩa để xác định các đơn vị ngữ liệu quan trọng","Phương pháp cấu trúc Là các phương pháp sử dụng các mối liên hệ cấu trúc - ngữ pháp - ngữ nghĩa để xác định các đơn vị ngữ liệu quan trọng"],[134,101,1,34,0,33,0,33,"Tư tưởng chính của các phương pháp này là những đơn vị ngữ liệu nào có chứa các thành phần liên kết nhiều với các thành phần khác sẽ có độ quan trọng lớn","Tư tưởng chính của các phương pháp này là những đơn vị ngữ liệu nào có chứa các thành phần liên kết nhiều với các thành phần khác sẽ có độ quan trọng lớn"],[148,114,0.9863013625144958,36,1,36,0,35," Phương pháp quan hệ câu: Dựa trên các từ thể hiện mối quan hệ giữa các câu chúng ta cấu trúc hóa đoạn văn bản từ các đơn vị thành phần như ngữ, mệnh đề, câu..","Phương pháp quan hệ câu: Dựa trên các từ thể hiện mối quan hệ giữa các câu chúng ta cấu trúc hóa đoạn văn bản từ các đơn vị thành phần như ngữ, mệnh đề, câu.."],[149,115,1,13,0,12,0,12,"Sau đó đơn vị được coi như trung tâm sẽ được trích chọn","Sau đó đơn vị được coi như trung tâm sẽ được trích chọn"],[170,137,1,44,0,43,0,43,"Các đơn vị ngữ liệu được trích rút hay giản lược từ các pha trước được liên kết lại thành đoạn theo thứ tự tiền định của chúng, không thêm bớt từ nối và cũng không sắp xếp lại các đơn vị ngữ liệu","Các đơn vị ngữ liệu được trích rút hay giản lược từ các pha trước được liên kết lại thành đoạn theo thứ tự tiền định của chúng, không thêm bớt từ nối và cũng không sắp xếp lại các đơn vị ngữ liệu"],[171,138,1,50,0,49,0,49,"Văn bản kết quả của phương pháp này có độ dễ đọc dễ hiểu kém, thậm chí lủng củng về nghĩa vì các đơn vị ngữ liệu được trích rút mắc phải một số lỗi như mập mờ tham chiếu, không có từ nối hoặc là thừa từ và ngữ","Văn bản kết quả của phương pháp này có độ dễ đọc dễ hiểu kém, thậm chí lủng củng về nghĩa vì các đơn vị ngữ liệu được trích rút mắc phải một số lỗi như mập mờ tham chiếu, không có từ nối hoặc là thừa từ và ngữ"],[173,140,1,85,0,84,0,84,"Phương pháp hiển thị liên kết Việc hiển thị liên kết là tiếp nhận các đơn vị ngữ liệu đã được trích rút và giản lược từ các pha trước đó, phân tích mối quan hệ về nghĩa của các câu rồi thêm bớt các từ nối, từ dẫn và sắp xếp theo một thứ tự mới dựa vào những gì đã thu thập sao cho thỏa mãn yêu cầu về hiển thị và yêu cầu về độ dễ đọc, dễ hiểu của người dùng","Phương pháp hiển thị liên kết Việc hiển thị liên kết là tiếp nhận các đơn vị ngữ liệu đã được trích rút và giản lược từ các pha trước đó, phân tích mối quan hệ về nghĩa của các câu rồi thêm bớt các từ nối, từ dẫn và sắp xếp theo một thứ tự mới dựa vào những gì đã thu thập sao cho thỏa mãn yêu cầu về hiển thị và yêu cầu về độ dễ đọc, dễ hiểu của người dùng"],[129,96,0.6222222447395325,14,1,22,0,21," Ngữ dư thừa (Stigma phrases): Một số ngữ dư thừa: \u201chiếm khi mà\u2026\u201d, \u201cbài này không nói đến\u2026\u201d, \u201cKhông thể nào\u2026\u201d, ..v..v..","Ngữ dư thừa (Stigma phrases): Một số ngữ dư thừa: hiếm khi mà., bài này không nói đến., Không thể nào., ..v..v.."],[344,301,1,42,0,41,0,41,"Đầu vào của chương trình là văn bản gốc, truy vấn, và độ rút gọn, đầu ra sẽ là văn bản tóm tắt, có thể xem chi tiết một số bước xử lý ở chức năng Note góc dưới trái giao diện","Đầu vào của chương trình là văn bản gốc, truy vấn, và độ rút gọn, đầu ra sẽ là văn bản tóm tắt, có thể xem chi tiết một số bước xử lý ở chức năng Note góc dưới trái giao diện"],[279,238,0.9399999976158142,47,0,49,0,49,"Ví dụ: Sinh viên tình nguyện(SVTN) đi đến các vùng sâu để giúp đỡ đồng bào Các câu sau câu này sẽ sử dụng cụm từ SVTN, nếu truy vấn có từ khóa \u201csinh viên tình nguyện\u201d thì các câu sử dụng từ viết tắt sẽ không được quan tâm","Ví dụ: Sinh viên tình nguyện(SVTN) đi đến các vùng sâu để giúp đỡ đồng bào Các câu sau câu này sẽ sử dụng cụm từ SVTN, nếu truy vấn có từ khóa sinh viên tình nguyện thì các câu sử dụng từ viết tắt sẽ không được quan tâm"],[140,107,0.6470588445663452,11,0,15,0,15,"Ví dụ \u201ccây\u201d là một loại \u201cthực vật\u201d, có bộ phận là \u201clá\u201d, chất liệu là \u201cgỗ\u201d","Ví dụ cây là một loại thực vật, có bộ phận là lá, chất liệu là gỗ"],[232,196,1,36,0,35,0,35,"Có 3 giải thuật có thể áp dụng: - Dựa trên tâm các đồ thị: một đồ thị trung tâm cho tất cả văn bản được xây dựng, tích hợp thêm đồ thị của truy vấn","Có 3 giải thuật có thể áp dụng: - Dựa trên tâm các đồ thị: một đồ thị trung tâm cho tất cả văn bản được xây dựng, tích hợp thêm đồ thị của truy vấn"],[185,151,1,41,0,40,0,40,"Sử dụng các độ đo ROUGE ROUGE(Recall-Oriented Understudy of Gisting Evaluation [2]) cũng được đưa ra bởi Lin, vào năm 2009, đây là tập hợp các độ đo dựa trên mô hình n-gram của BLEU với nhiều cách tính khác nhau","Sử dụng các độ đo ROUGE ROUGE(Recall-Oriented Understudy of Gisting Evaluation [2]) cũng được đưa ra bởi Lin, vào năm 2009, đây là tập hợp các độ đo dựa trên mô hình n-gram của BLEU với nhiều cách tính khác nhau"],[188,154,1,21,0,20,0,20,"Độ đo ROUGE được sử dụng làm độ đo chính thức của các hội nghị DUC 2004- 2007 và TAC 2008-2012","Độ đo ROUGE được sử dụng làm độ đo chính thức của các hội nghị DUC 2004- 2007 và TAC 2008-2012"],[72,40,1,13,0,12,0,12,"Trong đó wi là trọng số của term ti trong văn bản D","Trong đó wi là trọng số của term ti trong văn bản D"],[357,312,1,35,0,34,0,34,"Ghi nhận các ý kiến của cử tri, Chủ tịch nước đánh giá cao tinh thần đóng góp ý kiến của mọi người, nhất là vấn đề sửa đổi Hiến Pháp và các đạo luật{3}","Ghi nhận các ý kiến của cử tri, Chủ tịch nước đánh giá cao tinh thần đóng góp ý kiến của mọi người, nhất là vấn đề sửa đổi Hiến Pháp và các đạo luật{3}"],[208,173,1,42,0,41,0,41,"MEAD được xây dựng bởi các chuyên gia nổi tiếng về Xử lý ngôn ngữ ở khắp nơi trên thế giới dưới sự tài trợ của Chương trình Nghiên cứu Công nghệ thông tin của Tổ chức Khoa học quốc gia Mỹ","MEAD được xây dựng bởi các chuyên gia nổi tiếng về Xử lý ngôn ngữ ở khắp nơi trên thế giới dưới sự tài trợ của Chương trình Nghiên cứu Công nghệ thông tin của Tổ chức Khoa học quốc gia Mỹ"],[333,291,0.9166666865348816,22,0,24,0,22,"Khi đó, véc tơ trọng tâm của tập câu được tính theo công thức: 1 m i i cen v V m   1.2","Khi đó, véc tơ trọng tâm của tập câu được tính theo công thức: 1 m i i cen v V m 1.2"],[121,89,0.9846153855323792,32,1,32,0,31," Đầu - cuối đoạn (First - Last Sentence): Xác suất câu đầu đoạn hay câu cuối đoạn chứa ý chính của cả đoạn là rất lớn, đặc biệt là câu đầu đoạn","Đầu - cuối đoạn (First - Last Sentence): Xác suất câu đầu đoạn hay câu cuối đoạn chứa ý chính của cả đoạn là rất lớn, đặc biệt là câu đầu đoạn"],[321,281,0.8979591727256775,44,1,49,0,47,"α là hệ số đánh giá độ quan trọng của từ, nếu từ xuất hiện trong truy vấn thì α>1, còn lại thì α=1 Với hệ số α cho từ xuất hiện trong truy vấn, trong quá trình kiểm thử trên tập mẫu thì α=4 cho kết quả tốt nhất","là hệ số đánh giá độ quan trọng của từ, nếu từ xuất hiện trong truy vấn thì >1, còn lại thì =1 Với hệ số cho từ xuất hiện trong truy vấn, trong quá trình kiểm thử trên tập mẫu thì =4 cho kết quả tốt nhất"],[338,295,1,46,0,45,0,45,"Chương trình thử nghiệm Để thực hiện thử nghiệm em đã xây dựng một số công cụ phục vụ tóm tắt 1 văn bản, công cụ tạo mẫu và công cụ kiểm thử trên mẫu: - Môi trường cài đặt: Java JDK 7u17, Windows 7 32bit","Chương trình thử nghiệm Để thực hiện thử nghiệm em đã xây dựng một số công cụ phục vụ tóm tắt 1 văn bản, công cụ tạo mẫu và công cụ kiểm thử trên mẫu: - Môi trường cài đặt: Java JDK 7u17, Windows 7 32bit"],[346,303,1,19,0,18,0,18,"Công cụ tạo tập mẫu Công cụ này hỗ trợ, tạo, chỉnh sửa các bản tóm tắt thủ công","Công cụ tạo tập mẫu Công cụ này hỗ trợ, tạo, chỉnh sửa các bản tóm tắt thủ công"],[251,214,0.875,35,0,34,0,34,"Phạm vi ứng dụng hướng tới của mô hình là tích hợp vào modul trả kết quả của bộ máy tìm kiếm văn bản(search engine), thực hiện tóm tắt văn bản kết quả theo tập","Phạm vi ứng dụng hướng tới của mô hình là tích hợp vào modul trả kết quả của bộ máy tìm kiếm văn bản(search engine), thực hiện tóm tắt văn bản kết quả theo tập từ khóa đã tìm kiếm(chính là truy vấn người dùng)"],[71,39,1,39,0,38,0,38,"Trọng số của từng term - dùng để đánh giá độ quan trọng của chúng - trong mô hình này chỉ mang hai giá trị 0 và 1, tùy theo sự xuất hiện của term đó trong văn bản","Trọng số của từng term - dùng để đánh giá độ quan trọng của chúng - trong mô hình này chỉ mang hai giá trị 0 và 1, tùy theo sự xuất hiện của term đó trong văn bản"],[76,44,0.9285714030265808,26,0,28,0,26,"Độ liên quan này chỉ có thể mang hai giá trị : 0 \u2013 văn bản không phù hợp với truy vấn và 1 \u2013 văn bản phù hợp","Độ liên quan này chỉ có thể mang hai giá trị : 0 văn bản không phù hợp với truy vấn và 1 văn bản phù hợp"],[82,50,1,39,0,38,0,38,"Các văn bản được biểu diễn thành các vector nhiều chiều, với trọng số không chỉ mang hai giá trị là 0 hay 1 mà có thể mang các giá trị khác tùy theo cách đánh giá, tính toán","Các văn bản được biểu diễn thành các vector nhiều chiều, với trọng số không chỉ mang hai giá trị là 0 hay 1 mà có thể mang các giá trị khác tùy theo cách đánh giá, tính toán"],[154,120,1,33,0,32,0,32,"Giản lược về cấu trúc câu Giản lược về cấu trúc câu là việc lược bỏ trong câu các phần thừa, ít mang giá trị, làm cho cấu trúc câu thu gọn lại","Giản lược về cấu trúc câu Giản lược về cấu trúc câu là việc lược bỏ trong câu các phần thừa, ít mang giá trị, làm cho cấu trúc câu thu gọn lại"],[186,152,1,18,0,17,0,17,"Thường sử dụng nhất là độ đo ROUGE-N, với n là giá trị của mô hình n-gram, n={1,2,3,4}","Thường sử dụng nhất là độ đo ROUGE-N, với n là giá trị của mô hình n-gram, n={1,2,3,4}"],[70,38,1,31,0,30,0,30,"Mô hình boolean Trong mô hình boolean, văn bản, vốn là tập hợp của các term (thuật ngữ), được biểu diễn bởi chỉ số từng term và trọng số của chúng","Mô hình boolean Trong mô hình boolean, văn bản, vốn là tập hợp của các term (thuật ngữ), được biểu diễn bởi chỉ số từng term và trọng số của chúng"],[238,201,1,38,0,37,0,37,"Trong đó mỗi văn bản được biểu diễn bởi đồ thị có trọng số dựa trên lý thuyết diễn ngôn, mỗi đỉnh đại diện cho một câu, trọng số trên mỗi cạnh là khoảng cách giữa hai câu","Trong đó mỗi văn bản được biểu diễn bởi đồ thị có trọng số dựa trên lý thuyết diễn ngôn, mỗi đỉnh đại diện cho một câu, trọng số trên mỗi cạnh là khoảng cách giữa hai câu"],[260,222,0.9824561476707458,28,0,27,0,27,"Nhưng không phải từ nào trong các câu đó cũng đều quan trọng nên các từ xuất hiện trong truy vấn gốc được nhân lên một trọng số α","Nhưng không phải từ nào trong các câu đó cũng đều quan trọng nên các từ xuất hiện trong truy vấn gốc được nhân lên một trọng số"],[299,259,1,21,0,20,0,20,"Trong giải thuật này chủ yếu dựa trên trọng số từ nên việc loại bỏ từ dừng là rất cần thiết","Trong giải thuật này chủ yếu dựa trên trọng số từ nên việc loại bỏ từ dừng là rất cần thiết"],[197,162,0.7868852615356445,24,13,36,0,23,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 23  SumUM: Hệ thống Tóm lược văn bản kỹ thuật của nhóm nghiên cứu xử lý ngôn ngữ tự nhiên trường Đại học Montréal, Canada","SumUM: Hệ thống Tóm lược văn bản kỹ thuật của nhóm nghiên cứu xử lý ngôn ngữ tự nhiên trường Đại học Montréal, Canada"],[32,1,1,80,0,79,0,79,"Cụ thể bài toán cần giải quyết được phát biểu như sau: Đầu vào: Văn bản, truy vấn, độ rút gọn Đầu ra: Bản tóm tắt của văn bản đầu vào xoay quanh vấn đề nêu trong truy vấn Để giải quyết được bài toán này, việc trước hết là tìm hiểu cơ sở lý thuyết về tóm tắt văn bản, tóm tắt hướng truy vấn, từ đó xác định hướng giải quyết và thực hiện cài đặt thử nghiệm","Cụ thể bài toán cần giải quyết được phát biểu như sau: Đầu vào: Văn bản, truy vấn, độ rút gọn Đầu ra: Bản tóm tắt của văn bản đầu vào xoay quanh vấn đề nêu trong truy vấn Để giải quyết được bài toán này, việc trước hết là tìm hiểu cơ sở lý thuyết về tóm tắt văn bản, tóm tắt hướng truy vấn, từ đó xác định hướng giải quyết và thực hiện cài đặt thử nghiệm"],[44,13,0.8631578683853149,41,13,53,0,40,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 14  Độ dễ đọc hiểu (Reading Comprehence): một người được giao việc đọc văn bản kết quả, sau đó trả lời các câu hỏi, hệ thống sẽ phải cho điểm và từ đó đưa ra phần trăm những câu trả lời đúng","Độ dễ đọc hiểu (Reading Comprehence): một người được giao việc đọc văn bản kết quả, sau đó trả lời các câu hỏi, hệ thống sẽ phải cho điểm và từ đó đưa ra phần trăm những câu trả lời đúng"],[47,16,0.95652174949646,11,1,11,0,10," Trợ giúp thông minh việc đọc và khai thác thông tin","Trợ giúp thông minh việc đọc và khai thác thông tin"],[55,24,1,43,0,42,0,42,"Ngược lại, tóm tắt đa văn bản là từ nhiều văn bản nguồn cũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng thời cho nhiều văn bản khác nhau","Ngược lại, tóm tắt đa văn bản là từ nhiều văn bản nguồn cũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng thời cho nhiều văn bản khác nhau"],[77,45,1,61,0,60,0,60,"Do vậy có thể thấy rằng hạn chế lớn nhất của mô hình này đó là việc đánh giá độ liên quan chỉ trả về hai kết quả, hoặc phù hợp hoặc không, như vậy yêu cầu của hệ thống khi cần sắp xếp và chọn lựa các văn bản theo mức độ liên quan đến truy vấn sẽ không đạt","Do vậy có thể thấy rằng hạn chế lớn nhất của mô hình này đó là việc đánh giá độ liên quan chỉ trả về hai kết quả, hoặc phù hợp hoặc không, như vậy yêu cầu của hệ thống khi cần sắp xếp và chọn lựa các văn bản theo mức độ liên quan đến truy vấn sẽ không đạt"],[78,46,1,41,0,40,0,40,"Độ liên quan của mô hình này không thể phân chia thành các mức khác nhau, do vậy không phản ánh được thực tế là việc liên quan giữa văn bản và truy vấn có thể là mờ, không chắn chắn","Độ liên quan của mô hình này không thể phân chia thành các mức khác nhau, do vậy không phản ánh được thực tế là việc liên quan giữa văn bản và truy vấn có thể là mờ, không chắn chắn"],[102,70,1,46,0,45,0,45,"Lý thuyết tập thô được các nhà nghiên cứu Trí tuệ nhân tạo phát triển và ngày càng thể hiện được tính ưu việt không chỉ trong việc biểu diễn và thao tác văn bản mà còn trong các vấn đề khác của lĩnh vực này","Lý thuyết tập thô được các nhà nghiên cứu Trí tuệ nhân tạo phát triển và ngày càng thể hiện được tính ưu việt không chỉ trong việc biểu diễn và thao tác văn bản mà còn trong các vấn đề khác của lĩnh vực này"],[163,129,0.738095223903656,31,12,42,10,40,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 21 Một phương pháp khác khá dễ hiểu đấy là việc thay thế một từ, ngữ bằng một từ, ngữ khác đồng nghĩa hoặc gần nghĩa nhưng có độ dài ngắn hơn","Phương pháp thay thế từ, ngữ đồng nghĩa ngắn hơn Một phương pháp khác khá dễ hiểu đấy là việc thay thế một từ, ngữ bằng một từ, ngữ khác đồng nghĩa hoặc gần nghĩa nhưng có độ dài ngắn hơn"],[176,143,1,13,0,12,0,12,"Hơn nữa, việc đánh giá nội dung tóm tắt cũng rất khó khăn","Hơn nữa, việc đánh giá nội dung tóm tắt cũng rất khó khăn"],[179,146,1,21,0,20,0,20,"Bên cạnh đó, khi việc đánh giá được thực hiện bởi con người thì chi phí đánh giá sẽ rất cao","Bên cạnh đó, khi việc đánh giá được thực hiện bởi con người thì chi phí đánh giá sẽ rất cao"],[180,147,1,44,0,43,0,43,"Mặt khác, tóm tắt văn bản còn liên quan đến tỉ lệ nén văn bản, do đó, việc đánh giá bản tóm tắt cần phải quan tâm đến vấn đề này, khi đó độ phức tạp và chi phí đánh giá sẽ tăng cao","Mặt khác, tóm tắt văn bản còn liên quan đến tỉ lệ nén văn bản, do đó, việc đánh giá bản tóm tắt cần phải quan tâm đến vấn đề này, khi đó độ phức tạp và chi phí đánh giá sẽ tăng cao"],[219,183,1,52,0,51,0,51,"Định nghĩa Theo định nghĩa ở trên, tóm tắt văn bản hướng truy vấn là một dạng tóm tắt văn bản (khi phân chia theo mục đích tóm tắt), điểm đặc trưng là ở giai đoạn tiền xử lý, việc tính toán sẽ phụ thuộc một phần vào truy vấn người dùng","Định nghĩa Theo định nghĩa ở trên, tóm tắt văn bản hướng truy vấn là một dạng tóm tắt văn bản (khi phân chia theo mục đích tóm tắt), điểm đặc trưng là ở giai đoạn tiền xử lý, việc tính toán sẽ phụ thuộc một phần vào truy vấn người dùng"],[221,185,1,36,0,35,0,35,"Ứng dụng của bài toán Tóm tắt hướng truy vấn thường sử dụng trong việc tóm tắt kết quả trả về của máy tìm kiếm thông tin, hoặc trong các hệ thống hỏi đáp tự động","Ứng dụng của bài toán Tóm tắt hướng truy vấn thường sử dụng trong việc tóm tắt kết quả trả về của máy tìm kiếm thông tin, hoặc trong các hệ thống hỏi đáp tự động"],[228,192,1,50,0,49,0,49,"Đồ thị của văn bản sẽ được xây dựng dựa trên việc phân tích các câu trong đó để tìm ra các cụm danh từ(noun phrases), sau đó phân tích các cụm danh từ này để tìm ra mối quan hệ giữa các danh từ sử dụng các hàm heuristic","Đồ thị của văn bản sẽ được xây dựng dựa trên việc phân tích các câu trong đó để tìm ra các cụm danh từ(noun phrases), sau đó phân tích các cụm danh từ này để tìm ra mối quan hệ giữa các danh từ sử dụng các hàm heuristic"],[234,197,0.7234042286872864,68,12,79,40,107,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 25 - Dựa trên việc kết hợp câu đã chọn: giống bước trên nhưng sau khi chọn được mỗi câu thì kết hợp câu đó vào tâm tạo thành tâm mới Phương pháp này cho kết quả tương đối chính xác nhưng phụ thuộc chủ yếu vào giải đoạn phân tích cú pháp để tìm các cụm danh từ, do đó cần bộ phân tích cú pháp chính xác","Sau đó các câu có đồ thị tương đồng với tâm lớn nhất sẽ được chọn - Dựa trên đồ thị truy vấn: các câu có đồ thị tương đồng với đồ thị truy vấn lớn nhất sẽ được chọn - Dựa trên việc kết hợp câu đã chọn: giống bước trên nhưng sau khi chọn được mỗi câu thì kết hợp câu đó vào tâm tạo thành tâm mới Phương pháp này cho kết quả tương đối chính xác nhưng phụ thuộc chủ yếu vào giải đoạn phân tích cú pháp để tìm các cụm danh từ, do đó cần bộ phân tích cú pháp chính xác"],[245,208,1,97,0,96,0,96,"Đề xuất hướng giải quyết cho tiếng Việt Qua tìm hiểu về các vấn đề liên quan trong tóm tắt và đặc trưng của tiếng Việt, dễ nhận thấy rằng việc tiếp cận ở mức cú pháp và ngữ nghĩa là khá khó khăn, một phần là vì công cụ và dữ liệu hỗ trợ, tuy đã có một số công cụ gán nhãn từ vựng và phân tích cú pháp cho độ chính xác cao nhưng thường chỉ áp dụng cho lĩnh vực hẹp, và còn ở mức nghiên cứu, chưa được công bố chính thức","Đề xuất hướng giải quyết cho tiếng Việt Qua tìm hiểu về các vấn đề liên quan trong tóm tắt và đặc trưng của tiếng Việt, dễ nhận thấy rằng việc tiếp cận ở mức cú pháp và ngữ nghĩa là khá khó khăn, một phần là vì công cụ và dữ liệu hỗ trợ, tuy đã có một số công cụ gán nhãn từ vựng và phân tích cú pháp cho độ chính xác cao nhưng thường chỉ áp dụng cho lĩnh vực hẹp, và còn ở mức nghiên cứu, chưa được công bố chính thức"],[295,254,1,32,0,31,0,31,"Ngoài ra việc tách câu khá đơn giản nhưng cần xử lý các trường hợp nhập nhằng dấu chấm câu và dấu chấm trong từ(trong email, số thập phân, địa chỉ web)","Ngoài ra việc tách câu khá đơn giản nhưng cần xử lý các trường hợp nhập nhằng dấu chấm câu và dấu chấm trong từ(trong email, số thập phân, địa chỉ web)"],[313,274,1,22,0,21,0,21,"Tuy chưa được đầy đủ và xử lý đơn giản nhưng cũng góp phần tăng độ chính xác cho việc tóm tắt","Tuy chưa được đầy đủ và xử lý đơn giản nhưng cũng góp phần tăng độ chính xác cho việc tóm tắt"],[351,307,1,52,0,51,0,51,"Công cụ kiểm thử Công cụ này được xây dựng dựa trên việc tích hợp giải thuật đã đề xuất ở trên và tích hợp thêm hai giải thuật để so sánh, việc so sánh dựa trên độ đo BLEUS, chi tiết về cách thực hiện sẽ trình bày ở phần sau","Công cụ kiểm thử Công cụ này được xây dựng dựa trên việc tích hợp giải thuật đã đề xuất ở trên và tích hợp thêm hai giải thuật để so sánh, việc so sánh dựa trên độ đo BLEUS, chi tiết về cách thực hiện sẽ trình bày ở phần sau"],[126,93,0.9696969985961914,16,1,16,0,15," Phương pháp ngữ cố định Các ngữ cố định có đặc điểm thống kê rất tốt","Phương pháp ngữ cố định Các ngữ cố định có đặc điểm thống kê rất tốt"],[127,94,1,17,0,16,0,16,"Sau các ngữ này thường là các câu hay từ có độ quan trọng là xác định","Sau các ngữ này thường là các câu hay từ có độ quan trọng là xác định"],[165,131,0.9841269850730896,31,1,31,0,30," Phương pháp thay thế bởi đại diện Tư tưởng của phương pháp này là thay thế một ngữ bằng một ngữ khác có ý nghĩa đại diện cho ngữ ban đầu","Phương pháp thay thế bởi đại diện Tư tưởng của phương pháp này là thay thế một ngữ bằng một ngữ khác có ý nghĩa đại diện cho ngữ ban đầu"],[194,160,0.9743589758872986,19,1,19,0,18," SweSUM: Ứng dụng Tóm tắt văn bản đa ngôn ngữ của Học viện công nghệ hoàng gia Thụy Điển","SweSUM: Ứng dụng Tóm tắt văn bản đa ngôn ngữ của Học viện công nghệ hoàng gia Thụy Điển"],[201,166,0.9677419066429138,15,1,15,0,14," Pertinence Summarizer: Hệ thống tóm tắt tin tức đa ngôn ngữ trực tuyến nổi tiếng","Pertinence Summarizer: Hệ thống tóm tắt tin tức đa ngôn ngữ trực tuyến nổi tiếng"],[204,169,0.9696969985961914,16,1,16,0,15," MEAD: Nền tảng cho các hệ thống Tóm tắt nhiều văn bản và đa ngôn ngữ","MEAD: Nền tảng cho các hệ thống Tóm tắt nhiều văn bản và đa ngôn ngữ"],[236,199,1,14,0,13,0,13,"Dựa trên cấu trúc diễn ngôn Phương pháp này được trình bày bởi W","Dựa trên cấu trúc diễn ngôn Phương pháp này được trình bày bởi W"],[92,60,0.8727272748947144,24,0,26,0,26,"Khi đó độ liên quan giữa hai văn bản biểu diễn bởi 2 vector X(x1, x2, \u2026, xn) và Y(y1, y2,\u2026,yn) được tính bằng công thức Cosin:","Khi đó độ liên quan giữa hai văn bản biểu diễn bởi 2 vector X(x1, x2, ., xn) và Y(y1, y2,.,yn) được tính bằng công thức Cosin: 2.5.3"],[152,118,1,35,0,34,0,34,"Các phương pháp trong pha này không làm tăng thêm độ chính xác mà chỉ giúp cho văn bản kết quả ngắn gọn hơn mà vẫn sát nghĩa và thuật toán thưởng rất phức tạp","Các phương pháp trong pha này không làm tăng thêm độ chính xác mà chỉ giúp cho văn bản kết quả ngắn gọn hơn mà vẫn sát nghĩa và thuật toán thưởng rất phức tạp"],[305,264,0.936170220375061,22,0,23,0,22,"Xử lý từ đồng nghĩa Có 3 loại từ đồng nghĩa cần xét đến:  Từ có nghĩa giống nhau hoặc gần giống nhau","Xử lý từ đồng nghĩa Có 3 loại từ đồng nghĩa cần xét đến: Từ có nghĩa giống nhau hoặc gần giống nhau"],[312,273,1,61,0,60,0,60,"Mỗi mục gồm các từ gần nghĩa hoặc đồng nghĩa với nhau về mặt nào đó, và mỗi từ chỉ xuất hiện trong một mục, trên thực tế có những từ có thể ở nhiều mục, nhưng số lượng các từ đó không nhiều nên trong bộ từ điển này sẽ sử dụng nghĩa phổ biến nhất của các từ đó","Mỗi mục gồm các từ gần nghĩa hoặc đồng nghĩa với nhau về mặt nào đó, và mỗi từ chỉ xuất hiện trong một mục, trên thực tế có những từ có thể ở nhiều mục, nhưng số lượng các từ đó không nhiều nên trong bộ từ điển này sẽ sử dụng nghĩa phổ biến nhất của các từ đó"],[359,314,0.8620689511299133,25,0,27,0,27,"Tuy nhiên, Chủ tịch nước cũng khẳng định \u201ckhông bao giờ bảo vệ chủ quyền bằng nói miệng\u201d; chủ trương hòa hiếu không có nghĩa là không làm gì{5}","Tuy nhiên, Chủ tịch nước cũng khẳng định không bao giờ bảo vệ chủ quyền bằng nói miệng; chủ trương hòa hiếu không có nghĩa là không làm gi{5}"],[371,314,0.8474576473236084,25,1,28,0,27,"{5} Tuy nhiên, Chủ tịch nước cũng khẳng định \u201ckhông bao giờ bảo vệ chủ quyền bằng nói miệng\u201d; chủ trương hòa hiếu không có nghĩa là không làm gì","Tuy nhiên, Chủ tịch nước cũng khẳng định không bao giờ bảo vệ chủ quyền bằng nói miệng; chủ trương hòa hiếu không có nghĩa là không làm gi{5}"],[286,245,1,26,0,25,0,25,"Vì thế, để xử lý tiếng Việt, bài toán tách từ (word segmentation) là 1 trong những bài toán cơ bản và quan trọng bậc nhất","Vì thế, để xử lý tiếng Việt, bài toán tách từ (word segmentation) là 1 trong những bài toán cơ bản và quan trọng bậc nhất"],[227,191,1,26,0,25,0,25,"Dựa trên đồ thị Phương pháp này được đưa ra bởi [3] Jagadeesh và đồng sự, áp dụng cho tóm tắt trích rút đa văn bản","Dựa trên đồ thị Phương pháp này được đưa ra bởi [3] Jagadeesh và đồng sự, áp dụng cho tóm tắt trích rút đa văn bản"],[300,260,1,35,0,34,0,34,"Từ dừng sẽ được loại bỏ nhờ một danh sách từ dừng xây dựng sẵn, tham khảo tại [7], sau khi tách từ, các từ xuất hiện trong từ điển từ dừng sẽ bị xóa","Từ dừng sẽ được loại bỏ nhờ một danh sách từ dừng xây dựng sẵn, tham khảo tại [7], sau khi tách từ, các từ xuất hiện trong từ điển từ dừng sẽ bị xóa"],[229,193,1,38,0,37,0,37,"Đồ thị thu được sẽ bao gồm 2 dạng nút, nút thành phần(là các danh từ trích rút từ văn bản) và nút liên kết, có 2 loại nút liên kết là isa(là một) và related_to(liên quan với)","Đồ thị thu được sẽ bao gồm 2 dạng nút, nút thành phần(là các danh từ trích rút từ văn bản) và nút liên kết, có 2 loại nút liên kết là isa(là một) và related_to(liên quan với)"],[294,253,1,28,0,27,0,27,"Với độ chính xác xấp xỉ 97% (theo thống kê của tác giả trên website) là kết quả rất cao so với công cụ tách từ hiện nay","Với độ chính xác xấp xỉ 97% (theo thống kê của tác giả trên website) là kết quả rất cao so với công cụ tách từ hiện nay"],[327,286,0.8941176533699036,76,12,90,0,78,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 33 Giải thuật loại bỏ câu trùng lặp như sau: Bước 1: xét câu si, tính độ tương đồng với các câu sau nó sj Bước 2: với mỗi câu sj, nếu độ tương đồng Ωij>α thì loại bỏ câu sj Bước 3: nếu hết văn bản thì dừng lại, không thì tăng i lên 1 và quay lại bước 1 Qua thực nghiệm trên một số văn bản, cho thấy ngưỡng α=0.8 cho kết quả tương đối chính xác","Giải thuật loại bỏ câu trùng lặp như sau: Bước 1: xét câu si, tính độ tương đồng với các câu sau nó sj Bước 2: với mỗi câu sj, nếu độ tương đồng ij> thì loại bỏ câu sj Bước 3: nếu hết văn bản thì dừng lại, không thì tăng i lên 1 và quay lại bước 1 Qua thực nghiệm trên một số văn bản, cho thấy ngưỡng =0.8 cho kết quả tương đối chính xác"],[330,289,0.761904776096344,64,0,66,0,64,"Giải thuật chọn câu theo các bước sau: Bước 1: khởi tạo tâm là truy vấn Bước 2: tính độ tương đồng Ω của các câu trong văn bản với tâm Bước 3: chọn câu có Ω lớn nhất, kết hợp vào tâm, xóa câu đó khỏi văn bản Bước 4: kiểm tra độ dài, nếu chưa đủ, tính toán lại tâm và quay lại bước 2","Giải thuật chọn câu theo các bước sau: Bước 1: khởi tạo tâm là truy vấn Bước 2: tính độ tương đồng của các câu trong văn bản với tâm Bước 3: chọn câu có lớn nhất, kết hợp vào tâm, xóa câu đó khỏi văn bản Bước 4: kiểm tra độ dài, nếu chưa đủ, tính toán lại tâm và quay lại bước 2 Tâm của tóm tắt sẽ được tính toán lại dựa trên công thức tính vector trọng tâm của nhóm, và độ tương tự của 1 câu với tâm sẽ là độ tương tự với vector đó"],[358,313,1,70,0,69,0,69,"Trả lời câu hỏi được đông đảo cử tri quan tâm về chủ trương bảo vệ chủ quyền lãnh thổ, củng cố quốc phòng - an ninh, Chủ tịch nước Trương Tấn Sang khẳng định chủ trương của Đảng, Nhà nước trước sau như một là kiên quyết bảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình, theo hệ thống luật pháp quốc tế{4}","Trả lời câu hỏi được đông đảo cử tri quan tâm về chủ trương bảo vệ chủ quyền lãnh thổ, củng cố quốc phòng - an ninh, Chủ tịch nước Trương Tấn Sang khẳng định chủ trương của Đảng, Nhà nước trước sau như một là kiên quyết bảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình, theo hệ thống luật pháp quốc tế{4}"],[370,313,0.8363636136054993,69,25,93,0,68,"Kết quả tóm tắt Kết quả được chọn theo thứ tự 4, 11, 6, 5, 7, 9 tổng số 111 từ / 6 câu {4} Trả lời câu hỏi được đông đảo cử tri quan tâm về chủ trương bảo vệ chủ quyền lãnh thổ, củng cố quốc phòng - an ninh, Chủ tịch nước Trương Tấn Sang khẳng định chủ trương của Đảng, Nhà nước trước sau như một là kiên quyết bảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình, theo hệ thống luật pháp quốc tế","Trả lời câu hỏi được đông đảo cử tri quan tâm về chủ trương bảo vệ chủ quyền lãnh thổ, củng cố quốc phòng - an ninh, Chủ tịch nước Trương Tấn Sang khẳng định chủ trương của Đảng, Nhà nước trước sau như một là kiên quyết bảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình, theo hệ thống luật pháp quốc tế{4}"],[281,240,0.9387755393981934,46,0,48,0,48,"Ví dụ: UBND thường được dùng thay thế cho \u201cỦy ban nhân dân\u201d Trong giải thuật này chỉ xử lý các cụm từ viết tắt chữ đầu trong ngoặc đơn, còn các trường hợp khác do chưa xây dựng được bộ dữ liệu cụ thể nên không xét đến","Ví dụ: UBND thường được dùng thay thế cho Ủy ban nhân dân Trong giải thuật này chỉ xử lý các cụm từ viết tắt chữ đầu trong ngoặc đơn, còn các trường hợp khác do chưa xây dựng được bộ dữ liệu cụ thể nên không xét đến"],[206,171,1,34,0,33,0,33,"MEAD biểu diễn, lưu trữ dữ liệu ở dạng XML, cung tấp cho chúng ta khung ứng dụng để cài đặt các ứng dụng Tóm tắt văn bản cho ngôn ngữ mà ta muốn","MEAD biểu diễn, lưu trữ dữ liệu ở dạng XML, cung tấp cho chúng ta khung ứng dụng để cài đặt các ứng dụng Tóm tắt văn bản cho ngôn ngữ mà ta muốn"],[74,42,1,24,0,23,0,23,"Câu truy vấn có thể biểu diễn thành dạng vector với các thành phần liên kết và các phép toán quan hệ cơ bản","Câu truy vấn có thể biểu diễn thành dạng vector với các thành phần liên kết và các phép toán quan hệ cơ bản"],[75,43,1,22,0,21,0,21,"Từ đây, độ liên quan giữa một văn bản và truy vấn được xác định thông qua các thành phần liên kết","Từ đây, độ liên quan giữa một văn bản và truy vấn được xác định thông qua các thành phần liên kết"],[155,121,1,15,0,14,0,14,"Công việc này thường dựa trên phân tích cú pháp các thành phần trong câu","Công việc này thường dựa trên phân tích cú pháp các thành phần trong câu"],[164,130,1,13,0,12,0,12,"Điều này thường thông qua một từ điển các từ đồng nghĩa (Thesaurus)","Điều này thường thông qua một từ điển các từ đồng nghĩa (Thesaurus)"],[65,33,1,27,0,26,0,26,"Tóm tắt hướng truy vấn được cài đặt và áp dụng nhiều hơn nhưng trong lĩnh vực hẹp hơn, đi sâu vào các chuyên ngành cụ thể","Tóm tắt hướng truy vấn được cài đặt và áp dụng nhiều hơn nhưng trong lĩnh vực hẹp hơn, đi sâu vào các chuyên ngành cụ thể"],[332,290,0.9032257795333862,28,0,30,0,30,"*) Véc tơ trọng tâm của nhóm Giả sử có một tập câu = {s1, s2, \u2026, sm} có lần lượt các véc tơ biểu diễn là v1, v2, \u2026, vm","*) Véc tơ trọng tâm của nhóm Giả sử có một tập câu = {s1, s2, ., sm} có lần lượt các véc tơ biểu diễn là v1, v2, ., vm"],[212,177,1,22,0,21,0,21,"Chúng ta có thể thử bằng cách chọn Tools - AutoSummarize trên thanh công cụ (có thể khác tùy vào phiên bản)","Chúng ta có thể thử bằng cách chọn Tools - AutoSummarize trên thanh công cụ (có thể khác tùy vào phiên bản)"],[291,250,1,29,0,28,0,28,"Phiên bản cũ nhất là phiên bản vnTokenizer 2.0 được xây dựng vào năm 2005 khi đó nó mới là một ứng dụng đơn với giao diện đơn giản","Phiên bản cũ nhất là phiên bản vnTokenizer 2.0 được xây dựng vào năm 2005 khi đó nó mới là một ứng dụng đơn với giao diện đơn giản"],[356,311,0.9739130139350891,56,0,57,0,56,"Đầu vào  Văn bản: Bảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình{1} Chiều ngày 26-4, Chủ tịch nước Trương Tấn Sang và Tổ Đại biểu Quốc hội (ĐBQH) số 1, Đoàn ĐBQH TP Hồ Chí Minh tiếp tục có buổi tiếp xúc với gần 400 cử tri của quận 1{2}","Đầu vào Văn bản: Bảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình{1} Chiều ngày 26-4, Chủ tịch nước Trương Tấn Sang và Tổ Đại biểu Quốc hội (ĐBQH) số 1, Đoàn ĐBQH TP Hồ Chí Minh tiếp tục có buổi tiếp xúc với gần 400 cử tri của quận 1{2}"],[361,316,1,20,0,19,0,19,"Chủ tịch nước cho biết, chủ trương hòa hiếu luôn được các nước bạn bè trên thế giới ủng hộ{7}","Chủ tịch nước cho biết, chủ trương hòa hiếu luôn được các nước bạn bè trên thế giới ủng hộ{7}"],[373,316,0.9268292784690857,19,1,19,0,18,"{7} Chủ tịch nước cho biết, chủ trương hòa hiếu luôn được các nước bạn bè trên thế giới ủng hộ","Chủ tịch nước cho biết, chủ trương hòa hiếu luôn được các nước bạn bè trên thế giới ủng hộ{7}"],[362,317,0.9473684430122375,36,0,37,0,37,"Đề cập đến tình hình biển, đảo, Chủ tịch nước bày tỏ thông cảm với những lo lắng, bức xúc của cử tri, mong cử tri phải bình tĩnh, không nghe những lời kích động của kẻ xấu{8}","Đề cập đến tình hình biển, đảo, Chủ tịch nước bày tỏ thông cảm với những lo lắng, bức xúc của cử tri, mong cử tri phải binh tĩnh, không nghe những lời kích động của kẻ xấu{8}"],[88,56,1,27,0,26,0,26,"Hai văn bản là hai vector, vậy khoảng cách hay góc giữa chúng đều có thể đại diện cho sự liên quan giữa hai văn bản này","Hai văn bản là hai vector, vậy khoảng cách hay góc giữa chúng đều có thể đại diện cho sự liên quan giữa hai văn bản này"],[210,175,1,11,0,10,0,10,"Hiện tại phiên bản mới nhất của MEAD là MEAD v3.07","Hiện tại phiên bản mới nhất của MEAD là MEAD v3.07"],[363,318,1,41,0,40,0,40,"Những mâu thuẫn trên Biển Đông là có, nhưng biện pháp hòa hiếu của nước ta đã có kết quả tốt, Nhà nước luôn hỗ trợ ngư dân ra khơi, số lượng tàu cá đánh bắt xa bờ ngày càng tăng{9}","Những mâu thuẫn trên Biển Đông là có, nhưng biện pháp hòa hiếu của nước ta đã có kết quả tốt, Nhà nước luôn hỗ trợ ngư dân ra khơi, số lượng tàu cá đánh bắt xa bờ ngày càng tăng{9}"],[374,318,0.9638554453849792,40,1,40,0,39,"{9} Những mâu thuẫn trên Biển Đông là có, nhưng biện pháp hòa hiếu của nước ta đã có kết quả tốt, Nhà nước luôn hỗ trợ ngư dân ra khơi, số lượng tàu cá đánh bắt xa bờ ngày càng tăng","Những mâu thuẫn trên Biển Đông là có, nhưng biện pháp hòa hiếu của nước ta đã có kết quả tốt, Nhà nước luôn hỗ trợ ngư dân ra khơi, số lượng tàu cá đánh bắt xa bờ ngày càng tăng{9}"],[365,320,1,25,0,24,0,24,"Mục tiêu cuối cùng của nước ta là chủ quyền lãnh thổ vững chắc, quốc phòng - an ninh ổn định, kinh tế phát triển{11}","Mục tiêu cuối cùng của nước ta là chủ quyền lãnh thổ vững chắc, quốc phòng - an ninh ổn định, kinh tế phát triển{11}"],[375,320,0.9411764740943909,24,1,24,0,23,"{11} Mục tiêu cuối cùng của nước ta là chủ quyền lãnh thổ vững chắc, quốc phòng - an ninh ổn định, kinh tế phát triển","Mục tiêu cuối cùng của nước ta là chủ quyền lãnh thổ vững chắc, quốc phòng - an ninh ổn định, kinh tế phát triển{11}"],[63,32,0.782608687877655,18,0,17,0,17,"Tóm tắt hướng truy vấn là tóm tắt theo quan điểm mong muốn của người dùng ứng dụng","Tóm tắt hướng truy vấn là tóm tắt theo quan điểm mong muốn của người dùng ứng dụng thông qua các tham số truyền vào câu truy vấn"],[225,189,1,49,0,48,0,48,"Tóm lại, tóm tắt hướng truy vấn thường được tích hợp ở giai đoạn xử lý kết quả của hệ thống tìm kiếm thông tin và hỏi đáp tự động, mục đích là thêm thông tin để kết quả rõ ràng và dễ hiểu hơn với người dùng 3.3","Tóm lại, tóm tắt hướng truy vấn thường được tích hợp ở giai đoạn xử lý kết quả của hệ thống tìm kiếm thông tin và hỏi đáp tự động, mục đích là thêm thông tin để kết quả rõ ràng và dễ hiểu hơn với người dùng 3.3"],[226,190,1,8,0,7,0,7,"Một số hướng tiếp cận phổ biến 3.3.1","Một số hướng tiếp cận phổ biến 3.3.1"],[246,209,1,21,0,20,0,20,"Mặt khác, do đặc trưng về ngữ pháp nên các hướng tiếp cận đó thường không chính xác với tiếng Việt","Mặt khác, do đặc trưng về ngữ pháp nên các hướng tiếp cận đó thường không chính xác với tiếng Việt"],[247,210,1,40,0,39,0,39,"Do đó em xin đề xuất mô hình trích rút các câu quan trọng cho bài toán tóm tắt hướng truy vấn dựa trên tần số từ và độ tương đồng câu, áp dụng cho tóm tắt đơn văn bản","Do đó em xin đề xuất mô hình trích rút các câu quan trọng cho bài toán tóm tắt hướng truy vấn dựa trên tần số từ và độ tương đồng câu, áp dụng cho tóm tắt đơn văn bản"],[250,213,1,46,0,45,0,45,"Phương pháp này dựa theo ý tưởng ở giải thuật thứ 2 trong hướng tiếp cận dựa trên đồ thị đã nêu ở trên, nhưng các câu ở đây biểu diễn theo mô hình không gian vector và độ tương đồng sử dụng độ đo cosin","Phương pháp này dựa theo ý tưởng ở giải thuật thứ 2 trong hướng tiếp cận dựa trên đồ thị đã nêu ở trên, nhưng các câu ở đây biểu diễn theo mô hình không gian vector và độ tương đồng sử dụng độ đo cosin"],[272,232,0.8695651888847351,10,1,10,1,10,"Hình 3: Mô hình tóm tắt văn bản hướng truy vấn","Hinh 3: Mô hình tóm tắt văn bản hướng truy vấn 1.1"],[278,237,0.9902912378311157,51,1,51,0,50," Xử lý các cụm từ trong ngoặc Các cụm từ trong ngoặc có thể là chú thích hoặc viết tắt của cụm từ nào đó, nếu là chú thích thì có thể bỏ qua còn từ viết tắt thì khá quan trọng, nhất là đối với tóm tắt hướng truy vấn","Xử lý các cụm từ trong ngoặc Các cụm từ trong ngoặc có thể là chú thích hoặc viết tắt của cụm từ nào đó, nếu là chú thích thì có thể bỏ qua còn từ viết tắt thì khá quan trọng, nhất là đối với tóm tắt hướng truy vấn"],[287,247,0.6060606241226196,20,26,45,0,19,"Ngoài tiếng Việt, có khá nhiều các ngôn ngữ châu Á khác cũng cần bước tách từ, ví dụ như: tiếng Nhật, tiếng Trung, tiếng Hàn,\u2026 do đó vấn đề này nhận được sự quan tâm rộng rãi và có nhiều hướng tiếp cận khác nhau","do đó vấn đề này nhận được sự quan tâm rộng rãi và có nhiều hướng tiếp cận khác nhau"],[310,271,1,20,0,19,0,19,"Việc xử lý từ đồng nghĩa là rất quan trọng, nhất là trong bài toán tóm tắt hướng truy vấn","Việc xử lý từ đồng nghĩa là rất quan trọng, nhất là trong bài toán tóm tắt hướng truy vấn"],[293,252,1,54,0,53,0,53,"Công cụ này được xây dựng sử dụng kết hợp từ điển (từ điển tiếng Việt được lấy từ đề tài VLSP) và ngram, trong đó mô hình ngram được huấn luyện sử dụng treebank tiếng Việt (70,000 câu đã được tách từ), treebank là kho ngữ liệu câu được chú giải ngữ pháp","Công cụ này được xây dựng sử dụng kết hợp từ điển (từ điển tiếng Việt được lấy từ đề tài VLSP) và ngram, trong đó mô hình ngram được huấn luyện sử dụng treebank tiếng Việt (70,000 câu đã được tách từ), treebank là kho ngữ liệu câu được chú giải ngữ pháp"],[348,305,1,32,0,31,0,31,"Ngoài ra còn có chức năng phát hiện ra các văn bản lỗi font, các văn bản này không thể sử dụng trong các công cụ đi kèm nên cần loại bỏ","Ngoài ra còn có chức năng phát hiện ra các văn bản lỗi font, các văn bản này không thể sử dụng trong các công cụ đi kèm nên cần loại bỏ"],[364,319,1,31,0,30,0,30,"Nước ta phấn đấu đến năm 2020 sẽ phát triển kinh tế biển đạt 52%-53% GDP, trong đó, dầu khí, vận tải biển, đánh bắt hải sản là thế mạnh lớn{10}","Nước ta phấn đấu đến năm 2020 sẽ phát triển kinh tế biển đạt 52%-53% GDP, trong đó, dầu khí, vận tải biển, đánh bắt hải sản là thế mạnh lớn{10}"],[139,106,0.98591548204422,35,1,35,0,34," Phương pháp liên kết từ vựng: Phương pháp liên kết từ vựng sử dụng các từ điển quan hệ từ vựng đế xây dựng các chuỗi từ liên kết với nhau vể mặt ngữ nghĩa","Phương pháp liên kết từ vựng: Phương pháp liên kết từ vựng sử dụng các từ điển quan hệ từ vựng đế xây dựng các chuỗi từ liên kết với nhau vể mặt ngữ nghĩa"],[142,109,1,22,0,21,0,21,"Sau khi xây dựng được các chuỗi từ này, đánh giá độ mạnh của chúng và có những trích chọn phù hợp","Sau khi xây dựng được các chuỗi từ này, đánh giá độ mạnh của chúng và có những trích chọn phù hợp"],[146,112,1,23,0,22,0,22,"Sau khi phân tách các cụm trùng lặp, chúng ta tạo chuỗi các từ tham chiếu đến cùng một từ được tham chiếu","Sau khi phân tách các cụm trùng lặp, chúng ta tạo chuỗi các từ tham chiếu đến cùng một từ được tham chiếu"],[147,113,1,30,0,29,0,29,"Chuỗi dài nhất sẽ được coi là trọng tâm của đoạn, các câu chứa các từ trong chuỗi này có một độ ưu tiên nào đó khi xét trích chọn","Chuỗi dài nhất sẽ được coi là trọng tâm của đoạn, các câu chứa các từ trong chuỗi này có một độ ưu tiên nào đó khi xét trích chọn"],[46,15,0.9589040875434875,35,0,36,0,35,"Ứng dụng của tóm tắt văn bản Tóm tắt văn bản có nhiều ứng dụng trong thực tế, một số ứng dụng nổi bật như:  Tóm tắt tự động các tin tức trên báo điện tử","Ứng dụng của tóm tắt văn bản Tóm tắt văn bản có nhiều ứng dụng trong thực tế, một số ứng dụng nổi bật như: Tóm tắt tự động các tin tức trên báo điện tử"],[287,246,0.6944444179534912,25,0,24,0,24,"Ngoài tiếng Việt, có khá nhiều các ngôn ngữ châu Á khác cũng cần bước tách từ, ví dụ như: tiếng Nhật, tiếng Trung, tiếng Hàn,\u2026 do đó vấn đề này nhận được sự quan tâm rộng rãi và có nhiều hướng tiếp cận khác nhau","Ngoài tiếng Việt, có khá nhiều các ngôn ngữ châu Á khác cũng cần bước tách từ, ví dụ như: tiếng Nhật, tiếng Trung, tiếng Hàn,"],[290,249,1,20,0,19,0,19,"Đây là công cụ tách từ tự động cho tiếng Việt, mã nguồn mở, được viết bằng ngôn ngữ Java","Đây là công cụ tách từ tự động cho tiếng Việt, mã nguồn mở, được viết bằng ngôn ngữ Java"],[68,36,1,23,0,22,0,22,"Các cấu trúc này phải có khả năng thao tác bằng các phép toán cơ bản như cộng, nhân, đại số quan hệ..","Các cấu trúc này phải có khả năng thao tác bằng các phép toán cơ bản như cộng, nhân, đại số quan hệ.."],[83,51,1,21,0,20,0,20,"Một khác biệt nữa so với mô hình boolean là các phép toán cơ bản của mô hình không gian vector","Một khác biệt nữa so với mô hình boolean là các phép toán cơ bản của mô hình không gian vector"],[86,54,1,39,0,38,0,38,"Truy vấn là kết quả của các phép toán vector giữa các vector biểu diễn cho những văn bản cấu thành nên truy vấn, như vậy, truy vấn trong trường hợp này cũng là một văn bản đặc biệt","Truy vấn là kết quả của các phép toán vector giữa các vector biểu diễn cho những văn bản cấu thành nên truy vấn, như vậy, truy vấn trong trường hợp này cũng là một văn bản đặc biệt"],[89,57,1,22,0,21,0,21,"Tất nhiên, để áp dụng được các phép toán vector cơ bản, hai vector cần chuẩn hóa về số chiều (độ dài)","Tất nhiên, để áp dụng được các phép toán vector cơ bản, hai vector cần chuẩn hóa về số chiều (độ dài)"],[98,65,1,27,0,26,0,26,"Các phép toán cơ bản trong mô hình tập thô dựa trên các quan hệ tương đương các tính chất như đối xứng, phản xạ, bắc cầu..","Các phép toán cơ bản trong mô hình tập thô dựa trên các quan hệ tương đương các tính chất như đối xứng, phản xạ, bắc cầu.."],[40,9,0.9523809552192688,60,0,62,0,62,"Đã có rất nhiều định nghĩa được đưa ra, tuy nhiên có thể sử dụng định nghĩa ngắn gọn sau: \u201cTóm tắt văn bản là quá trình rút ra những thông tin quan trọng nhất từ một hay nhiều nguồn văn bản để tạo ra một văn bản gọn hơn phục vụ cho một số nhiệm vụ hay người dùng cụ thể\u201d 2.2","Đã có rất nhiều định nghĩa được đưa ra, tuy nhiên có thể sử dụng định nghĩa ngắn gọn sau: Tóm tắt văn bản là quá trình rút ra những thông tin quan trọng nhất từ một hay nhiều nguồn văn bản để tạo ra một văn bản gọn hơn phục vụ cho một số nhiệm vụ hay người dùng cụ thể 2.2"],[54,23,1,25,0,24,0,24,"Theo đầu vào hệ thống Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn gọn của văn bản đó","Theo đầu vào hệ thống Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn gọn của văn bản đó"],[57,26,1,57,0,56,0,56,"Ngoài ra, tóm tắt đa văn bản còn phải đối mặt với các vấn đề như dư thừa trùng lặp dữ liệu giữa các văn bản nguồn, nội dung các văn bản nguồn phân tán, độ rút gọn yêu cầu cao, thời gian xử lý cần phải nhanh trong khi sự phức tạp trong xử lý lớn","Ngoài ra, tóm tắt đa văn bản còn phải đối mặt với các vấn đề như dư thừa trùng lặp dữ liệu giữa các văn bản nguồn, nội dung các văn bản nguồn phân tán, độ rút gọn yêu cầu cao, thời gian xử lý cần phải nhanh trong khi sự phức tạp trong xử lý lớn"],[116,83,1,50,0,49,0,49,"Pha Phân tích Ở pha này văn bản nguồn sẽ được tách thành các đoạn, câu, từ, kết hợp với các thông số đầu vào và áp dụng một số thuật toán cụ thể để chọn ra các đoạn hoặc câu phù hợp làm đầu vào cho pha tiếp theo","Pha Phân tích Ở pha này văn bản nguồn sẽ được tách thành các đoạn, câu, từ, kết hợp với các thông số đầu vào và áp dụng một số thuật toán cụ thể để chọn ra các đoạn hoặc câu phù hợp làm đầu vào cho pha tiếp theo"],[137,104,1,26,0,25,0,25,"Các đoạn (câu) trong văn bản nguồn được tính toán độ liên quan lẫn nhau sử dụng các kỹ thuật như Cosine, TF.IPF hay N-gram Overlap","Các đoạn (câu) trong văn bản nguồn được tính toán độ liên quan lẫn nhau sử dụng các kỹ thuật như Cosine, TF.IPF hay N-gram Overlap"],[209,174,1,15,0,14,0,14,"MEAD được cung cấp ở dạng mã nguồn mở để nghiên cứu và kế thừa","MEAD được cung cấp ở dạng mã nguồn mở để nghiên cứu và kế thừa"],[264,226,1,55,0,54,0,54,"- Truy vấn: sử dụng bộ mã như văn bản, là một đoạn văn bản chứa các từ khóa cần tìm kiếm, nếu cần chính xác thì dùng dấu phảy để ngăn cách các từ khóa - Độ rút gọn: có thể là số lượng từ (100-150 từ) hoặc phần trăm văn bản nguồn (10-20%)","- Truy vấn: sử dụng bộ mã như văn bản, là một đoạn văn bản chứa các từ khóa cần tìm kiếm, nếu cần chính xác thì dùng dấu phảy để ngăn cách các từ khóa - Độ rút gọn: có thể là số lượng từ (100-150 từ) hoặc phần trăm văn bản nguồn (10-20%)"],[123,91,0.9811320900917053,26,1,26,0,25," Minh họa - Chú thích (Comments): Trong các câu chú thích, câu minh họa cho ảnh hay đồ thị thường chứa các thông tin quan trọng","Minh họa - Chú thích (Comments): Trong các câu chú thích, câu minh họa cho ảnh hay đồ thị thường chứa các thông tin quan trọng"],[230,194,1,22,0,21,0,21,"Sau khi xây dựng đồ thị cho mỗi câu, chúng sẽ được kết hợp để tạo đồ thị cho toàn văn bản","Sau khi xây dựng đồ thị cho mỗi câu, chúng sẽ được kết hợp để tạo đồ thị cho toàn văn bản"],[248,211,1,42,0,41,0,41,"Mô tả sơ lược như sau: Đầu tiên sử dụng câu truy vấn làm tâm tóm tắt, sau đó tìm câu có độ tương đồng với tâm lớn nhất, mỗi câu được chọn sẽ kết hợp với tâm tạo nên tâm mới","Mô tả sơ lược như sau: Đầu tiên sử dụng câu truy vấn làm tâm tóm tắt, sau đó tìm câu có độ tương đồng với tâm lớn nhất, mỗi câu được chọn sẽ kết hợp với tâm tạo nên tâm mới"],[263,225,0.9677419066429138,45,0,46,0,45,"Tổng quan về modul đó như sau:  Đầu vào - Văn bản: văn bản đầu vào sử dụng bộ mã Unicode utf-8, chỉ chứa text, chính xác về chính tả, dấu câu, không quá ngắn(5 câu trở lên), nội dung phải liên quan tới truy vấn","Tổng quan về modul đó như sau: Đầu vào - Văn bản: văn bản đầu vào sử dụng bộ mã Unicode utf-8, chỉ chứa text, chính xác về chính tả, dấu câu, không quá ngắn(5 câu trở lên), nội dung phải liên quan tới truy vấn"],[87,55,1,24,0,23,0,23,"Việc xác định độ liên quan giữa truy vấn và văn bản được quy thành độ liên quan giữa văn bản và văn bản","Việc xác định độ liên quan giữa truy vấn và văn bản được quy thành độ liên quan giữa văn bản và văn bản"],[276,235,0.8695651888847351,20,0,21,0,21,"Việc phát hiện câu tiêu đề có thể dựa vào dấu hiệu \u201ccâu tiêu đề là câu duy nhất của đoạn đầu tiên\u201d","Việc phát hiện câu tiêu đề có thể dựa vào dấu hiệu câu tiêu đề là câu duy nhất của đoạn đầu tiên"],[318,278,1,27,0,26,0,26,"Mô hình hóa văn bản Việc cuối cùng trong giai đoạn tiền xử lý là mô hình hóa văn bản, sử dụng mô hình không gian vector","Mô hình hóa văn bản Việc cuối cùng trong giai đoạn tiền xử lý là mô hình hóa văn bản, sử dụng mô hình không gian vector"],[223,187,1,31,0,30,0,30,"Sau khi xác định được văn bản phù hợp, văn bản đó sẽ được tóm tắt lại theo truy vấn người dùng để đưa ra hiển thị kèm với kết quả","Sau khi xác định được văn bản phù hợp, văn bản đó sẽ được tóm tắt lại theo truy vấn người dùng để đưa ra hiển thị kèm với kết quả"],[205,170,1,35,0,34,0,34,"Đây là một bộ công cụ xây dựng trên nền Linux và Solaris, sử dụng ngôn ngữ Perl - Một ngôn ngữ có khả năng xử lý văn bản rất linh hoạt và mạnh mẽ","Đây là một bộ công cụ xây dựng trên nền Linux và Solaris, sử dụng ngôn ngữ Perl - Một ngôn ngữ có khả năng xử lý văn bản rất linh hoạt và mạnh mẽ"],[62,31,1,22,0,21,0,21,"Theo mục đích tóm tắt Tóm tắt chung là tóm tắt theo quan điểm ban đầu của tác giả văn bản gốc","Theo mục đích tóm tắt Tóm tắt chung là tóm tắt theo quan điểm ban đầu của tác giả văn bản gốc"],[271,231,1,48,0,47,0,47,"PHÂN TÍCH MÔ HÌNH THỰC HIỆN BÀI TOÁN Dựa vào các kiến thức về tóm tắt văn bản đã trình bày ở trên, trong phần này em sẽ trình bày chi tiết các kỹ thuật áp dụng trong từng bước của mô hình xử lý đã đề xuất","PHÂN TÍCH MÔ HÌNH THỰC HIỆN BÀI TOÁN Dựa vào các kiến thức về tóm tắt văn bản đã trình bày ở trên, trong phần này em sẽ trình bày chi tiết các kỹ thuật áp dụng trong từng bước của mô hình xử lý đã đề xuất"],[354,309,1,23,0,22,0,22,"Thử nghiệm một văn bản Phần này em sử dụng công cụ tóm tắt đã xây dựng để thử nghiệm một văn bản","Thử nghiệm một văn bản Phần này em sử dụng công cụ tóm tắt đã xây dựng để thử nghiệm một văn bản"],[258,220,1,48,0,47,0,47,"Hoặc tìm cách sửa một lỗi máy tính thì người dùng sẽ đưa ra các thông tin về lỗi đó, sau khi xem bản tóm tắt của các kết quả từ máy tìm kiếm, sẽ biết được kết quả nào phù hợp để quyết định đọc hay không","Hoặc tìm cách sửa một lỗi máy tính thì người dùng sẽ đưa ra các thông tin về lỗi đó, sau khi xem bản tóm tắt của các kết quả từ máy tìm kiếm, sẽ biết được kết quả nào phù hợp để quyết định đọc hay không"],[73,41,1,43,0,42,0,42,"Đối với vấn đề truy vấn, trong mô hình này câu truy vấn bao gồm các văn bản tìm kiếm liên hệ với nhau thông qua các phép đại số quan hệ cơ bản như NOT (phủ định), AND (và) hay OR (hoặc)","Đối với vấn đề truy vấn, trong mô hình này câu truy vấn bao gồm các văn bản tìm kiếm liên hệ với nhau thông qua các phép đại số quan hệ cơ bản như NOT (phủ định), AND (và) hay OR (hoặc)"],[157,123,0.9538461565971375,31,0,32,0,31,"Giản lược về mặt ngữ nghĩa  Phương pháp trừu tượng hóa khái niệm Tư tưởng của phương pháp này là từ các khái niệm cụ thể thay thế bằng khái niệm chung","Giản lược về mặt ngữ nghĩa Phương pháp trừu tượng hóa khái niệm Tư tưởng của phương pháp này là từ các khái niệm cụ thể thay thế bằng khái niệm chung"],[99,66,1,20,0,19,0,19,"Lý thuyết logic mờ đã và đang được ứng dụng rất mạnh mẽ trong lĩnh vực Trí tuệ nhân tạo","Lý thuyết logic mờ đã và đang được ứng dụng rất mạnh mẽ trong lĩnh vực Trí tuệ nhân tạo"],[183,149,1,37,0,36,0,36,"Sử dụng so khớp n-gram Phương pháp này được Lin và Hovy đưa ra năm 2002 dựa trên mô hình n-gram của độ đo BLEU (Bilingual Evaluation Understudy [1], độ đo đánh giá kết quả dịch máy)","Sử dụng so khớp n-gram Phương pháp này được Lin và Hovy đưa ra năm 2002 dựa trên mô hình n-gram của độ đo BLEU (Bilingual Evaluation Understudy [1], độ đo đánh giá kết quả dịch máy)"],[101,69,1,36,0,35,0,35,"Nhóm tác giả Hồ Tú Bảo, Saori Kawasaki, Nguyễn Ngọc Bình đã đề xuất ra mô hình tập thô dung sai trong đó bỏ đi tính chất bắc cầu trong quá trình xử lý văn bản","Nhóm tác giả Hồ Tú Bảo, Saori Kawasaki, Nguyễn Ngọc Bình đã đề xuất ra mô hình tập thô dung sai trong đó bỏ đi tính chất bắc cầu trong quá trình xử lý văn bản"],[275,234,0.9808917045593262,77,0,78,0,77,"Chuẩn hóa  Xử lý câu tiêu đề Câu tiêu đề của một văn bản (nếu có) thường mang nội dung chính trình bày trong văn bản, do đó các từ khóa trong đó cũng được dùng để phát hiện tóm tắt (một số giải thuật còn tăng trọng số cho những từ xuất hiện trong tiêu đề), nhưng không đưa câu tiêu đề vào kết quả tóm tắt, nên cần phát hiện để loại bỏ khỏi kết quả","Chuẩn hóa Xử lý câu tiêu đề Câu tiêu đề của một văn bản (nếu có) thường mang nội dung chính trình bày trong văn bản, do đó các từ khóa trong đó cũng được dùng để phát hiện tóm tắt (một số giải thuật còn tăng trọng số cho những từ xuất hiện trong tiêu đề), nhưng không đưa câu tiêu đề vào kết quả tóm tắt, nên cần phát hiện để loại bỏ khỏi kết quả"],[37,6,1,30,0,29,0,29,"Mục đích là giúp người sử dụng có cái nhìn tổng quan về nội dung trình bày trong văn bản, để quyết định sử dụng văn bản đó hợp lý","Mục đích là giúp người sử dụng có cái nhìn tổng quan về nội dung trình bày trong văn bản, để quyết định sử dụng văn bản đó hợp lý"],[178,145,1,28,0,27,0,27,"Thực tế luôn có khả năng một hệ thống sinh ra một bản tóm tắt tốt nhưng lại sai khác với bản tóm tắt do người thực hiện","Thực tế luôn có khả năng một hệ thống sinh ra một bản tóm tắt tốt nhưng lại sai khác với bản tóm tắt do người thực hiện"],[255,217,1,38,0,37,0,37,"Do đó các câu chứa nhiều từ khóa trong truy vấn, hay trong trường hợp này là độ tương đồng lớn, sẽ mang các thông tin quan trọng liên quan đến truy vấn mà người dùng quan tâm","Do đó các câu chứa nhiều từ khóa trong truy vấn, hay trong trường hợp này là độ tương đồng lớn, sẽ mang các thông tin quan trọng liên quan đến truy vấn mà người dùng quan tâm"],[306,267,0.675000011920929,27,22,50,0,28,"Ví dụ: siêng năng, chăm chỉ, cần cù, \u2026  Từ đồng nghĩa hoàn toàn Ví dụ: hổ, cọp, hùm, \u2026  Từ đồng nghĩa không hoàn toàn Ví dụ: Ăn, xơi, chén, \u2026(biểu thị thái độ, tình cảm khác nhau đối với người đối thoại hoặc điều được nói đến)","Từ đồng nghĩa không hoàn toàn Ví dụ: Ăn, xơi, chén, .(biểu thị thái độ, tình cảm khác nhau đối với người đối thoại hoặc điều được nói đến)"],[100,68,0.6944444179534912,25,22,46,0,24,"Mô hình tập thô gần đây được sử dụng nhiều cho các bài toán tìm kiếm cũng như phân nhóm văn bản\u2026 Tuy nhiên khi áp dụng mô hình tập thô cho quá trình xử lý văn bản thì tính chất bắc cầu không còn phù hợp","Tuy nhiên khi áp dụng mô hình tập thô cho quá trình xử lý văn bản thì tính chất bắc cầu không còn phù hợp"],[161,128,0.807692289352417,21,0,24,0,24,"Ví dụ: \u201cAnh ấy bước vào, ngồi xuống ghế, xem thực đơn, gọi món, ăn, trả tiền và ra về\u201d => \u201cAnh ấy đi ăn tiệm\u201d","Ví dụ: Anh ấy bước vào, ngồi xuống ghế, xem thực đơn, gọi món, ăn, trả tiền và ra về => Anh ấy đi ăn tiệm"],[67,35,1,33,0,32,0,32,"Mô hình biểu diễn văn bản Văn bản thông thường là dạng dữ liệu phi cấu trúc, do vậy muốn xử lý chúng trước hết phải biểu diễn thành dạng có cấu trúc","Mô hình biểu diễn văn bản Văn bản thông thường là dạng dữ liệu phi cấu trúc, do vậy muốn xử lý chúng trước hết phải biểu diễn thành dạng có cấu trúc"],[117,84,1,23,0,22,0,22,"Các phương pháp áp dụng trong pha Phân tích được chia thành hai loại: Phương pháp thống kê và Phương pháp cấu trúc","Các phương pháp áp dụng trong pha Phân tích được chia thành hai loại: Phương pháp thống kê và Phương pháp cấu trúc"],[203,168,1,13,0,12,0,12,"Chúng ta có thể thử nghiệm hệ thống này trên trang web: www.pertinence.net","Chúng ta có thể thử nghiệm hệ thống này trên trang web: www.pertinence.net"],[309,270,1,39,0,38,0,38,"Còn loại 3 thì phải xét đến ngữ nghĩa của từ trong ngữ cảnh của văn bản, đây có thể coi là bài toán phức tạp nhất trong xử lý ngôn ngữ, hiện nay chưa có nhiều nghiên cứu","Còn loại 3 thì phải xét đến ngữ nghĩa của từ trong ngữ cảnh của văn bản, đây có thể coi là bài toán phức tạp nhất trong xử lý ngôn ngữ, hiện nay chưa có nhiều nghiên cứu"],[184,150,0.8999999761581421,54,0,59,0,59,"Ý tưởng của phương pháp này là so khớp n-gram liên tiếp của bản tóm tắt thủ công và tóm tắt tự động, theo công thức sau: Score=α1*Score1+ α2*Score2+ α3*Score3+ α4*Score4 Trong đó: Scorei = Số i-gram trùng nhau/Tổng số i-gram của bản tóm tắt thủ công αi là hệ số đánh giá độ quan trọng của các Scorei 2.8.2","Ý tưởng của phương pháp này là so khớp n-gram liên tiếp của bản tóm tắt thủ công và tóm tắt tự động, theo công thức sau: Score=1*Score1+ 2*Score2+ 3*Score3+ 4*Score4 Trong đó: Scorei = Số i-gram trùng nhau/Tổng số i-gram của bản tóm tắt thủ công i là hệ số đánh giá độ quan trọng của các Scorei 2.8.2"],[136,103,0.9876543283462524,40,1,40,0,39," Phương pháp quan hệ lẫn nhau: Phương pháp này xác định mối quan hệ giữa các đoạn trong văn bản hay các câu trong đoạn với nhau thông qua các kỹ thuật thu thập thông tin ở mức văn bản","Phương pháp quan hệ lẫn nhau: Phương pháp này xác định mối quan hệ giữa các đoạn trong văn bản hay các câu trong đoạn với nhau thông qua các kỹ thuật thu thập thông tin ở mức văn bản"],[222,186,1,44,0,43,0,43,"Hiện nay, đối với máy tìm kiếm, hệ thống sẽ tóm tắt văn bản theo tóm tắt đơn văn bản thông thường, lưu vào cơ sở dữ liệu, và thực hiện tìm kiếm trên bản tóm tắt đó để giảm thời gian tìm kiếm","Hiện nay, đối với máy tìm kiếm, hệ thống sẽ tóm tắt văn bản theo tóm tắt đơn văn bản thông thường, lưu vào cơ sở dữ liệu, và thực hiện tìm kiếm trên bản tóm tắt đó để giảm thời gian tìm kiếm"],[254,216,1,24,0,23,0,23,"Vì văn bản đã được máy tìm kiếm lựa chọn nên nội dung của văn bản và truy vấn sẽ liên quan với nhau","Vì văn bản đã được máy tìm kiếm lựa chọn nên nội dung của văn bản và truy vấn sẽ liên quan với nhau"],[79,47,0.9333333373069763,21,0,22,0,21,"Hạn chế này được loại bỏ khi ta sử dụng một mô hình tổng quát hơn \u2013 Mô hình không gian vector (VSM)","Hạn chế này được loại bỏ khi ta sử dụng một mô hình tổng quát hơn Mô hình không gian vector (VSM)"],[177,144,1,47,0,46,0,46,"Trường hợp kết quả là một câu trả lời cho một câu hỏi, ta có thể xác định được câu trả lời đó đúng hay sai, nhưng trong các trường hợp khác, thật khó trả lời liệu đầu ra là phải một kết quả đúng hay không","Trường hợp kết quả là một câu trả lời cho một câu hỏi, ta có thể xác định được câu trả lời đó đúng hay sai, nhưng trong các trường hợp khác, thật khó trả lời liệu đầu ra là phải một kết quả đúng hay không"],[319,279,1,45,0,44,0,44,"Tương tự các công thức dùng để mô hình hóa văn bản ở trên, để mô hình hóa câu, ta sử dụng công thức sau TF.ISF, công thức này tương tự như TF.IDF nhưng các thông số ở trong phạm vi câu và văn bản","Tương tự các công thức dùng để mô hình hóa văn bản ở trên, để mô hình hóa câu, ta sử dụng công thức sau TF.ISF, công thức này tương tự như TF.IDF nhưng các thông số ở trong phạm vi câu và văn bản"],[48,17,0.9523809552192688,10,1,10,0,9," Tóm lược danh sách tìm kiếm từ các Search Engine","Tóm lược danh sách tìm kiếm từ các Search Engine"],[36,5,1,38,0,37,0,37,"Công việc tóm tắt văn bản đã xuất hiện từ rất lâu đời, và nó được làm thủ công, do con người đọc, rút ra các ý chính rồi trình bày lại một cách ngắn gọn, dễ hiểu","Công việc tóm tắt văn bản đã xuất hiện từ rất lâu đời, và nó được làm thủ công, do con người đọc, rút ra các ý chính rồi trình bày lại một cách ngắn gọn, dễ hiểu"],[190,156,1,33,0,32,0,32,"Một số hệ thống tóm tắt văn bản tiêu biểu Hiện tại, trên thế giới đã có rất nhiều nghiên cứu và dự án xây dựng các ứng dụng tóm tắt văn bản","Một số hệ thống tóm tắt văn bản tiêu biểu Hiện tại, trên thế giới đã có rất nhiều nghiên cứu và dự án xây dựng các ứng dụng tóm tắt văn bản"],[202,167,1,36,0,35,0,35,"Hiện tại để thử nghiệm khả năng của mình, Pertinence đã được tích hợp với Google và tóm tắt tự động danh sách tìm kiếm trả về từ Google thông qua câu truy vấn đưa vào","Hiện tại để thử nghiệm khả năng của mình, Pertinence đã được tích hợp với Google và tóm tắt tự động danh sách tìm kiếm trả về từ Google thông qua câu truy vấn đưa vào"],[81,49,1,24,0,23,0,23,"Mô hình không gian vector Như trên đã đề cập, mô hình không gian vector là mô hình tổng quát hơn mô hình Boolean","Mô hình không gian vector Như trên đã đề cập, mô hình không gian vector là mô hình tổng quát hơn mô hình Boolean"],[242,205,1,39,0,38,0,38,"Trước tiên các văn bản sẽ được biểu diễn trong mô hình không gian vector, mỗi câu được tính khoảng cách với câu truy vấn, sau đó sử dụng thuật toán phân cụm, chia các câu vào các cụm","Trước tiên các văn bản sẽ được biểu diễn trong mô hình không gian vector, mỗi câu được tính khoảng cách với câu truy vấn, sau đó sử dụng thuật toán phân cụm, chia các câu vào các cụm"],[329,288,0.96875,62,0,63,0,63,"Quá trình chọn câu quan trọng sẽ thực hiện như hình dưới đây Hình 4: Minh họa quá trình chọn câu quan trọng Sau khi chuyển biểu diễn các câu về mô hình không gian vector, mỗi câu sẽ là một vector, văn bản là danh sách các vector, độ tương đồng giữa các câu sẽ được tính toán sử dụng độ đo cosin","Quá trình chọn câu quan trọng sẽ thực hiện như hình dưới đây Hinh 4: Minh họa quá trình chọn câu quan trọng Sau khi chuyển biểu diễn các câu về mô hình không gian vector, mỗi câu sẽ là một vector, văn bản là danh sách các vector, độ tương đồng giữa các câu sẽ được tính toán sử dụng độ đo cosin"],[110,77,0.7356321811676025,32,13,44,10,41,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 18 Hình 2: Mô hình tóm tắt văn bản trích rút Như vậy một hệ Trích rút tiến hành ít bước hơn, các phương pháp thường dùng là thống kê, học trên ngữ liệu","Phân tích (Analysis) Biến đổi (Transform) Hiển thị (Generation) Hinh 2: Mô hình tóm tắt văn bản trích rút Như vậy một hệ Trích rút tiến hành ít bước hơn, các phương pháp thường dùng là thống kê, học trên ngữ liệu"],[166,132,0.6666666865348816,10,0,11,0,11,"Ví dụ: \u201cNgười phát ngôn viên của chính phủ Hoa Kỳ thông báo\u2026\u201d => \u201cWashington thông báo\u2026\u201d","Ví dụ: Người phát ngôn viên của chính phủ Hoa Kỳ thông báo"],[211,176,0.978723406791687,23,1,23,0,22," Microsoft Word AutoSummary: Microsoft cũng cài đặt chức năng Trích rút và sinh tiêu đề trong Microsoft Word từ phiên bản Word '97","Microsoft Word AutoSummary: Microsoft cũng cài đặt chức năng Trích rút và sinh tiêu đề trong Microsoft Word từ phiên bản Word '97"],[108,76,1,19,0,18,0,18,"Thậm chí trong các pha phân tích và hiển thị, chỉ có một số công đoạn được sử dụng","Thậm chí trong các pha phân tích và hiển thị, chỉ có một số công đoạn được sử dụng"],[94,61,1,35,0,34,0,34,"Mô hình tập thô dung sai Mô hình tập thô dung sai (Tolerance Rough Set Model) là một mô hình mới, tiên tiến dựa trên lý thuyết về logic mờ và tập mờ (Fuzzy Set)","Mô hình tập thô dung sai Mô hình tập thô dung sai (Tolerance Rough Set Model) là một mô hình mới, tiên tiến dựa trên lý thuyết về logic mờ và tập mờ (Fuzzy Set)"],[360,315,1,32,0,31,0,31,"Nước ta cũng mua sắm trang bị vũ khí, nhưng không phải để gây chiến tranh, chạy đua vũ trang mà là tăng cường phòng thủ, bảo vệ chủ quyền lãnh thổ{6}","Nước ta cũng mua sắm trang bị vũ khí, nhưng không phải để gây chiến tranh, chạy đua vũ trang mà là tăng cường phòng thủ, bảo vệ chủ quyền lãnh thổ{6}"],[372,315,0.9538461565971375,31,1,31,0,30,"{6} Nước ta cũng mua sắm trang bị vũ khí, nhưng không phải để gây chiến tranh, chạy đua vũ trang mà là tăng cường phòng thủ, bảo vệ chủ quyền lãnh thổ","Nước ta cũng mua sắm trang bị vũ khí, nhưng không phải để gây chiến tranh, chạy đua vũ trang mà là tăng cường phòng thủ, bảo vệ chủ quyền lãnh thổ{6}"],[151,117,1,27,0,26,0,26,"Pha Biến đổi Ở pha này, các câu sẽ được biến đổi, làm gọn lại hoặc kết hợp nhiều câu tạo thành câu mới ngắn gọn hơn","Pha Biến đổi Ở pha này, các câu sẽ được biến đổi, làm gọn lại hoặc kết hợp nhiều câu tạo thành câu mới ngắn gọn hơn"],[325,285,1,41,0,40,0,40,"Độ đo sử dụng để loại bỏ câu trùng lặp và chọn câu phù hợp tạo tóm tắt là độ đo cosin đã trình bày ở trên, nhưng hai vector được tính toán bây giờ là biểu diễn cho hai câu","Độ đo sử dụng để loại bỏ câu trùng lặp và chọn câu phù hợp tạo tóm tắt là độ đo cosin đã trình bày ở trên, nhưng hai vector được tính toán bây giờ là biểu diễn cho hai câu"],[301,261,1,13,0,12,0,12,"Dưới đây là một số từ dừng trích trong file sẽ sử dụng","Dưới đây là một số từ dừng trích trong file sẽ sử dụng"],[307,268,0.8333333134651184,10,0,11,0,11,"Mang, khiêng, vác, \u2026(biểu thị những cách thức hành động khác nhau)","Mang, khiêng, vác, .(biểu thị những cách thức hành động khác nhau)"],[113,80,1,24,0,23,0,23,"Trong mỗi pha có thể áp dụng nhiều kỹ thuật xử lý khác nhau, chi tiết sẽ được trình bày ở phần tiếp theo","Trong mỗi pha có thể áp dụng nhiều kỹ thuật xử lý khác nhau, chi tiết sẽ được trình bày ở phần tiếp theo"],[115,82,1,9,0,8,0,8,"Các phương pháp áp dụng trong các pha 2.7.1","Các phương pháp áp dụng trong các pha 2.7.1"],[198,163,1,19,0,18,0,18,"SumUM có thể thực hiện cả chức năng tóm tắt chỉ định và tóm tắt thông tin rất tốt.","SumUM có thể thực hiện cả chức năng tóm tắt chỉ định và tóm tắt thông tin rất tốt."],[262,224,1,21,0,20,0,20,"Theo đó thì bản tóm tắt sẽ dễ hiểu hơn vì bao gồm các thông tin liên quan tới truy vấn","Theo đó thì bản tóm tắt sẽ dễ hiểu hơn vì bao gồm các thông tin liên quan tới truy vấn"],[324,284,1,47,0,46,0,46,"Để hạn chế hiện tượng trùng lặp thông tin trong kết quả tóm tắt, trước khi đưa vào lựa chọn, các câu sẽ được so sánh với nhau để tìm các câu gần tương tự nhau, và loại bỏ câu có vị trí xa tiêu đề hơn","Để hạn chế hiện tượng trùng lặp thông tin trong kết quả tóm tắt, trước khi đưa vào lựa chọn, các câu sẽ được so sánh với nhau để tìm các câu gần tương tự nhau, và loại bỏ câu có vị trí xa tiêu đề hơn"],[241,204,1,32,0,31,0,31,"Dựa trên tần số từ và độ tương đồng câu Phương pháp này trình bày bởi Siva kumar và đồng sự [5] áp dụng cho tóm tắt trích rút đa văn bản","Dựa trên tần số từ và độ tương đồng câu Phương pháp này trình bày bởi Siva kumar và đồng sự [5] áp dụng cho tóm tắt trích rút đa văn bản"],[231,195,1,19,0,18,0,18,"Một thuật toán tìm kiếm sẽ được sử dụng để tìm các câu quan trọng đưa vào tóm tắt","Một thuật toán tìm kiếm sẽ được sử dụng để tìm các câu quan trọng đưa vào tóm tắt"],[35,4,1,32,0,31,0,31,"Định nghĩa Tóm tắt văn bản là quá trình làm giảm độ dài, độ phức tạp của văn bản mà vẫn giữ lại được nội dung quan trọng của văn bản đó","Định nghĩa Tóm tắt văn bản là quá trình làm giảm độ dài, độ phức tạp của văn bản mà vẫn giữ lại được nội dung quan trọng của văn bản đó"],[49,18,0.9599999785423279,12,1,12,0,11," Giản lược nội dung trình bày cho các thiết bị cầm tay","Giản lược nội dung trình bày cho các thiết bị cầm tay"],[343,300,1,16,0,15,0,15,"Chi tiết các chức năng đã ghi chú đầy đủ trên ảnh giao diện chương trình","Chi tiết các chức năng đã ghi chú đầy đủ trên ảnh giao diện chương trình"],[214,179,1,17,0,16,0,16,"Ngoài ra còn các hệ thống Tóm tắt văn bản nổi tiếng khác như ANES hay SUMMONS","Ngoài ra còn các hệ thống Tóm tắt văn bản nổi tiếng khác như ANES hay SUMMONS"],[112,79,1,29,0,28,0,28,"Vì vậy, kết quả của các hệ Tóm lược thường thuyết phục hơn (về mặt dễ đọc, dễ hiểu, liên kết ngôn ngữ tốt, gần gũi với con người)","Vì vậy, kết quả của các hệ Tóm lược thường thuyết phục hơn (về mặt dễ đọc, dễ hiểu, liên kết ngôn ngữ tốt, gần gũi với con người)"],[237,200,1,28,0,27,0,27,"Bosma [4], mục đích là tạo ra bản tóm tắt ngắn gọn chứa câu trả lời để đưa ra kết quả trong hệ thống hỏi đáp tự động","Bosma [4], mục đích là tạo ra bản tóm tắt ngắn gọn chứa câu trả lời để đưa ra kết quả trong hệ thống hỏi đáp tự động"],[249,212,1,13,0,12,0,12,"Sau khi kết thúc sẽ loại bỏ câu truy vấn khỏi kết quả","Sau khi kết thúc sẽ loại bỏ câu truy vấn khỏi kết quả"],[261,223,1,27,0,26,0,26,"Do đó kết quả tóm tắt sẽ ưu tiên các từ khóa trong truy vấn, và các từ khóa xuất hiện nhiều trong các câu được chọn","Do đó kết quả tóm tắt sẽ ưu tiên các từ khóa trong truy vấn, và các từ khóa xuất hiện nhiều trong các câu được chọn"],[277,236,1,27,0,26,0,26,"Trong giải thuật này chỉ sử dụng câu tiêu đề như câu thông thường, sau đó loại khỏi kết quả (nếu nó được chọn vào kết quả)","Trong giải thuật này chỉ sử dụng câu tiêu đề như câu thông thường, sau đó loại khỏi kết quả (nếu nó được chọn vào kết quả)"],[323,283,1,27,0,26,0,26,"Chọn câu phù hợp tạo tóm tắt Bước này sẽ áp dụng các giải thuật đánh giá câu quan trọng để đưa vào kết quả tóm tắt","Chọn câu phù hợp tạo tóm tắt Bước này sẽ áp dụng các giải thuật đánh giá câu quan trọng để đưa vào kết quả tóm tắt"],[38,7,1,21,0,20,0,20,"Tuy nhiên với lượng văn bản nhiều và dài thì việc làm thủ công vô cùng tốn thời gian, công sức","Tuy nhiên với lượng văn bản nhiều và dài thì việc làm thủ công vô cùng tốn thời gian, công sức"],[191,157,1,15,0,14,0,14,"Các ứng dụng này có thể đáp ứng rất nhiều các mục đích khác nhau","Các ứng dụng này có thể đáp ứng rất nhiều các mục đích khác nhau"],[259,221,1,27,0,26,0,26,"Trong giải thuật chọn câu, các câu được chọn sẽ được thêm vào truy vấn, với mục đích làm thêm từ khóa liên quan đến truy vấn","Trong giải thuật chọn câu, các câu được chọn sẽ được thêm vào truy vấn, với mục đích làm thêm từ khóa liên quan đến truy vấn"],[145,111,0.7796609997749329,23,12,34,1,23,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 20 phương pháp này, các cụm trùng lặp được chọn ra, phân rã xem đâu là từ tham chiếu và từ được tham chiếu","Theo phương pháp này, các cụm trùng lặp được chọn ra, phân rã xem đâu là từ tham chiếu và từ được tham chiếu"],[243,206,1,40,0,39,0,39,"Mỗi câu được tính điểm số vị trí và điểm số độ quan trọng trong cụm, sau đó từ các cụm có điểm số cao nhất, trích rút ra các câu có điểm số cao nhất tạo thành tóm tắt","Mỗi câu được tính điểm số vị trí và điểm số độ quan trọng trong cụm, sau đó từ các cụm có điểm số cao nhất, trích rút ra các câu có điểm số cao nhất tạo thành tóm tắt"],[303,262,0.7735849022865295,41,12,62,0,42,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 31 thậm chí vì vậy tuy nhiên thật ra với lại thế là trước kia đáng lẽ sau cùng tuy vậy ắt hẳn quả thật Bảng 1: Ví dụ một số từ dừng Ngoài ra ở bước này, các dấu câu, dấu phảy cũng bị xóa vì nó cũng giống từ dừng","thậm chí vì vậy tuy nhiên thật ra với lại thế là trước kia đáng lẽ sau cùng tuy vậy ắt hẳn quả thật Ngoài ra ở bước này, các dấu câu, dấu phảy cũng bị xóa vì nó cũng giống từ dừng"],[42,12,0.9830508232116699,29,1,29,0,28," Độ liên quan (Relevance): xác định mức độ phù hợp của văn bản tóm tắt với chủ đề cho trước (chủ đề có thể là một câu truy vấn)","Độ liên quan (Relevance): xác định mức độ phù hợp của văn bản tóm tắt với chủ đề cho trước (chủ đề có thể là một câu truy vấn)"],[50,19,0.95652174949646,11,1,11,0,10," Sinh tự động chủ đề, tiêu đề, dẫn đường văn bản","Sinh tự động chủ đề, tiêu đề, dẫn đường văn bản"],[85,53,0.6153846383094788,24,30,53,0,23,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 16 thay vào đó là các phép toán vector như cộng hai vector, nhân hai vector, tích vô hướng\u2026 Khi biểu diễn văn bản thành các vector, vấn đề về truy vấn và xác định độ liên quan hoàn toàn được giải quyết","Khi biểu diễn văn bản thành các vector, vấn đề về truy vấn và xác định độ liên quan hoàn toàn được giải quyết"],[122,90,1,17,0,16,0,16,"Ngoài ra, các đoạn đầu và cuối trong văn bản cũng quan trọng hơn các đoạn giữa","Ngoài ra, các đoạn đầu và cuối trong văn bản cũng quan trọng hơn các đoạn giữa"],[215,180,1,22,0,21,0,21,"Tuy nhiên tại Việt Nam hiện nay chưa có một nghiên cứu và ứng dụng Tóm tắt văn bản chính thức nào","Tuy nhiên tại Việt Nam hiện nay chưa có một nghiên cứu và ứng dụng Tóm tắt văn bản chính thức nào"],[224,188,1,75,0,74,0,74,"Đối với hệ thống hỏi đáp tự động, hệ thống sẽ tiến hành phân loại câu hỏi và thực hiện so khớp hoặc tính tương đồng với câu hỏi trong cơ sở dữ liệu để xác định câu trả lời phù hợp nhất, sau đó tóm tắt văn bản chứa câu trả lời, sử dụng câu trả lời như truy vấn, và hiển thị kèm với câu trả lời, có đánh dấu câu trả lời","Đối với hệ thống hỏi đáp tự động, hệ thống sẽ tiến hành phân loại câu hỏi và thực hiện so khớp hoặc tính tương đồng với câu hỏi trong cơ sở dữ liệu để xác định câu trả lời phù hợp nhất, sau đó tóm tắt văn bản chứa câu trả lời, sử dụng câu trả lời như truy vấn, và hiển thị kèm với câu trả lời, có đánh dấu câu trả lời"],[267,228,0.9777777791023254,22,1,22,0,21," Đầu ra: văn bản tóm tắt Chi tiết các kỹ thuật sử dụng trong các bước sẽ trình bày ở phần sau","Đầu ra: văn bản tóm tắt Chi tiết các kỹ thuật sử dụng trong các bước sẽ trình bày ở phần sau"],[328,287,1,35,0,34,0,34,"Do đó trong bước này sẽ thực hiện loại bỏ một câu nếu có độ tương tự lớn hơn 0.8 với câu nào đó đứng trước nó, theo thứ tự vị trí trong văn bản","Do đó trong bước này sẽ thực hiện loại bỏ một câu nếu có độ tương tự lớn hơn 0.8 với câu nào đó đứng trước nó, theo thứ tự vị trí trong văn bản"],[342,299,1,24,0,23,0,23,"Chương trình tóm tắt Đây là chương trình thực hiện tóm tắt một văn bản dựa trên giải thuật đã phân tích ở trên","Chương trình tóm tắt Đây là chương trình thực hiện tóm tắt một văn bản dựa trên giải thuật đã phân tích ở trên"],[253,215,1,12,0,11,0,11,"Do đó có một số ràng buộc với dữ liệu đầu vào","Do đó có một số ràng buộc với dữ liệu đầu vào"],[213,178,1,20,0,19,0,19,"Công cụ này cho phép chúng ta chọn thông số về độ rút gọn, trích rút hay sinh tiêu đề..","Công cụ này cho phép chúng ta chọn thông số về độ rút gọn, trích rút hay sinh tiêu đề.."],[355,310,1,9,0,8,0,8,"Kết quả thực hiện thu được như sau: 2.2.1","Kết quả thực hiện thu được như sau: 2.2.1"],[345,302,0.625,5,1,7,1,7,"Hình 5: Giao diện chương trình demo 2.1.1.2","Hinh 5: Giao diện chương trinh demo 2.1.1.2"],[339,296,1,7,0,6,0,6,"- Công cụ lập trình Netbeans 7.3","- Công cụ lập trình Netbeans 7.3"],[69,37,1,15,0,14,0,14,"Có ba mô hình thỏa mãn yêu cầu đó thường được sử dụng là: 2.5.1","Có ba mô hình thỏa mãn yêu cầu đó thường được sử dụng là: 2.5.1"],[298,258,0.7272727489471436,36,27,62,0,35,"Loại bỏ từ dừng Từ dừng (StopWord) là những từ thường xuất hiện nhiều trong các tài liệu nhưng thường chỉ mang ý nhấn mạnh, bổ nghĩa\u2026 nó có ý nghĩa lớn trong một số phương pháp dựa trên dấu hiệu đặc biệt, nhưng trong phương pháp dựa trên tần số từ đang xét thì các từ này làm giảm độ chính xác","nó có ý nghĩa lớn trong một số phương pháp dựa trên dấu hiệu đặc biệt, nhưng trong phương pháp dựa trên tần số từ đang xét thì các từ này làm giảm độ chính xác"],[153,119,1,7,0,6,0,6,"Có thể chia làm 2 loại: 2.7.2.1","Có thể chia làm 2 loại: 2.7.2.1"],[308,269,1,17,0,16,0,16,"Với loại 1 và loại 2 thì các từ đồng nghĩa có thể thay thế cho nhau","Với loại 1 và loại 2 thì các từ đồng nghĩa có thể thay thế cho nhau"],[314,275,1,15,0,14,0,14,"Dưới đây là một số mục từ trong bộ từ đồng nghĩa sẽ sử dụng","Dưới đây là một số mục từ trong bộ từ đồng nghĩa sẽ sử dụng"],[282,241,1,11,0,10,0,10,"Các cụm từ trong ngoặc đơn khác sẽ bị xóa đi","Các cụm từ trong ngoặc đơn khác sẽ bị xóa đi"],[169,136,1,13,0,12,0,12,"Phương pháp hiển thị phân đoạn Đây là phương pháp đơn giản nhất","Phương pháp hiển thị phân đoạn Đây là phương pháp đơn giản nhất"],[111,78,1,20,0,19,0,19,"Còn hệ Tóm lược thì phức tạp, do kết hợp các phương pháp của xử lý ngôn ngữ tự nhiên","Còn hệ Tóm lược thì phức tạp, do kết hợp các phương pháp của xử lý ngôn ngữ tự nhiên"],[181,148,0.9629629850387573,13,0,12,0,12,"Dưới đây là hai phương pháp đánh giá tự động thường sử dụng:","Dưới đây là hai phương pháp đánh giá tự động thường sử dụng: 2.8.1"],[138,105,1,12,0,11,0,11,"Sau đó chọn ra đoạn (câu) có độ liên quan lớn nhất","Sau đó chọn ra đoạn (câu) có độ liên quan lớn nhất"],[341,298,1,7,0,6,0,6,"Các công cụ đã xây dựng 2.1.1.1","Các công cụ đã xây dựng 2.1.1.1"],[125,92,0.7714285850524902,27,12,38,4,30,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 19 này thường chỉ được dùng để đánh giá độ quan trọng của các câu khác liên quan, chứ không được chọn làm đầu vào cho pha tiếp","Tuy nhiên, các câu này thường chỉ được dùng để đánh giá độ quan trọng của các câu khác liên quan, chứ không được chọn làm đầu vào cho pha tiếp"],[97,64,0.8125,13,0,15,0,15,"Sử dụng các suy diễn hợp lý để xác định và \u201clàm đẹp\u201d các ngưỡng này","Sử dụng các suy diễn hợp lý để xác định và làm đẹp các ngưỡng này"]],"t":"\n \r\nNhư đã nêu ở trên, mục tiêu cụ thể của đồ án là đề xuất và thử nghiệm một hướng \r\ntiếp cận cho bài toán tóm tắt hướng truy vấn đơn văn bản áp dụng được cho tiếng \r\nViệt. Cụ thể bài toán cần giải quyết được phát biểu như sau: \r\nĐầu vào: Văn bản, truy vấn, độ rút gọn \r\nĐầu ra: Bản tóm tắt của văn bản đầu vào xoay quanh vấn đề nêu trong truy vấn \r\nĐể giải quyết được bài toán này, việc trước hết là tìm hiểu cơ sở lý thuyết về tóm \r\ntắt văn bản, tóm tắt hướng truy vấn, từ đó xác định hướng giải quyết và thực hiện cài \r\nđặt thử nghiệm. \r\nII. TỔNG QUAN VỀ TÓM TẮT VĂN BẢN TỰ ĐỘNG \r\n2.1. Định nghĩa \r\nTóm tắt văn bản là quá trình làm giảm độ dài, độ phức tạp của văn bản mà vẫn \r\ngiữ lại được nội dung quan trọng của văn bản đó. Công việc tóm tắt văn bản đã xuất \r\nhiện từ rất lâu đời, và nó được làm thủ công, do con người đọc, rút ra các ý chính rồi \r\ntrình bày lại một cách ngắn gọn, dễ hiểu. Mục đích là giúp người sử dụng có cái nhìn \r\ntổng quan về nội dung trình bày trong văn bản, để quyết định sử dụng văn bản đó hợp \r\nlý. Tuy nhiên với lượng văn bản nhiều và dài thì việc làm thủ công vô cùng tốn thời \r\ngian, công sức. \r\nNgày nay, thời đại công nghệ thông tin phát triển mạnh, tóm tắt văn bản tự động \r\n(gọi tắt là tóm tắt văn bản) được nghiên cứu phát triển nhằm mục đích làm thay con \r\nngười công việc nặng nhọc đó. Đã có rất nhiều định nghĩa được đưa ra, tuy nhiên có \r\nthể sử dụng định nghĩa ngắn gọn sau: \r\nTóm tắt văn bản là quá trình rút ra những thông tin quan trọng nhất từ một hay \r\nnhiều nguồn văn bản để tạo ra một văn bản gọn hơn phục vụ cho một số nhiệm vụ \r\nhay người dùng cụ thể \r\n2.2. Các tiêu chí đánh giá \r\n Độ mạch lạc (Coherence): đánh giá mức độ rõ ràng của văn bản tóm tắt, tính \r\nsúc tích, khả năng có thể đọc và hiểu được của bài viết. \r\n Độ hàm chứa thông tin (Informationess): tỉ lệ thông tin của văn bản gốc trong \r\nvăn bản tóm tắt. \r\n Độ liên quan (Relevance): xác định mức độ phù hợp của văn bản tóm tắt với \r\nchủ đề cho trước (chủ đề có thể là một câu truy vấn). \r\n\r\n  \r\n\r\n   \r\n Độ dễ đọc hiểu (Reading Comprehence): một người được giao việc đọc văn \r\nbản kết quả, sau đó trả lời các câu hỏi, hệ thống sẽ phải cho điểm và từ đó đưa ra \r\nphần trăm những câu trả lời đúng. \r\n2.3. Ứng dụng của tóm tắt văn bản \r\nTóm tắt văn bản có nhiều ứng dụng trong thực tế, một số ứng dụng nổi bật như: \r\n Tóm tắt tự động các tin tức trên báo điện tử. \r\n Trợ giúp thông minh việc đọc và khai thác thông tin. \r\n Tóm lược danh sách tìm kiếm từ các Search Engine. \r\n Giản lược nội dung trình bày cho các thiết bị cầm tay. \r\n Sinh tự động chủ đề, tiêu đề, dẫn đường văn bản. \r\n Hỗ trợ tóm lược nội dung cuộc họp, website, chương trình phát thanh và \r\ntruyền hình, sổ tay công việc. \r\n2.4. Phân loại tóm tắt văn bản \r\nCó nhiều cách phân loại tóm tắt, phụ thuộc vào tiêu chí sử dụng để phân loại, sau \r\nđây là một số cách phân loại cần quan tâm: \r\n2.4.1. Theo đầu vào hệ thống \r\nTóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn gọn của văn bản \r\nđó. Ngược lại, tóm tắt đa văn bản là từ nhiều văn bản nguồn cũng chỉ cho ra một \r\nđoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng \r\nthời cho nhiều văn bản khác nhau. Rõ ràng, tóm tắt đa văn bản thì khó hơn, vì ngoài \r\nnhững công việc của tóm tắt đơn văn bản, tóm tắt đa văn bản còn phải thực hiện các \r\ncông việc như tiền xử lý trích rút, tích hợp thống nhất khuôn dạng và hiển thị kết quả \r\ntheo cách riêng. Ngoài ra, tóm tắt đa văn bản còn phải đối mặt với các vấn đề như dư \r\nthừa trùng lặp dữ liệu giữa các văn bản nguồn, nội dung các văn bản nguồn phân tán, \r\nđộ rút gọn yêu cầu cao, thời gian xử lý cần phải nhanh trong khi sự phức tạp trong xử \r\nlý lớn. \r\n2.4.2. Theo đầu ra hệ thống \r\nTóm tắt trích rút là quá trình thu gọn văn bản mà trong kết quả ra chứa các đơn \r\nvị ngữ liệu văn bản nguồn. Tóm tắt tóm lược là quá trình thu gọn văn bản mà trong \r\nkết quả ra có một số các đơn vị ngữ liệu mới được sinh ra từ các đơn vị ngữ liệu văn \r\nbản nguồn. \r\n2.4.3. Theo mục đích tóm tắt \r\nTóm tắt chung là tóm tắt theo quan điểm ban đầu của tác giả văn bản gốc. Tóm \r\ntắt hướng truy vấn là tóm tắt theo quan điểm mong muốn của người dùng ứng dụng \r\n\r\n  \r\n\r\n   \r\nthông qua các tham số truyền vào câu truy vấn. Tóm tắt hướng truy vấn được cài đặt \r\nvà áp dụng nhiều hơn nhưng trong lĩnh vực hẹp hơn, đi sâu vào các chuyên ngành cụ \r\nthể. \r\n2.5. Mô hình biểu diễn văn bản \r\nVăn bản thông thường là dạng dữ liệu phi cấu trúc, do vậy muốn xử lý chúng \r\ntrước hết phải biểu diễn thành dạng có cấu trúc. Các cấu trúc này phải có khả năng \r\nthao tác bằng các phép toán cơ bản như cộng, nhân, đại số quan hệ... Có ba mô hình \r\nthỏa mãn yêu cầu đó thường được sử dụng là: \r\n2.5.1. Mô hình boolean \r\nTrong mô hình boolean, văn bản, vốn là tập hợp của các term (thuật ngữ), được \r\nbiểu diễn bởi chỉ số từng term và trọng số của chúng. Trọng số của từng term - dùng \r\nđể đánh giá độ quan trọng của chúng - trong mô hình này chỉ mang hai giá trị 0 và 1, \r\ntùy theo sự xuất hiện của term đó trong văn bản. \r\n \r\nTrong đó wi là trọng số của term ti trong văn bản D. \r\nĐối với vấn đề truy vấn, trong mô hình này câu truy vấn bao gồm các văn bản \r\ntìm kiếm liên hệ với nhau thông qua các phép đại số quan hệ cơ bản như NOT (phủ \r\nđịnh), AND (và) hay OR (hoặc). Câu truy vấn có thể biểu diễn thành dạng vector với \r\ncác thành phần liên kết và các phép toán quan hệ cơ bản. Từ đây, độ liên quan giữa \r\nmột văn bản và truy vấn được xác định thông qua các thành phần liên kết. Độ liên \r\nquan này chỉ có thể mang hai giá trị : 0  văn bản không phù hợp với truy vấn và 1  \r\nvăn bản phù hợp. \r\nDo vậy có thể thấy rằng hạn chế lớn nhất của mô hình này đó là việc đánh giá độ \r\nliên quan chỉ trả về hai kết quả, hoặc phù hợp hoặc không, như vậy yêu cầu của hệ \r\nthống khi cần sắp xếp và chọn lựa các văn bản theo mức độ liên quan đến truy vấn sẽ \r\nkhông đạt. Độ liên quan của mô hình này không thể phân chia thành các mức khác \r\nnhau, do vậy không phản ánh được thực tế là việc liên quan giữa văn bản và truy vấn \r\ncó thể là mờ, không chắn chắn. Hạn chế này được loại bỏ khi ta sử dụng một mô hình \r\ntổng quát hơn  Mô hình không gian vector (VSM). \r\n2.5.2. Mô hình không gian vector \r\nNhư trên đã đề cập, mô hình không gian vector là mô hình tổng quát hơn mô hình \r\nBoolean. Các văn bản được biểu diễn thành các vector nhiều chiều, với trọng số không \r\nchỉ mang hai giá trị là 0 hay 1 mà có thể mang các giá trị khác tùy theo cách đánh giá, \r\ntính toán. Một khác biệt nữa so với mô hình boolean là các phép toán cơ bản của mô \r\nhình không gian vector. Các phép toán đại số quan hệ dĩ nhiên không phù hợp nữa, \r\n\r\n  \r\n\r\n   \r\nthay vào đó là các phép toán vector như cộng hai vector, nhân hai vector, tích vô \r\nhướng. \r\nKhi biểu diễn văn bản thành các vector, vấn đề về truy vấn và xác định độ liên \r\nquan hoàn toàn được giải quyết. Truy vấn là kết quả của các phép toán vector giữa \r\ncác vector biểu diễn cho những văn bản cấu thành nên truy vấn, như vậy, truy vấn \r\ntrong trường hợp này cũng là một văn bản đặc biệt. Việc xác định độ liên quan giữa \r\ntruy vấn và văn bản được quy thành độ liên quan giữa văn bản và văn bản. Hai văn \r\nbản là hai vector, vậy khoảng cách hay góc giữa chúng đều có thể đại diện cho sự liên \r\nquan giữa hai văn bản này. Tất nhiên, để áp dụng được các phép toán vector cơ bản, \r\nhai vector cần chuẩn hóa về số chiều (độ dài). \r\nCác chỉ số sử dụng trong phương pháp này: \r\n Tần suất thuật ngữ của một từ w trong một văn bản d, ký hiệu TF(w,d), có \r\nthể sử dụng các công thức sau, với fij là số lần xuất hiện của từ wi trong văn bản dj:  \r\n \r\n Tần suất văn bản của một từ w, ký hiệu DF(w) là số lượng văn bản mà từ w \r\ncó xuất hiện. Nghịch đảo của tần suất văn bản của một từ w, ký hiệu IDF(w) được \r\ncho bởi công thức: \r\n \r\nTrong đó: m là tổng số văn bản,, h là số văn bản chứa từ w \r\n Tần suất TF-IDF là kết hợp của hai loại tần suất nói trên: \r\nTF-IDF(w,d) = TF(w,d) * IDF(w) \r\nTheo mô hình này, mỗi văn bản sẽ được biểu diễn dưới dạng D(t1, t2,.,tn) với n \r\nlà tổng số thuật ngữ xuất hiện, mỗi thuật ngữ sẽ được đánh index, ti là trọng số của \r\nthuật ngữ thứ i(trong danh sách thuật ngữ) trong văn bản D. Khi đó độ liên quan giữa \r\nhai văn bản biểu diễn bởi 2 vector X(x1, x2, ., xn) và Y(y1, y2,.,yn) được tính bằng \r\ncông thức Cosin: \r\n \r\n\r\n  \r\n\r\n   \r\n2.5.3. Mô hình tập thô dung sai \r\n Mô hình tập thô dung sai (Tolerance Rough Set Model) là một mô hình mới, \r\ntiên tiến dựa trên lý thuyết về logic mờ và tập mờ (Fuzzy Set). Điều cốt lõi của lý \r\nthuyết này là việc xác định chính xác một giả thiết nào đó (ví dụ như hai văn bản này \r\ncó phù hợp, có giống nhau không...) là một điều rất khó. Tuy nhiên chúng ta có thể \r\nchỉ ra một cặp xấp xỉ trên và xấp xỉ dưới để khẳng định được giả thiết đó là đúng. Sử \r\ndụng các suy diễn hợp lý để xác định và làm đẹp các ngưỡng này. Các phép toán \r\ncơ bản trong mô hình tập thô dựa trên các quan hệ tương đương các tính chất như đối \r\nxứng, phản xạ, bắc cầu... Lý thuyết logic mờ đã và đang được ứng dụng rất mạnh mẽ \r\ntrong lĩnh vực Trí tuệ nhân tạo. \r\nMô hình tập thô gần đây được sử dụng nhiều cho các bài toán tìm kiếm cũng như \r\nphân nhóm văn bản. Tuy nhiên khi áp dụng mô hình tập thô cho quá trình xử lý văn \r\nbản thì tính chất bắc cầu không còn phù hợp. Nhóm tác giả Hồ Tú Bảo, Saori \r\nKawasaki, Nguyễn Ngọc Bình đã đề xuất ra mô hình tập thô dung sai trong đó bỏ đi \r\ntính chất bắc cầu trong quá trình xử lý văn bản. Lý thuyết tập thô được các nhà nghiên \r\ncứu Trí tuệ nhân tạo phát triển và ngày càng thể hiện được tính ưu việt không chỉ \r\ntrong  việc biểu diễn và thao tác văn bản mà còn trong các vấn đề khác của lĩnh vực \r\nnày. \r\n2.6. Mô hình tóm tắt văn bản \r\n \r\nHinh 1: Mô hình chung của tóm tắt văn bản \r\nMột mô hình tóm tắt văn bản tổng quát gồm các pha sau: \r\n Phân tích (Analysis): Phân tích văn bản đầu vào để đưa ra những mô tả bao \r\ngồm các thông tin dùng để tìm kiếm, đánh giá các đơn vị ngữ liệu quan trọng cũng \r\nnhư các tham số đầu vào cho việc tóm tắt. \r\n Biến đổi (Transformation): Lựa chọn các thông tin trích chọn được, biến đổi \r\nđể giản lược và thống nhất, kết quả là các đơn vị ngữ liệu đã được tóm tắt. \r\n Hiển thị (Generation): Từ các đơn vị ngữ liệu đã tóm tắt, liên kết chúng lại \r\nthành đoạn theo một thứ tự nào đó hoặc theo cấu kết ngữ pháp rồi hiển thị phù hợp \r\nvới yêu cầu người dùng. \r\nMột hệ Tóm lược (Abstraction) bao gồm tất cả các pha trên, tuy nhiên một hệ \r\nTrích rút (Extraction) chỉ gồm pha Phân tích và Pha Hiển thị, không có pha biến đổi. \r\nThậm chí trong các pha phân tích và hiển thị, chỉ có một số công đoạn được sử dụng. \r\nPhân tích \r\n(Analysis)\r\nBiến đổi \r\n(Transform)\r\nHiển thị \r\n(Generation)\r\n\r\n  \r\n\r\n   \r\n \r\nHinh 2: Mô hình tóm tắt văn bản trích rút \r\nNhư vậy một hệ Trích rút tiến hành ít bước hơn, các phương pháp thường dùng \r\nlà thống kê, học trên ngữ liệu. Còn hệ Tóm lược thì phức tạp, do kết hợp các phương \r\npháp của xử lý ngôn ngữ tự nhiên. Vì vậy, kết quả của các hệ Tóm lược thường thuyết \r\nphục hơn (về mặt dễ đọc, dễ hiểu, liên kết ngôn ngữ tốt, gần gũi với con người). \r\nTrong mỗi pha có thể áp dụng nhiều kỹ thuật xử lý khác nhau, chi tiết sẽ được \r\ntrình bày ở phần tiếp theo. \r\n2.7. Các phương pháp áp dụng trong các pha \r\n2.7.1. Pha Phân tích \r\nỞ pha này văn bản nguồn sẽ được tách thành các đoạn, câu, từ, kết hợp với các \r\nthông số đầu vào và áp dụng một số thuật toán cụ thể để chọn ra các đoạn hoặc câu \r\nphù hợp làm đầu vào cho pha tiếp theo. \r\nCác phương pháp áp dụng trong pha Phân tích được chia thành hai loại: Phương \r\npháp thống kê và Phương pháp cấu trúc. \r\n2.7.1.1. Phương pháp thống kê \r\nPhương pháp này sử dụng các số liệu thống kê về độ quan trọng của từ, câu hay \r\nđoạn, nhận được từ các nghiên cứu về ngôn ngữ học hay thông qua các phương pháp \r\nhọc máy dựa trên tập mẫu để trích rút ra các đơn vị ngữ liệu quan trọng  \r\n Phương pháp vị trí \r\nPhương pháp vị trí bao gồm các phương pháp xác định độ quan trọng dựa trên \r\nthống kê về vị trí của từ, ngữ hay câu trong văn bản. Các thống kê này tất nhiên phụ \r\nthuộc vào thể loại văn bản. \r\n Chủ đề - Tiêu đề (Title-based): Chủ đề các đoạn văn bản hay tiêu đề các bảng \r\nthường chứa các từ và ngữ quan trọng, nên trích rút thông tin từ đây. \r\n Đầu - cuối đoạn (First - Last Sentence): Xác suất câu đầu đoạn hay câu cuối \r\nđoạn chứa ý chính của cả đoạn là rất lớn, đặc biệt là câu đầu đoạn. Ngoài ra, \r\ncác đoạn đầu và cuối trong văn bản cũng quan trọng hơn các đoạn giữa. \r\n Minh họa - Chú thích (Comments): Trong các câu chú thích, câu minh họa \r\ncho ảnh hay đồ thị thường chứa các thông tin quan trọng. Tuy nhiên, các câu \r\n\r\n  \r\n\r\n   \r\nnày thường chỉ được dùng để đánh giá độ quan trọng của các câu khác liên \r\nquan, chứ không được chọn làm đầu vào cho pha tiếp. \r\n Phương pháp ngữ cố định \r\nCác ngữ cố định có đặc điểm thống kê rất tốt. Sau các ngữ này thường là các câu \r\nhay từ có độ quan trọng là xác định. Người ta chia thành hai loại ngữ cố định, một \r\nloại mang lại độ quan trọng cho thành phần đi sau, được gọi là ngữ nhấn mạnh, một \r\nloại giúp ta loại bỏ, không xét đến những thành phần đi sau vì nó không có nhiều giá \r\ntrị trong việc trích rút, được gọi là ngữ dư thừa: \r\n Ngữ nhấn mạnh (Bonus phrase - Emphasizer): Ngữ nhấn mạnh gồm các ngữ \r\nnhư nói chung là., đặc biệt là., cuối cùng thì., trong bài viết này \r\ntôi muốn chỉ ra., bài viết nói về., nội dung gồm.,..v..v... \r\n Ngữ dư thừa (Stigma phrases): Một số ngữ dư thừa: hiếm khi mà., bài \r\nnày không nói đến., Không thể nào., ..v..v... \r\n Phương pháp thống kê tần suất từ \r\nĐộ quan trọng của từ phụ thuộc vào số lần xuất hiện của từ đó trong các văn bản \r\nliên quan. Các kỹ thuật như TF.IPF hay Tập thuật ngữ thường xuyên (Frequent Item \r\nSet) dùng cho công việc xác định tần suất của từ. \r\n2.7.1.2. Phương pháp cấu trúc \r\nLà các phương pháp sử dụng các mối liên hệ cấu trúc - ngữ pháp - ngữ nghĩa để \r\nxác định các đơn vị ngữ liệu quan trọng. Tư tưởng chính của các phương pháp này là \r\nnhững đơn vị ngữ liệu nào có chứa các thành phần liên kết nhiều với các thành phần \r\nkhác sẽ có độ quan trọng lớn. Việc đánh giá các mối quan hệ sẽ dựa trên các mạng \r\nngữ nghĩa, các quan hệ cú pháp hoặc thông qua các phương pháp xác định độ liên \r\nquan truyền thống. \r\n Phương pháp quan hệ lẫn nhau: Phương pháp này xác định mối quan hệ \r\ngiữa các đoạn trong văn bản hay các câu trong đoạn với nhau thông qua các kỹ thuật \r\nthu thập thông tin ở mức văn bản. Các đoạn (câu) trong văn bản nguồn được tính toán \r\nđộ liên quan lẫn nhau sử dụng các kỹ thuật như Cosine, TF.IPF hay N-gram Overlap. \r\nSau đó chọn ra đoạn (câu) có độ liên quan lớn nhất. \r\n Phương pháp liên kết từ vựng: Phương pháp liên kết từ vựng sử dụng các từ \r\nđiển quan hệ từ vựng đế xây dựng các chuỗi từ liên kết với nhau vể mặt ngữ nghĩa. \r\nVí dụ cây là một loại thực vật, có bộ phận là lá, chất liệu là gỗ. Các từ cây, \r\nthực vật, lá, gỗ có quan hệ ngữ nghĩa nào đó với nhau. Sau khi xây dựng được \r\ncác chuỗi từ này, đánh giá độ mạnh của chúng và có những trích chọn phù hợp. \r\n Phương pháp Liên kết tham chiếu: Phương pháp liên kết tham chiếu còn \r\nđược gọi là phương pháp trích chọn trùng lặp (Anaphora-based Method). Theo \r\n\r\n  \r\n\r\n   \r\nphương pháp này, các cụm trùng lặp được chọn ra, phân rã xem đâu là từ tham chiếu \r\nvà từ được tham chiếu. Sau khi phân tách các cụm trùng lặp, chúng ta tạo chuỗi các \r\ntừ tham chiếu đến cùng một từ được tham chiếu. Chuỗi dài nhất sẽ được coi là trọng \r\ntâm của đoạn, các câu chứa các từ trong chuỗi này có một độ ưu tiên nào đó khi xét \r\ntrích chọn. \r\n Phương pháp quan hệ câu: Dựa trên các từ thể hiện mối quan hệ giữa các \r\ncâu chúng ta cấu trúc hóa đoạn văn bản từ các đơn vị thành phần như ngữ, mệnh đề, \r\ncâu... Sau đó đơn vị được coi như trung tâm sẽ được trích chọn. \r\n2.7.2. Pha Biến đổi \r\nỞ pha này, các câu sẽ được biến đổi, làm gọn lại hoặc kết hợp nhiều câu tạo thành \r\ncâu mới ngắn gọn hơn. Các phương pháp trong pha này không làm tăng thêm độ \r\nchính xác mà chỉ giúp cho văn bản kết quả ngắn gọn hơn mà vẫn sát nghĩa và thuật \r\ntoán thưởng rất phức tạp. Có thể chia làm 2 loại: \r\n2.7.2.1. Giản lược về cấu trúc câu \r\nGiản lược về cấu trúc câu là việc lược bỏ trong câu các phần thừa, ít mang giá trị, \r\nlàm cho cấu trúc câu thu gọn lại. Công việc này thường dựa trên phân tích cú pháp \r\ncác thành phần trong câu. \r\n2.7.2.2. Giản lược về mặt ngữ nghĩa \r\n Phương pháp trừu tượng hóa khái niệm \r\nTư tưởng của phương pháp này là từ các khái niệm cụ thể thay thế bằng khái niệm \r\nchung. \r\nVí dụ: Tôi ăn dâu, táo và đào => Tôi ăn trái cây \r\n Phương pháp thay thế bộ phận \r\nTư tưởng của phương pháp này là từ các khái niệm bộ phận thay thế bằng khái \r\nniệm toàn bộ. \r\nVí dụ: Xích, líp, ghi đông, bàn đạp . => Cái xe đạp.. \r\n Phương pháp thay thế ngữ tương đương \r\nTư tưởng của phương pháp này là các ngữ đóng vai trò như nhau trong câu được \r\nthay bằng một ngữ chung. \r\nVí dụ: Anh ấy bước vào, ngồi xuống ghế, xem thực đơn, gọi món, ăn, trả tiền và \r\nra về => Anh ấy đi ăn tiệm. \r\n Phương pháp thay thế từ, ngữ đồng nghĩa ngắn hơn \r\n\r\n  \r\n\r\n   \r\nMột phương pháp khác khá dễ hiểu đấy là việc thay thế một từ, ngữ bằng một từ, \r\nngữ khác đồng nghĩa hoặc gần nghĩa nhưng có độ dài ngắn hơn. Điều này thường \r\nthông qua một từ điển các từ đồng nghĩa (Thesaurus). \r\n Phương pháp thay thế bởi đại diện \r\nTư tưởng của phương pháp này là thay thế một ngữ bằng một ngữ khác có ý nghĩa \r\nđại diện cho ngữ ban đầu. \r\nVí dụ: Người phát ngôn viên của chính phủ Hoa Kỳ thông báo. => \r\nWashington thông báo.. \r\n2.7.3. Pha Hiển thị \r\n2.7.3.1. Phương pháp hiển thị phân đoạn \r\nĐây là phương pháp đơn giản nhất. Các đơn vị ngữ liệu được trích rút hay giản \r\nlược từ các pha trước được liên kết lại thành đoạn theo thứ tự tiền định của chúng, \r\nkhông thêm bớt từ nối và cũng không sắp xếp lại các đơn vị ngữ liệu. Văn bản kết \r\nquả của phương pháp này có độ dễ đọc dễ hiểu kém, thậm chí lủng củng về nghĩa vì \r\ncác đơn vị ngữ liệu được trích rút mắc phải một số lỗi như mập mờ tham chiếu, không \r\ncó từ nối hoặc là thừa từ và ngữ. \r\n2.7.3.2. Phương pháp hiển thị liên kết \r\nViệc hiển thị liên kết là tiếp nhận các đơn vị ngữ liệu đã được trích rút và giản \r\nlược từ các pha trước đó, phân tích mối quan hệ về nghĩa của các câu rồi thêm bớt \r\ncác từ nối, từ dẫn và sắp xếp theo một thứ tự mới dựa vào những gì đã thu thập sao \r\ncho thỏa mãn yêu cầu về hiển thị và yêu cầu về độ dễ đọc, dễ hiểu của người dùng. \r\n2.8. Đánh giá kết quả tóm tắt \r\nĐánh giá một bản tóm tắt là một công việc khó bởi không tồn tại một bản tóm tắt \r\nlý tưởng cho một (hoặc một tập) văn bản đưa ra. Hơn nữa, việc đánh giá nội dung \r\ntóm tắt cũng rất khó khăn. Trường hợp kết quả là một câu trả lời cho một câu hỏi, ta \r\ncó thể xác định được câu trả lời đó đúng hay sai, nhưng trong các trường hợp khác, \r\nthật khó trả lời liệu đầu ra là phải một kết quả đúng hay không? Thực tế luôn có khả \r\nnăng một hệ thống sinh ra một bản tóm tắt tốt nhưng lại sai khác với bản tóm tắt do \r\nngười thực hiện. Bên cạnh đó, khi việc đánh giá được thực hiện bởi con người thì chi \r\nphí đánh giá sẽ rất cao. Mặt khác, tóm tắt văn bản còn liên quan đến tỉ lệ nén văn bản, \r\ndo đó, việc đánh giá bản tóm tắt cần phải quan tâm đến vấn đề này, khi đó độ phức \r\ntạp và chi phí đánh giá sẽ tăng cao. \r\nDưới đây là hai phương pháp đánh giá tự động thường sử dụng: \r\n\r\n  \r\n\r\n   \r\n2.8.1. Sử dụng so khớp n-gram \r\nPhương pháp này được Lin và Hovy đưa ra năm 2002 dựa trên mô hình n-gram \r\ncủa độ đo BLEU (Bilingual Evaluation Understudy [1], độ đo đánh giá kết quả dịch \r\nmáy). Ý tưởng của phương pháp này là so khớp n-gram liên tiếp của bản tóm tắt thủ \r\ncông và tóm tắt tự động, theo công thức sau: \r\nScore=1*Score1+ 2*Score2+ 3*Score3+ 4*Score4 \r\nTrong đó: \r\nScorei = Số i-gram trùng nhau/Tổng số i-gram của bản tóm tắt thủ công \r\n   i là hệ số đánh giá độ quan trọng của các Scorei \r\n2.8.2. Sử dụng các độ đo ROUGE \r\nROUGE(Recall-Oriented Understudy of Gisting Evaluation [2]) cũng được đưa \r\nra bởi Lin, vào năm 2009, đây là tập hợp các độ đo dựa trên mô hình n-gram của \r\nBLEU với nhiều cách tính khác nhau. Thường sử dụng nhất là độ đo ROUGE-N, với \r\nn là giá trị của mô hình n-gram, n={1,2,3,4}. \r\nCông thức của độ đo ROUGE-N như sau: Cho R=(r1, r2, ., rn) là tập các tóm tắt \r\nmẫu, s là tóm tắt tự động, n(d) là vector biểu diễn mô hình n-gram của văn bản d. \r\n \r\nĐộ đo ROUGE được sử dụng làm độ đo chính thức của các hội nghị DUC 2004-\r\n2007 và TAC 2008-2012. \r\n2.9. Một số hệ thống tóm tắt văn bản tiêu biểu \r\nHiện tại, trên thế giới đã có rất nhiều nghiên cứu và dự án xây dựng các ứng dụng \r\ntóm tắt văn bản. Các ứng dụng này có thể đáp ứng rất nhiều các mục đích khác nhau. \r\nCó thể kể ra một số ứng dụng Tóm tắt văn bản tiêu biểu như sau: \r\n SUMMARIST: Một hệ thống Trích rút văn bản năm thứ tiếng (tiếng Anh, \r\ntiếng Nhật, tiếng Tây Ban Nha, tiếng Ả-rập và tiếng Hàn Quốc). Hiện tại \r\nSUMMARIST đang nghiên cứu để cải tiến trở thành một hệ thống Tóm lược \r\nvăn bản và hỗ trợ nhiều ngôn ngữ hơn như tiếng Pháp và Indonesia. \r\n SweSUM: Ứng dụng Tóm tắt văn bản đa ngôn ngữ của Học viện công nghệ \r\nhoàng gia Thụy Điển. SweSUM có thể tóm tắt các văn bản có ngôn ngữ vùng \r\nScandinavi như Thụy Điển, Đan Mạch, Na Uy và các ngôn ngữ khác như tiếng \r\nAnh, Pháp, Đức, Tây Ban Nha và cả tiếng Iran. \r\n\r\n  \r\n\r\n   \r\n SumUM: Hệ thống Tóm lược văn bản kỹ thuật của nhóm nghiên cứu xử lý \r\nngôn ngữ tự nhiên trường Đại học Montréal, Canada. SumUM có thể thực hiện \r\ncả chức năng tóm tắt chỉ định và tóm tắt thông tin rất tốt.. \r\n FJCL: Hệ thống Rút trích văn bản tiếng Nhật được phát triển trong phòng \r\nnghiên cứu Ikeda của trường đại học Gifu. Đây là một hệ thống sử dụng các \r\nphương pháp áp dụng cho hệ ngôn ngữ đơn âm tiết (monosyllabic language \r\nsystem) như tiếng Nhật, Hàn Quốc, Trung Quốc và Việt Nam. \r\n Pertinence Summarizer: Hệ thống tóm tắt tin tức đa ngôn ngữ trực tuyến nổi \r\ntiếng. Hiện tại để thử nghiệm khả năng của mình, Pertinence đã được tích hợp \r\nvới Google và tóm tắt tự động danh sách tìm kiếm trả về từ Google thông qua \r\ncâu truy vấn đưa vào. Chúng ta có thể thử nghiệm hệ thống này trên trang web: \r\nwww.pertinence.net. \r\n MEAD: Nền tảng cho các hệ thống Tóm tắt nhiều văn bản và đa ngôn ngữ. \r\nĐây là một bộ công cụ xây dựng trên nền Linux và Solaris, sử dụng ngôn ngữ \r\nPerl - Một ngôn ngữ có khả năng xử lý văn bản rất linh hoạt và mạnh mẽ. \r\nMEAD biểu diễn, lưu trữ dữ liệu ở dạng XML, cung tấp cho chúng ta khung \r\nứng dụng để cài đặt các ứng dụng Tóm tắt văn bản cho ngôn ngữ mà ta muốn. \r\nNgoài ra MEAD cũng cung cấp các công cụ để xây dựng các ứng dụng đánh \r\ngiá hệ thống tóm tắt theo các tiêu chí và các tập mẫu nổi tiếng. MEAD được \r\nxây dựng bởi các chuyên gia nổi tiếng về Xử lý ngôn ngữ ở khắp nơi trên thế \r\ngiới dưới sự tài trợ của Chương trình Nghiên cứu Công nghệ thông tin của Tổ \r\nchức Khoa học quốc gia Mỹ. MEAD được cung cấp ở dạng mã nguồn mở để \r\nnghiên cứu và kế thừa. Hiện tại phiên bản mới nhất của MEAD là MEAD \r\nv3.07. \r\n Microsoft Word AutoSummary: Microsoft cũng cài đặt chức năng Trích rút \r\nvà sinh tiêu đề trong Microsoft Word từ phiên bản Word '97. Chúng ta có thể \r\nthử bằng cách chọn Tools - AutoSummarize trên thanh công cụ (có thể khác \r\ntùy vào phiên bản). Công cụ này cho phép chúng ta chọn thông số về độ rút \r\ngọn, trích rút hay sinh tiêu đề... \r\nNgoài ra còn các hệ thống Tóm tắt văn bản nổi tiếng khác như ANES hay \r\nSUMMONS. Tuy nhiên tại Việt Nam hiện nay chưa có một nghiên cứu và ứng dụng \r\nTóm tắt văn bản chính thức nào. \r\n  \r\n\r\n  \r\n\r\n   \r\nIII. BÀI TOÁN TÓM TẮT VĂN BẢN HƯỚNG TRUY VẤN \r\n3.1. Định nghĩa \r\nTheo định nghĩa ở trên, tóm tắt văn bản hướng truy vấn là một dạng tóm tắt văn \r\nbản (khi phân chia theo mục đích tóm tắt), điểm đặc trưng là ở giai đoạn tiền xử lý, \r\nviệc tính toán sẽ phụ thuộc một phần vào truy vấn người dùng. \r\n3.2. Ứng dụng của bài toán \r\nTóm tắt hướng truy vấn thường sử dụng trong việc tóm tắt kết quả trả về của máy \r\ntìm kiếm thông tin, hoặc trong các hệ thống hỏi đáp tự động. \r\nHiện nay, đối với máy tìm kiếm, hệ thống sẽ tóm tắt văn bản theo tóm tắt đơn văn \r\nbản thông thường, lưu vào cơ sở dữ liệu, và thực hiện tìm kiếm trên bản tóm tắt đó \r\nđể giảm thời gian tìm kiếm. Sau khi xác định được văn bản phù hợp, văn bản đó sẽ \r\nđược tóm tắt lại theo truy vấn người dùng để đưa ra hiển thị kèm với kết quả. Đối với \r\nhệ thống hỏi đáp tự động, hệ thống sẽ tiến hành phân loại câu hỏi và thực hiện so \r\nkhớp hoặc tính tương đồng với câu hỏi trong cơ sở dữ liệu để xác định câu trả lời phù \r\nhợp nhất, sau đó tóm tắt văn bản chứa câu trả lời, sử dụng câu trả lời như truy vấn, \r\nvà hiển thị kèm với câu trả lời, có đánh dấu câu trả lời. \r\nTóm lại, tóm tắt hướng truy vấn thường được tích hợp ở giai đoạn xử lý kết quả \r\ncủa hệ thống tìm kiếm thông tin và hỏi đáp tự động, mục đích là thêm thông tin để \r\nkết quả rõ ràng và dễ hiểu hơn với người dùng \r\n3.3. Một số hướng tiếp cận phổ biến \r\n3.3.1. Dựa trên đồ thị \r\nPhương pháp này được đưa ra bởi [3] Jagadeesh và đồng sự, áp dụng cho tóm tắt \r\ntrích rút đa văn bản. Đồ thị của văn bản sẽ được xây dựng dựa trên việc phân tích các \r\ncâu trong đó để tìm ra các cụm danh từ(noun phrases), sau đó phân tích các cụm danh \r\ntừ này để tìm ra mối quan hệ giữa các danh từ sử dụng các hàm heuristic. Đồ thị thu \r\nđược sẽ bao gồm 2 dạng nút, nút thành phần(là các danh từ trích rút từ văn bản) và \r\nnút liên kết, có 2 loại nút liên kết là isa(là một) và related_to(liên quan với). \r\nSau khi xây dựng đồ thị cho mỗi câu, chúng sẽ được kết hợp để tạo đồ thị cho \r\ntoàn văn bản. Một thuật toán tìm kiếm sẽ được sử dụng để tìm các câu quan trọng đưa \r\nvào tóm tắt. Có 3 giải thuật có thể áp dụng: \r\n- Dựa trên tâm các đồ thị: một đồ thị trung tâm cho tất cả văn bản được xây \r\ndựng, tích hợp thêm đồ thị của truy vấn. Sau đó các câu có đồ thị tương \r\nđồng với tâm lớn nhất sẽ được chọn \r\n- Dựa trên đồ thị truy vấn: các câu có đồ thị tương đồng với đồ thị truy vấn \r\nlớn nhất sẽ được chọn \r\n\r\n  \r\n\r\n   \r\n- Dựa trên việc kết hợp câu đã chọn: giống bước trên nhưng sau khi chọn \r\nđược mỗi câu thì kết hợp câu đó vào tâm tạo thành tâm mới \r\nPhương pháp này cho kết quả tương đối chính xác nhưng phụ thuộc chủ yếu vào \r\ngiải đoạn phân tích cú pháp để tìm các cụm danh từ, do đó cần bộ phân tích cú pháp \r\nchính xác. \r\n3.3.2. Dựa trên cấu trúc diễn ngôn \r\nPhương pháp này được trình bày bởi W. Bosma [4], mục đích là tạo ra bản tóm \r\ntắt ngắn gọn chứa câu trả lời để đưa ra kết quả trong hệ thống hỏi đáp tự động. Trong \r\nđó mỗi văn bản được biểu diễn bởi đồ thị có trọng số dựa trên lý thuyết diễn ngôn, \r\nmỗi đỉnh đại diện cho một câu, trọng số trên mỗi cạnh là khoảng cách giữa hai câu. \r\nMột thuật toán tìm kiếm đồ thị sẽ được sử dụng để chọn ra các câu có tổng trọng số \r\ntrên đường đi tới câu trả lời(vai trò như truy vấn) nhỏ nhất. \r\n3.3.3. Dựa trên tần số từ và độ tương đồng câu \r\nPhương pháp này trình bày bởi Siva kumar và đồng sự [5] áp dụng cho tóm tắt \r\ntrích rút đa văn bản. Trước tiên các văn bản sẽ được biểu diễn trong mô hình không \r\ngian vector, mỗi câu được tính khoảng cách với câu truy vấn, sau đó sử dụng thuật \r\ntoán phân cụm, chia các câu vào các cụm. Mỗi câu được tính điểm số vị trí và điểm \r\nsố độ quan trọng trong cụm, sau đó từ các cụm có điểm số cao nhất, trích rút ra các \r\ncâu có điểm số cao nhất tạo thành tóm tắt. \r\n3.4. Đề xuất hướng giải quyết cho tiếng Việt \r\nQua tìm hiểu về các vấn đề liên quan trong tóm tắt và đặc trưng của tiếng Việt, \r\ndễ nhận thấy rằng việc tiếp cận ở mức cú pháp và ngữ nghĩa là khá khó khăn, một \r\nphần là vì công cụ và dữ liệu hỗ trợ, tuy đã có một số công cụ gán nhãn từ vựng và \r\nphân tích cú pháp cho độ chính xác cao nhưng thường chỉ áp dụng cho lĩnh vực hẹp, \r\nvà còn ở mức nghiên cứu, chưa được công bố chính thức. Mặt khác, do đặc trưng về \r\nngữ pháp nên các hướng tiếp cận đó thường không chính xác với tiếng Việt. \r\nDo đó em xin đề xuất mô hình trích rút các câu quan trọng cho bài toán tóm tắt \r\nhướng truy vấn dựa trên tần số từ và độ tương đồng câu, áp dụng cho tóm tắt đơn \r\nvăn bản. Mô tả sơ lược như sau: Đầu tiên sử dụng câu truy vấn làm tâm tóm tắt, sau \r\nđó tìm câu có độ tương đồng với tâm lớn nhất, mỗi câu được chọn sẽ kết hợp với tâm \r\ntạo nên tâm mới. Sau khi kết thúc sẽ loại bỏ câu truy vấn khỏi kết quả. Phương pháp \r\nnày dựa theo ý tưởng ở giải thuật thứ 2 trong hướng tiếp cận dựa trên đồ thị đã nêu ở \r\ntrên, nhưng các câu ở đây biểu diễn theo mô hình không gian vector và độ tương đồng \r\nsử dụng độ đo cosin. \r\nPhạm vi ứng dụng hướng tới của mô hình là tích hợp vào modul trả kết quả của \r\nbộ máy tìm kiếm văn bản(search engine), thực hiện tóm tắt văn bản kết quả theo tập \r\n\r\n  \r\n\r\n   \r\ntừ khóa đã tìm kiếm(chính là truy vấn người dùng). Do đó có một số ràng buộc với \r\ndữ liệu đầu vào. \r\nVì văn bản đã được máy tìm kiếm lựa chọn nên nội dung của văn bản và truy vấn \r\nsẽ liên quan với nhau. Do đó các câu chứa nhiều từ khóa trong truy vấn, hay trong \r\ntrường hợp này là độ tương đồng lớn, sẽ mang các thông tin quan trọng liên quan đến \r\ntruy vấn mà người dùng quan tâm. Tuy nhiên trong vấn đề tìm kiếm, phần lớn người \r\ndùng thường không nắm rõ được nội dung mình muốn biết nên mới sử dụng tìm kiếm, \r\nmà chỉ biết các từ khóa liên quan tới vấn đề đó. Ví dụ như tìm kiếm thông tin về giá \r\nvàng, người ta không biết giá vàng tăng hay giảm, có biến động gì gần đây. Hoặc tìm \r\ncách sửa một lỗi máy tính thì người dùng sẽ đưa ra các thông tin về lỗi đó, sau khi \r\nxem bản tóm tắt của các kết quả từ máy tìm kiếm, sẽ biết được kết quả nào phù hợp \r\nđể quyết định đọc hay không. \r\nTrong giải thuật chọn câu, các câu được chọn sẽ được thêm vào truy vấn, với mục \r\nđích làm thêm từ khóa liên quan đến truy vấn. Nhưng không phải từ nào trong các \r\ncâu đó cũng đều quan trọng nên các từ xuất hiện trong truy vấn gốc được nhân lên \r\nmột trọng số . Do đó kết quả tóm tắt sẽ ưu tiên các từ khóa trong truy vấn, và các từ \r\nkhóa xuất hiện nhiều trong các câu được chọn. Theo đó thì bản tóm tắt sẽ dễ hiểu hơn \r\nvì bao gồm các thông tin liên quan tới truy vấn. \r\nTổng quan về modul đó như sau: \r\n Đầu vào \r\n- Văn bản: văn bản đầu vào sử dụng bộ mã Unicode utf-8, chỉ chứa text, chính \r\nxác về chính tả, dấu câu, không quá ngắn(5 câu trở lên), nội dung phải liên \r\nquan tới truy vấn. \r\n- Truy vấn: sử dụng bộ mã như văn bản, là một đoạn văn bản chứa các từ khóa \r\ncần tìm kiếm, nếu cần chính xác thì dùng dấu phảy để ngăn cách các từ khóa \r\n- Độ rút gọn: có thể là số lượng từ (100-150 từ) hoặc phần trăm văn bản nguồn \r\n(10-20%). \r\n Thực hiện tóm tắt \r\nBước này áp dụng mô hình tóm tắt đã đề xuất để tạo kết quả \r\n- Chuẩn hóa: bước này sẽ thực hiện xử lý tiêu đề, các đoạn văn trong ngoặc đơn  \r\n- Tách câu, tách từ: thực hiện tách câu, tách từ sử dụng công cụ VNTokenizer \r\n- Loại bỏ từ dừng: tìm kiếm và loại bỏ các từ dừng dựa trên danh sách có sẵn \r\n- Xử lý từ đồng nghĩa: đồng bộ các từ đồng nghĩa về cùng 1 dạng  \r\n- Mô hinh hóa văn bản: tính TF.IDF và chuyển các câu về dạng vector \r\n\r\n  \r\n\r\n   \r\n- Trích rút câu, tạo tóm tắt: đây là giải thuật đã đề xuất, thực hiện tính toán độ \r\ntương đồng sử dụng độ đo cosin và một số phép toán trên vector để tìm kiếm \r\ncác câu phù hợp đưa vào kết quả tóm tắt, và được ghép lại theo phương pháp \r\nhiển thị phân đoạn. \r\n Đầu ra: văn bản tóm tắt \r\n Chi tiết các kỹ thuật sử dụng trong các bước sẽ trình bày ở phần sau. \r\n  \r\n\r\n  \r\n\r\n   \r\nPHẦN 2. GIẢI QUYẾT VẤN ĐỀ \r\nI.  PHÂN TÍCH MÔ HÌNH THỰC HIỆN BÀI TOÁN \r\nDựa vào các kiến thức về tóm tắt văn bản đã trình bày ở trên, trong phần này em \r\nsẽ trình bày chi tiết các kỹ thuật áp dụng trong từng bước của mô hình xử lý đã đề \r\nxuất. \r\n \r\nHinh 3: Mô hình tóm tắt văn bản hướng truy vấn \r\n\r\n  \r\n\r\n   \r\n1.1. Giai đoạn phân tích \r\n1.1.1. Chuẩn hóa \r\n Xử lý câu tiêu đề \r\nCâu tiêu đề của một văn bản (nếu có) thường mang nội dung chính trình bày trong \r\nvăn bản, do đó các từ khóa trong đó cũng được dùng để phát hiện tóm tắt (một số giải \r\nthuật còn tăng trọng số cho những từ xuất hiện trong tiêu đề), nhưng không đưa câu \r\ntiêu đề vào kết quả tóm tắt, nên cần phát hiện để loại bỏ khỏi kết quả. Việc phát hiện \r\ncâu tiêu đề có thể dựa vào dấu hiệu câu tiêu đề là câu duy nhất của đoạn đầu tiên. \r\nTrong giải thuật này chỉ sử dụng câu tiêu đề như câu thông thường, sau đó loại khỏi \r\nkết quả (nếu nó được chọn vào kết quả). \r\n Xử lý các cụm từ trong ngoặc \r\nCác cụm từ trong ngoặc có thể là chú thích hoặc viết tắt của cụm từ nào đó, nếu \r\nlà chú thích thì có thể bỏ qua còn từ viết tắt thì khá quan trọng, nhất là đối với tóm \r\ntắt hướng truy vấn. \r\nVí dụ: Sinh viên tình nguyện(SVTN) đi đến các vùng sâu để giúp đỡ đồng bào \r\nCác câu sau câu này sẽ sử dụng cụm từ SVTN, nếu truy vấn có từ khóa sinh viên \r\ntình nguyện thì các câu sử dụng từ viết tắt sẽ không được quan tâm. \r\nViệc xử lý từ viết tắt không đơn giản là phát hiện các từ trong ngoặc, tùy từng \r\nloại văn bản của chuyên ngành nào đó, các từ viết tắt vẫn được sử dụng mà không \r\ngây hiểu lầm cho người đọc, vì trong các lĩnh vực ấy nó chỉ có thể thay thế cho cụm \r\ntừ cố định nào đó, hoặc do thói quen, sử dụng nhiều thì mọi người đều biết. \r\nVí dụ: UBND thường được dùng thay thế cho Ủy ban nhân dân \r\nTrong giải thuật này chỉ xử lý các cụm từ viết tắt chữ đầu trong ngoặc đơn, còn \r\ncác trường hợp khác do chưa xây dựng được bộ dữ liệu cụ thể nên không xét đến. \r\nCác cụm từ trong ngoặc đơn khác sẽ bị xóa đi. \r\n1.1.2. Tách câu, tách từ \r\nTrong tiếng Việt, dấu cách (space) không được sử dụng như 1 kí hiệu phân tách \r\ntừ, nó chỉ có ý nghĩa phân tách các âm tiết với nhau, có khoảng 70% các từ gồm 2 âm \r\ntiết, và 14% các từ gồm 3 âm tiết, còn lại là 1 âm tiết. Hơn nữa, việc kết hợp các âm \r\ntiết có nhiều cách, mỗi cách cho một nghĩa khác nhau. Vì thế, để xử lý tiếng Việt, bài \r\ntoán tách từ (word segmentation) là 1 trong những bài toán cơ bản và quan trọng bậc \r\nnhất. Ngoài tiếng Việt, có khá nhiều các ngôn ngữ châu Á khác cũng cần bước tách \r\ntừ, ví dụ như: tiếng Nhật, tiếng Trung, tiếng Hàn,. do đó vấn đề này nhận được sự \r\nquan tâm rộng rãi và có nhiều hướng tiếp cận khác nhau. \r\nMột số phương pháp có thể áp dụng: \r\n\r\n  \r\n\r\n   \r\no So khớp từ dài nhất (Longest Matching) \r\no So khớp cực đại (Maximum Matching) \r\no Mô hình Markov ẩn (Hidden Markov Models- HMM) \r\no Học dựa trên sự cải biến (Transformation-based Learning  TBL) \r\no Chuyển đổi trạng thái trọng số hữu hạn(Weighted Finite State Transducer) \r\no Độ hỗn loạn cực đại (Maximum Entropy  ME) \r\no Máy học sử dụng vectơ hỗ trợ (Support Vector Machines) \r\no Trường xác xuất có điều kiện (CRFs) \r\nBài toán tách từ khá phức tạp, do đó việc tách từ trong bước này sẽ sử dụng công \r\ncụ VNTokenizer, được phát triển bởi nhóm tác giả Lê Hồng Phương. \r\nĐây là công cụ tách từ tự động cho tiếng Việt, mã nguồn mở, được viết bằng ngôn \r\nngữ Java. Phiên bản cũ nhất là phiên bản vnTokenizer 2.0 được xây dựng vào năm \r\n2005 khi đó nó mới là một ứng dụng đơn với giao diện đơn giản. Để sử dụng trong \r\nchương trình lần này, phiên bản mới nhất 4.1.1c, mã nguồn của công cụ được tải tại \r\nwebsite của dự án VLSP [6]. \r\nCông cụ này được xây dựng sử dụng kết hợp từ điển (từ điển tiếng Việt được lấy \r\ntừ đề tài VLSP) và ngram, trong đó mô hình ngram được huấn luyện sử dụng treebank \r\ntiếng Việt (70,000 câu đã được tách từ), treebank là kho ngữ liệu câu được chú giải \r\nngữ pháp. \r\nVới độ chính xác xấp xỉ 97% (theo thống kê của tác giả trên website) là kết quả \r\nrất cao so với công cụ tách từ hiện nay. \r\nNgoài ra việc tách câu khá đơn giản nhưng cần xử lý các trường hợp nhập nhằng \r\ndấu chấm câu và dấu chấm trong từ(trong email, số thập phân, địa chỉ web). Do đó \r\nđể tiết kiệm thời gian, việc tách câu trong phần này sử dụng luôn modul tách câu \r\ntrong công cụ VNTokenizer. \r\n1.1.3. Loại bỏ từ dừng \r\nTừ dừng (StopWord) là những từ thường xuất hiện nhiều trong các tài liệu nhưng \r\nthường chỉ mang ý nhấn mạnh, bổ nghĩa. nó có ý nghĩa lớn trong một số phương \r\npháp dựa trên dấu hiệu đặc biệt, nhưng trong phương pháp dựa trên tần số từ đang \r\nxét thì các từ này làm giảm độ chính xác. Trong giải thuật này chủ yếu dựa trên trọng \r\nsố từ nên việc loại bỏ từ dừng là rất cần thiết. \r\nTừ dừng sẽ được loại bỏ nhờ một danh sách từ dừng xây dựng sẵn, tham khảo tại \r\n[7], sau khi tách từ, các từ xuất hiện trong từ điển từ dừng sẽ bị xóa. Dưới đây là một \r\nsố từ dừng trích trong file sẽ sử dụng. \r\n\r\n  \r\n\r\n   \r\nthậm chí vì vậy tuy nhiên \r\nthật ra với lại thế là \r\ntrước kia đáng lẽ sau cùng \r\ntuy vậy ắt hẳn quả thật \r\nNgoài ra ở bước này, các dấu câu, dấu phảy cũng bị xóa vì nó cũng giống từ dừng. \r\n1.1.4. Xử lý từ đồng nghĩa \r\nCó 3 loại từ đồng nghĩa cần xét đến: \r\n Từ có nghĩa giống nhau hoặc gần giống nhau. \r\nVí dụ: siêng năng, chăm chỉ, cần cù, . \r\n Từ đồng nghĩa hoàn toàn \r\nVí dụ: hổ, cọp, hùm, . \r\n Từ đồng nghĩa không hoàn toàn \r\nVí dụ:  \r\nĂn, xơi, chén, .(biểu thị thái độ, tình cảm khác nhau đối với người đối \r\nthoại hoặc điều được nói đến). \r\nMang, khiêng, vác, .(biểu thị những cách thức hành động khác nhau). \r\nVới loại 1 và loại 2 thì các từ đồng nghĩa có thể thay thế cho nhau. Còn loại 3 thì \r\nphải xét đến ngữ nghĩa của từ trong ngữ cảnh của văn bản, đây có thể coi là bài toán \r\nphức tạp nhất trong xử lý ngôn ngữ, hiện nay chưa có nhiều nghiên cứu. \r\nViệc xử lý từ đồng nghĩa là rất quan trọng, nhất là trong bài toán tóm tắt hướng \r\ntruy vấn. Trong mô hình lần này, do chỉ xử lý ở mức nông, nên không xét đến các \r\nvấn đề ở mức cú pháp và ngữ nghĩa, nhưng để tăng độ chính xác, bài toán sẽ sử dụng \r\nviệc đồng nhất các từ đồng nghĩa(xử lý chung cho cả 3 loại trên) dựa trên từ điển \r\nđồng nghĩa thô xây dựng sẵn, bộ từ điển này gồm gần 2800 mục, xây dựng bằng cách \r\ndùng công cụ tải các trang của từ điển Việt  Việt tại trang tratu.soha.vn, sau đó tách \r\nthẻ có chứa các từ đồng nghĩa rồi ghép lại. Mỗi mục gồm các từ gần nghĩa hoặc đồng \r\nnghĩa với nhau về mặt nào đó, và mỗi từ chỉ xuất hiện trong một mục, trên thực tế có \r\nnhững từ có thể ở nhiều mục, nhưng số lượng các từ đó không nhiều nên trong bộ từ \r\nđiển này sẽ sử dụng nghĩa phổ biến nhất của các từ đó. Tuy chưa được đầy đủ và xử \r\nlý đơn giản nhưng cũng góp phần tăng độ chính xác cho việc tóm tắt. Dưới đây là \r\nmột số mục từ trong bộ từ đồng nghĩa sẽ sử dụng. \r\n \r\nhttp://tratu.soha.vn/\r\n\r\n  \r\n\r\n   \r\nlãnh thổ, bờ cõi, biên thuỳ, biên giới,biên cương \r\nrỗi rãi, rỗi, rảnh rỗi, rảnh rang, rảnh \r\nthương nhân, nhà buôn, thương gia, doanh nhân, doanh gia \r\nquả cảm, gan góc, dũng cảm, gan dạ, dũng mãnh, can đảm, anh dũng \r\ntả, mô tả, miêu tả, diễn tả, diễn đạt, biểu đạt \r\nSau bước tách từ và loại bỏ từ dừng, các câu sẽ được xử lý theo theo cách duyệt \r\ntất cả các từ, với mỗi từ, tìm từ đó trong từ điển đồng nghĩa, nếu có thì thực hiện thay \r\nthế từ đó bằng từ đầu tiên trong mục từ chứa nó. \r\n1.1.5. Mô hình hóa văn bản \r\nViệc cuối cùng trong giai đoạn tiền xử lý là mô hình hóa văn bản, sử dụng mô \r\nhình không gian vector. Tương tự các công thức dùng để mô hình hóa văn bản ở trên, \r\nđể mô hình hóa câu, ta sử dụng công thức sau TF.ISF, công thức này tương tự như \r\nTF.IDF nhưng các thông số ở trong phạm vi câu và văn bản. Cụ thể mỗi từ tần số của \r\nmỗi từ wi trong câu sj  được tính như sau: \r\n \r\nTrong đó: \r\nfij là số lần xuất hiện của từ ti trong câu sj, \r\nm là tổng số câu trong văn bản \r\nhi là tổng số câu mà từ ti xuất hiện. \r\n là hệ số đánh giá độ quan trọng của từ, nếu từ xuất hiện trong truy \r\nvấn thì >1, còn lại thì =1 \r\nVới hệ số  cho từ xuất hiện trong truy vấn, trong quá trình kiểm thử trên tập mẫu \r\nthì =4  cho kết quả tốt nhất. \r\n1.1.6. Chọn câu phù hợp tạo tóm tắt \r\nBước này sẽ áp dụng các giải thuật đánh giá câu quan trọng để đưa vào kết quả \r\ntóm tắt. Để hạn chế hiện tượng trùng lặp thông tin trong kết quả tóm tắt, trước khi \r\nđưa vào lựa chọn, các câu sẽ được so sánh với nhau để tìm các câu gần tương tự nhau, \r\nvà loại bỏ câu có vị trí xa tiêu đề hơn. Độ đo sử dụng để loại bỏ câu trùng lặp và chọn \r\ncâu phù hợp tạo tóm tắt là độ đo cosin đã trình bày ở trên, nhưng hai vector được tính \r\ntoán bây giờ là biểu diễn cho hai câu. \r\n\r\n  \r\n\r\n   \r\nGiải thuật loại bỏ câu trùng lặp như sau: \r\nBước 1: xét câu si, tính độ tương đồng với các câu sau nó sj \r\nBước 2: với mỗi câu sj, nếu độ tương đồng ij> thì loại bỏ câu sj \r\nBước 3: nếu hết văn bản thì dừng lại, không thì tăng i lên 1 và quay lại bước 1 \r\nQua thực nghiệm trên một số văn bản, cho thấy ngưỡng =0.8 cho kết quả tương \r\nđối chính xác. Do đó trong bước này sẽ thực hiện loại bỏ một câu nếu có độ tương tự \r\nlớn hơn 0.8 với câu nào đó đứng trước nó, theo thứ tự vị trí trong văn bản. \r\nQuá trình chọn câu quan trọng sẽ thực hiện như hình dưới đây \r\n \r\nHinh 4: Minh họa quá trình chọn câu quan trọng \r\nSau khi chuyển biểu diễn các câu về mô hình không gian vector, mỗi câu sẽ là \r\nmột vector, văn bản là danh sách các vector, độ tương đồng giữa các câu sẽ được tính \r\ntoán sử dụng độ đo cosin.  \r\nGiải thuật chọn câu theo các bước sau: \r\nBước 1: khởi tạo tâm là truy vấn \r\nBước 2: tính độ tương đồng  của các câu trong văn bản với tâm \r\nBước 3: chọn câu có  lớn nhất, kết hợp vào tâm, xóa câu đó khỏi văn bản \r\nBước 4: kiểm tra độ dài, nếu chưa đủ, tính toán lại tâm và quay lại bước 2 \r\n\r\n  \r\n\r\n   \r\nTâm của tóm tắt sẽ được tính toán lại dựa trên công thức tính vector trọng tâm \r\ncủa nhóm, và độ tương tự của 1 câu với tâm sẽ là độ tương tự với vector đó. \r\n*) Véc tơ trọng tâm của nhóm \r\nGiả sử có một tập câu = {s1, s2, ., sm} có lần lượt các véc tơ biểu diễn là v1, v2, \r\n., vm. Khi đó, véc tơ trọng tâm của tập câu được tính theo công thức: \r\n1\r\nm\r\ni\r\ni\r\ncen\r\nv\r\nV\r\nm\r\n\r\n\r\n \r\n \r\n1.2. Giai đoạn hiển thị \r\nỞ bước này, văn bản tóm tắt sẽ được tạo ra bằng cách ghép các câu được chọn \r\ntheo thứ tự trong văn bản, đó chính là phương pháp hiển thị phân đoạn. \r\n  \r\n\r\n  \r\n\r\n   \r\nII. CÀI ĐẶT THỬ NGHIỆM \r\n2.1. Chương trình thử nghiệm \r\nĐể thực hiện thử nghiệm em đã xây dựng một số công cụ phục vụ tóm tắt 1 văn \r\nbản, công cụ tạo mẫu và công cụ kiểm thử trên mẫu: \r\n- Môi trường cài đặt: Java JDK 7u17, Windows 7 32bit. \r\n- Công cụ lập trình Netbeans 7.3. \r\n2.1.1. Các công cụ đã xây dựng \r\n2.1.1.1. Chương trình tóm tắt \r\nĐây là chương trình thực hiện tóm tắt một văn bản dựa trên giải thuật đã phân \r\ntích ở trên. Chi tiết các chức năng đã ghi chú đầy đủ trên ảnh giao diện chương trình. \r\nĐầu vào của chương trình là văn bản gốc, truy vấn, và độ rút gọn, đầu ra sẽ là văn \r\nbản tóm tắt, có thể xem chi tiết một số bước xử lý ở chức năng Note góc dưới trái \r\ngiao diện. \r\n \r\nHinh 5: Giao diện chương trinh demo \r\n2.1.1.2. Công cụ tạo tập mẫu \r\nCông cụ này hỗ trợ, tạo, chỉnh sửa các bản tóm tắt thủ công. Chức năng chính là \r\nquản lý các văn bản mẫu bao gồm văn bản gốc và bản tóm tắt thủ công, được tích \r\nhợp chức năng tách từ, tách câu của VNTokenizer nên việc tạo văn bản mẫu sẽ chính \r\nxác và hiệu quả hơn. Ngoài ra còn có chức năng phát hiện ra các văn bản lỗi font, các \r\nvăn bản này không thể sử dụng trong các công cụ đi kèm nên cần loại bỏ. \r\n \r\n\r\n  \r\n\r\n   \r\n \r\nHinh 6: Chương trinh quản lý tập mẫu \r\n2.1.1.3. Công cụ kiểm thử \r\nCông cụ này được xây dựng dựa trên việc tích hợp giải thuật đã đề xuất ở trên và \r\ntích hợp thêm hai giải thuật để so sánh, việc so sánh dựa trên độ đo BLEUS, chi tiết \r\nvề cách thực hiện sẽ trình bày ở phần sau. \r\n \r\nHinh 7: Giao diện chương trinh kiểm thử \r\n\r\n  \r\n\r\n   \r\n2.2. Thử nghiệm một văn bản \r\nPhần này em sử dụng công cụ tóm tắt đã xây dựng để thử nghiệm một văn bản. \r\nKết quả thực hiện thu được như sau: \r\n2.2.1. Đầu vào \r\n Văn bản: \r\nBảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình{1} \r\nChiều ngày 26-4, Chủ tịch nước Trương Tấn Sang và Tổ Đại biểu Quốc hội \r\n(ĐBQH) số 1, Đoàn ĐBQH TP Hồ Chí Minh tiếp tục có buổi tiếp xúc với gần 400 cử \r\ntri của quận 1{2}. Ghi nhận các ý kiến của cử tri, Chủ tịch nước đánh giá cao tinh \r\nthần đóng góp ý kiến của mọi người, nhất là vấn đề sửa đổi Hiến Pháp và các đạo \r\nluật{3}. Trả lời câu hỏi được đông đảo cử tri quan tâm về chủ trương bảo vệ chủ \r\nquyền lãnh thổ, củng cố quốc phòng - an ninh, Chủ tịch nước Trương Tấn Sang khẳng \r\nđịnh chủ trương của Đảng, Nhà nước trước sau như một là kiên quyết bảo vệ vững \r\nchắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình, theo hệ thống luật pháp \r\nquốc tế{4}. Tuy nhiên, Chủ tịch nước cũng khẳng định không bao giờ bảo vệ chủ \r\nquyền bằng nói miệng; chủ trương hòa hiếu không có nghĩa là không làm gi{5}. \r\nNước ta cũng mua sắm trang bị vũ khí, nhưng không phải để gây chiến tranh, chạy \r\nđua vũ trang mà là tăng cường phòng thủ, bảo vệ chủ quyền lãnh thổ{6}. Chủ tịch \r\nnước cho biết, chủ trương hòa hiếu luôn được các nước bạn bè trên thế giới ủng \r\nhộ{7}. \r\nĐề cập đến tình hình biển, đảo, Chủ tịch nước bày tỏ thông cảm với những lo \r\nlắng, bức xúc của cử tri, mong cử tri phải binh tĩnh, không nghe những lời kích động \r\ncủa kẻ xấu{8}. Những mâu thuẫn trên Biển Đông là có, nhưng biện pháp hòa hiếu \r\ncủa nước ta đã có kết quả tốt, Nhà nước luôn hỗ trợ ngư dân ra khơi, số lượng tàu \r\ncá đánh bắt xa bờ ngày càng tăng{9}. Nước ta phấn đấu đến năm 2020 sẽ phát triển \r\nkinh tế biển đạt 52%-53% GDP, trong đó, dầu khí, vận tải biển, đánh bắt hải sản là \r\nthế mạnh lớn{10}. Mục tiêu cuối cùng của nước ta là chủ quyền lãnh thổ vững chắc, \r\nquốc phòng - an ninh ổn định, kinh tế phát triển{11}. \r\nLiên quan đến các vấn đề kinh tế - xã hội, Chủ tịch nước Trương Tấn Sang cho \r\nbiết kinh tế nước nhà có những phát triển đáng kể, nông nghiệp đạt nhiều thắng lợi, \r\ncác ngành thuộc về dầu khí tăng trưởng khá{12}. Tuy nhiên, Chủ tịch nước mong cử \r\ntri hiểu kinh tế Việt Nam dùng chủ yếu là tiền","u":"http://202.191.57.85:8000/InternetData/Data/LVTN/9.txt","sentences":[[1,"Cụ thể bài toán cần giải quyết được phát biểu như sau: Đầu vào: Văn bản, truy vấn, độ rút gọn Đầu ra: Bản tóm tắt của văn bản đầu vào xoay quanh vấn đề nêu trong truy vấn Để giải quyết được bài toán này, việc trước hết là tìm hiểu cơ sở lý thuyết về tóm tắt văn bản, tóm tắt hướng truy vấn, từ đó xác định hướng giải quyết và thực hiện cài đặt thử nghiệm"],[2,"II"],[3,"TỔNG QUAN VỀ TÓM TẮT VĂN BẢN TỰ ĐỘNG 2.1"],[4,"Định nghĩa Tóm tắt văn bản là quá trình làm giảm độ dài, độ phức tạp của văn bản mà vẫn giữ lại được nội dung quan trọng của văn bản đó"],[5,"Công việc tóm tắt văn bản đã xuất hiện từ rất lâu đời, và nó được làm thủ công, do con người đọc, rút ra các ý chính rồi trình bày lại một cách ngắn gọn, dễ hiểu"],[6,"Mục đích là giúp người sử dụng có cái nhìn tổng quan về nội dung trình bày trong văn bản, để quyết định sử dụng văn bản đó hợp lý"],[7,"Tuy nhiên với lượng văn bản nhiều và dài thì việc làm thủ công vô cùng tốn thời gian, công sức"],[8,"Ngày nay, thời đại công nghệ thông tin phát triển mạnh, tóm tắt văn bản tự động (gọi tắt là tóm tắt văn bản) được nghiên cứu phát triển nhằm mục đích làm thay con người công việc nặng nhọc đó"],[9,"Đã có rất nhiều định nghĩa được đưa ra, tuy nhiên có thể sử dụng định nghĩa ngắn gọn sau: Tóm tắt văn bản là quá trình rút ra những thông tin quan trọng nhất từ một hay nhiều nguồn văn bản để tạo ra một văn bản gọn hơn phục vụ cho một số nhiệm vụ hay người dùng cụ thể 2.2"],[10,"Các tiêu chí đánh giá Độ mạch lạc (Coherence): đánh giá mức độ rõ ràng của văn bản tóm tắt, tính súc tích, khả năng có thể đọc và hiểu được của bài viết"],[11,"Độ hàm chứa thông tin (Informationess): tỉ lệ thông tin của văn bản gốc trong văn bản tóm tắt"],[12,"Độ liên quan (Relevance): xác định mức độ phù hợp của văn bản tóm tắt với chủ đề cho trước (chủ đề có thể là một câu truy vấn)"],[13,"Độ dễ đọc hiểu (Reading Comprehence): một người được giao việc đọc văn bản kết quả, sau đó trả lời các câu hỏi, hệ thống sẽ phải cho điểm và từ đó đưa ra phần trăm những câu trả lời đúng"],[14,"2.3"],[15,"Ứng dụng của tóm tắt văn bản Tóm tắt văn bản có nhiều ứng dụng trong thực tế, một số ứng dụng nổi bật như: Tóm tắt tự động các tin tức trên báo điện tử"],[16,"Trợ giúp thông minh việc đọc và khai thác thông tin"],[17,"Tóm lược danh sách tìm kiếm từ các Search Engine"],[18,"Giản lược nội dung trình bày cho các thiết bị cầm tay"],[19,"Sinh tự động chủ đề, tiêu đề, dẫn đường văn bản"],[20,"Hỗ trợ tóm lược nội dung cuộc họp, website, chương trình phát thanh và truyền hình, sổ tay công việc"],[21,"2.4"],[22,"Phân loại tóm tắt văn bản Có nhiều cách phân loại tóm tắt, phụ thuộc vào tiêu chí sử dụng để phân loại, sau đây là một số cách phân loại cần quan tâm: 2.4.1"],[23,"Theo đầu vào hệ thống Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn gọn của văn bản đó"],[24,"Ngược lại, tóm tắt đa văn bản là từ nhiều văn bản nguồn cũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng thời cho nhiều văn bản khác nhau"],[25,"Rõ ràng, tóm tắt đa văn bản thì khó hơn, vì ngoài những công việc của tóm tắt đơn văn bản, tóm tắt đa văn bản còn phải thực hiện các công việc như tiền xử lý trích rút, tích hợp thống nhất khuôn dạng và hiển thị kết quả theo cách riêng"],[26,"Ngoài ra, tóm tắt đa văn bản còn phải đối mặt với các vấn đề như dư thừa trùng lặp dữ liệu giữa các văn bản nguồn, nội dung các văn bản nguồn phân tán, độ rút gọn yêu cầu cao, thời gian xử lý cần phải nhanh trong khi sự phức tạp trong xử lý lớn"],[27,"2.4.2"],[28,"Theo đầu ra hệ thống Tóm tắt trích rút là quá trình thu gọn văn bản mà trong kết quả ra chứa các đơn vị ngữ liệu văn bản nguồn"],[29,"Tóm tắt tóm lược là quá trình thu gọn văn bản mà trong kết quả ra có một số các đơn vị ngữ liệu mới được sinh ra từ các đơn vị ngữ liệu văn bản nguồn"],[30,"2.4.3"],[31,"Theo mục đích tóm tắt Tóm tắt chung là tóm tắt theo quan điểm ban đầu của tác giả văn bản gốc"],[32,"Tóm tắt hướng truy vấn là tóm tắt theo quan điểm mong muốn của người dùng ứng dụng thông qua các tham số truyền vào câu truy vấn"],[33,"Tóm tắt hướng truy vấn được cài đặt và áp dụng nhiều hơn nhưng trong lĩnh vực hẹp hơn, đi sâu vào các chuyên ngành cụ thể"],[34,"2.5"],[35,"Mô hình biểu diễn văn bản Văn bản thông thường là dạng dữ liệu phi cấu trúc, do vậy muốn xử lý chúng trước hết phải biểu diễn thành dạng có cấu trúc"],[36,"Các cấu trúc này phải có khả năng thao tác bằng các phép toán cơ bản như cộng, nhân, đại số quan hệ.."],[37,"Có ba mô hình thỏa mãn yêu cầu đó thường được sử dụng là: 2.5.1"],[38,"Mô hình boolean Trong mô hình boolean, văn bản, vốn là tập hợp của các term (thuật ngữ), được biểu diễn bởi chỉ số từng term và trọng số của chúng"],[39,"Trọng số của từng term - dùng để đánh giá độ quan trọng của chúng - trong mô hình này chỉ mang hai giá trị 0 và 1, tùy theo sự xuất hiện của term đó trong văn bản"],[40,"Trong đó wi là trọng số của term ti trong văn bản D"],[41,"Đối với vấn đề truy vấn, trong mô hình này câu truy vấn bao gồm các văn bản tìm kiếm liên hệ với nhau thông qua các phép đại số quan hệ cơ bản như NOT (phủ định), AND (và) hay OR (hoặc)"],[42,"Câu truy vấn có thể biểu diễn thành dạng vector với các thành phần liên kết và các phép toán quan hệ cơ bản"],[43,"Từ đây, độ liên quan giữa một văn bản và truy vấn được xác định thông qua các thành phần liên kết"],[44,"Độ liên quan này chỉ có thể mang hai giá trị : 0 văn bản không phù hợp với truy vấn và 1 văn bản phù hợp"],[45,"Do vậy có thể thấy rằng hạn chế lớn nhất của mô hình này đó là việc đánh giá độ liên quan chỉ trả về hai kết quả, hoặc phù hợp hoặc không, như vậy yêu cầu của hệ thống khi cần sắp xếp và chọn lựa các văn bản theo mức độ liên quan đến truy vấn sẽ không đạt"],[46,"Độ liên quan của mô hình này không thể phân chia thành các mức khác nhau, do vậy không phản ánh được thực tế là việc liên quan giữa văn bản và truy vấn có thể là mờ, không chắn chắn"],[47,"Hạn chế này được loại bỏ khi ta sử dụng một mô hình tổng quát hơn Mô hình không gian vector (VSM)"],[48,"2.5.2"],[49,"Mô hình không gian vector Như trên đã đề cập, mô hình không gian vector là mô hình tổng quát hơn mô hình Boolean"],[50,"Các văn bản được biểu diễn thành các vector nhiều chiều, với trọng số không chỉ mang hai giá trị là 0 hay 1 mà có thể mang các giá trị khác tùy theo cách đánh giá, tính toán"],[51,"Một khác biệt nữa so với mô hình boolean là các phép toán cơ bản của mô hình không gian vector"],[52,"Các phép toán đại số quan hệ dĩ nhiên không phù hợp nữa, thay vào đó là các phép toán vector như cộng hai vector, nhân hai vector, tích vô hướng"],[53,"Khi biểu diễn văn bản thành các vector, vấn đề về truy vấn và xác định độ liên quan hoàn toàn được giải quyết"],[54,"Truy vấn là kết quả của các phép toán vector giữa các vector biểu diễn cho những văn bản cấu thành nên truy vấn, như vậy, truy vấn trong trường hợp này cũng là một văn bản đặc biệt"],[55,"Việc xác định độ liên quan giữa truy vấn và văn bản được quy thành độ liên quan giữa văn bản và văn bản"],[56,"Hai văn bản là hai vector, vậy khoảng cách hay góc giữa chúng đều có thể đại diện cho sự liên quan giữa hai văn bản này"],[57,"Tất nhiên, để áp dụng được các phép toán vector cơ bản, hai vector cần chuẩn hóa về số chiều (độ dài)"],[58,"Các chỉ số sử dụng trong phương pháp này: Tần suất thuật ngữ của một từ w trong một văn bản d, ký hiệu TF(w,d), có thể sử dụng các công thức sau, với fij là số lần xuất hiện của từ wi trong văn bản dj: Tần suất văn bản của một từ w, ký hiệu DF(w) là số lượng văn bản mà từ w có xuất hiện"],[59,"Nghịch đảo của tần suất văn bản của một từ w, ký hiệu IDF(w) được cho bởi công thức: Trong đó: m là tổng số văn bản,, h là số văn bản chứa từ w Tần suất TF-IDF là kết hợp của hai loại tần suất nói trên: TF-IDF(w,d) = TF(w,d) * IDF(w) Theo mô hình này, mỗi văn bản sẽ được biểu diễn dưới dạng D(t1, t2,.,tn) với n là tổng số thuật ngữ xuất hiện, mỗi thuật ngữ sẽ được đánh index, ti là trọng số của thuật ngữ thứ i(trong danh sách thuật ngữ) trong văn bản D"],[60,"Khi đó độ liên quan giữa hai văn bản biểu diễn bởi 2 vector X(x1, x2, ., xn) và Y(y1, y2,.,yn) được tính bằng công thức Cosin: 2.5.3"],[61,"Mô hình tập thô dung sai Mô hình tập thô dung sai (Tolerance Rough Set Model) là một mô hình mới, tiên tiến dựa trên lý thuyết về logic mờ và tập mờ (Fuzzy Set)"],[62,"Điều cốt lõi của lý thuyết này là việc xác định chính xác một giả thiết nào đó (ví dụ như hai văn bản này có phù hợp, có giống nhau không...) là một điều rất khó"],[63,"Tuy nhiên chúng ta có thể chỉ ra một cặp xấp xỉ trên và xấp xỉ dưới để khẳng định được giả thiết đó là đúng"],[64,"Sử dụng các suy diễn hợp lý để xác định và làm đẹp các ngưỡng này"],[65,"Các phép toán cơ bản trong mô hình tập thô dựa trên các quan hệ tương đương các tính chất như đối xứng, phản xạ, bắc cầu.."],[66,"Lý thuyết logic mờ đã và đang được ứng dụng rất mạnh mẽ trong lĩnh vực Trí tuệ nhân tạo"],[67,"Mô hình tập thô gần đây được sử dụng nhiều cho các bài toán tìm kiếm cũng như phân nhóm văn bản"],[68,"Tuy nhiên khi áp dụng mô hình tập thô cho quá trình xử lý văn bản thì tính chất bắc cầu không còn phù hợp"],[69,"Nhóm tác giả Hồ Tú Bảo, Saori Kawasaki, Nguyễn Ngọc Bình đã đề xuất ra mô hình tập thô dung sai trong đó bỏ đi tính chất bắc cầu trong quá trình xử lý văn bản"],[70,"Lý thuyết tập thô được các nhà nghiên cứu Trí tuệ nhân tạo phát triển và ngày càng thể hiện được tính ưu việt không chỉ trong việc biểu diễn và thao tác văn bản mà còn trong các vấn đề khác của lĩnh vực này"],[71,"2.6"],[72,"Mô hình tóm tắt văn bản Hinh 1: Mô hình chung của tóm tắt văn bản Một mô hình tóm tắt văn bản tổng quát gồm các pha sau: Phân tích (Analysis): Phân tích văn bản đầu vào để đưa ra những mô tả bao gồm các thông tin dùng để tìm kiếm, đánh giá các đơn vị ngữ liệu quan trọng cũng như các tham số đầu vào cho việc tóm tắt"],[73,"Biến đổi (Transformation): Lựa chọn các thông tin trích chọn được, biến đổi để giản lược và thống nhất, kết quả là các đơn vị ngữ liệu đã được tóm tắt"],[74,"Hiển thị (Generation): Từ các đơn vị ngữ liệu đã tóm tắt, liên kết chúng lại thành đoạn theo một thứ tự nào đó hoặc theo cấu kết ngữ pháp rồi hiển thị phù hợp với yêu cầu người dùng"],[75,"Một hệ Tóm lược (Abstraction) bao gồm tất cả các pha trên, tuy nhiên một hệ Trích rút (Extraction) chỉ gồm pha Phân tích và Pha Hiển thị, không có pha biến đổi"],[76,"Thậm chí trong các pha phân tích và hiển thị, chỉ có một số công đoạn được sử dụng"],[77,"Phân tích (Analysis) Biến đổi (Transform) Hiển thị (Generation) Hinh 2: Mô hình tóm tắt văn bản trích rút Như vậy một hệ Trích rút tiến hành ít bước hơn, các phương pháp thường dùng là thống kê, học trên ngữ liệu"],[78,"Còn hệ Tóm lược thì phức tạp, do kết hợp các phương pháp của xử lý ngôn ngữ tự nhiên"],[79,"Vì vậy, kết quả của các hệ Tóm lược thường thuyết phục hơn (về mặt dễ đọc, dễ hiểu, liên kết ngôn ngữ tốt, gần gũi với con người)"],[80,"Trong mỗi pha có thể áp dụng nhiều kỹ thuật xử lý khác nhau, chi tiết sẽ được trình bày ở phần tiếp theo"],[81,"2.7"],[82,"Các phương pháp áp dụng trong các pha 2.7.1"],[83,"Pha Phân tích Ở pha này văn bản nguồn sẽ được tách thành các đoạn, câu, từ, kết hợp với các thông số đầu vào và áp dụng một số thuật toán cụ thể để chọn ra các đoạn hoặc câu phù hợp làm đầu vào cho pha tiếp theo"],[84,"Các phương pháp áp dụng trong pha Phân tích được chia thành hai loại: Phương pháp thống kê và Phương pháp cấu trúc"],[85,"2.7.1.1"],[86,"Phương pháp thống kê Phương pháp này sử dụng các số liệu thống kê về độ quan trọng của từ, câu hay đoạn, nhận được từ các nghiên cứu về ngôn ngữ học hay thông qua các phương pháp học máy dựa trên tập mẫu để trích rút ra các đơn vị ngữ liệu quan trọng Phương pháp vị trí Phương pháp vị trí bao gồm các phương pháp xác định độ quan trọng dựa trên thống kê về vị trí của từ, ngữ hay câu trong văn bản"],[87,"Các thống kê này tất nhiên phụ thuộc vào thể loại văn bản"],[88,"Chủ đề - Tiêu đề (Title-based): Chủ đề các đoạn văn bản hay tiêu đề các bảng thường chứa các từ và ngữ quan trọng, nên trích rút thông tin từ đây"],[89,"Đầu - cuối đoạn (First - Last Sentence): Xác suất câu đầu đoạn hay câu cuối đoạn chứa ý chính của cả đoạn là rất lớn, đặc biệt là câu đầu đoạn"],[90,"Ngoài ra, các đoạn đầu và cuối trong văn bản cũng quan trọng hơn các đoạn giữa"],[91,"Minh họa - Chú thích (Comments): Trong các câu chú thích, câu minh họa cho ảnh hay đồ thị thường chứa các thông tin quan trọng"],[92,"Tuy nhiên, các câu này thường chỉ được dùng để đánh giá độ quan trọng của các câu khác liên quan, chứ không được chọn làm đầu vào cho pha tiếp"],[93,"Phương pháp ngữ cố định Các ngữ cố định có đặc điểm thống kê rất tốt"],[94,"Sau các ngữ này thường là các câu hay từ có độ quan trọng là xác định"],[95,"Người ta chia thành hai loại ngữ cố định, một loại mang lại độ quan trọng cho thành phần đi sau, được gọi là ngữ nhấn mạnh, một loại giúp ta loại bỏ, không xét đến những thành phần đi sau vì nó không có nhiều giá trị trong việc trích rút, được gọi là ngữ dư thừa: Ngữ nhấn mạnh (Bonus phrase - Emphasizer): Ngữ nhấn mạnh gồm các ngữ như nói chung là., đặc biệt là., cuối cùng thì., trong bài viết này tôi muốn chỉ ra., bài viết nói về., nội dung gồm.,..v..v.."],[96,"Ngữ dư thừa (Stigma phrases): Một số ngữ dư thừa: hiếm khi mà., bài này không nói đến., Không thể nào., ..v..v.."],[97,"Phương pháp thống kê tần suất từ Độ quan trọng của từ phụ thuộc vào số lần xuất hiện của từ đó trong các văn bản liên quan"],[98,"Các kỹ thuật như TF.IPF hay Tập thuật ngữ thường xuyên (Frequent Item Set) dùng cho công việc xác định tần suất của từ"],[99,"2.7.1.2"],[100,"Phương pháp cấu trúc Là các phương pháp sử dụng các mối liên hệ cấu trúc - ngữ pháp - ngữ nghĩa để xác định các đơn vị ngữ liệu quan trọng"],[101,"Tư tưởng chính của các phương pháp này là những đơn vị ngữ liệu nào có chứa các thành phần liên kết nhiều với các thành phần khác sẽ có độ quan trọng lớn"],[102,"Việc đánh giá các mối quan hệ sẽ dựa trên các mạng ngữ nghĩa, các quan hệ cú pháp hoặc thông qua các phương pháp xác định độ liên quan truyền thống"],[103,"Phương pháp quan hệ lẫn nhau: Phương pháp này xác định mối quan hệ giữa các đoạn trong văn bản hay các câu trong đoạn với nhau thông qua các kỹ thuật thu thập thông tin ở mức văn bản"],[104,"Các đoạn (câu) trong văn bản nguồn được tính toán độ liên quan lẫn nhau sử dụng các kỹ thuật như Cosine, TF.IPF hay N-gram Overlap"],[105,"Sau đó chọn ra đoạn (câu) có độ liên quan lớn nhất"],[106,"Phương pháp liên kết từ vựng: Phương pháp liên kết từ vựng sử dụng các từ điển quan hệ từ vựng đế xây dựng các chuỗi từ liên kết với nhau vể mặt ngữ nghĩa"],[107,"Ví dụ cây là một loại thực vật, có bộ phận là lá, chất liệu là gỗ"],[108,"Các từ cây, thực vật, lá, gỗ có quan hệ ngữ nghĩa nào đó với nhau"],[109,"Sau khi xây dựng được các chuỗi từ này, đánh giá độ mạnh của chúng và có những trích chọn phù hợp"],[110,"Phương pháp Liên kết tham chiếu: Phương pháp liên kết tham chiếu còn được gọi là phương pháp trích chọn trùng lặp (Anaphora-based Method)"],[111,"Theo phương pháp này, các cụm trùng lặp được chọn ra, phân rã xem đâu là từ tham chiếu và từ được tham chiếu"],[112,"Sau khi phân tách các cụm trùng lặp, chúng ta tạo chuỗi các từ tham chiếu đến cùng một từ được tham chiếu"],[113,"Chuỗi dài nhất sẽ được coi là trọng tâm của đoạn, các câu chứa các từ trong chuỗi này có một độ ưu tiên nào đó khi xét trích chọn"],[114,"Phương pháp quan hệ câu: Dựa trên các từ thể hiện mối quan hệ giữa các câu chúng ta cấu trúc hóa đoạn văn bản từ các đơn vị thành phần như ngữ, mệnh đề, câu.."],[115,"Sau đó đơn vị được coi như trung tâm sẽ được trích chọn"],[116,"2.7.2"],[117,"Pha Biến đổi Ở pha này, các câu sẽ được biến đổi, làm gọn lại hoặc kết hợp nhiều câu tạo thành câu mới ngắn gọn hơn"],[118,"Các phương pháp trong pha này không làm tăng thêm độ chính xác mà chỉ giúp cho văn bản kết quả ngắn gọn hơn mà vẫn sát nghĩa và thuật toán thưởng rất phức tạp"],[119,"Có thể chia làm 2 loại: 2.7.2.1"],[120,"Giản lược về cấu trúc câu Giản lược về cấu trúc câu là việc lược bỏ trong câu các phần thừa, ít mang giá trị, làm cho cấu trúc câu thu gọn lại"],[121,"Công việc này thường dựa trên phân tích cú pháp các thành phần trong câu"],[122,"2.7.2.2"],[123,"Giản lược về mặt ngữ nghĩa Phương pháp trừu tượng hóa khái niệm Tư tưởng của phương pháp này là từ các khái niệm cụ thể thay thế bằng khái niệm chung"],[124,"Ví dụ: Tôi ăn dâu, táo và đào => Tôi ăn trái cây Phương pháp thay thế bộ phận Tư tưởng của phương pháp này là từ các khái niệm bộ phận thay thế bằng khái niệm toàn bộ"],[125,"Ví dụ: Xích, líp, ghi đông, bàn đạp"],[126,"=> Cái xe đạp."],[127,"Phương pháp thay thế ngữ tương đương Tư tưởng của phương pháp này là các ngữ đóng vai trò như nhau trong câu được thay bằng một ngữ chung"],[128,"Ví dụ: Anh ấy bước vào, ngồi xuống ghế, xem thực đơn, gọi món, ăn, trả tiền và ra về => Anh ấy đi ăn tiệm"],[129,"Phương pháp thay thế từ, ngữ đồng nghĩa ngắn hơn Một phương pháp khác khá dễ hiểu đấy là việc thay thế một từ, ngữ bằng một từ, ngữ khác đồng nghĩa hoặc gần nghĩa nhưng có độ dài ngắn hơn"],[130,"Điều này thường thông qua một từ điển các từ đồng nghĩa (Thesaurus)"],[131,"Phương pháp thay thế bởi đại diện Tư tưởng của phương pháp này là thay thế một ngữ bằng một ngữ khác có ý nghĩa đại diện cho ngữ ban đầu"],[132,"Ví dụ: Người phát ngôn viên của chính phủ Hoa Kỳ thông báo"],[133,"=> Washington thông báo."],[134,"2.7.3"],[135,"Pha Hiển thị 2.7.3.1"],[136,"Phương pháp hiển thị phân đoạn Đây là phương pháp đơn giản nhất"],[137,"Các đơn vị ngữ liệu được trích rút hay giản lược từ các pha trước được liên kết lại thành đoạn theo thứ tự tiền định của chúng, không thêm bớt từ nối và cũng không sắp xếp lại các đơn vị ngữ liệu"],[138,"Văn bản kết quả của phương pháp này có độ dễ đọc dễ hiểu kém, thậm chí lủng củng về nghĩa vì các đơn vị ngữ liệu được trích rút mắc phải một số lỗi như mập mờ tham chiếu, không có từ nối hoặc là thừa từ và ngữ"],[139,"2.7.3.2"],[140,"Phương pháp hiển thị liên kết Việc hiển thị liên kết là tiếp nhận các đơn vị ngữ liệu đã được trích rút và giản lược từ các pha trước đó, phân tích mối quan hệ về nghĩa của các câu rồi thêm bớt các từ nối, từ dẫn và sắp xếp theo một thứ tự mới dựa vào những gì đã thu thập sao cho thỏa mãn yêu cầu về hiển thị và yêu cầu về độ dễ đọc, dễ hiểu của người dùng"],[141,"2.8"],[142,"Đánh giá kết quả tóm tắt Đánh giá một bản tóm tắt là một công việc khó bởi không tồn tại một bản tóm tắt lý tưởng cho một (hoặc một tập) văn bản đưa ra"],[143,"Hơn nữa, việc đánh giá nội dung tóm tắt cũng rất khó khăn"],[144,"Trường hợp kết quả là một câu trả lời cho một câu hỏi, ta có thể xác định được câu trả lời đó đúng hay sai, nhưng trong các trường hợp khác, thật khó trả lời liệu đầu ra là phải một kết quả đúng hay không"],[145,"Thực tế luôn có khả năng một hệ thống sinh ra một bản tóm tắt tốt nhưng lại sai khác với bản tóm tắt do người thực hiện"],[146,"Bên cạnh đó, khi việc đánh giá được thực hiện bởi con người thì chi phí đánh giá sẽ rất cao"],[147,"Mặt khác, tóm tắt văn bản còn liên quan đến tỉ lệ nén văn bản, do đó, việc đánh giá bản tóm tắt cần phải quan tâm đến vấn đề này, khi đó độ phức tạp và chi phí đánh giá sẽ tăng cao"],[148,"Dưới đây là hai phương pháp đánh giá tự động thường sử dụng: 2.8.1"],[149,"Sử dụng so khớp n-gram Phương pháp này được Lin và Hovy đưa ra năm 2002 dựa trên mô hình n-gram của độ đo BLEU (Bilingual Evaluation Understudy [1], độ đo đánh giá kết quả dịch máy)"],[150,"Ý tưởng của phương pháp này là so khớp n-gram liên tiếp của bản tóm tắt thủ công và tóm tắt tự động, theo công thức sau: Score=1*Score1+ 2*Score2+ 3*Score3+ 4*Score4 Trong đó: Scorei = Số i-gram trùng nhau/Tổng số i-gram của bản tóm tắt thủ công i là hệ số đánh giá độ quan trọng của các Scorei 2.8.2"],[151,"Sử dụng các độ đo ROUGE ROUGE(Recall-Oriented Understudy of Gisting Evaluation [2]) cũng được đưa ra bởi Lin, vào năm 2009, đây là tập hợp các độ đo dựa trên mô hình n-gram của BLEU với nhiều cách tính khác nhau"],[152,"Thường sử dụng nhất là độ đo ROUGE-N, với n là giá trị của mô hình n-gram, n={1,2,3,4}"],[153,"Công thức của độ đo ROUGE-N như sau: Cho R=(r1, r2, ., rn) là tập các tóm tắt mẫu, s là tóm tắt tự động, n(d) là vector biểu diễn mô hình n-gram của văn bản d"],[154,"Độ đo ROUGE được sử dụng làm độ đo chính thức của các hội nghị DUC 2004- 2007 và TAC 2008-2012"],[155,"2.9"],[156,"Một số hệ thống tóm tắt văn bản tiêu biểu Hiện tại, trên thế giới đã có rất nhiều nghiên cứu và dự án xây dựng các ứng dụng tóm tắt văn bản"],[157,"Các ứng dụng này có thể đáp ứng rất nhiều các mục đích khác nhau"],[158,"Có thể kể ra một số ứng dụng Tóm tắt văn bản tiêu biểu như sau: SUMMARIST: Một hệ thống Trích rút văn bản năm thứ tiếng (tiếng Anh, tiếng Nhật, tiếng Tây Ban Nha, tiếng Ả-rập và tiếng Hàn Quốc)"],[159,"Hiện tại SUMMARIST đang nghiên cứu để cải tiến trở thành một hệ thống Tóm lược văn bản và hỗ trợ nhiều ngôn ngữ hơn như tiếng Pháp và Indonesia"],[160,"SweSUM: Ứng dụng Tóm tắt văn bản đa ngôn ngữ của Học viện công nghệ hoàng gia Thụy Điển"],[161,"SweSUM có thể tóm tắt các văn bản có ngôn ngữ vùng Scandinavi như Thụy Điển, Đan Mạch, Na Uy và các ngôn ngữ khác như tiếng Anh, Pháp, Đức, Tây Ban Nha và cả tiếng Iran"],[162,"SumUM: Hệ thống Tóm lược văn bản kỹ thuật của nhóm nghiên cứu xử lý ngôn ngữ tự nhiên trường Đại học Montréal, Canada"],[163,"SumUM có thể thực hiện cả chức năng tóm tắt chỉ định và tóm tắt thông tin rất tốt."],[164,"FJCL: Hệ thống Rút trích văn bản tiếng Nhật được phát triển trong phòng nghiên cứu Ikeda của trường đại học Gifu"],[165,"Đây là một hệ thống sử dụng các phương pháp áp dụng cho hệ ngôn ngữ đơn âm tiết (monosyllabic language system) như tiếng Nhật, Hàn Quốc, Trung Quốc và Việt Nam"],[166,"Pertinence Summarizer: Hệ thống tóm tắt tin tức đa ngôn ngữ trực tuyến nổi tiếng"],[167,"Hiện tại để thử nghiệm khả năng của mình, Pertinence đã được tích hợp với Google và tóm tắt tự động danh sách tìm kiếm trả về từ Google thông qua câu truy vấn đưa vào"],[168,"Chúng ta có thể thử nghiệm hệ thống này trên trang web: www.pertinence.net"],[169,"MEAD: Nền tảng cho các hệ thống Tóm tắt nhiều văn bản và đa ngôn ngữ"],[170,"Đây là một bộ công cụ xây dựng trên nền Linux và Solaris, sử dụng ngôn ngữ Perl - Một ngôn ngữ có khả năng xử lý văn bản rất linh hoạt và mạnh mẽ"],[171,"MEAD biểu diễn, lưu trữ dữ liệu ở dạng XML, cung tấp cho chúng ta khung ứng dụng để cài đặt các ứng dụng Tóm tắt văn bản cho ngôn ngữ mà ta muốn"],[172,"Ngoài ra MEAD cũng cung cấp các công cụ để xây dựng các ứng dụng đánh giá hệ thống tóm tắt theo các tiêu chí và các tập mẫu nổi tiếng"],[173,"MEAD được xây dựng bởi các chuyên gia nổi tiếng về Xử lý ngôn ngữ ở khắp nơi trên thế giới dưới sự tài trợ của Chương trình Nghiên cứu Công nghệ thông tin của Tổ chức Khoa học quốc gia Mỹ"],[174,"MEAD được cung cấp ở dạng mã nguồn mở để nghiên cứu và kế thừa"],[175,"Hiện tại phiên bản mới nhất của MEAD là MEAD v3.07"],[176,"Microsoft Word AutoSummary: Microsoft cũng cài đặt chức năng Trích rút và sinh tiêu đề trong Microsoft Word từ phiên bản Word '97"],[177,"Chúng ta có thể thử bằng cách chọn Tools - AutoSummarize trên thanh công cụ (có thể khác tùy vào phiên bản)"],[178,"Công cụ này cho phép chúng ta chọn thông số về độ rút gọn, trích rút hay sinh tiêu đề.."],[179,"Ngoài ra còn các hệ thống Tóm tắt văn bản nổi tiếng khác như ANES hay SUMMONS"],[180,"Tuy nhiên tại Việt Nam hiện nay chưa có một nghiên cứu và ứng dụng Tóm tắt văn bản chính thức nào"],[181,"III"],[182,"BÀI TOÁN TÓM TẮT VĂN BẢN HƯỚNG TRUY VẤN 3.1"],[183,"Định nghĩa Theo định nghĩa ở trên, tóm tắt văn bản hướng truy vấn là một dạng tóm tắt văn bản (khi phân chia theo mục đích tóm tắt), điểm đặc trưng là ở giai đoạn tiền xử lý, việc tính toán sẽ phụ thuộc một phần vào truy vấn người dùng"],[184,"3.2"],[185,"Ứng dụng của bài toán Tóm tắt hướng truy vấn thường sử dụng trong việc tóm tắt kết quả trả về của máy tìm kiếm thông tin, hoặc trong các hệ thống hỏi đáp tự động"],[186,"Hiện nay, đối với máy tìm kiếm, hệ thống sẽ tóm tắt văn bản theo tóm tắt đơn văn bản thông thường, lưu vào cơ sở dữ liệu, và thực hiện tìm kiếm trên bản tóm tắt đó để giảm thời gian tìm kiếm"],[187,"Sau khi xác định được văn bản phù hợp, văn bản đó sẽ được tóm tắt lại theo truy vấn người dùng để đưa ra hiển thị kèm với kết quả"],[188,"Đối với hệ thống hỏi đáp tự động, hệ thống sẽ tiến hành phân loại câu hỏi và thực hiện so khớp hoặc tính tương đồng với câu hỏi trong cơ sở dữ liệu để xác định câu trả lời phù hợp nhất, sau đó tóm tắt văn bản chứa câu trả lời, sử dụng câu trả lời như truy vấn, và hiển thị kèm với câu trả lời, có đánh dấu câu trả lời"],[189,"Tóm lại, tóm tắt hướng truy vấn thường được tích hợp ở giai đoạn xử lý kết quả của hệ thống tìm kiếm thông tin và hỏi đáp tự động, mục đích là thêm thông tin để kết quả rõ ràng và dễ hiểu hơn với người dùng 3.3"],[190,"Một số hướng tiếp cận phổ biến 3.3.1"],[191,"Dựa trên đồ thị Phương pháp này được đưa ra bởi [3] Jagadeesh và đồng sự, áp dụng cho tóm tắt trích rút đa văn bản"],[192,"Đồ thị của văn bản sẽ được xây dựng dựa trên việc phân tích các câu trong đó để tìm ra các cụm danh từ(noun phrases), sau đó phân tích các cụm danh từ này để tìm ra mối quan hệ giữa các danh từ sử dụng các hàm heuristic"],[193,"Đồ thị thu được sẽ bao gồm 2 dạng nút, nút thành phần(là các danh từ trích rút từ văn bản) và nút liên kết, có 2 loại nút liên kết là isa(là một) và related_to(liên quan với)"],[194,"Sau khi xây dựng đồ thị cho mỗi câu, chúng sẽ được kết hợp để tạo đồ thị cho toàn văn bản"],[195,"Một thuật toán tìm kiếm sẽ được sử dụng để tìm các câu quan trọng đưa vào tóm tắt"],[196,"Có 3 giải thuật có thể áp dụng: - Dựa trên tâm các đồ thị: một đồ thị trung tâm cho tất cả văn bản được xây dựng, tích hợp thêm đồ thị của truy vấn"],[197,"Sau đó các câu có đồ thị tương đồng với tâm lớn nhất sẽ được chọn - Dựa trên đồ thị truy vấn: các câu có đồ thị tương đồng với đồ thị truy vấn lớn nhất sẽ được chọn - Dựa trên việc kết hợp câu đã chọn: giống bước trên nhưng sau khi chọn được mỗi câu thì kết hợp câu đó vào tâm tạo thành tâm mới Phương pháp này cho kết quả tương đối chính xác nhưng phụ thuộc chủ yếu vào giải đoạn phân tích cú pháp để tìm các cụm danh từ, do đó cần bộ phân tích cú pháp chính xác"],[198,"3.3.2"],[199,"Dựa trên cấu trúc diễn ngôn Phương pháp này được trình bày bởi W"],[200,"Bosma [4], mục đích là tạo ra bản tóm tắt ngắn gọn chứa câu trả lời để đưa ra kết quả trong hệ thống hỏi đáp tự động"],[201,"Trong đó mỗi văn bản được biểu diễn bởi đồ thị có trọng số dựa trên lý thuyết diễn ngôn, mỗi đỉnh đại diện cho một câu, trọng số trên mỗi cạnh là khoảng cách giữa hai câu"],[202,"Một thuật toán tìm kiếm đồ thị sẽ được sử dụng để chọn ra các câu có tổng trọng số trên đường đi tới câu trả lời(vai trò như truy vấn) nhỏ nhất"],[203,"3.3.3"],[204,"Dựa trên tần số từ và độ tương đồng câu Phương pháp này trình bày bởi Siva kumar và đồng sự [5] áp dụng cho tóm tắt trích rút đa văn bản"],[205,"Trước tiên các văn bản sẽ được biểu diễn trong mô hình không gian vector, mỗi câu được tính khoảng cách với câu truy vấn, sau đó sử dụng thuật toán phân cụm, chia các câu vào các cụm"],[206,"Mỗi câu được tính điểm số vị trí và điểm số độ quan trọng trong cụm, sau đó từ các cụm có điểm số cao nhất, trích rút ra các câu có điểm số cao nhất tạo thành tóm tắt"],[207,"3.4"],[208,"Đề xuất hướng giải quyết cho tiếng Việt Qua tìm hiểu về các vấn đề liên quan trong tóm tắt và đặc trưng của tiếng Việt, dễ nhận thấy rằng việc tiếp cận ở mức cú pháp và ngữ nghĩa là khá khó khăn, một phần là vì công cụ và dữ liệu hỗ trợ, tuy đã có một số công cụ gán nhãn từ vựng và phân tích cú pháp cho độ chính xác cao nhưng thường chỉ áp dụng cho lĩnh vực hẹp, và còn ở mức nghiên cứu, chưa được công bố chính thức"],[209,"Mặt khác, do đặc trưng về ngữ pháp nên các hướng tiếp cận đó thường không chính xác với tiếng Việt"],[210,"Do đó em xin đề xuất mô hình trích rút các câu quan trọng cho bài toán tóm tắt hướng truy vấn dựa trên tần số từ và độ tương đồng câu, áp dụng cho tóm tắt đơn văn bản"],[211,"Mô tả sơ lược như sau: Đầu tiên sử dụng câu truy vấn làm tâm tóm tắt, sau đó tìm câu có độ tương đồng với tâm lớn nhất, mỗi câu được chọn sẽ kết hợp với tâm tạo nên tâm mới"],[212,"Sau khi kết thúc sẽ loại bỏ câu truy vấn khỏi kết quả"],[213,"Phương pháp này dựa theo ý tưởng ở giải thuật thứ 2 trong hướng tiếp cận dựa trên đồ thị đã nêu ở trên, nhưng các câu ở đây biểu diễn theo mô hình không gian vector và độ tương đồng sử dụng độ đo cosin"],[214,"Phạm vi ứng dụng hướng tới của mô hình là tích hợp vào modul trả kết quả của bộ máy tìm kiếm văn bản(search engine), thực hiện tóm tắt văn bản kết quả theo tập từ khóa đã tìm kiếm(chính là truy vấn người dùng)"],[215,"Do đó có một số ràng buộc với dữ liệu đầu vào"],[216,"Vì văn bản đã được máy tìm kiếm lựa chọn nên nội dung của văn bản và truy vấn sẽ liên quan với nhau"],[217,"Do đó các câu chứa nhiều từ khóa trong truy vấn, hay trong trường hợp này là độ tương đồng lớn, sẽ mang các thông tin quan trọng liên quan đến truy vấn mà người dùng quan tâm"],[218,"Tuy nhiên trong vấn đề tìm kiếm, phần lớn người dùng thường không nắm rõ được nội dung mình muốn biết nên mới sử dụng tìm kiếm, mà chỉ biết các từ khóa liên quan tới vấn đề đó"],[219,"Ví dụ như tìm kiếm thông tin về giá vàng, người ta không biết giá vàng tăng hay giảm, có biến động gì gần đây"],[220,"Hoặc tìm cách sửa một lỗi máy tính thì người dùng sẽ đưa ra các thông tin về lỗi đó, sau khi xem bản tóm tắt của các kết quả từ máy tìm kiếm, sẽ biết được kết quả nào phù hợp để quyết định đọc hay không"],[221,"Trong giải thuật chọn câu, các câu được chọn sẽ được thêm vào truy vấn, với mục đích làm thêm từ khóa liên quan đến truy vấn"],[222,"Nhưng không phải từ nào trong các câu đó cũng đều quan trọng nên các từ xuất hiện trong truy vấn gốc được nhân lên một trọng số"],[223,"Do đó kết quả tóm tắt sẽ ưu tiên các từ khóa trong truy vấn, và các từ khóa xuất hiện nhiều trong các câu được chọn"],[224,"Theo đó thì bản tóm tắt sẽ dễ hiểu hơn vì bao gồm các thông tin liên quan tới truy vấn"],[225,"Tổng quan về modul đó như sau: Đầu vào - Văn bản: văn bản đầu vào sử dụng bộ mã Unicode utf-8, chỉ chứa text, chính xác về chính tả, dấu câu, không quá ngắn(5 câu trở lên), nội dung phải liên quan tới truy vấn"],[226,"- Truy vấn: sử dụng bộ mã như văn bản, là một đoạn văn bản chứa các từ khóa cần tìm kiếm, nếu cần chính xác thì dùng dấu phảy để ngăn cách các từ khóa - Độ rút gọn: có thể là số lượng từ (100-150 từ) hoặc phần trăm văn bản nguồn (10-20%)"],[227,"Thực hiện tóm tắt Bước này áp dụng mô hình tóm tắt đã đề xuất để tạo kết quả - Chuẩn hóa: bước này sẽ thực hiện xử lý tiêu đề, các đoạn văn trong ngoặc đơn - Tách câu, tách từ: thực hiện tách câu, tách từ sử dụng công cụ VNTokenizer - Loại bỏ từ dừng: tìm kiếm và loại bỏ các từ dừng dựa trên danh sách có sẵn - Xử lý từ đồng nghĩa: đồng bộ các từ đồng nghĩa về cùng 1 dạng - Mô hinh hóa văn bản: tính TF.IDF và chuyển các câu về dạng vector - Trích rút câu, tạo tóm tắt: đây là giải thuật đã đề xuất, thực hiện tính toán độ tương đồng sử dụng độ đo cosin và một số phép toán trên vector để tìm kiếm các câu phù hợp đưa vào kết quả tóm tắt, và được ghép lại theo phương pháp hiển thị phân đoạn"],[228,"Đầu ra: văn bản tóm tắt Chi tiết các kỹ thuật sử dụng trong các bước sẽ trình bày ở phần sau"],[229,"PHẦN 2"],[230,"GIẢI QUYẾT VẤN ĐỀ I"],[231,"PHÂN TÍCH MÔ HÌNH THỰC HIỆN BÀI TOÁN Dựa vào các kiến thức về tóm tắt văn bản đã trình bày ở trên, trong phần này em sẽ trình bày chi tiết các kỹ thuật áp dụng trong từng bước của mô hình xử lý đã đề xuất"],[232,"Hinh 3: Mô hình tóm tắt văn bản hướng truy vấn 1.1"],[233,"Giai đoạn phân tích 1.1.1"],[234,"Chuẩn hóa Xử lý câu tiêu đề Câu tiêu đề của một văn bản (nếu có) thường mang nội dung chính trình bày trong văn bản, do đó các từ khóa trong đó cũng được dùng để phát hiện tóm tắt (một số giải thuật còn tăng trọng số cho những từ xuất hiện trong tiêu đề), nhưng không đưa câu tiêu đề vào kết quả tóm tắt, nên cần phát hiện để loại bỏ khỏi kết quả"],[235,"Việc phát hiện câu tiêu đề có thể dựa vào dấu hiệu câu tiêu đề là câu duy nhất của đoạn đầu tiên"],[236,"Trong giải thuật này chỉ sử dụng câu tiêu đề như câu thông thường, sau đó loại khỏi kết quả (nếu nó được chọn vào kết quả)"],[237,"Xử lý các cụm từ trong ngoặc Các cụm từ trong ngoặc có thể là chú thích hoặc viết tắt của cụm từ nào đó, nếu là chú thích thì có thể bỏ qua còn từ viết tắt thì khá quan trọng, nhất là đối với tóm tắt hướng truy vấn"],[238,"Ví dụ: Sinh viên tình nguyện(SVTN) đi đến các vùng sâu để giúp đỡ đồng bào Các câu sau câu này sẽ sử dụng cụm từ SVTN, nếu truy vấn có từ khóa sinh viên tình nguyện thì các câu sử dụng từ viết tắt sẽ không được quan tâm"],[239,"Việc xử lý từ viết tắt không đơn giản là phát hiện các từ trong ngoặc, tùy từng loại văn bản của chuyên ngành nào đó, các từ viết tắt vẫn được sử dụng mà không gây hiểu lầm cho người đọc, vì trong các lĩnh vực ấy nó chỉ có thể thay thế cho cụm từ cố định nào đó, hoặc do thói quen, sử dụng nhiều thì mọi người đều biết"],[240,"Ví dụ: UBND thường được dùng thay thế cho Ủy ban nhân dân Trong giải thuật này chỉ xử lý các cụm từ viết tắt chữ đầu trong ngoặc đơn, còn các trường hợp khác do chưa xây dựng được bộ dữ liệu cụ thể nên không xét đến"],[241,"Các cụm từ trong ngoặc đơn khác sẽ bị xóa đi"],[242,"1.1.2"],[243,"Tách câu, tách từ Trong tiếng Việt, dấu cách (space) không được sử dụng như 1 kí hiệu phân tách từ, nó chỉ có ý nghĩa phân tách các âm tiết với nhau, có khoảng 70% các từ gồm 2 âm tiết, và 14% các từ gồm 3 âm tiết, còn lại là 1 âm tiết"],[244,"Hơn nữa, việc kết hợp các âm tiết có nhiều cách, mỗi cách cho một nghĩa khác nhau"],[245,"Vì thế, để xử lý tiếng Việt, bài toán tách từ (word segmentation) là 1 trong những bài toán cơ bản và quan trọng bậc nhất"],[246,"Ngoài tiếng Việt, có khá nhiều các ngôn ngữ châu Á khác cũng cần bước tách từ, ví dụ như: tiếng Nhật, tiếng Trung, tiếng Hàn,"],[247,"do đó vấn đề này nhận được sự quan tâm rộng rãi và có nhiều hướng tiếp cận khác nhau"],[248,"Một số phương pháp có thể áp dụng: o So khớp từ dài nhất (Longest Matching) o So khớp cực đại (Maximum Matching) o Mô hình Markov ẩn (Hidden Markov Models- HMM) o Học dựa trên sự cải biến (Transformation-based Learning TBL) o Chuyển đổi trạng thái trọng số hữu hạn(Weighted Finite State Transducer) o Độ hỗn loạn cực đại (Maximum Entropy ME) o Máy học sử dụng vectơ hỗ trợ (Support Vector Machines) o Trường xác xuất có điều kiện (CRFs) Bài toán tách từ khá phức tạp, do đó việc tách từ trong bước này sẽ sử dụng công cụ VNTokenizer, được phát triển bởi nhóm tác giả Lê Hồng Phương"],[249,"Đây là công cụ tách từ tự động cho tiếng Việt, mã nguồn mở, được viết bằng ngôn ngữ Java"],[250,"Phiên bản cũ nhất là phiên bản vnTokenizer 2.0 được xây dựng vào năm 2005 khi đó nó mới là một ứng dụng đơn với giao diện đơn giản"],[251,"Để sử dụng trong chương trình lần này, phiên bản mới nhất 4.1.1c, mã nguồn của công cụ được tải tại website của dự án VLSP [6]"],[252,"Công cụ này được xây dựng sử dụng kết hợp từ điển (từ điển tiếng Việt được lấy từ đề tài VLSP) và ngram, trong đó mô hình ngram được huấn luyện sử dụng treebank tiếng Việt (70,000 câu đã được tách từ), treebank là kho ngữ liệu câu được chú giải ngữ pháp"],[253,"Với độ chính xác xấp xỉ 97% (theo thống kê của tác giả trên website) là kết quả rất cao so với công cụ tách từ hiện nay"],[254,"Ngoài ra việc tách câu khá đơn giản nhưng cần xử lý các trường hợp nhập nhằng dấu chấm câu và dấu chấm trong từ(trong email, số thập phân, địa chỉ web)"],[255,"Do đó để tiết kiệm thời gian, việc tách câu trong phần này sử dụng luôn modul tách câu trong công cụ VNTokenizer"],[256,"1.1.3"],[257,"Loại bỏ từ dừng Từ dừng (StopWord) là những từ thường xuất hiện nhiều trong các tài liệu nhưng thường chỉ mang ý nhấn mạnh, bổ nghĩa"],[258,"nó có ý nghĩa lớn trong một số phương pháp dựa trên dấu hiệu đặc biệt, nhưng trong phương pháp dựa trên tần số từ đang xét thì các từ này làm giảm độ chính xác"],[259,"Trong giải thuật này chủ yếu dựa trên trọng số từ nên việc loại bỏ từ dừng là rất cần thiết"],[260,"Từ dừng sẽ được loại bỏ nhờ một danh sách từ dừng xây dựng sẵn, tham khảo tại [7], sau khi tách từ, các từ xuất hiện trong từ điển từ dừng sẽ bị xóa"],[261,"Dưới đây là một số từ dừng trích trong file sẽ sử dụng"],[262,"thậm chí vì vậy tuy nhiên thật ra với lại thế là trước kia đáng lẽ sau cùng tuy vậy ắt hẳn quả thật Ngoài ra ở bước này, các dấu câu, dấu phảy cũng bị xóa vì nó cũng giống từ dừng"],[263,"1.1.4"],[264,"Xử lý từ đồng nghĩa Có 3 loại từ đồng nghĩa cần xét đến: Từ có nghĩa giống nhau hoặc gần giống nhau"],[265,"Ví dụ: siêng năng, chăm chỉ, cần cù,"],[266,"Từ đồng nghĩa hoàn toàn Ví dụ: hổ, cọp, hùm,"],[267,"Từ đồng nghĩa không hoàn toàn Ví dụ: Ăn, xơi, chén, .(biểu thị thái độ, tình cảm khác nhau đối với người đối thoại hoặc điều được nói đến)"],[268,"Mang, khiêng, vác, .(biểu thị những cách thức hành động khác nhau)"],[269,"Với loại 1 và loại 2 thì các từ đồng nghĩa có thể thay thế cho nhau"],[270,"Còn loại 3 thì phải xét đến ngữ nghĩa của từ trong ngữ cảnh của văn bản, đây có thể coi là bài toán phức tạp nhất trong xử lý ngôn ngữ, hiện nay chưa có nhiều nghiên cứu"],[271,"Việc xử lý từ đồng nghĩa là rất quan trọng, nhất là trong bài toán tóm tắt hướng truy vấn"],[272,"Trong mô hình lần này, do chỉ xử lý ở mức nông, nên không xét đến các vấn đề ở mức cú pháp và ngữ nghĩa, nhưng để tăng độ chính xác, bài toán sẽ sử dụng việc đồng nhất các từ đồng nghĩa(xử lý chung cho cả 3 loại trên) dựa trên từ điển đồng nghĩa thô xây dựng sẵn, bộ từ điển này gồm gần 2800 mục, xây dựng bằng cách dùng công cụ tải các trang của từ điển Việt Việt tại trang tratu.soha.vn, sau đó tách thẻ có chứa các từ đồng nghĩa rồi ghép lại"],[273,"Mỗi mục gồm các từ gần nghĩa hoặc đồng nghĩa với nhau về mặt nào đó, và mỗi từ chỉ xuất hiện trong một mục, trên thực tế có những từ có thể ở nhiều mục, nhưng số lượng các từ đó không nhiều nên trong bộ từ điển này sẽ sử dụng nghĩa phổ biến nhất của các từ đó"],[274,"Tuy chưa được đầy đủ và xử lý đơn giản nhưng cũng góp phần tăng độ chính xác cho việc tóm tắt"],[275,"Dưới đây là một số mục từ trong bộ từ đồng nghĩa sẽ sử dụng"],[276,"http://tratu.soha.vn/ lãnh thổ, bờ cõi, biên thuỳ, biên giới,biên cương rỗi rãi, rỗi, rảnh rỗi, rảnh rang, rảnh thương nhân, nhà buôn, thương gia, doanh nhân, doanh gia quả cảm, gan góc, dũng cảm, gan dạ, dũng mãnh, can đảm, anh dũng tả, mô tả, miêu tả, diễn tả, diễn đạt, biểu đạt Sau bước tách từ và loại bỏ từ dừng, các câu sẽ được xử lý theo theo cách duyệt tất cả các từ, với mỗi từ, tìm từ đó trong từ điển đồng nghĩa, nếu có thì thực hiện thay thế từ đó bằng từ đầu tiên trong mục từ chứa nó"],[277,"1.1.5"],[278,"Mô hình hóa văn bản Việc cuối cùng trong giai đoạn tiền xử lý là mô hình hóa văn bản, sử dụng mô hình không gian vector"],[279,"Tương tự các công thức dùng để mô hình hóa văn bản ở trên, để mô hình hóa câu, ta sử dụng công thức sau TF.ISF, công thức này tương tự như TF.IDF nhưng các thông số ở trong phạm vi câu và văn bản"],[280,"Cụ thể mỗi từ tần số của mỗi từ wi trong câu sj được tính như sau: Trong đó: fij là số lần xuất hiện của từ ti trong câu sj, m là tổng số câu trong văn bản hi là tổng số câu mà từ ti xuất hiện"],[281,"là hệ số đánh giá độ quan trọng của từ, nếu từ xuất hiện trong truy vấn thì >1, còn lại thì =1 Với hệ số cho từ xuất hiện trong truy vấn, trong quá trình kiểm thử trên tập mẫu thì =4 cho kết quả tốt nhất"],[282,"1.1.6"],[283,"Chọn câu phù hợp tạo tóm tắt Bước này sẽ áp dụng các giải thuật đánh giá câu quan trọng để đưa vào kết quả tóm tắt"],[284,"Để hạn chế hiện tượng trùng lặp thông tin trong kết quả tóm tắt, trước khi đưa vào lựa chọn, các câu sẽ được so sánh với nhau để tìm các câu gần tương tự nhau, và loại bỏ câu có vị trí xa tiêu đề hơn"],[285,"Độ đo sử dụng để loại bỏ câu trùng lặp và chọn câu phù hợp tạo tóm tắt là độ đo cosin đã trình bày ở trên, nhưng hai vector được tính toán bây giờ là biểu diễn cho hai câu"],[286,"Giải thuật loại bỏ câu trùng lặp như sau: Bước 1: xét câu si, tính độ tương đồng với các câu sau nó sj Bước 2: với mỗi câu sj, nếu độ tương đồng ij> thì loại bỏ câu sj Bước 3: nếu hết văn bản thì dừng lại, không thì tăng i lên 1 và quay lại bước 1 Qua thực nghiệm trên một số văn bản, cho thấy ngưỡng =0.8 cho kết quả tương đối chính xác"],[287,"Do đó trong bước này sẽ thực hiện loại bỏ một câu nếu có độ tương tự lớn hơn 0.8 với câu nào đó đứng trước nó, theo thứ tự vị trí trong văn bản"],[288,"Quá trình chọn câu quan trọng sẽ thực hiện như hình dưới đây Hinh 4: Minh họa quá trình chọn câu quan trọng Sau khi chuyển biểu diễn các câu về mô hình không gian vector, mỗi câu sẽ là một vector, văn bản là danh sách các vector, độ tương đồng giữa các câu sẽ được tính toán sử dụng độ đo cosin"],[289,"Giải thuật chọn câu theo các bước sau: Bước 1: khởi tạo tâm là truy vấn Bước 2: tính độ tương đồng của các câu trong văn bản với tâm Bước 3: chọn câu có lớn nhất, kết hợp vào tâm, xóa câu đó khỏi văn bản Bước 4: kiểm tra độ dài, nếu chưa đủ, tính toán lại tâm và quay lại bước 2 Tâm của tóm tắt sẽ được tính toán lại dựa trên công thức tính vector trọng tâm của nhóm, và độ tương tự của 1 câu với tâm sẽ là độ tương tự với vector đó"],[290,"*) Véc tơ trọng tâm của nhóm Giả sử có một tập câu = {s1, s2, ., sm} có lần lượt các véc tơ biểu diễn là v1, v2, ., vm"],[291,"Khi đó, véc tơ trọng tâm của tập câu được tính theo công thức: 1 m i i cen v V m 1.2"],[292,"Giai đoạn hiển thị Ở bước này, văn bản tóm tắt sẽ được tạo ra bằng cách ghép các câu được chọn theo thứ tự trong văn bản, đó chính là phương pháp hiển thị phân đoạn"],[293,"II"],[294,"CÀI ĐẶT THỬ NGHIỆM 2.1"],[295,"Chương trình thử nghiệm Để thực hiện thử nghiệm em đã xây dựng một số công cụ phục vụ tóm tắt 1 văn bản, công cụ tạo mẫu và công cụ kiểm thử trên mẫu: - Môi trường cài đặt: Java JDK 7u17, Windows 7 32bit"],[296,"- Công cụ lập trình Netbeans 7.3"],[297,"2.1.1"],[298,"Các công cụ đã xây dựng 2.1.1.1"],[299,"Chương trình tóm tắt Đây là chương trình thực hiện tóm tắt một văn bản dựa trên giải thuật đã phân tích ở trên"],[300,"Chi tiết các chức năng đã ghi chú đầy đủ trên ảnh giao diện chương trình"],[301,"Đầu vào của chương trình là văn bản gốc, truy vấn, và độ rút gọn, đầu ra sẽ là văn bản tóm tắt, có thể xem chi tiết một số bước xử lý ở chức năng Note góc dưới trái giao diện"],[302,"Hinh 5: Giao diện chương trinh demo 2.1.1.2"],[303,"Công cụ tạo tập mẫu Công cụ này hỗ trợ, tạo, chỉnh sửa các bản tóm tắt thủ công"],[304,"Chức năng chính là quản lý các văn bản mẫu bao gồm văn bản gốc và bản tóm tắt thủ công, được tích hợp chức năng tách từ, tách câu của VNTokenizer nên việc tạo văn bản mẫu sẽ chính xác và hiệu quả hơn"],[305,"Ngoài ra còn có chức năng phát hiện ra các văn bản lỗi font, các văn bản này không thể sử dụng trong các công cụ đi kèm nên cần loại bỏ"],[306,"Hinh 6: Chương trinh quản lý tập mẫu 2.1.1.3"],[307,"Công cụ kiểm thử Công cụ này được xây dựng dựa trên việc tích hợp giải thuật đã đề xuất ở trên và tích hợp thêm hai giải thuật để so sánh, việc so sánh dựa trên độ đo BLEUS, chi tiết về cách thực hiện sẽ trình bày ở phần sau"],[308,"Hinh 7: Giao diện chương trinh kiểm thử 2.2"],[309,"Thử nghiệm một văn bản Phần này em sử dụng công cụ tóm tắt đã xây dựng để thử nghiệm một văn bản"],[310,"Kết quả thực hiện thu được như sau: 2.2.1"],[311,"Đầu vào Văn bản: Bảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình{1} Chiều ngày 26-4, Chủ tịch nước Trương Tấn Sang và Tổ Đại biểu Quốc hội (ĐBQH) số 1, Đoàn ĐBQH TP Hồ Chí Minh tiếp tục có buổi tiếp xúc với gần 400 cử tri của quận 1{2}"],[312,"Ghi nhận các ý kiến của cử tri, Chủ tịch nước đánh giá cao tinh thần đóng góp ý kiến của mọi người, nhất là vấn đề sửa đổi Hiến Pháp và các đạo luật{3}"],[313,"Trả lời câu hỏi được đông đảo cử tri quan tâm về chủ trương bảo vệ chủ quyền lãnh thổ, củng cố quốc phòng - an ninh, Chủ tịch nước Trương Tấn Sang khẳng định chủ trương của Đảng, Nhà nước trước sau như một là kiên quyết bảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình, theo hệ thống luật pháp quốc tế{4}"],[314,"Tuy nhiên, Chủ tịch nước cũng khẳng định không bao giờ bảo vệ chủ quyền bằng nói miệng; chủ trương hòa hiếu không có nghĩa là không làm gi{5}"],[315,"Nước ta cũng mua sắm trang bị vũ khí, nhưng không phải để gây chiến tranh, chạy đua vũ trang mà là tăng cường phòng thủ, bảo vệ chủ quyền lãnh thổ{6}"],[316,"Chủ tịch nước cho biết, chủ trương hòa hiếu luôn được các nước bạn bè trên thế giới ủng hộ{7}"],[317,"Đề cập đến tình hình biển, đảo, Chủ tịch nước bày tỏ thông cảm với những lo lắng, bức xúc của cử tri, mong cử tri phải binh tĩnh, không nghe những lời kích động của kẻ xấu{8}"],[318,"Những mâu thuẫn trên Biển Đông là có, nhưng biện pháp hòa hiếu của nước ta đã có kết quả tốt, Nhà nước luôn hỗ trợ ngư dân ra khơi, số lượng tàu cá đánh bắt xa bờ ngày càng tăng{9}"],[319,"Nước ta phấn đấu đến năm 2020 sẽ phát triển kinh tế biển đạt 52%-53% GDP, trong đó, dầu khí, vận tải biển, đánh bắt hải sản là thế mạnh lớn{10}"],[320,"Mục tiêu cuối cùng của nước ta là chủ quyền lãnh thổ vững chắc, quốc phòng - an ninh ổn định, kinh tế phát triển{11}"],[321,"Liên quan đến các vấn đề kinh tế - xã hội, Chủ tịch nước Trương Tấn Sang cho biết kinh tế nước nhà có những phát triển đáng kể, nông nghiệp đạt nhiều thắng lợi, các ngành thuộc về dầu khí tăng trưởng khá{12}"],[322,"Tuy nhiên, Chủ tịch nước mong cử tri hiểu kinh tế Việt Nam dùng chủ yếu là tiền"]],"downloaded":true,"m":[-1,-1],"n":"9.txt","o":"http://202.191.57.85:8000/InternetData/Data/LVTN/9.pdf\r"},{"saved_path":"temp/70.txt","r":0,"s":[],"t":"\n XÂY DỰNG HỆ THỐNG TÓM TẮT TRÍCH RÚT ĐƠN VĂN BẢN THEO  PHƯƠNG  PHÁP\r\nĐỒ THỊ\r\n\r\n\r\n      Phương pháp đồ thị là phương pháp mới vẫn chưa có nhiều nghiên cứu  áp\r\ndụng cho bài toán tóm tắt văn bản. Em thấy rằng việc mô  hình  hóa  một  văn\r\nbản thành một đồ thị là việc làm dễ dàng và trực quan và tạo thuận  lơi  cho\r\ncác bước xử lý. Trong đồ án này, mục đích của em là thực hiện việc  so  sánh\r\nhiệu quả của một phương pháp đồ thị với các phương pháp  đã  có.  Chính  bởi\r\nvậy, em chọn phương pháp đồ thị cho việc giải quyết bài  toán  tóm  tắt  đơn\r\nvăn bản trong phạm vi đồ án tốt nghiệp này. Cụ thể, phương pháp em lựa  chọn\r\nlà Tóm tắt trích rút đơn văn bản theo phương pháp đồ thị.\r\n       Sau đây em xin trình bày các phần cụ thể của hệ thống tóm  tắt  trích\r\nrút đơn văn bản theo phương pháp đồ thị mà em xây dựng:\r\n\r\n1.1.  Phương pháp đồ thị áp dụng trong bài toán tóm tắt\r\n\r\n\r\n      Phương pháp đồ thị là phương pháp sử dụng đồ thị làm mô hình  để  biểu\r\ndiễn dữ liệu đầu vào của hệ thống. Sử dụng đồ thị để biểu diễn một  văn  bản\r\nsẽ giúp chúng ta hiểu hơn về sự liên kết giữa các phần khác  nhau   của  văn\r\nbản. Giải thuật dựa trên đồ thị sử dụng một giải thuật xếp hạng để cho  điểm\r\ncác ngữ liệu khác nhau của một văn bản cụ thể là một câu trong văn  bản  hay\r\nmột node trong đồ thị. Giải thuật xếp hạng được sử dụng với các  tiêu  chuẩn\r\nkhác nhau trong việc sắp xếp các node theo mức độ quan trọng.\r\n      Cấu tạo của các node và các cạnh sẽ được xác định bởi  loại  văn  bản.\r\nVí dụ, một vài ngữ liệu của văn bản như: các từ hoặc các câu có thể được  mô\r\nhình hóa thành các node. Các cạnh là thể hiệncủa sự liên  kết  từ  ngữ  hoặc\r\nngữ nghĩa hoặc sự tương đồng giữa hai node.\r\n      Tùy vào các đặc tính của văn bản mà ta mô hình hóa cho nó  thành  dạng\r\nđồ thị phù hợp, một giải thuật xếp hạng dựa trên đồ thị gồm các bước cơ  bản\r\nsau:\r\n     Định nghĩa đơn vị của văn bản nó có thể là nhóm từ, từ  hoặc  các  đơn\r\n      vị khác và mô hình hóa chúng thành các đỉnh hay các node của đồ thị.\r\n     Xác định mối quan hệ giữa các đơn vị ngữ liệu để  có  thể  hình  thành\r\n      các cạnh cho các node của đồ thị. Các cạnh có thể là có hướng hoặc  vô\r\n      hướng và có trọng số hoặc không có trọng số.\r\n     Tiến hành thực hiện giải thuật xếp hạng lặp lại cho tới  khi  toàn  bộ\r\n      các node trong đồ thị được  sắp xếp theo mức độ quan trọng.\r\n     Sắp xếp các node theo số điểm của chúng.\r\n      Khi hệ thống thực hiện tới bước thứ 4 thì một số  điểm  cuối  cùng  đã\r\nđược gán cho mỗi node. Các node được xếp hạng dựa trên  số  điểm  cuối  cùng\r\ncủa chúng. Sau đó, tùy thuộc vào tỷ lệ rút gọn  Tỷ lệ rút  gọn  là  độ  dài\r\nmong muốn đối với văn bản tóm tắt, các câu có điểm số cao nhất sẽ  được  lựa\r\nchọn cho bản tóm tắt cuối cùng.\r\n      Sau đây là hai giải thuật tiêu biểu áp dụng việc  tính  toán  độ  quan\r\ntrọng dựa trên đồ thị:\r\n     LexRank:\r\n      Erkan và Radov đã thiết kế LexRank để sắp xếp văn bản tóm tắt trong hệ\r\nthống tóm tắt đa văn bản. Nó giải thuyết rằng một câu  tương  tự  với  nhiều\r\ncâu khác trong một nhóm thì càng quan trọng và càng gần với  chủ  đề.  Trong\r\ngiải thuật này, một đồ thị vô hướng và kết nối đầy đủ được xây dựng cho  các\r\ncâu trong mỗi nhóm. Nếu hai câu có sự tương đồng thì một cạnh sẽ  được  hình\r\nthành giữa chúng. Độ tương đồng cosine được sử dụng cho việc  tính  toán  độ\r\ntương đồng giữa hai câu. Sau khi tính toán độ tương đồng  giữa các  cặp  câu\r\nvà xây dựng đồ thị, chúng ta sẽ xác định được câu trung tâm của đồ  thị  xây\r\ndựng cho mỗi nhóm bằng cách sau. Ta sẽ xác định độ quan trọng  của  mỗi  câu\r\nnó chính là độ tương đồng với các câu. Câu có độ quan trọng cao nhất  sẽ  là\r\ncâu trung tâm.\r\n     TextRank:\r\n      TextRank là mô hình xếp hạng dựa trên đồ thị nó sử dụng cho tất cả các\r\nđồ thị được chuyển đổi từ các văn bản ngôn ngữ  tự  nhiên.  TextRank  chuyển\r\nhóa từ mô hình xếp hạng trang của Google và được thiết kế  để  sử  dụng  cho\r\ncác hệ thống tóm tắt đơn văn bản. TextRank được sử  dụng  để  trích  rút  từ\r\nkhóa hoặc câu. Một đồ thị vô hướng và đầy đủ được sử  dụng  cho  việc  trích\r\nrút câu. Mỗi câu được mô hình hóa thành một đỉnh hay một node trong đồ  thị.\r\nĐể tạo ra một cạnh giữa hai câu, một mối quan hệ tương đồng được  tính  toán\r\nnhư là một hàm của các khái niệm liên kết. Mỗi cạnh với một trọng số chỉ  ra\r\nđộ quan trọng của mối quan hệ giữa hai node trong đồ thị. Các câu  dựa  trên\r\nđiểm của chúng được xếp hạng và các câu có số điểm  cao  nhất  sẽ  được  lựa\r\nchọn cho văn bản tóm tắt đầu ra.\r\n\r\n      Từ những tìm hiểu trên về việc sử dụng đồ thị cho công việc TTVB,  nên\r\nem quyết định thực hiện xây dựng một hệ thống tóm tắt đơn văn bản trích  rút\r\ndựa trên đồ thị. Hệ thống có sự kế thừa phương pháp TextRank trong  việc  xử\r\nlý trên đồ thị đó là việc sử dụng giải thuật  PageRank  cho  công  việc  xếp\r\nhạng các node trên đồ thị mô hình hóa văn bản đầu vào.\r\n\r\n1.2.  Mô hình hệ thống\r\n\r\n\r\n\r\n      Dựa trên mô hình chung của bài toán TTVB, chúng tôi  đã  xây  dựng  mô\r\nhình ứng dụng tóm tắt trích rút tự động văn bản tiếng  Việt.  Ứng  dụng  gồm\r\ncác giai đoạn sau:\r\n       Tiền xử lý\r\n       Xử lý\r\n       Hiển thị\r\n[pic]\r\n\r\n\r\n           \r\n\r\n      Mỗi giai đoạn gồm các module chức năng thực hiện các công việc cụ thể:\r\n     Giai đoạn tiền xử lý: Chuẩn hóa đầu vào,  thực  hiện  các  giải  thuật\r\n      của quá trình tiền  xử lý và mô hình hóa văn bản đầu vào.\r\n     Giai đoạn xử lý: Xây dựng giải thuật cho việc TTVB.\r\n     Giai đoạn hiển thị: Đưa ra các câu đã được  chọn  trong  văn  bản  đầu\r\n      vào hiển thị lên màn hình.\r\n\r\n1.3.  Giai đoạn tiền xử lý\r\n\r\n\r\n      Trước khi bắt đầu quá trình  biểu diễn văn bản,  người  ta  tiến  hành\r\nbước tiền xử lý văn bản. Đây là bước hết sức quan trọng vì nó  có  nhiệm  vụ\r\nlàm giảm số từ không mang nhiều ý nghĩa có trong văn bản và qua đó làm  giảm\r\nkích thước dữ liệu trong quá trình biểu diễn mô hình hóa văn bản.\r\n\r\n1.3.1.      Mô hình từ điển\r\n\r\n      Từ điển được sử dụng trong hệ thống tóm tắt gồm có 3 loại:\r\n          Từ điển từ vựng\r\n          Từ điển từ dừng\r\n          Từ điển từ đồng nghĩa, trái nghĩa\r\n\r\n\r\nCách thức thu thập và xây dựng các từ điển đó được tiến hành như sau:\r\n\r\n|Từ điển từ vựng:                                                |\r\n|Cách thức thu thập:  Em sử dụng từ điển có sẵn được sử dụng     |\r\n|trong tool tách từ DongDu của hai tác giả: Lưu Tuấn Anh và      |\r\n|Yamamoto Kazuhide, nguồn từ trang: http://viet.jnlp.org/dongdu. |\r\n|Cách thức tổ chức: Từ điển được lưu dưới dạng file .txt, với mỗi|\r\n|dòng là một từ vựng, mỗi tiếng trong từ cách nhau bởi dấu khoảng|\r\n|trắng.                                                          |\r\n|Độ lớn:  31242 từ                                               |\r\n\r\n|Từ điển từ dừng:                                                |\r\n|Cách thức thu thâp: Chúng em sử dụng tool trích rút trên trang  |\r\n|web: http://tratu.soha.vn .                                     |\r\n|Cách thức tổ chức:  Từ điển được lưu dưới dạng file .txt, với   |\r\n|mỗi dòng là một từ dừng, mỗi tiếng trong từ cách nhau bởi dấu   |\r\n|gạch dưới.                                                      |\r\n|Độ lớn: 571 từ                                                  |\r\n\r\n|Từ điển từ đồng nghĩa, trái nghĩa:                              |\r\n|Cách thức thu thâp: Em sử dụng bộ từ điển có sẵn do một bạn     |\r\n|trong nhóm trích rút từ trang: http://tratu.soha.vn .           |\r\n|Cách thức tổ chức:  Từ điển được lưu dưới dạng file .txt, với   |\r\n|mỗi dòng là một tổ hợp được chia thành 3 phần cách nhau bởi đấu |\r\n|hai chấm gồm:  từ vựng: từ đồng nghĩa : từ trái nghĩa ; mỗi     |\r\n|tiếng trong từ cách nhau bởi dấu gạch dưới.                     |\r\n|Độ lớn: 7734 tổ hợp                                             |\r\n\r\n\r\n1.3.2.      Tách câu\r\n\r\n      Theo sách ngữ pháp tiếng Việt của Ủy ban Khoa học Xã hội (1980):  Câu\r\nlà đơn vị dùng từ hay đúng hơn dùng ngữ mà cấu tạo nên trong  quá  trình  tư\r\nduy, thông báo, nó có nghĩa hoàn chỉnh, có cấu tạo ngữ pháp và có tính  chất\r\nđộc lập. Dựa trên cơ sở này ta sẽ tiến hành xét một  đơn  vị  ngôn  ngữ  có\r\nphải là câu hay không để thực hiện tách câu.\r\n      Vấn đề tách câu thành các đơn vị câu độc lập dường  như  được  ít  các\r\nnhà nghiên cứu quan tâm nhất, mặc dù nó cũng là phần việc quan  trọng  trong\r\nphân tích văn bản. Để tách một văn bản ra thành các đơn vị câu độc  lập  đối\r\nvới tiếng Việt không đơn thuần là chỉ dựa vào các  dấu  hiệu  kết  thức  câu\r\nnhư: . , ?, !, .. Vẫn có những câu tiếng Việt mà các  dấu  hiệu  kết\r\ncâu chưa phải là kết câu. Ví dụ như: dấu . nằm trong số  tiền  (20.000.000\r\nvnđ) hoặc trong số điện thoại (0974.334.345)  hoặc trong  các  từ  viết  tắt\r\nPGS.TS.\r\n      Đối với vấn đề tách câu em đã xây dựng một module xử  lý  các  vấn  đề\r\nsau:\r\n     Tách các câu theo dấu hiệu nhận biết của các dấu kết thúc  câu  gồm  :\r\n      .,!, ?,,..\r\n     Sử dụng các biểu thức chính quy để tránh các trường hợp  các  dấu  báo\r\n      hiệu kết thúc câu nằm trong cụm thuộc các dạng đặc biệt gồm: Email, số\r\n      tiền, từ viết tắt.\r\n     Ngoài ra, trong module này em cũng loại  bỏ  bớt  các  dấu  không  cần\r\n      thiết cho việc mô hình hóa văn bản như các dấu: ,, /, ( ),.\r\n\r\n1.3.3.      Xử lý các từ đầu câu\r\n\r\n\r\n      Trước khi thực hiện việc tách từ, em có xây dựng một module  nhằm  đưa\r\ncác từ viết hoa ở đầu câu về dạng thường nếu không phải là  danh  từ  riêng.\r\nModel này giúp làm tăng tính chính xác cho việc so khớp  từ  điển  của  bước\r\ntách từ, từ đó cho ta được kết quả chính xác hơn sau khi tách từ.\r\n      Module này làm hai việc như sau:\r\n     Lấy các từ viết hoa trong văn bản (ngoại trừ các từ đầu câu).\r\n     Xét từ đầu tiên trong từng câu nếu từ đó có trong  danh  sách  các  từ\r\n      viết hoa thì giữ nguyên nếu không thì ta chuyển nó về thành  dạng  chữ\r\n      in thường.\r\n\r\n1.3.4.      Tách từ\r\n\r\n\r\n      Tách từ là việc phân tích dữ liệu đầu vào và tách nó thành các từ  tố.\r\nChẳng hạn, ta có chuỗi đầu vào là Công nghệ  thông  tin  và  ta  quy  định\r\nkhoảng trắng là dấu hiệu phân tách giữa các từ tố. Khi đó một  Tokenizer  sẽ\r\nđơn giản tách chuỗi đầu vào thành 4 từ tố  (Công,  nghệ,  thông,  tin).  Tuy\r\nnhiên, nếu ta quy định các từ tố được tách ra phải là các từ  có  nghĩa  thì\r\nvấn đề không còn đơn giản như vậy.\r\n      Nếu như với tiếng Anh thì ta có thể sử dụng khoảng trắng làm dấu  hiệu\r\nphân tách các từ tố có nghĩa, thì trong tiếng Việt điều đó hoàn  toàn  không\r\ncòn đúng và nó trở nên phức tạp hơn nhiều.\r\nVí dụ:\r\n|Đoạn văn bản đầu vào:                                            |\r\n|                                                                 |\r\n|Ta càng cố gắng thì càng bị đè nén. Bản than không thể tìm chốn |\r\n|dung thân.                                                      |\r\n|Sau khi thực hiện tách từ ta được kết quả như sau:               |\r\n|                                                                 |\r\n|ta càng cố_gắng thì càng bị đè_nén. bản_thân không thể tìm chốn |\r\n|dung_thân.                                                      |\r\n\r\n\r\n\r\n                      \r\n\r\n      Với những điều kiện tiên quyết của việc tách  từ  trong  văn  bản  nói\r\ntrên, em đã tìm hiểu qua một số phương pháp tách từ phổ biến cho  việc  tách\r\ntừ như:\r\n\r\n       o So khớp từ dài nhất (Longest Matching)\r\n\r\n       o So khớp cực đại (Maximum Matching)\r\n\r\n       o Mô hình Markov ẩn (Hidden Markov Models- HMM)\r\n\r\n       o Học dựa trên sự cải biến (Transformation-based Learning  TBL)\r\n\r\n       o Chuyển đổi trạng  thái  trọng  số  hữu  hạn(Weighted  Finite  State\r\n         Transducer)\r\n\r\n       o Độ hỗn loạn cực đại (Maximum Entropy  ME)\r\n\r\n       o Máy học sử dụng vectơ hỗ trợ (Support Vector Machines)\r\n\r\n       o Trường xác xuất có điều kiện (CRFs)\r\n\r\n\r\n\r\n      Cuối cùng, em lựa chọn phương pháp so khớp từ dài nhất dựa trên một từ\r\nđiển tiếng Việt có sẵn và cụ thể là phương pháp so khớp từ dài nhất từ  trái\r\nqua vì sự rõ ràng và dễ cài đặt của nó.\r\nSau đây là mô hình thuật toán xem sử dụng:\r\n\r\n                                    [pic]\r\n\r\n\r\n                      \r\n      Ví dụ minh họa cho thuật toán trên, ta xét câu sau:\r\n                 Cuộc đời là những thách thức.\r\n      Đầu tiên, ta lấy được độ dài lớn nhất của từ có trong từ  điển  để  có\r\nthể lấy được chuỗi xét hợp lý đối với từ điển. Để dễ dàng, em giả sử độ  dài\r\nlớn nhất của từ trong từ điển lớn hơn chuỗi ví dụ của ta. Khi đó,  đầu  tiên\r\nta kiểm tra xem cụm cuộc đời là những thách thức  có  trong  từ  điển  hay\r\nkhông?Nếu không có ta tách bớt âm tiết cuối ra lưu một chuỗi  khác  và  kiểm\r\ntra cụm từ cuộc đời là những thử  có trong từ điển không?Nếu không ta  lại\r\ntách tiếp từ cuối cùng của cụm đang xét nối vào chuỗi lưu các từ  chưa  được\r\nxét tới. Tiếp tục tới khi ta xét tới từ cuộc đời nó có trong  từ  điển  ta\r\nđã có một từ được tìm thấy. Ta lại lặp lại các bước như trên  với  phần  còn\r\nlại chưa xét của câu cho tới khi không còn chuỗi nào của câu đang xét.\r\n      Sau khi thực hiện thuật toán trên ta thu được kết quả là:\r\n                 cuộc_đời là những thách_thức\r\n\r\n1.3.5.      Loại bỏ từ dừng (stopword)\r\n\r\n      Từ dừng là các từ xuất hiện thường xuyên trong  văn  bản  nhưng  không\r\nmang nhiều ý nghĩa về nội dung văn bản. Đó có thể là các loại từ  mang  tính\r\nhỗ trợ cho từ khác hoặc mang ý nghĩa về mặt  cấu  trúc.  Do  đó,  trong  quá\r\ntrình xây dựng hệ thống tóm tắt, ta cần tìm ra các từ dừng và loại bỏ  chúng\r\nra khỏi văn bản giúp cho hệ thống bớt đi gánh nặng khi phải  xử  lý  các  từ\r\nkhông mang nhiều ý nghĩa của văn bản.\r\n      Loại bỏ từ dừng đơn giản là việc so sánh các từ tìm  được  với  bộ  từ\r\nđiển từ dừng và loại bỏ chúng khỏi văn bản đầu vào.Tuy nhiên, việc  loại  bỏ\r\ntừ dừng cũng đóng vai trò quan trọng trong hệ thống tóm tắt bởi các yếu tố:\r\n     Làm đơn giản hóa dữ liệu xử lý, làm giảm độ lớn của các node cũng  như\r\n      độ phức tạp tính toán của chúng.\r\n     Nó tránh được hiện tượng nhiễu dữ liệu (tránh cho các  hệ  thống  đánh\r\n      giá mức độ quan trọng dựa trên tần suất xuất hiện của từ).\r\nDưới đây là bảng ví dụ về các từ dừng thường thấy trong văn bản tiếng Việt\r\n\r\n|Có thể               |Nếu                  |Vì vậy             |\r\n|Sau khi              |Thì                  |Nếu không          |\r\n|Trước khi            |Vì thế               |Loại trừ           |\r\n|Tất cả               |Cho nên              |Một số             |\r\n|Những                |Nhưng                |Rõ ràng            |\r\n|Phần lớn             |Bởi                  |Với                |\r\n|Hầu như              |Là                   |Với lại            |\r\n|Bởi vì               |Thay vì              |Cho dù             |\r\n\r\n\r\n                     \r\n      Với việc loại bỏ từ dừng, em xây dựng một module so sánh  các  từ  thu\r\nđược ở bước tách từ với danh sách từ dừng trong từ điển từ dừng. Nếu từ  nào\r\nxuất hiện trong từ điển từ dừng thì ta loại nó ra khỏi văn bản đầu vào.\r\n      Sau đây là sơ đồ giải thuật của thuật toán loại bỏ từ dừng:\r\n\r\n\r\n      [pic]\r\n\r\n                  \r\n\r\n1.3.6.      Xử lý các từ đồng nghĩa\r\n\r\n      Theo Cơ sở ngữ học và tiếng Việt  Mai Ngọc Chừ (1997), từ đồng  nghĩa\r\nlà những từ tương đồng với nhau về nghĩa, khác nhau về âm thanh và  có  phân\r\nbiệt với nhau về một vài sắc thái phong cách. Những từ đồng nghĩa  với  nhau\r\ntập hợp thành một nhóm gọi là nhóm đồng nghĩa.\r\n      Ví dụ: cố, gắng, cố gắng được gọi là một nhóm từ đồng nghĩa.\r\n      Từ đồng nghĩa không phải là những từ trùng nhau hoàn  toàn  về  nghĩa,\r\nchúng nhất định có dị biệt nào đó bên cạnh sự tương đồng. Chính sự  dị  biệt\r\nđó lại là lý do tồn tại và làm nên những giá  trị  khác  nhau  giữa  các  từ\r\ntrong một nhóm từ đồng nghĩa.\r\n      Những từ đồng nghĩa với nhau không nhất thiết  phải  tương  đương  với\r\nnhau về mặt số lượng nghĩa, tức là các từ trong một nhóm có thể có một  hoặc\r\nhai nghĩa, có những từ có thể có tới năm bảy nghĩa.  Thông  thường,  các  từ\r\nđồng nghĩa chỉ ở một nghĩa nào đó. Chính vì thế, một  từ  đa  nghĩa  có  thể\r\ntham gia vào nhiều nhóm tương đồng khác nhau. Ở nhóm này  nó  tham  gia  với\r\nnghĩa này, ở nhóm khác nó tham gia với nghĩa khác.\r\n      Ví dụ: Từ coi trong tiếng Việt  là một từ đa nghĩa.  Tùy  theo  từng\r\nnghĩa được nêu lên để tập hợp các từ mà coi có thể tham gia vào  các  nhóm\r\nkhác nhau như:\r\n      Coi  Xem : coi phim  xem phim\r\n      Coi  Giữ : coi đồ - giữ đồ\r\n      Với bài toán TTVB thì từ đồng nghĩa có một  ý  nghĩa  quan  trọng  khi\r\ntrong các câu có chứa các từ đồng nghĩa với nhau. Việc xử lý từ  đồng  nghĩa\r\nsẽ giúp nâng cao hơn độ chính xác khi so sánh độ tương đồng ngữ  nghĩa  giữa\r\ncác câu trong văn bản.\r\n      Đối với việc xử lý từ đồng nghĩa, em sử dụng bộ  từ  điển  đồng  nghĩa\r\nđược trích rút từ trang: http://tratu.soha.vn.\r\n      Em tiến hành xây dựng Module thực hiện việc so sánh các  từ  thu  được\r\nsau bước loại bỏ từ dừng, ta tiến hành so sánh từng từ với các từ  trong  từ\r\nđiển. Nếu từ có trong từ điển đồng nghĩa thì ta sẽ tiếp tục so khớp  các  từ\r\ncòn lại với nhóm từ đông nghĩa đó nếu có thì chuyển hết các từ đó về một  từ\r\nchung duy nhất đại diện cho nhóm từ đồng nghĩa đó. Cụ thể, em chuyển các  từ\r\nthành từ đầu tiên tìm thấy có trong từ điển xuất hiện  trong  nhóm  từ  đồng\r\nnghĩa.\r\n      Ví dụ minh họa, ta có văn bản đầu vào:\r\n      Ta không cố gắng tìm kiếm lối thoát cho bản thân mình. Ta chỉ cố  tìm\r\ncách sống chung với nó.\r\n      Sau bước loại bỏ từ dừng ta đã thu được danh sách gồm các từ:\r\n      ta, không, cố_gắng, tìm_kiếm, lối_thoát,  cho,  bản_thân,  mình,  ta,\r\nchỉ, cố, tìm, cách, sống, chung, với, nó\r\n      Trong danh sách từ thu được dễ nhận thấy hai từ: cố_gắng, cố là hai từ\r\nđồng nghĩa với nhau. Khi thực hiện giải thuật thì từ  cố  sẽ  được  chuyển\r\nthành từ cố_gắng như vậy sau giải thuật xử lý từ đồng nghĩa  ta  thu  được\r\ndanh sách các từ:\r\n      ta, không, cố_gắng, tìm_kiếm, lối_thoát,  cho,  bản_thân,  mình,  ta,\r\nchỉ, cố_gắng, tìm, cách, sống, chung, với, nó\r\n      Giải thuật cụ thể cho module xử lý từ đồng nghĩa như sau:\r\n                                    [pic]\r\n\r\n\r\n\r\n              \r\n\r\n1.3.7.      Mô hình hóa văn bản\r\n\r\n      Sau khi quá trình xứ lý từ đồng nghĩa, ta tiến hành mô  hình  hóa  văn\r\nbản đầu vào thành một dạng cấu trúc phục vụ cho công việc xử lý. Mô hình  đồ\r\nthị chính là mô hình em sử dụng cho việc mô hình hóa văn  bản  đầu  vào.  Cụ\r\nthể, em sẽ tiến hành mô hình hóa văn bản  thành  một  đồ  thị  trọng  số  vô\r\nhướng.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n                 \r\n      Ta mô hình hóa văn bản đầu vào thành một đồ thị  trọng  số  vô  hướng,\r\ntrong đó mỗi node biểu diễn từng câu trong văn bản  đầu  vào,  mỗi  cạnh  là\r\nliên kết giữa các cặp node trong đồ thị tương ứng với các cặp câu trong  văn\r\nbản đầu vào.\r\n      Các bước tiến hành cụ thể gồm:\r\n         - Xây dựng đối tượng Graph đại diện cho văn bản đầu vào.\r\n         - Xây dựng đối tượng Node đại diện cho từng câu trong văn bản.\r\n         - Mỗi đối tượng Node khi khởi tạo gồm có các thuộc tính sau:\r\n               o Chỉ số tương ứng với chỉ số của câu trong văn bản  đầu  vào\r\n                 (phục vụ cho việc sắp xếp câu khi hiển thị).\r\n               o Nội dung trước tiền xử lý (Là nội dung của  câu  trước  khi\r\n                 tiền xử lý).\r\n               o Nội dung đã tiền xử lý ( Là nội dung của câu sau  khi  tiền\r\n                 xử lý).\r\n               o Trọng số.\r\n\r\n\r\n\r\n1.4.  Giai đoạn xử lý\r\n\r\n\r\n      Trong gia đoạn xử lý, chúng ta tiến hành áp dụng các giải  thuật  nhằm\r\ncho điểm các node trong đồ thị tương ứng với các câu trong văn bản đầu  vào.\r\nTừ đó chúng ta có được các câu  điểm cao đồng nghĩa với việc nó  quan  trọng\r\ncó thể đại diện cho văn bản đầu vào.\r\n      Sự chính xác của toàn bộ ứng dụng phần lớn phụ  thuộc  vào  giai  đoạn\r\nnày. Trong đồ án này, em tiến hành thực hiện tính  toán  trọng  số  cho  các\r\nnode trong đồ thị bằng cách  kết hợp giữa giải thuật PageRank của Google  và\r\ngiải thuật tính toán độ tương đồng giữa các câu.\r\n\r\n1.4.1.      Giải thuật tính độ tương đồng\r\n\r\n\r\n      Đây là giải thuật cho ta độ tương đồng giữa các cặp node trong đồ  thị\r\ndựa vào tấn số của một từ đối với một câu.\r\n      Các tham số chính của giải thuật gồm:\r\n          Tần số của từ Term Frequency(TF).\r\n          Tần số của câu nghịch đảo Inverse Sentence Frequency(ISF).\r\n      Để tính được độ tương đồng của cặp node bất kỳ trước tiên ta phải tính\r\nđược giá trị TF*ISF cho mỗi câu. Các đại lượng được tính bằng công thức  như\r\nsau:\r\n\r\n\r\n                     tfi, j  = 1 + log(m)               isfi = log[pic]\r\n\r\n\r\n     Trong đó,\r\n          m là số lần xuất hiện của từ thứ i trong câu j.\r\n          tfi,j  là term frequency của từ thứ i trong câu thứ j.\r\n          isfi  là inverse sentence frequency của từ thứ i.\r\n          N là tổng số các câu trong văn bản đầu vào.\r\n          ni  là số câu chứa từ thứ i.\r\n\r\n\r\n      Từ đó, ta tính trọng số tương ứng của một từ thứ i trong câu thứ j như\r\nsau:\r\n\r\n\r\n\r\n                                                         Wi,j   =  tfi,j  *\r\n        isfi\r\n\r\n      Trọng số cạnh giữa 2 đỉnh tương ứng độ tương đồng giữa 2 câu Sm và  Sn\r\nđược tính theo công thức cosine như sau:\r\n\r\n\r\n\r\n\r\n                         W(sm, sn)  = [pic]\r\n\r\n\r\n\r\n\r\n      Với t là số từ của văn bản đầu vào.\r\n\r\n\r\n      Các bước thực hiện của thuật toán cụ thể như sau:\r\n\r\n\r\n      |Đầu vào:Văn bản đã được mô hình hóa sau bước tiền xử lý         |\r\n|Đầu ra:    Độ tương đồng giữa các câu trong văn bản đầu vào     |\r\n|Bước 1: Trên mỗi câu ta tính số lượng của từng từ trong câu đó  |\r\n|và số lượng câu trong văn bản chứa từ đó.                       |\r\n|                                                                |\r\n|Bước 2: Tính các đại lượng Term Frequency (TF) và Inverse       |\r\n|Sentence Frequency (ISF) của mỗi từ trong mỗi câu theo công     |\r\n|thức:                                                           |\r\n|TFi,Sj = 1 + log(m)[pic]                                        |\r\n|ISFi= [pic]                                                     |\r\n|                                                                |\r\n|Bước 3: Tính toán trọng số của một từ đối với một câu theo công |\r\n|thức:                                                           |\r\n|Wi,Sj      =     TFi,Sj  *  ISFi                                |\r\n|Bước 4: Tính toán độ tương đồng giữa các cặp câu trong văn bản  |\r\n|theo công thức:                                                 |\r\n|Similarity(Sj, Sk) =  [pic]                                     |\r\n|                                                                |\r\n|Trong đó,                                                       |\r\n|getDotProduct: là tích vô hướng của các giá trị trọng số trong  |\r\n|câu thứ j và câu thứ k.                                         |\r\n|getRootSumSj: Là tổng bình phương của giá trị trọng số của câu  |\r\n|thứ j.                                                          |\r\n|getRootSumSk: Là tổng bình phương của giá trị trọng số của câu  |\r\n|thứ k.                                                          |\r\n|Chúng được tính theo công thức:                                 |\r\n|getDotProduct = [pic]                                           |\r\n|getRootSumSj = [pic]                                            |\r\n|getRootSumSk= [pic]                                             |\r\n|                                                                |\r\n\r\n\r\n                                    [pic]\r\n\r\n\r\n\r\n                \r\n\r\n1.4.2.      Giải thuật PageRank\r\n\r\n      PageRank là giải thuật nổi tiếng được sử dụng bởi  Google  trong  việc\r\nxếp hạng các trang web dựa vào link liên kết bao  gồm:  link  liên  kết  với\r\ntrang web (incoming link) và link trang web liên kết tới  (outcoming  link).\r\nTrang web nào càng có nhiều liên kết đồng thời liên kết  với  các  trang  có\r\nxếp hạng càng cao thì hạng của nó càng cao. Nhận thấy được sự tương đồng  về\r\nmặt cấu trúc giữa mô hình liên kết giữa các trang web với mô hình đồ thị  em\r\nsử dụng, các trang web tương ứng với các node trong đồ  thị,  các  liên  kết\r\ntương ứng với các cạnh liên kết giữa các node. Chính bởi  vậy,  em  sử  dụng\r\ngiải thuật PageRank cho bước tính điểm cho các node trong đồ thị  tương  ứng\r\nvới số điểm của các câu trong văn bản đầu vào. Sau đây, em xin trình bày  cụ\r\nthể cách thức áp dụng giải thuật PageRank cho hệ thống của em:\r\n\r\n1.4.2.1. Giới thiệu về giải thuật PageRank\r\n\r\n      PageRank là giải thuật gán trọng số cho các trang Web  được  đánh  chỉ\r\nsố bằng một kỹ thuật tìm kiếm. Hệ thống  PageRank  được  sử  dụng  trong  kỹ\r\nthuật tìm kiếm nổi tiếng Google giúp cho việc xác định sự liên quan hay  tầm\r\nquan trọng của một trang web. PageRank được phát triển bởi  người  sáng  lập\r\nGoogle Larry Page và Sergey Brin khi họ đang học tâp tại  đại  học  Stanford\r\nnăm 1998.\r\n      Giá trị PageRank hình thành từ thuật toán học dựa trên  Webgraph:  các\r\ntrang World Wide Web được coi như các đỉnh và các đường link  là  các  cạnh.\r\nGiá trị xếp hạng cho thấy tầm quan trọng của từng trang cụ  thể.  Mỗi  đường\r\nlink tới trang web sẽ được tính như một sự hỗ trợ  làm  tăng  thêm  giá  trị\r\nPageRank. Giá trị PageRank của trang được định nghĩa đệ  quy  và  phụ  thuộc\r\nvào số lượng và giá trị của các trang mà có  link  dẫn  đến  trang  đó.  Một\r\ntrang web có chứa nhiều link liên kết từ các trang web có giá  trị  PageRank\r\ncao thì giá trị PageRank của trang đó cũng sẽ cao.\r\n\r\n\r\n                                    [pic]\r\n\r\n\r\n\r\n\r\n      Chúng ta có thể thấy trang C có một PageRank cáo hơn so với  trang  E,\r\nmặc dù có ít link đến trang C, một link duy nhất dẫn  tới  trang  C  từ  một\r\ntrnag quan trọng và chính vì thế mà C có gí trị cao.\r\n      Thuật toán PageRank là phân bố xác suất được sử dụng để thể  hiện  khả\r\nnăng khi một người click chuột ngẫu nhiên và  đường  link  và  sẽ  tới  được\r\ntrang web cụ thể. PageRank có thể được tính toán cho các  tập  văn  bản  với\r\ntài liệu có độ dài bất kỳ. Khi bắt đầu tính toán thì  sự  phân  bố  đó  được\r\nchia đều cho tất cả những văn bản trong tập văn bản. Các tính toán  PageRank\r\ncần lặp đi lặp lại qua các văn bản trong tập văn bản để có thể đạt được  giá\r\ntrị thực tế một cách thiết thực hơn. Xác suất có giá trị từ  0  tới  1.  Với\r\ngiá trị 0.5, thường được hiểu là 50% cơ hội của một việc gì đó  có  thể  xảy\r\nra. Trong PageRank, 0.5 có nghĩa là 50% cơ hội một người nào  đó  click  vào\r\nmột link ngẫu nhiên để được chuyển đến văn bản đó (giá trị PageRank = 0.5).\r\n\r\n1.4.2.2. Áp dụng giải thuật PageRank cho bài toán TTVB\r\n\r\n      Giải thuật này, được thực hiện nhằm tính toán trọng số cho  từng  node\r\ntrong đồ thị để có thể chọn ra các câu có trọng số cao  là  những  câu  quan\r\ntrọng có thể đại diện cho văn bản để đưa vào giai đoạn hiển thị.\r\n      Công thức được sử dụng cho giải thuật này là :\r\n\r\n                       PRW(Vi)  = (1 - d) + d * [pic]\r\n\r\n\r\n     Trong đó,\r\n          PRW(Vi):  là xếp hạng của đỉnh Vi.\r\n          In(Vi):  là tất cả các đỉnh đi tới đỉnh Vi.\r\n          Out(Vi): là tập các đỉnh mà đỉnh Vi đi tới.\r\n          d(DAMPING_FACTOR: là một  hệ  số  được  tùy  chọn  trong  khoảng\r\n           (0,1) - Là một hệ số trong giải thuật  PageRank.  Chính  là  xác\r\n           suất một người truy cập vào một trang  web  và  tiếp  tục  click\r\n           trong bất cứ bước nào. Có nhiều nghiên cứu đã thử  các  giá  trị\r\n           yếu tố damping, giá trị ước lượng bằng 0.85  là  người  dùng  sẽ\r\n           tiếp tục lướt web.\r\n      Do ta tiến hành mô hình hóa đồ thị thành dạng đồ thị trọng số vô hướng\r\nnên ta có giả thuyết là tất cả các node trong đồ thị đều được  nối  với  các\r\nnode còn lại tương đương bán bậc ra của mỗi node  bằng bán bậc vào của  đỉnh\r\nđó và bằng số node  1. Như vậy, ta có thể thay thế  công  thức  trên  thành\r\nnhư sau:\r\n\r\n\r\n                       PRW(Vi)  = (1 - d) + d * [pic]\r\n\r\n\r\n      Ngoài ra, còn có một số nguyên tắc sau được áp dụng cho đồ  thị  chúng\r\nta xây dựng:\r\n          Không quan tâm tới thứ tự node mà chỉ quan tâm tới nội dung  của\r\n           node.\r\n          Độ tương đồng của một node trong đồ thị với chính nó là bằng 0.\r\n               o  i< N: Sim(Si,Si) = 0\r\n\r\n\r\n      Sau khi giải thuật PageRank được thực hiện xong,  mỗi  node  trong  đồ\r\nthị đã có một trọng số tỷ lệ thuận với độ quan trọng cuả nó  trong  văn  bản\r\nđầu vào.\r\n\r\nCác bước tiến hành của giải thuật cụ thể như sau:\r\n|Đầu vào:  Văn bản đã được mô hình hóa sau giai đoạn tiền xử lý     |\r\n|Đầu ra:  Các node với một trọng số được gán theo mức độ quan trọng.|\r\n|                                                                   |\r\n|Bước 1:  Khởi tạo đồ thị từ văn bản đầu vào. Khởi tạo trọng số cho |\r\n|tất cả các node bằng 1                                             |\r\n|Bước 2 : Thực hiện giải thuật PageRank để tính toán trọng số cho   |\r\n|các node theo công thức:                                           |\r\n|PRW(Vi)  = (1 - d) + d * [pic]                                     |\r\n|Giải thuật được  mô tả dưới dạng giả ngôn ngữ:                     |\r\n|While(!Vòng lặp hội tụ)                                            |\r\n|For i = [1,Số câu]                                                 |\r\n|Sum = 0.0 // Tổng toàn cục                                         |\r\n|For j = [1, Số câu]                                                |\r\n|If( i # j)                                                         |\r\n|Wij = getSimilarity(Si,Sj)                                         |\r\n|PRVj = getRank(j)                                                  |\r\n|denSum = 0.0 //Tổng cục bộ                                         |\r\n|for k =[1, Số câu]                                                 |\r\n|if(k # j)                                                          |\r\n|Wjk = getSimilarity(Sj,Sk)                                         |\r\n|demSum = demSum + Wjk                                              |\r\n|end for                                                            |\r\n|Sum = Sum +   [pic]                                                |\r\n|end for                                                            |\r\n|denSum = 0.0                                                       |\r\n|rank = (1  DAMPING_FACTOR)  +  DAMPING_FACTOR * Sum               |\r\n|tmpranks.save(i,rank) // Cập nhật giá trị trọng số cho node        |\r\n|Sum = 0.0                                                          |\r\n|end for                                                            |\r\n|end while                                                          |\r\n\r\n                                    [pic]\r\n\r\n                     \r\n\r\n1.4.3.      Phương pháp đồ thị cải tiến\r\n\r\n      Trong quá trình tìm hiểu, xây dựng hệ thống em thấy có  thể  thêm  một\r\nsố yếu tố so với hệ thống đang xây dựng để có thể làm tăng  tính  chính  xác\r\ncho văn bản tóm tắt. Nhằm mục đích so sánh với phương pháp đồ thị  xây  dựng\r\ntheo [6] để chứng thực hiệu quả của sự cải tiến đó như thế nào. Em  đã  tiến\r\nhành thực hiện cải tiến hệ thống ở bước tính toán độ tương  đồng  bằng  cách\r\nxét thêm vị trí của từ trong văn bản đầu vào. Từ đó, em có một  đầu  ra  mới\r\nđể so sánh với hệ thống đã xây dựng trước đó. Sau đây, em xin trình bày  chi\r\ntiết phần cải tiến hệ thống mà em đê xuất:\r\n\r\n1.4.3.1.Một số nhận định của bản thân\r\n\r\n      Bằng thực nghiệm thu thập các bài báo mạng để phục vụ  cho  việc  kiểm\r\nthử, đánh giá hệ thống của mình em rút ra một số nhận định sau. Nó là cơ  sở\r\ncho việc em đề xuất thêm cải tiến cho hệ thống sử dụng phương  pháp  đồ  thị\r\ntheo giải thuật PageRank. Cụ thể là:\r\n     Các bài báo mạng thường có cấu trúc trình bày gồm 2 phần:\r\n         o Tiêu đề\r\n         o Nội dung bài báo\r\n     Các từ xuất hiện trong tiêu đề thường là các từ quan trọng  trong  văn\r\n      bản bởi tiêu đề thường phản ánh nội dung của văn bản,  tuy  không  thể\r\n      chỉ dùng chúng để quyết định độ quan trọng của các câu trong văn  bản.\r\n      Nhưng ta có thể áp dụng cho giải thuật bằng cách tăng trọng số của các\r\n      từ đó theo một hệ số nào đó. Điều này, có nghĩa những câu gần với tiêu\r\n      đề sẽ có điểm số cao hơn đồng nghĩa với việc chúng có  khả  năng  được\r\n      chọn cho văn bản tóm tắt cao hơn.\r\n\r\n1.4.3.2. Đề xuất phương án cải tiến\r\n\r\n      Từ những nhận định trên, em đề xuất một cái tiến nhỏ trong  việc  tính\r\ntoán trọng  số  các  từ  trong  phương  pháp  đồ  thị  sử  dụng  giải  thuật\r\nPageRank.Cụ thể, em sẽ sử dụng thêm một hệ số cho bài toán TTVB theo  phương\r\npháp đồ thị đó là:\r\n          htd : Hệ số nhân cho các từ xuất hiện  trong  tiêu  đề  của  văn\r\n           bản.\r\n      Để đạt được hiệu quả cao khi sử dụng các hệ số này, đòi hỏi phải  trải\r\nqua quá trình thực nghiệm với các kết quả của giải thuật hoặc  áp  dụng  các\r\nthuật toán học máy để quyết định giá trị phù hợp cho  chúng.  Do  thời  gian\r\nthực nghiệm chưa được nhiều nên em tạm thời lấy giá trị cho  hệ  số  đưa  ra\r\nsau một số lần so sánh kết quả kiểm thử với các hệ số khác  nhau  được  tiến\r\nhành kiểm thử trên 55 văn bản mẫu. Cụ thể , giá trị em chọn cho hệ  số  nhân\r\ncho các từ xuất hiện trong tiêu đề văn bản là 4: htd = 4.\r\n      Khi thực hiện tính toán tần số của từ đối với mỗi câu ta sẽ  xét  thêm\r\nvị trí của từ nếu chúng nằm trong câu tiêu đề thì ta sẽ tăng nó lên  một  hệ\r\nsố là 4.\r\n      Việc nhận định câu tiêu đề được chúng em quy ước khi thu thập thủ công\r\ncác bài báo mạng để phục vụ việc kiểm thử.\r\n\r\n1.4.4.      Sinh câu tóm tắt\r\n\r\n      Kết quả của giải thuật PageRank hay giải thuật cải tiến  PageRank  đều\r\nđưa ra danh sách các node trong đồ thị đã được gán một trọng số  mới  tỷ  lệ\r\nthuận với độ quan trọng của node trong đồ thị tương ứng với  câu  trong  văn\r\nbản đầu vào\r\n      Ở bước này ta cho danh sách các node thu được ở trên  qua  một  module\r\nthực hiện các công việc sau:\r\n     Loại bỏ các câu đầu tiên  Câu tiêu đề (node có  chỉ  số  bằng  0)  ra\r\n      khỏi danh sách node thu được.\r\n     Loại bỏ một câu trong cặp câu có độ tương đồng  cao  (là  các  câu  có\r\n      khả năng trùng lặp nội dung). Ta thực hiện loại bỏ câu có độ dài  ngắn\r\n      hơn trong cặp câu cần loại.\r\n     Lấy danh sách các node theo tỷ lệ rút gọn.\r\n     Sắp xếp chỉ số các node được chọn cho văn bản tóm  tắt  theo  tứ  tăng\r\n      dần.\r\n     Thực hiện việc loại bỏ các nội dung không cần  thiết  trong  các  câu.\r\n      Các nội dung loại bỏ này gồm:\r\n         o Nội dung trong dấu ngoặc đơn ().\r\n         o Nội dung ở giữa 2 dấu  gạch ngang -.\r\n     Lấy ra các node sau khi đã sắp xếp tăng dần theo chỉ số được  gán  ban\r\n      đầu.\r\n      Đối với việc lựa chọn ngưỡng cho việc loại bỏ  bớt  câu  có  nội  dung\r\ntrùng nhau trong văn bản cần có thời gian trải qua  quá  trình  thực  nghiệm\r\nkiểm thử hoặc áp dụng các phương pháp hoc máy mới có thể cho  hiệu  quả  cao\r\nnhất. Do thời gian có hạn nên em chưa thể đưa ra được một ngưỡng  chính  xác\r\ntổng quát cho bài toán tóm tắt văn bản. Tuy nhiên, trong đồ án  này  em  vẫn\r\nđưa ra một ngưỡng cho việc loại bỏ câu theo ý kiến chủ  quan  dựa  trên  quá\r\ntrình thử nghiệm thủ công nhằm có thể minh họa một  phần  nào  đó  cho  cách\r\nthức áp dụng module này vào hệ thống của em. Cụ  thể,  ngưỡng  loại  bỏ  câu\r\ntrùng nhau được đưa ra là 0.8.\r\n\r\n1.5.   Giai đoạn hiển thị\r\n\r\n\r\n       Giai đoạn hiển thị đơn giản là tiếp nhận các node được  chọn  ở  giai\r\nđoạn xử lý sau đó lấy ra nội dung ban đầu các node đó và hiển thị  chúng  ra\r\nmàn hình.\r\n\r\n1.6.  Xây dựng chương trình tóm tắt trích rút đơn văn bản\r\n\r\n\r\n      Chương trình tóm tắt đơn văn bản được em xây dựng trên môi trường .NET\r\nbằng ngôn ngữ C#. Đây là một ngôn ngữ có khả năng xử lý tốt đối với dữ  liệu\r\nphẳng, đồng thời nó có hỗ trợ các đối tượng cấu trúc dữ  liệu  rất  hữu  ích\r\ncho bài toán tóm tắt văn bản.\r\n      Em xây dựng chương trình tóm tắt đơn văn bản gồm 3 projects:\r\n     Preprocessor: Tương ứng với giai đoạn tiền xử lý.\r\n     Processor: Tương ứng với giai đoạn xử lý\r\n     UserInterface: Tương ứng với giai đoạn hiển thị\r\n\r\n[pic]\r\n\r\n\r\n\r\n\r\n\r\nCHƯƠNG 2: CÀI ĐẶT ỨNG DỤNG\r\n\r\n\r\n2.1.   Một số giao diện chương trình\r\n\r\n      Trong phần này, em xin đưa ra các giao  diện  của  hệ  thống  tóm  tắt\r\ntrích rút đơn văn bản theo phương pháp đồ thị mà đồ án xây  dựng.  Nhằm  mục\r\nđích, mô tả trực quan hơn hệ thống.\r\n      Hệ thống thì gồm có 3 giao diện:\r\n\r\n[pic]\r\n\r\n\r\n                    \r\n      Giao diện chính cho phép thực hiện chọn văn bản đầu vào dạng .txt,\r\nchọn tỷ lệ trích rút theo số câu và sau đó yêu cầu hệ thống thực hiện quá\r\ntrình tóm tắt để cho ra kết quả. Kết quả đầu ra gồm hai văn bản tóm tắt\r\ntương ứng với hai phương pháp đã được trình bày ở phần trên.\r\n\r\n\r\n[pic]\r\n\r\n             \r\n      Giao diện này hiển thị chi tiết trọng số của các node trong đồ thị\r\ntương ứng với trọng số của các câu trong văn bản đầu vào.\r\n\r\n\r\n[pic]\r\n\r\n\r\n               \r\n      Giao diện này thực hiện việc đánh giá kết quả của văn bản tóm tắt  với\r\nvăn bản mẫu có sẵn.\r\n\r\n\r\n2.2.    Kiểm thử, đánh giá\r\n\r\n\r\n2.2.1.      Bộ dữ liệu mẫu\r\n\r\n      Bộ dữ liệu mẫu sử dụng cho quá trình kiểm thử trong đồ án  tốt  nghiệp\r\nnày là các văn bản tóm tắt thủ công được nhóm làm về tóm tắt văn  bản  chúng\r\nem thực hiện dưới sự hướng dẫn giúp đỡ của PGS.TS.Lê Thanh Hương.\r\n      Các tài liệu phục vụ cho việc tóm tắt thủ công là các bài báo  về  các\r\nmảng khác nhau của xã hội như: kinh tế, chính trị, văn hóa,  được  thu  thập\r\ntừ các trang Web lớn như: http://dantri.vn ,  http://vnexpress.vn  ,...  Các\r\nbài báo sau khi thu thập về chúng em sẽ tiến hành xử lý thủ công để loại  bỏ\r\nnhững lỗi ngữ pháp, lỗi trình bày, lỗi chính tả, cách  thức  trình  bày  bài\r\nbáo,. để có thể có được dữ liệu đầu vào phù hợp với hệ thống của  chúng  em.\r\nChúng em tiến hành chuẩn hóa văn bản thu thập như sau:\r\n          Câu tiêu đề được cho thành câu đầu tiên trong văn bản đầu vào.\r\n          Cắt bỏ các ảnh và các câu heading đi kèm theo các ảnh  có  trong\r\n           bài báo.\r\n      Độ dài văn bản tóm tắt mẫu khoảng 120 từ.\r\n      Số  lượng bài báo chúng em thu thập đồng thời tóm tắt thủ công để phục\r\nvụ cho kiểm thử là: 55 bài báo được lưu dưới dạng file .txt.\r\n      Độ dài của 55 bài báo nằm trong khoảng : 300  1000 từ.\r\n\r\n2.2.2.      phương pháp sử dụng cho việc đánh giá\r\n\r\n      Em quyết định chọn phương pháp đánh giá BLEU  cho  việc  đánh  giá  hệ\r\nthống tóm tắt tự động mà đồ án xây dựng. Bởi, nó là  phương  pháp  đánh  giá\r\nphổ biến được sử dụng nhiều cho đánh giá tóm tắt đơn văn bản.\r\n\r\n2.2.2.1.Giới  thiệu  phương  pháp  đánh  giá  BLEU   (Bilingual   Evaluation\r\nUnderstudy)\r\n\r\n      BLEU là một giải thuật sử dụng cho việc đánh giá chất  lượng  của  văn\r\nbản được sinh ra bởi một hệ thống dịch máy đối  với  một  văn  bản  mẫu  đối\r\nsánh. Chất lượng ở đây là độ trùng khớp giữa văn bản sinh ra  bởi  hệ  thống\r\ndịch máy với văn bản do con người tạo ra.\r\n      Nhiệm vụ chính của BLEU là tính toán độ đo BLEU của văn bản  đánh  giá\r\ndựa trên độ chính xác n-grams (số tiếng sử dụng cho việc so  khớp)  gồm:  1-\r\ngram, 2-gram, 3-gram, 4-gram. Các khái niệm của phương pháp BLEU:\r\n          Độ chính xác n-gram : Là nền tảng của phương pháp BLEU. Nó  được\r\n           tính bằng cách đếm số n-grams của văn bản đánh giá có trong  văn\r\n           bản mẫu rồi chia cho số n-grams trong văn bản đánh giá.\r\n      Để tính toán độ đo BLEU, đầu tiên chúng ta tính toán trung  bình  hình\r\nhọc của các độ chính xác n-grams  là  pn, sử dụng n-grams có  độ  dài  N  và\r\nmột trọng số trung bình wn.\r\n      Tiếp theo, cho c là độ dài của văn bản đánh giá và r là độ dài văn bản\r\nmẫu. Ta thực hiện tính toán độ rút gọn quy ước Brevity Penalty  (  BP)  theo\r\ncông thức sau:\r\n\r\n\r\n                                    [pic]\r\n\r\n\r\n      Sau đó tính toán độ đo BLEU theo công thức sau:\r\n\r\n\r\n                                    [pic]\r\n\r\n\r\n      Trong đó,\r\n            Pn: Là trung bình hình học của  các độ chính xác n-grams.\r\n            N: là độ dài của n-grams (Có thể là 1, 2 ,3 ,4).\r\n           Wn: là trọng số trung bình nó được lấy giá trị là: 1/ N.\r\n\r\n2.2.2.2.Đánh giá phương pháp  BLEU\r\n\r\n      Độ đo BLEU nằm trong khoảng (0,1). Giá trị này biểu hiện cho sự  tương\r\nđồng giữa văn bản đánh giá và văn bản mẫu, giá trị  càng  gần  tới  một  thì\r\nchứng tỏ các văn bản càng tương tự nhau.  Một số văn bản đánh  giá  đạt  giá\r\ntrị là 1 tức là nó đồng nhất với văn bản mẫu. Thực  tế,  thì  thậm  chí  một\r\nngười dịch cũng sẽ không thể đạt được số điểm là 1. Theo Denkowski và  Lavie\r\ntrong AMTA Evaluation Tutorial [1] nếu độ đo BLEU trên  0.3  chứng  tỏ  rằng\r\nvăn bản đánh giá có thể hiểu được. Nếu độ đo BLEU là trên 0.5  thì  văn  bản\r\nđánh giá là tốt và đạt được sự trôi chảy.\r\n\r\n\r\n2.2.3.      Các kết quả kiểm thử\r\n\r\n      Trong phần này, em thực hiện kiểm thử với 55 văn bản thu thập  từ  các\r\ntrang web và tạo văn bản mẫu như đã giới thiệu ở trên. Kiểm thử sử  dụng  độ\r\nđo BLEU với n-grams là 4.\r\n      Để hiểu rõ hơn cho hệ thống của mình em xin đưa ra một ví dụ minh  họa\r\nđầu vào, đầu ra của hệ thống tóm tắt đơn văn bản theo phương pháp đồ thị:\r\n\r\n\r\n|Văn bản đầu vào:                                                    |\r\n|                                                                    |\r\n|Nhiều dự án biệt thự Hà Nội cả quý I không ai hỏi mua.             |\r\n|Nếu biệt thự/nhà liền kề tại Hà Nội nhiều dự án không có khách hỏi  |\r\n|mua thì tại TP HCM có xu hướng khách tìm đến đất nền nhiều hơn.     |\r\n|Thị trường biệt thự và nhà liền kề trong quý I/2013, theo khảo sát  |\r\n|của Savills, nguồn cung có 3 dự án (Khu đô thị Dream Tower, Tây Nam |\r\n|Hồ Linh Đàm và Đặng Xá II), cung cấp khoảng 245 căn nhà cho thị     |\r\n|trường.                                                             |\r\n|Nhìn chung cả quý, nguồn cung phân khúc căn hộ này trên thị trường  |\r\n|Hà Nội gồm 42.000 căn từ 125 dự án, trong đó 102 dự án hợp đồng mua |\r\n|bán (HĐMB) cung cấp khoảng 29.800 căn nhà gồm 16.900 nhà liền kề và |\r\n|12.900 biệt thự. Nguồn cung còn lại đến từ các dự án dạng hợp đồng  |\r\n|góp vốn (HĐGV).                                                     |\r\n|Nguồn cung khá dồi dào trên, thanh khoản của thị trường quý vừa qua |\r\n|vẫn thấp. Giá chào thứ cấp bình quân của toàn thị trường giảm so với|\r\n|quý trước ở mức -13% đối với biệt thự và -9% đối với liền kề. Nhiều |\r\n|dự án tại vùng 2, đặc biệt là Mê Linh và Hoài Đức, trong quý này    |\r\n|không có khách hỏi mua.                                             |\r\n|Giá chào bình quân thứ cấp tại vùng 1 từ 41,7 triệu VNĐ đến 158     |\r\n|triệu đồng/m2, trong khi tại vùng 2 dao động từ 9,4 - 54 triệu      |\r\n|đồng/m2. Các quận Cầu Giấy, Tây Hồ và Từ Liêm có giá chào bình quân |\r\n|thứ cấp cao nhất với mức hơn 108 triệu đồng/m2 đối với biệt thự và  |\r\n|nhà liền kề. Hầu hết các dự án thuộc vùng 2 đều có giá chào dưới 20 |\r\n|triệu đồng/m2.                                                      |\r\n|Về nguồn cầu, theo Savills, nhu cầu đối với thị trường biệt thự/nhà |\r\n|liền kề hiện đang thấp hơn so với nguồn cung sẵn có do người mua vẫn|\r\n|đang chờ 1 mức giá thấp hơn nữa. Mức trần lãi suất huy động đã được |\r\n|hạ xuống chỉ còn 7,5% vào ngày 26/3/2013, điều này có thể sẽ làm lãi|\r\n|suất cho vay giảm hơn nữa, tạo thêm thuận lợi cho thị trường nhà ở. |\r\n|Trong khi đó, nguồn cung tương lai của thị trường biệt thự/nhà liền |\r\n|kề tại Hà Nội sẽ đến từ 76 dự án nằm rải rác tại 14 quận với tổng   |\r\n|diện tích 10.200 ha đất. Số lượng dự án tương lai là không đổi so  |\r\n|với quý trước, và có khả năng vẫn tiếp tục duy trì ở mức này do UBND|\r\n|TP Hà Nội đang dự định ngừng cấp phép cho các dự án nhà ở thương mại|\r\n|nằm ở Hà Nội từ nay cho đến cuối năm 2014- bà Đỗ Thu Hằng, Trưởng  |\r\n|Bộ phận Nghiên cứu và Tư vấn của Savills Hà Nội.                    |\r\n|Ông Trần Như Trung cho biết, cũng trong tình trạng ế ẩm như Hà Nội, |\r\n|dù tại thị trường TP HCM trong quý I không có dự án nào mới gia nhập|\r\n|thị trường. Có 11 dự án đang hoạt động trong thị trường sơ cấp cung |\r\n|cấp hơn 290 căn, trong đó biệt thự chiếm 52% thị phần.              |\r\n|Vì vậy, toàn thị trường biệt thự/nhà liền kề TP HCM cung cấp hơn    |\r\n|3.200 căn, tăng nhẹ 3% so với cùng kỳ năm trước, trong đó thị trường|\r\n|thứ cấp chiếm khoảng 91% thị phần. Trong thị trường sơ cấp có 12 dự |\r\n|án đất nền đang hoạt động cung cấp tổng cộng 577 lô, giảm -7% so với|\r\n|quý trước.                                                          |\r\n|Tình hình hoạt động của phân khúc biệt thự/nhà liền kề trong thị    |\r\n|trường sơ cấp tại TP HCM cũng không tốt trong quý I/2013. Tỉ lệ hấp |\r\n|thụ trung bình là 5%, giảm -8 điểm % so với quý trước. Tỉ lệ hấp thụ|\r\n|trung bình của phân khúc đất nền cũng giảm mạnh, giảm -11 điểm phần |\r\n|trăm xuống 9% sau khi đạt mức tỉ lệ hấp thụ hai con số trong hai quý|\r\n|vừa qua.                                                            |\r\n|Giá bán trung bình của biệt thự/nhà liền kề trên thị trường thứ cấp |\r\n|ở mức ổn định, tuy nhiên, giá đã giảm mạnh -12% so với cùng kỳ năm  |\r\n|trước. Giá bán trung bình đất nền trên thị trường thứ cấp không đổi |\r\n|so với quý trước.                                                   |\r\n|Trong khi đó, về nguồn cầu, các chủ đầu tư với cam kết trong phát   |\r\n|triển dự án và tiến độ xây dựng cũng như có chiến lược tiếp thị tốt |\r\n|hoặc giảm giá tiếp tục thu hút sự chú ý của người mua nhà. Tuy      |\r\n|nhiên, so với biệt thự, nhà liền kề đã hoàn thiện, đất nền vẫn hấp  |\r\n|dẫn hơn với đối tượng người mua trung lưu, nhờ vào những lợi thế của|\r\n|chi phí xây dựng thấp hơn.                                          |\r\n|Hơn nữa, theo Savills, đất nền cũng cung cấp sự đa dạng hoá danh mục|\r\n|đầu tư cho các nhà đầu tư trung và dài hạn. Đặc biệt, các dự án tọa |\r\n|lạc trong những khu vực dân cư đông đúc và được bao quanh bởi các cơ|\r\n|sở và công trình tiện ích hoặc tiếp giáp với các hệ thống cơ sở hạ  |\r\n|tầng lớn đang phát triển phù hợp cho cả hai mục đích sống và thương |\r\n|mại.                                                                |\r\n|Trong tương lai, theo Savills, tại thị trường TP HCM, phân khúc biệt|\r\n|thự/nhà liền kề này sẽ có khoảng 57.200 căn từ hơn 140 dự án trải   |\r\n|rộng trên 9.190 ha dự kiến sẽ gia nhập thị trường trong vòng 8 năm  |\r\n|tới. Riêng năm 2013, có hơn 1.200 căn từ 11 dự án dự kiến sẽ gia    |\r\n|nhập thị trường trong 3 quý tới.                                   |\r\n|Văn bản mẫu kiểm thử:                                               |\r\n|                                                                    |\r\n|Nếu biệt thự/nhà liền kề tại Hà Nội nhiều dự án không có khách hỏi |\r\n|mua thì tại TP HCM có xu hướng khách tìm đến đất nền nhiều hơn.     |\r\n|Thị trường biệt thự và nhà liền kề trong quý I/2013, nguồn cung có 3|\r\n|dự án , cung cấp khoảng 245 căn nhà cho thị trường.                 |\r\n|Về nguồn cầu,  nhu cầu đối với thị trường biệt thự/nhà liền kề hiện |\r\n|đang thấp hơn so với nguồn cung sẵn có do người mua vẫn đang chờ 1  |\r\n|mức giá thấp hơn nữa.                                               |\r\n|Tuy nhiên, so với biệt thự, nhà liền kề đã hoàn thiện, đất nền vẫn  |\r\n|hấp dẫn hơn với đối tượng người mua trung lưu, nhờ vào những lợi thế|\r\n|của chi phí xây dựng thấp hơn.                                     |\r\n|                                                                    |\r\n|Văn bản 1: Văn bản kết quả của PP đồ thị sử dụng PageRank:          |\r\n|                                                                    |\r\n|Nếu biệt thự/nhà liền kề tại Hà Nội nhiều dự án không có khách hỏi |\r\n|mua thì tại TP HCM có xu hướng khách tìm đến đất nền nhiều hơn.     |\r\n|Về nguồn cầu, theo Savills, nhu cầu đối với thị trường biệt thự/nhà |\r\n|liền kề hiện đang thấp hơn so với nguồn cung sẵn có do người mua vẫn|\r\n|đang chờ 1 mức giá thấp hơn nữa.                                    |\r\n|Trong tương lai, theo Savills, tại thị trường TP HCM, phân khúc biệt|\r\n|thự/nhà liền kề này sẽ có khoảng 57.200 căn từ hơn 140 dự án trải   |\r\n|rộng trên 9.190 ha dự kiến sẽ gia nhập thị trường trong vòng 8 năm  |\r\n|tới.                                                               |\r\n|                                                                    |\r\n|Văn bản 2: Văn bản kết quả của PP đồ thị sử dụng PageRank cải tiến: |\r\n|                                                                    |\r\n|Nếu biệt thự/nhà liền kề tại Hà Nội nhiều dự án không có khách hỏi |\r\n|mua thì tại TP HCM có xu hướng khách tìm đến đất nền nhiều hơn.     |\r\n|Thị trường biệt thự và nhà liền kề trong quý I/2013, theo khảo sát  |\r\n|của Savills, nguồn cung có 3 dự án, cung cấp khoảng 245 căn nhà cho |\r\n|thị trường.                                                         |\r\n|Nhìn chung cả quý, nguồn cung phân khúc căn hộ này trên thị trường  |\r\n|Hà Nội gồm 42.000 căn từ 125 dự án, trong đó 102 dự án hợp đồng mua |\r\n|bán cung cấp khoảng 29.800 căn nhà gồm 16.900 nhà liền kề và 12.900 |\r\n|biệt thự.                                                          |\r\n|Kết quả kiểm thử bằng độ đo BLEU:                                   |\r\n|Văn bản 1:     0.566497                                             |\r\n|Văn bản 2:     0.58661                                              |\r\n\r\n\r\n\r\n               \r\n\r\n      Kết quả trung bình kiểm thử trên 55 bài báo theo độ đo BLEU như sau:\r\n\r\n|         |Phương pháp đồ thị           |Phương pháp đồ thị cải tiến |\r\n|         |                             |                            |\r\n|Kết quả  |0.515435                     |0.542422                    |\r\n\r\n\r\n                     \r\n\r\n2.2.4.      Nhận xét, đánh giá\r\n\r\n\r\n     Về mặt chất lượng văn bản tóm tắt:\r\n\r\n\r\n      Theo kết quả đánh giá khi sử dụng độ đo BLEU ta thấy  rằng  những  văn\r\nbản đầu ra của hệ thống đã có sự đồng nhất khá lớn đối với văn bản  tóm  tắt\r\nmẫu.\r\n\r\n      Bằng trực quan, khi trực tiếp quan sát các văn bản đầu ra của hệ thống\r\nthì thực tế đối với mục đích trôi chảy thì các văn bản đầu ra của  hệ  thống\r\ncòn có nhiều hạn chế bởi cách thức tóm tắt là trích  rút  câu  nên  các  câu\r\nđược trích rút còn rời rạc chưa có sự liên kết chặt chẽ về  mặt  ngữ  nghĩa,\r\nnhưng với mục đích tóm gọn nội dung thì văn bản tóm tắt đã đáp ứng khá tốt.\r\n\r\n     Về mặt thời gian\r\n\r\n      Hệ thống tóm tắt có thời gian chạy chậm, do một  số  thuật  toán  chưa\r\nđược tối ưu. Thời gian chạy của hệ thống tỷ lệ thuận với độ dài của văn  bản\r\nđầu vào.\r\n\r\n     So sánh hai phương pháp mà hệ thống xây dựng\r\n\r\n      Dựa trên kết quả kiểm thử của độ đo BLEU, ta thấy rằng phương pháp cải\r\ntiến có xét tới vị trí từ thuộc câu tiêu đề có số  điểm  cao  hơn  chứng  tỏ\r\nrằng sự cải tiến đã có hiệu quả góp phần làm cho kết quả đầu  ra  chính  xác\r\nhơn so với phương pháp đồ thị được xây dựng ban đầu.\r\n\r\n     Khả năng ứng dụng của hệ thống\r\n\r\n      Hệ thống có khả năng thực hiện tóm tắt hiệu quả đối với  các  văn  bản\r\nngắn và trung bình như các bài báo, tin tức trên Internet.\r\n\r\n      Hệ thống có thể được tích hợp trong các công cụ  thu  thập  thông  tin\r\ndạng văn bản để có thể đưa ra được nhiều  thông  tin  chính  xác  tới  người\r\ndùng.\r\n\r\n\r\n\r\nKẾT LUẬN VÀ HƯỚNG PHÁT TRIỂN\r\n\r\n\r\n\r\n      Đồ án là kết quả của quá trình tìm hiểu, phân  tích  trong  việc  giải\r\nquyết bài toán tóm tắt trích rút đơn văn bản. Trong quá trình thực hiện,  em\r\nđã có cơ hội tìm hiể về một phương pháp mới trong việc giải quyết  bài  toán\r\ntóm tắt đơn văn bản đó là phương pháp đồ thị đồng thời áp dụng nó  vào  việc\r\nxây dựng hệ thống tóm tắt đơn văn bản. Sản phẩm của đồ án là  một  hệ  thống\r\ntóm tắt trích rút đơn văn bản có thể tạo ra các văn bản tóm tắt từ  các  văn\r\nbản đầu vào. Điều này giúp ích rất nhiều cho con người trong việc  tìm  kiếm\r\nthông tin, giúp họ tiếp cận với thông tin một  cách  nhanh  chóng  và  thuận\r\ntiện hơn.\r\n      Sau đây em xin đánh những việc đã làm được và chưa làm được trong phạm\r\nvi đồ án này:\r\n\r\n\r\n     Công việc làm được:\r\n          Tìm hiểu phương pháp đồ thị, giải thuật  PageRank  áp  dụng  cho\r\n           bài toán tóm tắt đơn văn bản.\r\n          Tìm hiểu các kiển thức chung  về  tiếng  Việt  áp  dụng  vào  hệ\r\n           thống gồm: tách câu, tách từ,.\r\n          Áp dụng phương pháp đồ thị,  giải  thuật  tính  độ  tương  đồng,\r\n           giải thuật PageRank trong việc xây dựng hệ thống tóm  tắt  trích\r\n           rút đơn văn bản.\r\n          Đề xuất cải tiến giúp nâng cao hiệu  quả  của  phương  pháp  tóm\r\n           tắt nguyên bản ban đầu.\r\n\r\n\r\n     Công việc chưa làm được:\r\n          Không sử dụng đồng tham chiếu cho phần tiền xử lý khi  xây  dựng\r\n           hệ thống tóm tắt.\r\n          Giải thuật tách từ của hệ thống chưa được cải tiến.\r\n          Chưa giải quyết được tính dễ đọc của bản tóm tắt.\r\n          Bộ từ điển còn ít từ vựng.\r\n          Hệ thống chưa được tối ưu hóa nên thời gian chạy còn chậm.\r\n          Chưa đối sánh được hiệu quả của phương  pháp  áp  dụng  với  các\r\n           phương pháp truyền thống đã có trước đó đối với bài toán tóm tắt\r\n           đơn văn bản.\r\n      Trong quá trình thực hiện đồ án, em đã vận dụng hết khả năng của  mình\r\nđể có thể tạo ra một kết quả tốt nhất. Tuy nhiên, do thời gian có  hạn  cùng\r\nvới khả năng, kiến thức bản thân còn hạn chế nên hệ thống  đồ  án  xây  dựng\r\ncòn nhiều điểm thiếu sót. Trong tương lai em sẽ tiến  hành  hoàn  thiện  các\r\nđiểm thiếu sót đồng thời phát triển thêm giúp nâng cao được hiệu quả của  hệ\r\nthống tóm tắt trích rút đơn văn bản mà em xây dựng  trong  đồ  án  này.  Các\r\ncông việc nhằm khắc phục hạn chế và hướng phát triển cụ thể như sau:\r\n\r\n\r\n     Hướng phát triển:\r\n          Áp dụng đồng tham chiếu giúp tăng hiệu quả hơn cho kết  quả  đầu\r\n           ra.\r\n\r\n          Xây dựng bộ từ điển thêm phong phú hơn.\r\n\r\n          Tối ưu hóa hệ thống do thời gian chạy của hệ thống còn chậm.\r\n\r\n          Cải tiến giải thuật cho bước tách từ.\r\n\r\n          Thực hiện cài đặt thêm các thuật toán khác để có  thể  đối  sánh\r\n           tốt hơn.\r\n\r\n          Nâng hệ thống lên thành hệ thống tóm tắt tóm  lược  để  có  được\r\n           đầu ra tốt hơn.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nTÀI LIỆU THAM KHẢO\r\n\r\n\r\n\r\n\r\n     1. Denkowski, M.Lavie.  (2010).  Choosing  the  Right  Evaluation  for\r\n        Machine Translation: an  Examination  of  Annotator  and  Automatic\r\n        Metric Performance on Human Judgment Tasks. In Proceedings  of  the\r\n        Association for Machine Translation in the Americas AMTA.\r\n     2. Lin, Chin-Yew. (2004). ROUGE: A Package for Automatic Evaluation of\r\n        Summaries. In Proceedings of NTCIR Workshop 2004. Tokyo.\r\n     3. L.Page, S.Brin (1998). The anatomy of the large-scale  hypertextual\r\n        Web search engine. Computer Networks and ISDN Systems, 30(1 - 7).\r\n     4. Papineni, K.Roukos,  S.Ward,  T.Zhu  (2002).  BLEU:  a  Method  for\r\n        Automatic Evaluation of Machine Translation. In Proceedings of  the\r\n        40th Annual Meeting on Association for  Computational  Linguistics,\r\n        pp.311-318.\r\n     5. Qazvinian, V.Hasanabadi, Halavati (2008). Summarising text  with  a\r\n        genetic algorithm-based sentence extraction.  Knowledge  Management\r\n        Studies, Vol.2, No.4, pp.426 - 444.\r\n     6.  M.Rada  (2004).  Graph-based  ranking  algorithms   for   sentence\r\n        extraction. applied to text summarization, pp.170-173.\r\n     7. Vũ Hải Tùng-lớp CNPM-K45. (2005). Thesis. Xây dựng hệ thống tóm tắt\r\n        đơn văn bản Summarizer. Trường ĐH Bách Khoa Hà Nội.\r\n     8. Dusek, Ondrej lingutil. from https://code.google.com/p/lingutil/  .\r\n        last visit May 2013.\r\n     9. Lưu Tuấn Anh, Yamamoto Kazuhide. Natural language processing.  from\r\n        http://viet.jnlp.org/dongdu . last visit May 2013.\r\n    10.     Nguyễn     Minh     Thành.     Text     Summarization.     from\r\n        https://sites.google.com/site/trangmonhocitc/text-summarization,\r\n        last visit May, 2013.\r\n\r\n\r\n\r\n\r\n\r\n-----------------------\r\n                                      2\r\n\r\n                                      3\r\n\r\n                                      1\r\n\r\n                                      4\r\n\r\n                                      7\r\n\r\n                                      5\r\n\r\n                                      6","u":"http://202.191.57.85:8000/InternetData/Data/LVTN/70.txt","sentences":[[1,"Em thấy rằng việc mô hình hóa một văn bản thành một đồ thị là việc làm dễ dàng và trực quan và tạo thuận lơi cho các bước xử lý"],[2,"Trong đồ án này, mục đích của em là thực hiện việc so sánh hiệu quả của một phương pháp đồ thị với các phương pháp đã có"],[3,"Chính bởi vậy, em chọn phương pháp đồ thị cho việc giải quyết bài toán tóm tắt đơn văn bản trong phạm vi đồ án tốt nghiệp này"],[4,"Cụ thể, phương pháp em lựa chọn là Tóm tắt trích rút đơn văn bản theo phương pháp đồ thị"],[5,"Sau đây em xin trình bày các phần cụ thể của hệ thống tóm tắt trích rút đơn văn bản theo phương pháp đồ thị mà em xây dựng: 1.1"],[6,"Phương pháp đồ thị áp dụng trong bài toán tóm tắt Phương pháp đồ thị là phương pháp sử dụng đồ thị làm mô hình để biểu diễn dữ liệu đầu vào của hệ thống"],[7,"Sử dụng đồ thị để biểu diễn một văn bản sẽ giúp chúng ta hiểu hơn về sự liên kết giữa các phần khác nhau của văn bản"],[8,"Giải thuật dựa trên đồ thị sử dụng một giải thuật xếp hạng để cho điểm các ngữ liệu khác nhau của một văn bản cụ thể là một câu trong văn bản hay một node trong đồ thị"],[9,"Giải thuật xếp hạng được sử dụng với các tiêu chuẩn khác nhau trong việc sắp xếp các node theo mức độ quan trọng"],[10,"Cấu tạo của các node và các cạnh sẽ được xác định bởi loại văn bản"],[11,"Ví dụ, một vài ngữ liệu của văn bản như: các từ hoặc các câu có thể được mô hình hóa thành các node"],[12,"Các cạnh là thể hiệncủa sự liên kết từ ngữ hoặc ngữ nghĩa hoặc sự tương đồng giữa hai node"],[13,"Tùy vào các đặc tính của văn bản mà ta mô hình hóa cho nó thành dạng đồ thị phù hợp, một giải thuật xếp hạng dựa trên đồ thị gồm các bước cơ bản sau: Định nghĩa đơn vị của văn bản nó có thể là nhóm từ, từ hoặc các đơn vị khác và mô hình hóa chúng thành các đỉnh hay các node của đồ thị"],[14,"Xác định mối quan hệ giữa các đơn vị ngữ liệu để có thể hình thành các cạnh cho các node của đồ thị"],[15,"Các cạnh có thể là có hướng hoặc vô hướng và có trọng số hoặc không có trọng số"],[16,"Tiến hành thực hiện giải thuật xếp hạng lặp lại cho tới khi toàn bộ các node trong đồ thị được sắp xếp theo mức độ quan trọng"],[17,"Sắp xếp các node theo số điểm của chúng"],[18,"Khi hệ thống thực hiện tới bước thứ 4 thì một số điểm cuối cùng đã được gán cho mỗi node"],[19,"Các node được xếp hạng dựa trên số điểm cuối cùng của chúng"],[20,"Sau đó, tùy thuộc vào tỷ lệ rút gọn Tỷ lệ rút gọn là độ dài mong muốn đối với văn bản tóm tắt, các câu có điểm số cao nhất sẽ được lựa chọn cho bản tóm tắt cuối cùng"],[21,"Sau đây là hai giải thuật tiêu biểu áp dụng việc tính toán độ quan trọng dựa trên đồ thị: LexRank: Erkan và Radov đã thiết kế LexRank để sắp xếp văn bản tóm tắt trong hệ thống tóm tắt đa văn bản"],[22,"Nó giải thuyết rằng một câu tương tự với nhiều câu khác trong một nhóm thì càng quan trọng và càng gần với chủ đề"],[23,"Trong giải thuật này, một đồ thị vô hướng và kết nối đầy đủ được xây dựng cho các câu trong mỗi nhóm"],[24,"Nếu hai câu có sự tương đồng thì một cạnh sẽ được hình thành giữa chúng"],[25,"Độ tương đồng cosine được sử dụng cho việc tính toán độ tương đồng giữa hai câu"],[26,"Sau khi tính toán độ tương đồng giữa các cặp câu và xây dựng đồ thị, chúng ta sẽ xác định được câu trung tâm của đồ thị xây dựng cho mỗi nhóm bằng cách sau"],[27,"Ta sẽ xác định độ quan trọng của mỗi câu nó chính là độ tương đồng với các câu"],[28,"Câu có độ quan trọng cao nhất sẽ là câu trung tâm"],[29,"TextRank: TextRank là mô hình xếp hạng dựa trên đồ thị nó sử dụng cho tất cả các đồ thị được chuyển đổi từ các văn bản ngôn ngữ tự nhiên"],[30,"TextRank chuyển hóa từ mô hình xếp hạng trang của Google và được thiết kế để sử dụng cho các hệ thống tóm tắt đơn văn bản"],[31,"TextRank được sử dụng để trích rút từ khóa hoặc câu"],[32,"Một đồ thị vô hướng và đầy đủ được sử dụng cho việc trích rút câu"],[33,"Mỗi câu được mô hình hóa thành một đỉnh hay một node trong đồ thị"],[34,"Để tạo ra một cạnh giữa hai câu, một mối quan hệ tương đồng được tính toán như là một hàm của các khái niệm liên kết"],[35,"Mỗi cạnh với một trọng số chỉ ra độ quan trọng của mối quan hệ giữa hai node trong đồ thị"],[36,"Các câu dựa trên điểm của chúng được xếp hạng và các câu có số điểm cao nhất sẽ được lựa chọn cho văn bản tóm tắt đầu ra"],[37,"Từ những tìm hiểu trên về việc sử dụng đồ thị cho công việc TTVB, nên em quyết định thực hiện xây dựng một hệ thống tóm tắt đơn văn bản trích rút dựa trên đồ thị"],[38,"Hệ thống có sự kế thừa phương pháp TextRank trong việc xử lý trên đồ thị đó là việc sử dụng giải thuật PageRank cho công việc xếp hạng các node trên đồ thị mô hình hóa văn bản đầu vào"],[39,"1.2"],[40,"Mô hình hệ thống Dựa trên mô hình chung của bài toán TTVB, chúng tôi đã xây dựng mô hình ứng dụng tóm tắt trích rút tự động văn bản tiếng Việt"],[41,"Ứng dụng gồm các giai đoạn sau: Tiền xử lý Xử lý Hiển thị [pic] Mỗi giai đoạn gồm các module chức năng thực hiện các công việc cụ thể: Giai đoạn tiền xử lý: Chuẩn hóa đầu vào, thực hiện các giải thuật của quá trình tiền xử lý và mô hình hóa văn bản đầu vào"],[42,"Giai đoạn xử lý: Xây dựng giải thuật cho việc TTVB"],[43,"Giai đoạn hiển thị: Đưa ra các câu đã được chọn trong văn bản đầu vào hiển thị lên màn hình"],[44,"1.3"],[45,"Giai đoạn tiền xử lý Trước khi bắt đầu quá trình biểu diễn văn bản, người ta tiến hành bước tiền xử lý văn bản"],[46,"Đây là bước hết sức quan trọng vì nó có nhiệm vụ làm giảm số từ không mang nhiều ý nghĩa có trong văn bản và qua đó làm giảm kích thước dữ liệu trong quá trình biểu diễn mô hình hóa văn bản"],[47,"1.3.1"],[48,"Mô hình từ điển Từ điển được sử dụng trong hệ thống tóm tắt gồm có 3 loại: Từ điển từ vựng Từ điển từ dừng Từ điển từ đồng nghĩa, trái nghĩa Cách thức thu thập và xây dựng các từ điển đó được tiến hành như sau: |Từ điển từ vựng: | |Cách thức thu thập: Em sử dụng từ điển có sẵn được sử dụng | |trong tool tách từ DongDu của hai tác giả: Lưu Tuấn Anh và | |Yamamoto Kazuhide, nguồn từ trang: http://viet.jnlp.org/dongdu"],[49,"| |Cách thức tổ chức: Từ điển được lưu dưới dạng file .txt, với mỗi| |dòng là một từ vựng, mỗi tiếng trong từ cách nhau bởi dấu khoảng| |trắng"],[50,"| |Độ lớn: 31242 từ | |Từ điển từ dừng: | |Cách thức thu thâp: Chúng em sử dụng tool trích rút trên trang | |web: http://tratu.soha.vn"],[51,"| |Cách thức tổ chức: Từ điển được lưu dưới dạng file .txt, với | |mỗi dòng là một từ dừng, mỗi tiếng trong từ cách nhau bởi dấu | |gạch dưới"],[52,"| |Độ lớn: 571 từ | |Từ điển từ đồng nghĩa, trái nghĩa: | |Cách thức thu thâp: Em sử dụng bộ từ điển có sẵn do một bạn | |trong nhóm trích rút từ trang: http://tratu.soha.vn"],[53,"| |Cách thức tổ chức: Từ điển được lưu dưới dạng file .txt, với | |mỗi dòng là một tổ hợp được chia thành 3 phần cách nhau bởi đấu | |hai chấm gồm: từ vựng: từ đồng nghĩa : từ trái nghĩa ; mỗi | |tiếng trong từ cách nhau bởi dấu gạch dưới"],[54,"| |Độ lớn: 7734 tổ hợp | 1.3.2"],[55,"Tách câu Theo sách ngữ pháp tiếng Việt của Ủy ban Khoa học Xã hội (1980): Câu là đơn vị dùng từ hay đúng hơn dùng ngữ mà cấu tạo nên trong quá trình tư duy, thông báo, nó có nghĩa hoàn chỉnh, có cấu tạo ngữ pháp và có tính chất độc lập"],[56,"Dựa trên cơ sở này ta sẽ tiến hành xét một đơn vị ngôn ngữ có phải là câu hay không để thực hiện tách câu"],[57,"Vấn đề tách câu thành các đơn vị câu độc lập dường như được ít các nhà nghiên cứu quan tâm nhất, mặc dù nó cũng là phần việc quan trọng trong phân tích văn bản"],[58,"Để tách một văn bản ra thành các đơn vị câu độc lập đối với tiếng Việt không đơn thuần là chỉ dựa vào các dấu hiệu kết thức câu như:"],[59,", ?, !, ."],[60,"Vẫn có những câu tiếng Việt mà các dấu hiệu kết câu chưa phải là kết câu"],[61,"Ví dụ như: dấu"],[62,"nằm trong số tiền (20.000.000 vnđ) hoặc trong số điện thoại (0974.334.345) hoặc trong các từ viết tắt PGS.TS"],[63,"Đối với vấn đề tách câu em đã xây dựng một module xử lý các vấn đề sau: Tách các câu theo dấu hiệu nhận biết của các dấu kết thúc câu gồm : .,!, ?,,."],[64,"Sử dụng các biểu thức chính quy để tránh các trường hợp các dấu báo hiệu kết thúc câu nằm trong cụm thuộc các dạng đặc biệt gồm: Email, số tiền, từ viết tắt"],[65,"Ngoài ra, trong module này em cũng loại bỏ bớt các dấu không cần thiết cho việc mô hình hóa văn bản như các dấu: ,, /, ( ),"],[66,"1.3.3"],[67,"Xử lý các từ đầu câu Trước khi thực hiện việc tách từ, em có xây dựng một module nhằm đưa các từ viết hoa ở đầu câu về dạng thường nếu không phải là danh từ riêng"],[68,"Model này giúp làm tăng tính chính xác cho việc so khớp từ điển của bước tách từ, từ đó cho ta được kết quả chính xác hơn sau khi tách từ"],[69,"Module này làm hai việc như sau: Lấy các từ viết hoa trong văn bản (ngoại trừ các từ đầu câu)"],[70,"Xét từ đầu tiên trong từng câu nếu từ đó có trong danh sách các từ viết hoa thì giữ nguyên nếu không thì ta chuyển nó về thành dạng chữ in thường"],[71,"1.3.4"],[72,"Tách từ Tách từ là việc phân tích dữ liệu đầu vào và tách nó thành các từ tố"],[73,"Chẳng hạn, ta có chuỗi đầu vào là Công nghệ thông tin và ta quy định khoảng trắng là dấu hiệu phân tách giữa các từ tố"],[74,"Khi đó một Tokenizer sẽ đơn giản tách chuỗi đầu vào thành 4 từ tố (Công, nghệ, thông, tin)"],[75,"Tuy nhiên, nếu ta quy định các từ tố được tách ra phải là các từ có nghĩa thì vấn đề không còn đơn giản như vậy"],[76,"Nếu như với tiếng Anh thì ta có thể sử dụng khoảng trắng làm dấu hiệu phân tách các từ tố có nghĩa, thì trong tiếng Việt điều đó hoàn toàn không còn đúng và nó trở nên phức tạp hơn nhiều"],[77,"Ví dụ: |Đoạn văn bản đầu vào: | | | |Ta càng cố gắng thì càng bị đè nén"],[78,"Bản than không thể tìm chốn | |dung thân"],[79,"| |Sau khi thực hiện tách từ ta được kết quả như sau: | | | |ta càng cố_gắng thì càng bị đè_nén"],[80,"bản_thân không thể tìm chốn | |dung_thân"],[81,"| Với những điều kiện tiên quyết của việc tách từ trong văn bản nói trên, em đã tìm hiểu qua một số phương pháp tách từ phổ biến cho việc tách từ như: o So khớp từ dài nhất (Longest Matching) o So khớp cực đại (Maximum Matching) o Mô hình Markov ẩn (Hidden Markov Models- HMM) o Học dựa trên sự cải biến (Transformation-based Learning TBL) o Chuyển đổi trạng thái trọng số hữu hạn(Weighted Finite State Transducer) o Độ hỗn loạn cực đại (Maximum Entropy ME) o Máy học sử dụng vectơ hỗ trợ (Support Vector Machines) o Trường xác xuất có điều kiện (CRFs) Cuối cùng, em lựa chọn phương pháp so khớp từ dài nhất dựa trên một từ điển tiếng Việt có sẵn và cụ thể là phương pháp so khớp từ dài nhất từ trái qua vì sự rõ ràng và dễ cài đặt của nó"],[82,"Sau đây là mô hình thuật toán xem sử dụng: [pic] Ví dụ minh họa cho thuật toán trên, ta xét câu sau: Cuộc đời là những thách thức"],[83,"Đầu tiên, ta lấy được độ dài lớn nhất của từ có trong từ điển để có thể lấy được chuỗi xét hợp lý đối với từ điển"],[84,"Để dễ dàng, em giả sử độ dài lớn nhất của từ trong từ điển lớn hơn chuỗi ví dụ của ta"],[85,"Khi đó, đầu tiên ta kiểm tra xem cụm cuộc đời là những thách thức có trong từ điển hay không?Nếu không có ta tách bớt âm tiết cuối ra lưu một chuỗi khác và kiểm tra cụm từ cuộc đời là những thử có trong từ điển không?Nếu không ta lại tách tiếp từ cuối cùng của cụm đang xét nối vào chuỗi lưu các từ chưa được xét tới"],[86,"Tiếp tục tới khi ta xét tới từ cuộc đời nó có trong từ điển ta đã có một từ được tìm thấy"],[87,"Ta lại lặp lại các bước như trên với phần còn lại chưa xét của câu cho tới khi không còn chuỗi nào của câu đang xét"],[88,"Sau khi thực hiện thuật toán trên ta thu được kết quả là: cuộc_đời là những thách_thức 1.3.5"],[89,"Loại bỏ từ dừng (stopword) Từ dừng là các từ xuất hiện thường xuyên trong văn bản nhưng không mang nhiều ý nghĩa về nội dung văn bản"],[90,"Đó có thể là các loại từ mang tính hỗ trợ cho từ khác hoặc mang ý nghĩa về mặt cấu trúc"],[91,"Do đó, trong quá trình xây dựng hệ thống tóm tắt, ta cần tìm ra các từ dừng và loại bỏ chúng ra khỏi văn bản giúp cho hệ thống bớt đi gánh nặng khi phải xử lý các từ không mang nhiều ý nghĩa của văn bản"],[92,"Loại bỏ từ dừng đơn giản là việc so sánh các từ tìm được với bộ từ điển từ dừng và loại bỏ chúng khỏi văn bản đầu vào.Tuy nhiên, việc loại bỏ từ dừng cũng đóng vai trò quan trọng trong hệ thống tóm tắt bởi các yếu tố: Làm đơn giản hóa dữ liệu xử lý, làm giảm độ lớn của các node cũng như độ phức tạp tính toán của chúng"],[93,"Nó tránh được hiện tượng nhiễu dữ liệu (tránh cho các hệ thống đánh giá mức độ quan trọng dựa trên tần suất xuất hiện của từ)"],[94,"Dưới đây là bảng ví dụ về các từ dừng thường thấy trong văn bản tiếng Việt |Có thể |Nếu |Vì vậy | |Sau khi |Thì |Nếu không | |Trước khi |Vì thế |Loại trừ | |Tất cả |Cho nên |Một số | |Những |Nhưng |Rõ ràng | |Phần lớn |Bởi |Với | |Hầu như |Là |Với lại | |Bởi vì |Thay vì |Cho dù | Với việc loại bỏ từ dừng, em xây dựng một module so sánh các từ thu được ở bước tách từ với danh sách từ dừng trong từ điển từ dừng"],[95,"Nếu từ nào xuất hiện trong từ điển từ dừng thì ta loại nó ra khỏi văn bản đầu vào"],[96,"Sau đây là sơ đồ giải thuật của thuật toán loại bỏ từ dừng: [pic] 1.3.6"],[97,"Xử lý các từ đồng nghĩa Theo Cơ sở ngữ học và tiếng Việt Mai Ngọc Chừ (1997), từ đồng nghĩa là những từ tương đồng với nhau về nghĩa, khác nhau về âm thanh và có phân biệt với nhau về một vài sắc thái phong cách"],[98,"Những từ đồng nghĩa với nhau tập hợp thành một nhóm gọi là nhóm đồng nghĩa"],[99,"Ví dụ: cố, gắng, cố gắng được gọi là một nhóm từ đồng nghĩa"],[100,"Từ đồng nghĩa không phải là những từ trùng nhau hoàn toàn về nghĩa, chúng nhất định có dị biệt nào đó bên cạnh sự tương đồng"],[101,"Chính sự dị biệt đó lại là lý do tồn tại và làm nên những giá trị khác nhau giữa các từ trong một nhóm từ đồng nghĩa"],[102,"Những từ đồng nghĩa với nhau không nhất thiết phải tương đương với nhau về mặt số lượng nghĩa, tức là các từ trong một nhóm có thể có một hoặc hai nghĩa, có những từ có thể có tới năm bảy nghĩa"],[103,"Thông thường, các từ đồng nghĩa chỉ ở một nghĩa nào đó"],[104,"Chính vì thế, một từ đa nghĩa có thể tham gia vào nhiều nhóm tương đồng khác nhau"],[105,"Ở nhóm này nó tham gia với nghĩa này, ở nhóm khác nó tham gia với nghĩa khác"],[106,"Ví dụ: Từ coi trong tiếng Việt là một từ đa nghĩa"],[107,"Tùy theo từng nghĩa được nêu lên để tập hợp các từ mà coi có thể tham gia vào các nhóm khác nhau như: Coi Xem : coi phim xem phim Coi Giữ : coi đồ - giữ đồ Với bài toán TTVB thì từ đồng nghĩa có một ý nghĩa quan trọng khi trong các câu có chứa các từ đồng nghĩa với nhau"],[108,"Việc xử lý từ đồng nghĩa sẽ giúp nâng cao hơn độ chính xác khi so sánh độ tương đồng ngữ nghĩa giữa các câu trong văn bản"],[109,"Đối với việc xử lý từ đồng nghĩa, em sử dụng bộ từ điển đồng nghĩa được trích rút từ trang: http://tratu.soha.vn"],[110,"Em tiến hành xây dựng Module thực hiện việc so sánh các từ thu được sau bước loại bỏ từ dừng, ta tiến hành so sánh từng từ với các từ trong từ điển"],[111,"Nếu từ có trong từ điển đồng nghĩa thì ta sẽ tiếp tục so khớp các từ còn lại với nhóm từ đông nghĩa đó nếu có thì chuyển hết các từ đó về một từ chung duy nhất đại diện cho nhóm từ đồng nghĩa đó"],[112,"Cụ thể, em chuyển các từ thành từ đầu tiên tìm thấy có trong từ điển xuất hiện trong nhóm từ đồng nghĩa"],[113,"Ví dụ minh họa, ta có văn bản đầu vào: Ta không cố gắng tìm kiếm lối thoát cho bản thân mình"],[114,"Ta chỉ cố tìm cách sống chung với nó"],[115,"Sau bước loại bỏ từ dừng ta đã thu được danh sách gồm các từ: ta, không, cố_gắng, tìm_kiếm, lối_thoát, cho, bản_thân, mình, ta, chỉ, cố, tìm, cách, sống, chung, với, nó Trong danh sách từ thu được dễ nhận thấy hai từ: cố_gắng, cố là hai từ đồng nghĩa với nhau"],[116,"Khi thực hiện giải thuật thì từ cố sẽ được chuyển thành từ cố_gắng như vậy sau giải thuật xử lý từ đồng nghĩa ta thu được danh sách các từ: ta, không, cố_gắng, tìm_kiếm, lối_thoát, cho, bản_thân, mình, ta, chỉ, cố_gắng, tìm, cách, sống, chung, với, nó Giải thuật cụ thể cho module xử lý từ đồng nghĩa như sau: [pic] 1.3.7"],[117,"Mô hình hóa văn bản Sau khi quá trình xứ lý từ đồng nghĩa, ta tiến hành mô hình hóa văn bản đầu vào thành một dạng cấu trúc phục vụ cho công việc xử lý"],[118,"Mô hình đồ thị chính là mô hình em sử dụng cho việc mô hình hóa văn bản đầu vào"],[119,"Cụ thể, em sẽ tiến hành mô hình hóa văn bản thành một đồ thị trọng số vô hướng"],[120,"Ta mô hình hóa văn bản đầu vào thành một đồ thị trọng số vô hướng, trong đó mỗi node biểu diễn từng câu trong văn bản đầu vào, mỗi cạnh là liên kết giữa các cặp node trong đồ thị tương ứng với các cặp câu trong văn bản đầu vào"],[121,"Các bước tiến hành cụ thể gồm: - Xây dựng đối tượng Graph đại diện cho văn bản đầu vào"],[122,"- Xây dựng đối tượng Node đại diện cho từng câu trong văn bản"],[123,"- Mỗi đối tượng Node khi khởi tạo gồm có các thuộc tính sau: o Chỉ số tương ứng với chỉ số của câu trong văn bản đầu vào (phục vụ cho việc sắp xếp câu khi hiển thị)"],[124,"o Nội dung trước tiền xử lý (Là nội dung của câu trước khi tiền xử lý)"],[125,"o Nội dung đã tiền xử lý ( Là nội dung của câu sau khi tiền xử lý)"],[126,"o Trọng số"],[127,"1.4"],[128,"Giai đoạn xử lý Trong gia đoạn xử lý, chúng ta tiến hành áp dụng các giải thuật nhằm cho điểm các node trong đồ thị tương ứng với các câu trong văn bản đầu vào"],[129,"Từ đó chúng ta có được các câu điểm cao đồng nghĩa với việc nó quan trọng có thể đại diện cho văn bản đầu vào"],[130,"Sự chính xác của toàn bộ ứng dụng phần lớn phụ thuộc vào giai đoạn này"],[131,"Trong đồ án này, em tiến hành thực hiện tính toán trọng số cho các node trong đồ thị bằng cách kết hợp giữa giải thuật PageRank của Google và giải thuật tính toán độ tương đồng giữa các câu"],[132,"1.4.1"],[133,"Giải thuật tính độ tương đồng Đây là giải thuật cho ta độ tương đồng giữa các cặp node trong đồ thị dựa vào tấn số của một từ đối với một câu"],[134,"Các tham số chính của giải thuật gồm: Tần số của từ Term Frequency(TF)"],[135,"Tần số của câu nghịch đảo Inverse Sentence Frequency(ISF)"],[136,"Để tính được độ tương đồng của cặp node bất kỳ trước tiên ta phải tính được giá trị TF*ISF cho mỗi câu"],[137,"Các đại lượng được tính bằng công thức như sau: tfi, j = 1 + log(m) isfi = log[pic] Trong đó, m là số lần xuất hiện của từ thứ i trong câu j"],[138,"tfi,j là term frequency của từ thứ i trong câu thứ j"],[139,"isfi là inverse sentence frequency của từ thứ i"],[140,"N là tổng số các câu trong văn bản đầu vào"],[141,"ni là số câu chứa từ thứ i"],[142,"Từ đó, ta tính trọng số tương ứng của một từ thứ i trong câu thứ j như sau: Wi,j = tfi,j * isfi Trọng số cạnh giữa 2 đỉnh tương ứng độ tương đồng giữa 2 câu Sm và Sn được tính theo công thức cosine như sau: W(sm, sn) = [pic] Với t là số từ của văn bản đầu vào"],[143,"Các bước thực hiện của thuật toán cụ thể như sau: |Đầu vào:Văn bản đã được mô hình hóa sau bước tiền xử lý | |Đầu ra: Độ tương đồng giữa các câu trong văn bản đầu vào | |Bước 1: Trên mỗi câu ta tính số lượng của từng từ trong câu đó | |và số lượng câu trong văn bản chứa từ đó"],[144,"| | | |Bước 2: Tính các đại lượng Term Frequency (TF) và Inverse | |Sentence Frequency (ISF) của mỗi từ trong mỗi câu theo công | |thức: | |TFi,Sj = 1 + log(m)[pic] | |ISFi= [pic] | | | |Bước 3: Tính toán trọng số của một từ đối với một câu theo công | |thức: | |Wi,Sj = TFi,Sj * ISFi | |Bước 4: Tính toán độ tương đồng giữa các cặp câu trong văn bản | |theo công thức: | |Similarity(Sj, Sk) = [pic] | | | |Trong đó, | |getDotProduct: là tích vô hướng của các giá trị trọng số trong | |câu thứ j và câu thứ k"],[145,"| |getRootSumSj: Là tổng bình phương của giá trị trọng số của câu | |thứ j"],[146,"| |getRootSumSk: Là tổng bình phương của giá trị trọng số của câu | |thứ k"],[147,"| |Chúng được tính theo công thức: | |getDotProduct = [pic] | |getRootSumSj = [pic] | |getRootSumSk= [pic] | | | [pic] 1.4.2"],[148,"Giải thuật PageRank PageRank là giải thuật nổi tiếng được sử dụng bởi Google trong việc xếp hạng các trang web dựa vào link liên kết bao gồm: link liên kết với trang web (incoming link) và link trang web liên kết tới (outcoming link)"],[149,"Trang web nào càng có nhiều liên kết đồng thời liên kết với các trang có xếp hạng càng cao thì hạng của nó càng cao"],[150,"Nhận thấy được sự tương đồng về mặt cấu trúc giữa mô hình liên kết giữa các trang web với mô hình đồ thị em sử dụng, các trang web tương ứng với các node trong đồ thị, các liên kết tương ứng với các cạnh liên kết giữa các node"],[151,"Chính bởi vậy, em sử dụng giải thuật PageRank cho bước tính điểm cho các node trong đồ thị tương ứng với số điểm của các câu trong văn bản đầu vào"],[152,"Sau đây, em xin trình bày cụ thể cách thức áp dụng giải thuật PageRank cho hệ thống của em: 1.4.2.1"],[153,"Giới thiệu về giải thuật PageRank PageRank là giải thuật gán trọng số cho các trang Web được đánh chỉ số bằng một kỹ thuật tìm kiếm"],[154,"Hệ thống PageRank được sử dụng trong kỹ thuật tìm kiếm nổi tiếng Google giúp cho việc xác định sự liên quan hay tầm quan trọng của một trang web"],[155,"PageRank được phát triển bởi người sáng lập Google Larry Page và Sergey Brin khi họ đang học tâp tại đại học Stanford năm 1998"],[156,"Giá trị PageRank hình thành từ thuật toán học dựa trên Webgraph: các trang World Wide Web được coi như các đỉnh và các đường link là các cạnh"],[157,"Giá trị xếp hạng cho thấy tầm quan trọng của từng trang cụ thể"],[158,"Mỗi đường link tới trang web sẽ được tính như một sự hỗ trợ làm tăng thêm giá trị PageRank"],[159,"Giá trị PageRank của trang được định nghĩa đệ quy và phụ thuộc vào số lượng và giá trị của các trang mà có link dẫn đến trang đó"],[160,"Một trang web có chứa nhiều link liên kết từ các trang web có giá trị PageRank cao thì giá trị PageRank của trang đó cũng sẽ cao"],[161,"[pic] Chúng ta có thể thấy trang C có một PageRank cáo hơn so với trang E, mặc dù có ít link đến trang C, một link duy nhất dẫn tới trang C từ một trnag quan trọng và chính vì thế mà C có gí trị cao"],[162,"Thuật toán PageRank là phân bố xác suất được sử dụng để thể hiện khả năng khi một người click chuột ngẫu nhiên và đường link và sẽ tới được trang web cụ thể"],[163,"PageRank có thể được tính toán cho các tập văn bản với tài liệu có độ dài bất kỳ"],[164,"Khi bắt đầu tính toán thì sự phân bố đó được chia đều cho tất cả những văn bản trong tập văn bản"],[165,"Các tính toán PageRank cần lặp đi lặp lại qua các văn bản trong tập văn bản để có thể đạt được giá trị thực tế một cách thiết thực hơn"],[166,"Xác suất có giá trị từ 0 tới 1"],[167,"Với giá trị 0.5, thường được hiểu là 50% cơ hội của một việc gì đó có thể xảy ra"],[168,"Trong PageRank, 0.5 có nghĩa là 50% cơ hội một người nào đó click vào một link ngẫu nhiên để được chuyển đến văn bản đó (giá trị PageRank = 0.5)"],[169,"1.4.2.2"],[170,"Áp dụng giải thuật PageRank cho bài toán TTVB Giải thuật này, được thực hiện nhằm tính toán trọng số cho từng node trong đồ thị để có thể chọn ra các câu có trọng số cao là những câu quan trọng có thể đại diện cho văn bản để đưa vào giai đoạn hiển thị"],[171,"Công thức được sử dụng cho giải thuật này là : PRW(Vi) = (1 - d) + d * [pic] Trong đó, PRW(Vi): là xếp hạng của đỉnh Vi"],[172,"In(Vi): là tất cả các đỉnh đi tới đỉnh Vi"],[173,"Out(Vi): là tập các đỉnh mà đỉnh Vi đi tới"],[174,"d(DAMPING_FACTOR: là một hệ số được tùy chọn trong khoảng (0,1) - Là một hệ số trong giải thuật PageRank"],[175,"Chính là xác suất một người truy cập vào một trang web và tiếp tục click trong bất cứ bước nào"],[176,"Có nhiều nghiên cứu đã thử các giá trị yếu tố damping, giá trị ước lượng bằng 0.85 là người dùng sẽ tiếp tục lướt web"],[177,"Do ta tiến hành mô hình hóa đồ thị thành dạng đồ thị trọng số vô hướng nên ta có giả thuyết là tất cả các node trong đồ thị đều được nối với các node còn lại tương đương bán bậc ra của mỗi node bằng bán bậc vào của đỉnh đó và bằng số node 1"],[178,"Như vậy, ta có thể thay thế công thức trên thành như sau: PRW(Vi) = (1 - d) + d * [pic] Ngoài ra, còn có một số nguyên tắc sau được áp dụng cho đồ thị chúng ta xây dựng: Không quan tâm tới thứ tự node mà chỉ quan tâm tới nội dung của node"],[179,"Độ tương đồng của một node trong đồ thị với chính nó là bằng 0"],[180,"o i< N: Sim(Si,Si) = 0 Sau khi giải thuật PageRank được thực hiện xong, mỗi node trong đồ thị đã có một trọng số tỷ lệ thuận với độ quan trọng cuả nó trong văn bản đầu vào"],[181,"Các bước tiến hành của giải thuật cụ thể như sau: |Đầu vào: Văn bản đã được mô hình hóa sau giai đoạn tiền xử lý | |Đầu ra: Các node với một trọng số được gán theo mức độ quan trọng.| | | |Bước 1: Khởi tạo đồ thị từ văn bản đầu vào"],[182,"Khởi tạo trọng số cho | |tất cả các node bằng 1 | |Bước 2 : Thực hiện giải thuật PageRank để tính toán trọng số cho | |các node theo công thức: | |PRW(Vi) = (1 - d) + d * [pic] | |Giải thuật được mô tả dưới dạng giả ngôn ngữ: | |While(!Vòng lặp hội tụ) | |For i = [1,Số câu] | |Sum = 0.0 // Tổng toàn cục | |For j = [1, Số câu] | |If( i # j) | |Wij = getSimilarity(Si,Sj) | |PRVj = getRank(j) | |denSum = 0.0 //Tổng cục bộ | |for k =[1, Số câu] | |if(k # j) | |Wjk = getSimilarity(Sj,Sk) | |demSum = demSum + Wjk | |end for | |Sum = Sum + [pic] | |end for | |denSum = 0.0 | |rank = (1 DAMPING_FACTOR) + DAMPING_FACTOR * Sum | |tmpranks.save(i,rank) // Cập nhật giá trị trọng số cho node | |Sum = 0.0 | |end for | |end while | [pic] 1.4.3"],[183,"Phương pháp đồ thị cải tiến Trong quá trình tìm hiểu, xây dựng hệ thống em thấy có thể thêm một số yếu tố so với hệ thống đang xây dựng để có thể làm tăng tính chính xác cho văn bản tóm tắt"],[184,"Nhằm mục đích so sánh với phương pháp đồ thị xây dựng theo [6] để chứng thực hiệu quả của sự cải tiến đó như thế nào"],[185,"Em đã tiến hành thực hiện cải tiến hệ thống ở bước tính toán độ tương đồng bằng cách xét thêm vị trí của từ trong văn bản đầu vào"],[186,"Từ đó, em có một đầu ra mới để so sánh với hệ thống đã xây dựng trước đó"],[187,"Sau đây, em xin trình bày chi tiết phần cải tiến hệ thống mà em đê xuất: 1.4.3.1.Một số nhận định của bản thân Bằng thực nghiệm thu thập các bài báo mạng để phục vụ cho việc kiểm thử, đánh giá hệ thống của mình em rút ra một số nhận định sau"],[188,"Nó là cơ sở cho việc em đề xuất thêm cải tiến cho hệ thống sử dụng phương pháp đồ thị theo giải thuật PageRank"],[189,"Cụ thể là: Các bài báo mạng thường có cấu trúc trình bày gồm 2 phần: o Tiêu đề o Nội dung bài báo Các từ xuất hiện trong tiêu đề thường là các từ quan trọng trong văn bản bởi tiêu đề thường phản ánh nội dung của văn bản, tuy không thể chỉ dùng chúng để quyết định độ quan trọng của các câu trong văn bản"],[190,"Nhưng ta có thể áp dụng cho giải thuật bằng cách tăng trọng số của các từ đó theo một hệ số nào đó"],[191,"Điều này, có nghĩa những câu gần với tiêu đề sẽ có điểm số cao hơn đồng nghĩa với việc chúng có khả năng được chọn cho văn bản tóm tắt cao hơn"],[192,"1.4.3.2"],[193,"Đề xuất phương án cải tiến Từ những nhận định trên, em đề xuất một cái tiến nhỏ trong việc tính toán trọng số các từ trong phương pháp đồ thị sử dụng giải thuật PageRank.Cụ thể, em sẽ sử dụng thêm một hệ số cho bài toán TTVB theo phương pháp đồ thị đó là: htd : Hệ số nhân cho các từ xuất hiện trong tiêu đề của văn bản"],[194,"Để đạt được hiệu quả cao khi sử dụng các hệ số này, đòi hỏi phải trải qua quá trình thực nghiệm với các kết quả của giải thuật hoặc áp dụng các thuật toán học máy để quyết định giá trị phù hợp cho chúng"],[195,"Do thời gian thực nghiệm chưa được nhiều nên em tạm thời lấy giá trị cho hệ số đưa ra sau một số lần so sánh kết quả kiểm thử với các hệ số khác nhau được tiến hành kiểm thử trên 55 văn bản mẫu"],[196,"Cụ thể , giá trị em chọn cho hệ số nhân cho các từ xuất hiện trong tiêu đề văn bản là 4: htd = 4"],[197,"Khi thực hiện tính toán tần số của từ đối với mỗi câu ta sẽ xét thêm vị trí của từ nếu chúng nằm trong câu tiêu đề thì ta sẽ tăng nó lên một hệ số là 4"],[198,"Việc nhận định câu tiêu đề được chúng em quy ước khi thu thập thủ công các bài báo mạng để phục vụ việc kiểm thử"],[199,"1.4.4"],[200,"Sinh câu tóm tắt Kết quả của giải thuật PageRank hay giải thuật cải tiến PageRank đều đưa ra danh sách các node trong đồ thị đã được gán một trọng số mới tỷ lệ thuận với độ quan trọng của node trong đồ thị tương ứng với câu trong văn bản đầu vào Ở bước này ta cho danh sách các node thu được ở trên qua một module thực hiện các công việc sau: Loại bỏ các câu đầu tiên Câu tiêu đề (node có chỉ số bằng 0) ra khỏi danh sách node thu được"],[201,"Loại bỏ một câu trong cặp câu có độ tương đồng cao (là các câu có khả năng trùng lặp nội dung)"],[202,"Ta thực hiện loại bỏ câu có độ dài ngắn hơn trong cặp câu cần loại"],[203,"Lấy danh sách các node theo tỷ lệ rút gọn"],[204,"Sắp xếp chỉ số các node được chọn cho văn bản tóm tắt theo tứ tăng dần"],[205,"Thực hiện việc loại bỏ các nội dung không cần thiết trong các câu"],[206,"Các nội dung loại bỏ này gồm: o Nội dung trong dấu ngoặc đơn ()"],[207,"o Nội dung ở giữa 2 dấu gạch ngang -"],[208,"Lấy ra các node sau khi đã sắp xếp tăng dần theo chỉ số được gán ban đầu"],[209,"Đối với việc lựa chọn ngưỡng cho việc loại bỏ bớt câu có nội dung trùng nhau trong văn bản cần có thời gian trải qua quá trình thực nghiệm kiểm thử hoặc áp dụng các phương pháp hoc máy mới có thể cho hiệu quả cao nhất"],[210,"Do thời gian có hạn nên em chưa thể đưa ra được một ngưỡng chính xác tổng quát cho bài toán tóm tắt văn bản"],[211,"Tuy nhiên, trong đồ án này em vẫn đưa ra một ngưỡng cho việc loại bỏ câu theo ý kiến chủ quan dựa trên quá trình thử nghiệm thủ công nhằm có thể minh họa một phần nào đó cho cách thức áp dụng module này vào hệ thống của em"],[212,"Cụ thể, ngưỡng loại bỏ câu trùng nhau được đưa ra là 0.8"],[213,"1.5"],[214,"Giai đoạn hiển thị Giai đoạn hiển thị đơn giản là tiếp nhận các node được chọn ở giai đoạn xử lý sau đó lấy ra nội dung ban đầu các node đó và hiển thị chúng ra màn hình"],[215,"1.6"],[216,"Xây dựng chương trình tóm tắt trích rút đơn văn bản Chương trình tóm tắt đơn văn bản được em xây dựng trên môi trường .NET bằng ngôn ngữ C#"],[217,"Đây là một ngôn ngữ có khả năng xử lý tốt đối với dữ liệu phẳng, đồng thời nó có hỗ trợ các đối tượng cấu trúc dữ liệu rất hữu ích cho bài toán tóm tắt văn bản"],[218,"Em xây dựng chương trình tóm tắt đơn văn bản gồm 3 projects: Preprocessor: Tương ứng với giai đoạn tiền xử lý"],[219,"Processor: Tương ứng với giai đoạn xử lý UserInterface: Tương ứng với giai đoạn hiển thị [pic] CHƯƠNG 2: CÀI ĐẶT ỨNG DỤNG 2.1"],[220,"Một số giao diện chương trình Trong phần này, em xin đưa ra các giao diện của hệ thống tóm tắt trích rút đơn văn bản theo phương pháp đồ thị mà đồ án xây dựng"],[221,"Nhằm mục đích, mô tả trực quan hơn hệ thống"],[222,"Hệ thống thì gồm có 3 giao diện: [pic] Giao diện chính cho phép thực hiện chọn văn bản đầu vào dạng .txt, chọn tỷ lệ trích rút theo số câu và sau đó yêu cầu hệ thống thực hiện quá trình tóm tắt để cho ra kết quả"],[223,"Kết quả đầu ra gồm hai văn bản tóm tắt tương ứng với hai phương pháp đã được trình bày ở phần trên"],[224,"[pic] Giao diện này hiển thị chi tiết trọng số của các node trong đồ thị tương ứng với trọng số của các câu trong văn bản đầu vào"],[225,"[pic] Giao diện này thực hiện việc đánh giá kết quả của văn bản tóm tắt với văn bản mẫu có sẵn"],[226,"2.2"],[227,"Kiểm thử, đánh giá 2.2.1"],[228,"Bộ dữ liệu mẫu Bộ dữ liệu mẫu sử dụng cho quá trình kiểm thử trong đồ án tốt nghiệp này là các văn bản tóm tắt thủ công được nhóm làm về tóm tắt văn bản chúng em thực hiện dưới sự hướng dẫn giúp đỡ của PGS.TS.Lê Thanh Hương"],[229,"Các tài liệu phục vụ cho việc tóm tắt thủ công là các bài báo về các mảng khác nhau của xã hội như: kinh tế, chính trị, văn hóa, được thu thập từ các trang Web lớn như: http://dantri.vn , http://vnexpress.vn ,.."],[230,"Các bài báo sau khi thu thập về chúng em sẽ tiến hành xử lý thủ công để loại bỏ những lỗi ngữ pháp, lỗi trình bày, lỗi chính tả, cách thức trình bày bài báo,"],[231,"để có thể có được dữ liệu đầu vào phù hợp với hệ thống của chúng em"],[232,"Chúng em tiến hành chuẩn hóa văn bản thu thập như sau: Câu tiêu đề được cho thành câu đầu tiên trong văn bản đầu vào"],[233,"Cắt bỏ các ảnh và các câu heading đi kèm theo các ảnh có trong bài báo"],[234,"Độ dài văn bản tóm tắt mẫu khoảng 120 từ"],[235,"Số lượng bài báo chúng em thu thập đồng thời tóm tắt thủ công để phục vụ cho kiểm thử là: 55 bài báo được lưu dưới dạng file .txt"],[236,"Độ dài của 55 bài báo nằm trong khoảng : 300 1000 từ"],[237,"2.2.2"],[238,"phương pháp sử dụng cho việc đánh giá Em quyết định chọn phương pháp đánh giá BLEU cho việc đánh giá hệ thống tóm tắt tự động mà đồ án xây dựng"],[239,"Bởi, nó là phương pháp đánh giá phổ biến được sử dụng nhiều cho đánh giá tóm tắt đơn văn bản"],[240,"2.2.2.1.Giới thiệu phương pháp đánh giá BLEU (Bilingual Evaluation Understudy) BLEU là một giải thuật sử dụng cho việc đánh giá chất lượng của văn bản được sinh ra bởi một hệ thống dịch máy đối với một văn bản mẫu đối sánh"],[241,"Chất lượng ở đây là độ trùng khớp giữa văn bản sinh ra bởi hệ thống dịch máy với văn bản do con người tạo ra"],[242,"Nhiệm vụ chính của BLEU là tính toán độ đo BLEU của văn bản đánh giá dựa trên độ chính xác n-grams (số tiếng sử dụng cho việc so khớp) gồm: 1- gram, 2-gram, 3-gram, 4-gram"],[243,"Các khái niệm của phương pháp BLEU: Độ chính xác n-gram : Là nền tảng của phương pháp BLEU"],[244,"Nó được tính bằng cách đếm số n-grams của văn bản đánh giá có trong văn bản mẫu rồi chia cho số n-grams trong văn bản đánh giá"],[245,"Để tính toán độ đo BLEU, đầu tiên chúng ta tính toán trung bình hình học của các độ chính xác n-grams là pn, sử dụng n-grams có độ dài N và một trọng số trung bình wn"],[246,"Tiếp theo, cho c là độ dài của văn bản đánh giá và r là độ dài văn bản mẫu"],[247,"Ta thực hiện tính toán độ rút gọn quy ước Brevity Penalty ( BP) theo công thức sau: [pic] Sau đó tính toán độ đo BLEU theo công thức sau: [pic] Trong đó, Pn: Là trung bình hình học của các độ chính xác n-grams"],[248,"N: là độ dài của n-grams (Có thể là 1, 2 ,3 ,4)"],[249,"Wn: là trọng số trung bình nó được lấy giá trị là: 1/ N"],[250,"2.2.2.2.Đánh giá phương pháp BLEU Độ đo BLEU nằm trong khoảng (0,1)"],[251,"Giá trị này biểu hiện cho sự tương đồng giữa văn bản đánh giá và văn bản mẫu, giá trị càng gần tới một thì chứng tỏ các văn bản càng tương tự nhau"],[252,"Một số văn bản đánh giá đạt giá trị là 1 tức là nó đồng nhất với văn bản mẫu"],[253,"Thực tế, thì thậm chí một người dịch cũng sẽ không thể đạt được số điểm là 1"],[254,"Theo Denkowski và Lavie trong AMTA Evaluation Tutorial [1] nếu độ đo BLEU trên 0.3 chứng tỏ rằng văn bản đánh giá có thể hiểu được"],[255,"Nếu độ đo BLEU là trên 0.5 thì văn bản đánh giá là tốt và đạt được sự trôi chảy"],[256,"2.2.3"],[257,"Các kết quả kiểm thử Trong phần này, em thực hiện kiểm thử với 55 văn bản thu thập từ các trang web và tạo văn bản mẫu như đã giới thiệu ở trên"],[258,"Kiểm thử sử dụng độ đo BLEU với n-grams là 4"],[259,"Để hiểu rõ hơn cho hệ thống của mình em xin đưa ra một ví dụ minh họa đầu vào, đầu ra của hệ thống tóm tắt đơn văn bản theo phương pháp đồ thị: |Văn bản đầu vào: | | | |Nhiều dự án biệt thự Hà Nội cả quý I không ai hỏi mua"],[260,"| |Nếu biệt thự/nhà liền kề tại Hà Nội nhiều dự án không có khách hỏi | |mua thì tại TP HCM có xu hướng khách tìm đến đất nền nhiều hơn"],[261,"| |Thị trường biệt thự và nhà liền kề trong quý I/2013, theo khảo sát | |của Savills, nguồn cung có 3 dự án (Khu đô thị Dream Tower, Tây Nam | |Hồ Linh Đàm và Đặng Xá II), cung cấp khoảng 245 căn nhà cho thị | |trường"],[262,"| |Nhìn chung cả quý, nguồn cung phân khúc căn hộ này trên thị trường | |Hà Nội gồm 42.000 căn từ 125 dự án, trong đó 102 dự án hợp đồng mua | |bán (HĐMB) cung cấp khoảng 29.800 căn nhà gồm 16.900 nhà liền kề và | |12.900 biệt thự"],[263,"Nguồn cung còn lại đến từ các dự án dạng hợp đồng | |góp vốn (HĐGV)"],[264,"| |Nguồn cung khá dồi dào trên, thanh khoản của thị trường quý vừa qua | |vẫn thấp"],[265,"Giá chào thứ cấp bình quân của toàn thị trường giảm so với| |quý trước ở mức -13% đối với biệt thự và -9% đối với liền kề"],[266,"Nhiều | |dự án tại vùng 2, đặc biệt là Mê Linh và Hoài Đức, trong quý này | |không có khách hỏi mua"],[267,"| |Giá chào bình quân thứ cấp tại vùng 1 từ 41,7 triệu VNĐ đến 158 | |triệu đồng/m2, trong khi tại vùng 2 dao động từ 9,4 - 54 triệu | |đồng/m2"],[268,"Các quận Cầu Giấy, Tây Hồ và Từ Liêm có giá chào bình quân | |thứ cấp cao nhất với mức hơn 108 triệu đồng/m2 đối với biệt thự và | |nhà liền kề"],[269,"Hầu hết các dự án thuộc vùng 2 đều có giá chào dưới 20 | |triệu đồng/m2"],[270,"| |Về nguồn cầu, theo Savills, nhu cầu đối với thị trường biệt thự/nhà | |liền kề hiện đang thấp hơn so với nguồn cung sẵn có do người mua vẫn| |đang chờ 1 mức giá thấp hơn nữa"],[271,"Mức trần lãi suất huy động đã được | |hạ xuống chỉ còn 7,5% vào ngày 26/3/2013, điều này có thể sẽ làm lãi| |suất cho vay giảm hơn nữa, tạo thêm thuận lợi cho thị trường nhà ở"],[272,"| |Trong khi đó, nguồn cung tương lai của thị trường biệt thự/nhà liền | |kề tại Hà Nội sẽ đến từ 76 dự án nằm rải rác tại 14 quận với tổng | |diện tích 10.200 ha đất"],[273,"Số lượng dự án tương lai là không đổi so | |với quý trước, và có khả năng vẫn tiếp tục duy trì ở mức này do UBND| |TP Hà Nội đang dự định ngừng cấp phép cho các dự án nhà ở thương mại| |nằm ở Hà Nội từ nay cho đến cuối năm 2014- bà Đỗ Thu Hằng, Trưởng | |Bộ phận Nghiên cứu và Tư vấn của Savills Hà Nội"],[274,"| |Ông Trần Như Trung cho biết, cũng trong tình trạng ế ẩm như Hà Nội, | |dù tại thị trường TP HCM trong quý I không có dự án nào mới gia nhập| |thị trường"],[275,"Có 11 dự án đang hoạt động trong thị trường sơ cấp cung | |cấp hơn 290 căn, trong đó biệt thự chiếm 52% thị phần"],[276,"| |Vì vậy, toàn thị trường biệt thự/nhà liền kề TP HCM cung cấp hơn | |3.200 căn, tăng nhẹ 3% so với cùng kỳ năm trước, trong đó thị trường| |thứ cấp chiếm khoảng 91% thị phần"],[277,"Trong thị trường sơ cấp có 12 dự | |án đất nền đang hoạt động cung cấp tổng cộng 577 lô, giảm -7% so với| |quý trước"],[278,"| |Tình hình hoạt động của phân khúc biệt thự/nhà liền kề trong thị | |trường sơ cấp tại TP HCM cũng không tốt trong quý I/2013"],[279,"Tỉ lệ hấp | |thụ trung bình là 5%, giảm -8 điểm % so với quý trước"],[280,"Tỉ lệ hấp thụ| |trung bình của phân khúc đất nền cũng giảm mạnh, giảm -11 điểm phần | |trăm xuống 9% sau khi đạt mức tỉ lệ hấp thụ hai con số trong hai quý| |vừa qua"],[281,"| |Giá bán trung bình của biệt thự/nhà liền kề trên thị trường thứ cấp | |ở mức ổn định, tuy nhiên, giá đã giảm mạnh -12% so với cùng kỳ năm | |trước"],[282,"Giá bán trung bình đất nền trên thị trường thứ cấp không đổi | |so với quý trước"],[283,"| |Trong khi đó, về nguồn cầu, các chủ đầu tư với cam kết trong phát | |triển dự án và tiến độ xây dựng cũng như có chiến lược tiếp thị tốt | |hoặc giảm giá tiếp tục thu hút sự chú ý của người mua nhà"],[284,"Tuy | |nhiên, so với biệt thự, nhà liền kề đã hoàn thiện, đất nền vẫn hấp | |dẫn hơn với đối tượng người mua trung lưu, nhờ vào những lợi thế của| |chi phí xây dựng thấp hơn"],[285,"| |Hơn nữa, theo Savills, đất nền cũng cung cấp sự đa dạng hoá danh mục| |đầu tư cho các nhà đầu tư trung và dài hạn"],[286,"Đặc biệt, các dự án tọa | |lạc trong những khu vực dân cư đông đúc và được bao quanh bởi các cơ| |sở và công trình tiện ích hoặc tiếp giáp với các hệ thống cơ sở hạ | |tầng lớn đang phát triển phù hợp cho cả hai mục đích sống và thương | |mại"],[287,"| |Trong tương lai, theo Savills, tại thị trường TP HCM, phân khúc biệt| |thự/nhà liền kề này sẽ có khoảng 57.200 căn từ hơn 140 dự án trải | |rộng trên 9.190 ha dự kiến sẽ gia nhập thị trường trong vòng 8 năm | |tới"],[288,"Riêng năm 2013, có hơn 1.200 căn từ 11 dự án dự kiến sẽ gia | |nhập thị trường trong 3 quý tới"],[289,"| |Văn bản mẫu kiểm thử: | | | |Nếu biệt thự/nhà liền kề tại Hà Nội nhiều dự án không có khách hỏi | |mua thì tại TP HCM có xu hướng khách tìm đến đất nền nhiều hơn"],[290,"| |Thị trường biệt thự và nhà liền kề trong quý I/2013, nguồn cung có 3| |dự án , cung cấp khoảng 245 căn nhà cho thị trường"],[291,"| |Về nguồn cầu, nhu cầu đối với thị trường biệt thự/nhà liền kề hiện | |đang thấp hơn so với nguồn cung sẵn có do người mua vẫn đang chờ 1 | |mức giá thấp hơn nữa"],[292,"| |Tuy nhiên, so với biệt thự, nhà liền kề đã hoàn thiện, đất nền vẫn | |hấp dẫn hơn với đối tượng người mua trung lưu, nhờ vào những lợi thế| |của chi phí xây dựng thấp hơn"],[293,"| | | |Văn bản 1: Văn bản kết quả của PP đồ thị sử dụng PageRank: | | | |Nếu biệt thự/nhà liền kề tại Hà Nội nhiều dự án không có khách hỏi | |mua thì tại TP HCM có xu hướng khách tìm đến đất nền nhiều hơn"],[294,"| |Về nguồn cầu, theo Savills, nhu cầu đối với thị trường biệt thự/nhà | |liền kề hiện đang thấp hơn so với nguồn cung sẵn có do người mua vẫn| |đang chờ 1 mức giá thấp hơn nữa"],[295,"| |Trong tương lai, theo Savills, tại thị trường TP HCM, phân khúc biệt| |thự/nhà liền kề này sẽ có khoảng 57.200 căn từ hơn 140 dự án trải | |rộng trên 9.190 ha dự kiến sẽ gia nhập thị trường trong vòng 8 năm | |tới"],[296,"| | | |Văn bản 2: Văn bản kết quả của PP đồ thị sử dụng PageRank cải tiến: | | | |Nếu biệt thự/nhà liền kề tại Hà Nội nhiều dự án không có khách hỏi | |mua thì tại TP HCM có xu hướng khách tìm đến đất nền nhiều hơn"],[297,"| |Thị trường biệt thự và nhà liền kề trong quý I/2013, theo khảo sát | |của Savills, nguồn cung có 3 dự án, cung cấp khoảng 245 căn nhà cho | |thị trường"],[298,"| |Nhìn chung cả quý, nguồn cung phân khúc căn hộ này trên thị trường | |Hà Nội gồm 42.000 căn từ 125 dự án, trong đó 102 dự án hợp đồng mua | |bán cung cấp khoảng 29.800 căn nhà gồm 16.900 nhà liền kề và 12.900 | |biệt thự"],[299,"| |Kết quả kiểm thử bằng độ đo BLEU: | |Văn bản 1: 0.566497 | |Văn bản 2: 0.58661 | Kết quả trung bình kiểm thử trên 55 bài báo theo độ đo BLEU như sau: | |Phương pháp đồ thị |Phương pháp đồ thị cải tiến | | | | | |Kết quả |0.515435 |0.542422 | 2.2.4"],[300,"Nhận xét, đánh giá Về mặt chất lượng văn bản tóm tắt: Theo kết quả đánh giá khi sử dụng độ đo BLEU ta thấy rằng những văn bản đầu ra của hệ thống đã có sự đồng nhất khá lớn đối với văn bản tóm tắt mẫu"],[301,"Bằng trực quan, khi trực tiếp quan sát các văn bản đầu ra của hệ thống thì thực tế đối với mục đích trôi chảy thì các văn bản đầu ra của hệ thống còn có nhiều hạn chế bởi cách thức tóm tắt là trích rút câu nên các câu được trích rút còn rời rạc chưa có sự liên kết chặt chẽ về mặt ngữ nghĩa, nhưng với mục đích tóm gọn nội dung thì văn bản tóm tắt đã đáp ứng khá tốt"],[302,"Về mặt thời gian Hệ thống tóm tắt có thời gian chạy chậm, do một số thuật toán chưa được tối ưu"],[303,"Thời gian chạy của hệ thống tỷ lệ thuận với độ dài của văn bản đầu vào"],[304,"So sánh hai phương pháp mà hệ thống xây dựng Dựa trên kết quả kiểm thử của độ đo BLEU, ta thấy rằng phương pháp cải tiến có xét tới vị trí từ thuộc câu tiêu đề có số điểm cao hơn chứng tỏ rằng sự cải tiến đã có hiệu quả góp phần làm cho kết quả đầu ra chính xác hơn so với phương pháp đồ thị được xây dựng ban đầu"],[305,"Khả năng ứng dụng của hệ thống Hệ thống có khả năng thực hiện tóm tắt hiệu quả đối với các văn bản ngắn và trung bình như các bài báo, tin tức trên Internet"],[306,"Hệ thống có thể được tích hợp trong các công cụ thu thập thông tin dạng văn bản để có thể đưa ra được nhiều thông tin chính xác tới người dùng"],[307,"KẾT LUẬN VÀ HƯỚNG PHÁT TRIỂN Đồ án là kết quả của quá trình tìm hiểu, phân tích trong việc giải quyết bài toán tóm tắt trích rút đơn văn bản"],[308,"Trong quá trình thực hiện, em đã có cơ hội tìm hiể về một phương pháp mới trong việc giải quyết bài toán tóm tắt đơn văn bản đó là phương pháp đồ thị đồng thời áp dụng nó vào việc xây dựng hệ thống tóm tắt đơn văn bản"],[309,"Sản phẩm của đồ án là một hệ thống tóm tắt trích rút đơn văn bản có thể tạo ra các văn bản tóm tắt từ các văn bản đầu vào"],[310,"Điều này giúp ích rất nhiều cho con người trong việc tìm kiếm thông tin, giúp họ tiếp cận với thông tin một cách nhanh chóng và thuận tiện hơn"],[311,"Sau đây em xin đánh những việc đã làm được và chưa làm được trong phạm vi đồ án này: Công việc làm được: Tìm hiểu phương pháp đồ thị, giải thuật PageRank áp dụng cho bài toán tóm tắt đơn văn bản"],[312,"Tìm hiểu các kiển thức chung về tiếng Việt áp dụng vào hệ thống gồm: tách câu, tách từ,"],[313,"Áp dụng phương pháp đồ thị, giải thuật tính độ tương đồng, giải thuật PageRank trong việc xây dựng hệ thống tóm tắt trích rút đơn văn bản"],[314,"Đề xuất cải tiến giúp nâng cao hiệu quả của phương pháp tóm tắt nguyên bản ban đầu"],[315,"Công việc chưa làm được: Không sử dụng đồng tham chiếu cho phần tiền xử lý khi xây dựng hệ thống tóm tắt"],[316,"Giải thuật tách từ của hệ thống chưa được cải tiến"],[317,"Chưa giải quyết được tính dễ đọc của bản tóm tắt"],[318,"Bộ từ điển còn ít từ vựng"],[319,"Hệ thống chưa được tối ưu hóa nên thời gian chạy còn chậm"],[320,"Chưa đối sánh được hiệu quả của phương pháp áp dụng với các phương pháp truyền thống đã có trước đó đối với bài toán tóm tắt đơn văn bản"],[321,"Trong quá trình thực hiện đồ án, em đã vận dụng hết khả năng của mình để có thể tạo ra một kết quả tốt nhất"],[322,"Tuy nhiên, do thời gian có hạn cùng với khả năng, kiến thức bản thân còn hạn chế nên hệ thống đồ án xây dựng còn nhiều điểm thiếu sót"],[323,"Trong tương lai em sẽ tiến hành hoàn thiện các điểm thiếu sót đồng thời phát triển thêm giúp nâng cao được hiệu quả của hệ thống tóm tắt trích rút đơn văn bản mà em xây dựng trong đồ án này"],[324,"Các công việc nhằm khắc phục hạn chế và hướng phát triển cụ thể như sau: Hướng phát triển: Áp dụng đồng tham chiếu giúp tăng hiệu quả hơn cho kết quả đầu ra"],[325,"Xây dựng bộ từ điển thêm phong phú hơn"],[326,"Tối ưu hóa hệ thống do thời gian chạy của hệ thống còn chậm"],[327,"Cải tiến giải thuật cho bước tách từ"],[328,"Thực hiện cài đặt thêm các thuật toán khác để có thể đối sánh tốt hơn"],[329,"Nâng hệ thống lên thành hệ thống tóm tắt tóm lược để có được đầu ra tốt hơn"],[330,"TÀI LIỆU THAM KHẢO 1"],[331,"Denkowski, M.Lavie"],[332,"(2010)"],[333,"Choosing the Right Evaluation for Machine Translation: an Examination of Annotator and Automatic Metric Performance on Human Judgment Tasks"],[334,"In Proceedings of the Association for Machine Translation in the Americas AMTA"],[335,"2"],[336,"Lin, Chin-Yew"],[337,"(2004)"],[338,"ROUGE: A Package for Automatic Evaluation of Summaries"],[339,"In Proceedings of NTCIR Workshop 2004"],[340,"Tokyo"],[341,"3"],[342,"L.Page, S.Brin (1998)"],[343,"The anatomy of the large-scale hypertextual Web search engine"],[344,"Computer Networks and ISDN Systems, 30(1 - 7)"],[345,"4"],[346,"Papineni, K.Roukos, S.Ward, T.Zhu (2002)"],[347,"BLEU: a Method for Automatic Evaluation of Machine Translation"],[348,"In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pp.311-318"],[349,"5"],[350,"Qazvinian, V.Hasanabadi, Halavati (2008)"],[351,"Summarising text with a genetic algorithm-based sentence extraction"],[352,"Knowledge Management Studies, Vol.2, No.4, pp.426 - 444"],[353,"6"],[354,"M.Rada (2004)"],[355,"Graph-based ranking algorithms for sentence extraction"],[356,"applied to text summarization, pp.170-173"],[357,"7"],[358,"Vũ Hải Tùng-lớp CNPM-K45"],[359,"(2005)"],[360,"Thesis"],[361,"Xây dựng hệ thống tóm tắt đơn văn bản Summarizer"],[362,"Trường ĐH Bách Khoa Hà Nội"],[363,"8"],[364,"Dusek, Ondrej lingutil"],[365,"from https://code.google.com/p/lingutil/"],[366,"last visit May 2013"],[367,"9"],[368,"Lưu Tuấn Anh, Yamamoto Kazuhide"],[369,"Natural language processing"],[370,"from http://viet.jnlp.org/dongdu"],[371,"last visit May 2013"],[372,"10"],[373,"Nguyễn Minh Thành"],[374,"Text Summarization"],[375,"from https://sites.google.com/site/trangmonhocitc/text-summarization, last visit May, 2013"],[376,"----------------------- 2 3 1 4 7 5 6"]],"downloaded":true,"m":[-1,-1],"n":"70.txt","o":"http://202.191.57.85:8000/InternetData/Data/LVTN/70.doc\r"},{"saved_path":"temp/48.txt","r":0.1685274839401245,"s":[[53,15,0.6274510025978088,16,0,11,0,15,"Phân loại tóm tắt văn bản Có nhiều cách phân loại tóm tắt, phụ thuộc vào tiêu chí sử dụng để phân loại, sau đây là một số cách phân loại cần quan tâm: 2.4.1","Phân loại tóm tắt văn bản: Có rất nhiều cách phân loại tóm tắt văn bản"]],"t":"\n VÀ ĐỊNH HƯỚNG GIẢI PHÁP\r\n\r\nMô tả bài toán và các vấn đề cần giải quyết.\r\nMô tả bài toán.\r\nBài toán tóm tắt văn bản hướng truy vấn có thể được tóm tắt như sau: Với một văn bản đã xác định, và một yêu cầu từ người dùng (thể hiện qua câu truy vấn), xây dựng một hệ thống tóm tắt văn bản cung cấp cho người dùng một bản tóm tắt chung nêu được các thông tin nổi bật nhất trong văn bản đáp ứng phù hợp với câu truy vấn (tìm câu trả lời phù hợp nhất với câu truy vấn từ người dùng).\r\nVấn đề cần giải quyết: Một trong những vấn đề thử thách của bài toán này là việc sinh bản tóm tắt lấy người dùng làm trung tâm dựa trên một câu truy vấn. \r\nĐịnh hướng giải quyết vấn đề đặt ra.\r\nĐể giải quyết vấn đề đã nêu ra ở trên tôi tập trung vào nghiên cứu các phương pháp tóm tắt văn bản, đặc biệt là phương pháp tóm tắt văn bản dựa vào độ tương đồng ngữ nghĩa  giữa 2 câu, cụ thể trong bài toán này dựa vào độ tương đồng ngữ nghĩa giữa các câu trong văn bản với truy vấn từ người dùng.\r\nCơ sở lý thuyết.\r\nTổng quan về tóm tắt văn bản.\r\nTóm tắt văn bản là gì?\r\nTrước tiên, chúng ta phải tìm hiểu khái niệm Tóm tắt văn bản là gì?: Đó là cách thức trình bày lại nội dung của văn bản gốc, loại bỏ các thông tin không cần thiết theo mục đích đã định, chỉ giữ lại các thông tin mà chúng ta đang quan tâm. \r\nNhư vậy tóm tắt văn bản cần phải đảm bảo các yêu cầu: luôn ngắn hơn nhiều so với văn bản gốc, không chứa thông tin không cần thiết với mục đích tóm tắt, phản ánh trung thực nội dung của văn bản gốc. \r\nCác lĩnh vực ứng dụng tóm tắt văn bản: Tóm tắt văn bản được áp dụng rất rộng rãi trên nhiều lĩnh vực khác nhau: Kinh tế, chính trị, văn hóa, thể thao, du lịch. với các ứng dụng như: \r\nTóm tắt tin tức trên các báo điện tử.\r\nGiảm dung lượng văn bản cho các thiết bị cầm tay.\r\nTrợ giúp việc lọc thông tin từ các công cụ tìm kiếm.\r\n\r\n\r\nPhân loại tóm tắt văn bản: \r\nCó rất nhiều cách phân loại tóm tắt văn bản. tùy vào mục đích và yêu cầu cụ thể sẽ có các phân loại khác nhau. \r\nPhân loại theo số lượng văn bản đầu vào: Tùy thuộc vào số lượng vănn bản đầu vào ta có thể phân loại thành tóm tắt đơn văn bản (đầu vào chỉ có một văn bản) hay đa văn bản (dữ liệu đầu vào nhiều hơn 1 văn bản). \r\n-  Tóm tắt đơn văn bản: Ưu điểm của loại tóm tắt này là là dễ thực hiện do không xuất hiện những nhập nhằng về mặt thời gian. Các văn bản đầu vào coi như đã đảm bảo về mặt trật tự, trật tự này do người tạo văn bản tạo ra. Tuy nhiên nhược điểm của loại tóm tắt này là phạm vi tóm tắt hẹp, chỉ áp dụng cục bộ cho 1 văn bản.\r\n-  Tóm tắt đa văn bản: đây là loại tóm tắt mở rộng của tóm tắt đơn văn bản. Ưu điểm của loại tóm tắt này là xử lý được thông tin trên nhiều văn bản có liên quan tới nhau. Tuy nhiên có nhược điểm là phải xử lý nhiều nhập nhằng giữa các văn bản như: nhập nhằng về trật tự thời gian, nhập nhằng đại từ, dư thừa thông tin.\r\nPhân loại theo nội dung đầu ra của bản tóm tắt: Với cách phân loại này thì ta có 2 loại tóm tắt văn bản là tóm tắt theo trích xuất (Extract) và tóm tắt tóm lược (Abstract).\r\n-  Tóm tắt theo trích xuất câu: theo cách tóm tắt này, bản tóm tắt được xâ dựng bằng cách rút ra các câu quan trọng và sắp xếp chúng theo thứ tự xuất hiện trong văn bản gốc. Ưu điểm của loại tóm tắt này là dễ thực hiện, không cần tri thức bổ sung, nhưng có nhược điểm là các câu trong tóm tắt rời rạc, không có sự gắn kết với nhau.\r\n-  Tóm tắt tóm lược : Ngoài việc đảm bảo nội dung của văn bản gốc thì các câu văn trong bản tóm tắt phải liền mạch, dễ đọc. Vì vậy phải cần thêm nhiều tri thức bổ sung để tạo thành câu có thể gắn kết với nhau từ các từ, các thành phần câu lấy ra từ văn bản gốc.\r\nPhân loại theo mục đích tóm tắt: Theo cách phân loại này thì mục có thể phân thành 2 loại tóm tắt là tóm tắt chung (general) và tóm tắt hướng truy vấn(Query-based).\r\n- Tóm tắt chung: mục đích chính là tìm ra bản tóm tắt cho toàn bộ văn bản mà sẽ tổng hợp được tất cả nội dung của văn bản đó. Cách tóm tắt này dựa trên quan điểm của người tạo ra văn bản, chứ không tóm tắt theo nhu cầu của người đọc.\r\n-Tóm tắt hướng truy vấn: loại tóm tắt này thường được sử dụng trong quá trình tóm tắt các kết quả trả về từ máy tìm kiếm. nội dung của bản tóm tắt sẽ dựa vào truy vấn từ người dùng, thể hiện nhu cầu của người dùng.\r\nNgoài ra, có nhiều cách khác để phân loại tóm tắt văn bản như: Dựa vào ngôn ngữ (tóm tắt đơn ngôn ngữ, đa ngôn ngữ, xuyên ngôn ngữ), dựa vào đối tượng đọc (tóm tắt cho chuyên gia, tóm tắt cho người đọc bình thường), dựa vào định dạng văn bản (tóm tắt văn bản không theo khuôn mẫu, tóm tắt văn bản có cấu trúc.) .\r\n\r\nQuy trình thực hiện tóm tắt văn bản.\r\nMô hình hệ thống tóm tắt văn bản tổng quát bao gồm 3 quá trình: Quá trình tiền xử lý, Quá trình xử lý, Quá trình tổng hợp.\r\nQuá trình tiền xử lý(phân tích): Xây dựng một biểu diễn có cấu trúc của văn bản.\r\nQuá trình xử lý (chuyển đổi): Bao gồm các giải thuật, tính toán chuyển đổi biểu diễn văn bản có cấu trúc sang một dạng biểu diễn có cấu trúc khác - biểu diễn cho tóm tắt. hoặc sàng lọc ra dữ liệu tốt nhất cho tóm tắt.\r\nQuá trình tổng hợp(sinh kết quả):  Tạo bản tóm tắt bằng cách dựa vào biểu diễn cho tóm tắt.\r\n\r\nII.1.3.1. Quá trình tiền xử lý.\r\nTiền xử lý văn bản nói chung là quá trình thực hiện đọc văn bản và chuyển đổi văn bản đó sang một dạng biểu diễn có cấu trúc. Mô hình biểu diễn này có vai trò rất quan trọng đến hiệu quả, hiệu suất của phương án giải quyết bài toán.\r\nMột số mô hình biểu diễn văn bản:\r\n Mô hình không gian vector : Mỗi văn bản hay thành phần của văn bản được biểu diễn thành một vector. Mỗi thành phần của vector là một thuật ngữ riêng biệt trong tập văn bản gốc và được gán một giá trị trọng số w đã được tính toán. Đặc điểm quan trọng của mô hình này là độ tương tự của 2 văn bản / 2 thành phần của văn bản có thể được tính qua độ tương tự giữa 2 vector đại diện chúng. Do tính đơn giản và hiệu quả của nó mà mô hình này được sử dụng rất rộng rãi.\r\n Mô hình dựa trên tập mờ : Chủ yếu xoay quanh bài toán biểu diễn văn bản về việc lưu trữ trên tập mờ, lưu trữ và xử lý các khái niệm thay vì làm việc trên các thuật ngữ.\r\nTiền xử lý đóng vai trò rất quan trọng trong các bài toán khai thác văn bản. Nó làm giảm thiểu phần dữ liệu thừa phải tính toán, làm giảm kích thước của bài toán. Một số phương pháp có thể áp dụng trong tiền xử lý văn bản : Case Folding (chuyển đổi tất cả các kí tự trong văn bản về cùng một dạng format), Stopword( loại bỏ từ dừng  những từ xuất hiện nhiều nhưng ít mang thông tin liên quan đến nội dung của văn bản).\r\nII.1.3.2. Quá trình xử lý.\r\nQuá trình này áp dụng các giải thuật để biến các giá trị biểu diễn của văn bản thành các giá trị biểu diễn khả năng xây dựng tóm tắt. các giá trị sau khi biến đổi được dùng làm đầu vào cho quá trình sinh kết quả. Không có một mô hình biểu diễn chung nào cho các giá trị này như ở giai đoạn tiền xử lý mà nó phụ thuộc vào giải thuật chuyển đổi và vào cách đánh giá để sinh kết quả.\r\nII.1.3.3. Quá trình tổng hợp sinh kết quả.\r\nBước cuối cùng của hệ thống nhằm đưa ra bản tóm tắt cho văn bản gốc. Đây thường là bước đơn giản nhất, tuy nhiêu độ phức tạp của nó cũng phụ thuộc vào quá trình xử lý ở trên.\r\nCác hướng tiếp cận tóm tắt văn bản.\r\nTrong phạm vi của đồ án chỉ nghiên cứu bài toán có đầu vào là 1 văn bản nên phần này chỉ đưa ra các hướng tiếp cận cho tóm tắt đơn văn bản.\r\nPhương pháp thống kê.\r\nHầu hết các nghiên cứu đầu tiên cho tóm tắt đơn văn bản đều tập trung trên những văn bản kỹ thuật (các bài báo khoa học).  Các phương pháp cổ điển thường tập trung vào các đặc trưng hình thái để tính điểm cho các câu và rút trích các câu quan trọng để đưa vào tóm tắt.\r\nÝ tưởng chính của hướng tiếp cận :\r\n Thu tập ngữ liệu.\r\n Tạo các bản tóm tắt thủ công.\r\n Thiết kế các công thức toán hay logic để tính điểm cho các câu.\r\nLặp cho đến khi tóm tắt tự động đạt được tính tương đương với tóm tắt thủ công :\r\n+   Tính điểm cho từng câu để tạo ra bản tóm tắt cho từng văn bản trong ngữ liệu dựa vào các đặc trưng về hình thái.\r\n+   So sánh tóm tắt được tạo tự động với tóm tắt được tạo thủ công.\r\n+   Cải thiện lại phương thức tính điểm cho câu.\r\n\r\nPhương pháp thống kê trên TF.ISF.\r\nPhương pháp này còn gọi là mô hình túi từ (bag-of-words), sử dụng mô hình trọng số TF.IDF (term frequency và inverse sentence frequence). Ở mô hình này, giá trị IDF được tính trên câu. Trong đó, TF là số lần xuất hiện của term trong 1 câu. Và DF là số câu có chứa term.\r\nCùng với phương pháp tính độ đo TF.IDF và phương pháp biểu diễn văn bản bằng vector không gian sử dụng Vector Space Model (Saton 1975).\r\nTuy nhiên, phương pháp dùng độ đo TF.IDF không được dùng độc lập, mà thường được kết hợp với các phương pháp khác như máy học, đồ thị. để đạt được hiệu quả cao hơn.\r\nPhương pháp học máy.\r\nNăm 1990, với sự phát triển của nhiều kỹ thuật máy học trong xử lý ngôn ngữ, một số nhà nghiên cứu đã ứng dụng các kỹ thuật này vào trong tóm tắt văn bản tự động.\r\n Một số nghiên cứu điển hiển của phương phát này là : Naive-Bayes, Decision Tree, Hidden Makov Model, Log-Linear, Neural Network, SVM.\r\nPhương pháp phân tích ngôn ngữ tự nhiên.\r\nPhương pháp tiếp theo xử dụng các kỹ thuật phân tích ngôn ngữ tự nhiên phức tạp. Không phải tất cả các phương pháp phân tích ngôn ngữ tự nhiên đều xử dụng máy học, đôi khi phương pháp chỉ sử dụng một số các heuristic để tạo rút trích. \r\nHầu hết các phương pháp này đều dựa trên cấu trúc diễn ngôn (discourse tructure) hay cấu trúc diễn đạt (thể hiện) của văn bản, như : cấu trúc các section của văn bản, liên kết ngữ pháp (trùng lặp, tĩnh lược, liên hợp), liên kết từ vựng (đồng nghĩa, bao hàm, lặp lại), cấu trúc chính phụ.\r\nĐánh giá hệ thống tóm tắt văn bản.\r\nViệc đánh giá kết quả tóm tắt văn bản là một việc khó khăn trong thời điểm hiện tại vì không tồn tại một tóm tắt lý tưởng cho một văn bản hay một tập văn bản. Việc sử dụng ý kiến đánh giá của các chuyên gia ngôn ngữ được xem là cách đánh giá tốt nhất, tuy nhiên, cách làm này lại tốn rất nhiều chi phí. Bên cạnh các phương pháp đánh giá thủ công do các chuyên gia thực hiện, vấn đề đánh giá tự động kết quả tóm tắt cũng nhận được nhiều sự quan tâm hiện nay. Từ năm 2000, hội nghị DUC đã được tổchức mỗi năm một lần để thực hiện việc đánh giá với quy mô lớn các hệ thống tóm tắt văn bản. Việc đánh giá tự động này nhằm mục đích là tìm ra được một độ đo đánh giá tóm tắt gần với những đánh giá của con người nhất.\r\nĐánh giá thủ công.\r\nCác chuyên gia của DUC ban đầu đã thực hiện đánh giá thủ công dựa trên cách đánh giá hệ thống tìm kiếm thông tin. Các chuyên gia đánh giá của DUC phải sử dung một chương trình phần mềm để đánh dấu từng đơn vị thông tin của tóm tắt tự động trùng khớp với đơn vị thông tin của tóm tắt chuẩn. Việc đánh dấu các đơn vị thông tin cũng được cho điểm dưới 4 mức độ : đầy đủ(điểm 4), gần đầy đủ (điểm 3), một vài (điểm 2), ít (điểm 1). Sau khi đánh dấu các đơn vị thông tin, 2 độ đo pricision và recall được lựa chọn để đánh giá. \r\n\r\n\r\n\r\n\r\n\r\nTrong đó: t là ngưỡng đánh giá các đơn vị thông tin (1,2,3,4) tương ứng với các giá trị (đầy đủ, gần đầy đủ, một vài, ít).\r\nViệc đánh giá thủ công cho kết quả tốt nhưng chi phí về thời gian quá lớn. Các chuyên gia về NIST đã tốn gần 3000 giờ để đánh giá hết 15 hệ thống tóm tắt năm 2011.\r\nĐánh giá tự động.\r\nNăm 2002, Lin và Hovy đã giới thiệu phương pháp đánh giá tự động đầu tiên dựa vào mô hình n-gram của độ đo BLUE của cộng đồng dịch máy. Phương pháp sử dụng điểm so khớp n- gram.\r\nNAMS = a1NAM1 + a2NAM2 + a3NAM3 + a4NAM4 \r\nTrong đó, NAMn là tỉ lệ trùng khớp n_gram.\r\n\r\n\r\n\r\nĐến 2004, Lin đã giới thiệu một tập các độ đo hướng Recal có tên là Recall- Orented  Understudy Of Gistion Evaluation (ROUGE). Tập độ đo này gồm nhiều độ đo khác nhau dựa trên mô hình n-gram của độ đo BLUE nhưng với nhiều cách thức tính khác nhau. Tiêu biểu nhất là độ đo ROUGE- N, vói n là giá trị của mô hình n-gram được sử dụng, thường n = {1,2,3,4}.\r\nROUGE là một hệ thống đánh giá tóm tắt tự động mà dựa trên tỉ lệ tóm tắt dựa trên đặc điểm của sự gắn kết và hàm lượng thông tin chứa trong bản tóm tắt tự động. Nó nhận bản tóm tắt như đầu vào.\r\nROUGE được sử dụng như một tiêu chuẩn để so sánh hiệu suất của tóm tắt đề xuất với các bản tóm tắt của các hệ thống khác trên cùng một tập tập tài liệu. Việc đánh giá được thực hiện dựa trên các điểm sau:\r\nROUGE- 1.n : Sử dụng n gram trùng lạp giữa tóm tắt của hệ thống và tóm tắt đề xuất.\r\nROUGE  L : (Longest) Chuỗi con chung lớn nhất (trùng lặp giữa tóm tắt do con người tạo và tóm tắt do máy tạo).\r\nROUGE-W: Dãy con chung dài nhất được đánh trọng số mà quyết định độ dài của dãy từ liên tiếp. \r\nROUGE không phải là một công cụ đánh giá bao hàm toàn diện. ROUGE-n, ROUGE-L, ROUGE-W, ROUGE SU4 tốt cho tóm tắt đơn văn bản trong khi ROUGE-1 làm việc tốt cho tóm tắt đa văn bản.\r\n\r\nĐộ tương đồng câu và các phương pháp tính độ tương đồng câu.\r\nĐộ tương đồng là một đại lượng được sử dụng để đo mối liên hệ giữa 2 đối tượng hoặc 2 đặc trưng. Giá trị này thường nằm trong khoảng (-1;1) hoặc (0;1). Thông thường giá trị này càng lớn thì 2 đối tượng hay 2 đặc trưng đó càng giống nhau. \r\nViệc đo độ tương đồng giữa 2 đối tượng, 2 đặc trưng chính là việc xác định 1 hàm ánh xạ mối quan hệ giữa 2 đối tượng, 2 đặc trưng đó sang một dạng số .\r\nVí dụ : trong mô hình không gian vector, độ đo cosin được sử dụng để tính độ tương đồng giữa 2 văn bản hoặc 2 câu trong văn bản. Mỗi văn bản/ câu trong văn bản được biểu diễn thông qua một vector.\r\n\r\nĐộ tương đồng câu.\r\nBài toán tính độ tương đồng câu được phát biểu như sau: trong một văng bản d có n câu (s1, s2, s3.sn). \r\nMục tiêu của bài toán là tìm ra một hàm S(si,sj) với i,j = 1,.,n sao cho S nằm trong khoảng (0,1). Hàm S(si,sj) được gọi là độ đo tương đồng giữa 2 câu si, sj. Giá trị này càng cao thì sự giống nhau về ngữ nghĩa càng nhiều. \r\nĐộ tương đồng ngữ nghĩa là một giá trị tin cậy phản ánh mối quan hệ ngữ nghĩa giữa 2 câu. Tuy nhiên, trên thực tế khó có thể lấy một giá trị có độ chính xác cao bởi ngữ nghĩa của một câu chỉ có thể được hiểu đầy đủ trong một ngữ cảnh cụ thể.\r\nCác phương pháp tính độ tương đồng câu.\r\nHiện nay có nhiều phương pháp để đo độ tương đồng giữa 2 câu, tuy nhiên có thể đưa về 2 nhóm phương pháp chính : phương pháp thống kê (độ đo cosin, độ đo euclid.) và phương pháp xử lý ngôn ngữ tự nhiên(Sử dụng phân tích cú pháp, sử dụng mạng ngữ nghĩa đối với từ: wordnet corpus, Brown corpus,Penn Treebank.).\r\nPhương pháp thống kê: Phương pháp này độ chính xác chưa cao do việc thống kê sẽ không đảm bảo được sự tương đồng về ngữ ngữ. Ngữ nghĩa của một câu hay một từ phải dựa vào hoàn cảnh cụ thể mới có thể xác định chính xác. Tuy nhiên phương pháp này xử lý nhanh, tốn ít chi phí, có nhiều kết quả khả quan.\r\nPhương pháp xử lý ngôn ngữ tự nhiên: Các phương pháp thuộc nhóm này sử dụng các tập dữ liệu chuẩn về ngôn ngữ để tìm ra mối quan hệ giữa các từ: Wordnet , Brown corpus, Penn Treebank. Phương pháp này cho kết quả cao, tuy nhiên khó khăn của phương pháp này gặp phải là việc xây dựng kho dữ liệu đòi hỏi sự tốn kém về mặt chi phí, nhân lực và thời gian. Đối với ngôn ngữ tiếng việt hiện tại chưa có corpus để sử dụng, vì vậy nhiều phương pháp được đề xuất thay thế Wordnet như : sử dụng phân tích chủ đề ẩn, sử dụng mạng ngữ nghĩa Wikipiedia. Các phương pháp này tập trung vào việc bổ sung các thành phần ngữ nghĩa hỗ trợ cho độ đo tương đồng Cosine.\r\nII.4.2.1. Phương pháp tính độ tương đồng câu sử dụng độ đo cosine.\r\nTrong phương pháp tính độ này, các câu sẽ được biểu diễn theo một mô hình không gian vector. Mỗi thành phần trong vector chỉ đến một từ tương ứng trong danh sách mục từ chính. Danh sách  từ chính thu được từ quá trình tiền xử lý văn bản đầu vào, các bước tiền xử lý gồm: tách câu, tách từ, gán nhãn từ loại, loại bỏ những câu không hợp lệ(không phải là câu thực sự) và biểu diễn câu trên không gian vectơ.\r\nKhông gian vector có kích thước bằng số từ trong danh sách từ chính mỗi tọa độ của vector là độ quan trọng của từ đó trong câu.\r\nĐộ quan trọng của từ thứ j trong câu có thể được tính bằng TF (Term frequency), ISF(Inverse sentence frequency), hoặc kết hợp TF-ISF.\r\n\r\n\r\n\r\n\r\n\r\nTrong đó: tfi,j : là tần suất xuất hiện từ i trong câu j( sự phổ biến của từ i trong câu j).\r\n\tisfi: tần số nghịch đảo câu trong văn bản(thể hiện độ hiếm của từ đó trong văn bản)\r\n\tViệc lấy maxlfreql,j để hạn chế sự ảnh hưởng của chiều dài câu đến giá trị tfi,j vì nếu ta tính tần suất xuất từ i trong câu theo công thức xác suất thông thường thì với những câu dài, số lượng từ trong câu sẽ lớn như vậy sẽ ảnh hưởng đến giá trị của tần số xuất hiện từ.\r\nFreqi,j:  số lần xuất hiện từ i trong câu j.\r\n\tN: Số câu trong văn bản.\r\n\tni: Số câu chứa từ i trong văn bản.\r\nĐộ quan trọng của từ trong câu:\r\n\r\nWi,j = tfi,j*isfi\r\n\r\nPhương pháp trọng số tf-isf đánh giá mức độ quan trọng của từ xét về mặt toàn cục kết hợp với trọng số cục bộ của cụm từ trong tài liệu. Những từ thường xuất hiện trong một câu nhưng ít xuất hiện trong toàn bộ tài liệu thì có trọng số cao.\r\nVới không gian biểu diễn văn bản là không gian vector , độ tương đồng giữa 2 câu được chọn là cosine góc giữa 2 vector tương ứng của 2 câu. Vector biểu diễn 2 câu có dạng \r\nSm =  <w1,m,.,wt,m>  \r\nSn  =  <w1,n,.,wt,n> \r\nĐộ tương đồng giữa 2 câu được tính theo công thức.\r\n\r\n\r\nLưu ý: Trước khi áp dụng công thức tính độ tương đồng ở trên phải tiến hành xét quan hệ ngữ nghĩa giữa các từ để đảm bảo độ chính xác của kết quả như  : xét từ đồng nghĩa, từ đồng âm.\r\nTrong  phương pháp tính độ tương đồng câu người ta còn sử dụng một đặc trưng khác là vị trí từ trong câu để tính tương đồng.\r\nVí dụ :  An đẩy Nam xuống sông.\r\n\tNam đẩy An xuống sông. \r\nNếu như xét độ tương đồng của câu dựa trên tần suất xuất hiện từ trong câu thì 2 câu này hoàn toàn tương đồng. Nhưng xét về ngữ nghĩa thì 2 câu trên hoàn toàn không giống nhau. Để hạn chế vấn đề này thì một đặc trưng khác của câu là vị trí từ trong câu đã được xem xét.\r\nCác ước lượng độ tương đồng về thứ tự từ trong mỗi câu được xác định như sau: \r\nNếu từ trong tập từ chung mà có trong câu thì từ đó sẽ có cùng thứ tự với từ trong câu đó.\r\nNgược lại, nếu từ trong tập từ chung mà không giống với từ nào trong câu thì thứ tự của nó sẽ bằng 0.\r\nÁp dụng với 2 câu trên ta có vector vị trí từ như sau :\r\nR1 = <1,2,3,4,5>\r\nR2 = <3,2,1,4,5>\r\nCông thức tính độ tương đồng vị trí từ trong câu: \r\n\r\n\r\n\r\nThường dùng kết hợp 2 độ đo trên để tính độ tương đồng cho toàn bộ câu\r\n\r\n\r\n\r\n\r\nII.4.2.2. Phương pháp tính độ tương đồng câu sử dụng Wordnet corpus\r\nPhương pháp này được thực hiện dựa trên ngữ nghĩa và cú pháp của các từ trong câu.\r\nPhương pháp này cho kết quả cao, tuy nhiên khó khăn của phương pháp này gặp phải là việc xây dựng kho dữ liệu đòi hỏi sự tốn kém về mặt chi phí, nhân lực và thời gian. Đối với ngôn ngữ tiếng việt hiện tại chưa có corpus để sử dụng.\r\nMô hình của phương pháp: Mô hình dựa trên mô hình được đề xuất để tính toán độ tương đồng câu trong tiếng anh. \r\n\r\n\r\n\r\n\r\nPhần II: CÁC KẾT QUẢ ĐẠT ĐƯỢC\r\n\r\nPhân tích và thiết kế hệ thống.\r\nGiải pháp giải quyết bài toán.\r\nDựa vào cơ sở lý thuyết đã trình bày ở trên, Đồ án đề xuất giải quyết bài toán tóm tắt văn bản hướng truy vấn theo phương pháp tính độ tương đồng giữa các câu trong văn bản với câu truy vấn sử dụng độ đo cosine.\r\nQuy trình thực hiện của hệ thống tóm tắt diễn ra theo 3 quá trình: Tiền xử lý, Xử lý, Sinh tóm tắt. Cụ thể các quá trình sẽ được trình bày trong phần dưới. \r\nMô hình xử lý chi tiết.\r\n\r\n\r\n\r\n\r\n\r\nQuá trình tiền xử lý:\r\nTrong quá trình này, hệ thống sẽ tiến hành xử lý văn bản đầu vào : tách câu , tách từ, loại bỏ từ dừng, vector hóa các câu trong văn bản. \r\nTách từ.\r\nTrong tiếng Việt, dấu cách không mang ý nghĩa phân tách các từ mà chỉ mang ý nghĩa phân tách các âm tiết với nhau, vì vậy để làm việc với tiếng Việt thì bài toán tách từ là một trong những bài toán cơ bản và quan trọng bậc nhất.\r\nSau khi tách câu tôi sử dụng mã nguồn công cụ tách từ vnTokenizer 4.1.1c (04/08/2010) của nhóm tác giả Lê Hồng Phương[] để tách nội dung của văn bản và câu truy vấn thành các đơn vị từ. (Mã nguồn của chương trình được public trên trang  ).\r\nTìm danh từ riêng.\r\nCác danh từ riêng trong văn bản thường rất quan trọng không thể bỏ đi ở các câu. Tuy nhiên khi nói tới một danh từ riêng người ta không xét tới ngữ nghĩa của danh từ đó. Vì thế, rất có thể danh từ riêng sẽ được nhận dạng nhầm trong bước loại bỏ từ dừng ( sẽ được trình bày ở phần ngay sau). Do đó trước khi loại bỏ các từ dừng trong văn bản thì phải thực hiện bước phát hiện danh từ riêng trước để tránh loại bỏ từ có ý nghĩa quan trọng.\r\nThêm nữa, ngôn ngữ tiếng Việt rất đa dạng, hiện tượng các từ đồng âm nhưng khác nhau về ý nghĩa rất phổ biến. Việc phát hiện danh từ riêng sẽ tránh được việc đồng nhất các từ này với các từ không phải danh từ riêng nhưng đồng âm với nó. Từ đấy việc tính toán trọng số từ trong câu sẽ chính xác hơn.\r\nÝ tưởng xác định danh từ riêng:\r\nTên riêng được xác định trong văn bản là từ có chữ cái đầu viết hoa. Như vậy thuật toán xác định tên riêng có thể được đề xuất như sau:\r\nĐầu vào : Danh sách câu đã được tách từ, danh sách danh từ riêng (ban đầu rỗng).\r\nĐầu ra: Danh sách tên riêng có trong văn bản.\r\nThuật toán:\r\nB1: Khởi tạo danh sách chứa tên riêng trong văn bản.\r\nB2: Duyệt tất cả các từ trong văn bản.\r\n\tNếu gặp từ có viết hoa đầu câu thì xét vị trí của từ đó có phải ở đầu câu hay không.\r\n\tNếu không ở đầu câu thì thêm vào danh sách tên riêng,đánh dấu từ đó là tên riêng, ở đầu câu thì bỏ qua.\r\n(Ở bước này ta không xét các từ viết hoa đầu câu).\r\nB3: Duyệt lại văn bản từ đầu( Chỉ xét các từ đầu câu).\r\n\tNếu từ đang xét nằm trong danh sách tên riêng đã tìm được ở bước trước thì đánh dấu từ đó là tên riêng.\r\n\tNếu không nằm trong danh sách thì xét từ đó có nhiều hơn 1 âm tiết hay không.\r\n\tNếu từ đó nhiều hơn 1 âm tiết thì xét đến âm tiết thứ 2 trong từ có viết hoa đầu hay không\r\n(Các danh từ riêng thì các âm tiết đều viết hoa chữ cái đầu.)\r\nB4: Lặp lại cho đến khi xét hết các từ trong văn bản.\r\n\r\nHình :Sơ đồ quá trình tìm danh từ riêng\r\n\r\n\r\nLoại bỏ từ dừng.\r\nTừ dừng là từ thường xuất hiện nhiều trong văn bản, tuy nhiên không có nhiều ý nghĩa đối với nội dung của văn bản hiện tại \r\nVí dụ : a lô, a ha, bao lâu, bây giờ, bấy giờ.\r\nỞ bước này, từ danh sách câu, các từ đã được tách ta tiến hành loại bỏ từ dừng. cách loại bỏ từ dừng chỉ đơn giản là tiến hành so khớp các từ trong văn bản với các từ lấy ra từ bộ từ điển từ dừng. Như vậy vấn đề gặp phải ở bước này là việc xây dựng bộ từ điển từ dừng.\r\nBộ từ điển từ dừng tôi đã sử dụng cho chương trình được lấy từ trang . Bộ từ điển này gồm 570 từ. Từ điển được lưu trong file text, mỗi dòng xác định một từ dừng sắp xếp theo thứ tự bảng chữ cái tiếng việt.\r\nMột số từ dừng trong từ điển.\r\n\r\n\r\nBảng : Mộ số từ dừng trong tiếng Việt\r\n\r\n\r\n\r\nQuá trình loại bỏ từ dừng: Thuật toán áp dụng loại bỏ từ dừng trên từng câu.\r\nĐầu vào: Câu S (đã được tách từ) cần loại bỏ từ dừng, file từ điển lưu trữ các từ dừng\r\nĐâu ra:  Câu S đã được loại bỏ hết các từ dừng.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nHình : Sơ đồ quá trình loại bỏ từ dừng\r\n\r\nXử lý từ đồng nghĩa.\r\nCác ngôn ngữ nói chung, tiếng Việt nói riêng, có rất nhiều từ phát âm khác nhau nhưng có ngữ nghĩa giống nhau, cùng nói về một sự vật hiện tượng nào đó, các từ này có thể quy về cùng một từ trong văn bản.  Như vậy nếu ta không xử lý các từ đồng nghĩa thì các này sẽ ảnh hưởng đến độ quan trọng của từ trong câu. Các từ đồng nghĩa sẽ được tính là nhiều từ, do vậy độ quan trọng của từ sẽ giảm, kết quả tính toán sẽ bị sai lệch  không như mong muốn.\r\nPhương pháp xác định từ đồng nghĩa cũng gặp nhiều khó khăn, do từ đồng nghĩa không phải là những từ trùng nhau hoàn toàn về nghĩa. Chúng sẽ có những dị biệt nào đó bên cạnh sự tương đồng. những từ đồng nghĩa với nhau không nhất thiết phải tương đương với nhau về số lượng nghĩa, tức là các từ trong một nhóm đồng nghĩa không nhất thiết phải có số lượng nghĩa bằng nhau từ này có thể có một hoặc hai nghĩa, từ khác có thể có ít hoặc nhiều nghĩa hơn. Các từ đồng nghĩa chỉ tương đồng ở một nghĩa nào đó của chúng .\r\nVới khó khăn nêu trên, để tìm các từ đồng nghĩa trong văn bản và câu truy vấn, hệ thống sử dụng bộ từ điển đồng nghĩa. Bộ từ điển đồng nghĩa này gồm 7734 nhóm từ đồng nghĩa được thu thập từ trang tra từ điển  . từ điển được lưu trong file text mỗi dòng trong file có 3 nội dung: từ đang xét, nhóm từ từ đồng nghĩa với từ đang xét, nhóm từ trái nghĩa. Mỗi nhóm từ trong 1 dòng được phân cách bởi dấu  ; . \r\nMột số từ đồng nghĩa tiếng việt.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nGiải thuật tìm từ đồng nghĩa\r\nĐầu vào: chuỗi đã được tách từ.\r\nĐầu ra: Danh sách câu với các từ đã được đánh dấu vào các nhóm từ tương đồng(các từ cùng nhóm sẽ có cùng 1 chỉ số đánh dấu từ đồng nghĩa).\r\nSau bước này sẽ thu được danh sách các từ đã được đồng nhất.Như vậy việc tính toán độ tương đồng giữa các câu trong văn bản và câu truy vấn sẽ trở nên dễ dàng và chính xác hơn. \r\n\r\n\r\nVector hóa các câu trong văn bản.\r\nQua các bước xử lý ở trên ta đã có danh sách câu đã loại bỏ từ dừng và đồng bộ hóa các từ đồng nghĩa trong văn bản với từ trong câu tuy vấn.Tiếp theo ta phải tiến hành vector hóa các câu trong văn bản, mỗi câu trong văn bản được biểu diễn dưới dạng vector. Mỗi vector có số chiều chính là số từ trong văn bản và câu truy vấn, tại vị trí mà từ của câu không xuất hiện trong danh sách từ chung thì sẽ là bằng 0, còn lại là trọng số của từ được tính theo công thức tính trọng số từ đã được nêu ở trên.\r\nVí dụ: Một đoạn (đại diện cho văn bản) gồm 2 câu: Con đường nào không thể tiếp tục thì hãy từ bỏ. Có nhiều con đường để chúng ta bước tiếp.\r\nTập từ chung trong văn bản : Con đường, nào, không thể, tiếp tục, thì hãy, từ bỏ, có nhiều, để , chúng ta, bước.\r\nNhư vậy vector của câu 1 Con đường nào không thể tiếp tục thì hãy từ bỏ\r\n{x,x,x,x,x,x,0,0,0,0}\r\n\tVector của câu 2 Có nhiều con đường để chúng ta bước tiếp\r\n\t\t\t\t{x,0,0,x,0,0,x,x,x,x}\r\n\tỞ đó : x là từ trong câu đó.\r\nQuá trình xử lý.\r\nTrong quá trình này hệ thống sẽ tiến hành tính toán các trọng số từ, độ tương đồng giữa các câu để làm cơ sở cho bước việc sinh văn bản tóm tắt.\r\nTính trọng số từ.\r\nViệc tính trọng số của từ là rất quan trọng trong bài toán này vì trọng số của từ chính là độ quan trọng của từ đó trong văn bản.\r\nỞ đây, trọng số của một từ trong câu được tính toán thông qua sự kết hợp 2 độ đo tf, isf\r\n\r\nWi,j = tfi,j* isfi\r\n\r\nTrong đó : wi,j là trọng số của từ thứ i trong câu j.\r\n\ttfi,j: tần số xuất hiện từ thứ i trong câu j (độ phổ biến của từ thứ i trong câu j).\t\r\n\r\n\r\n\tisfi: tần suất xuất hiện nghịch đảo của từ thứ I trong văn bản( độ hiếm của từ thứ i trong văn bản).\r\n\r\nNhư vậy, theo công thức trên thì một từ được cho là quan trọng nếu nó xuất hiện nhiều trong câu nhưng lại xuất hiện ít trong văn bản.\r\nThuật toán tính trọng số của một từ (calWeight(word,S,Ls))\r\nĐầu vào : từ cần tính trọng số, câu chứa từ đang xét, danh sách câu trong văn bản.\r\nĐầu ra : trọng số của từ.\r\n\r\n\r\n\r\n\r\n\r\nTính trọng số của tất cả các từ trong văn bản.\r\nĐầu vào: danh sách câu trong văn bản (Ls).\r\nKết quả: tất cả các từ trong văn bản đều được tính trọng số.\r\n\r\n\r\n\r\n\r\n\t\r\n\r\n\r\nTính độ tương đồng giữa với câu truy vấn.\r\n\r\nSau khi tiền xử lý, các câu trong văn bản sẽ được biểu diễn dưới dạng vector, nên ta sẽ dùng độ đo cosine để tính độ tương đồng giữa 2 câu. Đặc biệt là câu trong văn bản với câu truy vấn.\r\nĐể dễ thực hiện ta xem câu truy vấn là 1 câu trong văn bản. câu này sẽ ở vị trí bắt đầu văn bản. Vì trong kết quả tóm tắt không chứa những câu có ý nghĩa giống nhau, nên để loại bỏ các câu giống nhau trong văn bản tóm tắt cũng phải sử dụng độ tương đồng giữa các câu đó. Do vậy ở bước này ta sẽ tính độ tương đồng giữa tất cả các câu với nhau.\r\n\r\n\r\n\r\n\r\n\r\nSơ đồ giải thuật tính độ tương đồng giữa 2 câu.\r\n\r\nĐầu vào: các vector trọng số của 2 câu, kích thước vector.\r\nĐầu ra: độ tương tự giữa 2 câu.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nNgoài ra, Đặc trưng vị trí từ trong câu cũng là 1 khía cạnh để đánh giá độ tương đồng giữa 2 câu\r\nKhi đó, độ tương đồng giữa 2 câu được tính theo công thức.\r\n\r\nSim(S1,S2) = Ss + (1-) Sr\r\n\r\nSs : độ tương đồng giữa 2 câu theo độ đo cosine\r\nSr: độ tương đồng giữa 2 câu theo vị trí từ.\r\n\r\nQuá trình sinh kết quả.\r\nSau quá trình xử lý, độ tương đồng giữa các câu trong văn bản với câu truy vấn, và độ tương tự giữa các câu trong văn bản với nhau đã được xác định. Từ đó ta sẽ xác định các câu để đưa vào bản tóm tắt dựa trên kết quả đó.\r\nYêu cầu của bản tóm tắt: \r\nNội dung tóm tắt phải phù hợp với truy vấn.\r\nCác câu trong tóm tắt không được trùng nhau.\r\nĐộ dài bản tóm giới hạn.\r\nNhư vậy, để đảm bảo yêu cầu của bản tóm tắt thì ta phải xác định các ngưỡng để lựa chọn các câu vào văn bản tóm tắt: \r\n : Ngưỡng để xác định độ tương đồng tối thiểu của câu truy vấn với các câu trong văn bản gốc. Các câu trong văn bản gốc có độ tương đồng với câu truy vấn phải lớn hơn  mới phù hợp để đưa vào văn bản tóm tắt.\r\n : Ngưỡng xác định độ tương đồng lớn nhất giữa các câu trong văn bản tóm tắt. 2 câu trong văn bản tóm tắt được coi là trùng nhau nếu độ tương đồng giữa chúng lớn hơn hoặc bằng .\r\nn : Ngưỡng xác định kích thước văn bản tóm tắt. có nhiều tiêu chí để lựa chọn  giá trị của n, Ở đây tôi chọn n là số từ tối đa trong bản tóm tắt. Một câu sẽ được đưa vào bản tóm tắt nếu như sau khi thêm câu đó vào số từ trong bản tóm tắt không vượt quá n.\r\nÝ tưởng chung để xác định các câu đưa vào bản tóm tắt.\r\nSắp xếp các câu trong văn bản theo thứ tự giảm dần độ tương đồng với câu truy vấn.\r\nLấy các câu theo thứ tự từ  trên xuống dưới sao cho đảm bảo các yêu cầu của bản tóm tắt.\r\nSắp xếp lại các câu trong bản tóm tắt theo thứ tự xuất hiện của nó trong văn bản gốc.\r\n\r\n\r\nTuy nhiên việc lựa chọn câu theo quy trình trên chưa thực sự cho kết quả chính xác vì trong trường hợp có nhiều câu tương tự cùng có độ đo lớn với câu truy vấn mà có 1 câu nói lên nội dung chính còn các câu còn lại là diễn giải cho câu đó thì sẽ xảy ra trường hợp câu diễn giải có độ tương đồng với câu truy vấn cao hơn câu  có nội dung chính. Như vậy khi lấy câu theo quy trình trên câu có nội dung chính sẽ bị loại bỏ do có độ tương đồng cao với câu đã có trong tóm tắt. \r\nVí dụ :\r\n Truy vấn từ người dùng là Món ăn truyền thống của dân tộc Mường\r\nTrong văn bản gốc có 2 câu tương tự có độ tương đồng cao với truy vấn là \r\nMón ăn có vị đắng là món ăn người Mường rất ưa thích\r\nMăng đắng, hoa, lá, quả đu đủ không chỉ là món ăn thường ngày của người Mường mà còn là món ăn để thờ phụng.\r\nNhư vậy câu thứ 2 được lựa chọn sẽ không tóm tắt được hết ý.\r\nĐể hạn chế được trường hợp trên thì trong đồ án áp dụng một thay đổi là trước khi chọn câu vào bản tóm tắt ta sẽ tiến hành gom nhóm cho các câu. Mỗi nhóm bao gồm các câu có độ tương đồng cao với nhau. Sắp xếp các câu trong nhóm theo thứ tự xuất hiện của nó trong văn bản. Khi chọn câu vào văn bản sẽ chọn mỗi duyệt lần lượt trong các nhóm, mỗi nhóm lấy 1 câu . Lặp lại cho đến khi số lượng từ trong văn bản thỏa mãn. (Ý tưởng của phương pháp này dựa trên ý tưởng diễn dịch. Câu mang ý chính của một đoạn văn bản diễn dịch sẽ nằm ở đầu đoạn). \r\n\r\nChi tiết kết quả thực hiện, cài đặt và thử nghiệm.\r\nGiả thiết ban đầu.\r\nNội dung của văn bản đầu vào phải phù hợp với câu truy vấn.\r\nVăn bản gốc được lưu dưới dạng file text (.txt), mã hóa unicode.\r\nTruy vấn từ người dùng trọng tâm đến nội dung tóm tắt, hạn chế các từ không. mang nhiều ý nghĩa.\r\nMục tiêu: Đưa ra nội dung tóm tắt của văn bản theo hướng truy vấn từ người dùng.\r\nCông cụ lựa chọn để giải quyết vấn đề.\r\nCông cụ xây dựng chương trình demo:\r\nNgôn ngữ sử dụng (Java): Java là ngôn ngữ lập trình mới do một nhóm nhà khoa học của hãng Sun Microsytem tạo nên. Làm việc với Java sẽ rất thuận tiện do các ưu điểm của ngôn ngữ này.\r\nJava đơn giản nên thời gian tìm hiểu ngắn.\r\nJava hướng đối tượng nên chương trình rất linh hoạt và có thể tái sử dụng nhiều lần.\r\nJava rất mạnh: bộ nhớ được giải phóng một cách tự động nhờ đó có thể tránh được những hư hỏng về bộ nhớ và đảm bảo tính toàn vẹn dữ liệu.\r\nJava có tính độc lập với cấu trúc, vì vậy không phụ thuộc vào hệ máy và ( loại máy và hệ điều hành).\r\nLý do đặc biệt khi chọn Java làm ngôn ngữ xây dựng chương trình demo là có nhiều mã nguồn có thể tái sử dụng cho việc tiền xử lý tiếng việt. Ví dụ chương trình tách từ tiếng Việt.\r\nIDE: netbean.\r\nIDE phổ biến để viết chương trình bằng ngôn ngữ Java, thân thiện, dễ sử dụng.\r\n\r\nKết quả thực nghiệm.\r\nPhần này sẽ trình bày kết quả thực nghiệm của chương trình với một đoạn văn bản ngắn, và đưa ra các kết quả tính toán là giải thích tại sao cách chương trình đưa ra kết quả cuối cùng, đưa ra kết quả của văn bản mẫu.\r\nGiao diện chương trình.\r\nChương trình gồm 3 giao diện : giao diện chính, giao diện hiển thị kết quả đánh giá và giao diện hiển thị song song nội dung của bản tóm tắt tay và nội dung của bản tóm tắt tự động sinh ra bởi hệ thống\r\n\r\nGiao diện chính của chương trình.\r\n\r\n\r\nDữ liệu vào\r\n1: cung cấp câu truy vấn từ người dùng. Dữ liệu này không được để trống.\r\n2: đường dẫn đền file gốc cần tóm tắt.\r\n3: Nội dung văn bản cần tóm tắt.\r\nChức năng và kết quả xử lý. \r\n4: Chức năng xử lý văn bản đầu vào đưa ra bản tóm tắt hiển thị ở 8.\r\n5: Lưu văn bản tóm tắt(tên bản tóm tắt trùng với tên của văn bản gốc nhưng được đặt ở thư mục tóm tắt.)\r\n6: Xem kết quả đánh giá: chức năng này sẽ mở giao diện đánh các kết quả tóm tắt đã thực hiện.\r\n7: Số lượng từ giới hạn trong bản tóm tắt.\r\n8: Lưu kết quả tóm tắt chương trình thực hiện tóm tắt văn bản gốc.\r\n\r\nGiao diện đánh giá kết quả tóm tắt \r\n\r\n\r\n\r\nViệc đánh giá kết quả tóm tắt dựa trên độ đo ROUGE với các tiêu chí Recall (R),  Precision(P), Fscore(F). Chỉ các văn bản (trong thư mục document) có đầy đủ bản tóm tắt tự động(trong thư mục auto_summation) và tóm tắt tay (trong thư mục hand_summation) mới có kết quả đánh giá hiển thị trên giao diện.\r\nGiao diện hiển thị song song nội dung tóm tắt tay và tóm tắt tự động\r\nThông qua giao diện này người dùng có thể nhìn thấy trực quan nội dung của văn bản tóm tắt tự động và nội dung của văn bản tóm tắt tay.\r\n\r\n\r\nCách sử dụng:\r\nKhi giao diện chính được mở: người dùng sẽ chọn file cần tóm tắt thông qua nút Open file và tìm ra 1 file bất kì có định dạng phần mở rộng .txt, nội dung của file sẽ được tải lên khu vực File content làm nội dung tóm tắt. Hoặc người dùng có thể patse trực tiếp đoạn văn bản cần tóm tắt vào khu vực File content (Tuy nhiên, trong trường hợp này người dùng sẽ không lưu được văn bản vào file vì không có file gốc để so sánh).\r\nSau khi chọn file cần tóm tắt người dùng phải nhập yêu cầu nội dung quan tâm vào phần Query. Nội dung query càng sát với yêu cầu người dùng thì kết quả tóm tắt càng phù hợp với mong muốn của người dùng.\r\nKhi đã đảm bảo các yêu cầu cơ bản query, file content đã có nội dùng người dùng sẽ tạo tóm tắt thông qua nút chức năng Sumarize. Kết quả tóm tắt sẽ hiển thị ở khu vực Sumary. Có thể thay đổi độ dài bản tóm tắt bằng cách lựa chọn số từ.\r\nChức năng Save được sử dụng khi người dùng muốn lưu lại bản tóm tắt vừa tạo (tên file tóm tắt được tạo mặc định là tên file gốc và lưu tại thư mục auto_summation).\r\nChức năng Evaluation để xem đánh giá của bản tóm tắt đã tạo. Để sử dụng chức năng này người dùng phải tạo bản tóm tắt tay của văn bản gốc vừa tóm tắt (tên file trùng với tên văn bản gốc) và đặt tại thư mục hand_summation.\r\n\r\nKết quả ví dụ.\r\nSau đây là kết quả tóm tắt 1 ví dụ (đơn giản) mẫu và giải thích cách chương trình tạo ra văn bản tóm tắt\r\nVăn bản gốc: Bất cứ ngôi đình nào cũng thờ Thành hoàng của làng - đây là yếu tố bắt buộc. Ngoài thành hoàng làng, tùy theo mỗi ngôi đình làng có thể thờ các vị thần, thánh khác do mỗi làng tôn thờ, hoặc việc thờ cúng các vị thần theo sắc phong của Nhà vua, tất cả được rước vào đình thành một tập thể siêu thần, thành một sức mạnh vô hình, tạo niềm tin, niềm hy vọng của làng xã Việt Nam. Việc vinh danh, tôn thờ những người có công to lớn đối với làng cùng với vị trí của nơi đặt đình làng và cách thức bày biện nội thất ngôi đình đã làm toát lên vai trò đây là nơi quan trọng bảo vệ, che chở cho mỗi làng trước các biến cố của tự nhiên và đời sống xã hội. Vào ngày lễ tết, nhân dân trong làng tới đình thắp hương tế lễ, cầu mong thành hoàng làng và trời đất phù giúp mưa thuận gió hoà để mùa màng gặt hái thuận tiện và có nhiều phúc lành. Đây cũng là dịp để tưởng niệm công tích của các vị thần và dịp này người ta tổ chức hội đình. Hầu hết các làng, xóm của người Mường đều có Đình, đình thờ thành hoàng vị thánh được người Mường tôn vinh đó là người có công khai phá ruộng nương, chỉ bảo cho người dân làm ăn. Bên cạnh đó người Mường thường thờ Thánh Tản Viên, họ tôn kính coi Thánh Tản Viên là người có thể đi mây về gió, ban phúc trừ tà. Trong 82 di tích đình của tỉnh Hòa Bình có tới 20 đình thờ Tản Viên Sơn Thánh, 36 đình không rõ tên các vị thần được thờ (do nhiều nguyên nhân), 31 đình còn lại là thờ thành hoàng địa phương và các thiên thần, nhân thần được các đời vua phong sắc. Đình làng ở Hòa Bình có thể được chia ra làm 3 loại cơ bản: Đình của người Mường, Đình của người Kinh và Đình giao thoa giữa hai dân tộc.\r\nTruy vấn từ người dùng:   Nét văn hóa đình làng Hòa Bình. \r\n\r\n\r\nTrọng số của các từ trong truy vấn.\r\n\r\nĐộ tương đồng của các câu với câu truy vấn\r\n\r\nTheo kết quả độ tương đồng với câu truy vấn ở trên 4 câu bị loại bỏ (do độ tương đồng với câu truy vấn < 0.3). Như vậy có 5 câu 8,7,1,5,2 thỏa mãn độ tương đồng với câu truy vấn >0.3.\r\nCác câu này được gom thành 2 nhóm:\r\nNhóm 1 gồm các câu 7,8.\r\nNhóm 2 gồm các câu 1,2,5.\r\nThực hiện việc chọn câu bằng cách duyệt các nhóm mỗi lần duyệt lấy 1 câu trong nhóm và thực hiện lặp lại cho tới khi đủ số từ trong bản tóm tắt. Việc lựa chọn kết quả vào tóm tắt sẽ dựa trên độ tương đồng với câu truy vấn mà đã được tính toán ở trên. 1 câu được lựa chọn vào bản tóm tắt phải thỏa mãn : độ tương đồng nhỏ nhất với câu truy vấn (ở đây được lựa chọn là >0.2), độ tương đồng lớn nhất với các câu đã có trong bản tóm tắt (<0.9), số lượng từ trong bản tóm tắt phải nhỏ hơn ngưỡng đã chọn (<120 từ).\r\nDựa vào các tiêu chí trên hệ thống lựa chọn được câu đưa vào bản tóm tắt\r\nKết quả tóm tắt: Bất cứ ngôi đình nào cũng thờ Thành hoàng của làng - đây là yếu tố bắt buộc .. Ngoài thành hoàng làng , tùy theo mỗi ngôi đình làng có thể thờ các vị thần , thánh khác do mỗi làng tôn thờ , hoặc việc thờ cúng các vị thần theo sắc phong của Nhà vua , tất cả được rước vào đình thành một tập thể siêu thần , thành một sức mạnh vô hình , tạo niềm tin , niềm hy vọng của làng xã Việt Nam .. Trong 82 di tích đình của tỉnh Hòa Bình có tới 20 đình thờ Tản Viên Sơn Thánh , 36 đình không rõ tên các vị thần được thờ , 31 đình còn lại là thờ thành hoàng địa phương và các thiên thần , nhân thần được các đời vua phong sắc .. Đình làng ở Hòa Bình có thể được chia ra làm 3 loại cơ bản : Đình của người Mường , Đình của người Kinh và Đình giao thoa giữa hai dân tộc ..\r\n\r\nĐánh giá.\r\nMô tả bộ dữ liệu.\r\nBộ dữ liệu gồm 50 tài liệu mẫu là các bài báo  được thu thập từ các trang web tin tức bởi các bạn trong nhóm đồ án thu thập và tạo văn bản tóm tắt tay. Tên các bản tóm tắt được đặt trùng với tên văn bản gốc. Độ dài các văn bản từ 400-1200 từ. các văn bản tóm tắt tay có độ dài xấp xỉ 120 từ.\r\nCâu truy vấn mặc định được lấy từ tiêu đề bài báo.\r\nĐộ đo ROUGE.\r\nĐồ án sử dụng độ đo Rouge để đánh giá độ chính xác của tóm tắt. ROUGE là một hệ thống đánh giá tóm tắt tự động mà dựa trên tỉ lệ tóm tắt dựa trên đặc điểm của sự gắn kết và hàm lượng thông tin chứa trong bản tóm tắt tự động. Nó nhận bản tóm tắt như đầu vào.\r\nĐộ đo ROUGE được xác nhận là một công cụ đánh giá tốt cho tóm tắt đa văn bản với sự tập trung vào nội dung trùng lặp. ROUGE không phải là một công cụ đánh giá bao hàm toàn diện. ROUGE-2, ROUGE-L, ROUGE-W, ROUGE SU4 tốt cho tóm tắt đơn van bản trong khi ROUGE-1 làm việc tốt cho tóm tắt đa văn bản.\r\nKết quả đánh giá.\r\nChất lượng của bản tóm tắt sinh ra từ hệ thống được đánh giá qua độ đo ROUGE với số GRAM n =4, với ngưỡng độ dài yêu cầu của bản tóm tắt là 120 từ,Kết quả đánh giá nằm trong khoảng từ 0.3 đến 0.8. Độ chính xác của hệ thống càng cao khi số từ giới trong bản tóm tắt càng cao.\r\nBản đánh giá kết quả khi không thực hiện gom nhóm trong quá trình sinh tóm tắt.\r\n\r\n\r\n\r\n\r\n\r\nBảng đánh giá kết quả khi thực hiện gom nhóm \r\n\r\n\r\n\r\nTừ kết quả thực nghiệm, có thể thấy rằng mô hình tóm tắt sử dụng cho kết quả khả quan mặc dù các câu trả về vẫn chưa thể hiện ngữ nghĩa, chưa có sự gắn kết giữa các câu trong tóm tắt. Theo 2 kết quả trên ta thấy việc áp dụng gom nhóm câu trong khi tạo kết quả tóm tắt mang lại hiệu quả tốt hơn cho hệ thống.\r\nKết quả đánh giá trung bình khi thực hiện với 50 văn bản gốc\r\n\r\n\r\n\r\n\r\nPhần III: KẾT LUẬN\r\n\r\nĐánh giá ưu nhược điểm và khả năng ứng dụng của hệ thống.\r\nƯu điểm.\r\nHệ thống cho kết quả tương đối chính xác, thời gian xử lý nhanh, không mất thời gian xây dựng kho dữ liệu từ điển.\r\nNhược điểm.\r\nHệ thống chưa xử lý được về mặt ngữ nghĩa.\r\nChưa giải quyết được tính dễ đọc của kết quả đầu ra, kết quả đầu ra không liền mạch, các câu chưa có sự liên kết với nhau\r\nĐộ chính xác của kết quả phụ thuộc nhiều vào việc xác định câu truy vấn, độ dài văn bản.\r\nKhả năng ứng dụng.\r\nHệ thống có thể áp dụng tóm tắt các văn bản ngắn, trung bình như: các bài báo, tin tức trên internet. Nội dung của văn bản gốc ko tập trung theo từng đoạn của văn bản.\r\nHệ thống được xây dựng để hỗ trợ các bộ máy tìm kiếm thông tin mà có kết quả trả về dưới dạng văn bản.\r\nĐánh giá công việc.\r\nĐồ án nghiên cứu giải quyết bài toán tóm tắt hướng truy vấn trên phạm vi đơn văn bản bằng phương pháp tính độ tương đồng với câu truy vấn. và nâng cao mức độ chính xác cho phương pháp bằng cách gom nhóm các câu tương đồng trong văn bản. Việc gom nhóm đã tránh được sự dư thừa trong bản tóm tắt. Kết quả thử nghiệm cho thấy khi hệ thống đưa ra tóm tắt bằng cách gom nhóm các câu tương đồng trong văn bản đạt kết quả cao hơn so với khi chỉ sử dụng độ tương đồng với câu truy vấn. \r\nTuy nhiên, hệ thống vẫn còn những hạn chế chưa khắc phục được \r\nChưa áp dụng được ngữ nghĩa. Bản tóm tắt chưa thật phù hợp với câu truy vấn về mặt ngữ nghĩa.\r\nChưa giải quyết được tính dễ đọc của bản tóm tắt.Nội dung của bản tóm tắt còn rời rạc , chưa liên kết giữa các câu với nhau, đôi khi còn tồn tại những câu không rõ nghĩa.\r\n\r\n\r\nĐịnh hướng phát triển và hoàn thiện các kết quả đạt được.\r\nXử lý đồng tham chiếu(đặc biệt là đồng tham chiếu đại từ) để xác định được chính xác các đại từ trong câu tóm tắt.\r\nXây dựng bộ từ điển corpus tiếng việt, từ đó có thể tăng ngữ nghĩa cho bản tóm tắt.\r\nÁp dụng các kĩ thuật phân tích xử lý văn bản tiếng việt nhằm nâng cao chất lượng hệ thống: gán nhãn từ loại, phân tích cú pháp,.\r\n\r\n\r\n\r\n\r\n\r\n\r\nTài  liệu tham khảo.\r\n\r\nA. P. Siva kumar, Dr. P. Premchand,Dr. A. Govardhan. \"Query-Based Summarizer Based on Similarity of Sentences and Word Frequency.\" Department of Computer Science Engineering, Osmania University, Hyderabad,  India.\r\nAhmed A. Mohamed, Sanguthevar Rajasekaran. \"Query-Based Summarization Based on Document Graphs .\" Department of Computer Science & Engineering, University of Connecticut.\r\nĐỗ Thị Thanh Nga. \"Tính toán độ tương tự ngữ nghĩa văn bản dựa vào độ tương tự giữa từ với từ.\" Luận văn thạc sĩ, Đại học Quốc Gia Hà Nội - Trường đại học Công Nghệ, 2010.\r\nHoàng Minh Hiền. \"Độ tương đồng ngữ nghĩa giữa 2 câu và ứng dụng trong tóm tắt văn bản.\" Khóa luận tốt nghiệp, Đại học Quốc Gia Hà Nội, 2008.\r\nLapalme, Olga Feiguina and Guy. \"Query-based summarization of customer reviews.\" Departement dinformatique et de recherche operationnelle, Universite de Montreal.\r\nLin, Chin- Yew. \"ROUGE: A Package for Automatic Evaluation of Summaries.\" Information Sciences Institute, University of Southern California.\r\nMariana Damova, Ivan Koychev. \"Query-Based Summarization: A survey.\" Faculty of Mathematics and Informatics, University of Sofia, Bulgaria. \r\nLưu Tuấn Anh. \"Kiến thức cơ bản về xử lý ngôn ngữ tự nhiên.\" http://viet.jnlp.org/kien-thuc-co-ban-ve-xu-ly-ngon-ngu-tu-nhien, 25/03/2013.\r\nNguyễn Minh Thành, \"Text  Summarization.\"  https://sites.google.com/site/trangmonhocitc/text-summarization,    15/03/2013.","u":"http://202.191.57.85:8000/InternetData/Data/LVTN/48.txt","sentences":[[1,"Mô tả bài toán"],[2,"Bài toán tóm tắt văn bản hướng truy vấn có thể được tóm tắt như sau: Với một văn bản đã xác định, và một yêu cầu từ người dùng (thể hiện qua câu truy vấn), xây dựng một hệ thống tóm tắt văn bản cung cấp cho người dùng một bản tóm tắt chung nêu được các thông tin nổi bật nhất trong văn bản đáp ứng phù hợp với câu truy vấn (tìm câu trả lời phù hợp nhất với câu truy vấn từ người dùng)"],[3,"Vấn đề cần giải quyết: Một trong những vấn đề thử thách của bài toán này là việc sinh bản tóm tắt lấy người dùng làm trung tâm dựa trên một câu truy vấn"],[4,"Định hướng giải quyết vấn đề đặt ra"],[5,"Để giải quyết vấn đề đã nêu ra ở trên tôi tập trung vào nghiên cứu các phương pháp tóm tắt văn bản, đặc biệt là phương pháp tóm tắt văn bản dựa vào độ tương đồng ngữ nghĩa giữa 2 câu, cụ thể trong bài toán này dựa vào độ tương đồng ngữ nghĩa giữa các câu trong văn bản với truy vấn từ người dùng"],[6,"Cơ sở lý thuyết"],[7,"Tổng quan về tóm tắt văn bản"],[8,"Tóm tắt văn bản là gì"],[9,"Trước tiên, chúng ta phải tìm hiểu khái niệm Tóm tắt văn bản là gì?: Đó là cách thức trình bày lại nội dung của văn bản gốc, loại bỏ các thông tin không cần thiết theo mục đích đã định, chỉ giữ lại các thông tin mà chúng ta đang quan tâm"],[10,"Như vậy tóm tắt văn bản cần phải đảm bảo các yêu cầu: luôn ngắn hơn nhiều so với văn bản gốc, không chứa thông tin không cần thiết với mục đích tóm tắt, phản ánh trung thực nội dung của văn bản gốc"],[11,"Các lĩnh vực ứng dụng tóm tắt văn bản: Tóm tắt văn bản được áp dụng rất rộng rãi trên nhiều lĩnh vực khác nhau: Kinh tế, chính trị, văn hóa, thể thao, du lịch"],[12,"với các ứng dụng như: Tóm tắt tin tức trên các báo điện tử"],[13,"Giảm dung lượng văn bản cho các thiết bị cầm tay"],[14,"Trợ giúp việc lọc thông tin từ các công cụ tìm kiếm"],[15,"Phân loại tóm tắt văn bản: Có rất nhiều cách phân loại tóm tắt văn bản"],[16,"tùy vào mục đích và yêu cầu cụ thể sẽ có các phân loại khác nhau"],[17,"Phân loại theo số lượng văn bản đầu vào: Tùy thuộc vào số lượng vănn bản đầu vào ta có thể phân loại thành tóm tắt đơn văn bản (đầu vào chỉ có một văn bản) hay đa văn bản (dữ liệu đầu vào nhiều hơn 1 văn bản)"],[18,"- Tóm tắt đơn văn bản: Ưu điểm của loại tóm tắt này là là dễ thực hiện do không xuất hiện những nhập nhằng về mặt thời gian"],[19,"Các văn bản đầu vào coi như đã đảm bảo về mặt trật tự, trật tự này do người tạo văn bản tạo ra"],[20,"Tuy nhiên nhược điểm của loại tóm tắt này là phạm vi tóm tắt hẹp, chỉ áp dụng cục bộ cho 1 văn bản"],[21,"- Tóm tắt đa văn bản: đây là loại tóm tắt mở rộng của tóm tắt đơn văn bản"],[22,"Ưu điểm của loại tóm tắt này là xử lý được thông tin trên nhiều văn bản có liên quan tới nhau"],[23,"Tuy nhiên có nhược điểm là phải xử lý nhiều nhập nhằng giữa các văn bản như: nhập nhằng về trật tự thời gian, nhập nhằng đại từ, dư thừa thông tin"],[24,"Phân loại theo nội dung đầu ra của bản tóm tắt: Với cách phân loại này thì ta có 2 loại tóm tắt văn bản là tóm tắt theo trích xuất (Extract) và tóm tắt tóm lược (Abstract)"],[25,"- Tóm tắt theo trích xuất câu: theo cách tóm tắt này, bản tóm tắt được xâ dựng bằng cách rút ra các câu quan trọng và sắp xếp chúng theo thứ tự xuất hiện trong văn bản gốc"],[26,"Ưu điểm của loại tóm tắt này là dễ thực hiện, không cần tri thức bổ sung, nhưng có nhược điểm là các câu trong tóm tắt rời rạc, không có sự gắn kết với nhau"],[27,"- Tóm tắt tóm lược : Ngoài việc đảm bảo nội dung của văn bản gốc thì các câu văn trong bản tóm tắt phải liền mạch, dễ đọc"],[28,"Vì vậy phải cần thêm nhiều tri thức bổ sung để tạo thành câu có thể gắn kết với nhau từ các từ, các thành phần câu lấy ra từ văn bản gốc"],[29,"Phân loại theo mục đích tóm tắt: Theo cách phân loại này thì mục có thể phân thành 2 loại tóm tắt là tóm tắt chung (general) và tóm tắt hướng truy vấn(Query-based)"],[30,"- Tóm tắt chung: mục đích chính là tìm ra bản tóm tắt cho toàn bộ văn bản mà sẽ tổng hợp được tất cả nội dung của văn bản đó"],[31,"Cách tóm tắt này dựa trên quan điểm của người tạo ra văn bản, chứ không tóm tắt theo nhu cầu của người đọc"],[32,"-Tóm tắt hướng truy vấn: loại tóm tắt này thường được sử dụng trong quá trình tóm tắt các kết quả trả về từ máy tìm kiếm"],[33,"nội dung của bản tóm tắt sẽ dựa vào truy vấn từ người dùng, thể hiện nhu cầu của người dùng"],[34,"Ngoài ra, có nhiều cách khác để phân loại tóm tắt văn bản như: Dựa vào ngôn ngữ (tóm tắt đơn ngôn ngữ, đa ngôn ngữ, xuyên ngôn ngữ), dựa vào đối tượng đọc (tóm tắt cho chuyên gia, tóm tắt cho người đọc bình thường), dựa vào định dạng văn bản (tóm tắt văn bản không theo khuôn mẫu, tóm tắt văn bản có cấu trúc.)"],[35,"Quy trình thực hiện tóm tắt văn bản"],[36,"Mô hình hệ thống tóm tắt văn bản tổng quát bao gồm 3 quá trình: Quá trình tiền xử lý, Quá trình xử lý, Quá trình tổng hợp"],[37,"Quá trình tiền xử lý(phân tích): Xây dựng một biểu diễn có cấu trúc của văn bản"],[38,"Quá trình xử lý (chuyển đổi): Bao gồm các giải thuật, tính toán chuyển đổi biểu diễn văn bản có cấu trúc sang một dạng biểu diễn có cấu trúc khác - biểu diễn cho tóm tắt"],[39,"hoặc sàng lọc ra dữ liệu tốt nhất cho tóm tắt"],[40,"Quá trình tổng hợp(sinh kết quả): Tạo bản tóm tắt bằng cách dựa vào biểu diễn cho tóm tắt"],[41,"II.1.3.1"],[42,"Quá trình tiền xử lý"],[43,"Tiền xử lý văn bản nói chung là quá trình thực hiện đọc văn bản và chuyển đổi văn bản đó sang một dạng biểu diễn có cấu trúc"],[44,"Mô hình biểu diễn này có vai trò rất quan trọng đến hiệu quả, hiệu suất của phương án giải quyết bài toán"],[45,"Một số mô hình biểu diễn văn bản: Mô hình không gian vector : Mỗi văn bản hay thành phần của văn bản được biểu diễn thành một vector"],[46,"Mỗi thành phần của vector là một thuật ngữ riêng biệt trong tập văn bản gốc và được gán một giá trị trọng số w đã được tính toán"],[47,"Đặc điểm quan trọng của mô hình này là độ tương tự của 2 văn bản / 2 thành phần của văn bản có thể được tính qua độ tương tự giữa 2 vector đại diện chúng"],[48,"Do tính đơn giản và hiệu quả của nó mà mô hình này được sử dụng rất rộng rãi"],[49,"Mô hình dựa trên tập mờ : Chủ yếu xoay quanh bài toán biểu diễn văn bản về việc lưu trữ trên tập mờ, lưu trữ và xử lý các khái niệm thay vì làm việc trên các thuật ngữ"],[50,"Tiền xử lý đóng vai trò rất quan trọng trong các bài toán khai thác văn bản"],[51,"Nó làm giảm thiểu phần dữ liệu thừa phải tính toán, làm giảm kích thước của bài toán"],[52,"Một số phương pháp có thể áp dụng trong tiền xử lý văn bản : Case Folding (chuyển đổi tất cả các kí tự trong văn bản về cùng một dạng format), Stopword( loại bỏ từ dừng những từ xuất hiện nhiều nhưng ít mang thông tin liên quan đến nội dung của văn bản)"],[53,"II.1.3.2"],[54,"Quá trình xử lý"],[55,"Quá trình này áp dụng các giải thuật để biến các giá trị biểu diễn của văn bản thành các giá trị biểu diễn khả năng xây dựng tóm tắt"],[56,"các giá trị sau khi biến đổi được dùng làm đầu vào cho quá trình sinh kết quả"],[57,"Không có một mô hình biểu diễn chung nào cho các giá trị này như ở giai đoạn tiền xử lý mà nó phụ thuộc vào giải thuật chuyển đổi và vào cách đánh giá để sinh kết quả"],[58,"II.1.3.3"],[59,"Quá trình tổng hợp sinh kết quả"],[60,"Bước cuối cùng của hệ thống nhằm đưa ra bản tóm tắt cho văn bản gốc"],[61,"Đây thường là bước đơn giản nhất, tuy nhiêu độ phức tạp của nó cũng phụ thuộc vào quá trình xử lý ở trên"],[62,"Các hướng tiếp cận tóm tắt văn bản"],[63,"Trong phạm vi của đồ án chỉ nghiên cứu bài toán có đầu vào là 1 văn bản nên phần này chỉ đưa ra các hướng tiếp cận cho tóm tắt đơn văn bản"],[64,"Phương pháp thống kê"],[65,"Hầu hết các nghiên cứu đầu tiên cho tóm tắt đơn văn bản đều tập trung trên những văn bản kỹ thuật (các bài báo khoa học).  Các phương pháp cổ điển thường tập trung vào các đặc trưng hình thái để tính điểm cho các câu và rút trích các câu quan trọng để đưa vào tóm tắt"],[66,"Ý tưởng chính của hướng tiếp cận : Thu tập ngữ liệu"],[67,"Tạo các bản tóm tắt thủ công"],[68,"Thiết kế các công thức toán hay logic để tính điểm cho các câu"],[69,"Lặp cho đến khi tóm tắt tự động đạt được tính tương đương với tóm tắt thủ công : +   Tính điểm cho từng câu để tạo ra bản tóm tắt cho từng văn bản trong ngữ liệu dựa vào các đặc trưng về hình thái"],[70,"+   So sánh tóm tắt được tạo tự động với tóm tắt được tạo thủ công"],[71,"+   Cải thiện lại phương thức tính điểm cho câu"],[72,"Phương pháp thống kê trên TF.ISF"],[73,"Phương pháp này còn gọi là mô hình túi từ (bag-of-words), sử dụng mô hình trọng số TF.IDF (term frequency và inverse sentence frequence)"],[74,"Ở mô hình này, giá trị IDF được tính trên câu"],[75,"Trong đó, TF là số lần xuất hiện của term trong 1 câu"],[76,"Và DF là số câu có chứa term"],[77,"Cùng với phương pháp tính độ đo TF.IDF và phương pháp biểu diễn văn bản bằng vector không gian sử dụng Vector Space Model (Saton 1975)"],[78,"Tuy nhiên, phương pháp dùng độ đo TF.IDF không được dùng độc lập, mà thường được kết hợp với các phương pháp khác như máy học, đồ thị"],[79,"để đạt được hiệu quả cao hơn"],[80,"Phương pháp học máy"],[81,"Năm 1990, với sự phát triển của nhiều kỹ thuật máy học trong xử lý ngôn ngữ, một số nhà nghiên cứu đã ứng dụng các kỹ thuật này vào trong tóm tắt văn bản tự động"],[82,"Một số nghiên cứu điển hiển của phương phát này là : Naive-Bayes, Decision Tree, Hidden Makov Model, Log-Linear, Neural Network, SVM"],[83,"Phương pháp phân tích ngôn ngữ tự nhiên"],[84,"Phương pháp tiếp theo xử dụng các kỹ thuật phân tích ngôn ngữ tự nhiên phức tạp"],[85,"Không phải tất cả các phương pháp phân tích ngôn ngữ tự nhiên đều xử dụng máy học, đôi khi phương pháp chỉ sử dụng một số các heuristic để tạo rút trích"],[86,"Hầu hết các phương pháp này đều dựa trên cấu trúc diễn ngôn (discourse tructure) hay cấu trúc diễn đạt (thể hiện) của văn bản, như : cấu trúc các section của văn bản, liên kết ngữ pháp (trùng lặp, tĩnh lược, liên hợp), liên kết từ vựng (đồng nghĩa, bao hàm, lặp lại), cấu trúc chính phụ"],[87,"Đánh giá hệ thống tóm tắt văn bản"],[88,"Việc đánh giá kết quả tóm tắt văn bản là một việc khó khăn trong thời điểm hiện tại vì không tồn tại một tóm tắt lý tưởng cho một văn bản hay một tập văn bản"],[89,"Việc sử dụng ý kiến đánh giá của các chuyên gia ngôn ngữ được xem là cách đánh giá tốt nhất, tuy nhiên, cách làm này lại tốn rất nhiều chi phí"],[90,"Bên cạnh các phương pháp đánh giá thủ công do các chuyên gia thực hiện, vấn đề đánh giá tự động kết quả tóm tắt cũng nhận được nhiều sự quan tâm hiện nay"],[91,"Từ năm 2000, hội nghị DUC đã được tổchức mỗi năm một lần để thực hiện việc đánh giá với quy mô lớn các hệ thống tóm tắt văn bản"],[92,"Việc đánh giá tự động này nhằm mục đích là tìm ra được một độ đo đánh giá tóm tắt gần với những đánh giá của con người nhất"],[93,"Đánh giá thủ công"],[94,"Các chuyên gia của DUC ban đầu đã thực hiện đánh giá thủ công dựa trên cách đánh giá hệ thống tìm kiếm thông tin"],[95,"Các chuyên gia đánh giá của DUC phải sử dung một chương trình phần mềm để đánh dấu từng đơn vị thông tin của tóm tắt tự động trùng khớp với đơn vị thông tin của tóm tắt chuẩn"],[96,"Việc đánh dấu các đơn vị thông tin cũng được cho điểm dưới 4 mức độ : đầy đủ(điểm 4), gần đầy đủ (điểm 3), một vài (điểm 2), ít (điểm 1)"],[97,"Sau khi đánh dấu các đơn vị thông tin, 2 độ đo pricision và recall được lựa chọn để đánh giá"],[98,"Trong đó: t là ngưỡng đánh giá các đơn vị thông tin (1,2,3,4) tương ứng với các giá trị (đầy đủ, gần đầy đủ, một vài, ít)"],[99,"Việc đánh giá thủ công cho kết quả tốt nhưng chi phí về thời gian quá lớn"],[100,"Các chuyên gia về NIST đã tốn gần 3000 giờ để đánh giá hết 15 hệ thống tóm tắt năm 2011"],[101,"Đánh giá tự động"],[102,"Năm 2002, Lin và Hovy đã giới thiệu phương pháp đánh giá tự động đầu tiên dựa vào mô hình n-gram của độ đo BLUE của cộng đồng dịch máy"],[103,"Phương pháp sử dụng điểm so khớp n- gram"],[104,"NAMS = a1NAM1 + a2NAM2 + a3NAM3 + a4NAM4 Trong đó, NAMn là tỉ lệ trùng khớp n_gram"],[105,"Đến 2004, Lin đã giới thiệu một tập các độ đo hướng Recal có tên là Recall- Orented Understudy Of Gistion Evaluation (ROUGE)"],[106,"Tập độ đo này gồm nhiều độ đo khác nhau dựa trên mô hình n-gram của độ đo BLUE nhưng với nhiều cách thức tính khác nhau"],[107,"Tiêu biểu nhất là độ đo ROUGE- N, vói n là giá trị của mô hình n-gram được sử dụng, thường n = {1,2,3,4}"],[108,"ROUGE là một hệ thống đánh giá tóm tắt tự động mà dựa trên tỉ lệ tóm tắt dựa trên đặc điểm của sự gắn kết và hàm lượng thông tin chứa trong bản tóm tắt tự động"],[109,"Nó nhận bản tóm tắt như đầu vào"],[110,"ROUGE được sử dụng như một tiêu chuẩn để so sánh hiệu suất của tóm tắt đề xuất với các bản tóm tắt của các hệ thống khác trên cùng một tập tập tài liệu"],[111,"Việc đánh giá được thực hiện dựa trên các điểm sau: ROUGE- 1.n : Sử dụng n gram trùng lạp giữa tóm tắt của hệ thống và tóm tắt đề xuất"],[112,"ROUGE L : (Longest) Chuỗi con chung lớn nhất (trùng lặp giữa tóm tắt do con người tạo và tóm tắt do máy tạo)"],[113,"ROUGE-W: Dãy con chung dài nhất được đánh trọng số mà quyết định độ dài của dãy từ liên tiếp"],[114,"ROUGE không phải là một công cụ đánh giá bao hàm toàn diện"],[115,"ROUGE-n, ROUGE-L, ROUGE-W, ROUGE SU4 tốt cho tóm tắt đơn văn bản trong khi ROUGE-1 làm việc tốt cho tóm tắt đa văn bản"],[116,"Độ tương đồng câu và các phương pháp tính độ tương đồng câu"],[117,"Độ tương đồng là một đại lượng được sử dụng để đo mối liên hệ giữa 2 đối tượng hoặc 2 đặc trưng"],[118,"Giá trị này thường nằm trong khoảng (-1;1) hoặc (0;1)"],[119,"Thông thường giá trị này càng lớn thì 2 đối tượng hay 2 đặc trưng đó càng giống nhau"],[120,"Việc đo độ tương đồng giữa 2 đối tượng, 2 đặc trưng chính là việc xác định 1 hàm ánh xạ mối quan hệ giữa 2 đối tượng, 2 đặc trưng đó sang một dạng số"],[121,"Ví dụ : trong mô hình không gian vector, độ đo cosin được sử dụng để tính độ tương đồng giữa 2 văn bản hoặc 2 câu trong văn bản"],[122,"Mỗi văn bản/ câu trong văn bản được biểu diễn thông qua một vector"],[123,"Độ tương đồng câu"],[124,"Bài toán tính độ tương đồng câu được phát biểu như sau: trong một văng bản d có n câu (s1, s2, s3.sn)"],[125,"Mục tiêu của bài toán là tìm ra một hàm S(si,sj) với i,j = 1,.,n sao cho S nằm trong khoảng (0,1)"],[126,"Hàm S(si,sj) được gọi là độ đo tương đồng giữa 2 câu si, sj"],[127,"Giá trị này càng cao thì sự giống nhau về ngữ nghĩa càng nhiều"],[128,"Độ tương đồng ngữ nghĩa là một giá trị tin cậy phản ánh mối quan hệ ngữ nghĩa giữa 2 câu"],[129,"Tuy nhiên, trên thực tế khó có thể lấy một giá trị có độ chính xác cao bởi ngữ nghĩa của một câu chỉ có thể được hiểu đầy đủ trong một ngữ cảnh cụ thể"],[130,"Các phương pháp tính độ tương đồng câu"],[131,"Hiện nay có nhiều phương pháp để đo độ tương đồng giữa 2 câu, tuy nhiên có thể đưa về 2 nhóm phương pháp chính : phương pháp thống kê (độ đo cosin, độ đo euclid.) và phương pháp xử lý ngôn ngữ tự nhiên(Sử dụng phân tích cú pháp, sử dụng mạng ngữ nghĩa đối với từ: wordnet corpus, Brown corpus,Penn Treebank.)"],[132,"Phương pháp thống kê: Phương pháp này độ chính xác chưa cao do việc thống kê sẽ không đảm bảo được sự tương đồng về ngữ ngữ"],[133,"Ngữ nghĩa của một câu hay một từ phải dựa vào hoàn cảnh cụ thể mới có thể xác định chính xác"],[134,"Tuy nhiên phương pháp này xử lý nhanh, tốn ít chi phí, có nhiều kết quả khả quan"],[135,"Phương pháp xử lý ngôn ngữ tự nhiên: Các phương pháp thuộc nhóm này sử dụng các tập dữ liệu chuẩn về ngôn ngữ để tìm ra mối quan hệ giữa các từ: Wordnet , Brown corpus, Penn Treebank"],[136,"Phương pháp này cho kết quả cao, tuy nhiên khó khăn của phương pháp này gặp phải là việc xây dựng kho dữ liệu đòi hỏi sự tốn kém về mặt chi phí, nhân lực và thời gian"],[137,"Đối với ngôn ngữ tiếng việt hiện tại chưa có corpus để sử dụng, vì vậy nhiều phương pháp được đề xuất thay thế Wordnet như : sử dụng phân tích chủ đề ẩn, sử dụng mạng ngữ nghĩa Wikipiedia"],[138,"Các phương pháp này tập trung vào việc bổ sung các thành phần ngữ nghĩa hỗ trợ cho độ đo tương đồng Cosine"],[139,"II.4.2.1"],[140,"Phương pháp tính độ tương đồng câu sử dụng độ đo cosine"],[141,"Trong phương pháp tính độ này, các câu sẽ được biểu diễn theo một mô hình không gian vector"],[142,"Mỗi thành phần trong vector chỉ đến một từ tương ứng trong danh sách mục từ chính"],[143,"Danh sách từ chính thu được từ quá trình tiền xử lý văn bản đầu vào, các bước tiền xử lý gồm: tách câu, tách từ, gán nhãn từ loại, loại bỏ những câu không hợp lệ(không phải là câu thực sự) và biểu diễn câu trên không gian vectơ"],[144,"Không gian vector có kích thước bằng số từ trong danh sách từ chính mỗi tọa độ của vector là độ quan trọng của từ đó trong câu"],[145,"Độ quan trọng của từ thứ j trong câu có thể được tính bằng TF (Term frequency), ISF(Inverse sentence frequency), hoặc kết hợp TF-ISF"],[146,"Trong đó: tfi,j : là tần suất xuất hiện từ i trong câu j( sự phổ biến của từ i trong câu j)"],[147,"isfi: tần số nghịch đảo câu trong văn bản(thể hiện độ hiếm của từ đó trong văn bản) Việc lấy maxlfreql,j để hạn chế sự ảnh hưởng của chiều dài câu đến giá trị tfi,j vì nếu ta tính tần suất xuất từ i trong câu theo công thức xác suất thông thường thì với những câu dài, số lượng từ trong câu sẽ lớn như vậy sẽ ảnh hưởng đến giá trị của tần số xuất hiện từ"],[148,"Freqi,j: số lần xuất hiện từ i trong câu j"],[149,"N: Số câu trong văn bản"],[150,"ni: Số câu chứa từ i trong văn bản"],[151,"Độ quan trọng của từ trong câu: Wi,j = tfi,j*isfi Phương pháp trọng số tf-isf đánh giá mức độ quan trọng của từ xét về mặt toàn cục kết hợp với trọng số cục bộ của cụm từ trong tài liệu"],[152,"Những từ thường xuất hiện trong một câu nhưng ít xuất hiện trong toàn bộ tài liệu thì có trọng số cao"],[153,"Với không gian biểu diễn văn bản là không gian vector , độ tương đồng giữa 2 câu được chọn là cosine góc giữa 2 vector tương ứng của 2 câu"],[154,"Vector biểu diễn 2 câu có dạng Sm = <w1,m,.,wt,m> Sn = <w1,n,.,wt,n> Độ tương đồng giữa 2 câu được tính theo công thức"],[155,"Lưu ý: Trước khi áp dụng công thức tính độ tương đồng ở trên phải tiến hành xét quan hệ ngữ nghĩa giữa các từ để đảm bảo độ chính xác của kết quả như : xét từ đồng nghĩa, từ đồng âm"],[156,"Trong phương pháp tính độ tương đồng câu người ta còn sử dụng một đặc trưng khác là vị trí từ trong câu để tính tương đồng"],[157,"Ví dụ : An đẩy Nam xuống sông"],[158,"Nam đẩy An xuống sông"],[159,"Nếu như xét độ tương đồng của câu dựa trên tần suất xuất hiện từ trong câu thì 2 câu này hoàn toàn tương đồng"],[160,"Nhưng xét về ngữ nghĩa thì 2 câu trên hoàn toàn không giống nhau"],[161,"Để hạn chế vấn đề này thì một đặc trưng khác của câu là vị trí từ trong câu đã được xem xét"],[162,"Các ước lượng độ tương đồng về thứ tự từ trong mỗi câu được xác định như sau: Nếu từ trong tập từ chung mà có trong câu thì từ đó sẽ có cùng thứ tự với từ trong câu đó"],[163,"Ngược lại, nếu từ trong tập từ chung mà không giống với từ nào trong câu thì thứ tự của nó sẽ bằng 0"],[164,"Áp dụng với 2 câu trên ta có vector vị trí từ như sau : R1 = <1,2,3,4,5> R2 = <3,2,1,4,5> Công thức tính độ tương đồng vị trí từ trong câu: Thường dùng kết hợp 2 độ đo trên để tính độ tương đồng cho toàn bộ câu II.4.2.2"],[165,"Phương pháp tính độ tương đồng câu sử dụng Wordnet corpus Phương pháp này được thực hiện dựa trên ngữ nghĩa và cú pháp của các từ trong câu"],[166,"Phương pháp này cho kết quả cao, tuy nhiên khó khăn của phương pháp này gặp phải là việc xây dựng kho dữ liệu đòi hỏi sự tốn kém về mặt chi phí, nhân lực và thời gian"],[167,"Đối với ngôn ngữ tiếng việt hiện tại chưa có corpus để sử dụng"],[168,"Mô hình của phương pháp: Mô hình dựa trên mô hình được đề xuất để tính toán độ tương đồng câu trong tiếng anh"],[169,"Phần II: CÁC KẾT QUẢ ĐẠT ĐƯỢC Phân tích và thiết kế hệ thống"],[170,"Giải pháp giải quyết bài toán"],[171,"Dựa vào cơ sở lý thuyết đã trình bày ở trên, Đồ án đề xuất giải quyết bài toán tóm tắt văn bản hướng truy vấn theo phương pháp tính độ tương đồng giữa các câu trong văn bản với câu truy vấn sử dụng độ đo cosine"],[172,"Quy trình thực hiện của hệ thống tóm tắt diễn ra theo 3 quá trình: Tiền xử lý, Xử lý, Sinh tóm tắt"],[173,"Cụ thể các quá trình sẽ được trình bày trong phần dưới"],[174,"Mô hình xử lý chi tiết"],[175,"Quá trình tiền xử lý: Trong quá trình này, hệ thống sẽ tiến hành xử lý văn bản đầu vào : tách câu , tách từ, loại bỏ từ dừng, vector hóa các câu trong văn bản"],[176,"Tách từ"],[177,"Trong tiếng Việt, dấu cách không mang ý nghĩa phân tách các từ mà chỉ mang ý nghĩa phân tách các âm tiết với nhau, vì vậy để làm việc với tiếng Việt thì bài toán tách từ là một trong những bài toán cơ bản và quan trọng bậc nhất"],[178,"Sau khi tách câu tôi sử dụng mã nguồn công cụ tách từ vnTokenizer 4.1.1c (04/08/2010) của nhóm tác giả Lê Hồng Phương[] để tách nội dung của văn bản và câu truy vấn thành các đơn vị từ"],[179,"(Mã nguồn của chương trình được public trên trang )"],[180,"Tìm danh từ riêng"],[181,"Các danh từ riêng trong văn bản thường rất quan trọng không thể bỏ đi ở các câu"],[182,"Tuy nhiên khi nói tới một danh từ riêng người ta không xét tới ngữ nghĩa của danh từ đó"],[183,"Vì thế, rất có thể danh từ riêng sẽ được nhận dạng nhầm trong bước loại bỏ từ dừng ( sẽ được trình bày ở phần ngay sau)"],[184,"Do đó trước khi loại bỏ các từ dừng trong văn bản thì phải thực hiện bước phát hiện danh từ riêng trước để tránh loại bỏ từ có ý nghĩa quan trọng"],[185,"Thêm nữa, ngôn ngữ tiếng Việt rất đa dạng, hiện tượng các từ đồng âm nhưng khác nhau về ý nghĩa rất phổ biến"],[186,"Việc phát hiện danh từ riêng sẽ tránh được việc đồng nhất các từ này với các từ không phải danh từ riêng nhưng đồng âm với nó"],[187,"Từ đấy việc tính toán trọng số từ trong câu sẽ chính xác hơn"],[188,"Ý tưởng xác định danh từ riêng: Tên riêng được xác định trong văn bản là từ có chữ cái đầu viết hoa"],[189,"Như vậy thuật toán xác định tên riêng có thể được đề xuất như sau: Đầu vào : Danh sách câu đã được tách từ, danh sách danh từ riêng (ban đầu rỗng)"],[190,"Đầu ra: Danh sách tên riêng có trong văn bản"],[191,"Thuật toán: B1: Khởi tạo danh sách chứa tên riêng trong văn bản"],[192,"B2: Duyệt tất cả các từ trong văn bản"],[193,"Nếu gặp từ có viết hoa đầu câu thì xét vị trí của từ đó có phải ở đầu câu hay không"],[194,"Nếu không ở đầu câu thì thêm vào danh sách tên riêng,đánh dấu từ đó là tên riêng, ở đầu câu thì bỏ qua"],[195,"(Ở bước này ta không xét các từ viết hoa đầu câu)"],[196,"B3: Duyệt lại văn bản từ đầu( Chỉ xét các từ đầu câu)"],[197,"Nếu từ đang xét nằm trong danh sách tên riêng đã tìm được ở bước trước thì đánh dấu từ đó là tên riêng"],[198,"Nếu không nằm trong danh sách thì xét từ đó có nhiều hơn 1 âm tiết hay không"],[199,"Nếu từ đó nhiều hơn 1 âm tiết thì xét đến âm tiết thứ 2 trong từ có viết hoa đầu hay không (Các danh từ riêng thì các âm tiết đều viết hoa chữ cái đầu.) B4: Lặp lại cho đến khi xét hết các từ trong văn bản"],[200,"Hình :Sơ đồ quá trình tìm danh từ riêng Loại bỏ từ dừng"],[201,"Từ dừng là từ thường xuất hiện nhiều trong văn bản, tuy nhiên không có nhiều ý nghĩa đối với nội dung của văn bản hiện tại Ví dụ : a lô, a ha, bao lâu, bây giờ, bấy giờ"],[202,"Ở bước này, từ danh sách câu, các từ đã được tách ta tiến hành loại bỏ từ dừng"],[203,"cách loại bỏ từ dừng chỉ đơn giản là tiến hành so khớp các từ trong văn bản với các từ lấy ra từ bộ từ điển từ dừng"],[204,"Như vậy vấn đề gặp phải ở bước này là việc xây dựng bộ từ điển từ dừng"],[205,"Bộ từ điển từ dừng tôi đã sử dụng cho chương trình được lấy từ trang"],[206,"Bộ từ điển này gồm 570 từ"],[207,"Từ điển được lưu trong file text, mỗi dòng xác định một từ dừng sắp xếp theo thứ tự bảng chữ cái tiếng việt"],[208,"Một số từ dừng trong từ điển"],[209,"Bảng : Mộ số từ dừng trong tiếng Việt Quá trình loại bỏ từ dừng: Thuật toán áp dụng loại bỏ từ dừng trên từng câu"],[210,"Đầu vào: Câu S (đã được tách từ) cần loại bỏ từ dừng, file từ điển lưu trữ các từ dừng Đâu ra: Câu S đã được loại bỏ hết các từ dừng"],[211,"Hình : Sơ đồ quá trình loại bỏ từ dừng Xử lý từ đồng nghĩa"],[212,"Các ngôn ngữ nói chung, tiếng Việt nói riêng, có rất nhiều từ phát âm khác nhau nhưng có ngữ nghĩa giống nhau, cùng nói về một sự vật hiện tượng nào đó, các từ này có thể quy về cùng một từ trong văn bản"],[213,"Như vậy nếu ta không xử lý các từ đồng nghĩa thì các này sẽ ảnh hưởng đến độ quan trọng của từ trong câu"],[214,"Các từ đồng nghĩa sẽ được tính là nhiều từ, do vậy độ quan trọng của từ sẽ giảm, kết quả tính toán sẽ bị sai lệch không như mong muốn"],[215,"Phương pháp xác định từ đồng nghĩa cũng gặp nhiều khó khăn, do từ đồng nghĩa không phải là những từ trùng nhau hoàn toàn về nghĩa"],[216,"Chúng sẽ có những dị biệt nào đó bên cạnh sự tương đồng"],[217,"những từ đồng nghĩa với nhau không nhất thiết phải tương đương với nhau về số lượng nghĩa, tức là các từ trong một nhóm đồng nghĩa không nhất thiết phải có số lượng nghĩa bằng nhau từ này có thể có một hoặc hai nghĩa, từ khác có thể có ít hoặc nhiều nghĩa hơn"],[218,"Các từ đồng nghĩa chỉ tương đồng ở một nghĩa nào đó của chúng"],[219,"Với khó khăn nêu trên, để tìm các từ đồng nghĩa trong văn bản và câu truy vấn, hệ thống sử dụng bộ từ điển đồng nghĩa"],[220,"Bộ từ điển đồng nghĩa này gồm 7734 nhóm từ đồng nghĩa được thu thập từ trang tra từ điển"],[221,"từ điển được lưu trong file text mỗi dòng trong file có 3 nội dung: từ đang xét, nhóm từ từ đồng nghĩa với từ đang xét, nhóm từ trái nghĩa"],[222,"Mỗi nhóm từ trong 1 dòng được phân cách bởi dấu ;"],[223,"Một số từ đồng nghĩa tiếng việt"],[224,"Giải thuật tìm từ đồng nghĩa Đầu vào: chuỗi đã được tách từ"],[225,"Đầu ra: Danh sách câu với các từ đã được đánh dấu vào các nhóm từ tương đồng(các từ cùng nhóm sẽ có cùng 1 chỉ số đánh dấu từ đồng nghĩa)"],[226,"Sau bước này sẽ thu được danh sách các từ đã được đồng nhất.Như vậy việc tính toán độ tương đồng giữa các câu trong văn bản và câu truy vấn sẽ trở nên dễ dàng và chính xác hơn"],[227,"Vector hóa các câu trong văn bản"],[228,"Qua các bước xử lý ở trên ta đã có danh sách câu đã loại bỏ từ dừng và đồng bộ hóa các từ đồng nghĩa trong văn bản với từ trong câu tuy vấn.Tiếp theo ta phải tiến hành vector hóa các câu trong văn bản, mỗi câu trong văn bản được biểu diễn dưới dạng vector"],[229,"Mỗi vector có số chiều chính là số từ trong văn bản và câu truy vấn, tại vị trí mà từ của câu không xuất hiện trong danh sách từ chung thì sẽ là bằng 0, còn lại là trọng số của từ được tính theo công thức tính trọng số từ đã được nêu ở trên"],[230,"Ví dụ: Một đoạn (đại diện cho văn bản) gồm 2 câu: Con đường nào không thể tiếp tục thì hãy từ bỏ"],[231,"Có nhiều con đường để chúng ta bước tiếp"],[232,"Tập từ chung trong văn bản : Con đường, nào, không thể, tiếp tục, thì hãy, từ bỏ, có nhiều, để , chúng ta, bước"],[233,"Như vậy vector của câu 1 Con đường nào không thể tiếp tục thì hãy từ bỏ {x,x,x,x,x,x,0,0,0,0} Vector của câu 2 Có nhiều con đường để chúng ta bước tiếp {x,0,0,x,0,0,x,x,x,x} Ở đó : x là từ trong câu đó"],[234,"Quá trình xử lý"],[235,"Trong quá trình này hệ thống sẽ tiến hành tính toán các trọng số từ, độ tương đồng giữa các câu để làm cơ sở cho bước việc sinh văn bản tóm tắt"],[236,"Tính trọng số từ"],[237,"Việc tính trọng số của từ là rất quan trọng trong bài toán này vì trọng số của từ chính là độ quan trọng của từ đó trong văn bản"],[238,"Ở đây, trọng số của một từ trong câu được tính toán thông qua sự kết hợp 2 độ đo tf, isf Wi,j = tfi,j* isfi Trong đó : wi,j là trọng số của từ thứ i trong câu j"],[239,"tfi,j: tần số xuất hiện từ thứ i trong câu j (độ phổ biến của từ thứ i trong câu j)"],[240,"isfi: tần suất xuất hiện nghịch đảo của từ thứ I trong văn bản( độ hiếm của từ thứ i trong văn bản)"],[241,"Như vậy, theo công thức trên thì một từ được cho là quan trọng nếu nó xuất hiện nhiều trong câu nhưng lại xuất hiện ít trong văn bản"],[242,"Thuật toán tính trọng số của một từ (calWeight(word,S,Ls)) Đầu vào : từ cần tính trọng số, câu chứa từ đang xét, danh sách câu trong văn bản"],[243,"Đầu ra : trọng số của từ"],[244,"Tính trọng số của tất cả các từ trong văn bản"],[245,"Đầu vào: danh sách câu trong văn bản (Ls)"],[246,"Kết quả: tất cả các từ trong văn bản đều được tính trọng số"],[247,"Tính độ tương đồng giữa với câu truy vấn"],[248,"Sau khi tiền xử lý, các câu trong văn bản sẽ được biểu diễn dưới dạng vector, nên ta sẽ dùng độ đo cosine để tính độ tương đồng giữa 2 câu"],[249,"Đặc biệt là câu trong văn bản với câu truy vấn"],[250,"Để dễ thực hiện ta xem câu truy vấn là 1 câu trong văn bản"],[251,"câu này sẽ ở vị trí bắt đầu văn bản"],[252,"Vì trong kết quả tóm tắt không chứa những câu có ý nghĩa giống nhau, nên để loại bỏ các câu giống nhau trong văn bản tóm tắt cũng phải sử dụng độ tương đồng giữa các câu đó"],[253,"Do vậy ở bước này ta sẽ tính độ tương đồng giữa tất cả các câu với nhau"],[254,"Sơ đồ giải thuật tính độ tương đồng giữa 2 câu"],[255,"Đầu vào: các vector trọng số của 2 câu, kích thước vector"],[256,"Đầu ra: độ tương tự giữa 2 câu"],[257,"Ngoài ra, Đặc trưng vị trí từ trong câu cũng là 1 khía cạnh để đánh giá độ tương đồng giữa 2 câu Khi đó, độ tương đồng giữa 2 câu được tính theo công thức"],[258,"Sim(S1,S2) = Ss + (1-) Sr Ss : độ tương đồng giữa 2 câu theo độ đo cosine Sr: độ tương đồng giữa 2 câu theo vị trí từ"],[259,"Quá trình sinh kết quả"],[260,"Sau quá trình xử lý, độ tương đồng giữa các câu trong văn bản với câu truy vấn, và độ tương tự giữa các câu trong văn bản với nhau đã được xác định"],[261,"Từ đó ta sẽ xác định các câu để đưa vào bản tóm tắt dựa trên kết quả đó"],[262,"Yêu cầu của bản tóm tắt: Nội dung tóm tắt phải phù hợp với truy vấn"],[263,"Các câu trong tóm tắt không được trùng nhau"],[264,"Độ dài bản tóm giới hạn"],[265,"Như vậy, để đảm bảo yêu cầu của bản tóm tắt thì ta phải xác định các ngưỡng để lựa chọn các câu vào văn bản tóm tắt: : Ngưỡng để xác định độ tương đồng tối thiểu của câu truy vấn với các câu trong văn bản gốc"],[266,"Các câu trong văn bản gốc có độ tương đồng với câu truy vấn phải lớn hơn mới phù hợp để đưa vào văn bản tóm tắt"],[267,": Ngưỡng xác định độ tương đồng lớn nhất giữa các câu trong văn bản tóm tắt"],[268,"2 câu trong văn bản tóm tắt được coi là trùng nhau nếu độ tương đồng giữa chúng lớn hơn hoặc bằng"],[269,"n : Ngưỡng xác định kích thước văn bản tóm tắt"],[270,"có nhiều tiêu chí để lựa chọn giá trị của n, Ở đây tôi chọn n là số từ tối đa trong bản tóm tắt"],[271,"Một câu sẽ được đưa vào bản tóm tắt nếu như sau khi thêm câu đó vào số từ trong bản tóm tắt không vượt quá n"],[272,"Ý tưởng chung để xác định các câu đưa vào bản tóm tắt"],[273,"Sắp xếp các câu trong văn bản theo thứ tự giảm dần độ tương đồng với câu truy vấn"],[274,"Lấy các câu theo thứ tự từ trên xuống dưới sao cho đảm bảo các yêu cầu của bản tóm tắt"],[275,"Sắp xếp lại các câu trong bản tóm tắt theo thứ tự xuất hiện của nó trong văn bản gốc"],[276,"Tuy nhiên việc lựa chọn câu theo quy trình trên chưa thực sự cho kết quả chính xác vì trong trường hợp có nhiều câu tương tự cùng có độ đo lớn với câu truy vấn mà có 1 câu nói lên nội dung chính còn các câu còn lại là diễn giải cho câu đó thì sẽ xảy ra trường hợp câu diễn giải có độ tương đồng với câu truy vấn cao hơn câu có nội dung chính"],[277,"Như vậy khi lấy câu theo quy trình trên câu có nội dung chính sẽ bị loại bỏ do có độ tương đồng cao với câu đã có trong tóm tắt"],[278,"Ví dụ : Truy vấn từ người dùng là Món ăn truyền thống của dân tộc Mường Trong văn bản gốc có 2 câu tương tự có độ tương đồng cao với truy vấn là Món ăn có vị đắng là món ăn người Mường rất ưa thích Măng đắng, hoa, lá, quả đu đủ không chỉ là món ăn thường ngày của người Mường mà còn là món ăn để thờ phụng"],[279,"Như vậy câu thứ 2 được lựa chọn sẽ không tóm tắt được hết ý"],[280,"Để hạn chế được trường hợp trên thì trong đồ án áp dụng một thay đổi là trước khi chọn câu vào bản tóm tắt ta sẽ tiến hành gom nhóm cho các câu"],[281,"Mỗi nhóm bao gồm các câu có độ tương đồng cao với nhau"],[282,"Sắp xếp các câu trong nhóm theo thứ tự xuất hiện của nó trong văn bản"],[283,"Khi chọn câu vào văn bản sẽ chọn mỗi duyệt lần lượt trong các nhóm, mỗi nhóm lấy 1 câu"],[284,"Lặp lại cho đến khi số lượng từ trong văn bản thỏa mãn"],[285,"(Ý tưởng của phương pháp này dựa trên ý tưởng diễn dịch"],[286,"Câu mang ý chính của một đoạn văn bản diễn dịch sẽ nằm ở đầu đoạn)"],[287,"Chi tiết kết quả thực hiện, cài đặt và thử nghiệm"],[288,"Giả thiết ban đầu"],[289,"Nội dung của văn bản đầu vào phải phù hợp với câu truy vấn"],[290,"Văn bản gốc được lưu dưới dạng file text (.txt), mã hóa unicode"],[291,"Truy vấn từ người dùng trọng tâm đến nội dung tóm tắt, hạn chế các từ không"],[292,"mang nhiều ý nghĩa"],[293,"Mục tiêu: Đưa ra nội dung tóm tắt của văn bản theo hướng truy vấn từ người dùng"],[294,"Công cụ lựa chọn để giải quyết vấn đề"],[295,"Công cụ xây dựng chương trình demo: Ngôn ngữ sử dụng (Java): Java là ngôn ngữ lập trình mới do một nhóm nhà khoa học của hãng Sun Microsytem tạo nên"],[296,"Làm việc với Java sẽ rất thuận tiện do các ưu điểm của ngôn ngữ này"],[297,"Java đơn giản nên thời gian tìm hiểu ngắn"],[298,"Java hướng đối tượng nên chương trình rất linh hoạt và có thể tái sử dụng nhiều lần"],[299,"Java rất mạnh: bộ nhớ được giải phóng một cách tự động nhờ đó có thể tránh được những hư hỏng về bộ nhớ và đảm bảo tính toàn vẹn dữ liệu"],[300,"Java có tính độc lập với cấu trúc, vì vậy không phụ thuộc vào hệ máy và ( loại máy và hệ điều hành)"],[301,"Lý do đặc biệt khi chọn Java làm ngôn ngữ xây dựng chương trình demo là có nhiều mã nguồn có thể tái sử dụng cho việc tiền xử lý tiếng việt"],[302,"Ví dụ chương trình tách từ tiếng Việt"],[303,"IDE: netbean"],[304,"IDE phổ biến để viết chương trình bằng ngôn ngữ Java, thân thiện, dễ sử dụng"],[305,"Kết quả thực nghiệm"],[306,"Phần này sẽ trình bày kết quả thực nghiệm của chương trình với một đoạn văn bản ngắn, và đưa ra các kết quả tính toán là giải thích tại sao cách chương trình đưa ra kết quả cuối cùng, đưa ra kết quả của văn bản mẫu"],[307,"Giao diện chương trình"],[308,"Chương trình gồm 3 giao diện : giao diện chính, giao diện hiển thị kết quả đánh giá và giao diện hiển thị song song nội dung của bản tóm tắt tay và nội dung của bản tóm tắt tự động sinh ra bởi hệ thống Giao diện chính của chương trình"],[309,"Dữ liệu vào 1: cung cấp câu truy vấn từ người dùng"],[310,"Dữ liệu này không được để trống"],[311,"2: đường dẫn đền file gốc cần tóm tắt"],[312,"3: Nội dung văn bản cần tóm tắt"],[313,"Chức năng và kết quả xử lý"],[314,"4: Chức năng xử lý văn bản đầu vào đưa ra bản tóm tắt hiển thị ở 8"],[315,"5: Lưu văn bản tóm tắt(tên bản tóm tắt trùng với tên của văn bản gốc nhưng được đặt ở thư mục tóm tắt.) 6: Xem kết quả đánh giá: chức năng này sẽ mở giao diện đánh các kết quả tóm tắt đã thực hiện"],[316,"7: Số lượng từ giới hạn trong bản tóm tắt"],[317,"8: Lưu kết quả tóm tắt chương trình thực hiện tóm tắt văn bản gốc"],[318,"Giao diện đánh giá kết quả tóm tắt Việc đánh giá kết quả tóm tắt dựa trên độ đo ROUGE với các tiêu chí Recall (R), Precision(P), Fscore(F)"],[319,"Chỉ các văn bản (trong thư mục document) có đầy đủ bản tóm tắt tự động(trong thư mục auto_summation) và tóm tắt tay (trong thư mục hand_summation) mới có kết quả đánh giá hiển thị trên giao diện"],[320,"Giao diện hiển thị song song nội dung tóm tắt tay và tóm tắt tự động Thông qua giao diện này người dùng có thể nhìn thấy trực quan nội dung của văn bản tóm tắt tự động và nội dung của văn bản tóm tắt tay"],[321,"Cách sử dụng: Khi giao diện chính được mở: người dùng sẽ chọn file cần tóm tắt thông qua nút Open file và tìm ra 1 file bất kì có định dạng phần mở rộng .txt, nội dung của file sẽ được tải lên khu vực File content làm nội dung tóm tắt"],[322,"Hoặc người dùng có thể patse trực tiếp đoạn văn bản cần tóm tắt vào khu vực File content (Tuy nhiên, trong trường hợp này người dùng sẽ không lưu được văn bản vào file vì không có file gốc để so sánh)"],[323,"Sau khi chọn file cần tóm tắt người dùng phải nhập yêu cầu nội dung quan tâm vào phần Query"],[324,"Nội dung query càng sát với yêu cầu người dùng thì kết quả tóm tắt càng phù hợp với mong muốn của người dùng"],[325,"Khi đã đảm bảo các yêu cầu cơ bản query, file content đã có nội dùng người dùng sẽ tạo tóm tắt thông qua nút chức năng Sumarize"],[326,"Kết quả tóm tắt sẽ hiển thị ở khu vực Sumary"],[327,"Có thể thay đổi độ dài bản tóm tắt bằng cách lựa chọn số từ"],[328,"Chức năng Save được sử dụng khi người dùng muốn lưu lại bản tóm tắt vừa tạo (tên file tóm tắt được tạo mặc định là tên file gốc và lưu tại thư mục auto_summation)"],[329,"Chức năng Evaluation để xem đánh giá của bản tóm tắt đã tạo"],[330,"Để sử dụng chức năng này người dùng phải tạo bản tóm tắt tay của văn bản gốc vừa tóm tắt (tên file trùng với tên văn bản gốc) và đặt tại thư mục hand_summation"],[331,"Kết quả ví dụ"],[332,"Sau đây là kết quả tóm tắt 1 ví dụ (đơn giản) mẫu và giải thích cách chương trình tạo ra văn bản tóm tắt Văn bản gốc: Bất cứ ngôi đình nào cũng thờ Thành hoàng của làng - đây là yếu tố bắt buộc"],[333,"Ngoài thành hoàng làng, tùy theo mỗi ngôi đình làng có thể thờ các vị thần, thánh khác do mỗi làng tôn thờ, hoặc việc thờ cúng các vị thần theo sắc phong của Nhà vua, tất cả được rước vào đình thành một tập thể siêu thần, thành một sức mạnh vô hình, tạo niềm tin, niềm hy vọng của làng xã Việt Nam"],[334,"Việc vinh danh, tôn thờ những người có công to lớn đối với làng cùng với vị trí của nơi đặt đình làng và cách thức bày biện nội thất ngôi đình đã làm toát lên vai trò đây là nơi quan trọng bảo vệ, che chở cho mỗi làng trước các biến cố của tự nhiên và đời sống xã hội"],[335,"Vào ngày lễ tết, nhân dân trong làng tới đình thắp hương tế lễ, cầu mong thành hoàng làng và trời đất phù giúp mưa thuận gió hoà để mùa màng gặt hái thuận tiện và có nhiều phúc lành"],[336,"Đây cũng là dịp để tưởng niệm công tích của các vị thần và dịp này người ta tổ chức hội đình"],[337,"Hầu hết các làng, xóm của người Mường đều có Đình, đình thờ thành hoàng vị thánh được người Mường tôn vinh đó là người có công khai phá ruộng nương, chỉ bảo cho người dân làm ăn"],[338,"Bên cạnh đó người Mường thường thờ Thánh Tản Viên, họ tôn kính coi Thánh Tản Viên là người có thể đi mây về gió, ban phúc trừ tà"],[339,"Trong 82 di tích đình của tỉnh Hòa Bình có tới 20 đình thờ Tản Viên Sơn Thánh, 36 đình không rõ tên các vị thần được thờ (do nhiều nguyên nhân), 31 đình còn lại là thờ thành hoàng địa phương và các thiên thần, nhân thần được các đời vua phong sắc"],[340,"Đình làng ở Hòa Bình có thể được chia ra làm 3 loại cơ bản: Đình của người Mường, Đình của người Kinh và Đình giao thoa giữa hai dân tộc"],[341,"Truy vấn từ người dùng: Nét văn hóa đình làng Hòa Bình"],[342,"Trọng số của các từ trong truy vấn"],[343,"Độ tương đồng của các câu với câu truy vấn Theo kết quả độ tương đồng với câu truy vấn ở trên 4 câu bị loại bỏ (do độ tương đồng với câu truy vấn < 0.3)"],[344,"Như vậy có 5 câu 8,7,1,5,2 thỏa mãn độ tương đồng với câu truy vấn >0.3"],[345,"Các câu này được gom thành 2 nhóm: Nhóm 1 gồm các câu 7,8"],[346,"Nhóm 2 gồm các câu 1,2,5"],[347,"Thực hiện việc chọn câu bằng cách duyệt các nhóm mỗi lần duyệt lấy 1 câu trong nhóm và thực hiện lặp lại cho tới khi đủ số từ trong bản tóm tắt"],[348,"Việc lựa chọn kết quả vào tóm tắt sẽ dựa trên độ tương đồng với câu truy vấn mà đã được tính toán ở trên"],[349,"1 câu được lựa chọn vào bản tóm tắt phải thỏa mãn : độ tương đồng nhỏ nhất với câu truy vấn (ở đây được lựa chọn là >0.2), độ tương đồng lớn nhất với các câu đã có trong bản tóm tắt (<0.9), số lượng từ trong bản tóm tắt phải nhỏ hơn ngưỡng đã chọn (<120 từ)"],[350,"Dựa vào các tiêu chí trên hệ thống lựa chọn được câu đưa vào bản tóm tắt Kết quả tóm tắt: Bất cứ ngôi đình nào cũng thờ Thành hoàng của làng - đây là yếu tố bắt buộc ."],[351,"Ngoài thành hoàng làng , tùy theo mỗi ngôi đình làng có thể thờ các vị thần , thánh khác do mỗi làng tôn thờ , hoặc việc thờ cúng các vị thần theo sắc phong của Nhà vua , tất cả được rước vào đình thành một tập thể siêu thần , thành một sức mạnh vô hình , tạo niềm tin , niềm hy vọng của làng xã Việt Nam ."],[352,"Trong 82 di tích đình của tỉnh Hòa Bình có tới 20 đình thờ Tản Viên Sơn Thánh , 36 đình không rõ tên các vị thần được thờ , 31 đình còn lại là thờ thành hoàng địa phương và các thiên thần , nhân thần được các đời vua phong sắc ."],[353,"Đình làng ở Hòa Bình có thể được chia ra làm 3 loại cơ bản : Đình của người Mường , Đình của người Kinh và Đình giao thoa giữa hai dân tộc ."],[354,"Đánh giá"],[355,"Mô tả bộ dữ liệu"],[356,"Bộ dữ liệu gồm 50 tài liệu mẫu là các bài báo được thu thập từ các trang web tin tức bởi các bạn trong nhóm đồ án thu thập và tạo văn bản tóm tắt tay"],[357,"Tên các bản tóm tắt được đặt trùng với tên văn bản gốc"],[358,"Độ dài các văn bản từ 400-1200 từ"],[359,"các văn bản tóm tắt tay có độ dài xấp xỉ 120 từ"],[360,"Câu truy vấn mặc định được lấy từ tiêu đề bài báo"],[361,"Độ đo ROUGE"],[362,"Đồ án sử dụng độ đo Rouge để đánh giá độ chính xác của tóm tắt"],[363,"ROUGE là một hệ thống đánh giá tóm tắt tự động mà dựa trên tỉ lệ tóm tắt dựa trên đặc điểm của sự gắn kết và hàm lượng thông tin chứa trong bản tóm tắt tự động"],[364,"Nó nhận bản tóm tắt như đầu vào"],[365,"Độ đo ROUGE được xác nhận là một công cụ đánh giá tốt cho tóm tắt đa văn bản với sự tập trung vào nội dung trùng lặp"],[366,"ROUGE không phải là một công cụ đánh giá bao hàm toàn diện"],[367,"ROUGE-2, ROUGE-L, ROUGE-W, ROUGE SU4 tốt cho tóm tắt đơn van bản trong khi ROUGE-1 làm việc tốt cho tóm tắt đa văn bản"],[368,"Kết quả đánh giá"],[369,"Chất lượng của bản tóm tắt sinh ra từ hệ thống được đánh giá qua độ đo ROUGE với số GRAM n =4, với ngưỡng độ dài yêu cầu của bản tóm tắt là 120 từ,Kết quả đánh giá nằm trong khoảng từ 0.3 đến 0.8"],[370,"Độ chính xác của hệ thống càng cao khi số từ giới trong bản tóm tắt càng cao"],[371,"Bản đánh giá kết quả khi không thực hiện gom nhóm trong quá trình sinh tóm tắt"],[372,"Bảng đánh giá kết quả khi thực hiện gom nhóm Từ kết quả thực nghiệm, có thể thấy rằng mô hình tóm tắt sử dụng cho kết quả khả quan mặc dù các câu trả về vẫn chưa thể hiện ngữ nghĩa, chưa có sự gắn kết giữa các câu trong tóm tắt"],[373,"Theo 2 kết quả trên ta thấy việc áp dụng gom nhóm câu trong khi tạo kết quả tóm tắt mang lại hiệu quả tốt hơn cho hệ thống"],[374,"Kết quả đánh giá trung bình khi thực hiện với 50 văn bản gốc Phần III: KẾT LUẬN Đánh giá ưu nhược điểm và khả năng ứng dụng của hệ thống"],[375,"Ưu điểm"],[376,"Hệ thống cho kết quả tương đối chính xác, thời gian xử lý nhanh, không mất thời gian xây dựng kho dữ liệu từ điển"],[377,"Nhược điểm"],[378,"Hệ thống chưa xử lý được về mặt ngữ nghĩa"],[379,"Chưa giải quyết được tính dễ đọc của kết quả đầu ra, kết quả đầu ra không liền mạch, các câu chưa có sự liên kết với nhau Độ chính xác của kết quả phụ thuộc nhiều vào việc xác định câu truy vấn, độ dài văn bản"],[380,"Khả năng ứng dụng"],[381,"Hệ thống có thể áp dụng tóm tắt các văn bản ngắn, trung bình như: các bài báo, tin tức trên internet"],[382,"Nội dung của văn bản gốc ko tập trung theo từng đoạn của văn bản"],[383,"Hệ thống được xây dựng để hỗ trợ các bộ máy tìm kiếm thông tin mà có kết quả trả về dưới dạng văn bản"],[384,"Đánh giá công việc"],[385,"Đồ án nghiên cứu giải quyết bài toán tóm tắt hướng truy vấn trên phạm vi đơn văn bản bằng phương pháp tính độ tương đồng với câu truy vấn"],[386,"và nâng cao mức độ chính xác cho phương pháp bằng cách gom nhóm các câu tương đồng trong văn bản"],[387,"Việc gom nhóm đã tránh được sự dư thừa trong bản tóm tắt"],[388,"Kết quả thử nghiệm cho thấy khi hệ thống đưa ra tóm tắt bằng cách gom nhóm các câu tương đồng trong văn bản đạt kết quả cao hơn so với khi chỉ sử dụng độ tương đồng với câu truy vấn"],[389,"Tuy nhiên, hệ thống vẫn còn những hạn chế chưa khắc phục được Chưa áp dụng được ngữ nghĩa"],[390,"Bản tóm tắt chưa thật phù hợp với câu truy vấn về mặt ngữ nghĩa"],[391,"Chưa giải quyết được tính dễ đọc của bản tóm tắt.Nội dung của bản tóm tắt còn rời rạc , chưa liên kết giữa các câu với nhau, đôi khi còn tồn tại những câu không rõ nghĩa"],[392,"Định hướng phát triển và hoàn thiện các kết quả đạt được"],[393,"Xử lý đồng tham chiếu(đặc biệt là đồng tham chiếu đại từ) để xác định được chính xác các đại từ trong câu tóm tắt"],[394,"Xây dựng bộ từ điển corpus tiếng việt, từ đó có thể tăng ngữ nghĩa cho bản tóm tắt"],[395,"Áp dụng các kĩ thuật phân tích xử lý văn bản tiếng việt nhằm nâng cao chất lượng hệ thống: gán nhãn từ loại, phân tích cú pháp,"],[396,"Tài liệu tham khảo"],[397,"A"],[398,"P"],[399,"Siva kumar, Dr"],[400,"P"],[401,"Premchand,Dr"],[402,"A"],[403,"Govardhan"],[404,"\"Query-Based Summarizer Based on Similarity of Sentences and Word Frequency.\" Department of Computer Science Engineering, Osmania University, Hyderabad, India"],[405,"Ahmed A"],[406,"Mohamed, Sanguthevar Rajasekaran"],[407,"\"Query-Based Summarization Based on Document Graphs .\" Department of Computer Science & Engineering, University of Connecticut"],[408,"Đỗ Thị Thanh Nga"],[409,"\"Tính toán độ tương tự ngữ nghĩa văn bản dựa vào độ tương tự giữa từ với từ.\" Luận văn thạc sĩ, Đại học Quốc Gia Hà Nội - Trường đại học Công Nghệ, 2010"],[410,"Hoàng Minh Hiền"],[411,"\"Độ tương đồng ngữ nghĩa giữa 2 câu và ứng dụng trong tóm tắt văn bản.\" Khóa luận tốt nghiệp, Đại học Quốc Gia Hà Nội, 2008"],[412,"Lapalme, Olga Feiguina and Guy"],[413,"\"Query-based summarization of customer reviews.\" Departement dinformatique et de recherche operationnelle, Universite de Montreal"],[414,"Lin, Chin- Yew"],[415,"\"ROUGE: A Package for Automatic Evaluation of Summaries.\" Information Sciences Institute, University of Southern California"],[416,"Mariana Damova, Ivan Koychev"],[417,"\"Query-Based Summarization: A survey.\" Faculty of Mathematics and Informatics, University of Sofia, Bulgaria"],[418,"Lưu Tuấn Anh"],[419,"\"Kiến thức cơ bản về xử lý ngôn ngữ tự nhiên.\" http://viet.jnlp.org/kien-thuc-co-ban-ve-xu-ly-ngon-ngu-tu-nhien, 25/03/2013"],[420,"Nguyễn Minh Thành, \"Text  Summarization.\"  https://sites.google.com/site/trangmonhocitc/text-summarization,    15/03/2013"],[421,""]],"downloaded":true,"m":[-1,-1],"n":"48.txt","o":"http://202.191.57.85:8000/InternetData/Data/LVTN/48.docx\r"},{"saved_path":"temp/20101559_Nguyen_Xuan_Hoa_1495982153177.txt","r":0,"s":[],"t":"\n \r\n\r\nTrong thời đại phát triển bùng nổ của Internet cũng như sự phát triển vượt bậc của \r\n\r\ncông nghệ thông tin. Internet giống như một thế giới ảo, thế giới giúp con người cũng như \r\n\r\nmáy tính, kết nối và chia sẻ thông tin với nhau. Mỗi ngày, một lượng vô cùng lớn các bài \r\n\r\nviết, hình ảnh hay video về mọi lĩnh vực của cuộc sống, được con người chia sẻ trên các \r\n\r\ntrang báo, diễn đàn hay mạng xã hội. Giữa một thế giới thông tin đa dạng, phong phú \r\n\r\nkhông ngừng phát triển như vậy, vấn đề làm sao để lấy được những thông tin cần thiết, cho \r\n\r\ncon người hoặc chương trình máy tính ngày càng trở nên khó khăn hơn. Để giải quyết vấn \r\n\r\nđề này ta nghĩ ngay đến lĩnh vực Khai phá dữ liệu. Mục đích của khai phá dữ liệu là tìm ra \r\n\r\nnhững thông tin cần thiết, bao quát, cỗi lõi và quan trọng nhất từ dữ liệu giúp người sử \r\n\r\ndụng tiếp cận nhanh và hiệu quả hơn. Khai phá dữ liệu văn bản, là một trong những hướng \r\n\r\nnghiên cứu thú vị về lĩnh vực khai phá dữ liệu, mà tóm tắt văn bản tự động là một bài toán \r\n\r\ncơ bản và quan trọng. \r\n\r\nĐồ án này trình bày phương pháp tóm tắt văn bản tiếng Anh sử dụng TextRank và \r\n\r\ncác độ đo tương đồng. \r\n\r\nBố cục của Đồ Án như sau : \r\n\r\n Chương 1: Tổng quan bài toán tóm tắt văn bản \r\n\r\nChương này trình bày tổng quan về bài toán tóm tắt văn bản tự động, tóm \r\n\r\ntắt văn bản sử dụng phương pháp trích rút. \r\n\r\n Chương 2: Tóm tắt văn bản hướng trích rút \r\n\r\nChương này trình bày hướng tiếp cận, thách thức của bài toán tóm tắt văn \r\n\r\nbản hướng trích rút \r\n\r\n Chương 3: Tóm tắt văn bản tiếng Anh sử dụng TextRank và các độ đo tương đồng \r\n\r\nChương này trình bày chi tiết về TextRank và các độ đo tương đồng để giải \r\n\r\nquyết bài toán tóm tắt văn bản. \r\n\r\n Chương 4: Kết quả thử nghiệm, đánh giá \r\n\r\nTrình bày về bộ dữ liệu thử nghiệm, các kết quả thử nghiệm và đánh giá kết \r\n\r\nquả tóm tắt trích rút văn bản tiếng Anh của TextRank và các độ đo tương \r\n\r\nđồng sử dụng trong TextRank. \r\n\r\n Chương 5: Kết luận \r\n\r\n Tổng kết lại đưa ra ưu điểm, hạn chế và nguyên nhân cùng hướng phát triển \r\n\r\ntrong tương lai \r\n\r\nSau cùng là danh mục các tài liệu tham khảo trong quá trình thực hiện Đồ \r\n\r\nán này. \r\n\r\n \r\n\r\n\r\n\r\n\r\n \r\n\r\nLời cám ơn \r\n\r\nLời đầu tiên, em xin gửi lời cảm ơn chân thành đến các thầy cô trong trường \r\n\r\nĐại học Bách Khoa Hà Nội nói chung, các thầy cô trong viện Công nghệ thông tin \r\n\r\nvà Truyền thông nói riêng đã truyền đạt cho chúng em những kiến thức, kỹ năng \r\n\r\nquý giá trong suốt quá trình học tập tại trường. \r\n\r\nEm xin gửi lời cảm ơn chân thành đến cô giáo Nguyễn Kim Anh, giảng viên \r\n\r\nBộ môn Hệ thống thông tin - Viện Công nghệ thông tin & Truyền thông đã giúp đỡ, \r\n\r\nhướng dẫn tận tình cho em trong quá trình học tập và làm Đồ án tốt nghiệp này. \r\n\r\nCuối cùng, em xin chân thành gửi lời cảm ơn tới gia đình, bạn bè đã quan \r\n\r\ntâm và động viên tinh thần cho em rất nhiều trong quá trình làm Đồ án tốt nghiệp. \r\n\r\n \r\n\r\n \r\n\r\n Hà Nội, tháng 5 năm 2015 \r\n\r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\nNguyễn Xuân Hòa \r\n\r\nLớp Công nghệ thông tin 2 K55 \r\n\r\nĐại học Bách khoa Hà Nội \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n  \r\n\r\n\r\n\r\n\r\n \r\n\r\n \r\n\r\nMục Lục \r\n\r\n3.4. Tóm tắt văn bản sử dụng giải thuật TextRank và các độ đo tương đồng ... 24 \r\n\r\nDANH MỤC CÁC HÌNH \r\n\r\nDANH MỤC CÁC BẢNG, BIỂU ĐỒ \r\n\r\n\r\n\r\nDANH MỤC CÁC TỪ VIẾT TẮT VÀ THUẬT NGỮ \r\n\r\nTừ viết tắt, thuật ngữ Giải thích \r\n\r\nDUC Document Understanding Conference \r\n\r\nROUGE Recall-Oriented Understudy for Gisting \r\n\r\nEvaluation \r\n\r\nSimilarity Độ tương đồng \r\n\r\nTF (term frequency) Tần số xuất hiện của một từ \r\n\r\nISF (Inverse sentence frequency) Tần số nghịch của một từ trong văn bản \r\n\r\nNVĐA Người viết Đồ án \r\n\r\nCNTT&TT Công nghệ thông tin và Truyền thông \r\n\r\n \r\n\r\n  \r\n\r\n \r\n\r\n \r\n\r\n\r\n\r\n\r\n \r\n\r\nMở đầu \r\n\r\nNgày nay, công nghệ thông tin đang phát triển rất mạnh mẽ, kèm theo với nó \r\n\r\nlà sự bùng nổ của internet đã mang đến cho con người số lượng thông tin khổng lồ.  \r\n\r\nLượng thông tin khổng lồ đó bao gồm các văn bản, hình ảnh, video...nó đã và đang \r\n\r\nmang lại lợi ích rất lớn cho con người, tuy nhiên sự khổng lồ đó lại gây khó khăn \r\n\r\nkhông nhỏ trong việc tìm kiếm và tiếp nhận. Một giải pháp cho vấn đề này chính là \r\n\r\ntóm tắt văn bản tự động, sử dụng kết tóm tắt sẽ giúp người dùng tiết kiệm được \r\n\r\nđáng kể thời gian tìm kiếm, đọc cũng như thời gian lĩnh hội thông tin. Từ nhu cầu \r\n\r\nthực tế đó, các hệ thống tóm tắt tự văn bản tự động trở nên cần thiết hơn bao giờ \r\n\r\nhết. \r\n\r\nTóm tắt văn bản tự động là một trong những lĩnh vực thú vị nhất trong  lĩnh \r\n\r\nvực Xử lý ngôn ngữ tự nhiên. Bài toán tóm tắt văn bản tự động nhận được sự quan \r\n\r\ntâm nghiên cứu của nhiều nhà khoa học, nhóm nghiên cứu cũng như các công ty lớn \r\n\r\ntrên thế giới. Các bài báo liên quan đến tóm tắt văn bản xuất hiện nhiều trong các \r\n\r\nhội nghị nổi tiếng như : DUC 2001-2007, TAC 2008, ACL 2001-2007. Có nhiều \r\n\r\ncách tiếp cận bài toán tóm tắt văn bản tự động, đó có 2 hướng tiếp cận thông dụng \r\n\r\nlà  Tóm tắt trích rút và Tóm tắt rút gọn. Đối với Tóm tắt trích rút, hệ thống sẽ \r\n\r\ntrích rút ra các thành phần có trong văn bản mà không chỉnh sửa nội dung của nó rồi \r\n\r\nghép lại thành một văn bản mới. Như vậy, tóm tắt trích rút chỉ sử dụng các thông tin \r\n\r\ncó sẵn trong văn bản như: từ, cụm từ, câu để tạo ra văn bản tóm tắt. Đối với Tóm tắt \r\n\r\nrút gọn, cách tiếp cận này sử dụng ngữ nghĩa của các thành phần trong văn bản, để  \r\n\r\ntạo ra văn bản tóm tắt. Nhờ sử dụng các kỹ thuật trong xử lí ngôn ngữ tự nhiên, tóm \r\n\r\ntắt rút gọn tạo ra văn bản tóm tắt gần giống với tóm tắt của con người. Tóm tắt trích \r\n\r\nrút có ưu điểm là không đòi các kĩ thuật phân tích, xử lý ngôn ngữ tự nhiên phức tạp \r\n\r\nnhư tóm tắt rút gọn, mà kết quả thu được cũng rất khả quan trên một số miền nội \r\n\r\ndung như các bài báo, tin tức. \r\n\r\nVới ưu điểm của tóm tắt trích rút, Đồ án này lựa chọn đề tài  Tóm tắt văn \r\n\r\nbản sử dụng TextRank và các độ đo tương đồng để thực hiện. Đồ án tập trung vào \r\n\r\nnghiên cứu phương pháp, thực hành xây dựng chương trình tóm tắt và đánh giá áp \r\n\r\ndụng cho văn bản Tiếng Anh. \r\n\r\n  \r\n\r\n  \r\n\r\n  \r\n\r\n  \r\n\r\n\r\n\r\n\r\n \r\n\r\nChương 1. Tổng quan về bài toán tóm tắt văn bản \r\n\r\n1.1. Bài toán tóm tắt văn bản tự động \r\n\r\nVào giữa thế kỉ XX, các nhà khoa học đã bắt đầu nghiên cứu về tóm \r\n\r\ntắt văn bản tự động. Năm 1958, nhà khoa học H. P. Luhn đã trình bày \r\n\r\nphương pháp tóm tắt tự động cho các bài báo kĩ thuật bằng phương pháp \r\n\r\nthống kê thông qua tần suất và phân bố từ trong văn bản.  Đến năm 1969, H. \r\n\r\nP. Edmundson đã công bố nghiên cứu về  phương pháp mới trong việc tóm \r\n\r\ntắt văn bản tự động, tập trung vào bốn yếu tố chính trong văn bản là: vai trò, \r\n\r\nkhoá, tiêu đề  và vị  trí. Cho đến cuối thế kỉ XX đầu thế kỉ XXI, với sự phát \r\n\r\ntriển bùng nổ của Internet  mạng thông tin toàn cầu, lượng thông tin mà con \r\n\r\nngười sinh ra, lưu trữ và chia sẻ là cực kì lớn. Vấn đề đặt ra là làm sao để thu \r\n\r\nnhận được những thông tin quan trọng một cách nhanh chóng hiệu và quả  \r\n\r\nnhất. Từ  đó, bài toán tóm tắt văn bản trở  nên cấp thiết và được quan tâm \r\n\r\nhơn đúng với tầm quan trọng của nó. \r\n\r\nMục đích của tóm tắt văn bản là trích xuất nội dung quan trọng nhất \r\n\r\ntừ một nguồn thông  tin và trình bày các nội dung đó theo một khuôn dạng \r\n\r\nsúc tích cho người sử dụng hoặc một chương trình cần đến. \r\n\r\nThông thường, kết quả  của quá trình tóm tắt văn bản tự  động không  \r\n\r\nchất lượng như văn bản tóm tắt bởi con người do còn bị  giới hạn bởi nhiều \r\n\r\nyếu tố. Vì vậy, để nâng cao chất lượng tóm tắt văn bản tự động, cách thực \r\n\r\nhiện thường hướng đến các miền bài toán cụ thể với một phương pháp cụ \r\n\r\nthể.  \r\n\r\n1.2. Một số khái niệm của bài toán tóm tắt \r\n\r\n- Tỷ lệ nén (Compression Rate): là độ  đo giữa thông tin văn bản tóm tắt \r\n\r\nvà văn bản gốc được tính bằng công thức: \r\n\r\n                 \r\n             \r\n\r\n            \r\n \r\n\r\nTrong đó: \r\n\r\n   SummaryLength: Độ dài văn bản tóm tắt  \r\n\r\n   SourceLength: Độ dài văn bản nguồn \r\n\r\n- Độ liên quan (Relevance):  là độ  đo cho mức độ liên quan của thông  \r\n\r\n\r\n\r\n\r\n \r\n\r\ntin mà văn bản tóm tắt có được so với văn bản gốc.   \r\n\r\n- Sự mạch lạc (Coherence): là thước đo cho sự  mạch lạc, tất cả các thành \r\n\r\nphần nằm trong nó tuân theo một thể thống nhất về mặt nội dung và \r\n\r\nkhông có sự trùng lặp giữa các phần. \r\n\r\n1.3. Phân loại bài toán tóm tắt \r\n\r\nCó nhiều cách phân loại tóm tắt văn bản khác nhau, việc đó phụ thuộc vào cơ \r\n\r\nsở dùng để  tóm tắt. Đồ án sẽ trình bày các cơ sở để phân loại tóm tắt là:  \r\n\r\n Dựa theo cơ sở đầu vào \r\n\r\n Dựa theo cơ sở đầu ra \r\n\r\n Dựa theo mục đích tóm tắt \r\n\r\n1.3.1. Phân loại tóm tắt theo cơ sở đầu vào \r\n\r\n Tóm tắt văn bản có cấu trúc: Một số loại văn bản có quy định về định \r\n\r\ndạng hoặc đặc trưng về cấu trúc (như các bài báo, tin tức hay báo cáo \r\n\r\nkhoa học.).  Đối văn bản có cấu trúc, tóm tắt văn bản thường sử dụng \r\n\r\nmột mô hình học dựa vào mẫu cấu trúc đã xây dựng từ trước để tiến hành \r\n\r\ntóm tắt. \r\n\r\n Tóm tắt đơn văn bản - đa văn bản: Tóm tắt đơn văn bản khi đầu vào \r\n\r\nchỉ là một văn bản,  trong khi đó đầu vào của tóm tắt đa văn bản là một \r\n\r\ntập các tài liệu có nội dung liên quan đến nhau như: các tin tức có liên \r\n\r\nquan đến sự kiện, các bài báo cùng chủ đề.Kết quả của tóm tắt đa văn \r\n\r\nbản phải tổng hợp được nội dung của cả tập văn bản đầu vào. \r\n\r\n Tóm tắt dựa trên miền dữ liệu: tóm tắt hướng đến một lĩnh vực nào đó \r\n\r\ncó miền nội dung nhất định ví dụ như: khoa học, chính trị xã hội,. \r\n\r\n1.3.2. Phân loại tóm tắt theo mục đích  \r\n\r\n Tóm tắt chỉ thị (Indicative): tóm tắt chỉ thị đưa ra loại của thông tin ví \r\n\r\ndụ như văn bản thuộc chỉ thị thông báo, báo cáo. \r\n\r\n Tóm tắt nội dung: tóm tắt đưa ra nội dung của thông tin, chất lượng nội \r\n\r\ndung của bản tóm tắt có phụ thuộc vào tỉ lệ nén. \r\n\r\n Tóm tắt trên cơ sở  truy vấn (Query-based): Tóm tắt trên cơ sở truy \r\n\r\nvấn là nội dung của văn bản tóm tắt sẽ dựa trên truy vấn của người dùng \r\n\r\n\r\n\r\n\r\n \r\n\r\nhay chương trình đưa vào, loại tóm tắt này thường được sử  dụng trong \r\n\r\nquá trình tóm tắt các kết quả  trả về từ máy tìm kiếm. \r\n\r\n1.3.3. Phân loại tóm tắt theo cơ sở đầu ra \r\n\r\n Tóm tắt trích rút (Extract): là tóm tắt có kết quả  đầu ra là một tóm tắt \r\n\r\nbao gồm toàn bộ các phần quan trọng được trích ra từ văn bản đầu vào. \r\n\r\nNói cách khác, văn bản tóm tắt được tạo ra bằng cách bỏ đi các từ, cụm \r\n\r\ntừ hoặc câu không quan trọng và giữ lại các từ, cụm từ hoặc câu quan \r\n\r\ntrọng trong văn bản gốc. \r\n\r\n Tóm tắt tóm lược (Abstract): là tóm tắt có kết quả  đầu ra là một tóm tắt \r\n\r\ncó chứa cả các thành phần không có sẵn trong văn bản đầu vào, hay nói \r\n\r\ncách khác là nó không giữ nguyên lại các thành phần của văn bản đầu vào \r\n\r\nmà dựa vào thông tin quan trọng để viết lại một văn bản tóm tắt mới. \r\n\r\nHiện nay, các hệ  thống sử  dụng tóm tắt theo trích rút được sử  dụng phổ \r\n\r\nbiến và cho kết quả  tốt hơn tóm tắt theo tóm lược. Nguyên nhân tạo ra sự  \r\n\r\nkhác biệt này là do các vấn đề trong bài toán tóm tắt theo tóm lược như: biểu \r\n\r\ndiễn ngữ nghĩa, suy luận và sinh ra ngôn ngữ tự nhiên có độ phức tạp cao \r\n\r\nhơn nhiều so với tóm tắt theo trích rút. Trên thực tế tóm tắt tóm lược cũng \r\n\r\nchưa có nhiều kết quả khả quan hơn so với hướng trích rút câu của bài toán \r\n\r\ntóm tắt trích rút.  \r\n\r\n*** \r\n\r\nMặc dù theo các cơ sở phân loại có nhiều loại tóm tắt khác nhau nhưng \r\n\r\ncó hai loại là tóm tắt đơn văn bản và tóm tắt đa văn bản vẫn được sự quan \r\n\r\ntâm nhiều hơn của các nhà nghiên cứu về tóm tắt văn bản tự động. \r\n\r\n1.4. Tóm tắt đơn văn bản \r\n\r\nTóm tắt đơn văn bản là một quá trình tóm tắt tự động với đầu vào là \r\n\r\nmột văn bản, đầu ra là một đoạn văn bản tóm tắt có nội dung chính của văn \r\n\r\nbản đầu vào. Văn bản đầu vào có thể là một tài liệu dạng văn bản bất kì, các \r\n\r\nnội dung văn bản trên trang WEB.  \r\n\r\nCác phương pháp nhăm giải quyết bài toán tóm tắt văn bản đơn tập \r\n\r\ntrung vào hai hướng là : Tóm tắt theo trích rút và Tóm tắt theo tóm lược. \r\n\r\n1.4.1. Tóm tắt theo hướng trích rút \r\n\r\n\r\n\r\n\r\n \r\n\r\nĐa số các phương pháp tóm tắt theo loại này đều tập trung vào việc \r\n\r\ntrích xuất ra các câu hay các ngữ nổi bật từ các đoạn văn bản và kết hợp \r\n\r\nchúng lại thành một văn bản tóm tắt. Một số nghiên cứu giai đoạn đầu \r\n\r\nthường sử dụng các đặc trưng như vị trí của câu trong văn bản, tần số xuất \r\n\r\nhiện của từ, ngữ hay sử dụng các cụm từ khóa để tính toán trọng số của mỗi \r\n\r\ncâu, qua đó chọn ra các câu có trọng số cao nhất cho văn bản tóm tắt. Các kĩ \r\n\r\nthuật tóm tắt gần đây sử dụng phương pháp học máy và xử lý ngôn ngữ tự \r\n\r\nnhiên nhằm phân tích để tìm ra các thành phần quan trọng của văn bản \r\n\r\n1.4.2. Tóm tắt theo hướng tóm lược \r\n\r\nCác phương pháp tóm tắt không sử dụng trích xuất để tạo ra tóm tắt \r\n\r\ncó thể xem như là một phương pháp tiếp cận tóm tắt theo tóm lược. Các \r\n\r\nhướng tiếp cận có thể kể đến như dựa vào trích xuất thông tin (information \r\n\r\nextraction), hợp nhất và nén thông tin.Một trong những phương pháp tóm \r\n\r\ntắt theo tóm lược cho kết quả tốt là các phương pháp dựa vào trích xuất \r\n\r\nthông tin, phương pháp dạng này sử dụng các mẫu đã được định nghĩa trước \r\n\r\nvề một sự kiện hay là cốt truyện và hệ thống sẽ tự động điền các thông tin \r\n\r\nvào trong mẫu có sẵn rồi sinh ra kết quả tóm tắt. Mặc dù cho ra kết quả tốt \r\n\r\ntuy nhiên các phương pháp dạng này chỉ áp dụng cho một miền nhất định. \r\n\r\n1.5. Tóm tắt đa văn bản \r\n\r\nTóm tắt đa văn bản là quá trình tóm tắt tự động với đầu vào là một tập \r\n\r\ncác văn bản có liên quan đến nhau, đầu ra là một văn bản tóm tắt nội dung \r\n\r\nchính chứa trong cả tập văn bản đầu vào. \r\n\r\nTóm tắt đa văn bản có thể nói là một mở rộng của tóm tắt đơn văn \r\n\r\nbản. Hay nói cách khác bài toán tóm tắt đa văn bản dựa trên cơ sở của bài \r\n\r\ntoán tóm tắt đơn văn bản. Do vậy cách giải quyết bài toán tóm tắt đa văn bản \r\n\r\ncũng tiếp cận theo hướng tóm tắt trích rút và tóm tắt tóm lược nhưng với độ \r\n\r\nphức tạp cao hơn. \r\n\r\n \r\n\r\n  \r\n\r\n\r\n\r\n\r\n \r\n\r\nChương 2. Tóm tắt văn bản hướng trích rút \r\n\r\n2.1. Hướng tiếp cận \r\n\r\n Như đã trình bày ở trên, tóm tắt văn bản tự động là bài toán thuộc \r\n\r\nlĩnh vực xử lý ngôn ngữ tự nhiên. Trong phân tích xử lý ngôn ngữ tự nhiên \r\n\r\ncó các độ sâu xử lý khác nhau được sắp xếp theo thứ tự tăng dần: đầu tiên là \r\n\r\nmức hình thái (Morphological), tiếp theo là mức cú pháp (Syntactic), mức \r\n\r\nngữ nghĩa (Semantic) và cuối cùng là mức ngữ dụng (Pragmatic). Tương tự \r\n\r\nnhư các độ sâu xử lý của xử lý ngôn ngữ tự nhiên, phương pháp tiếp cận để \r\n\r\ngiải quyết bài toán tóm tắt đa văn bản cũng có thể được phân loại dựa vào độ \r\n\r\nsâu xử lý được thực hiện trong quá trình tóm tắt. Tuy nhiên các hướng tiếp \r\n\r\ncận để giải quyết bài toán tóm tắt văn bản tự động chỉ có ba mứclà: hình thái, \r\n\r\ncú pháp, và ngữ nghĩa. \r\n\r\n Mức hình thái : tại mức xử lý này, trong các văn bản, đơn vị \r\n\r\nđược sử dụng để so sánh là các từ, câu hay đoạn văn. Các \r\n\r\nphương pháp tại mức này thường sử dụng độ đo tương đồng \r\n\r\ndựa trên mô hình không gian vector áp dụng trọng số TF.IDF \r\n\r\ncho các từ. \r\n\r\n Mức cú pháp: đơn vị được sử dụng để so sánh tại mức xử lý \r\n\r\nnày là sử dụng việc phân tích những cấu trúc ngữ pháp tương \r\n\r\nứng giữa các văn bản với nhau. Các phương pháp tại mức này \r\n\r\ntập trung vào việc phân tích cấu trúc ngữ pháp giữa các câu hay \r\n\r\ncác ngữ trong từng đoạn văn thuộc các văn bản. Phương pháp \r\n\r\ndo Barzilay và các đồng tác giả khác đề xuất năm 1999 thuộc \r\n\r\nmức xử lý này \r\n\r\n Mức ngữ nghĩa: tại mức xử lý này tập trung nhiều vào việc \r\n\r\nphân tích các tên thực thể, mối quan hệ giữa các thực thể cũng \r\n\r\nnhư các sự kiện nảy sinh thực thể để xác định được độ quan \r\n\r\ntrọng của thông tin. Phương pháp của McKeown và Radev đề \r\n\r\nxuất năm 1995 là một dạng tóm tắt tại mức xử lý này \r\n\r\n2.2. Các thách thức của quá trình tóm tắt văn bản hướng trích rút \r\n\r\nĐặc trưng của tóm tắt văn bản hướng trích rút sử dụng chính các \r\n\r\nthành phần trong văn bản gốc vào bản tóm tắt. Thách thức lớn nhất của tóm \r\n\r\ntắt văn bản hướng trích rút là văn bản tóm tắt bị dư thừa hoặc thiếu dữ \r\n\r\nliệu,thông tin. Có ba nguyên nhân chính gây ra sự dư thừa hoặc thiếu dữ liệu, \r\n\r\n\r\n\r\n\r\n \r\n\r\nthông tin là: Cách chọn đơn vị văn bản để trích rút, phương pháp đánh giá \r\n\r\ncác đơn vị văn bản, và tỉ lệ nén. \r\n\r\nĐơn vị  văn bản:  Điểm mấu chốt của một hệ thống Tóm tắt văn bản \r\n\r\nlà việc tìm ra những thành phần quan trọng trong văn bản cần tóm tắt. Các \r\n\r\nthành phần này được gọi là các đơn vị văn bản. Đơn vị văn bản là đơn vị nhỏ \r\n\r\nnhất có nghĩa được chọn để trích rút làm văn bản tóm tắt. Các đơn vị văn bản \r\n\r\nquan trọng sẽ có xác suất lớn để chứa ý chính hay nội dung quan trọng của \r\n\r\nđoạn văn hay cả văn bản. Đơn vị văn bản lựa chọn để trích rút có thể là: từ, \r\n\r\ncụm từ hoặc câu. \r\n\r\nĐánh giá đơn vị  văn bản:  Các phương pháp tóm tắt văn bản khác \r\n\r\nnhau chủ yếu ở cách đánh giá và xác định các ĐVVB quan trọng. Phần lớn \r\n\r\ncác phương pháp tóm tắt văn bản đều dựa trên kết quả thống kê như phương \r\n\r\npháp dựa trên tần suất xuất hiện từ (TF-IPF), phương pháp sử dụng tiêu đề \r\n\r\n(title-based), phương pháp dựa trên vị trí (position) của câu trong đoạn, của \r\n\r\nđoạn trong văn bản,...Các phương pháp khác nhau lại cho kết quả khác nhau \r\n\r\nđối với từng tài liệu. \r\n\r\nTỉ lệ nén:  Về mặt hình thức, tỉ lệ nén ảnh hưởng trực tiếp đến số \r\n\r\nlượng các đơn vị văn bản được trích rút. Các mức tỉ lệ nén thường được dùng \r\n\r\nlà 10%, 20%, 50%. \r\n\r\n2.3. Phương pháp đánh giá kết quả tóm tắt \r\n\r\nPhương pháp tốt nhất để đánh giá kết quả tóm tắt là sử dụng đánh giá \r\n\r\ntừ các chuyên gia về ngôn ngữ, nhưng đây là phương pháp tốn rất nhiều chi \r\n\r\nphí. Do đó, ngoài các phương pháp đánh giá thủ công, vấn đề  đánh giá tự  \r\n\r\nđộng kết quả tóm tắt cũng nhận được sự quan tâm cần thiết. Từ năm 2000, \r\n\r\nViện tiêu chuẩn và kĩ thuật quốc gia Hoa Kỳ - NIST tổ chức hội nghị DUC \r\n\r\nhàng năm để đánh giá các hệ thống tóm tắt văn bản. Việc đánh giá tự  động \r\n\r\nnhằm mục đích là tìm ra được một độ  đo đánh giá văn bản tóm tắt  giống với  \r\n\r\nđánh giá của con người nhất. \r\n\r\nMột số độ đo để đánh giá kết quả tóm tắt văn bản hướng trích rút: \r\n\r\n Độ đo Recall (triệu hồi hay độ phủ): là tỉ lệ giữa tổng số câu \r\n\r\nđược máy đưa ra trùng với con người so với tổng số câu được \r\n\r\nmáy và con người đưa ra: \r\n\r\n         \r\n         \r\n\r\n            \r\n        \r\n\r\n\r\n\r\n\r\n \r\n\r\nTrong đó:  \r\n\r\n H là tập các câu do con người đưa ra \r\n\r\n M là tập các câu do máy đưa ra \r\n\r\n \r\n\r\n Độ đo ROUGE: Độ đo ROUGE - Recall Oriented Understudy for \r\n\r\nGisting Evaluation được Lin và Hovy đề xuất năm 2003. Hiện nay  \r\n\r\nphương pháp đo này được sử dụng như một phương pháp chuẩn \r\n\r\nđánh giá kết quả tóm tắt tự động cho văn bản tiếng Anh. Về mặt \r\n\r\nhình thức, độ đo ROUGE-N là độ đo Recall n-gram giữa tập văn \r\n\r\nbản tóm tắt do máy đưa ra so với các tập văn bản tóm tắt tham \r\n\r\nkhảo của con người tóm tắt. ROUGE-N được tính theo công thức: \r\n\r\n \r\n\r\n         \r\n                                               \r\n\r\n                                          \r\n  \r\n\r\nTrong đó:  \r\n\r\n n : là độ dài của n-gram \r\n\r\n gramn là bộ n từ liên tiếp trong văn bản S. \r\n\r\n Countmatch (gramn) : là số trùng lặp gramn tối đa giữa văn \r\n\r\nbản tóm tắt tự động và văn bản tóm tắt bằng tay. \r\n\r\n \r\n\r\n \r\n\r\n  \r\n\r\n\r\n\r\n\r\n \r\n\r\nChương 3. Tóm tắt văn bản Tiếng Anh sử dụng \r\n\r\nTextRank và các độ đo tương đồng \r\n\r\n3.1. Khái quát thuật toán xếp hạng dựa trên đồ thị \r\n\r\nCác thuật toán xếp hạng dựa trên đồ thị đã được đưa ra và sử dụng \r\n\r\nrộng rãi trong những năm cuối thế  kỷ  XX. Trong số  đó có thuật toán HITS \r\n\r\ncủa Kleinberg và Page rank của Google do hai nhà đồng sáng lập phát triển \r\n\r\n(Brin và Page). Chúng được sử  dụng trong việc phân tích mạng xã hội, cấu \r\n\r\ntrúc liên kết của các trang web,.Thực tế  thì thuật toán xếp  hạng dựa trên \r\n\r\nđồ  thị  xác định đỉnh nào là quan trọng trong đồ thị bằng cách tính toán đệ \r\n\r\nquy các thông tin trên toàn đồ  thị  thay vì chỉ  sử  dụng thông tin trên từng \r\n\r\nđỉnh. Quá trình này làm cho việc xác định mức độ quan trọng chính xác hơn. \r\n\r\nTừ  cách tiếp cận trên, ta có thể  áp dụng sang các đồ thị câu và đồ thị \r\n\r\nngữ  nghĩa trích xuất được từ các tài liệu trong ngôn ngữ  tự  nhiên. Kết quả  \r\n\r\ncủa việc sử  dụng mô hình xếp hạng dựa trên đồ  thị  có thể  ứng dụng trong \r\n\r\nnhiều chương trình xử  lý ngôn ngữ  tự  nhiên. Ví dụ  như mô hình xếp hạng \r\n\r\nhướng văn bản được ứng dụng trong các vấn đề  như tự  động trích xuất từ \r\n\r\nkhoá đến tóm tắt văn bản và xác định từ nhập nhằng ý nghĩa (Mihalcea et al., \r\n\r\n2004).  Phần tiếp theo sẽ trình bày chi tiết về mô hình TextRank và ứng dụng \r\n\r\ntrong việc tóm tắt văn bản. \r\n\r\n3.2. Mô hình TextRank \r\n\r\nNhư trình bày ở trên, thuật toán xếp hạng dựa trên đồ  thị  là cách đưa \r\n\r\nra cách chọn đỉnh quan trọng trong đồ  thị  dựa  trên các thông tin toàn cục \r\n\r\ncủa các đỉnh trong đồ thị. Ý tưởng của thuật toán này dựa trên hai yếu tố: bỏ \r\n\r\nphiếu và đề cử. Mỗi một liên kết đến đỉnh đang xét thì nó được 1 phiếu bầu. \r\n\r\nNhư vậy, càng nhiều phiếu bầu thì đỉnh đó càng quan trọng. Từ  cách xác \r\n\r\nđịnh trên thì trọng số của một đỉnh chính là số phiếu bầu cho đỉnh đó. \r\n\r\nTa có đồ thị G = (V, E) là đồ thị có hướng. Trong đó:  \r\n\r\n V là tập các đỉnh \r\n\r\n E là tập các cạnh của đồ thị, E là tập con của VxV ( E   VxV) \r\n\r\nVới mỗi đỉnh Vi  ta có:  \r\n\r\n In(Vi ) là tập các đỉnh trỏ đến Vi. \r\n\r\n\r\n\r\n\r\n \r\n\r\n Out(Vi) là tập các đỉnh mà Vi trỏ đến. \r\n\r\nTrọng số của đỉnh Vi được xác định như sau (Brin and Page, 1998): \r\n\r\n                  \r\n \r\n\r\n                 \r\n              \r\n\r\n \r\n\r\nTrong  đó d là nhân tố  giảm, có giá trị  từ  0 đến 1. Nó là xác xuất mà \r\n\r\nmột đỉnh có liên kết đến một đỉnh bất kỳ  trong đồ  thị. Đối với các trang web \r\n\r\nthì d là xác suất người dùng nhấn vào một liên kết bất kỳ và xác suất để \r\n\r\nngười dùng vào một trang web hoàn toàn mới  là 1    d. Theo Pagerank thì d \r\n\r\n= 0.85. Đây cũng là xác suất sẽ đươc sử dụng trong TextRank. \r\n\r\nBan đầu gán cho tất cả  các đỉnh trong đồ thị các giá trị khởi tạo và \r\n\r\ntính toán lặp lại cho đến khi kết quả hội tụ lại đạt ngưỡng xác định. Sau quá \r\n\r\ntrình tính toán thì trọng số của mỗi đỉnh chính là mức độ quan trọng của đỉnh \r\n\r\nđó trong toàn đồ thị. Có điều cần lưu ý, đó là giá trị trọng số của mỗi đỉnh sẽ \r\n\r\nkhông phụ thuộc vào giá trị khởi tạo ban đầu được gán cho mỗi đỉnh. Ngoài \r\n\r\nra thì số  lượng các vòng lặp tính toán để ra  được trọng số là khác nhau \r\n\r\n3.2.1. Áp dụng mô hình TextRank với đồ thị vô hướng  \r\n\r\n \r\n\r\n\r\nthị \r\n\r\n\r\n\r\n\r\n \r\n\r\nViệc áp dụng mô hình TextRank vào đồ thị vô hướng cũng giống như \r\n\r\nvới đồ thị có hướng. Có một điểm cần lưu ý, đó là trong đồ thị vô hướng thì \r\n\r\nsố đỉnh vào bằng số đỉnh ra. \r\n\r\nĐường cong hội tụ  của phương pháp xếp hạng dựa trên đồ  thị với đồ \r\n\r\nthị có hướng - vô hướng, có trọng số - không trọng số, 250 đỉnh và 250 cạnh \r\n\r\nTrong \r\nvới 250 đỉnh và 250 cạnh,  với  ngưỡng dừng là  10\r\n-5\r\n\r\n (ngưỡng này được xác \r\n\r\nđịnh đủ nhỏ  để  thuật toán dừng tính toán)  cho thấy số  lần lặp của quá trình \r\n\r\ntính toán không cao mặc dù số lượng đỉnh và cạnh lớn. Bên cạnh đó thì \r\n\r\nđường cong độ tụ của đồ  thị  có hướng và vô hương gần như trùng nhau. \r\n\r\nĐiều đó cho thấy đồ  thị vô hướng hay có hướng đều cho kết quả giống nhau, \r\n\r\nchỉ khác nhau ở số lần tính toán lặp lại.[1] \r\n\r\n3.2.2. Áp dụng mô hình TextRank với đồ thị có trọng số \r\n\r\nTrên môi trường Web, hiếm có trang Web nào lại chứa nhiều liên kết \r\n\r\nđến một trang khác. Vì vậy mà thuật toán Pagerank ban đầu  chỉ sử dụng đồ \r\n\r\nthị không trọng số. Tuy nhiên đối với các văn bản trong ngôn ngữ tự nhiên \r\n\r\nthì việc một văn bản nào đó có nhiều thành phần tham chiếu đến một văn bản \r\n\r\nkhác là hoàn toàn xảy ra. Do đó, để cải tiến PageRank cho phù hợp với ngôn \r\n\r\nngữ  tự  nhiên,  thuật toán TextRank sử  dụng đồ  thị  có trọng số. \r\n\r\nTrọng số  ở  đây được định nghĩa là độ dài kết nối giữa hai đỉnh Vi và \r\n\r\nVj, ký hiệu wij. Từ đó suy ra, công thức (1) cần phải được thay đổi để  phù \r\n\r\nhợp với đồ  thị  có trọng số  trong thuật toán TextRank. Ta được công thức \r\n\r\nmới như sau: \r\n\r\n                  \r\n   \r\n\r\n                        \r\n             \r\n\r\n \r\n\r\nNhư vậy, cũng theo hình 2.1  ở  trên thì số  lần lặp lại tính toán để  có \r\n\r\nđộ  tụ  đạt ngưỡng 10\r\n-5\r\n\r\n của đồ thị có trọng số và đồ thị không trọng số là \r\n\r\ntương đương nhau. \r\n\r\n3.2.3. Đồ thị  hóa văn bản \r\n\r\nVăn bản là một chuỗi tập hợp các câu, từ được sắp xếp với nhau. Vì \r\n\r\nvậy, để áp dụng được vào thuật toán dùng đồ thị thì cần phải đồ thị hoá văn \r\n\r\nbản. Đồ thị hoá văn bản là xây dựng một đồ thị để đại diện cho văn bản. Tùy \r\n\r\n\r\n\r\n\r\n \r\n\r\nthuộc vào mục đích,  các định các đỉnh của đồ thị được chọn để đại diện cho \r\n\r\ncác từ, cụm từ, hoặc câu. Cũng giống việc xác định các đỉnh, việc xác định \r\n\r\ncác cạnh trong đồ thị là gì cũng phụ thuộc vào mục đích ứng dụng. Các cung \r\n\r\nthể hiện liên kết giữa các đỉnh hay chính là quan hệ giữa các thành phần \r\n\r\ntrong văn bản. Quan hệ đó có thể là về từ vựng, ngữ nghĩa hoặc ngữ cảnh. \r\n\r\nTùy vào  các loại và đặc trưng để  đưa vào đồ  thị  mà có các cách \r\n\r\nthức làm việc. Nhưng cách thức hoạt động của thuật  toán xếp hạng dựa vào \r\n\r\nđồ  thị  áp dụng cho ngôn ngữ tự nhiên có các bước như sau: \r\n\r\n Xác định đơn vị  văn bản  dùng tốt nhất cho từng công việc, \r\n\r\nthêm vào là đỉnh của đồ thị. \r\n\r\n Xác định quan hệ  kết nối giữa các đơn vị  văn bản đã xác định  \r\n\r\nở trên để  vẽ  các cạnh giữa các đỉnh trong đồ  thị. Các cạnh \r\n\r\nnày có thể  là vô hướng hoặc có hướng, có trọng số hoặc không \r\n\r\ntrọng số. \r\n\r\n Lặp lại thuật toán xếp hạng cho đến khi độ tụ thoả mãn \r\n\r\nngưỡng. \r\n\r\n Sắp xếp các đỉnh dựa trên các trọng số  đã được tính toán trong \r\n\r\nbước trên. \r\n\r\nNhư vậy, thuật toán này giúp cho chúng ta làm được hai việc: trích rút \r\n\r\ntừ khoá và trích rút câu trong văn bản ngôn ngữ tự nhiên. Vấn đề được đề \r\n\r\ncập ngay sau đây. \r\n\r\n3.2.4. Sử dụng TextRank để trích rút câu \r\n\r\n Đặc điểm của TextRank là sử  dụng đồ  thị, nên để  áp dụng được \r\n\r\nTextRank thì cần phải đồ  thị  hoá văn bản. Muốn trích rút được câu thì cần \r\n\r\nphải xếp hạng được các câu trong văn bản trên toàn đồ  thị. Vì thế, mỗi câu \r\n\r\nsẽ  là một đỉnh của đồ thị. Một định nghĩa quan hệ được đưa ra để xác định \r\n\r\nkết nối giữa các câu với nhau, đó là độ  tương  đồng  giữa các câu. Ở đây, độ \r\n\r\ntương đồng được xác định bằng độ  bao phủ  về  mặt nội dung giữa các câu \r\n\r\nvới nhau. Mối quan hệ  giữa hai câu đó được xem là một đề cử: một câu đề \r\n\r\ncập đến một khái niệm nào đó trong văn bản sẽ  đề  cử cho  độc giả  một \r\n\r\ncâu khác trong văn bản cũng đề  cập đến khái niệm đó. Do đó xuất hiện một \r\n\r\nliên kết giữa các câu có chung nôi dung.  \r\n\r\n\r\n\r\n\r\n \r\n\r\nĐộ bao phủ của hai câu có thể đo bằng số lượng từ  trùng nhau giữa \r\n\r\nhai câu hoặc có thể  chạy chung một hoặc nhiều bộ  lọc ngữ  nghĩa,  cú pháp. \r\n\r\nĐể  giảm giá trị của độ tương đồng giữa các câu, tạo thuận lợi trong quá trình \r\n\r\ntính toán do tồn tại  các câu dài thì TextRank sử  dụng hệ  số  chuẩn hoá  là \r\n\r\nchia số  lượng nội dung bao phủ cho độ dài của từng câu.  \r\n\r\nVới hai câu  Si  và  Sj  với một câu được đại diện bởi một tập  N  các \r\n\r\ntừ  xuất hiện trong câu:  Si =w1\r\ni \r\n+ w2\r\n\r\ni \r\n+.+ wN\r\n\r\ni \r\n \r\n\r\nĐộ tương đồng giữa hai câu Si và Sj được tính theo công thức: \r\n\r\n                    \r\n                     \r\n\r\n                     \r\n       \r\n\r\nTrong đó: \r\n\r\n Similarity(Si,Sj) là độ tương đồng giữa hai câu Si và Sj \r\n\r\n wk  là từ trong câu \r\n\r\n log(|Si |) + log(|Sj |) là độ dài câu Si và Sj đã chuẩn hóa \r\n\r\nCó rất nhiều độ đo độ sự tương đồng giữa các câu với nhau như độ \r\n\r\ntương tự cô-sin, TRComparer. Các độ đo sự tương đồng có thể  được sử  \r\n\r\ndụng riêng lẻ hoặc kết hợp với nhau. Ở các phần sau của Đồ án sẽ trình bày \r\n\r\ncác biến thể khác của công thức tính độ tương đồng giữa các câu để áp dụng \r\n\r\ntrong thuật toán TextRank. \r\n\r\n3.3. Giải thuật TextRank \r\n\r\nThuật toán được triển khai theo công thức tính điểm cho các đỉnh trên đồ thị  \r\n\r\n                  \r\n   \r\n\r\n                        \r\n       \r\n\r\nCông thức trên có thể viết gọn lại thành: \r\n\r\n                     \r\n          \r\n\r\n \r\n\r\nTrong đó:   \r\n   \r\n\r\n              \r\n       \r\n\r\n\r\n\r\n\r\n \r\n\r\n- Đầu vào của thuật toán là đồ thị G=(V, E) Trong đó: \r\n\r\n V là tập các đỉnh, Int(Vi) là tập các đỉnh trỏ đến đỉnh Vi , Out(Vi) là \r\n\r\ntập các đỉnh Vi trỏ đến. \r\n\r\n E là tập các cung, wịj là giá trị/trọng số cung nối hai đỉnh Vi, Vj  \r\n\r\n- Đầu ra của thuật toán là điểm Score(Vi) của mỗi đỉnh  \r\n\r\nCài đặt giải thuật TextRank tính điểm (Score) cho các đỉnh: \r\n\r\n Đầu tiên khởi tạo giá trị ban đầu cho các đỉnh với giá trị  tùy chọn. \r\n\r\n \r\n\r\nforeach(Vi   V){ \r\n\r\nvertexScoreVi = 0.15; \r\n\r\n} \r\n\r\n \r\n\r\n \r\n\r\n Giá trị ngưỡng hội tụ  threshold , được gán bằng 10\r\n-5\r\n\r\n \r\n\r\n Biên độ score của đỉnh sau mỗi vòng lặp -  ScoreChanged  ban đầu \r\n\r\nđược gán bằng 0. \r\n\r\n \r\n\r\nthreshold = 0.00001; \r\n\r\nScoreChanged = 0; \r\n\r\n \r\n\r\n \r\n\r\n  \r\n\r\n\r\n\r\n\r\n \r\n\r\n Vòng lặp tính điểm Score cho các đỉnh \r\n\r\n \r\n\r\ndo{ \r\n\r\n  beforeLoopScoreChanged = 0; \r\n\r\n  foreach(Vi   V){ \r\n\r\n   CurrentVertexScoreVi = 0; \r\n\r\n   sumA = 0; \r\n\r\n   foreach(Vj   In(Vi)){ \r\n\r\n    // Tổng giá trị các cung mà đỉnh Vj đi đến \r\n\r\n    sumWjOut = 0;  \r\n\r\n    foreach(Vk   Out(Vj){ \r\n\r\n     sumWjOut += wjk; \r\n\r\n    } \r\n\r\n    sumA += (wij/sumWEjOut)*WS(Vj); \r\n\r\n   } \r\n\r\n   currentVertexScoreVi +=(1 - d)+ d* sumA; \r\n\r\n   currentScoreChanged = \r\n\r\n                                                                    abs(currentVertexScoreVi - vertexScoreVi); \r\n\r\n   if(currentScoreChanged > beforeLoopScoreChanged){ \r\n\r\n    ScoreChanged = currentScoreChanged;  \r\n\r\n   }else{ \r\n\r\n    ScoreChanged= beforeLoopScoreChanged; \r\n\r\n   } \r\n\r\n   vertexScoreVi = currentVertexScoreVi; \r\n\r\n} \r\n\r\n}while(ScoreChanged  > threshold) \r\n\r\n \r\n\r\n \r\n\r\n  \r\n\r\n\r\n\r\n\r\n \r\n\r\n3.4. Tóm tắt văn bản sử dụng giải thuật TextRank và các độ đo tương đồng \r\n\r\n3.4.1. Sơ đồ tổng quan các bước thực hiện bài toán.  \r\n\r\n \r\n\r\n \r\n\r\nVăn bản đầu vào \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n1. Pha Tiền xử lý \r\n\r\n2. Pha Dựng đồ thị \r\n\r\n3. Pha Trích rút câu \r\n\r\nTách từ, loại bỏ các từ \r\n\r\ndừng và từ dư thừa \r\n\r\n- Dựng đỉnh \r\n\r\n- - Mỗi đỉnh Vi tương ứng với câu Si  \r\n\r\n- - Vi={wi\r\n1, wi\r\n\r\n2,. wi\r\nn) \r\n\r\n-  \r\n\r\nDựng cung \r\n\r\n- Eij(Vi, Vj) = Similarity(Vi, Vj) \r\n\r\n- Similarity = {Cosine , KeyWord, \r\n\r\nFiltered, TRCmp., LinTFIDF} \r\n\r\n-   \r\n\r\nTextRank: Tính điểm cho mỗi \r\nđỉnh Vi trên đồ thị G=(V,E) \r\n\r\n-> {ScoreCal(Vi)} \r\n\r\n \r\nVăn bản tóm tắt \r\n\r\n  \r\n\r\nCác câu đã loại bỏ từ \r\ndừng, từ dư thừa \r\n\r\nSi={ai\r\n1\r\n, ai\r\n\r\n2 \r\n,., ai\r\n\r\nn\r\n} \r\n\r\nĐồ thị G = (V, E) biểu diễn cho văn \r\n\r\nbản  \r\n\r\n - Lấy ra n đỉnh Vk  có điểm số \r\n\r\ncao nhất: Output (V) = {Vk} \r\n\r\n Output(S) = {Sk} \r\n\r\n \r\n\r\nTách văn bản => Các câu \r\n\r\nvăn \r\n\r\n\r\n\r\n\r\n \r\n\r\n3.4.2. Pha tiền xử lí văn bản \r\n\r\nVăn bản đầu vào được mô hình hóa bởi lớp văn bản (Document) có \r\n\r\nchứa các thuộc tính quan trọng như sau:  \r\n\r\n \r\n\r\n \r\n\r\nClass Document = {docTextValues,  SentenceDictionary<id, Sentense>} \r\n\r\n \r\n\r\n \r\n\r\n- Trong đó: \r\n\r\n docTextValues: là nội dung văn bản nguồn \r\n\r\n SentenceDictionary: là danh sách các câu từ văn bản nguồn \r\n\r\nTrong danh sách SentenceDictionary<id, Sentense>, lớp câu \r\n\r\n(Sentense) được mô hình hóa có chứa các thuộc tính quan trọng như sau: \r\n\r\n \r\n\r\nClass Sentense = { id, senTextValues, <Terms> } \r\n\r\n \r\n\r\n- Trong đó:  \r\n\r\n id: là mã số của câu, tương ứng với số thứ thự của câu trong văn \r\n\r\nbản \r\n\r\n senTextValues: là nguyên văn câu trong văn bản nguồn \r\n\r\n <Terms>: là danh sách các từ của câu \r\n\r\n Tách câu:  \r\n\r\n- Văn bản đầu vào được tách thành danh sách các câu Si: \r\n\r\n- Đầu vào: Văn bản nguồn \r\n\r\n- Đầu ra: Danh sách các câu (SentenceDictionary) \r\n\r\n Quá trình thực hiện trong thuật toán: \r\n\r\n Doccument(docTextValues)  \r\n\r\n-> SentenceDictionary<id, Sentense> \r\n\r\n  \r\n\r\n\r\n\r\n\r\n \r\n\r\n Tách từ, loại bỏ từ dừng - từ dư thừa \r\n\r\n- Đầu vào: Văn bản nguồn \r\n\r\n- Danh sách một số từ ít quan trọng  không chứa nhiều thông tin trong văn \r\n\r\nbản Tiếng Anh (all, just, less, being, indeed, over, both, anyway, detail, \r\n\r\nfour, front, already, through, yourselves, fify, mill, still, its, before, move, \r\n\r\nwhose, one, system, also, somewhere, herself, thick,...[7]) \r\n\r\n Quá trình thực hiện: \r\n\r\n Chuyển các kí viết hoa tự về kí tự thường:  \r\n\r\nSentense.toLower(senTextValues) -> tmpTextValues \r\n\r\n Tách từ:   \r\n\r\nSentense.Split (tmpTextValues) -> tmpTerms<terms> \r\n\r\n Loại bỏ từ dừng và các từ dư thừa.   \r\n\r\nif (preTerms<terms>  stopWord )  \r\n\r\n-> Sentense.addTerms(term) \r\n\r\n Kết quả: Đầu ra là danh sách câu chứa các từ đã loại bỏ từ dừng và \r\n\r\ntừ dư thừa: <Sentense = {<Terms>}> \r\n\r\n3.4.3. Pha dựng đồ thị  \r\n\r\n3.4.3.1. Khởi tạo các đỉnh \r\n\r\nMỗi đỉnh là 1 câu trong văn bản. Một đỉnh là một vector tương ứng \r\n\r\nvới một câu. Lớp đỉnh (Vertex) được mô hình hóa với các thuộc tính quan \r\n\r\ntrọng như sau: \r\n\r\n \r\n\r\nClass Vertex = { id, score} \r\n\r\n \r\n\r\n \r\n\r\n- Trong đó:  \r\n\r\n id: là mã số của đỉnh trong đồ thị - trùng với id của câu trong văn \r\n\r\nbản \r\n\r\n score: là điểm số xếp hạng của đỉnh trong đồ thị \r\n\r\n\r\n\r\n\r\n \r\n\r\nKhởi tạo các  đỉnh Vi có id tương ứng với với id của câu Si: \r\n\r\n- Đầu vào là danh sách các câu {Si}. Đầu ra là danh sách các đỉnh {Vi} \r\n\r\n Các bước thực hiện trong chương trình: \r\n\r\n Vertex Vi = new Vertex(si.id) \r\n\r\n3.4.3.2. Dựng các cung liên kết giữa các đỉnh trong đồ thị \r\n\r\nTrên đồ thị, mỗi đỉnh đại diện cho một câu trong văn bản. Do vậy các \r\n\r\ncung liên kết giữa các đỉnh trên đồ thị cũng thể hiện sự liên kết giữa các câu \r\n\r\nvới nhau. Giá trị của cung liên kết hai đỉnh trên đồ thị đại diện cho giá trị độ \r\n\r\nđo tương đồng giữa hai câu. Đây là công đoạn quan trọng có ảnh hưởng trực \r\n\r\ntiếp đến kết quả bài toán tóm tắt. \r\n\r\nLớp cung Edge được mô hình hóa với các thuộc tính quan trọng \r\n\r\nnhư sau: \r\n\r\n \r\n\r\nClass Edge = { 1stVertexId, 2ndVetexId, weight} \r\n\r\n \r\n\r\n- Trong đó:  \r\n\r\n 1stVertexId, 2ndVetexId: là id của hai đỉnh được nối bởi cung \r\n\r\nđang xét \r\n\r\n weight: là giá trị/trọng số của cung \r\n\r\nThực hiện dựng cung: \r\n\r\n- Đầu vào là danh sách các các đỉnh Vi tương ứng với mỗi câu Si={wi\r\n1\r\n, \r\n\r\nwi\r\n2\r\n, . wi\r\n\r\nn\r\n}. \r\n\r\n- Đầu ra là giá trị cung nối giữa các đỉnh: WeightE(Vi,Vj) \r\n\r\n Các bước thực hiện: \r\n\r\n Khởi tạo danh sách các cung: graph.Edges = list<Edge> \r\n\r\n Khởi tạo một cung: Edge E(Vi,Vj) = Edge(Vi,Vj) \r\n\r\n Tính giá trị cung nối giữa hai đỉnh Vi, Vj áp dụng công \r\n\r\nthức tính độ tương đồng cho các câu Si, Sj:  \r\n\r\n\r\n\r\n\r\n \r\n\r\n                                   \r\n\r\n\r\nTên độ đo Công thức \r\n\r\n \r\n\r\nĐộ tương đồng \r\n\r\nCô-sin \r\n\r\n \r\n\r\n            \r\n        \r\n\r\n \r\n   \r\n\r\n   \r\n  \r\n\r\n       \r\n  \r\n\r\n    \r\n \r\n\r\nFiltered \r\n\r\n  \r\n\r\n \r\n\r\n         \r\n       \r\n\r\n         \r\n \r\n\r\n \r\n\r\nTRComparer   \r\n\r\n         \r\n       \r\n\r\n               \r\n \r\n\r\n \r\n\r\nLinTFIDF   \r\n\r\n         \r\n                     \r\n\r\n \r\n\r\n                 \r\n                 \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\nKeyWord  \r\n\r\n         \r\n                       \r\n\r\n          \r\n \r\n\r\n \r\n\r\n\r\n Độ tương đồng cô-sin: Với hai câu A, B \r\n\r\n            \r\n        \r\n\r\n \r\n   \r\n\r\n   \r\n  \r\n\r\n       \r\n  \r\n\r\n   \r\n\r\n \r\n\r\nTrong đó: Ai, Bi là trọng số tf-isf của từ tương ứng trong câu A, B \r\n\r\n Filtered: Với hai câu Si, Sj, độ tương đồng Filtered được tính theo công thức: \r\n\r\n         \r\n       \r\n\r\n         \r\n \r\n\r\nTrong đó:  \r\n\r\n\r\n\r\n\r\n \r\n\r\n- Si={ w1\r\ni\r\n, w2\r\n\r\ni\r\n, ., wn\r\n\r\ni\r\n} ; wk\r\n\r\ni\r\n là các từ trong câu Si \r\n\r\n- Sj={ w1\r\nj\r\n, w2\r\n\r\nj\r\n, ., wn\r\n\r\nj\r\n} ; wk\r\n\r\nj\r\n là các từ trong câu Sj \r\n\r\n TRComparer: Với hai câu Si, Sj, độ tương đồng TRComparer được tính theo \r\n\r\ncông thức: \r\n\r\n         \r\n       \r\n\r\n               \r\n \r\n\r\nTrong đó:  \r\n\r\n- Si={ w1\r\ni\r\n, w2\r\n\r\ni\r\n, ., wn\r\n\r\ni\r\n} ; wk\r\n\r\ni\r\n là các từ trong câu Si \r\n\r\n- Sj={ w1\r\nj\r\n, w2\r\n\r\nj\r\n, ., wn\r\n\r\nj\r\n} ; wk\r\n\r\nj\r\n là các từ trong câu Sj \r\n\r\n LinTFIDF: Với hai câu Si, Sj, độ tương đồng LinTFIDF được tính theo công \r\n\r\nthức: \r\n\r\n         \r\n                     \r\n\r\n \r\n\r\n                 \r\n                 \r\n\r\n \r\n\r\n \r\n\r\nTrong đó: \r\n\r\n- tfw,i, tfw,j là số lần từ w xuất hiện trong câu Si, Sj \r\n\r\n- isfw là tần số nghịch đảo của từ w trong văn bản  \r\n\r\n KeyWord: Với hai câu Si, Sj, độ tương đồng KeyWord được tính theo công \r\n\r\nthức: \r\n\r\n         \r\n                       \r\n\r\n          \r\n \r\n\r\nTrong đó: \r\n\r\n- K: trong đồ án tập K được coi là tập tất cả các từ trong văn bản \r\n\r\n3.4.4. Pha trích rút câu \r\n\r\nSau khi xây dựng được đồ thị biểu diễn cho văn bản. Chương trình \r\n\r\nthực hiện thuật toán TextRank để tính điểm và xếp hạng cho các đỉnh trên đồ \r\n\r\nthị. Đỉnh Vi có thứ hạng càng cao càng thể hiện sự quan trọng của nó trong \r\n\r\nđồ thị, cũng đồng nghĩa với việc câu Si là quan trọng trong văn bản. Chương \r\n\r\ntrình sẽ lấy ra n đỉnh {Si} tương ứng với các đỉnh {Vi} có thứ hạng cao nhất. \r\n\r\n\r\n\r\n\r\n \r\n\r\n- Đầu vào: là đồ thị G=(V,E) với danh sách tập các đỉnh V={Vi} và tập giá \r\n\r\ntrị cung E={Eij} \r\n\r\n \r\n\r\n\r\n- Đầu ra là các các câu tương ứng với đỉnh có thứ  hạng cao nhất. \r\n\r\n Các bước thực hiện:  \r\n\r\n Tính điểm cho các đỉnh bằng thuật toán: TextRank (V,E) \r\n\r\n Sắp xếp các đỉnh theo điểm số: SortVertexByScore (Vi)  \r\n\r\n Lấy ra n đỉnh có điểm số cao nhất: n=10% *(tổng số \r\n\r\nđỉnh) \r\n\r\nVoutput = {Vop\r\n1\r\n, Vop\r\n\r\n2\r\n, ., Vop\r\n\r\nn\r\n} \r\n\r\n Lấy ra các câu để làm văn bản tóm tắt Souput tương ứng với \r\n\r\nVouput: Soutput = {Sop\r\n1\r\n, Sop\r\n\r\n2\r\n, ., Sop\r\n\r\nn\r\n} \r\n\r\n  \r\n\r\n\r\n\r\n\r\n \r\n\r\nChương 4. Kết quả thử nghiệm, đánh giá \r\n\r\n4.1. Tập dữ liệu thử nghiệm \r\n\r\n4.1.1. Tổng quan về DUC 2007 \r\n\r\nHội thảo về Hiểu tài liệu - Document Understanding Conference \r\n\r\n(DUC) là một loạt các đánh giá về các hệ thống tổng hợp văn bản tự động. \r\n\r\nNó được tổ chức bởi Viện Tiêu chuẩn và Công nghệ Quốc gia - National \r\n\r\nInstitute of Standards and Technology  (NIST) với mục tiêu tăng tiến trình \r\n\r\ntổng hợp tự động và cho phép các nhà nghiên cứu tham gia vào các thí \r\n\r\nnghiệm với quy mô lớn. \r\n\r\nDUC 2007 là bộ dữ liệu văn bản bao gồm các văn bản gốc và dữ liệu \r\n\r\nđã xử lý, được làm thủ công bởi 32 tổ chức  đến từ 11 nước tham gia đóng \r\n\r\ngóp. Bộ dữ liệu bao gồm ba phần là dữ liệu văn bản thô  testdocs và dữ \r\n\r\nliệu đã được xử lí đánh dấu  marked corpus, và marked corpus update \r\n\r\n Phần dữ liệu testdocs bao gồm: \r\n\r\n Phần main có 45 chủ đề chính, mỗi chủ đề chứa 25 tài liệu lấy từ \r\n\r\ncác nguồn AP, NYT, XIN newswire và được phát triển bởi 10 \r\n\r\nchuyên gia/người đánh giá của NIST.  \r\n\r\n Phần update là dữ liệu về Mô hình tóm tắt(Model summaries) \r\n\r\nđược viết bởi 10 người đánh giá, có 4 mô hình tóm tắt cho mỗi chủ \r\n\r\nđề. \r\n\r\n Phần marked corpus và marked corpus update bao gồm dữ liệu \r\n\r\ncủa một số chủ đề đã được tóm tắt từ nguồn văn bản testdocs.  \r\n\r\n4.1.2. Khai thác và sử dụng DUC 2007 cho mục đích tóm tắt văn bản \r\n\r\nDữ liệu văn bản thô testdocs được chia thành 45 chủ đề, mỗi chủ đề \r\n\r\nbao gồm 25 văn bản. Các văn bản trong testdocs sẽ được khai thác để làm dữ \r\n\r\nliệu đầu vào cho hệ thống tóm tắt. Các văn bản có cấu trúc lưu trữ như sau:  \r\n\r\n\r\n\r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n\r\nTrong đó cần quan tâm đến các thẻ:   \r\n\r\n <DOCNO>: mã số văn bản  cũng có thể coi là tên của văn \r\n\r\nbản \r\n\r\n <TEXT>: nội dung của văn bản \r\n\r\n <P>: các đoạn văn trong văn bản \r\n\r\nDữ liệu trong phần marked corpus là các chủ đề đã được phân tích \r\n\r\nvà lưu trữ dưới định dạng *.scu - Summary Content Unit (SCU) được miêu \r\n\r\ntả như sau:  \r\n\r\n \r\n\r\n\r\n\r\n\r\n\r\n \r\n\r\nTrong đó:  \r\n\r\n- <collection name= >: tên chủ đề  được đặt theo tên thư mục lưu trữ \r\n\r\n- <document name=>: tên văn bản  mã số văn bản trong chủ đề \r\n\r\n- <line>: 1 câu trong văn bản \r\n\r\n- scu-count: số các SCU realized by the sentence; agrees with count of \r\n\r\nSCU elements \r\n\r\n- <sum-count =>: số bản tóm tắt có sử dụng câu đang xét \r\n\r\n- <sums=>: các id đại diện cho tổ chức sử dụng câu này trong tóm tắt \r\n\r\n- uid: định danh SCU \r\n\r\n- label: nội dung của SCU \r\n\r\n- weight: số lượng các đoạn văn bản tóm tắt bằng tay mà SCU thể hiện \r\n\r\n \r\n\r\nĐể lấy ra được một bản tóm tắt mẫu phục vụ cho việc đánh giá kết \r\n\r\nquả sau này, ta cần trích rút ra những câu theo thuộc tính sums của nút con \r\n\r\n<annotation>. Với mỗi một giá trị này, ta sẽ có được một bản tóm tắt \r\n\r\nmẫu. \r\n\r\n4.2. Phương pháp thử nghiệm  \r\n\r\nĐồ án thực hiện thử nghiệm tóm tắt văn bản Tiếng Anh bằng phương \r\n\r\npháp TextRank. Trong đó, vấn đề quan trọng là thử nghiệm các cách khác \r\n\r\nnhau để tính giá trị cung của đồ thị sử dụng trong thuật toán TextRank  các \r\n\r\nđộ đo tương đồng: Cosine, KeyWord, Filtered, TRCmp, LinTFIDF. \r\n\r\nTrong  Đồ án này, chương trình được thử nghiệm trên tập dữ liệu \r\n\r\nDUC 2007 bao gồm 575 văn bản thuộc 23 chủ đề đã được đánh dấu tóm tắt \r\n\r\nbởi nhóm Pyramid Summary Content Unit. \r\n\r\n Tỉ lệ nén thử nghiệm: Các văn bản đầu trong bộ dữ liệu được chương \r\n\r\ntrình tóm tắt trích rút với tỉ lệ nén 10%, 20% theo tổng số câu trong \r\n\r\nvăn bản  Tối thiểu số câu trích rút ra là 1. Trong một cách thử \r\n\r\nnghiệm khác: Mỗi văn bản đầu vào được chương trình trích rút lấy số \r\n\r\ncâu cố định là 2 câu để làm văn bản tóm tắt. \r\n\r\n Các độ đo tương đồng được thử nghiệm: Đồ án thử nghiệm riêng lẻ \r\n\r\nvà kết hợp các độ đo tương đồng như đã trình bày ở chương 3. Cách \r\n\r\nthức kết hợp các độ đo tương đồng là áp dụng đồng thời N độ đo - \r\n\r\nN={1,2,3,4} và lấy giá trị trung bình cộng của chúng. \r\n\r\n\r\n\r\n\r\n \r\n\r\n Phương pháp đánh giá kết quả:  Đồ án sử dụng phương pháp đánh \r\n\r\ngiá ROUGE-N  đã trình bày ở chương 2 để đánh giá kết quả của hệ \r\n\r\nthống tóm tắt văn bản tự động, với N= 1, 2.  \r\n\r\n4.3. Kết quả thử nghiệm, đánh giá \r\n\r\n4.3.1. Kết quả thử nghiệm từng độ đo tương đồng riêng lẻ  \r\n\r\n Áp dụng trích rút với tỉ  lệ nén. \r\n\r\nTỉ lệ nén 10%  \r\n\r\nPhương pháp ROUGE-1 ROUGE-2 \r\n\r\nKeyWord 0.4900 0.3616 \r\n\r\nTRComparer 0.4599 0.3309 \r\n\r\nLinTFIDF 0.4231 0.2958 \r\n\r\nCosine 0.4179 0.2898 \r\n\r\nFiltered 0.3087 0.2169 \r\n\r\nTrung bình: 0.4199 0.2990 \r\n\r\n\r\n \r\n\r\nTỉ lệ nén 20%  \r\n\r\nPhương pháp ROUGE-1 ROUGE-2 \r\n\r\nKeyWord 0.6453 0.5270 \r\n\r\nTRComparer 0.6099 0.4855 \r\n\r\nLinTFIDF 0.5826 0.4564 \r\n\r\nCosine 0.5805 0.4548 \r\n\r\nFiltered 0.5322 0.4069 \r\n\r\nTrung bình:  0.5901  0.4661 \r\n\r\n\r\n  \r\n\r\n\r\n\r\n\r\n \r\n\r\n Áp dụng trích rút với số câu cố định. \r\n\r\nSố câu trích rút: 2 \r\n\r\nPhương pháp (N=1) ROUGE-1 ROUGE-2 \r\n\r\nKeyWord 0.5154 0.3915 \r\n\r\nTRComparer 0.4859 0.3621 \r\n\r\nLinTFIDF 0.4390 0.3194 \r\n\r\nCosine 0.4334 0.3148 \r\n\r\nFiltered 0.3332 0.2596 \r\n\r\nTrung bình:  0.4414  0.3295 \r\n\r\n\r\nbằng 2 \r\n\r\n \r\n\r\n \r\n\r\nBiểu đồ 1. Kết quả tóm tắt áp dụng từng độ đo tương đồng riêng lẻ với tỉ lệ nén \r\n\r\n10%  \r\n\r\n0\r\n\r\n0.1\r\n\r\n0.2\r\n\r\n0.3\r\n\r\n0.4\r\n\r\n0.5\r\n\r\n0.6\r\n\r\nCosine Filtered TRComparer LinTFIDF KeyWord\r\n\r\nROUGE-1\r\n\r\nROUGE-2\r\n\r\n\r\n\r\n\r\n \r\n\r\n \r\n\r\nBiểu đồ 2. So sánh kết quả giữa các mức độ nén \r\n\r\n4.3.2. Kết quả thử nghiệm kết hợp đồng thời  nhiều độ đo tương đồng \r\n\r\n Kết quả khi áp dụng đồng thời 2 độ đo tương đồng \r\n\r\nTỉ lệ nén 10%  \r\n\r\nPhương pháp (N=2) ROUGE-1 ROUGE-2 \r\n\r\nKeyWord + TRComparer 0.4717 0.3436 \r\n\r\nKeyWord + LinTFIDF 0.4454 0.3172 \r\n\r\nCosine + KeyWord 0.4421 0.3131 \r\n\r\nCosine + TRComparer 0.4407 0.3139 \r\n\r\nTRComparer + LinTFIDF 0.4352 0.3072 \r\n\r\nCosine + LinTFIDF 0.4178 0.2892 \r\n\r\nKeyWord + Filtered 0.3099 0.2178 \r\n\r\nFiltered + LinTFIDF 0.3067 0.2166 \r\n\r\nCosine + Filtered 0.3056 0.2152 \r\n\r\nFiltered + TRComparer 0.3054 0.2133 \r\n\r\nTrung bình N=2: 0.3880 0.2747 \r\n\r\nĐiểm cơ sở (Trung bình N=1) 0.4199 0.2990 \r\n\r\n\r\n0\r\n\r\n0.1\r\n\r\n0.2\r\n\r\n0.3\r\n\r\n0.4\r\n\r\n0.5\r\n\r\n0.6\r\n\r\n0.7\r\n\r\nROUGE-1 ROUGE-2\r\n\r\nTỉ lệ nén 10% \r\n\r\nTỉ lệ nén 20% \r\n\r\nTrích rút 2 câu\r\n\r\n\r\n\r\n\r\n \r\n\r\n Kết quả khi áp dụng đồng thời 3, 4 độ đo tương đồng \r\n\r\nTỉ lệ nén 10% \r\n\r\nPhương pháp (N=3) ROUGE-1 ROUGE-2 \r\n\r\nCosine + KeyWord + TRComparer 0.4522 0.3244 \r\n\r\nKeyWord + TRComparer + LinTFIDF 0.4483 0.3199 \r\n\r\nCosine + KeyWord + LinTFIDF 0.4367 0.3082 \r\n\r\nCosine + TRComparer + LinTFIDF 0.4298 0.3013 \r\n\r\nKeyWord + Filtered + TRComparer 0.3079 0.2156 \r\n\r\nCosine + KeyWord + Filtered 0.3074 0.2171 \r\n\r\nKeyWord + Filtered + LinTFIDF 0.3067 0.2165 \r\n\r\nCosine + Filtered + TRComparer 0.3058 0.2162 \r\n\r\nFiltered + TRComparer + LinTFIDF 0.3049 0.2149 \r\n\r\nCosine + Filtered + LinTFIDF 0.2981 0.2083 \r\n\r\nTrung bình N=3: 0.3597 0.2542 \r\n\r\nĐiểm cơ sở (Trung bình N=1) 0.4199 0.2990 \r\n\r\n\r\n \r\n\r\nTỉ lệ nén 10% \r\n\r\nPhương pháp (N=4) ROUGE-1 ROUGE-2 \r\n\r\nCosine + KeyWord + TRComparer + LinTFIDF 0.4380 0.3094 \r\n\r\nKeyWord + Filtered + TRComparer + LinTFIDF 0.3073 0.2182 \r\n\r\nCosine + KeyWord + Filtered + TRComparer 0.3063 0.2167 \r\n\r\nCosine + KeyWord + Filtered + LinTFIDF 0.2997 0.2098 \r\n\r\nCosine + Filtered + TRComparer + LinTFIDF 0.2980 0.2086 \r\n\r\nTrung bình N=4: 0.3298 0.2325 \r\n\r\nĐiểm cơ sở (Trung bình N=1) 0.4199 0.2990 \r\n\r\n\r\n\r\n\r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\nBiểu đồ 3. So sánh kết quả áp dụng đồng thời N độ đo tương đồng, tỉ lệ nén 10% \r\n\r\n4.3.3. Đánh giá kết quả thử nghiệm \r\n\r\nĐồ án đã thử nghiệm tóm tắt 575 văn bản trong tập dữ liệu DUC 2007. \r\n\r\nTrong đó có thử nghiệm việc sử dụng Cosine, KeyWord, Filtered, TRCmp, LinTFIDF \r\n\r\nlà các cách khác nhau đ","u":"http://202.191.57.85:8000/InternetData/Data/DATN/20101559_Nguyen_Xuan_Hoa_1495982153177.txt","sentences":[[1,"Internet giống như một thế giới ảo, thế giới giúp con người cũng như máy tính, kết nối và chia sẻ thông tin với nhau"],[2,"Mỗi ngày, một lượng vô cùng lớn các bài viết, hình ảnh hay video về mọi lĩnh vực của cuộc sống, được con người chia sẻ trên các trang báo, diễn đàn hay mạng xã hội"],[3,"Giữa một thế giới thông tin đa dạng, phong phú không ngừng phát triển như vậy, vấn đề làm sao để lấy được những thông tin cần thiết, cho con người hoặc chương trình máy tính ngày càng trở nên khó khăn hơn"],[4,"Để giải quyết vấn đề này ta nghĩ ngay đến lĩnh vực Khai phá dữ liệu"],[5,"Mục đích của khai phá dữ liệu là tìm ra những thông tin cần thiết, bao quát, cỗi lõi và quan trọng nhất từ dữ liệu giúp người sử dụng tiếp cận nhanh và hiệu quả hơn"],[6,"Khai phá dữ liệu văn bản, là một trong những hướng nghiên cứu thú vị về lĩnh vực khai phá dữ liệu, mà tóm tắt văn bản tự động là một bài toán cơ bản và quan trọng"],[7,"Đồ án này trình bày phương pháp tóm tắt văn bản tiếng Anh sử dụng TextRank và các độ đo tương đồng"],[8,"Bố cục của Đồ Án như sau : Chương 1: Tổng quan bài toán tóm tắt văn bản Chương này trình bày tổng quan về bài toán tóm tắt văn bản tự động, tóm tắt văn bản sử dụng phương pháp trích rút"],[9,"Chương 2: Tóm tắt văn bản hướng trích rút Chương này trình bày hướng tiếp cận, thách thức của bài toán tóm tắt văn bản hướng trích rút Chương 3: Tóm tắt văn bản tiếng Anh sử dụng TextRank và các độ đo tương đồng Chương này trình bày chi tiết về TextRank và các độ đo tương đồng để giải quyết bài toán tóm tắt văn bản"],[10,"Chương 4: Kết quả thử nghiệm, đánh giá Trình bày về bộ dữ liệu thử nghiệm, các kết quả thử nghiệm và đánh giá kết quả tóm tắt trích rút văn bản tiếng Anh của TextRank và các độ đo tương đồng sử dụng trong TextRank"],[11,"Chương 5: Kết luận Tổng kết lại đưa ra ưu điểm, hạn chế và nguyên nhân cùng hướng phát triển trong tương lai Sau cùng là danh mục các tài liệu tham khảo trong quá trình thực hiện Đồ án này"],[12,"Lời cám ơn Lời đầu tiên, em xin gửi lời cảm ơn chân thành đến các thầy cô trong trường Đại học Bách Khoa Hà Nội nói chung, các thầy cô trong viện Công nghệ thông tin và Truyền thông nói riêng đã truyền đạt cho chúng em những kiến thức, kỹ năng quý giá trong suốt quá trình học tập tại trường"],[13,"Em xin gửi lời cảm ơn chân thành đến cô giáo Nguyễn Kim Anh, giảng viên Bộ môn Hệ thống thông tin - Viện Công nghệ thông tin & Truyền thông đã giúp đỡ, hướng dẫn tận tình cho em trong quá trình học tập và làm Đồ án tốt nghiệp này"],[14,"Cuối cùng, em xin chân thành gửi lời cảm ơn tới gia đình, bạn bè đã quan tâm và động viên tinh thần cho em rất nhiều trong quá trình làm Đồ án tốt nghiệp"],[15,"Hà Nội, tháng 5 năm 2015 Nguyễn Xuân Hòa Lớp Công nghệ thông tin 2 K55 Đại học Bách khoa Hà Nội Mục Lục 3.4"],[16,"Tóm tắt văn bản sử dụng giải thuật TextRank và các độ đo tương đồng .."],[17,"24 DANH MỤC CÁC HÌNH DANH MỤC CÁC BẢNG, BIỂU ĐỒ DANH MỤC CÁC TỪ VIẾT TẮT VÀ THUẬT NGỮ Từ viết tắt, thuật ngữ Giải thích DUC Document Understanding Conference ROUGE Recall-Oriented Understudy for Gisting Evaluation Similarity Độ tương đồng TF (term frequency) Tần số xuất hiện của một từ ISF (Inverse sentence frequency) Tần số nghịch của một từ trong văn bản NVĐA Người viết Đồ án CNTT&TT Công nghệ thông tin và Truyền thông Mở đầu Ngày nay, công nghệ thông tin đang phát triển rất mạnh mẽ, kèm theo với nó là sự bùng nổ của internet đã mang đến cho con người số lượng thông tin khổng lồ"],[18,"Lượng thông tin khổng lồ đó bao gồm các văn bản, hình ảnh, video...nó đã và đang mang lại lợi ích rất lớn cho con người, tuy nhiên sự khổng lồ đó lại gây khó khăn không nhỏ trong việc tìm kiếm và tiếp nhận"],[19,"Một giải pháp cho vấn đề này chính là tóm tắt văn bản tự động, sử dụng kết tóm tắt sẽ giúp người dùng tiết kiệm được đáng kể thời gian tìm kiếm, đọc cũng như thời gian lĩnh hội thông tin"],[20,"Từ nhu cầu thực tế đó, các hệ thống tóm tắt tự văn bản tự động trở nên cần thiết hơn bao giờ hết"],[21,"Tóm tắt văn bản tự động là một trong những lĩnh vực thú vị nhất trong lĩnh vực Xử lý ngôn ngữ tự nhiên"],[22,"Bài toán tóm tắt văn bản tự động nhận được sự quan tâm nghiên cứu của nhiều nhà khoa học, nhóm nghiên cứu cũng như các công ty lớn trên thế giới"],[23,"Các bài báo liên quan đến tóm tắt văn bản xuất hiện nhiều trong các hội nghị nổi tiếng như : DUC 2001-2007, TAC 2008, ACL 2001-2007"],[24,"Có nhiều cách tiếp cận bài toán tóm tắt văn bản tự động, đó có 2 hướng tiếp cận thông dụng là Tóm tắt trích rút và Tóm tắt rút gọn"],[25,"Đối với Tóm tắt trích rút, hệ thống sẽ trích rút ra các thành phần có trong văn bản mà không chỉnh sửa nội dung của nó rồi ghép lại thành một văn bản mới"],[26,"Như vậy, tóm tắt trích rút chỉ sử dụng các thông tin có sẵn trong văn bản như: từ, cụm từ, câu để tạo ra văn bản tóm tắt"],[27,"Đối với Tóm tắt rút gọn, cách tiếp cận này sử dụng ngữ nghĩa của các thành phần trong văn bản, để tạo ra văn bản tóm tắt"],[28,"Nhờ sử dụng các kỹ thuật trong xử lí ngôn ngữ tự nhiên, tóm tắt rút gọn tạo ra văn bản tóm tắt gần giống với tóm tắt của con người"],[29,"Tóm tắt trích rút có ưu điểm là không đòi các kĩ thuật phân tích, xử lý ngôn ngữ tự nhiên phức tạp như tóm tắt rút gọn, mà kết quả thu được cũng rất khả quan trên một số miền nội dung như các bài báo, tin tức"],[30,"Với ưu điểm của tóm tắt trích rút, Đồ án này lựa chọn đề tài Tóm tắt văn bản sử dụng TextRank và các độ đo tương đồng để thực hiện"],[31,"Đồ án tập trung vào nghiên cứu phương pháp, thực hành xây dựng chương trình tóm tắt và đánh giá áp dụng cho văn bản Tiếng Anh"],[32,"Chương 1"],[33,"Tổng quan về bài toán tóm tắt văn bản 1.1"],[34,"Bài toán tóm tắt văn bản tự động Vào giữa thế kỉ XX, các nhà khoa học đã bắt đầu nghiên cứu về tóm tắt văn bản tự động"],[35,"Năm 1958, nhà khoa học H"],[36,"P"],[37,"Luhn đã trình bày phương pháp tóm tắt tự động cho các bài báo kĩ thuật bằng phương pháp thống kê thông qua tần suất và phân bố từ trong văn bản"],[38,"Đến năm 1969, H"],[39,"P"],[40,"Edmundson đã công bố nghiên cứu về phương pháp mới trong việc tóm tắt văn bản tự động, tập trung vào bốn yếu tố chính trong văn bản là: vai trò, khoá, tiêu đề và vị trí"],[41,"Cho đến cuối thế kỉ XX đầu thế kỉ XXI, với sự phát triển bùng nổ của Internet mạng thông tin toàn cầu, lượng thông tin mà con người sinh ra, lưu trữ và chia sẻ là cực kì lớn"],[42,"Vấn đề đặt ra là làm sao để thu nhận được những thông tin quan trọng một cách nhanh chóng hiệu và quả nhất"],[43,"Từ đó, bài toán tóm tắt văn bản trở nên cấp thiết và được quan tâm hơn đúng với tầm quan trọng của nó"],[44,"Mục đích của tóm tắt văn bản là trích xuất nội dung quan trọng nhất từ một nguồn thông tin và trình bày các nội dung đó theo một khuôn dạng súc tích cho người sử dụng hoặc một chương trình cần đến"],[45,"Thông thường, kết quả của quá trình tóm tắt văn bản tự động không chất lượng như văn bản tóm tắt bởi con người do còn bị giới hạn bởi nhiều yếu tố"],[46,"Vì vậy, để nâng cao chất lượng tóm tắt văn bản tự động, cách thực hiện thường hướng đến các miền bài toán cụ thể với một phương pháp cụ thể"],[47,"1.2"],[48,"Một số khái niệm của bài toán tóm tắt - Tỷ lệ nén (Compression Rate): là độ đo giữa thông tin văn bản tóm tắt và văn bản gốc được tính bằng công thức: Trong đó: SummaryLength: Độ dài văn bản tóm tắt SourceLength: Độ dài văn bản nguồn - Độ liên quan (Relevance): là độ đo cho mức độ liên quan của thông tin mà văn bản tóm tắt có được so với văn bản gốc"],[49,"- Sự mạch lạc (Coherence): là thước đo cho sự mạch lạc, tất cả các thành phần nằm trong nó tuân theo một thể thống nhất về mặt nội dung và không có sự trùng lặp giữa các phần"],[50,"1.3"],[51,"Phân loại bài toán tóm tắt Có nhiều cách phân loại tóm tắt văn bản khác nhau, việc đó phụ thuộc vào cơ sở dùng để tóm tắt"],[52,"Đồ án sẽ trình bày các cơ sở để phân loại tóm tắt là: Dựa theo cơ sở đầu vào Dựa theo cơ sở đầu ra Dựa theo mục đích tóm tắt 1.3.1"],[53,"Phân loại tóm tắt theo cơ sở đầu vào Tóm tắt văn bản có cấu trúc: Một số loại văn bản có quy định về định dạng hoặc đặc trưng về cấu trúc (như các bài báo, tin tức hay báo cáo khoa học.)"],[54,"Đối văn bản có cấu trúc, tóm tắt văn bản thường sử dụng một mô hình học dựa vào mẫu cấu trúc đã xây dựng từ trước để tiến hành tóm tắt"],[55,"Tóm tắt đơn văn bản - đa văn bản: Tóm tắt đơn văn bản khi đầu vào chỉ là một văn bản, trong khi đó đầu vào của tóm tắt đa văn bản là một tập các tài liệu có nội dung liên quan đến nhau như: các tin tức có liên quan đến sự kiện, các bài báo cùng chủ đề.Kết quả của tóm tắt đa văn bản phải tổng hợp được nội dung của cả tập văn bản đầu vào"],[56,"Tóm tắt dựa trên miền dữ liệu: tóm tắt hướng đến một lĩnh vực nào đó có miền nội dung nhất định ví dụ như: khoa học, chính trị xã hội,"],[57,"1.3.2"],[58,"Phân loại tóm tắt theo mục đích Tóm tắt chỉ thị (Indicative): tóm tắt chỉ thị đưa ra loại của thông tin ví dụ như văn bản thuộc chỉ thị thông báo, báo cáo"],[59,"Tóm tắt nội dung: tóm tắt đưa ra nội dung của thông tin, chất lượng nội dung của bản tóm tắt có phụ thuộc vào tỉ lệ nén"],[60,"Tóm tắt trên cơ sở truy vấn (Query-based): Tóm tắt trên cơ sở truy vấn là nội dung của văn bản tóm tắt sẽ dựa trên truy vấn của người dùng hay chương trình đưa vào, loại tóm tắt này thường được sử dụng trong quá trình tóm tắt các kết quả trả về từ máy tìm kiếm"],[61,"1.3.3"],[62,"Phân loại tóm tắt theo cơ sở đầu ra Tóm tắt trích rút (Extract): là tóm tắt có kết quả đầu ra là một tóm tắt bao gồm toàn bộ các phần quan trọng được trích ra từ văn bản đầu vào"],[63,"Nói cách khác, văn bản tóm tắt được tạo ra bằng cách bỏ đi các từ, cụm từ hoặc câu không quan trọng và giữ lại các từ, cụm từ hoặc câu quan trọng trong văn bản gốc"],[64,"Tóm tắt tóm lược (Abstract): là tóm tắt có kết quả đầu ra là một tóm tắt có chứa cả các thành phần không có sẵn trong văn bản đầu vào, hay nói cách khác là nó không giữ nguyên lại các thành phần của văn bản đầu vào mà dựa vào thông tin quan trọng để viết lại một văn bản tóm tắt mới"],[65,"Hiện nay, các hệ thống sử dụng tóm tắt theo trích rút được sử dụng phổ biến và cho kết quả tốt hơn tóm tắt theo tóm lược"],[66,"Nguyên nhân tạo ra sự khác biệt này là do các vấn đề trong bài toán tóm tắt theo tóm lược như: biểu diễn ngữ nghĩa, suy luận và sinh ra ngôn ngữ tự nhiên có độ phức tạp cao hơn nhiều so với tóm tắt theo trích rút"],[67,"Trên thực tế tóm tắt tóm lược cũng chưa có nhiều kết quả khả quan hơn so với hướng trích rút câu của bài toán tóm tắt trích rút"],[68,"*** Mặc dù theo các cơ sở phân loại có nhiều loại tóm tắt khác nhau nhưng có hai loại là tóm tắt đơn văn bản và tóm tắt đa văn bản vẫn được sự quan tâm nhiều hơn của các nhà nghiên cứu về tóm tắt văn bản tự động"],[69,"1.4"],[70,"Tóm tắt đơn văn bản Tóm tắt đơn văn bản là một quá trình tóm tắt tự động với đầu vào là một văn bản, đầu ra là một đoạn văn bản tóm tắt có nội dung chính của văn bản đầu vào"],[71,"Văn bản đầu vào có thể là một tài liệu dạng văn bản bất kì, các nội dung văn bản trên trang WEB"],[72,"Các phương pháp nhăm giải quyết bài toán tóm tắt văn bản đơn tập trung vào hai hướng là : Tóm tắt theo trích rút và Tóm tắt theo tóm lược"],[73,"1.4.1"],[74,"Tóm tắt theo hướng trích rút Đa số các phương pháp tóm tắt theo loại này đều tập trung vào việc trích xuất ra các câu hay các ngữ nổi bật từ các đoạn văn bản và kết hợp chúng lại thành một văn bản tóm tắt"],[75,"Một số nghiên cứu giai đoạn đầu thường sử dụng các đặc trưng như vị trí của câu trong văn bản, tần số xuất hiện của từ, ngữ hay sử dụng các cụm từ khóa để tính toán trọng số của mỗi câu, qua đó chọn ra các câu có trọng số cao nhất cho văn bản tóm tắt"],[76,"Các kĩ thuật tóm tắt gần đây sử dụng phương pháp học máy và xử lý ngôn ngữ tự nhiên nhằm phân tích để tìm ra các thành phần quan trọng của văn bản 1.4.2"],[77,"Tóm tắt theo hướng tóm lược Các phương pháp tóm tắt không sử dụng trích xuất để tạo ra tóm tắt có thể xem như là một phương pháp tiếp cận tóm tắt theo tóm lược"],[78,"Các hướng tiếp cận có thể kể đến như dựa vào trích xuất thông tin (information extraction), hợp nhất và nén thông tin.Một trong những phương pháp tóm tắt theo tóm lược cho kết quả tốt là các phương pháp dựa vào trích xuất thông tin, phương pháp dạng này sử dụng các mẫu đã được định nghĩa trước về một sự kiện hay là cốt truyện và hệ thống sẽ tự động điền các thông tin vào trong mẫu có sẵn rồi sinh ra kết quả tóm tắt"],[79,"Mặc dù cho ra kết quả tốt tuy nhiên các phương pháp dạng này chỉ áp dụng cho một miền nhất định"],[80,"1.5"],[81,"Tóm tắt đa văn bản Tóm tắt đa văn bản là quá trình tóm tắt tự động với đầu vào là một tập các văn bản có liên quan đến nhau, đầu ra là một văn bản tóm tắt nội dung chính chứa trong cả tập văn bản đầu vào"],[82,"Tóm tắt đa văn bản có thể nói là một mở rộng của tóm tắt đơn văn bản"],[83,"Hay nói cách khác bài toán tóm tắt đa văn bản dựa trên cơ sở của bài toán tóm tắt đơn văn bản"],[84,"Do vậy cách giải quyết bài toán tóm tắt đa văn bản cũng tiếp cận theo hướng tóm tắt trích rút và tóm tắt tóm lược nhưng với độ phức tạp cao hơn"],[85,"Chương 2"],[86,"Tóm tắt văn bản hướng trích rút 2.1"],[87,"Hướng tiếp cận Như đã trình bày ở trên, tóm tắt văn bản tự động là bài toán thuộc lĩnh vực xử lý ngôn ngữ tự nhiên"],[88,"Trong phân tích xử lý ngôn ngữ tự nhiên có các độ sâu xử lý khác nhau được sắp xếp theo thứ tự tăng dần: đầu tiên là mức hình thái (Morphological), tiếp theo là mức cú pháp (Syntactic), mức ngữ nghĩa (Semantic) và cuối cùng là mức ngữ dụng (Pragmatic)"],[89,"Tương tự như các độ sâu xử lý của xử lý ngôn ngữ tự nhiên, phương pháp tiếp cận để giải quyết bài toán tóm tắt đa văn bản cũng có thể được phân loại dựa vào độ sâu xử lý được thực hiện trong quá trình tóm tắt"],[90,"Tuy nhiên các hướng tiếp cận để giải quyết bài toán tóm tắt văn bản tự động chỉ có ba mứclà: hình thái, cú pháp, và ngữ nghĩa"],[91,"Mức hình thái : tại mức xử lý này, trong các văn bản, đơn vị được sử dụng để so sánh là các từ, câu hay đoạn văn"],[92,"Các phương pháp tại mức này thường sử dụng độ đo tương đồng dựa trên mô hình không gian vector áp dụng trọng số TF.IDF cho các từ"],[93,"Mức cú pháp: đơn vị được sử dụng để so sánh tại mức xử lý này là sử dụng việc phân tích những cấu trúc ngữ pháp tương ứng giữa các văn bản với nhau"],[94,"Các phương pháp tại mức này tập trung vào việc phân tích cấu trúc ngữ pháp giữa các câu hay các ngữ trong từng đoạn văn thuộc các văn bản"],[95,"Phương pháp do Barzilay và các đồng tác giả khác đề xuất năm 1999 thuộc mức xử lý này Mức ngữ nghĩa: tại mức xử lý này tập trung nhiều vào việc phân tích các tên thực thể, mối quan hệ giữa các thực thể cũng như các sự kiện nảy sinh thực thể để xác định được độ quan trọng của thông tin"],[96,"Phương pháp của McKeown và Radev đề xuất năm 1995 là một dạng tóm tắt tại mức xử lý này 2.2"],[97,"Các thách thức của quá trình tóm tắt văn bản hướng trích rút Đặc trưng của tóm tắt văn bản hướng trích rút sử dụng chính các thành phần trong văn bản gốc vào bản tóm tắt"],[98,"Thách thức lớn nhất của tóm tắt văn bản hướng trích rút là văn bản tóm tắt bị dư thừa hoặc thiếu dữ liệu,thông tin"],[99,"Có ba nguyên nhân chính gây ra sự dư thừa hoặc thiếu dữ liệu, thông tin là: Cách chọn đơn vị văn bản để trích rút, phương pháp đánh giá các đơn vị văn bản, và tỉ lệ nén"],[100,"Đơn vị văn bản: Điểm mấu chốt của một hệ thống Tóm tắt văn bản là việc tìm ra những thành phần quan trọng trong văn bản cần tóm tắt"],[101,"Các thành phần này được gọi là các đơn vị văn bản"],[102,"Đơn vị văn bản là đơn vị nhỏ nhất có nghĩa được chọn để trích rút làm văn bản tóm tắt"],[103,"Các đơn vị văn bản quan trọng sẽ có xác suất lớn để chứa ý chính hay nội dung quan trọng của đoạn văn hay cả văn bản"],[104,"Đơn vị văn bản lựa chọn để trích rút có thể là: từ, cụm từ hoặc câu"],[105,"Đánh giá đơn vị văn bản: Các phương pháp tóm tắt văn bản khác nhau chủ yếu ở cách đánh giá và xác định các ĐVVB quan trọng"],[106,"Phần lớn các phương pháp tóm tắt văn bản đều dựa trên kết quả thống kê như phương pháp dựa trên tần suất xuất hiện từ (TF-IPF), phương pháp sử dụng tiêu đề (title-based), phương pháp dựa trên vị trí (position) của câu trong đoạn, của đoạn trong văn bản,...Các phương pháp khác nhau lại cho kết quả khác nhau đối với từng tài liệu"],[107,"Tỉ lệ nén: Về mặt hình thức, tỉ lệ nén ảnh hưởng trực tiếp đến số lượng các đơn vị văn bản được trích rút"],[108,"Các mức tỉ lệ nén thường được dùng là 10%, 20%, 50%"],[109,"2.3"],[110,"Phương pháp đánh giá kết quả tóm tắt Phương pháp tốt nhất để đánh giá kết quả tóm tắt là sử dụng đánh giá từ các chuyên gia về ngôn ngữ, nhưng đây là phương pháp tốn rất nhiều chi phí"],[111,"Do đó, ngoài các phương pháp đánh giá thủ công, vấn đề đánh giá tự động kết quả tóm tắt cũng nhận được sự quan tâm cần thiết"],[112,"Từ năm 2000, Viện tiêu chuẩn và kĩ thuật quốc gia Hoa Kỳ - NIST tổ chức hội nghị DUC hàng năm để đánh giá các hệ thống tóm tắt văn bản"],[113,"Việc đánh giá tự động nhằm mục đích là tìm ra được một độ đo đánh giá văn bản tóm tắt giống với đánh giá của con người nhất"],[114,"Một số độ đo để đánh giá kết quả tóm tắt văn bản hướng trích rút: Độ đo Recall (triệu hồi hay độ phủ): là tỉ lệ giữa tổng số câu được máy đưa ra trùng với con người so với tổng số câu được máy và con người đưa ra: Trong đó: H là tập các câu do con người đưa ra M là tập các câu do máy đưa ra Độ đo ROUGE: Độ đo ROUGE - Recall Oriented Understudy for Gisting Evaluation được Lin và Hovy đề xuất năm 2003"],[115,"Hiện nay phương pháp đo này được sử dụng như một phương pháp chuẩn đánh giá kết quả tóm tắt tự động cho văn bản tiếng Anh"],[116,"Về mặt hình thức, độ đo ROUGE-N là độ đo Recall n-gram giữa tập văn bản tóm tắt do máy đưa ra so với các tập văn bản tóm tắt tham khảo của con người tóm tắt"],[117,"ROUGE-N được tính theo công thức: Trong đó: n : là độ dài của n-gram gramn là bộ n từ liên tiếp trong văn bản S"],[118,"Countmatch (gramn) : là số trùng lặp gramn tối đa giữa văn bản tóm tắt tự động và văn bản tóm tắt bằng tay"],[119,"Chương 3"],[120,"Tóm tắt văn bản Tiếng Anh sử dụng TextRank và các độ đo tương đồng 3.1"],[121,"Khái quát thuật toán xếp hạng dựa trên đồ thị Các thuật toán xếp hạng dựa trên đồ thị đã được đưa ra và sử dụng rộng rãi trong những năm cuối thế kỷ XX"],[122,"Trong số đó có thuật toán HITS của Kleinberg và Page rank của Google do hai nhà đồng sáng lập phát triển (Brin và Page)"],[123,"Chúng được sử dụng trong việc phân tích mạng xã hội, cấu trúc liên kết của các trang web,.Thực tế thì thuật toán xếp hạng dựa trên đồ thị xác định đỉnh nào là quan trọng trong đồ thị bằng cách tính toán đệ quy các thông tin trên toàn đồ thị thay vì chỉ sử dụng thông tin trên từng đỉnh"],[124,"Quá trình này làm cho việc xác định mức độ quan trọng chính xác hơn"],[125,"Từ cách tiếp cận trên, ta có thể áp dụng sang các đồ thị câu và đồ thị ngữ nghĩa trích xuất được từ các tài liệu trong ngôn ngữ tự nhiên"],[126,"Kết quả của việc sử dụng mô hình xếp hạng dựa trên đồ thị có thể ứng dụng trong nhiều chương trình xử lý ngôn ngữ tự nhiên"],[127,"Ví dụ như mô hình xếp hạng hướng văn bản được ứng dụng trong các vấn đề như tự động trích xuất từ khoá đến tóm tắt văn bản và xác định từ nhập nhằng ý nghĩa (Mihalcea et al., 2004)"],[128,"Phần tiếp theo sẽ trình bày chi tiết về mô hình TextRank và ứng dụng trong việc tóm tắt văn bản"],[129,"3.2"],[130,"Mô hình TextRank Như trình bày ở trên, thuật toán xếp hạng dựa trên đồ thị là cách đưa ra cách chọn đỉnh quan trọng trong đồ thị dựa trên các thông tin toàn cục của các đỉnh trong đồ thị"],[131,"Ý tưởng của thuật toán này dựa trên hai yếu tố: bỏ phiếu và đề cử"],[132,"Mỗi một liên kết đến đỉnh đang xét thì nó được 1 phiếu bầu"],[133,"Như vậy, càng nhiều phiếu bầu thì đỉnh đó càng quan trọng"],[134,"Từ cách xác định trên thì trọng số của một đỉnh chính là số phiếu bầu cho đỉnh đó"],[135,"Ta có đồ thị G = (V, E) là đồ thị có hướng"],[136,"Trong đó: V là tập các đỉnh E là tập các cạnh của đồ thị, E là tập con của VxV ( E VxV) Với mỗi đỉnh Vi ta có: In(Vi ) là tập các đỉnh trỏ đến Vi"],[137,"Out(Vi) là tập các đỉnh mà Vi trỏ đến"],[138,"Trọng số của đỉnh Vi được xác định như sau (Brin and Page, 1998): Trong đó d là nhân tố giảm, có giá trị từ 0 đến 1"],[139,"Nó là xác xuất mà một đỉnh có liên kết đến một đỉnh bất kỳ trong đồ thị"],[140,"Đối với các trang web thì d là xác suất người dùng nhấn vào một liên kết bất kỳ và xác suất để người dùng vào một trang web hoàn toàn mới là 1 d"],[141,"Theo Pagerank thì d = 0.85"],[142,"Đây cũng là xác suất sẽ đươc sử dụng trong TextRank"],[143,"Ban đầu gán cho tất cả các đỉnh trong đồ thị các giá trị khởi tạo và tính toán lặp lại cho đến khi kết quả hội tụ lại đạt ngưỡng xác định"],[144,"Sau quá trình tính toán thì trọng số của mỗi đỉnh chính là mức độ quan trọng của đỉnh đó trong toàn đồ thị"],[145,"Có điều cần lưu ý, đó là giá trị trọng số của mỗi đỉnh sẽ không phụ thuộc vào giá trị khởi tạo ban đầu được gán cho mỗi đỉnh"],[146,"Ngoài ra thì số lượng các vòng lặp tính toán để ra được trọng số là khác nhau 3.2.1"],[147,"Áp dụng mô hình TextRank với đồ thị vô hướng thị Việc áp dụng mô hình TextRank vào đồ thị vô hướng cũng giống như với đồ thị có hướng"],[148,"Có một điểm cần lưu ý, đó là trong đồ thị vô hướng thì số đỉnh vào bằng số đỉnh ra"],[149,"Đường cong hội tụ của phương pháp xếp hạng dựa trên đồ thị với đồ thị có hướng - vô hướng, có trọng số - không trọng số, 250 đỉnh và 250 cạnh Trong với 250 đỉnh và 250 cạnh, với ngưỡng dừng là 10 -5 (ngưỡng này được xác định đủ nhỏ để thuật toán dừng tính toán) cho thấy số lần lặp của quá trình tính toán không cao mặc dù số lượng đỉnh và cạnh lớn"],[150,"Bên cạnh đó thì đường cong độ tụ của đồ thị có hướng và vô hương gần như trùng nhau"],[151,"Điều đó cho thấy đồ thị vô hướng hay có hướng đều cho kết quả giống nhau, chỉ khác nhau ở số lần tính toán lặp lại.[1] 3.2.2"],[152,"Áp dụng mô hình TextRank với đồ thị có trọng số Trên môi trường Web, hiếm có trang Web nào lại chứa nhiều liên kết đến một trang khác"],[153,"Vì vậy mà thuật toán Pagerank ban đầu chỉ sử dụng đồ thị không trọng số"],[154,"Tuy nhiên đối với các văn bản trong ngôn ngữ tự nhiên thì việc một văn bản nào đó có nhiều thành phần tham chiếu đến một văn bản khác là hoàn toàn xảy ra"],[155,"Do đó, để cải tiến PageRank cho phù hợp với ngôn ngữ tự nhiên, thuật toán TextRank sử dụng đồ thị có trọng số"],[156,"Trọng số ở đây được định nghĩa là độ dài kết nối giữa hai đỉnh Vi và Vj, ký hiệu wij"],[157,"Từ đó suy ra, công thức (1) cần phải được thay đổi để phù hợp với đồ thị có trọng số trong thuật toán TextRank"],[158,"Ta được công thức mới như sau: Như vậy, cũng theo hình 2.1 ở trên thì số lần lặp lại tính toán để có độ tụ đạt ngưỡng 10 -5 của đồ thị có trọng số và đồ thị không trọng số là tương đương nhau"],[159,"3.2.3"],[160,"Đồ thị hóa văn bản Văn bản là một chuỗi tập hợp các câu, từ được sắp xếp với nhau"],[161,"Vì vậy, để áp dụng được vào thuật toán dùng đồ thị thì cần phải đồ thị hoá văn bản"],[162,"Đồ thị hoá văn bản là xây dựng một đồ thị để đại diện cho văn bản"],[163,"Tùy thuộc vào mục đích, các định các đỉnh của đồ thị được chọn để đại diện cho các từ, cụm từ, hoặc câu"],[164,"Cũng giống việc xác định các đỉnh, việc xác định các cạnh trong đồ thị là gì cũng phụ thuộc vào mục đích ứng dụng"],[165,"Các cung thể hiện liên kết giữa các đỉnh hay chính là quan hệ giữa các thành phần trong văn bản"],[166,"Quan hệ đó có thể là về từ vựng, ngữ nghĩa hoặc ngữ cảnh"],[167,"Tùy vào các loại và đặc trưng để đưa vào đồ thị mà có các cách thức làm việc"],[168,"Nhưng cách thức hoạt động của thuật toán xếp hạng dựa vào đồ thị áp dụng cho ngôn ngữ tự nhiên có các bước như sau: Xác định đơn vị văn bản dùng tốt nhất cho từng công việc, thêm vào là đỉnh của đồ thị"],[169,"Xác định quan hệ kết nối giữa các đơn vị văn bản đã xác định ở trên để vẽ các cạnh giữa các đỉnh trong đồ thị"],[170,"Các cạnh này có thể là vô hướng hoặc có hướng, có trọng số hoặc không trọng số"],[171,"Lặp lại thuật toán xếp hạng cho đến khi độ tụ thoả mãn ngưỡng"],[172,"Sắp xếp các đỉnh dựa trên các trọng số đã được tính toán trong bước trên"],[173,"Như vậy, thuật toán này giúp cho chúng ta làm được hai việc: trích rút từ khoá và trích rút câu trong văn bản ngôn ngữ tự nhiên"],[174,"Vấn đề được đề cập ngay sau đây"],[175,"3.2.4"],[176,"Sử dụng TextRank để trích rút câu Đặc điểm của TextRank là sử dụng đồ thị, nên để áp dụng được TextRank thì cần phải đồ thị hoá văn bản"],[177,"Muốn trích rút được câu thì cần phải xếp hạng được các câu trong văn bản trên toàn đồ thị"],[178,"Vì thế, mỗi câu sẽ là một đỉnh của đồ thị"],[179,"Một định nghĩa quan hệ được đưa ra để xác định kết nối giữa các câu với nhau, đó là độ tương đồng giữa các câu"],[180,"Ở đây, độ tương đồng được xác định bằng độ bao phủ về mặt nội dung giữa các câu với nhau"],[181,"Mối quan hệ giữa hai câu đó được xem là một đề cử: một câu đề cập đến một khái niệm nào đó trong văn bản sẽ đề cử cho độc giả một câu khác trong văn bản cũng đề cập đến khái niệm đó"],[182,"Do đó xuất hiện một liên kết giữa các câu có chung nôi dung"],[183,"Độ bao phủ của hai câu có thể đo bằng số lượng từ trùng nhau giữa hai câu hoặc có thể chạy chung một hoặc nhiều bộ lọc ngữ nghĩa, cú pháp"],[184,"Để giảm giá trị của độ tương đồng giữa các câu, tạo thuận lợi trong quá trình tính toán do tồn tại các câu dài thì TextRank sử dụng hệ số chuẩn hoá là chia số lượng nội dung bao phủ cho độ dài của từng câu"],[185,"Với hai câu Si và Sj với một câu được đại diện bởi một tập N các từ xuất hiện trong câu: Si =w1 i + w2 i +.+ wN i Độ tương đồng giữa hai câu Si và Sj được tính theo công thức: Trong đó: Similarity(Si,Sj) là độ tương đồng giữa hai câu Si và Sj wk là từ trong câu log(|Si |) + log(|Sj |) là độ dài câu Si và Sj đã chuẩn hóa Có rất nhiều độ đo độ sự tương đồng giữa các câu với nhau như độ tương tự cô-sin, TRComparer"],[186,"Các độ đo sự tương đồng có thể được sử dụng riêng lẻ hoặc kết hợp với nhau"],[187,"Ở các phần sau của Đồ án sẽ trình bày các biến thể khác của công thức tính độ tương đồng giữa các câu để áp dụng trong thuật toán TextRank"],[188,"3.3"],[189,"Giải thuật TextRank Thuật toán được triển khai theo công thức tính điểm cho các đỉnh trên đồ thị Công thức trên có thể viết gọn lại thành: Trong đó: - Đầu vào của thuật toán là đồ thị G=(V, E) Trong đó: V là tập các đỉnh, Int(Vi) là tập các đỉnh trỏ đến đỉnh Vi , Out(Vi) là tập các đỉnh Vi trỏ đến"],[190,"E là tập các cung, wịj là giá trị/trọng số cung nối hai đỉnh Vi, Vj - Đầu ra của thuật toán là điểm Score(Vi) của mỗi đỉnh Cài đặt giải thuật TextRank tính điểm (Score) cho các đỉnh: Đầu tiên khởi tạo giá trị ban đầu cho các đỉnh với giá trị tùy chọn"],[191,"foreach(Vi V){ vertexScoreVi = 0.15; } Giá trị ngưỡng hội tụ threshold , được gán bằng 10 -5 Biên độ score của đỉnh sau mỗi vòng lặp - ScoreChanged ban đầu được gán bằng 0"],[192,"threshold = 0.00001; ScoreChanged = 0; Vòng lặp tính điểm Score cho các đỉnh do{ beforeLoopScoreChanged = 0; foreach(Vi V){ CurrentVertexScoreVi = 0; sumA = 0; foreach(Vj In(Vi)){ // Tổng giá trị các cung mà đỉnh Vj đi đến sumWjOut = 0; foreach(Vk Out(Vj){ sumWjOut += wjk; } sumA += (wij/sumWEjOut)*WS(Vj); } currentVertexScoreVi +=(1 - d)+ d* sumA; currentScoreChanged = abs(currentVertexScoreVi - vertexScoreVi); if(currentScoreChanged > beforeLoopScoreChanged){ ScoreChanged = currentScoreChanged; }else{ ScoreChanged= beforeLoopScoreChanged; } vertexScoreVi = currentVertexScoreVi; } }while(ScoreChanged > threshold) 3.4"],[193,"Tóm tắt văn bản sử dụng giải thuật TextRank và các độ đo tương đồng 3.4.1"],[194,"Sơ đồ tổng quan các bước thực hiện bài toán"],[195,"Văn bản đầu vào 1"],[196,"Pha Tiền xử lý 2"],[197,"Pha Dựng đồ thị 3"],[198,"Pha Trích rút câu Tách từ, loại bỏ các từ dừng và từ dư thừa - Dựng đỉnh - - Mỗi đỉnh Vi tương ứng với câu Si - - Vi={wi 1, wi 2,"],[199,"wi n) - Dựng cung - Eij(Vi, Vj) = Similarity(Vi, Vj) - Similarity = {Cosine , KeyWord, Filtered, TRCmp., LinTFIDF} - TextRank: Tính điểm cho mỗi đỉnh Vi trên đồ thị G=(V,E) -> {ScoreCal(Vi)} Văn bản tóm tắt Các câu đã loại bỏ từ dừng, từ dư thừa Si={ai 1 , ai 2 ,., ai n } Đồ thị G = (V, E) biểu diễn cho văn bản - Lấy ra n đỉnh Vk có điểm số cao nhất: Output (V) = {Vk} Output(S) = {Sk} Tách văn bản => Các câu văn 3.4.2"],[200,"Pha tiền xử lí văn bản Văn bản đầu vào được mô hình hóa bởi lớp văn bản (Document) có chứa các thuộc tính quan trọng như sau: Class Document = {docTextValues, SentenceDictionary<id, Sentense>} - Trong đó: docTextValues: là nội dung văn bản nguồn SentenceDictionary: là danh sách các câu từ văn bản nguồn Trong danh sách SentenceDictionary<id, Sentense>, lớp câu (Sentense) được mô hình hóa có chứa các thuộc tính quan trọng như sau: Class Sentense = { id, senTextValues, <Terms> } - Trong đó: id: là mã số của câu, tương ứng với số thứ thự của câu trong văn bản senTextValues: là nguyên văn câu trong văn bản nguồn <Terms>: là danh sách các từ của câu Tách câu: - Văn bản đầu vào được tách thành danh sách các câu Si: - Đầu vào: Văn bản nguồn - Đầu ra: Danh sách các câu (SentenceDictionary) Quá trình thực hiện trong thuật toán: Doccument(docTextValues) -> SentenceDictionary<id, Sentense> Tách từ, loại bỏ từ dừng - từ dư thừa - Đầu vào: Văn bản nguồn - Danh sách một số từ ít quan trọng không chứa nhiều thông tin trong văn bản Tiếng Anh (all, just, less, being, indeed, over, both, anyway, detail, four, front, already, through, yourselves, fify, mill, still, its, before, move, whose, one, system, also, somewhere, herself, thick,...[7]) Quá trình thực hiện: Chuyển các kí viết hoa tự về kí tự thường: Sentense.toLower(senTextValues) -> tmpTextValues Tách từ: Sentense.Split (tmpTextValues) -> tmpTerms<terms> Loại bỏ từ dừng và các từ dư thừa"],[201,"if (preTerms<terms> stopWord ) -> Sentense.addTerms(term) Kết quả: Đầu ra là danh sách câu chứa các từ đã loại bỏ từ dừng và từ dư thừa: <Sentense = {<Terms>}> 3.4.3"],[202,"Pha dựng đồ thị 3.4.3.1"],[203,"Khởi tạo các đỉnh Mỗi đỉnh là 1 câu trong văn bản"],[204,"Một đỉnh là một vector tương ứng với một câu"],[205,"Lớp đỉnh (Vertex) được mô hình hóa với các thuộc tính quan trọng như sau: Class Vertex = { id, score} - Trong đó: id: là mã số của đỉnh trong đồ thị - trùng với id của câu trong văn bản score: là điểm số xếp hạng của đỉnh trong đồ thị Khởi tạo các đỉnh Vi có id tương ứng với với id của câu Si: - Đầu vào là danh sách các câu {Si}"],[206,"Đầu ra là danh sách các đỉnh {Vi} Các bước thực hiện trong chương trình: Vertex Vi = new Vertex(si.id) 3.4.3.2"],[207,"Dựng các cung liên kết giữa các đỉnh trong đồ thị Trên đồ thị, mỗi đỉnh đại diện cho một câu trong văn bản"],[208,"Do vậy các cung liên kết giữa các đỉnh trên đồ thị cũng thể hiện sự liên kết giữa các câu với nhau"],[209,"Giá trị của cung liên kết hai đỉnh trên đồ thị đại diện cho giá trị độ đo tương đồng giữa hai câu"],[210,"Đây là công đoạn quan trọng có ảnh hưởng trực tiếp đến kết quả bài toán tóm tắt"],[211,"Lớp cung Edge được mô hình hóa với các thuộc tính quan trọng như sau: Class Edge = { 1stVertexId, 2ndVetexId, weight} - Trong đó: 1stVertexId, 2ndVetexId: là id của hai đỉnh được nối bởi cung đang xét weight: là giá trị/trọng số của cung Thực hiện dựng cung: - Đầu vào là danh sách các các đỉnh Vi tương ứng với mỗi câu Si={wi 1 , wi 2 ,"],[212,"wi n }"],[213,"- Đầu ra là giá trị cung nối giữa các đỉnh: WeightE(Vi,Vj) Các bước thực hiện: Khởi tạo danh sách các cung: graph.Edges = list<Edge> Khởi tạo một cung: Edge E(Vi,Vj) = Edge(Vi,Vj) Tính giá trị cung nối giữa hai đỉnh Vi, Vj áp dụng công thức tính độ tương đồng cho các câu Si, Sj: Tên độ đo Công thức Độ tương đồng Cô-sin Filtered TRComparer LinTFIDF KeyWord Độ tương đồng cô-sin: Với hai câu A, B Trong đó: Ai, Bi là trọng số tf-isf của từ tương ứng trong câu A, B Filtered: Với hai câu Si, Sj, độ tương đồng Filtered được tính theo công thức: Trong đó: - Si={ w1 i , w2 i , ., wn i } ; wk i là các từ trong câu Si - Sj={ w1 j , w2 j , ., wn j } ; wk j là các từ trong câu Sj TRComparer: Với hai câu Si, Sj, độ tương đồng TRComparer được tính theo công thức: Trong đó: - Si={ w1 i , w2 i , ., wn i } ; wk i là các từ trong câu Si - Sj={ w1 j , w2 j , ., wn j } ; wk j là các từ trong câu Sj LinTFIDF: Với hai câu Si, Sj, độ tương đồng LinTFIDF được tính theo công thức: Trong đó: - tfw,i, tfw,j là số lần từ w xuất hiện trong câu Si, Sj - isfw là tần số nghịch đảo của từ w trong văn bản KeyWord: Với hai câu Si, Sj, độ tương đồng KeyWord được tính theo công thức: Trong đó: - K: trong đồ án tập K được coi là tập tất cả các từ trong văn bản 3.4.4"],[214,"Pha trích rút câu Sau khi xây dựng được đồ thị biểu diễn cho văn bản"],[215,"Chương trình thực hiện thuật toán TextRank để tính điểm và xếp hạng cho các đỉnh trên đồ thị"],[216,"Đỉnh Vi có thứ hạng càng cao càng thể hiện sự quan trọng của nó trong đồ thị, cũng đồng nghĩa với việc câu Si là quan trọng trong văn bản"],[217,"Chương trình sẽ lấy ra n đỉnh {Si} tương ứng với các đỉnh {Vi} có thứ hạng cao nhất"],[218,"- Đầu vào: là đồ thị G=(V,E) với danh sách tập các đỉnh V={Vi} và tập giá trị cung E={Eij} - Đầu ra là các các câu tương ứng với đỉnh có thứ hạng cao nhất"],[219,"Các bước thực hiện: Tính điểm cho các đỉnh bằng thuật toán: TextRank (V,E) Sắp xếp các đỉnh theo điểm số: SortVertexByScore (Vi) Lấy ra n đỉnh có điểm số cao nhất: n=10% *(tổng số đỉnh) Voutput = {Vop 1 , Vop 2 , ., Vop n } Lấy ra các câu để làm văn bản tóm tắt Souput tương ứng với Vouput: Soutput = {Sop 1 , Sop 2 , ., Sop n } Chương 4"],[220,"Kết quả thử nghiệm, đánh giá 4.1"],[221,"Tập dữ liệu thử nghiệm 4.1.1"],[222,"Tổng quan về DUC 2007 Hội thảo về Hiểu tài liệu - Document Understanding Conference (DUC) là một loạt các đánh giá về các hệ thống tổng hợp văn bản tự động"],[223,"Nó được tổ chức bởi Viện Tiêu chuẩn và Công nghệ Quốc gia - National Institute of Standards and Technology (NIST) với mục tiêu tăng tiến trình tổng hợp tự động và cho phép các nhà nghiên cứu tham gia vào các thí nghiệm với quy mô lớn"],[224,"DUC 2007 là bộ dữ liệu văn bản bao gồm các văn bản gốc và dữ liệu đã xử lý, được làm thủ công bởi 32 tổ chức đến từ 11 nước tham gia đóng góp"],[225,"Bộ dữ liệu bao gồm ba phần là dữ liệu văn bản thô testdocs và dữ liệu đã được xử lí đánh dấu marked corpus, và marked corpus update Phần dữ liệu testdocs bao gồm: Phần main có 45 chủ đề chính, mỗi chủ đề chứa 25 tài liệu lấy từ các nguồn AP, NYT, XIN newswire và được phát triển bởi 10 chuyên gia/người đánh giá của NIST"],[226,"Phần update là dữ liệu về Mô hình tóm tắt(Model summaries) được viết bởi 10 người đánh giá, có 4 mô hình tóm tắt cho mỗi chủ đề"],[227,"Phần marked corpus và marked corpus update bao gồm dữ liệu của một số chủ đề đã được tóm tắt từ nguồn văn bản testdocs"],[228,"4.1.2"],[229,"Khai thác và sử dụng DUC 2007 cho mục đích tóm tắt văn bản Dữ liệu văn bản thô testdocs được chia thành 45 chủ đề, mỗi chủ đề bao gồm 25 văn bản"],[230,"Các văn bản trong testdocs sẽ được khai thác để làm dữ liệu đầu vào cho hệ thống tóm tắt"],[231,"Các văn bản có cấu trúc lưu trữ như sau: Trong đó cần quan tâm đến các thẻ: <DOCNO>: mã số văn bản cũng có thể coi là tên của văn bản <TEXT>: nội dung của văn bản <P>: các đoạn văn trong văn bản Dữ liệu trong phần marked corpus là các chủ đề đã được phân tích và lưu trữ dưới định dạng *.scu - Summary Content Unit (SCU) được miêu tả như sau: Trong đó: - <collection name= >: tên chủ đề được đặt theo tên thư mục lưu trữ - <document name=>: tên văn bản mã số văn bản trong chủ đề - <line>: 1 câu trong văn bản - scu-count: số các SCU realized by the sentence; agrees with count of SCU elements - <sum-count =>: số bản tóm tắt có sử dụng câu đang xét - <sums=>: các id đại diện cho tổ chức sử dụng câu này trong tóm tắt - uid: định danh SCU - label: nội dung của SCU - weight: số lượng các đoạn văn bản tóm tắt bằng tay mà SCU thể hiện Để lấy ra được một bản tóm tắt mẫu phục vụ cho việc đánh giá kết quả sau này, ta cần trích rút ra những câu theo thuộc tính sums của nút con <annotation>"],[232,"Với mỗi một giá trị này, ta sẽ có được một bản tóm tắt mẫu"],[233,"4.2"],[234,"Phương pháp thử nghiệm Đồ án thực hiện thử nghiệm tóm tắt văn bản Tiếng Anh bằng phương pháp TextRank"],[235,"Trong đó, vấn đề quan trọng là thử nghiệm các cách khác nhau để tính giá trị cung của đồ thị sử dụng trong thuật toán TextRank các độ đo tương đồng: Cosine, KeyWord, Filtered, TRCmp, LinTFIDF"],[236,"Trong Đồ án này, chương trình được thử nghiệm trên tập dữ liệu DUC 2007 bao gồm 575 văn bản thuộc 23 chủ đề đã được đánh dấu tóm tắt bởi nhóm Pyramid Summary Content Unit"],[237,"Tỉ lệ nén thử nghiệm: Các văn bản đầu trong bộ dữ liệu được chương trình tóm tắt trích rút với tỉ lệ nén 10%, 20% theo tổng số câu trong văn bản Tối thiểu số câu trích rút ra là 1"],[238,"Trong một cách thử nghiệm khác: Mỗi văn bản đầu vào được chương trình trích rút lấy số câu cố định là 2 câu để làm văn bản tóm tắt"],[239,"Các độ đo tương đồng được thử nghiệm: Đồ án thử nghiệm riêng lẻ và kết hợp các độ đo tương đồng như đã trình bày ở chương 3"],[240,"Cách thức kết hợp các độ đo tương đồng là áp dụng đồng thời N độ đo - N={1,2,3,4} và lấy giá trị trung bình cộng của chúng"],[241,"Phương pháp đánh giá kết quả: Đồ án sử dụng phương pháp đánh giá ROUGE-N đã trình bày ở chương 2 để đánh giá kết quả của hệ thống tóm tắt văn bản tự động, với N= 1, 2"],[242,"4.3"],[243,"Kết quả thử nghiệm, đánh giá 4.3.1"],[244,"Kết quả thử nghiệm từng độ đo tương đồng riêng lẻ Áp dụng trích rút với tỉ lệ nén"],[245,"Tỉ lệ nén 10% Phương pháp ROUGE-1 ROUGE-2 KeyWord 0.4900 0.3616 TRComparer 0.4599 0.3309 LinTFIDF 0.4231 0.2958 Cosine 0.4179 0.2898 Filtered 0.3087 0.2169 Trung bình: 0.4199 0.2990 Tỉ lệ nén 20% Phương pháp ROUGE-1 ROUGE-2 KeyWord 0.6453 0.5270 TRComparer 0.6099 0.4855 LinTFIDF 0.5826 0.4564 Cosine 0.5805 0.4548 Filtered 0.5322 0.4069 Trung bình: 0.5901 0.4661 Áp dụng trích rút với số câu cố định"],[246,"Số câu trích rút: 2 Phương pháp (N=1) ROUGE-1 ROUGE-2 KeyWord 0.5154 0.3915 TRComparer 0.4859 0.3621 LinTFIDF 0.4390 0.3194 Cosine 0.4334 0.3148 Filtered 0.3332 0.2596 Trung bình: 0.4414 0.3295 bằng 2 Biểu đồ 1"],[247,"Kết quả tóm tắt áp dụng từng độ đo tương đồng riêng lẻ với tỉ lệ nén 10% 0 0.1 0.2 0.3 0.4 0.5 0.6 Cosine Filtered TRComparer LinTFIDF KeyWord ROUGE-1 ROUGE-2 Biểu đồ 2"],[248,"So sánh kết quả giữa các mức độ nén 4.3.2"],[249,"Kết quả thử nghiệm kết hợp đồng thời nhiều độ đo tương đồng Kết quả khi áp dụng đồng thời 2 độ đo tương đồng Tỉ lệ nén 10% Phương pháp (N=2) ROUGE-1 ROUGE-2 KeyWord + TRComparer 0.4717 0.3436 KeyWord + LinTFIDF 0.4454 0.3172 Cosine + KeyWord 0.4421 0.3131 Cosine + TRComparer 0.4407 0.3139 TRComparer + LinTFIDF 0.4352 0.3072 Cosine + LinTFIDF 0.4178 0.2892 KeyWord + Filtered 0.3099 0.2178 Filtered + LinTFIDF 0.3067 0.2166 Cosine + Filtered 0.3056 0.2152 Filtered + TRComparer 0.3054 0.2133 Trung bình N=2: 0.3880 0.2747 Điểm cơ sở (Trung bình N=1) 0.4199 0.2990 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 ROUGE-1 ROUGE-2 Tỉ lệ nén 10% Tỉ lệ nén 20% Trích rút 2 câu Kết quả khi áp dụng đồng thời 3, 4 độ đo tương đồng Tỉ lệ nén 10% Phương pháp (N=3) ROUGE-1 ROUGE-2 Cosine + KeyWord + TRComparer 0.4522 0.3244 KeyWord + TRComparer + LinTFIDF 0.4483 0.3199 Cosine + KeyWord + LinTFIDF 0.4367 0.3082 Cosine + TRComparer + LinTFIDF 0.4298 0.3013 KeyWord + Filtered + TRComparer 0.3079 0.2156 Cosine + KeyWord + Filtered 0.3074 0.2171 KeyWord + Filtered + LinTFIDF 0.3067 0.2165 Cosine + Filtered + TRComparer 0.3058 0.2162 Filtered + TRComparer + LinTFIDF 0.3049 0.2149 Cosine + Filtered + LinTFIDF 0.2981 0.2083 Trung bình N=3: 0.3597 0.2542 Điểm cơ sở (Trung bình N=1) 0.4199 0.2990 Tỉ lệ nén 10% Phương pháp (N=4) ROUGE-1 ROUGE-2 Cosine + KeyWord + TRComparer + LinTFIDF 0.4380 0.3094 KeyWord + Filtered + TRComparer + LinTFIDF 0.3073 0.2182 Cosine + KeyWord + Filtered + TRComparer 0.3063 0.2167 Cosine + KeyWord + Filtered + LinTFIDF 0.2997 0.2098 Cosine + Filtered + TRComparer + LinTFIDF 0.2980 0.2086 Trung bình N=4: 0.3298 0.2325 Điểm cơ sở (Trung bình N=1) 0.4199 0.2990 Biểu đồ 3"],[250,"So sánh kết quả áp dụng đồng thời N độ đo tương đồng, tỉ lệ nén 10% 4.3.3"],[251,"Đánh giá kết quả thử nghiệm Đồ án đã thử nghiệm tóm tắt 575 văn bản trong tập dữ liệu DUC 2007"],[252,"Trong đó có thử nghiệm việc sử dụng Cosine, KeyWord, Filtered, TRCmp, LinTFIDF là các cách khác nhau đ"]],"downloaded":true,"m":[-1,-1],"n":"20101559_Nguyen_Xuan_Hoa_1495982153177.txt","o":"http://storage.googleapis.com/soict-projects/httt/dhcq/20101559_Nguyen_Xuan_Hoa_1495982153177.pdf\r"},{"saved_path":"temp/20130150_Nguyen_Nam_Anh_1527526468353.txt","r":0.333812952041626,"s":[[55,113,0.930232584476471,40,0,42,0,42,"Ngược lại, tóm tắt đa văn bản là từ nhiều văn bản nguồn cũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng thời cho nhiều văn bản khác nhau","Ngược lại tóm tắt đa văn bản là từ một văn bản nguồn cũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng thời cho nhiều văn bản khác nhau"],[54,112,0.800000011920929,18,5,24,0,19,"Theo đầu vào hệ thống Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn gọn của văn bản đó","Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn ngọn của văn bản đó"]],"t":"\n\r\nTrường Đại học Bách Khoa Hà Nội  \r\n\r\nViện Công nghệ Thông Tin và Truyền Thông \r\n\r\n \r\n\r\n \r\n\r\nĐồ án Tốt nghiệp Đại học \r\n\r\n \r\n\r\n \r\n\r\nTóm tắt văn bản bằng \r\n\r\nDeep Learning và Áp dụng \r\n\r\nxây dựng ứng dụng Android \r\n \r\n\r\n \r\n\r\nNguyễn Nam Anh  \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\nHà Nội, 06/2018\r\n\r\n\r\n\r\nTrường Đại học Bách Khoa Hà Nội \r\n\r\nViện Công nghệ Thông Tin và Truyền Thông \r\n\r\n \r\n\r\n \r\n\r\nĐồ án Tốt nghiệp Đại học \r\n\r\n \r\n\r\n \r\n\r\nTóm tắt văn bản bằng \r\n\r\nDeep Learning và Áp dụng \r\n\r\nxây dựng ứng dụng Android \r\n \r\n\r\n \r\n\r\n\r\nNgười hướng dẫn ThS. Hoàng Anh Việt \r\n\r\n \r\n\r\n \r\n\r\nHà Nội, 06/2018\r\n\r\n\r\n\r\n \r\niii \r\n\r\nHọ và tên sinh viên :  Nguyễn Nam Anh           \r\n\r\nĐiện thoại liên lạc:     0978 322 456   Email: namanh11611@gmail.com \r\n\r\nLớp:   CNTT 2.01  K58       Hệ đào tạo: Chính quy \r\n\r\n \r\n\r\nTôi  Nguyễn Nam Anh  cam kết Đồ án Tốt nghiệp (ĐATN) là công trình nghiên \r\n\r\ncứu của bản thân tôi dưới sự hướng dẫn của ThS. Hoàng Anh Việt. Các kết quả nêu \r\n\r\ntrong ĐATN là trung thực, là thành quả của riêng tôi, không sao chép theo bất kỳ \r\n\r\ncông trình nào khác. Tất cả những tham khảo trong ĐATN  bao gồm hình ảnh, bảng \r\n\r\nbiểu, số liệu, và các câu từ trích dẫn  đều được ghi rõ ràng và đầy đủ nguồn gốc \r\n\r\ntrong danh mục tài liệu tham khảo. Tôi xin hoàn toàn chịu trách nhiệm với dù chỉ một \r\n\r\nsao chép vi phạm quy chế của nhà trường. \r\n\r\n      Hà Nội, ngày 28 tháng 5 năm 2018 \r\n\r\n Tác giả ĐATN \r\n\r\n \r\n\r\n \r\n\r\nNguyễn Nam Anh \r\n\r\nLời cam kết \r\n\r\n\r\n\r\n \r\niv \r\n\r\nNăm tháng trôi đi tựa như một cơn gió lướt qua tuổi thanh xuân. Năm năm gắn với \r\n\r\nBách Khoa, tuy không dài nhưng cũng không phải là ngắn, khoảng thời gian đó sẽ \r\n\r\nmãi là ký ức về một thời tuổi trẻ khao khát và dại khờ. Không phải ngẫu nhiên mà \r\n\r\ncon đường phía bên kia cổng Parabol được đặt tên là Giải Phóng. Trải qua chín kỳ \r\n\r\nthi và một kỳ đồ án, ai cũng mòn mỏi chờ đợi đến ngày mình trưởng thành, đủ năng \r\n\r\nlực và bản lĩnh để bước chân qua cánh cổng Parabol. Thế nhưng, nếu được chọn lại \r\n\r\nmột lần nữa, chúng tôi vẫn sẽ chọn Bách Khoa. \r\n\r\nEm xin gửi lời cảm ơn chân thành tới các thầy cô trường đại học Bách Khoa Hà Nội \r\n\r\nnói chung và viện Công nghệ Thông tin và Truyền thông nói riêng, đặc biệt là thầy \r\n\r\nThS. Hoàng Anh Việt đã tận tình dạy dỗ, truyền đạt cho chúng em những kiến thức \r\n\r\nbổ ích suốt năm năm đại học. Thầy cô không chỉ giảng dạy những bài học về chuyên \r\n\r\nmôn mà còn truyền cho chúng em cả chất Bách Khoa đã được hun đúc qua bao \r\n\r\nnhiêu thế hệ. \r\n\r\nCảm ơn những người anh, người em đã luôn ở bên đồng hành cùng tôi trong những \r\n\r\nkhoảnh khắc khó khăn nhất. Mỗi người các bạn là một mảnh ghép tạo nên bức tranh \r\n\r\nvề thời sinh viên Bách Khoa gian khó nhưng cũng đầy ắp kỷ niệm của tôi. Và cảm \r\n\r\nơn em, người tôi từng thương, đã giúp tôi nhận ra phải biết trân trọng những người ở \r\n\r\nbên cạnh mình đến nhường nào. \r\n\r\nCuối cùng, con xin được gửi lời cảm ơn chân thành tới gia đình đã luôn ở bên cạnh \r\n\r\nyêu thương, động viên và tạo mọi điều kiện tốt nhất cho con trong suốt năm năm qua. \r\n\r\nQua mỗi lần tưởng chừng như gục ngã, bố mẹ và em gái luôn là nguồn động lực lớn \r\n\r\nnhất để giúp con đứng dậy mạnh mẽ hơn. \r\n\r\nLời cảm ơn \r\n\r\n\r\n\r\n \r\nv \r\n\r\nTrong thời đại công nghệ số, lượng thông tin trên mạng Internet đang tăng trưởng \r\n\r\ntừng giây theo cấp số mũ. Trong đó, đa phần nội dung số được biểu diễn dưới dạng \r\n\r\ncác văn bản thuần tuý. Để có thể nắm bắt được lượng thông tin lớn nhất trong thời \r\n\r\ngian nhanh nhất, cần thiết có một phương pháp tóm tắt văn bản chính xác và hiệu \r\n\r\nquả. Bên cạnh đó, để cải tiến phương thức tương tác giữa con người và máy tính, cần \r\n\r\nthiết có một công cụ để chuyển văn bản thành giọng nói, giúp người dùng dễ dàng \r\n\r\ntiếp nhận thông tin từ các thiết bị hơn. \r\n\r\nĐã có nhiều giải pháp tóm tắt văn bản được đưa ra, nhưng mỗi phương pháp đều có \r\n\r\nnhững nhược điểm chưa khắc phục được về vấn đề xử lý ngữ nghĩa. Gần đây, với sự \r\n\r\nphát triển của công nghệ Machine Learning nói chung và Deep Learning nói riêng, \r\n\r\nbài toán tóm tắt văn bản đã được giải quyết một cách tối ưu hơn nhiều so với các \r\n\r\nphương pháp cũ. Để giải quyết bài toán, người viết đồ án lựa chọn mô hình sequence \r\n\r\nto sequence kết hợp với kỹ thuật attention. Mô hình được thực hiện dựa trên việc xây \r\n\r\ndựng mạng neural LSTM  một dạng đặc biệt của mạng neural hồi quy. Đi kèm với \r\n\r\nđó là công nghệ text-to-speech trên nền tảng Android đã được phát triển bởi Google \r\n\r\nđể giúp truyền đạt thông tin tới người dùng qua giọng nói thay vì dạng văn bản thông \r\n\r\nthường. Tất cả các công nghệ trên sẽ được tích hợp trên một ứng dụng di động \r\n\r\nAndroid hoàn chỉnh. \r\n\r\nNội dung đồ án sẽ khái quát những kiến thức về phương pháp tóm tắt văn bản bằng \r\n\r\ncông nghệ Deep Learning và công nghệ text-to-speech. Cùng với đó là quy trình phát \r\n\r\ntriển ứng dụng trên nền tảng Android với hai chức năng chính áp dụng các công nghệ \r\n\r\nđã trình bày. \r\n\r\nTóm tắt \r\n\r\n\r\n\r\n \r\nvi \r\n\r\nMục lục \r\n\r\n\r\n\r\n \r\nvii \r\n\r\nviii \r\n\r\nix \r\n\r\nx \r\n\r\nxi \r\n\r\nDanh mục hình vẽ \r\n\r\n\r\n\r\n \r\nxii \r\n\r\nxiii \r\n\r\nDanh mục bảng \r\n\r\n\r\n\r\n \r\nxiv \r\n\r\nDanh mục công thức  \r\n\r\n\r\n\r\n \r\nxv \r\n\r\nAI \r\nArtificial Intelligence \r\n\r\nTrí tuệ nhân tạo \r\n\r\nML \r\nMachine Learning \r\n\r\nHọc Máy \r\n\r\nDL \r\nDeep Learning \r\n\r\nHọc sâu \r\n\r\nRNN \r\nRecurrent Neural Network \r\n\r\nMạng nơ-ron hồi quy \r\n\r\nbiRNN \r\nBidirectional RNN \r\n\r\nMạng nơ-ron hồi quy 2 chiều \r\n\r\nLSTM \r\nLong Short-Term Memory \r\n\r\nMạng bộ nhớ dài-ngắn \r\n\r\nTTS \r\nText-to-Speech \r\n\r\nChuyển văn bản thành giọng nói \r\n\r\nDanh mục các từ viết tắt \r\n\r\n\r\n\r\n \r\nxvi \r\n\r\nSeq2Seq Sequence to Sequence \r\n\r\nAPI \r\nApplication Programming Interface \r\n\r\nGiao diện lập trình ứng dụng \r\n\r\nMVC Model  View  Controller \r\n\r\n \r\n\r\n\r\n\r\n \r\nxvii \r\n\r\nExtractive Text \r\n\r\nSummarization \r\n\r\nPhương pháp tóm tắt trích xuất văn bản \r\n\r\nAbstractive Text \r\n\r\nSummarization \r\n\r\nPhương pháp tóm tắt tóm lược văn bản \r\n\r\nNeural Network Mạng nơ-ron \r\n\r\nWord Empeddings Kỹ thuật ánh xạ từ với các vec-tơ số thực \r\n\r\nAttention Kỹ thuật chú ý từ \r\n\r\nEncoder Bộ mã hoá \r\n\r\nDecoder Bộ giải mã \r\n\r\n \r\n\r\nDanh mục thuật ngữ \r\n\r\n\r\n\r\n \r\n1 \r\n\r\n1.1 Đặt vấn đề \r\n\r\nCùng với sự phát triển của Internet, lượng kiến thức và thông tin của nhân loại là vô \r\n\r\ncùng lớn và gia tăng nhanh chóng theo thời gian. Con người bị choáng ngợp trước \r\n\r\nlượng thông tin vô cùng lớn này. Nhu cầu nắm bắt các thông tin chính ngày càng lớn. \r\n\r\nDo đó, tầm quan trọng của việc tóm tắt văn bản ngày càng được nâng cao. Việc tóm \r\n\r\ntắt giúp cho người đọc dễ dàng nắm bắt được thông tin quan trọng một cách nhanh \r\n\r\nchóng. \r\n\r\nVậy tóm tắt văn bản là gì? Tóm tắt văn bản là quá trình lấy các thông tin quan trọng \r\n\r\nnhất từ một hoặc nhiều văn bản để tạo ra một văn bản ngắn gọn nhưng vẫn mang đầy \r\n\r\nđủ các thông tin của phiên bản gốc và đảm bảo tính đúng về ngữ pháp. Bản tóm tắt \r\n\r\nphải chứa những thông tin chính và ý nghĩa tổng thể của văn bản gốc. Đồng thời nội \r\n\r\ndung của bản tóm tắt phải trung thực. Độ dài của bản tóm tắt nhỏ độ dài của bản gốc. \r\n\r\nTóm tắt văn bản tự động là quá trình tóm tắt văn bản bằng phần mềm.  \r\n\r\nTóm tắt văn bản tự động là một thách thức rất lớn, bởi vì khi chúng ta tóm tắt một \r\n\r\nđoạn văn, chúng ta thường hay đọc nó để hiểu nội dung của nó sau đó ghi những điểm \r\n\r\nchính của nó. Vì máy tính thiếu kiến thức về ngôn ngữ và khả năng ngôn ngữ nên \r\n\r\ntổng hợp văn bản tự động trở thành một việc không dễ dàng. Chính vì thế, đã có nhiều \r\n\r\nkỹ thuật được sử dụng để trích xuất các nội dung quan trọng từ vản bản để mô tả tóm \r\n\r\nlược tài liệu. Mục đích của tóm tắt văn bản tự động là để tạo ra một văn bản trình bày \r\n\r\nngắn hơn văn bản gốc, loại bỏ đi các thông tin không quan trọng và vẫn giữ được \r\n\r\nnhững nội dung cốt lõi. Qua đó, giúp con người tiết kiệm công sức và thời gian trong \r\n\r\nviệc nắm bắt các thông tin quan trọng. \r\n\r\nChương 1 Giới thiệu đề tài \r\n\r\n\r\n\r\n \r\n2 \r\n\r\n1.2 Mục tiêu và phạm vi đề tài \r\n\r\n1.2.1 Lịch sử nghiên cứu về tóm tắt văn bản \r\n\r\nTóm tắt văn bản bắt đầu từ những năm cuối thập kỉ 1950 với nghiên cứu của Luhn \r\n\r\n(1958) dựa trên tần số từ. Ý tưởng cơ bản của phương pháp tần số từ dựa trên kiến \r\n\r\nthức cho rằng tần số của từng từ trong văn bản là một độ đo hữu dụng để đánh giá \r\n\r\ntầm quan trọng của chúng. \r\n\r\nTiếp theo đó là phương pháp tóm tắt dựa trên vị trí của các câu trong văn bản của \r\n\r\nBaxendale (1958) và những nghiên cứu của Edmundson (1969) về vị trí của các câu \r\n\r\ntrong văn bản và các từ/cụm từ mang ý nghĩa tổng quát. Theo đó, những câu bắt đầu \r\n\r\nvà kết thúc của đoạn văn, bài viết hay những câu chứa những từ như important \r\n\r\n(quan trọng), result are (kết quả là). là những câu có ý nghĩa quan trọng. \r\n\r\nĐầu những năm 1970, tiếp tục có những nghiên cứu với hướng tiếp cận ngoài (sử \r\n\r\ndụng các cụm từ dấu hiệu) và được ứng dụng trong các phần mềm thương mại. \r\n\r\nNhững năm 1980, phát triển nhiều nghiên cứu với nhiều hướng khác nhau, đặc biệt \r\n\r\nlà hướng tiếp cận mức thực thể dựa trên trí tuệ nhân tạo như sử dụng script (Lehnert \r\n\r\n1981), các luật sản xuất mạng và logic (Fum 1985), mạng ngữ nghĩa (Reimer và Hahn \r\n\r\n1988) cũng như các hướng tiếp cận kết hợp (Rau 1989) hay (Aretoulaki 1994). \r\n\r\nWillam B. Cavnar (1994) biểu diễn văn bản dựa trên n-gram thay cho cách biểu diễn \r\n\r\ntruyền thống bằng từ khoá. \r\n\r\nJaine Carbonell (1998) đã tóm tắt văn bản bằng cách xếp hạng các câu trội (câu chứa \r\n\r\ncác ý chính của văn bản) và rút ra các câu trội. \r\n\r\nJade Goldstein (1999) phân loại tóm tắt dựa trên độ đo liên quan, phương pháp sử \r\n\r\ndụng kết hợp giữa ngữ học, thống kê. Một câu được đặc trưng bằng các đặc tính ngữ \r\n\r\nhọc và độ đo thống kê. \r\n\r\n\r\n\r\n \r\n3 \r\n\r\nJ.Larocca Neto (2000) đã tạo tóm tắt văn bản dựa trên các dãy từ trong câu được chọn \r\n\r\ntheo hệ số tf, sau đó dùng kỹ thuật gom cụm (clustering) để tạo tóm tắt. \r\n\r\nYoshio (2001) đã tạo tóm tắt văn bản tiếng Nhật. Có 2 phương pháp là rút câu dựa \r\n\r\ntrên từ khoá và rút câu dựa trên kiến trúc ngữ nghĩa trong đó có xây dựng độ đo mối \r\n\r\nliên kiết giữa hai từ. \r\n\r\nHiện nay, một số nghiên cứu về xử lý ngôn ngữ tự nhiên cũng bước đầu được áp dụng \r\n\r\ntrong tóm tắt văn bản. Mặt khác, các nghiên cứu về tóm tắt đa văn bản, đa ngôn ngữ \r\n\r\nvà tóm tắt đa phương tiện cũng bắt đầu phát triển. \r\n\r\n1.2.2 Phân loại phương pháp tóm tắt văn bản \r\n\r\n1.2.2.1 Phương pháp tóm tắt trích xuất \r\n\r\nPhương pháp tóm tắt trích xuất (Extractive Text Summarization) bao gồm việc lựa \r\n\r\nchọn đơn vị của văn bản (câu hay đoạn văn), được coi là có chứa lượng thông tin cốt \r\n\r\ntử của văn bản (informative content, informativity), và kết nối các đơn vị này theo \r\n\r\nmột trình tự thích hợp. Một trích xuất là sự lắp ghép các đoạn được trích rút ra từ văn \r\n\r\nbản nguồn. Mục tiêu của trích xuất là cung cấp một cái nhìn tổng quan về nội dung \r\n\r\ncủa văn bản gốc. Độ dài của văn bản tóm tắt bằng trích xuất có thể được xác định bởi \r\n\r\ntỉ lệ nén, hay nói cách khác Văn bản tóm tắt ngắn hơn bao nhiêu so với văn bản \r\n\r\ngốc. \r\n\r\nThuật toán tóm tắt tự động bằng trích xuất có thể chia ra làm 3 mức: surfacelevel \r\n\r\n(mức bề mặt), intermediate-level (mức trung bình) và deep parsing techniques (các \r\n\r\nkĩ thuật phân tích sâu). \r\n\r\nTóm tắt trích rút xuất phát từ ý tưởng: Một tài liệu được chia nhỏ thành các đơn vị \r\n\r\nngữ pháp (các câu văn), sau đó được đánh trọng số theo kinh nghiệm (heuristic); Các \r\n\r\nđơn vị ngữ pháp có điểm cao nhất sẽ được trích rút và liên kết với nhau để tạo nên \r\n\r\nvăn bản tóm tắt. \r\n\r\n\r\n\r\n \r\n4 \r\n\r\n1.2.2.2 Phương pháp tóm tắt tóm lược \r\n\r\nTuy tóm tắt bằng trích rút đã thành công trong việc xác định câu nào trong văn bản \r\n\r\nđầu vào mang nội dung quan trọng nhưng dường như những phương pháp này rất xa \r\n\r\nvới việc tạo ra một bản tóm tắt tối ưu theo nghĩa cả về nội dung và chất lượng trong \r\n\r\nngôn ngữ học. Trong khi đó, hệ thống tạo ra văn bản tóm tắt bằng phương pháp tóm \r\n\r\nlược (Abstractive Text Summarization) dựa trên việc hiểu văn bản gốc và đạt tới việc \r\n\r\nsinh ra một văn bản mới một cách chính xác về ngữ pháp, súc tích và mạch lạc về nội \r\n\r\ndung, bằng cách sinh ra văn bản tóm tắt bằng những từ vựng không xuất hiện trong \r\n\r\nvăn bản gốc. Trong tóm lược, việc diễn giải, viết lại các câu phức tạp sẽ nhằm mục \r\n\r\nđích tạo ra phiên bản súc tích của nội dung ban đầu. Mặc dù con người có thể tái sử \r\n\r\ndụng một phần văn bản gốc nhưng không phải sử dụng toàn bộ nó, sử dụng các đoạn \r\n\r\nhay một phần của câu thay vì sử dụng toàn bộ câu. \r\n\r\nTuy đã có nhiều nghiên cứu trong lĩnh vực tóm tắt văn bản, nhưng việc ứng dụng các \r\n\r\nkết quả vào thực tế vẫn đang còn hạn chế. Như vậy, mục tiêu của đề tài là nghiên cứu \r\n\r\nvề phương pháp tóm tắt văn bản bằng Deep Learning, sau đó áp dụng kết quả vào \r\n\r\nứng dụng thực tế, cụ thể là ứng dụng di động trên nền tảng Android. \r\n\r\n1.3 Định hướng giải pháp \r\n\r\nHầu hết các phương pháp tóm tắt văn bản hiện nay là trích xuất. Mục đích của tóm \r\n\r\ntắt tự động là tạo ra những văn bản giống với tóm tắt của con người, mà con người \r\n\r\nthường không tóm tắt theo kiểu trích xuất. Thực tế cho thấy, các phương pháp tóm \r\n\r\ntắt tóm lược gần với cách tóm tắt của con người hơn so với các phương pháp trích \r\n\r\nxuất.  \r\n\r\nVới sự tiến bộ trong lĩnh vực Machine Learning (Học máy) nói chung và Deep \r\n\r\nLearning (Học sâu) nói riêng, có rất nhiều phương pháp đã chứng minh được tính \r\n\r\nhiệu quả trong việc giải quyết những bài toán phức tạp mà các cách tiếp cận truyền \r\n\r\nthống chưa thể giải quyết triệt để được.  \r\n\r\n\r\n\r\n \r\n5 \r\n\r\nTrong phạm vi khóa luận, sinh viên tập trung nghiên cứu các bài toán tóm tắt đơn văn \r\n\r\nbản, theo phương pháp tóm tắt tóm lược (Abstractive Summarization) sử dụng công \r\n\r\nnghệ Deep Learning. Cụ thể, sinh viên sử dụng mô hình đang phổ biến hiện nay là \r\n\r\nSequence to Sequence cùng với kĩ thuật attention. Mô hình được xây dựng dựa trên \r\n\r\nmạng neural LSTM và kỹ thuật word embeddings. \r\n\r\nVề ứng dụng di động, sinh viên xây dựng trên nền tảng Android, vì đây là hệ điều \r\n\r\nhành chiếm thị phần lớn nhất của thị trường điện thoại di động. Như vậy, ứng dụng \r\n\r\ncó thể dễ dàng tiếp cận với lượng lớn người dùng. Kết quả tóm tắt văn bản sẽ xử lý \r\n\r\ntrên server được xây dựng bằng Django. \r\n\r\n1.4 Bố cục đồ án \r\n\r\nPhần còn lại của báo cáo đồ án tốt nghiệp này được tổ chức như sau.  \r\n\r\nChương 2 trình bày tình hình các nghiên cứu về tóm tắt văn bản tự động theo hai \r\n\r\nhướng tiếp cận chính là đơn văn bản và đa văn bản. Trong đó, mỗi phương pháp tóm \r\n\r\ntắt mô tả tổng quan về cách thực hiện, bộ dữ liệu sử dụng, các kết quả đạt được và độ \r\n\r\nchính xác. Cùng với đó là phân tích tổng quan về yêu cầu của phần mềm. \r\n\r\nTrong Chương 3, sinh viên giới thiệu về các lý thuyết nền tảng của phương pháp tóm \r\n\r\ntắt văn bản bằng Deep Learning. Chúng ta sẽ tìm hiểu về các khái niệm Machine \r\n\r\nLearning, Deep Learning, mạng neural nhân tạo, mạng RNN, mạng LSTM. Sau đó \r\n\r\nlà trình bày về mô hình sequence to sequence, kỹ thuật attention và word embeddings. \r\n\r\nSau khi đã tìm hiểu về các phương pháp tóm tắt văn bản, cơ sở lý thuyết của tóm tắt \r\n\r\nvăn bản bằng Deep Learning, Chương 4 trình bày quá trình triển khai model tóm tắt \r\n\r\nvăn bản và các kết quả đạt được. Nội dung gồm hai phần chính, trong đó phần 4.1 \r\n\r\nmô tả model được xây dựng dựa trên thư viện TensorFlow, và phần 4.2 mô tả ứng \r\n\r\ndụng di động Android với chức năng chính là tóm tắt văn bản. \r\n\r\n\r\n\r\n \r\n6 \r\n\r\nChương 5 nêu các đóng góp chính của sinh viên trong đồ án. Cụ thể, nội dung chương \r\n\r\nnày trình bày về việc cải tiến word embedding, quá trình xây dựng server và ứng dụng \r\n\r\ndi động Android. \r\n\r\nKết luận và hướng phát triển của đồ án được trình bày trong Chương 6. Trong đó, \r\n\r\nsinh viên tổng kết lại những kết quả đã đạt được và những gì cần cải tiến trong tương \r\n\r\nlai của đồ án này. \r\n\r\n\r\n\r\n \r\n7 \r\n\r\nChương 2 sẽ trình bày tổng quan về các kết quả nghiên cứu liên quan đến tóm tắt văn \r\n\r\nbản tự động. Với mục đích là một đồ án nghiên cứu, chúng ta cần nắm được lịch sử \r\n\r\ncác phương pháp tóm tắt văn bản đã được xây dựng và phát triển. Sinh viên sẽ trình \r\n\r\nbày từ những nghiên cứu về cách trích xuất văn bản cơ bản cho đến các phương pháp \r\n\r\ntóm lược phức tạp ngày nay áp dụng Deep Learning. Nhìn chung, mỗi phương pháp \r\n\r\nđều có ưu, nhược điểm riêng, tính hiệu quả của nó thể hiện qua các kết quả được đo \r\n\r\nđạc, đánh giá cụ thể. \r\n\r\nCùng với đó, nội dung Chương 2 cũng trình bày tóm tắt về các chức năng của ứng \r\n\r\ndụng Android. Trong đó chú trọng về chức năng Tóm tắt văn bản. \r\n\r\n2.1 Khảo sát hiện trạng \r\n\r\nTóm tắt văn bản tự động là một bài toán kinh điển trong lĩnh vực xử lý dữ liệu văn \r\n\r\nbản. Hiện nay trên thế giới, nhiều nhà khoa học và các công ty tỏ ra rất quan tâm đến \r\n\r\nbài toán này. Tại các hội nghị nổi tiếng như: DUC 2001 - 2007, TAC 2008 - 2011, \r\n\r\nACL 2001-2015, tóm tắt văn bản tự động đã được đề cập đến nhiều trong các bài báo. \r\n\r\nNgoài ra, có nhiều hệ thống tóm tắt văn bản độc lập hoặc tích hợp được phát triển \r\n\r\nnhư: MEAD, LexRank. \r\n\r\nCác kết quả nghiên cứu của tóm tắt văn bản được ứng dụng trong nhiều lĩnh vực như: \r\n\r\n Tóm tắt tin tức trong lĩnh vực báo chí \r\n\r\nChương 2 Khảo sát và \r\n\r\nphân tích yêu cầu \r\n\r\n\r\n\r\n \r\n8 \r\n\r\n Tóm tắt kết quả tìm kiếm trong các search engine \r\n\r\n Thu thập dữ liệu thông minh \r\n\r\n Tóm tắt bài báo khoa học \r\n\r\n Tóm tắt nội dung cuộc họp, hội nghị \r\n\r\n Hệ thống trả lời tự động \r\n\r\nMặc dù có 2 dạng tóm tắt là tóm tắt trích xuất (Extractive Text Summarization) và \r\n\r\ntóm tắt tóm lược (Abstractive Text Summarization), tuy nhiên để thực hiện tóm lược \r\n\r\ncần có một lượng tri thức đầy đủ về lĩnh vực cần tóm tắt. Điều này hiện nay vẫn còn \r\n\r\nhạn chế nhiều, do đó các hướng tiếp cận đa số tập trung vào dạng tóm tắt trích xuất. \r\n\r\nMột trong những cách phân chia của bài toán tóm tắt là: tóm tắt đơn văn bản và tóm \r\n\r\ntắt đa văn bản. Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn ngọn \r\n\r\ncủa văn bản đó. Ngược lại tóm tắt đa văn bản là từ một văn bản nguồn cũng chỉ cho \r\n\r\nra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản \r\n\r\nđồng thời cho nhiều văn bản khác nhau. \r\n\r\n2.2 Tình hình nghiên cứu hiện nay \r\n\r\n2.2.1 Hướng tiếp cận cho tóm tắt đơn văn bản \r\n\r\n2.2.1.1 Phương pháp thống kê \r\n\r\nHầu hết các nghiên cứu đầu tiên cho tóm tắt đơn văn bản đều tập trung trên những \r\n\r\nvăn bản kỹ thuật (các bài báo khoa học). Các phương pháp cổ điển thường tập trung \r\n\r\nvào các đặc trưng hình thái để tính điểm cho các câu và trích rút các câu quan trọng \r\n\r\nđể đưa vào tóm tắt. \r\n\r\nÝ tưởng chính của hướng tiếp cận gồm các bước (i) thu thập dữ liệu, (ii) tạo các văn \r\n\r\nbản tóm tắt thủ công, (iii) thiết kế các công thức toán học hay logic để tính điểm cho \r\n\r\ncác câu, (iv) tính điểm cho từng câu để tạo ra bản tóm tắt cho từng văn bản trong dữ \r\n\r\nliệu dựa vào các đặc trưng về hình thái, (v) so sánh tóm tắt được tạo tự động với tóm \r\n\r\n\r\n\r\n \r\n9 \r\n\r\ntắt được tạo thủ công, và (vi) cải thiện lại phương thức tính điểm. Các bước (iv), (v) \r\n\r\nvà (vi) sẽ được lặp lại cho đến khi tóm tắt tự động đạt được tính tương đương với tóm \r\n\r\ntắt thủ công. \r\n\r\nCác nghiên cứu đại diện cho phương pháp này gồm: \r\n\r\n Luhn (1958): dùng phương pháp so khớp từng ký tự để giải quyết stemming; \r\n\r\nsử dụng các đặc trưng như word frequency, stop words, word distance. \r\n\r\n Baxendale (1958): phương pháp khá chính xác nhưng mang tính chủ quan và \r\n\r\nđơn giản, được sử dụng khá nhiều vào các hệ thống học máy sau này; sử dụng \r\n\r\ncác đặc trưng như sentence position. Thử nghiệm 200 đoạn văn, 85% các câu \r\n\r\nđầu là câu chính và 7% các câu cuối và câu chính. \r\n\r\n Edmundson (1969): điển hình nhất trong các phương pháp cổ điển; sử dụng \r\n\r\nphương pháp kết nối tuyến tính để kết hợp các điểm đặc trưng lại với nhau; sử \r\n\r\ndụng các đặc trưng như: word frequency, stop words, position, cue words, \r\n\r\ntitle; đã được thử nghiệm với 400 văn bản kỹ thuật và kết quả đạt 44%. \r\n\r\n2.2.1.2 Phương pháp thống kê trên TF.IDF \r\n\r\nPhương pháp này còn gọi là mô hình túi từ (bag-of-words), sử dụng mô hình trọng \r\n\r\nsố TF.IDF (term frequency và inverse sentence frequence). Ở mô hình này, giá trị \r\n\r\nIDF được tính trên câu. Trong đó, TF là số lần xuất hiện của term trong 1 câu. Và DF \r\n\r\nlà số câu có chứa term. \r\n\r\nCùng với phương pháp tính độ đo TF.IDF và phương pháp biểu diễn văn bản bằng \r\n\r\nvector không gian sử dụng Vector Space Model (Saton 1975). \r\n\r\nTuy nhiên, phương pháp dùng độ đo TF.IDF không được dùng độc lập, mà thường \r\n\r\nđược kết hợp với các phương pháp khác như máy học, đồ thị. để đạt được hiệu quả \r\n\r\ncao hơn. \r\n\r\n\r\n\r\n \r\n10 \r\n\r\n2.2.1.3 Phương pháp Nave-Bayes \r\n\r\nCác hướng tiếp cận theo phương pháp này giả định rằng các đặc trưng của văn bản \r\n\r\nđộc lập nhau. Sử dụng bộ phân lớp Nave-Bayes để xác định câu nào thuộc về tóm \r\n\r\ntắt và ngược lại. Tính xác suất các câu thuộc về tóm tắt, n câu có xác suất cao nhất sẽ \r\n\r\nđược trích rút. \r\n\r\nCác nghiên cứu đại điện cho phương pháp này: \r\n\r\n Kupiec (1995): các đặc trưng sử dụng gồm word frequency, location, cue \r\n\r\nword, title & leading, sentence length, uppercase words. Ngữ liệu: 188 cặp văn \r\n\r\nbản khoa học và tóm tắt. Tổng số câu:  568 câu. Số câu khớp trực tiếp với tóm \r\n\r\ntắt 451 (79%). \r\n\r\n Aone (1999): kết hợp thêm nhiều đặc trưng phong phú hơn: TF.IDF (single \r\n\r\nword, two-noun word, named-entities), discourse (cohension) (sử dụng \r\n\r\nWordNet và kỹ thuật sử lý ngôn ngữ tự nhiên để phân tích sự tham chiếu đối \r\n\r\nvới các thực thể). Ngữ liệu được sử dụng của TREC. Hệ thống được xây dựng \r\n\r\nmang tên DimSum. \r\n\r\n2.2.1.4 Phương pháp Decision Tree \r\n\r\nLin & Hovy (1999) đại diện của phương pháp này giả định rằng, các đặc trưng không \r\n\r\nđộc lập với nhau. Tác giả đã kiểm tra nhiều đặc trưng và ảnh hưởng của chúng lên \r\n\r\nquá trình rút trích. Hệ thống tóm tắt của Lin là loại tóm tắt hướng về truy vấn (query-\r\n\r\nbased). \r\n\r\nCác đặc trưng: position (OOP), numeric data, proper name, pronoun & adjective, \r\n\r\nweekday hoặc month. Cùng với 2 đăc trưng mới: query signature (số từ truy vấn có \r\n\r\ntrong câu) và IR signature (những từ nổi bật, quan trọng ~ tf*idf). \r\n\r\nHệ thống Summarist của Lin và Hovy sử dụng thuật toán C4.5 để huấn luyện cây \r\n\r\nquyết định. Hệ thống sử dụng tập ngữ liệu của TIPSTER-SUMMAC. \r\n\r\n\r\n\r\n \r\n11 \r\n\r\n2.2.1.5 Phương pháp Hidden Makov Model \r\n\r\nNhững hướng tiếp cận trước đều dựa trên những đặc trưng và không tuần tự. Conroy \r\n\r\nvà Oleary (2001) đã đưa ra hướng tiếp cận dựa trên mô hình HMM với ý tưởng cơ \r\n\r\nbản là sử dụng một chuỗi tuần tự các câu. Tác giả đưa ra khái niệm về sự phụ thuộc \r\n\r\ncục bộ (local dependencies) giữa các câu và sử dụng mô hình HMM để xác định sự \r\n\r\nphụ thuộc này. \r\n\r\nCác đặc trưng sử dụng: position, number of term, likelihood of sentence. \r\n\r\nMô hình HMM bao gồm 2s + 1 trạng thái, trong đó s là số trạng thái tóm tắt (câu \r\n\r\nthuộc tóm tắt) và s+1 là câu không thuộc tóm tắt. \r\n\r\nMô hình HMM xây dựng ma trận chuyển vị M, coi các đặc trưng là đa biến và tính \r\n\r\nxác suất của các câu qua từng trạng thái. \r\n\r\nSử dụng tập ngữ liệu của TREC và được đánh giá với 2 hệ thống khác là DimSum và \r\n\r\nQR, kết quả đều cho độ đo Precision cao hơn. \r\n\r\n2.2.1.6 Phương pháp Log-Linear \r\n\r\nOsborne (2002) đại diện cho mô hình này cũng coi các đặc trưng là không độc lập \r\n\r\nvới nhau và sử dụng mô hình Log-Linear khắc phục giả định này. \r\n\r\nCác đặc trưng sử dụng: word pair, sentence length, sentence position và discourse \r\n\r\nfeatures (nằm trong introduction, hay conclusion). \r\n\r\n2.2.1.7 Phương pháp mạng neural \r\n\r\nDUC 2002 đã đưa ra một baseline rất mạnh cho tóm tắt đơn văn bản bằng phương \r\n\r\npháp rút trích n câu đầu tiên của các báo tin tức và dường như kết thúc hướng nghiên \r\n\r\ncứu này. \r\n\r\nNhưng Svore (2007) đã đưa ra một hướng tiếp cận mới sử dụng mạng neural để huấn \r\n\r\nluyện, kết quả cho thấy đã vượt qua baseline của DUC 2002. \r\n\r\n\r\n\r\n \r\n12 \r\n\r\nCác đặc trưng sử dụng: position, n-grams frequency. Ngoài ra, còn sử dụng thêm nhật \r\n\r\nký truy vấn của bộ máy tìm kiếm Microsoft và WordNet. Tác giả cho rằng, những \r\n\r\ncâu có chứa từ khoá trong các các câu truy vấn thì sẽ có kết quả tốt hơn, và tìm từ \r\n\r\nkhoá đó trên WordNet. \r\n\r\nMô hình được huấn luyện từ các đặc trưng và các nhãn trong các bài báo. Sau đó \r\n\r\nđược xếp hạng bằng hệ thống RankNet. Ngữ liệu được lấy từ CNN.com và được đánh \r\n\r\ngiá bằng độ đo ROUGE-1 và ROUGE-2 (hai độ đo phổ biến hiện tại cho tóm tắt văn \r\n\r\nbản). \r\n\r\n2.2.1.8 Phương pháp phân tích ngôn ngữ tự nhiên \r\n\r\nPhương pháp tiếp theo sử dụng các kỹ thuật phân tích ngôn ngữ tự nhiên phức tạp. \r\n\r\nKhông phải tất cả các phương pháp phân tích ngôn ngữ tự nhiên đều sử dụng máy \r\n\r\nhọc, đôi khi phương pháp chỉ sử dụng một số các heuristic để tạo trích rút. \r\n\r\nHầu hết các phương pháp này đều dựa trên cấu trúc diễn ngôn (discourse tructure) \r\n\r\nhay cấu trúc diễn đạt (thể hiện) của văn bản, như: cấu trúc các section của văn bản, \r\n\r\nliên kết ngữ pháp (trùng lặp, tĩnh lược, liên hợp), liên kết từ vựng (đồng nghĩa, bao \r\n\r\nhàm, lặp lại), cấu trúc chính phụ. \r\n\r\nCác nghiên cứu đại điện cho phương pháp này: \r\n\r\n Ono (1994) xây dựng một thủ tục để rút trích các cấu trúc chính phụ (rhetorical \r\n\r\nstructure) từ các văn bản tiếng Nhật, và xây dựng một cây nhị phân để thể \r\n\r\nhiện. Các bước để trích rút cấu trúc: phân tích câu, trích rút một quan hệ chính \r\n\r\nphụ, phân đoạn, tạo ứng viên và đánh giá độ ưu tiên. Sau khi xây dựng cây sẽ \r\n\r\nthực hiện tỉa nhánh để giảm bớt câu và tạo tóm tắt. Kết quả đạt được 51% các \r\n\r\ncâu chính được xác định, và 74% các câu quan trọng nhất được xác định. \r\n\r\n Barzilay và Elhadad (1997): hai tác giả cũng đã sử dụng một lượng đáng kể \r\n\r\nnhững phân tích ngôn ngữ trong tóm tắt văn bản dựa trên chuỗi từ vựng \r\n\r\n(lexical chain). Chuỗi từ vựng là chuỗi các từ liên quan trong văn bản. Các \r\n\r\nbước thực hiện: phân đoạn văn bản, xác định các chuỗi từ vựng và sử dụng \r\n\r\n\r\n\r\n \r\n13 \r\n\r\ncác chuỗi từ vựng tốt nhất để xác định câu được chèn vào tóm tắt. Để tìm các \r\n\r\nchuỗi từ vựng, tác giả sử dụng WordNet. Các từ có liên quan với nhau sẽ được \r\n\r\nđưa vào chuỗi. Sự liên quan được tính bằng khoảng cách trong WordNet. \r\n\r\nChuỗi sẽ được tính điểm dựa vào chiều dài và sự đồng nhất của nó. Kết quả \r\n\r\nđạt được tốt hơn hệ thống tóm tắt của Microsoft. Với độ precious là 61 và độ \r\n\r\nrecall 67 (Microsoft là 33 và 27). Hạn chế: không thể kiểm được chiều dài và \r\n\r\nmức độ chi tiết của tóm tắt do số chuỗi còn ít. Tóm tắt thiếu sự kết dính và \r\n\r\nchưa chi tiết do chọn cả câu. \r\n\r\n Marcu (1998): sử dụng các heuristic dựa trên cấu trúc diễn đạt với các đặc \r\n\r\ntrưng truyền thống. Lý thuyết về cấu trúc diễn đạt được tác giả thể hiện thông \r\n\r\nqua lý thuyết cấu trúc chính phụ (Rhetorical Structure Theory). Lý thuyết cho \r\n\r\nrằng hai khoảng văn bản không trùng lặp có quan hệ trung tâm (nucleus) và \r\n\r\nvệ tinh (satellite). Trong đó trung tâm quan trọng hơn vệ tinh và độc lập hoàn \r\n\r\ntoàn trong cấu trúc chính phụ. Cấu trúc trọng tâm và vệ tinh được biểu diễn \r\n\r\nthành cây nhị phân. Để tính điểm cho các cấu trúc, tác giả sử dụng nhiều độ \r\n\r\nđo khác nhau như: clustering based metric, marker based metric, rhetorical \r\n\r\nclustering based technique, shape based metric, title based metric, position \r\n\r\nbased metric, connectedness based metric và sử dụng phương pháp kết hợp \r\n\r\ntuyến tính. Lấy ra n câu chứa cấu trúc có điểm cao nhất. Hệ thống đat được \r\n\r\nkết quả độ đo F 75.42% cao hơn 3.5% so với baseline bằng phương pháp lấy \r\n\r\nn câu đầu. Ngữ liệu được sử dụng là từ TREC. \r\n\r\n2.2.2 Hướng tiếp cận cho tóm tắt đa văn bản \r\n\r\nCác vấn đề phát sinh trong tóm tắt đa văn bản là tính trùng lặp và bổ sung thông tin \r\n\r\ntrong các nguồn văn bản. Do đó, nhiệm vụ trong tóm tắt đa văn bản không chỉ bao \r\n\r\ngồm việc sao chép dữ liệu từ những văn bản gốc sang bản tóm tắt mà còn đảm bảo \r\n\r\ntính mới, không dư thừa của thông tin, cũng như đảm bảo tóm tắt có tính kết dính và \r\n\r\nhoàn chỉnh. \r\n\r\n\r\n\r\n \r\n14 \r\n\r\n2.2.2.1 Phương pháp dùng template \r\n\r\nMcKeown và Radev (1995, 1998) đã xây dựng hệ thống SUMMONS dựa trên hướng \r\n\r\ntiếp cận dùng template cho tóm tắt đa văn bản. \r\n\r\nHệ thống đọc trong CSDL các tập mẫu được xây dựng sẵn bởi một hệ thống khác. \r\n\r\nTrước tiên, hệ thống sẽ điền vào các chỗ trống trong template các thông tin từ các \r\n\r\nvăn bản nguồn. Sau dó, hệ thống tổng hợp thành một bản tóm tắt và cho ra kết quả. \r\n\r\nHệ thống SUMMONS bao gồm 2 thành phần chính: content planner (lập nội dung) \r\n\r\nvà linguistic generator (tạo ngôn ngữ). Tuy nhiên, hệ thống chỉ có thể phục vụ cho \r\n\r\nmột miền dữ liệu nhỏ. \r\n\r\n2.2.2.2 Phương pháp gom cụm chủ đề và hợp nhất thông tin \r\n\r\nMcKeown (1999) đã cải tiến hệ thống SUMMONS cũng như Barzilay (1999) bằng \r\n\r\nmột hướng tiếp cận dựa trên gom cụm và hợp nhất thông tin. \r\n\r\nHướng tiếp cận mới bao gồm 2 giai đoạn: \r\n\r\n Gom cụm các đơn vị văn bản (clustering): các đơn vị văn bản được biểu diễn \r\n\r\nbằng vector với các đặc trưng như TF-IDF, noun-phrase, proper noun, synset \r\n\r\n(tập đồng nghĩa từ Wordnet). Từng cặp đơn vị văn bản sẽ được tính độ tương \r\n\r\nđồng với nhau để phân loại cho các các cụm theo từng chủ đề (themes). \r\n\r\n Hợp nhất thông tin: sau khi phân cụm, các cụm sẽ được so sánh với nhau bằng \r\n\r\nmột giải thuật để tìm sự trùng lặp thông tin. Sau cùng hệ thống trích rút câu \r\n\r\nnổi bật trong từng cụm để làm tóm tắt, nếu trùng lặp thì câu xuất hiện ở văn \r\n\r\nbản mới hơn sẽ được trích rút. Giải thuật để tìm sự trùng lặp là sử dụng bộ \r\n\r\nphân tích thống kê của Collin (1999) xây dựng cây phụ thuộc (dependency \r\n\r\ntree). \r\n\r\n\r\n\r\n \r\n15 \r\n\r\n2.2.2.3 Phương pháp gom cụm (cluster-based) với MMR \r\n\r\nCác văn bản thường được viết để giải quyết nhiều chủ đề khác nhau, mỗi chủ đề sẽ \r\n\r\nđược viết sau chủ đề khác theo một cách có tổ chức. Mỗi chủ đề cũng có thể được \r\n\r\nviết vào những phần riêng biệt hoặc không. Các chủ đề này cũng cần được viết vào \r\n\r\ntóm tắt theo thứ tự như trong văn bản. Vấn đề đặt ra là làm thế nào xác định được các \r\n\r\ncụm chủ đề của văn bản. \r\n\r\nPhương pháp gom cụm là nhằm phân loại các câu vào các cụm theo từng chủ đề mà \r\n\r\nchúng nói đến. Có nhiều phương pháp gom cụm khác nhau. Một trong số đó là \r\n\r\nphương pháp MMR (Maximal Marginal Relevance) của Carbonell và Jade Goldstein \r\n\r\n(1998). \r\n\r\nMô hình MMR đã được áp dụng cho Text Summarization bởi Ganapathiraju (2002). \r\n\r\nHệ thống tóm tắt với MMR bao gồm các chức năng (i) phân đoạn văn bản thành các \r\n\r\ncâu, (ii) phân cụm các câu, và (iii) tính điểm MMR cho các câu để chọn câu thích \r\n\r\nhợp được đưa vào tóm tắt. Tập dữ liệu huấn luyện được lấy từ DUC 2002. \r\n\r\n2.2.2.4 Phương pháp gom cụm với lý thuyết đồ thị \r\n\r\nVấn đề chủ yếu của tóm tắt đa văn bản là gom cụm các câu để tránh sự dư thừa trong \r\n\r\ntóm tắt. Một hướng tiếp cận mới là ứng dụng lý thuyết đồ thị. Sau khi đã tiền xử lý \r\n\r\nvăn bản như: loại bỏ stopword, xử lý dẫn suất (stemming), các câu được thể hiện \r\n\r\nthành các node trong một đồ thị vô hướng. Mỗi câu một node. Hai câu có những từ \r\n\r\nchung sẽ được nối một cạnh. Hoặc sử dụng độ đo cosin, tính độ tương đồng giữa 2 \r\n\r\ncâu, nếu lớn hơn một ngưỡng Q thì sẽ có một cạnh nối giữa 2 node. \r\n\r\nSau khi biểu diễn thành đồ thị, đồ thị sẽ được phân hoạch thành các đồ thị con dựa \r\n\r\nvào các cạnh nối. Nếu tóm tắt cần tạo là tóm tắt dựa vào truy vấn, thì đồ thị nào gần \r\n\r\nvới truy vấn nhất sẽ được dùng để tạo tóm tắt. Nếu tóm tắt là chung, thì tất cả các đồ \r\n\r\nthị con đều tham gia vào tóm tắt. \r\n\r\n\r\n\r\n \r\n16 \r\n\r\nĐể tạo tóm tắt, mỗi đồ thị con sẽ đưa ra các node (câu) ứng viên cao nhất (các node \r\n\r\ncó nhiều cạnh nối nhất) để include vào truy vấn. \r\n\r\n2.2.2.5 Phương pháp kích hoạt lan truyền trên đồ thị \r\n\r\nMani và Bloedorn (1997) đã đề xuất một framework cho tóm tắt văn bản dựa trên đồ \r\n\r\nthị để tìm sự tương đồng hoặc không tương đồng giữa các cặp văn bản. Phương pháp \r\n\r\nnày không tạo ra văn bản tóm tắt nhưng highlight thông tin trên văn bản gốc. \r\n\r\nVăn bản được thể hiện thành đồ thị như sau: mỗi node biểu diễn sự xuất hiện của một \r\n\r\ntừ đơn trong văn bản, mỗi node có nhiều loại liên kết với các node khác như: SAME, \r\n\r\nALPHA, PHRASE, NAME, COREF. \r\n\r\nSau khi tạo đồ thị, các node chủ đề sẽ được xác định bằng phương pháp phân tích dẫn \r\n\r\nxuất (stemming) và trở thành entry node. Các node sẽ được đánh trọng số bằng \r\n\r\nphương pháp TF*IDF.  Một sự tìm kiếm văn bản liên quan ngữ nghĩa giữa các node \r\n\r\nsẽ được lan truyền. Trọng số của các node sẽ được thay đổi trong quá trình lan truyền. \r\n\r\nCác cặp đồ thị (các văn bản) sẽ được so sánh với nhau để tìm những node chung dựa \r\n\r\nvào dẫn xuất cũng như đồng ngữ nghĩa. Điểm của các node chung cũng sẽ được tính \r\n\r\nlại. Quá trình lan truyền lại tiếp tục cho đến khi không còn cập nhật trọng số điểm \r\n\r\ncho các node. \r\n\r\nSau cùng những câu chứa các node có điểm chung và riêng cao sẽ được đánh dấu. \r\n\r\n2.2.2.6 Phương pháp dựa trên trọng tâm \r\n\r\nRadev (2004) đã đề xuất phương pháp sử dụng các trọng tâm của cụm đề làm trung \r\n\r\ntâm cho tóm tắt. Hướng tiếp cận này đã được phát triển trong hệ thống MEAD. \r\n\r\nCác văn bản trong hướng tiếp cận này sử dụng mô hình túi từ. Bao gồm 2 giai đoạn: \r\n\r\n Giai đoạn xác định chủ đề: Các văn bản được biểu diễn dưới vector và một \r\n\r\nthuật toán gom cụm tích tụ (an agglomerative clustering) được sử dụng để thực \r\n\r\n\r\n\r\n \r\n17 \r\n\r\nhiện nhiệm vụ này. Văn bản liên quan nhất với trọng tâm cluster sẽ được thêm \r\n\r\nvào, và cluster sẽ được tính lại trọng tâm. \r\n\r\n Giai đoạn chọn câu: Trong mỗi cluster, chọn các câu là trung tâm của chủ đề \r\n\r\ntrong cụm. Hai độ đo tương tự MMR là cluster-based relative utility (CBRU) \r\n\r\nand cross-sentence informational subsumption (CSIS) được sử dụng để độ liên \r\n\r\nquan của câu với chủ đề của cụm và độ dư thừa giữa các câu. Tuy nhiên, hai \r\n\r\nđộ đo này không phụ thuộc truy vấn như MMR. Để tính độ tương đồng, mỗi \r\n\r\ncâu được biểu diễn bởi các đặc trưng: centroid value, positional value, first-\r\n\r\nsentence overlap. \r\n\r\n2.3 Phân tích yêu cầu phần mềm \r\n\r\n2.3.1 Biểu đồ use case tổng quan \r\n\r\n \r\n\r\n\r\n \r\n\r\n\r\n\r\n \r\n18 \r\n\r\nPhần mềm có một tác nhân chính là Người dùng, người có thể tương tác với phần \r\n\r\nmềm. Ban đầu, người dùng có thể chọn toàn bộ văn bản xuất hiện trên màn hình hoặc \r\n\r\nchỉ chọn một phần văn bản mà mình muốn. Phần văn bản đã chọn sẽ được đọc bằng \r\n\r\ntext-to-speech. \r\n\r\nTrong trường hợp chọn một phần văn bản, người dùng có thể tuỳ chọn tóm tắt phần \r\n\r\nvăn bản mà mình đã chọn. Kết quả tóm tắt sẽ được xử lý trên server và hiển thị trên \r\n\r\nmàn hình. \r\n\r\n2.3.2 Đặc tả chức năng \r\n\r\n2.3.2.1 Đặc tả use case TTS toàn bộ văn bản \r\n\r\n\r\nMã use case UC001 Tên use case TTS toàn bộ văn bản \r\n\r\nTác nhân Người dùng \r\n\r\nTiền điều kiện Người dùng đã mở giao diện tương tác  \r\n\r\nLuồng sự kiện \r\n\r\nchính (Thành \r\n\r\ncông) \r\n\r\nSTT Tác nhân Hành động \r\n\r\n1 Người dùng Chọn chức năng TTS toàn bộ văn bản \r\n\r\n2 Hệ thống Lấy dữ liệu toàn bộ văn bản đang hiển thị \r\n\r\ntrên màn hình, thực hiện TTS \r\n\r\n \r\n\r\nLuồng sự kiện \r\n\r\nthay thế \r\n\r\nSTT Tác nhân Hành động \r\n\r\n2a Hệ thống Hệ thống thông báo không có văn bản \r\n\r\n \r\n\r\nHậu điều kiện Không \r\n\r\n\r\n\r\n \r\n19 \r\n\r\n \r\n\r\n2.3.2.2 Đặc tả use case TTS văn bản được chọn \r\n\r\n\r\nMã use case UC002 Tên use case TTS văn bản được chọn \r\n\r\nTác nhân Người dùng \r\n\r\nTiền điều kiện Người dùng đã mở giao diện tương tác  \r\n\r\nLuồng sự kiện \r\n\r\nchính (Thành \r\n\r\ncông) \r\n\r\nSTT Tác nhân Hành động \r\n\r\n1 Người dùng Chọn chức năng TTS văn bản được chọn \r\n\r\n2 Người dùng Vẽ trên màn hình để chọn văn bản \r\n\r\n3 Hệ thống Lấy dữ liệu văn bản trong vùng được chọn \r\n\r\ntrên màn hình, thực hiện TTS \r\n\r\n \r\n\r\nLuồng sự kiện \r\n\r\nthay thế \r\n\r\nSTT Tác nhân Hành động \r\n\r\n3a Hệ thống Hệ thống thông báo không có văn bản nào \r\n\r\nđược chọn \r\n\r\n \r\n\r\nHậu điều kiện Không \r\n\r\n \r\n\r\n\r\n\r\n \r\n20 \r\n\r\n2.3.2.3 Đặc tả use case Tóm tắt văn bản \r\n\r\n\r\nMã use case UC003 Tên use case Tóm tắt văn bản \r\n\r\nTác nhân Người dùng \r\n\r\nTiền điều kiện Người dùng đã chọn một vùng văn bản \r\n\r\nLuồng sự kiện \r\n\r\nchính (Thành \r\n\r\ncông) \r\n\r\nSTT Tác nhân Hành động \r\n\r\n1 Người dùng Chọn chức năng Tóm tắt văn bản \r\n\r\n2 Hệ thống Thực hiện tóm tắt văn bản và trả về kết quả \r\n\r\nhiển thị trên màn hình \r\n\r\n3 Người dùng Xác nhận kết quả trả về \r\n\r\n \r\n\r\nLuồng sự kiện \r\n\r\nthay thế \r\n\r\nSTT Tác nhân Hành động \r\n\r\n2a Hệ thống Hệ thống thông báo không có văn bản được \r\n\r\nchọn \r\n\r\n2b Hệ thống Hệ thống thông báo không có kết nối \r\n\r\nInternet \r\n\r\n \r\n\r\nHậu điều kiện Không \r\n\r\n \r\n\r\n\r\n\r\n \r\n21 \r\n\r\n\r\nSTT Trường \r\n\r\ndữ liệu \r\n\r\nMô tả Bắt buộc Điều kiện \r\n\r\nhợp lệ \r\n\r\nVí dụ \r\n\r\n1 Văn bản Nội dung văn bản cần \r\n\r\ntóm tắt \r\n\r\nCó Dạng text Hello \r\n\r\nWorld \r\n\r\n \r\n\r\n\r\nSTT Trường \r\n\r\ndữ liệu \r\n\r\nMô tả Bắt buộc Điều kiện \r\n\r\nhợp lệ \r\n\r\nVí dụ \r\n\r\n1 Văn bản Nội dung văn bản đã \r\n\r\nđược tóm tắt \r\n\r\nCó Dạng text Hello \r\n\r\nWorld \r\n\r\n \r\n\r\n2.3.3 Yêu cầu phi chức năng \r\n\r\nVề hiệu năng, hệ thống phải đảm bảo hoạt động liên tục 24/24, giúp người dùng có \r\n\r\nthể tương tác bất cứ lúc nào. Hệ thống cũng phải đảm bảo tính dễ dùng, giúp người \r\n\r\ndùng nhận biết được hệ thống đã lấy được dữ liệu hay chưa, thao tác thành công hay \r\n\r\nkhông. \r\n\r\n \r\n\r\n \r\n\r\nNhư vậy, Chương 2 cho chúng ta cái nhìn tổng quan về các phương pháp tóm tắt văn \r\n\r\nbản cũng như ưu, nhược điểm của chúng. Có thể nhận thấy rằng, tóm tắt văn bản \r\n\r\nbằng Deep Learning đang là phương pháp tiên tiến nhất hiện nay. Để tìm hiểu về \r\n\r\n\r\n\r\n \r\n22 \r\n\r\nphương pháp này, Chương 3 sẽ trình bày về các lý thuyết nền tảng mà chúng ta cần \r\n\r\nnắm rõ. \r\n\r\nNgoài ra, chúng ta cũng đã làm rõ những yêu cầu tổng quan cũng như đặc tả các use \r\n\r\ncase của phần mềm. Đây là tiền đề để sinh viên xây dựng ứng dụng di động Android. \r\n\r\n\r\n\r\n \r\n23 \r\n\r\nTrải qua nhiều tiến bộ của khoa học máy tính, Deep Learning đang nổi lên như là một \r\n\r\ncông nghệ tiên tiến giúp con người giải quyết nhiều bài toán phức tạp với độ chính \r\n\r\nxác cao. Theo như những gì đã trình bày ở Chương 2, Deep Learning cũng đã được \r\n\r\nứng dụng trong bài toán tóm tắt văn bản và đạt được những kết quả khả quan. Chương \r\n\r\nnày sẽ đi sâu vào trình bày các khái niệm liên quan đến công nghệ tóm tắt văn bản \r\n\r\nbằng Deep Learning. \r\n\r\n3.1 Công nghệ Deep Learning \r\n\r\n3.1.1 Machine Learning \r\n\r\n \r\n\r\n\r\nChương 3 Cơ sở lý thuyết  \r\n\r\n\r\n\r\n \r\n24 \r\n\r\nNhững năm gần đây, AI - Artificial Intelligence (Trí Tuệ Nhân Tạo), và cụ thể hơn \r\n\r\nlà Machine Learning (Học Máy) nổi lên như một bằng chứng của cuộc cách mạng \r\n\r\ncông nghiệp lần thứ tư. Trí Tuệ Nhân Tạo đang len lỏi vào mọi lĩnh vực trong đời \r\n\r\nsống mà có thể chúng ta không nhận ra. Xe tự hành của Google và Tesla, hệ thống tự \r\n\r\ntag khuôn mặt trong ảnh của Facebook, trợ lý ảo Siri của Apple, hệ thống gợi ý sản \r\n\r\nphẩm của Amazon, hệ thống gợi ý phim của Netflix, máy chơi cờ vây AlphaGo của \r\n\r\nGoogle DeepMind. chỉ là một vài trong vô vàn những ứng dụng của AI/Machine \r\n\r\nLearning. \r\n\r\nMachine Learning là một tập con của AI. Nói đơn giản, Machine Learning là một \r\n\r\nlĩnh vực nhỏ của Khoa Học Máy Tính, nó có khả năng tự học hỏi dựa trên dữ liệu \r\n\r\nđưa vào mà không cần phải được lập trình cụ thể. \r\n\r\nNhững năm gần đây, khi mà khả năng tính toán của các máy tính được nâng lên một \r\n\r\ntầm cao mới và lượng dữ liệu khổng lồ được thu thập bởi các hãng công nghệ lớn, \r\n\r\nMachine Learning đã tiến thêm một bước dài và một lĩnh vực mới được ra đời gọi là \r\n\r\nDeep Learning. Deep Learning đã giúp máy tính thực thi những việc tưởng chừng \r\n\r\nnhư không thể vào 10 năm trước: phân loại cả ngàn vật thể khác nhau trong các bức \r\n\r\nảnh, tự tạo chú thích cho ảnh, bắt chước giọng nói và chữ viết của con người, giao \r\n\r\ntiếp với con người, hay thậm chí cả sáng tác văn hay âm nhạc. \r\n\r\nNgược dòng lịch sử, Machine Learning đã xuất hiện từ rất lâu trước khi mạng Internet \r\n\r\nra đời. Một trong những thuật toán Machine Learning đầu tiên là thuật toán \r\n\r\nPerceptron được phát minh ra bởi Frank Rosenblatt vào năm 1957. Đây là một thuật \r\n\r\ntoán kinh điển dùng để phân loại hai khái niệm. Một ví dụ đơn giản là phân loại thư \r\n\r\nrác và thư bình thường. Perceptron là một thuật toán supervised learning: ta đưa cho \r\n\r\nmáy tính hàng loạt các ví dụ cùng câu trả lời mẫu với hy vọng máy tính sẽ tìm được \r\n\r\nnhững đặc điểm cần thiết để đưa ra dự đoán cho những ví dụ khác chưa có câu trả lời \r\n\r\ntrong tương lai. Ngoài ra, cũng có những thuật toán Machine Learning không cần câu \r\n\r\ntrả lời mẫu, được gọi là unsupervised learning. Trong trường hợp này, máy tính cố \r\n\r\ngắng khai thác ra cấu trúc ẩn của một tập dữ liệu mà không cần câu trả lời mẫu. Một \r\n\r\nloại Machine Learning khác được gọi là reinforcement learning. Trong dạng này, \r\n\r\n\r\n\r\n \r\n25 \r\n\r\ncũng không hề có câu trả lời mẫu, nhưng thay vì đó máy tính nhận được phản hồi cho \r\n\r\nmỗi hành động. Dựa vào phản hồi tích cực hay tiêu cực mà máy tính sẽ điều chỉnh \r\n\r\nhoạt động cho phù hợp. \r\n\r\n3.1.2 Deep Learning \r\n\r\nNếu coi ta Machine Learning là công nghệ tiên tiến nhất, thì Deep Learning là \"tiên \r\n\r\ntiến của tiên tiến\". Machine Learning lấy một vài ý tưởng cốt lõi của trí tuệ nhân tạo \r\n\r\nvà tập trung vào việc giải quyết các vấn đề thế giới thực với các mạng thần kinh được \r\n\r\nthiết kế để bắt chước khả năng đưa ra quyết định của chúng ta. Deep Learning, đúng \r\n\r\nnhư tên gọi của nó, đi sâu hơn nữa vào một tập hợp các công cụ và kỹ thuật học máy, \r\n\r\ntừ đó áp dụng chúng để giải quyết bất kỳ vấn đề nào đòi hỏi \"khả năng tư duy\"  con \r\n\r\nngười hay nhân tạo. \r\n\r\nVề cơ bản, Deep Learning là cho một hệ thống máy tính \"ăn\" rất nhiều dữ liệu, để \r\n\r\nchúng có thể sử dụng và đưa ra các quyết định về những dữ liệu khác. Dữ liệu này \r\n\r\nđược nạp thông qua các mạng thần kinh, tương tự như học máy. Những mạng lưới \r\n\r\nnày  các cấu trúc logic yêu cầu một loạt các câu hỏi đúng/sai, hoặc trích xuất một \r\n\r\ngiá trị số, của mỗi bit dữ liệu đi qua chúng và phân loại theo các câu trả lời nhận được. \r\n\r\nVì công việc của Deep Learning là tập trung phát triển những mạng lưới này, chúng \r\n\r\nđã trở thành \"mạng thần kinh sâu\" (Deep Neural Network)  những mạng logic phức \r\n\r\ntạp cần thiết để xử lý các bộ dữ liệu lớn, như thư viện hình ảnh của Google hay \r\n\r\nInstagram. \r\n\r\nVới các bộ dữ liệu toàn diện như vậy, và các mạng logic phức tạp để xử lý phân loại \r\n\r\nchúng, việc một chiếc máy tính lấy một hình ảnh và nhận dạng với độ chính xác cao \r\n\r\ntrở nên \"quá đỗi bình thường\". \r\n\r\nCác hình ảnh là ví dụ tuyệt vời nhất về cách thức hoạt động của Deep Learning, vì \r\n\r\nchúng có chứa nhiều yếu tố khác nhau và để hiểu rõ được làm thế nào để máy tính, \r\n\r\nvới não bộ một chiều chủ yếu dựa trên sự tính toán, có thể học cách giải thích chúng \r\n\r\ngiống như con người. Tuy vậy, Deep Learning có thể được áp dụng cho bất kỳ hình \r\n\r\n\r\n\r\n \r\n26 \r\n\r\nthức dữ liệu nào  âm thanh, video, lời nói, chữ viết...  để đưa ra những kết luận như \r\n\r\nthể do con người thực hiện với tốc độ rất nhanh. Chúng ta hãy thử xem xét một số ví \r\n\r\ndụ thực tiễn. \r\n\r\nGiả sử một hệ thống được thiết kế để tự động ghi nhận và báo cáo có bao nhiêu chiếc \r\n\r\nxe của một mẫu xe nhất định đã đi ngang qua một con đường. Trước tiên, nó sẽ được \r\n\r\nquyền truy cập vào một cơ sở dữ liệu khổng lồ về các loại xe, bao gồm hình dáng, \r\n\r\nkích thước và thậm chí là tiếng của động cơ. Điều này có thể được biên soạn theo \r\n\r\ncách thủ công hoặc, trong các điều kiện tiên tiến hơn, được thu thập tự động bởi hệ \r\n\r\nthống nếu như nó được lập trình để tìm kiếm trên internet và lấy dữ liệu mà nó tìm \r\n\r\nthấy ở đó. Tiếp theo, nó sẽ lấy dữ liệu cần được xử lý  dữ liệu trong thế giới thực có \r\n\r\nchứa thông tin chi tiết cần nắm bắt, trong trường hợp này là bởi các camera và \r\n\r\nmicrophone bên đường. Bằng cách so sánh dữ liệu từ cảm biến với những dữ liệu mà \r\n\r\nnó đã \"học được\", nó có thể phân loại, với một độ chính xác nhất định, từng loại xe \r\n\r\nđã đi qua con đường đó. \r\n\r\nTrên đây là một ví dụ cụ thể, ngoài ra Deep Learning còn có thể ứng dụng ở trong rất \r\n\r\nnhiều các lĩnh vực khác như:  \r\n\r\n Cung cấp khả năng điều hướng cho xe tự lái: Với hệ thống cảm biến và phần \r\n\r\nmềm phân tích trên buồng lái, các xe tự lái có thể học cách nhận dạng những \r\n\r\nchướng ngại vật có trên đường và có giải pháp xử lý thích hợp bằng cách sử \r\n\r\ndụng Deep Learning. \r\n\r\n Phục chế màu cho ảnh đen trắng: thông qua việc dạy cho máy tính cách nhận \r\n\r\nbiết các vật thể và cách mà mắt người nhìn chúng, các hình ảnh và video đen \r\n\r\ntrắng sẽ có thể được tái hiện lại với đầy đủ các màu sắc phù hợp. \r\n\r\n Dự đoán kết quả của các thủ tục pháp lý: Một nhóm các nhà nghiên cứu người \r\n\r\nAnh và Mỹ đã có thể dự đoán chính xác kết quả của một phiên tòa, sau khi hệ \r\n\r\nthống máy tính của họ được nạp sẵn những thông tin cơ bản của vụ án. \r\n\r\n Thuốc đặc trị: Các kỹ thuật Deep Learning hiện đang được dùng để phát triển \r\n\r\ncác loại thuốc đã được chỉnh sửa sao cho phù hợp với bộ gen của bệnh nhân. \r\n\r\n\r\n\r\n \r\n27 \r\n\r\n Phân tích và báo cáo tự động: Các hệ thống có thể phân tích dữ liệu và báo \r\n\r\ncáo những thông tin chi tiết của chúng dưới dạng âm thanh tự nhiên hoặc ngôn \r\n\r\nngữ của con người. \r\n\r\n Chơi trò chơi: Các hệ thống Deep Learning đã và đang được dạy cách chơi (và \r\n\r\ngiành chiến thắng) các trò chơi như cờ vây, Breakout của Atari hay Starcraft. \r\n\r\n3.2 Neural Network \r\n\r\n3.2.1 Mạng neural nhân tạo \r\n\r\nMạng neural nhân tạo (Artificial Neurol Network - ANN) là mạng các neural kết nối \r\n\r\nvới nhau. Mỗi neural là một mô hình tính toán và NN là một hệ thống tính toán. Đầu \r\n\r\nra của mỗi neural lại là đầu vào của một neural khác. Kiến trúc của mạng được quyết \r\n\r\nđịnh bởi sự kết nối của các neural trong mạng.  \r\n\r\nMột trong những yếu tố chính của mạng neural là khả năng học hỏi. Mạng neural \r\n\r\nkhông chỉ là một hệ thống phức tạp, mà còn là một hệ thống thích nghi phức tạp, có \r\n\r\nnghĩa là nó có thể thay đổi cấu trúc nội bộ của nó trong quá trình huấn luyện. Thông \r\n\r\nthường, việc huấn luyện là việc thay đổi các trọng số. \r\n\r\nHai kiến trúc mạng phổ biến: \r\n\r\n Mạng truyền thẳng (feed-forward network) \r\n\r\n \r\n\r\n\r\n\r\n\r\n \r\n28 \r\n\r\n Mạng phản hồi (feed-back network hay recurrent neural network) \r\n\r\n \r\n\r\n\r\nThuật toán được sử dụng phổ biến để huấn luyện mạng neural là thuật toán lan truyền \r\n\r\nngược (backpropagation algorithm). Thuật toán này sẽ sử dụng tập giá trị đầu ra và \r\n\r\ntập giá trị mong muốn để tìm ra các trọng số của mạng làm cực tiểu hàm lỗi. Sai số \r\n\r\ncủa mạng trên một bộ dữ liệu huấn luyện được tính tổng bình phương của độ sai lệch \r\n\r\ngiữa các đầu ra của mạng và các giá trị mong muốn. Hàm lỗi tổng bình phương trên \r\n\r\ntoàn tập dữ liệu sẽ được tính bằng tổng hàm lỗi trên mỗi bộ dữ liệu của tập dữ liệu. \r\n\r\nTa cần tìm trọng số của mạng sao cho hàm tổng bình phương lỗi đạt giá trị nhỏ nhất. \r\n\r\nBackpropagation được xây dựng dựa trên thuật toán lặp là kĩ thuật gradient descent. \r\n\r\nTheo kĩ thuật này, vector trọng số của lần lặp này sẽ được điều chỉnh dựa vào vector \r\n\r\ntrọng số ở lần lặp trước, tỷ lệ học (learning rate) và vector gradient (vector các đạo \r\n\r\nhàm riêng) của hàm lỗi tại đó. Theo đó, đạo hàm riêng của một tầng được tính dựa \r\n\r\nvào tầng trước đó theo hướng đầu ra ngược về đầu vào. Đạo hàm riêng của hàm lỗi \r\n\r\ntrên toàn tập dữ liệu bằng tổng đạo hàm riêng của hàm lỗi trên từng bộ dữ liệu của \r\n\r\ntoàn tập dữ liệu. Đạo hàm riêng của hàm lỗi theo trọng số của đường truyền từ neural \r\n\r\ni tới neural j bằng tích của của sai số tại neural j với đầu ra tại i, trong đó sai số ở \r\n\r\nneural j là đạo hàm riêng của của hàm lỗi theo tổng trọng số của neural j. Sai số ở \r\n\r\nneural j lại được tính dựa trên sự sai khác của đầu ra tại neural này và giá trị đầu ra \r\n\r\nmong muốn. Tóm lại, thuật toán lan truyền ngược gồm giai đoạn: giai đoạn đầu các \r\n\r\nthông tin được truyền theo thẳng qua mạng để tìm tổng trọng số đầu vào và đầu ra, \r\n\r\ngiai đoạn tiếp theo các sai sẽ được tính và truyền ngược lại. \r\n\r\n\r\n\r\n \r\n29 \r\n\r\n3.2.2 Mạng RNN \r\n\r\nMô hình mạng neural hồi quy (Recurrent Neural Networks) được sử dụng phổ biến \r\n\r\ntrong các bài toán xử lí ngôn ngữ tự nhiên, mô hình hóa được bản chất của của ngôn \r\n\r\nngữ tự nhiên. Dữ liệu trong NLP có sự phụ thuộc lẫn nhau giữa các thành phần trong \r\n\r\ndữ liệu và chúng thường ở dạng chuỗi.  RNN thường được sử dụng cho các bài toán \r\n\r\nNLP vì chúng là mô hình mạng sử dụng đầu vào là thông tin dạng chuỗi.   \r\n\r\nMột số mạng neural truyền thống được giả định rằng các đầu vào độc lập với nhau, \r\n\r\ncác mô hình không phù hợp với nhiều bài toán. Ví dụ với bào toán dự đoán từ, ta phải \r\n\r\nbiết được các từ trước đó thì mới có thể dự đoán được từ tiếp theo. Mạng RNN có \r\n\r\nkhả năng nhớ các thông tin trước đó dựa vào việc thực hiện cùng một tác vụ tính toán \r\n\r\ncho mỗi phần tử của chuỗi đầu vào. Trên lí thuyết, RNN có thể nhớ tất cả các thông \r\n\r\ntin trước đó, có khả năng sử dụng một đoạn văn bản rất dài. Tuy nhiên, mạng chỉ có \r\n\r\nthể nhớ được trong vài bước tính toán ban đầu, thông tin được tính toán trước đó dần \r\n\r\nmất trong quá trình truyền. Một mạng neural được duỗi ra giống như một chuỗi tuần \r\n\r\ntự. Ví dụ đầu vào là một chuỗi gồm năm từ, mạng sẽ duỗi ra với năm tầng mạng, mỗi \r\n\r\ntầng cho một từ. Mỗi tầng thể hiện mạng tại một thời điểm gọi là bước thời gian \r\n\r\n(time-step).  Mạng RNN khi được duỗi ra thường có mô hình dạng sau: \r\n\r\n \r\n\r\n\r\n \r\n\r\n\r\n\r\n \r\n30 \r\n\r\nViệc tính toán bên trong RNN sẽ được thực hiện như sau:  \r\n\r\n t là đầu vào tại bước thời gian thứ t. Ví dụ 1 là one-hot vector biểu diễn từ \r\n\r\nthứ hai trong câu. \r\n\r\n t là trạng thái ẩn tại bước thời gian thứ t. Nó được coi là bộ nhớ của mạng. t \r\n\r\nđược tính dựa trên các trạng thái ẩn trước đó và đầu vào hiện tại theo công \r\n\r\nthức:  = ( + 1). Hàm f thường là hàm sigmoid hoặc ReLU. Để tính \r\n\r\ntrạng thái ẩn cho mạng ở phần tử đầu tiên, ta cần khởi tạo một giá trị -1. -1 \r\n\r\nthường được khởi tạo là -1. \r\n\r\n t là đầu ra tại bước thời gian thứ t. Thông thường được tính theo hàm softmax. \r\n\r\nVí dụ, ta muốn dự đoán một từ có xuất hiện không thì t là vector xác suất \r\n\r\ntrong tập từ điển của ta:  = (  ). \r\n\r\nTrạng thái ẩn như là bộ nhớ của mạng. Thu thập thông tin về những gì đã xảy ra trong \r\n\r\ntất cả các bước thời gian trước đó. Đầu ra ở bước được tính toán chỉ dựa trên bộ nhớ \r\n\r\nvào thời gian. Tuy nhiên, mạng không thể nhớ được nhiều thông tin. Thông tin đồng \r\n\r\nthời bị mất dần qua các bước thời gian.  \r\n\r\nKhông giống như mạng thần kinh sâu truyền thống, sử dụng các tham số khác nhau \r\n\r\nở mỗi lớp, một RNN chia sẻ các tham số giống nhau qua tất cả các bước. Tức là, ta \r\n\r\nđang thực hiện cùng một công việc ở từng bước, chỉ với các đầu vào khác nhau. Điều \r\n\r\nnày làm giảm tổng số các tham số chúng ta cần phải học.  \r\n\r\nSơ đồ trên có đầu ra ở mỗi bước thời gian, nhưng tùy thuộc vào các bài toán khác \r\n\r\nnhau mà đầu ra này có thể không cần thiết. Ví dụ, khi dự đoán tình cảm của một câu \r\n\r\nchúng ta chỉ có thể quan tâm đến kết quả cuối cùng chứ không phải tình cảm sau mỗi \r\n\r\ntừ. Tương tự như vậy, chúng ta có thể không cần đầu vào ở từng thời điểm. Các tính \r\n\r\nnăng chính của một RNN là trạng thái ẩn của nó, trong đó nắm bắt một số thông tin \r\n\r\nvề một chuỗi.  \r\n\r\nHuấn luyện mạng RNN tương tự như mạng neural thông thường. Mạng vẫn sử dụng \r\n\r\nthuật toán lan truyền ngược nhưng có chút thay đổi. Đạo hàm tại mỗi đầu ra sẽ được \r\n\r\n\r\n\r\n \r\n31 \r\n\r\ntính dựa trên tất cả cả bước thời gian vì tham số được sử dụng chung cho toàn mạng. \r\n\r\nĐạo hàm tại đầu ra được tính bằng tổng của các bước trước đó. Giải thuật này còn \r\n\r\nđược gọi là lan truyền ngược liên hồi (Backpropagation Through Time BPTT).  \r\n\r\nQua nhiều năm nghiên cứu và phát triển, một số loại mạng RNN được sinh ra để khác \r\n\r\nphục các nhược điểm của RNN truyền thống. Một số mô hình tiêu biểu:  \r\n\r\n RNN hai chiều (Bidirectional RNNs) dựa trên ý tưởng rằng tại mỗi bước thời \r\n\r\ngian, trạng thái ẩn không chỉ phụ thuộc vào các yếu tố trước đó trong chuỗi, \r\n\r\nmà còn các yếu tố trong tương lai. Ví dụ: để dự đoán một từ bị thiếu trong một \r\n\r\nchuỗi ta phải biết cả ngữ cảnh trái và phải. RNN hai chiều khá đơn giản. Họ \r\n\r\nchỉ là hai RNN xếp chồng lên nhau. Đầu ra sau đó được tính dựa trên trạng \r\n\r\nthái ẩn của cả hai RNN. Đầu vào của của mạng tại timestep thứ i bao gồm cả \r\n\r\ntrạng thái ẩn tại bước thời gian thứ i  1 cùng RNN và trạng thái ẩn của bước \r\n\r\nthời gian thứ i + 1 của RNN chồng lên nó. Nhờ đó, tại mỗi bước thời gian sẽ \r\n\r\nnhớ được thông tin toàn mạng. \r\n\r\n \r\n\r\n\r\n RNN sâu (Deep (Bidirectional) RNN) tương tự như mạng RNN hai chiều, \r\n\r\nnhưng tại mỗi bước thời gian thay vì có một trạng thái ẩn thì mạng lại có nhiều \r\n\r\ntrạng thái ẩn. Nhờ có nhiều trạng thái ẩn mà khả năng học của mạng cũng cao \r\n\r\nhơn. \r\n\r\n\r\n\r\n \r\n32 \r\n\r\n \r\n\r\n\r\n LSTM (Long short term memory networks) có kiến trúc giống với RNN thông \r\n\r\nthường. Nhưng chúng sử dụng nhiều hàm tính toán khác ở trạng thái ẩn. Điểm \r\n\r\nnổi bật của mạng là nó khắc phục được các vấn đề phụ thuộc xa (long-term \r\n\r\ndependency problem) của RNN. \r\n\r\n3.2.3 Mạng LSTM \r\n\r\nMạng bộ nhớ dài-ngắn (Long Short Term Memory networks), thường được gọi là \r\n\r\nLSTM - là một dạng đặc biệt của RNN, nó có khả năng học được các phụ thuộc xa. \r\n\r\nLSTM được giới thiệu bởi Hochreiter & Schmidhuber (1997), và sau đó đã được cải \r\n\r\ntiến và phổ biến bởi rất nhiều người trong ngành. Chúng hoạt động cực kì hiệu quả \r\n\r\ntrên nhiều bài toán khác nhau nên dần đã trở nên phổ biến như hiện nay. \r\n\r\nLSTM được thiết kế để tránh được vấn đề phụ thuộc xa (long-term dependency). Việc \r\n\r\nnhớ thông tin trong suốt thời gian dài là đặc tính mặc định của chúng, chứ ta không \r\n\r\ncần phải huấn luyện nó để có thể nhớ được. Tức là ngay nội tại của nó đã có thể ghi \r\n\r\nnhớ được mà không cần bất kì can thiệp nào. \r\n\r\n\r\n\r\n \r\n33 \r\n\r\nMọi mạng hồi quy đều có dạng là một chuỗi các mô-đun lặp đi lặp lại của mạng \r\n\r\nneural. Với mạng RNN chuẩn, các mô-dun này có cấu trúc rất đơn giản, thường là \r\n\r\nmột tầng tanh. \r\n\r\n \r\n\r\n\r\nLSTM cũng có kiến trúc dạng chuỗi như vậy, nhưng các mô-đun trong nó có cấu trúc \r\n\r\nkhác với mạng RNN chuẩn. Thay vì chỉ có một tầng mạng neural, chúng có tới 4 tầng \r\n\r\ntương tác với nhau một cách rất đặc biệt. \r\n\r\n \r\n\r\n\r\nỞ sơ đồ trên, mỗi một đường mang một véc-tơ từ đầu ra của một nút tới đầu vào của \r\n\r\nmột nút khác. Các hình trong màu hồng biểu diễn các phép toán như phép cộng véc-\r\n\r\ntơ chẳng hạn, còn các ô màu vàng được sử dụng để học trong các từng mạng neural. \r\n\r\nCác đường hợp nhau kí hiệu việc kết hợp, còn các đường rẽ nhánh ám chỉ nội dung \r\n\r\ncủa nó được sao chép và chuyển tới các nơi khác nhau. \r\n\r\n\r\n\r\n \r\n34 \r\n\r\n3.3 Mô hình tóm tắt văn bản \r\n\r\n3.3.1 Mô hình Sequence to Sequence \r\n\r\nMô hình sequence to sequence hay encoder-decoder (seq2seq) là mô hình sinh ra để \r\n\r\ngiải quyết các bài toán sinh chuỗi đầu ra từ câu đầu vào cho trước. Mô hình seq2seq \r\n\r\ngồm một bộ mã hóa (encoder) và một bộ giải mã (decoder). Mô hình mã hóa một dãy \r\n\r\ncó độ dài biến đổi thành một biểu diễn vector chiều dài cố định và để giải mã một sự \r\n\r\nbiểu diễn cố định trở lại thành một dãy có độ dài biến đổi. Từ góc độ xác suất, mô \r\n\r\nhình mới này là một phương pháp tổng quát để tìm hiểu sự phân bố có điều kiện đối \r\n\r\nvới một dãy có độ dài thay đổi theo một dãy có độ dài thay đổi khác.   \r\n\r\nBộ mã hóa là một RNN đọc mỗi từ của một chuỗi đầu vào x tuần tự. Khi nó đọc từng \r\n\r\ntừ, trạng thái ẩn của RNN thay đổi. Sau khi đọc kết thúc chuỗi (được đánh dấu bởi \r\n\r\nmột ký hiệu cuối của chuỗi), trạng thái ẩn của một RNN là một vector cố định c được \r\n\r\ntổng hợp từ chuỗi đầu vào. C được dùng như ngữ cảnh cho bộ gải mã. Nhờ có vector \r\n\r\nngữ cảnh bộ giải mã có thể xác định đầu ra chính xác hơn. \r\n\r\nVí dụ với một mô hình dự đoán từ, khi gặp từ hạ ta sẽ không thể biết đó là từ chỉ \r\n\r\nmùa trong năm hay là động từ mang nghĩa hạ xuống, nhưng nếu có một ngữ cảnh cụ \r\n\r\nthể thì bộ giải mã của ta có thể xác định được từ đó có nghĩa là gì. Bộ giải mã của mô \r\n\r\nhình được đề xuất là một RNN khác được huấn luyện để tạo chuỗi đầu ra bằng cách \r\n\r\ndự đoán từ  tiếp theo với trạng thái ẩn . Tuy nhiên, không giống như RNN thông \r\n\r\nthường, cả  và  cùng bị điều khiển bởi 1 và vector ngữ cảnh c của dãy đầu \r\n\r\nvào.  \r\n\r\nDo đó, trạng thái ẩn của bộ giải mã tại thời điểm t được tính như sau: \r\n\r\n = (1, 1, ) \r\n\r\nCông thức 1 Trạng thái ẩn của bộ giải mã tại thời điểm t \r\n\r\n \r\n\r\n\r\n\r\n \r\n35 \r\n\r\nTương tự, xác xuất phân bố của từ tiếp theo là:  \r\n\r\n(| 1, 2, . ,  , ) = ( , 1, ) \r\n\r\nCông thức 2 Xác suất phân bố từ tiếp theo \r\n\r\nTrong đó, f, g là các hàm tính xác suất (thường là hàm softmax)  \r\n\r\nVí dụ:  = (1, . ,   | 1, . , ), trong đó độ dài các chuỗi đầu vào và đầu ra T, T \r\n\r\ncó thể khác nhau.  \r\n\r\nBộ mã hóa và giải mã được huấn luyện đồng thời và kiểm tra hàm mất mát ở bộ giải \r\n\r\nmã.  \r\n\r\nKhi bộ RNN Encoder-Decoder được đào tạo, mô hình có thể được sử dụng theo hai \r\n\r\ncách. Một cách là sử dụng mô hình để tạo một chuỗi đích từ chuỗi đầu vào. Mặt khác, \r\n\r\nmô hình có thể được sử dụng để tính điểm cho cặp chuỗi đầu vào và chuỗi đầu ra \r\n\r\ntheo xác suất (\r\n\r\n\r\n\r\n),  là tập tham số của mô hình. \r\n\r\n3.3.2 Kỹ thuật Attention \r\n\r\nKhi sử dụng mô hình seq2seq ta thấy có các vấn đề:  \r\n\r\n Mô hình yêu cầu phải sử dụng toàn bộ thông tin chuỗi đầu để bộ mã hóa tạo \r\n\r\nra vectơ c dù cho chuỗi đầu vào dài hay ngắn. Việc này không hợp lí vì trong \r\n\r\nmột số trường hợp nhất định ta chỉ cần thông tin của một thành phần của chuỗi. \r\n\r\nVí dụ như việc dịch một từ thì ta chỉ cần quan tâm tới ngữ cảnh của các từ \r\n\r\nxung quanh nó trong câu. \r\n\r\n Yêu cầu bộ giải mã phải trích xuất được thông tin từ vector vì tất cả các đầu \r\n\r\nra của bộ giải mã đều sử dụng chung một vector ngữ cảnh c. \r\n\r\n Vector ngữ cảnh c phải chứa đầy đủ thông tin cho bộ giải mã. \r\n\r\n\r\n\r\n \r\n36 \r\n\r\nTrong thực tế, con người chúng ta tiếp nhận rất nhiều thông tin. Nhưng chỉ những \r\n\r\nthông tin quan trọng và cần thiết được sử dụng để đưa ra quyết định nào đó. Kĩ thuật \r\n\r\nattention dựa trên ý tưởng này để giải quyết các vấn đề của mô hình seq2seq.  \r\n\r\nKĩ thuật này được được đề xuất lần đầu tiên bởi Bahdanau và cộng sự vào năm 2014 \r\n\r\nlấy cảm hứng từ mô hình visual attention trong ngành công nghiệp computer vision. \r\n\r\nVới kĩ thuật này, thay vì mã hóa toàn bộ chuỗi đầu vào thành một vector ngữ cảnh \r\n\r\nduy nhất bằng một dãy vector. Dãy vector này được tính trung bình và là đầu vào của \r\n\r\ncác thành phần trong bộ giải mã. Bộ mã hóa, giải mã và cơ chế attention được huấn \r\n\r\nluyện đồng thời cùng nhau (join training). Chuỗi đầu vào được mã hóa bằng RNN \r\n\r\nhai chiều (bidirectional RNN) và sinh ra một chuỗi các vector. Tại mỗi thời điểm, bộ \r\n\r\ngiải mã sẽ chọn một thành phần trong chuỗi vector để tập trung vào và sinh ra một \r\n\r\nvector ngữ cảnh để sinh ra đầu ra tại thời điểm đó. \r\n\r\n3.3.3 Word vector \r\n\r\nWord vector là vector có trọng số, số chiều nhất định và được sử dụng để biểu diễn \r\n\r\nmột từ. Đầu vào khi sử dụng học sâu cho NLP là vector chứa giá trị số. Tùy theo cách \r\n\r\nchọn đơn vị đầu vào mà có các cách biểu diễn khác nhau. \r\n\r\nĐơn vị đầu vào thường được chia làm hai loại: ký tự (character) và từ (token). \r\n\r\nBiểu diễn dưới dạng ký tự (character) là một cách biểu diễn đơn giản vì số lượng kí \r\n\r\ntự không lớn, có giới hạn. Do đó, số chiều của vector biểu diễn cũng nhỏ, không sợ \r\n\r\ncác vấn đề về lưu trữ và xử lí. Giữa các kí tự không có mối quan hệ về ngữ nghĩa, \r\n\r\nnên hai kí tự khác nhau thì chỉ cần hai vector khác nhau là có thể biểu diễn được.  \r\n\r\nKhi cần biểu diễn một kí tự chúng ta có thể biểu diễn bằng một one-hot vector. Số \r\n\r\nchiều của one-hot vector phụ thuộc vào số lượng phần tử có trong tập hợp mà chúng \r\n\r\nta cần biểu diễn. Ví dụ chúng ta cần biểu diễn cho 102 kí tự trên bàn phím thì chúng \r\n\r\nta cần vector 102 chiều. \r\n\r\n \r\n\r\n\r\n\r\n \r\n37 \r\n\r\nTuy nhiên, chúng ta có thể sử dụng nhiều cách để biểu diễn một từ (token).  \r\n\r\n Sử dụng một số nguyên để biểu diễn: cách này đơn giản nhưng không hiệu \r\n\r\nquả vì nó không biểu diễn được mối quan giữa các từ và đầu vào là một vector. \r\n\r\n Sử dụng one-hot vector: Giống với cách biểu diễn kí tự, ta coi mỗi token là \r\n\r\nmột phần tử và một triệu từ được coi là một triệu phần tử trong tập hợp. Khi \r\n\r\nđó, mỗi từ sẽ đc biểu diễn bằng một vector một triệu chiều. Do đó, khi phải \r\n\r\nlưu một triệu phần tử thì chúng ta cần phải sử dụng một ma trận \r\n\r\n1.000.000x1000.000 để biểu diễn. Điều này dẫn đến những vẫn đề về lưu trữ \r\n\r\nvà xử lí. Mặt khác, việc dùng one-hot vector cũng không thể biểu diễn được \r\n\r\nmối quan hệ giữa các từ. \r\n\r\n Sử dụng các vector random: khắc phục được nhược điểm về số chiều của \r\n\r\nvector. Mỗi từ được coi là một điểm trong không gian với số chiều nhất định. \r\n\r\nTuy nhiên, cách này vẫn không biểu diễn được mối quan hệ giữa các từ. \r\n\r\n Sử dụng word embeddings: Đây được xem là cách biểu diễn hiệu quả nhất với \r\n\r\nsố chiều biểu diễn một từ thấp và biểu diễn được mối quan hệ giữa các từ với \r\n\r\nnhau. \r\n\r\n3.3.4 Word Empeddings \r\n\r\nWord embeddings là một trong những phương diện nghiên cứu thú vị nhất của \r\n\r\nphương pháp Deep Learning trong xử lý ngôn ngữ tự nhiên. Một word embeddings \r\n\r\nlà một hàm ánh xạ từ thành các vector nhiều chiều (200 đến 500 chiều). \r\n\r\nVí dụ như: \r\n\r\nW(cat) = (0.2, -0.4, 0.7, .) \r\n\r\nW(mat) = (0.0, 0.6, -0.1, .)  \r\n\r\nThường thì hàm W sẽ là một bảng tra cứu, lưu trữ dưới dạng một ma trận , với \r\n\r\n() = .  W khởi tạo một vector random cho mỗi từ, vector này được thay đổi \r\n\r\nsao cho nó biểu diễn được mối quan hệ với những từ khác liên quan.  \r\n\r\n\r\n\r\n \r\n38 \r\n\r\nCác vector có tính chất (i) số lượng chiều không lớn (200 đến 500 chiều, nhỏ so với \r\n\r\ntập từ vựng), (ii) các từ có nghĩa gần nhau sẽ gần nhau trong không gian, và (iii) mối \r\n\r\nquan hệ tương đồng ngữ nghĩa sẽ được chuyển thành mối quan hệ giống nhau giữa \r\n\r\ncác vector. \r\n\r\nVí dụ việc huấn luyện mạng phát hiện ra cụm 5-gram (chuỗi 5 từ) có hợp lệ hay \r\n\r\nkhông. Hàm W ánh xạ mỗi từ tới một vector, các vector này được đưa vào một hàm \r\n\r\nkhác là R. R sẽ xác định cụm năm từ đó có hợp lệ hay không. \r\n\r\nR(W(cat), W(sat), W(on), W(the), W(mat)) = 1  \r\n\r\nR(W(cat), W(sat), W(song), W(the), W(mat)) = 0 \r\n\r\nBằng cách đổi từ có cùng lớp nghĩa, chúng ta sẽ sinh ra được các câu không hợp lệ \r\n\r\nvà các câu có cùng lớp nghĩa (the wall is blue  the wall is red). Hơn thế, chúng \r\n\r\nta có thể thay đổi nhiều từ. Bằng cách này chúng ta sẽ dịch được vector các từ nghĩa \r\n\r\ngần nhau tới gần nhau hơn và mối liên hệ giữa các từ cũng dần được mã hóa. Ví dụ \r\n\r\nvề sự khác biệt giữa man và woman:  \r\n\r\nW(man)  W(woman)  W(uncle)  W(aunt)  \r\n\r\nW(man)  W(woman)  W(king)  W(queen) \r\n\r\n \r\n\r\n \r\n\r\n\r\n\r\n\r\n \r\n39 \r\n\r\nNhững mối quan hệ phức tạp hơn cũng được mã hóa theo cách này. \r\n\r\n \r\n\r\n\r\nTrong đồ án, sinh viên sử dụng word empedding là ConceptNet Numberbatch, nội \r\n\r\ndung sẽ được trình bày chi tiết trong phần 5.1. \r\n\r\n3.4 Text-to-Speech \r\n\r\nTrên máy tính, Text-to-Speech (TTS) là việc tạo ra giọng nói của người từ đầu vào \r\n\r\nlà văn bản hay các mã hóa việc phát âm. Tuy rằng không phải hệ thống text-to-speech \r\n\r\nnào cũng có đầu vào là văn bản (nhiều hệ thống thu nhận mã hóa cách phát âm, ví dụ \r\n\r\nmã IPA). Hệ thống thực hiện việc này còn gọi là máy tổng hợp giọng nói (text-to-\r\n\r\nspeech engine), có thể là hệ thống phần mềm hoặc phần cứng. \r\n\r\nCác hệ thống TTS có nhiều ứng dụng. Ví dụ như có thể giúp người có thị lực kém \r\n\r\n(hoặc khiếm thị) nghe được máy đọc ra văn bản, đặc biệt là các văn bản có thể xử lý \r\n\r\ntrên máy tính. Hệ thống có thể lắp đặt trong phần mềm xử lý văn bản hay trình duyệt \r\n\r\nmạng. \r\n\r\nHai tính chất quan trọng của chất lượng hệ thống tổng hợp giọng nói là mức độ tự \r\n\r\nnhiên và mức độ dễ nghe. Mức độ tự nhiên của giọng nói tổng hợp chính là sự giống \r\n\r\nnhau giữa giọng tổng hợp và giọng nói tự nhiên của người thật. Mức độ dễ nghe chỉ \r\n\r\n\r\n\r\n \r\n40 \r\n\r\nđến việc câu phát âm có thể hiểu được dễ dàng không. Một hệ thống TTS lý tưởng \r\n\r\ncần vừa tự nhiên vừa dễ nghe, và mục tiêu xây dựng hệ thống TTS là làm tăng tối đa \r\n\r\nhai tính chất này. Một số hệ thống TTS có thể thiên về mức độ dễ nghe hơn, hoặc \r\n\r\nmức độ tự nhiên hơn; tùy thuộc vào mục đích mà công nghệ được lựa chọn. Có hai \r\n\r\ncông nghệ chính được dùng là tổng hợp ghép nối và tổng hợp cộng hưởng tần số; \r\n\r\nngoài ra cũng có một số công nghệ khác. \r\n\r\nTổng hợp ghép nối dựa trên việc nối vào nhau các đoạn của một giọng nói đã được \r\n\r\nghi âm. Thông thường, tổng hợp ghép nối tạo ra giọng nói tương đối tự nhiên. Tuy \r\n\r\nnhiên, giọng nói tự nhiên được ghi âm có sự thay đổi từ lần phát âm này sang lần phát \r\n\r\nâm khác, và công nghệ tự động hóa việc ghép nối các đoạn của sóng âm thỉnh thoảng \r\n\r\ntạo ra những tiếng cọ xát không tự nhiên ở phần ghép nối. \r\n\r\nTổng hợp cộng hưởng tần số không sử dụng bất cứ mẫu giọng thật nào khi chạy. Thay \r\n\r\nvào đó, tín hiệu âm thanh cho ra dựa trên một mô hình âm thanh. Các thông số như \r\n\r\ntần số cơ bản, sự phát âm, và mức độ tiếng ồn được thay đổi theo thời gian để tạo ra \r\n\r\ndạng sóng cho giọng nói nhân tạo. Phương pháp này đôi khi còn được gọi là tổng hợp \r\n\r\ndựa trên quy tắc, dù cho nhiều hệ thống ghép nối mẫu âm thanh thật cũng có dùng \r\n\r\ncác thành phần dựa trên quy tắc. \r\n\r\nNhiều hệ thống dựa trên tổng hợp cộng hưởng tần số tạo ra giọng nói nhân tạo, như \r\n\r\ngiọng robot. Giọng nói nhân tạo thường không tự nhiên, và có thể phân biệt rõ ràng \r\n\r\nvới giọng người thật. Tuy nhiên độ tự nhiên cao không phải lúc nào cũng là mục đích \r\n\r\ncủa hệ thống và hệ thống này cũng có các ưu điểm riêng của nó. \r\n\r\nHệ thống tổng hợp giọng nói nhân tạo nói khá dễ nghe, ngay cả ở tốc độ cao, không \r\n\r\ncó tiếng cọ xát do ghép âm tạo ra. Các hệ thống này hoạt động ở tốc độ cao, có thể \r\n\r\nhướng dẫn người khiếm thị nhanh chóng dò dẫm trên máy tính, bằng cách đọc to \r\n\r\nnhững gì hiện ra trên màn hình. Các hệ thống này cũng nhỏ gọn hơn các hệ thống \r\n\r\nghép nối âm, vì không phải chứa cơ sở dữ liệu mẫu âm thanh lớn. Nó có thể dùng \r\n\r\ntrong các hệ thống nhúng khi bộ nhớ và tốc độ xử lý có hạn. Hệ thống này cũng có \r\n\r\nkhả năng điều khiển mọi khía cạnh của tín hiệu âm thanh đi ra, nó cho ra một dải rộng \r\n\r\n\r\n\r\n \r\n41 \r\n\r\ncác lời văn và ngữ điệu, và không chỉ thể hiện được câu nói thường hay câu hỏi, mà \r\n\r\ncả các trạng thái tình cảm thông qua âm điệu của giọng nói. \r\n\r\n3.5 Android \r\n\r\nAndroid là một hệ điều hành dựa trên nền tảng Linux được thiết kế dành cho các thiết \r\n\r\nbị di động có màn hình cảm ứng như điện thoại thông minh và máy tính bảng. Ban \r\n\r\nđầu, Android được phát triển bởi Tổng công ty Android, với sự hỗ trợ tài chính từ \r\n\r\nGoogle và sau này được chính Google mua lại vào năm 2005. Android ra mắt vào \r\n\r\nnăm 2007 cùng với tuyên bố thành lập Liên minh thiết bị cầm tay mở: một hiệp hội \r\n\r\ngồm các công ty phần cứng, phần mềm, và viễn thông với mục tiêu đẩy mạnh các \r\n\r\ntiêu chuẩn mở cho các thiết bị di động. Chiếc điện thoại đầu tiên chạy Android được \r\n\r\nbán vào năm 2008. \r\n\r\nAndroid có mã nguồn mở và Google phát hành mã nguồn theo Giấy phép Apache. \r\n\r\nChính mã nguồn mở cùng với một giấy phép không có nhiều ràng buộc đã cho phép \r\n\r\ncác nhà phát triển thiết bị, mạng di động và các lập trình viên nhiệt huyết được điều \r\n\r\nchỉnh và phân phối Android một cách tự do. Ngoài ra, Android còn có một cộng đồng \r\n\r\nlập trình viên đông đảo chuyên viết các ứng dụng để mở rộng chức năng của thiết bị, \r\n\r\nbằng một loại ngôn ngữ lập trình Java có sửa đổi. Vào tháng 10 năm 2012, có khoảng \r\n\r\n700.000 ứng dụng trên Android, và số lượt tải ứng dụng từ Google Play, cửa hàng \r\n\r\nứng dụng chính của Android, ước tính khoảng 25 tỷ lượt. \r\n\r\nAndroid chiếm 87,7% thị phần điện thoại thông minh trên toàn thế giới vào thời điểm \r\n\r\nquý 2 năm 2017, với tổng cộng 2 tỷ thiết bị đã được kích hoạt và 1,3 triệu lượt kích \r\n\r\nhoạt mỗi ngày. Sự thành công của hệ điều hành cũng khiến nó trở thành mục tiêu \r\n\r\ntrong các vụ kiện liên quan đến bằng phát minh, góp mặt trong cái gọi là \"cuộc chiến \r\n\r\nđiện thoại thông minh\" giữa các công ty công nghệ. \r\n\r\nCác ứng dụng cho Android được phát triển bằng ngôn ngữ Java sử dụng Bộ phát triển \r\n\r\nphần mềm Android (SDK). SDK bao gồm một bộ đầy đủ các công cụ dùng để phát \r\n\r\ntriển, gồm có công cụ gỡ lỗi, thư viện phần mềm, bộ giả lập điện thoại dựa trên \r\n\r\n\r\n\r\n \r\n42 \r\n\r\nQEMU, tài liệu hướng dẫn, mã nguồn mẫu, và hướng dẫn từng bước. Môi trường \r\n\r\nphát triển tích hợp (IDE) được hỗ trợ chính thức là Eclipse sử dụng phần bổ sung \r\n\r\nAndroid Development Tools (ADT). Các công cụ phát triển khác cũng có sẵn, gồm \r\n\r\ncó Bộ phát triển gốcdành cho các ứng dụng hoặc phần mở rộng viết bằng C hoặc \r\n\r\nC++, Google App Inventor, một môi trường đồ họa cho những nhà lập trình mới bắt \r\n\r\nđầu, và nhiều nền tảng ứng dụng web di động đa nền tảng phong phú. \r\n\r\nAndroid có một hạt nhân dựa trên nhân Linux phiên bản 2.6, kể từ Android 4.0 Ice \r\n\r\nCream Sandwich trở về sau, là phiên bản 3.x, với middleware, thư viện và API viết \r\n\r\nbằng C, còn phần mềm ứng dụng chạy trên một nền tảng ứng dụng gồm các thư viện \r\n\r\ntương thích với Java dựa trên Apache Harmony. Android sử dụng máy ảo Dalvik với \r\n\r\nmột trình biên dịch động để chạy 'mã dex' (Dalvik Executable) của Dalvik, thường \r\n\r\nđược biên dịch sang Java bytecode. Nền tảng phần cứng chính của Android là kiến \r\n\r\ntrúc ARM. Người ta cũng hỗ trợ x86 thông qua dự án Android x86, và Google TV \r\n\r\ncũng sử dụng một phiên bản x86 đặc biệt của Android. \r\n\r\n \r\n\r\n \r\n\r\nTổng kết lại, Chương 3 đã trình bày về các kiến thức cơ bản của phương pháp tóm \r\n\r\ntắt văn bản bằng Deep Learning và kiến thức liên quan đến nền tảng Android cũng \r\n\r\nnhư công nghệ Text-to-Speech. Trong chương tiếp theo, người viết đồ án sẽ mô tả \r\n\r\nquy trình xây dựng và phát triển sản phẩm. \r\n\r\n\r\n\r\n \r\n43 \r\n\r\nYếu tố quan trọng nhất trong phương pháp tóm tắt văn bản bằng Deep Learning là \r\n\r\nxây dựng thành công model đã được huấn luyện với một tập dữ liệu tốt. Chương 4 sẽ \r\n\r\ntrình bày quy trình xây dựng và huấn luyện model, cùng với đó là trình bày về ứng \r\n\r\ndụng di động Android tích hợp chức năng tóm tắt văn bản và công nghệ text-to-\r\n\r\nspeech. \r\n\r\n4.1 Mô hình tóm tắt văn bản \r\n\r\n4.1.1 Tiền xử lý dữ liệu \r\n\r\nTập dữ liệu được sử dụng bao gồm các review về thức ăn trên Amazon được thu thập \r\n\r\ntừ tháng 10/1999 đến tháng 10/2012. Có tổng cộng 568.454 bản review về 74.258 \r\n\r\nsản phẩm được đánh giá từ 256.059 người dùng. Mỗi bản review bao gồm thông tin \r\n\r\nvề sản phẩm, người dùng, xếp hạng, tiêu đề và nội dung đánh giá. Tuy nhiên, trong \r\n\r\nphạm vi đồ án này, chúng ta chỉ chú ý đến hai trường dữ liệu là tiêu đề (summary) và \r\n\r\nnội dung đánh giá (text). \r\n\r\nTrước tiên, dữ liệu được xử lý theo các bước (i) chuyển chữ viết hoa thành chữ \r\n\r\nthường, (ii) thay thế các cụm từ viết tắt về dạng chuẩn của nó (ví dụ như cant thành \r\n\r\ncannot), (iii) xoá bỏ các ký tự không cần thiết, và (iv) xoá bỏ stop words để tiết \r\n\r\nkiệm bộ nhớ và tăng tốc độ xử lý (stop words là các từ trong tiếng Anh có nghĩa \r\n\r\nkhông ảnh hưởng đến nội dung tóm tắt văn bản, ví dụ như mạo từ the). \r\n\r\nChương 4 Phát triển và \r\n\r\ntriển khai ứng dụng \r\n\r\n\r\n\r\n \r\n44 \r\n\r\nChúng ta sẽ sử dụng ConceptNet Numberbatch (CN) như đã được giới thiệu. Trong \r\n\r\nđó, mỗi token từ sẽ được chuyển sang thành vector 300 chiều. \r\n\r\nVới các từ không có trong CN mà có tần suất xuất hiện lớn hơn 20 lần, chúng ta sẽ \r\n\r\ntạo một vector 300 chiều với các giá trị ngẫu nhiên trong khoảng [-1, 1], sau đó thêm \r\n\r\nnó vào word empeddings. Ngoài ra, token <UNK> dùng để đánh dấu các từ chưa \r\n\r\nbiết, token <EOS> dùng để đánh dấu kết thúc câu. \r\n\r\nĐể huấn luyện model nhanh hơn, các đoạn review sẽ được sắp xếp theo độ dài từ nhỏ \r\n\r\nđến lớn. Các review có nhiều hơn 1 token <UNK> sẽ bị loại bỏ để đảm bảo model \r\n\r\nđược huấn luyện với tập dữ liệu tốt. \r\n\r\n4.1.2 Kiến trúc Encoder-Decoder \r\n\r\nĐể xây dựng mô hình seq2seq, kiến trúc Encoder-Decoder với mạng RNN là một \r\n\r\nphương thức tiếp cận hiệu quả và tiêu chuẩn, gồm 2 phần chính là bộ mã hoá \r\n\r\n(encoder) và bộ giải mã (decoder). \r\n\r\n \r\n\r\n\r\nMỗi từ đầu vào sẽ được đánh số theo hai từ điển là vocab_to_int và int_to_vocab để \r\n\r\ntương ứng với một số nguyên, giúp cho việc truy xuất dữ liệu nhanh hơn. Sau đó, từ \r\n\r\nđược đưa vào word_embedding_matrix, mỗi từ được biểu diễn dưới dạng vector 300 \r\n\r\nchiều. Vector đi lần lượt qua các lớp ẩn, kết hợp với lớp ẩn sinh ra từ token trước đó. \r\n\r\nSau khi nhận layer ẩn cuối cùng, bộ giải mã kết hợp với token <EOS> để làm đầu \r\n\r\nvào. Sử dụng lớp softmax và kĩ thuật attention, bộ giải mã sẽ sinh lần lượt từng từ \r\n\r\ncho output. Quá trình dừng lại khi sinh đến kí tự <EOS>. \r\n\r\n\r\n\r\n \r\n45 \r\n\r\nTrong quá trình xử lý dữ liệu, những từ không nằm trong CN hoặc có tần suất xuất \r\n\r\nhiện dưới 20 lần sẽ bị gán nhãn <UNK> sẽ bị loại bỏ sẽ gây mất mát thông tin. \r\n\r\nThường những từ này là tên riêng. Tuy nhiên tỷ lệ rất nhỏ, chỉ chiếm 0.7%, nên sẽ \r\n\r\nkhông ảnh hưởng nhiều đến kết quả tóm tắt văn bản, vậy nên chúng ta có thể bỏ qua. \r\n\r\nChúng ta sử dụng mạng LSTM với 2 lớp ẩn. Mỗi lớp ẩn có kích thước là 256 units. \r\n\r\nCác trọng số trong mô hình được khởi tạo giá trị trong khoảng [-0.1;0.1]. Learning \r\n\r\nrate là 0.005. \r\n\r\n4.1.3 Kỹ thuật attention \r\n\r\nKĩ thuật attention là một cơ chế giúp giải quyết hạn chế của kiến trúc Encoder-\r\n\r\nDecoder trên các chuỗi dài, cụ thể nó sẽ tăng tốc độ học và nâng cao kỹ năng của mô \r\n\r\nhình trong việc dự đoán từ tiếp theo. Nó giúp cho mạng neural có thể chú ý hơn vào \r\n\r\nnhững nội dung quan trọng. Chuỗi đầu vào 1: được mã hoá bằng mạng RNN 2 \r\n\r\nchiều, sinh ra n vector 1:. \r\n\r\n1: = (1:) =   (1:) \r\n\r\nCông thức 3 Mã hoá chuỗi đầu vào bằng biRNN \r\n\r\nTại mỗi bước , decoder sẽ chọn ra những phần nào trong 1: để tập trung vào, sinh \r\n\r\nra vector ngữ cảnh  để dùng cho bước dự đoán thứ . \r\n\r\n(+1 = |1: , 1:) = ((+1))  \r\n\r\n+1 = ( , [; \r\n]) \r\n\r\n = (1:, 1:) \r\n\r\n  ~ (|1:1, 1:) \r\n\r\nCông thức 4 Sinh vector ngữ cảnh \r\n\r\n\r\n\r\n \r\n46 \r\n\r\n4.2 Ứng dụng di động Android \r\n\r\n4.2.1 Thiết kế kiến trúc \r\n\r\nTổng quan, ứng dụng được thiết kế theo mô hình Client - Server. Các thiết bị đóng \r\n\r\nvai trò máy khách gửi yêu cầu (request) tới máy chủ, máy chủ xử lý và gửi phản hồi \r\n\r\n(response) trở lại cho máy khách. \r\n\r\n \r\n\r\n\r\nCả phía Client và Server đều được xây dựng theo mô hình MVC. MVC là viết tắt của \r\n\r\nModel  View  Controller, trong đó Model chứa các đối tượng mô tả dữ liệu, View \r\n\r\nđảm nhận việc hiển thị thông tin, tương tác người dùng, còn Controller giữ nhiệm vụ \r\n\r\nnhận điều hướng các yêu cầu từ người dùng và gọi những phương thức xử lý chúng. \r\n\r\nĐối với ứng dụng phía client, phần View là các Activity và View hiển thị đối với \r\n\r\nngười dùng, phần Controller xử lý các thao tác, điều khiển các luồng sự kiện, còn \r\n\r\nModel lưu trữ thông tin đối tượng của hệ thống. \r\n\r\n\r\n\r\n \r\n47 \r\n\r\nThiết kế tổng quan: \r\n\r\n \r\n\r\n\r\nTổng quan, phần mềm được chia thành 4 package lớn là Service, Controller, View và \r\n\r\nModel. Trong đó, nhiệm vụ của mỗi package được phân tách rõ ràng. \r\n\r\nGói Service là gói chính của ứng dụng, giúp người dùng thực hiện các tác vụ ngay cả \r\n\r\nkhi không mở ứng dụng. \r\n\r\nGói Controller điều khiển các luồng, thực hiện các hành động chính của ứng dụng \r\n\r\nkhi người dùng thao tác. \r\n\r\nGói View để người dùng có thể vẽ custom view khi chọn vùng văn bản, gồm 2 class \r\n\r\nlà DrawLayout.java và CustomView.java. \r\n\r\nGói Model chứa các lớp lưu trữ dữ liệu. \r\n\r\n\r\n\r\n \r\n48 \r\n\r\n4.2.2 Thiết kế giao diện \r\n\r\nGiao diện chương trình: \r\n\r\n \r\n\r\n\r\nKhi ở giao diện chính, chúng ta có thể chọn toàn bộ các văn bản xuất hiện trên màn \r\n\r\nhình hoặc chọn một vùng văn bản. Nội dung văn bản đã được chọn sẽ được đọc bằng \r\n\r\ncông cụ text-to-speech. \r\n\r\nNếu chọn một vùng văn bản, layout được chuyển qua giao diện tóm tắt văn bản. \r\n\r\n \r\n\r\n\r\n\r\n\r\n \r\n49 \r\n\r\nỞ giao diện này, người dùng có thể chọn chức năng tóm tắt. Dữ liệu sẽ được gửi tới \r\n\r\nserver, sau đó trả về kết quả là một đoạn văn bản đã được tóm tắt hiển thị trên Dialog. \r\n\r\n \r\n\r\n\r\n4.3 Xây dựng ứng dụng \r\n\r\n4.3.1 Thư viện và công cụ sử dụng \r\n\r\nCác công cụ, ngôn ngữ lập trình, API, thư viện, IDE được sử dụng để phát triển ứng \r\n\r\ndụng. \r\n\r\n\r\nMục đích Công cụ Địa chỉ URL \r\n\r\nNgôn ngữ lập trình Python 3.6 64-bit https://www.python.org/ \r\n\r\nIDE lập trình PyCharm 2017.3.4 https://www.jetbrains.com/pycharm/ \r\n\r\nIDE lập trình Android Studio 2.3.3 https://developer.android.com/studio/ \r\n\r\nThư viện           \r\n\r\nDeep Learning \r\n\r\nTensorFlow 1.7.0 https://www.tensorflow.org/ \r\n\r\nFramework  Django 2.0.4 https://www.djangoproject.com/ \r\n\r\n4.3.2 Kết quả đạt được \r\n\r\nĐể đánh giá kết quả của model tóm tắt văn bản, người viết đồ án lựa chọn phương \r\n\r\npháp Rouge làm thước đo. Recall Oriented Understudy (ROUGE) là một phương \r\n\r\n\r\n\r\n \r\n50 \r\n\r\npháp do Lin và Hovy đưa ra vào năm 2003 cũng dựa trên các khái niệm tương tự. \r\n\r\nPhương pháp này sử dụng n-gram để đánh giá sự tương quan giữa các kết qủa của \r\n\r\nmô hình tóm tắt và tập dữ liệu đánh giá. Phương pháp này đã cho ra kết quả khả quan \r\n\r\nvà được sự đánh giá cao của cộng đồng nghiên cứu tóm tắt văn bản. ROUGE-N là \r\n\r\nmột thu hồi n-gram (n-gram recall) giữa một bản tóm tắt tự động và một tập các tài \r\n\r\nliệu tóm tắt tham chiếu (ReferenceSummaries). ROUGE-N được tính như sau: \r\n\r\n   =  \r\n  ()    {}\r\n\r\n  ()    {}\r\n \r\n\r\nCông thức 5 Công thức tính ROUGE-N \r\n\r\nTrong đó: \r\n\r\n n là chiều dài của n-gram \r\n\r\n () là số lượng tối đa n-gram có thể xảy ra đồng thời trong \r\n\r\nbản tóm tắt tự động và bản tóm tắt tham chiếu \r\n\r\nROUGE-N là một độ đo liên quan đến độ recall bởi vì mẫu số của vế phải trong công \r\n\r\nthức trên là tổng số n-gram xảy ra ở phía bản tóm tắt tham chiếu. Cũng có một lưu ý \r\n\r\nrằng, số lượng n-gram ở mẫu số trong công thức tính ROUGE-N sẽ tăng lên khi chúng \r\n\r\nta cho thêm nhiều tham chiếu. Điều này hoàn toàn trực quan và hợp lí bởi vì có thể \r\n\r\ntồn tại nhiều bản tóm tắt tốt. \r\n\r\nMỗi khi chúng ta thêm một tham chiếu vào tập các văn bản tham chiếu, chúng ta đã \r\n\r\nmở rộng không gian các văn bản tóm tắt thay thế (alternative summaries). Bằng cách \r\n\r\nđiều khiển các kiểu tham chiếu mà ta thêm vào tập văn bản tham chiếu, chúng ta có \r\n\r\nthể thiết kế các đánh giá tập trung vào các khía cạnh khác nhau của việc tóm tắt. \r\n\r\nNgoài ra, tổng tử số lớn hơn tổng số số bản tóm tắt tham chiếu. Điều này hiệu quả vì \r\n\r\ncung cấp thêm nhiều trọng số để matching các n-grams xảy ra trong đa tham chiếu. \r\n\r\nDo đó, một bản tóm tắt tự động càng chứa nhiều những từ được xuất hiện trong nhiều \r\n\r\nbản tóm tắt tham chiếu thì sẽ dành được điểm ROUGE-N càng cao. Điều này một lần \r\n\r\nnữa lại rất trực quan và hợp lí bởi vì chúng ta thường ưu tiên các bản tóm tắt tự động \r\n\r\n\r\n\r\n \r\n51 \r\n\r\ncàng có nhiều nét giống với các điểm giống nhau giữa các bản tóm tắt tham chiếu \r\n\r\ncàng tốt. \r\n\r\nKhi sử dụng đa tham chiếu, chúng ta tính ROUGE-N theo từng cặp, giữa bản tóm tắt \r\n\r\ntự động s và từng bản tóm tắt tham chiếu ri trong tập các văn bản tóm tắt tham chiếu. \r\n\r\nSau đó, kết quả điểm ROUGE-N cuối cùng trong đa tham chiếu sẽ là điểm ROUGE-\r\n\r\nN cao nhất trong tất cả các cặp được tính. Điều này có thể được thể hiện theo công \r\n\r\nthức sau: \r\n\r\n   =   ( , ) \r\n\r\nCông thức 6 Công thức tính ROUGE-N cuối cùng trong đa tham chiếu \r\n\r\nKết quả của model đạt được như sau: \r\n\r\n ROUGE-1: 26.86% \r\n\r\n ROUGE-2: 6.71% \r\n\r\nChúng ta sẽ so sánh kết quả với một số các model tóm tắt văn bản khác đã được công \r\n\r\nbố kết quả: \r\n\r\n\r\nModel ROUGE-1 ROUGE-2 \r\n\r\nModel Lead-3 (Nallapati) [3] 21.90% 7.20% \r\n\r\nModel SummaRuNNer (Nallapati) [5] 26.20% 10.80% \r\n\r\nModel Cheng et al  16 [5] 22.70% 8.50% \r\n\r\nModel ABS+ [5] 26.67% 6.72% \r\n\r\nModel of Sumit Chopra, Michael Auli [6] 26.90% 6.57% \r\n\r\n \r\n\r\n\r\n\r\n \r\n52 \r\n\r\nThông thường, các phương pháp tóm tắt trích xuất sẽ đạt kết quả ROUGE cao hơn \r\n\r\ncác phương pháp tóm tắt tóm lược. Bởi vì, phương pháp trích xuất sử dụng các từ \r\n\r\nxuất hiện trong văn bản để tạo ra bản tóm tắt, còn phương pháp tóm lược thì viết lại \r\n\r\ncâu theo ý hiểu của máy. \r\n\r\nNhư vậy, so với các model tóm tắt văn bản bằng Deep Learning khác, model của hệ \r\n\r\nthống đạt được kết quả gần tương đương. Trong đó kết quả ROUGE-1 gần bằng các \r\n\r\nmodel khác, còn kết quả ROUGE-2 vẫn khá thấp vì ảnh hưởng bởi tập dữ liệu không \r\n\r\nđược xử lý tốt. \r\n\r\nMột số kết quả thực nghiệm của model tóm tắt văn bản: \r\n\r\n\r\nVăn bản đầu vào Tóm tắt \r\n\r\nThe coffee tasted great and was at such a good price! I highly \r\n\r\nrecommend this to everyone! \r\n\r\ngreat coffee great \r\n\r\nprice \r\n\r\nThis saltwater taffy had great flavors and was very soft and \r\n\r\nchewy. Each candy was individually wrapped well. None of the \r\n\r\ncandies were stuck together, which did happen in the expensive \r\n\r\nversion, Fralinger's. Would highly recommend this candy! I \r\n\r\nserved it at a beach-themed party and everyone loved it! \r\n\r\ngreat candy \r\n\r\nRight now I'm mostly just sprouting this so my cats can eat the \r\n\r\ngrass. They love it. I rotate it around with Wheatgrass and Rye \r\n\r\ntoo. \r\n\r\ncats love it \r\n\r\nThis is a very healthy dog food. Good for their digestion. Also \r\n\r\ngood for small puppies. My dog eats her required amount at \r\n\r\nevery feeding. \r\n\r\nhealthy dog food \r\n\r\n\r\n\r\n \r\n53 \r\n\r\nGood flavor! These came securely packed. They were fresh and \r\n\r\ndelicious! I love these Twizzlers! \r\n\r\nfresh and \r\n\r\ndelicious \r\n\r\nGood oatmeal. I like the apple cinnamon the best. Though I \r\n\r\nwouldn't follow the directions on the package since it always \r\n\r\ncomes out too soupy for my taste.  That could just be me since \r\n\r\nI like my oatmeal really thick to add some milk on top of. \r\n\r\ngood oatmeal \r\n\r\nDeal was awesome!  Arrived before Halloween as indicated \r\n\r\nand was enough to satisfy trick or treaters.  I love the quality of \r\n\r\nthis product and it was much less expensive than the local \r\n\r\nstore's candy. \r\n\r\ngreat deal \r\n\r\nThis product serves me well as a source of electrolytes during \r\n\r\nand after a long run or bike ride. I have tried all of the flavors \r\n\r\nbut really do like the grapefruit flavor... no after-taste and I \r\n\r\nactually like the slight carbonation. I use other Hammer \r\n\r\nproducts and really like their whole product line. \r\n\r\ngreat flavor \r\n\r\nThese taste really good. I have been purchasing a different \r\n\r\nbrand and these are very similar in taste and texture. I agree \r\n\r\nwith the other reviewer regarding ordering in the summer. \r\n\r\nThere is no insulating packaging with ice packs so they will \r\n\r\nmelt in warm weather like all chocolate food items. Order in \r\n\r\ncold weather and buy enough to last!!! \r\n\r\ngreat taste \r\n\r\nWe have three dogs and all of them love this food!  We bought \r\n\r\nit specifically for one of our dogs who has food allergies and it \r\n\r\nworks great for him, no more hot spots or tummy problems. I \r\n\r\nlove that it ships right to our door with free shipping. \r\n\r\ndogs love it \r\n\r\n\r\n\r\n \r\n54 \r\n\r\nDon't buy just a few of these!  I order these by the case.  I can't \r\n\r\neven remember the first time I tasted an anchovy stuffed olive \r\n\r\nbut I have tried several of the brands online and this brand is \r\n\r\nmy favorite. \r\n\r\nbest olives ever \r\n\r\nFresh, a great way to get a little chocolate in my life without a \r\n\r\nmillion calories. They taste just like chocolate pudding. \r\n\r\nfresh tasting \r\n\r\nThis is the worst cheese that I have ever bought! I will never \r\n\r\nbuy it again and I hope you wont either! \r\n\r\nworst cheese ever \r\n\r\n4.4 Kiểm thử \r\n\r\nĐể kiểm thử ứng dụng Android, người viết đồ án sử dụng kỹ thuật Kiểm thử hộp đen \r\n\r\nvà Kiểm thử hộp trắng. \r\n\r\n4.4.1 Kiểm thử hộp đen \r\n\r\nKiểm thử hộp đen đối với chức năng Tóm tắt văn bản. Chức năng được kiểm thử \r\n\r\ntrong các test-case: không chọn văn bản, chọn vùng không có văn bản, chọn vùng \r\n\r\nvăn bản khi không có kết nối và có kết nối Internet. \r\n\r\n \r\n\r\n\r\n\r\n\r\n \r\n55 \r\n\r\n4.4.2 Kiểm thử hộp trắng \r\n\r\n \r\n\r\n\r\n \r\n\r\nĐồ thị nút của chương trình được thể hiện như sau: \r\n\r\n \r\n\r\n\r\nCác đường độc lập: \r\n\r\n 1  2  4 \r\n\r\n 1  3  4 \r\n\r\n\r\n\r\n \r\n56 \r\n\r\nTest-case cho đường 1: textSummary =   \r\n\r\nKết quả mong đợi: hiển thị thông báo No text to summarize. \r\n\r\nTest-case cho đường 2: textSummary = Hello World \r\n\r\nKết quả mong đợi: phương thức trả về chuỗi Hello World. \r\n\r\n4.5 Triển khai \r\n\r\nChương trình được xây dựng và thử nghiệm trên máy tính cá nhân có cấu hình và các \r\n\r\nphần mềm cần thiết như sau:  \r\n\r\n Ram: 8Gb \r\n\r\n Vi xử lý: Intel Core i7 CPU 2.60 GHz \r\n\r\n Hệ điều hành: Window 7 \r\n\r\n Phần mềm phát triển: PyCharm, Android Studio \r\n\r\n Ngôn ngữ sử dụng: Python, Java \r\n\r\n Card đồ họa: Nvidia geforce 920MX \r\n\r\n Thư viện: TensorFlow \r\n\r\n \r\n\r\n \r\n\r\nNhư vậy, Chương 4 đã trình bày quy trình triển khai mô hình tóm tắt văn bản và ứng \r\n\r\ndụng di động Android. Có thể nhận thấy, kết quả nghiên cứu khi áp dụng vào bài toán \r\n\r\nthực tế đã đạt được kết quả khả quan. \r\n\r\n\r\n\r\n \r\n57 \r\n\r\nĐể xây dựng nên sản phẩm hoàn chỉnh, trong quá trình làm đồ án, người viết đồ án \r\n\r\nđã lựa chọn các công nghệ hoặc phương pháp thực hiện phù hợp nhất đảm bảo sản \r\n\r\nphẩm có thể đạt được kết quả tốt, đồng thời chạy ổn định. Chương 5 trình bày về các \r\n\r\ncải tiến hoặc vấn đề mà sinh viên thấy tâm đắc nhất trong quá trình xây dựng đồ án. \r\n\r\n5.1 Cải tiến word embedding \r\n\r\nHiện tại, các hệ thống tóm tắt văn bản bằng Deep Learning thường sử dụng \r\n\r\nWord2Vec, một trong các công cụ sử dụng word embedding phổ biến nhất. Word2vec \r\n\r\nsử dụng một tầng ẩn, các neural ở tầng này đều là các neural tuyến tính. Các neural ở \r\n\r\ntầng đầu vào có số neural tương ứng với số từ trong tập từ điển để huấn luyện. Kích \r\n\r\nthước của tầng đầu ra bằng với kích thước tầng đầu vào.   \r\n\r\nGiả sử ta có tập từ điển để huấn luyện có V từ và N là số chiều của vector từ tương \r\n\r\nứng. Dữ liệu đầu vào đi từ tầng đầu vào đến tầng ẩn thì đi qua một ma trận WI có \r\n\r\nkích thước VxN với mỗi hàng đại diện cho một từ vựng. Tương tự, khi đi từ tầng ẩn \r\n\r\nđến đầu ra, dữ liệu sẽ đi qua một ma trận WO có kích thước NxV. Đầu vào của mạng \r\n\r\nlà một one-hot vector.  \r\n\r\nTrong khóa luận này, sinh viên sử dụng ConceptNet Numberbatch là công cụ chuyển \r\n\r\ntừ sang vector. ConceptNet Numberbatch bao gồm các vector ngữ nghĩa tiên tiến có \r\n\r\nthể được sử dụng trực tiếp như là một biểu diễn ý nghĩa của từ hoặc là điểm xuất phát \r\n\r\nChương 5 Các giải pháp và \r\n\r\nđóng góp nổi bật \r\n\r\n\r\n\r\n \r\n58 \r\n\r\ncho việc học máy tiếp theo. ConceptNet Numberbatch là một phần của dự án dữ liệu \r\n\r\nmở ConceptNet. ConceptNet cung cấp nhiều cách để tính toán với ý nghĩa từ, một \r\n\r\ntrong số đó là từ embeddings. ConceptNet Numberbatch là một bản chụp chỉ những \r\n\r\ntừ nhúng.  \r\n\r\nNó được xây dựng bằng cách sử dụng một tổ hợp kết hợp dữ liệu từ ConceptNet, \r\n\r\nWord2Vec, GloVe, và OpenSubtitles 2016, sử dụng một biến thể cho việc trang bị \r\n\r\nthêm.  \r\n\r\nDữ liệu được xây dựng dựa trên:  \r\n\r\n ConceptNet 5.5 bao gồm dữ liệu từ Wiktionary, WordNet, và nhiều người \r\n\r\nđóng góp cho dự án Open Mind Common Sense, do Rob Speer biên soạn. \r\n\r\n Glove bởi Jeffrey Pennington, Richard Socher và Christopher Manning. \r\n\r\n Word2Vec bởi Tomas Mikolov và nghiên cứu của Google. \r\n\r\n Văn bản song song từ OpenSubtitles 2016 của Pierre Lison và Jrg Tiedemann \r\n\r\nđã phân tích sử dụng fastText của Piotr Bojanowski, Edouard Grave, Armand \r\n\r\nJoulin và Tomas Mikolov. \r\n\r\nDữ liệu đa ngôn ngữ trong ConceptNet Numberbatch thể hiện 78 mã ngôn ngữ khác \r\n\r\nnhau, trong đó có cả tiếng Việt. \r\n\r\n5.2 Xây dựng server với Django \r\n\r\nTrong quá trình xây dựng đồ án, để tối ưu dung lượng cho ứng dụng bên phía người \r\n\r\ndùng, người viết đồ án đã xây dựng server để lưu model và thực hiện công việc tóm \r\n\r\ntắt văn bản. Ứng dụng bên phía client sẽ nhận nhiệm vụ gửi request là đoạn text cần \r\n\r\ntóm tắt và nhận về response là đoạn summary đã được tóm tắt. \r\n\r\nTrong đó, Django là một web framework nổi tiếng được viết hoàn toàn bằng ngôn \r\n\r\nngữ Python. Nó có nhiều ưu điểm như (i) nhanh và linh hoạt, (ii) đầy đủ các thư viện, \r\n\r\nmodule hỗ trợ, (iii) đảm bảo tính bảo mật, và (iv) khả năng mở rộng tốt. \r\n\r\n\r\n\r\n \r\n59 \r\n\r\nBên cạnh việc phát triển web nhanh, Django là một framework hỗ trợ việc phát triển \r\n\r\ncác API nhanh chóng, cấu trúc MVC rất rõ ràng. Django cho phép tạo các URL của \r\n\r\nAPI một cách dễ dàng, đồng thời Django có thể dễ dàng thêm các gói phần mềm để \r\n\r\nkết nối tới các hệ thống, cơ sở dữ liệu khác. \r\n\r\n \r\n\r\n \r\n\r\n\r\nỞ đây, chúng ta xây dựng một app đặt tên là api_textsum, thực hiện chức năng tóm \r\n\r\ntắt văn bản trên server. Kiến trúc của app cũng được thiết kế theo mô hình MVC, \r\n\r\ntrong đó file views.py để tương tác với người dùng. \r\n\r\nTuy nhiên, khả năng web host dường như là chướng ngại lớn nhất khi làm đồ án với \r\n\r\nDjango. Đối với PHP, số lượng host rất nhiều và khá rẻ. Về Django, chúng ta vẫn có \r\n\r\nnhiều sự lựa chọn như Heroku hoặc Pythonanywhere. Vậy nhưng, Heroku vẫn còn \r\n\r\n\r\n\r\n \r\n60 \r\n\r\nthiếu tính ổn định đối với host free, còn Pythonanywhere thì hạn chế về mặt dung \r\n\r\nlượng file được phép tải lên. Để đảm bảo ứng dụng được chạy ổn định, hiện tại hệ \r\n\r\nthống vẫn sử dụng localhost. \r\n\r\n5.3 Xây dựng ứng dụng Android \r\n\r\nTrong quá trình xây dựng ứng dụng Android, một trong những vấn đề sinh viên gặp \r\n\r\nphải đó là phương thức để người dùng chọn một vùng văn bản. Phương thức chọn \r\n\r\nvăn bản cần dễ thực hiện và quen thuộc với người dùng. \r\n\r\nCanvas trong Android đã cung cấp cho chúng ta các phương thức để vẽ tất cả các đối \r\n\r\ntượng hình học cơ bản như điểm, đường hoặc hình đa giác. Chính vì vậy, sinh viên \r\n\r\nđã dùng canvas để tạo một view tuỳ chỉnh theo hình vẽ từ thao tác của người dùng. \r\n\r\nNhững thành phần mà chúng ta vẽ đều sẽ được xử lý trong phương thức \r\n\r\nonDraw(Canvas canvas) của class View. \r\n\r\nTrong Java, Paint dùng để định nghĩa size, color, kiểu nét vẽ mà chúng ta sẽ sử dụng \r\n\r\nđể vẽ bởi canvas. Paint gồm một số phương thức đặc trưng như: \r\n\r\n setColor(int color): cài đặt màu cho nét vẽ. \r\n\r\n setStyle(Style style): cài đặt style cho nét vẽ, có thể chỉ vẽ đường, chỉ tô đối \r\n\r\ntượng hoặc kết hợp cả hai. \r\n\r\n setStrokeWidth(float width): cài đặt giá trị độ rộng cho nét vẽ. \r\n\r\nSau khi đã truyền tham số cho Paint xong, chúng ta vẽ các đối tượng hình học bởi \r\n\r\nphương thức canvas.drawPoint (vẽ điểm), canvas.drawLine (vẽ đường), \r\n\r\ncan","u":"http://202.191.57.85:8000/InternetData/Data/DATN/20130150_Nguyen_Nam_Anh_1527526468353.txt","sentences":[[1,"Hoàng Anh Việt Hà Nội, 06/2018 iii Họ và tên sinh viên : Nguyễn Nam Anh Điện thoại liên lạc: 0978 322 456 Email: namanh11611@gmail.com Lớp: CNTT 2.01 K58 Hệ đào tạo: Chính quy Tôi Nguyễn Nam Anh cam kết Đồ án Tốt nghiệp (ĐATN) là công trình nghiên cứu của bản thân tôi dưới sự hướng dẫn của ThS"],[2,"Hoàng Anh Việt"],[3,"Các kết quả nêu trong ĐATN là trung thực, là thành quả của riêng tôi, không sao chép theo bất kỳ công trình nào khác"],[4,"Tất cả những tham khảo trong ĐATN bao gồm hình ảnh, bảng biểu, số liệu, và các câu từ trích dẫn đều được ghi rõ ràng và đầy đủ nguồn gốc trong danh mục tài liệu tham khảo"],[5,"Tôi xin hoàn toàn chịu trách nhiệm với dù chỉ một sao chép vi phạm quy chế của nhà trường"],[6,"Hà Nội, ngày 28 tháng 5 năm 2018 Tác giả ĐATN Nguyễn Nam Anh Lời cam kết iv Năm tháng trôi đi tựa như một cơn gió lướt qua tuổi thanh xuân"],[7,"Năm năm gắn với Bách Khoa, tuy không dài nhưng cũng không phải là ngắn, khoảng thời gian đó sẽ mãi là ký ức về một thời tuổi trẻ khao khát và dại khờ"],[8,"Không phải ngẫu nhiên mà con đường phía bên kia cổng Parabol được đặt tên là Giải Phóng"],[9,"Trải qua chín kỳ thi và một kỳ đồ án, ai cũng mòn mỏi chờ đợi đến ngày mình trưởng thành, đủ năng lực và bản lĩnh để bước chân qua cánh cổng Parabol"],[10,"Thế nhưng, nếu được chọn lại một lần nữa, chúng tôi vẫn sẽ chọn Bách Khoa"],[11,"Em xin gửi lời cảm ơn chân thành tới các thầy cô trường đại học Bách Khoa Hà Nội nói chung và viện Công nghệ Thông tin và Truyền thông nói riêng, đặc biệt là thầy ThS"],[12,"Hoàng Anh Việt đã tận tình dạy dỗ, truyền đạt cho chúng em những kiến thức bổ ích suốt năm năm đại học"],[13,"Thầy cô không chỉ giảng dạy những bài học về chuyên môn mà còn truyền cho chúng em cả chất Bách Khoa đã được hun đúc qua bao nhiêu thế hệ"],[14,"Cảm ơn những người anh, người em đã luôn ở bên đồng hành cùng tôi trong những khoảnh khắc khó khăn nhất"],[15,"Mỗi người các bạn là một mảnh ghép tạo nên bức tranh về thời sinh viên Bách Khoa gian khó nhưng cũng đầy ắp kỷ niệm của tôi"],[16,"Và cảm ơn em, người tôi từng thương, đã giúp tôi nhận ra phải biết trân trọng những người ở bên cạnh mình đến nhường nào"],[17,"Cuối cùng, con xin được gửi lời cảm ơn chân thành tới gia đình đã luôn ở bên cạnh yêu thương, động viên và tạo mọi điều kiện tốt nhất cho con trong suốt năm năm qua"],[18,"Qua mỗi lần tưởng chừng như gục ngã, bố mẹ và em gái luôn là nguồn động lực lớn nhất để giúp con đứng dậy mạnh mẽ hơn"],[19,"Lời cảm ơn v Trong thời đại công nghệ số, lượng thông tin trên mạng Internet đang tăng trưởng từng giây theo cấp số mũ"],[20,"Trong đó, đa phần nội dung số được biểu diễn dưới dạng các văn bản thuần tuý"],[21,"Để có thể nắm bắt được lượng thông tin lớn nhất trong thời gian nhanh nhất, cần thiết có một phương pháp tóm tắt văn bản chính xác và hiệu quả"],[22,"Bên cạnh đó, để cải tiến phương thức tương tác giữa con người và máy tính, cần thiết có một công cụ để chuyển văn bản thành giọng nói, giúp người dùng dễ dàng tiếp nhận thông tin từ các thiết bị hơn"],[23,"Đã có nhiều giải pháp tóm tắt văn bản được đưa ra, nhưng mỗi phương pháp đều có những nhược điểm chưa khắc phục được về vấn đề xử lý ngữ nghĩa"],[24,"Gần đây, với sự phát triển của công nghệ Machine Learning nói chung và Deep Learning nói riêng, bài toán tóm tắt văn bản đã được giải quyết một cách tối ưu hơn nhiều so với các phương pháp cũ"],[25,"Để giải quyết bài toán, người viết đồ án lựa chọn mô hình sequence to sequence kết hợp với kỹ thuật attention"],[26,"Mô hình được thực hiện dựa trên việc xây dựng mạng neural LSTM một dạng đặc biệt của mạng neural hồi quy"],[27,"Đi kèm với đó là công nghệ text-to-speech trên nền tảng Android đã được phát triển bởi Google để giúp truyền đạt thông tin tới người dùng qua giọng nói thay vì dạng văn bản thông thường"],[28,"Tất cả các công nghệ trên sẽ được tích hợp trên một ứng dụng di động Android hoàn chỉnh"],[29,"Nội dung đồ án sẽ khái quát những kiến thức về phương pháp tóm tắt văn bản bằng công nghệ Deep Learning và công nghệ text-to-speech"],[30,"Cùng với đó là quy trình phát triển ứng dụng trên nền tảng Android với hai chức năng chính áp dụng các công nghệ đã trình bày"],[31,"Tóm tắt vi Mục lục vii viii ix x xi Danh mục hình vẽ xii xiii Danh mục bảng xiv Danh mục công thức xv AI Artificial Intelligence Trí tuệ nhân tạo ML Machine Learning Học Máy DL Deep Learning Học sâu RNN Recurrent Neural Network Mạng nơ-ron hồi quy biRNN Bidirectional RNN Mạng nơ-ron hồi quy 2 chiều LSTM Long Short-Term Memory Mạng bộ nhớ dài-ngắn TTS Text-to-Speech Chuyển văn bản thành giọng nói Danh mục các từ viết tắt xvi Seq2Seq Sequence to Sequence API Application Programming Interface Giao diện lập trình ứng dụng MVC Model View Controller xvii Extractive Text Summarization Phương pháp tóm tắt trích xuất văn bản Abstractive Text Summarization Phương pháp tóm tắt tóm lược văn bản Neural Network Mạng nơ-ron Word Empeddings Kỹ thuật ánh xạ từ với các vec-tơ số thực Attention Kỹ thuật chú ý từ Encoder Bộ mã hoá Decoder Bộ giải mã Danh mục thuật ngữ 1 1.1 Đặt vấn đề Cùng với sự phát triển của Internet, lượng kiến thức và thông tin của nhân loại là vô cùng lớn và gia tăng nhanh chóng theo thời gian"],[32,"Con người bị choáng ngợp trước lượng thông tin vô cùng lớn này"],[33,"Nhu cầu nắm bắt các thông tin chính ngày càng lớn"],[34,"Do đó, tầm quan trọng của việc tóm tắt văn bản ngày càng được nâng cao"],[35,"Việc tóm tắt giúp cho người đọc dễ dàng nắm bắt được thông tin quan trọng một cách nhanh chóng"],[36,"Vậy tóm tắt văn bản là gì"],[37,"Tóm tắt văn bản là quá trình lấy các thông tin quan trọng nhất từ một hoặc nhiều văn bản để tạo ra một văn bản ngắn gọn nhưng vẫn mang đầy đủ các thông tin của phiên bản gốc và đảm bảo tính đúng về ngữ pháp"],[38,"Bản tóm tắt phải chứa những thông tin chính và ý nghĩa tổng thể của văn bản gốc"],[39,"Đồng thời nội dung của bản tóm tắt phải trung thực"],[40,"Độ dài của bản tóm tắt nhỏ độ dài của bản gốc"],[41,"Tóm tắt văn bản tự động là quá trình tóm tắt văn bản bằng phần mềm"],[42,"Tóm tắt văn bản tự động là một thách thức rất lớn, bởi vì khi chúng ta tóm tắt một đoạn văn, chúng ta thường hay đọc nó để hiểu nội dung của nó sau đó ghi những điểm chính của nó"],[43,"Vì máy tính thiếu kiến thức về ngôn ngữ và khả năng ngôn ngữ nên tổng hợp văn bản tự động trở thành một việc không dễ dàng"],[44,"Chính vì thế, đã có nhiều kỹ thuật được sử dụng để trích xuất các nội dung quan trọng từ vản bản để mô tả tóm lược tài liệu"],[45,"Mục đích của tóm tắt văn bản tự động là để tạo ra một văn bản trình bày ngắn hơn văn bản gốc, loại bỏ đi các thông tin không quan trọng và vẫn giữ được những nội dung cốt lõi"],[46,"Qua đó, giúp con người tiết kiệm công sức và thời gian trong việc nắm bắt các thông tin quan trọng"],[47,"Chương 1 Giới thiệu đề tài 2 1.2 Mục tiêu và phạm vi đề tài 1.2.1 Lịch sử nghiên cứu về tóm tắt văn bản Tóm tắt văn bản bắt đầu từ những năm cuối thập kỉ 1950 với nghiên cứu của Luhn (1958) dựa trên tần số từ"],[48,"Ý tưởng cơ bản của phương pháp tần số từ dựa trên kiến thức cho rằng tần số của từng từ trong văn bản là một độ đo hữu dụng để đánh giá tầm quan trọng của chúng"],[49,"Tiếp theo đó là phương pháp tóm tắt dựa trên vị trí của các câu trong văn bản của Baxendale (1958) và những nghiên cứu của Edmundson (1969) về vị trí của các câu trong văn bản và các từ/cụm từ mang ý nghĩa tổng quát"],[50,"Theo đó, những câu bắt đầu và kết thúc của đoạn văn, bài viết hay những câu chứa những từ như important (quan trọng), result are (kết quả là)"],[51,"là những câu có ý nghĩa quan trọng"],[52,"Đầu những năm 1970, tiếp tục có những nghiên cứu với hướng tiếp cận ngoài (sử dụng các cụm từ dấu hiệu) và được ứng dụng trong các phần mềm thương mại"],[53,"Những năm 1980, phát triển nhiều nghiên cứu với nhiều hướng khác nhau, đặc biệt là hướng tiếp cận mức thực thể dựa trên trí tuệ nhân tạo như sử dụng script (Lehnert 1981), các luật sản xuất mạng và logic (Fum 1985), mạng ngữ nghĩa (Reimer và Hahn 1988) cũng như các hướng tiếp cận kết hợp (Rau 1989) hay (Aretoulaki 1994)"],[54,"Willam B"],[55,"Cavnar (1994) biểu diễn văn bản dựa trên n-gram thay cho cách biểu diễn truyền thống bằng từ khoá"],[56,"Jaine Carbonell (1998) đã tóm tắt văn bản bằng cách xếp hạng các câu trội (câu chứa các ý chính của văn bản) và rút ra các câu trội"],[57,"Jade Goldstein (1999) phân loại tóm tắt dựa trên độ đo liên quan, phương pháp sử dụng kết hợp giữa ngữ học, thống kê"],[58,"Một câu được đặc trưng bằng các đặc tính ngữ học và độ đo thống kê"],[59,"3 J.Larocca Neto (2000) đã tạo tóm tắt văn bản dựa trên các dãy từ trong câu được chọn theo hệ số tf, sau đó dùng kỹ thuật gom cụm (clustering) để tạo tóm tắt"],[60,"Yoshio (2001) đã tạo tóm tắt văn bản tiếng Nhật"],[61,"Có 2 phương pháp là rút câu dựa trên từ khoá và rút câu dựa trên kiến trúc ngữ nghĩa trong đó có xây dựng độ đo mối liên kiết giữa hai từ"],[62,"Hiện nay, một số nghiên cứu về xử lý ngôn ngữ tự nhiên cũng bước đầu được áp dụng trong tóm tắt văn bản"],[63,"Mặt khác, các nghiên cứu về tóm tắt đa văn bản, đa ngôn ngữ và tóm tắt đa phương tiện cũng bắt đầu phát triển"],[64,"1.2.2 Phân loại phương pháp tóm tắt văn bản 1.2.2.1 Phương pháp tóm tắt trích xuất Phương pháp tóm tắt trích xuất (Extractive Text Summarization) bao gồm việc lựa chọn đơn vị của văn bản (câu hay đoạn văn), được coi là có chứa lượng thông tin cốt tử của văn bản (informative content, informativity), và kết nối các đơn vị này theo một trình tự thích hợp"],[65,"Một trích xuất là sự lắp ghép các đoạn được trích rút ra từ văn bản nguồn"],[66,"Mục tiêu của trích xuất là cung cấp một cái nhìn tổng quan về nội dung của văn bản gốc"],[67,"Độ dài của văn bản tóm tắt bằng trích xuất có thể được xác định bởi tỉ lệ nén, hay nói cách khác Văn bản tóm tắt ngắn hơn bao nhiêu so với văn bản gốc"],[68,"Thuật toán tóm tắt tự động bằng trích xuất có thể chia ra làm 3 mức: surfacelevel (mức bề mặt), intermediate-level (mức trung bình) và deep parsing techniques (các kĩ thuật phân tích sâu)"],[69,"Tóm tắt trích rút xuất phát từ ý tưởng: Một tài liệu được chia nhỏ thành các đơn vị ngữ pháp (các câu văn), sau đó được đánh trọng số theo kinh nghiệm (heuristic); Các đơn vị ngữ pháp có điểm cao nhất sẽ được trích rút và liên kết với nhau để tạo nên văn bản tóm tắt"],[70,"4 1.2.2.2 Phương pháp tóm tắt tóm lược Tuy tóm tắt bằng trích rút đã thành công trong việc xác định câu nào trong văn bản đầu vào mang nội dung quan trọng nhưng dường như những phương pháp này rất xa với việc tạo ra một bản tóm tắt tối ưu theo nghĩa cả về nội dung và chất lượng trong ngôn ngữ học"],[71,"Trong khi đó, hệ thống tạo ra văn bản tóm tắt bằng phương pháp tóm lược (Abstractive Text Summarization) dựa trên việc hiểu văn bản gốc và đạt tới việc sinh ra một văn bản mới một cách chính xác về ngữ pháp, súc tích và mạch lạc về nội dung, bằng cách sinh ra văn bản tóm tắt bằng những từ vựng không xuất hiện trong văn bản gốc"],[72,"Trong tóm lược, việc diễn giải, viết lại các câu phức tạp sẽ nhằm mục đích tạo ra phiên bản súc tích của nội dung ban đầu"],[73,"Mặc dù con người có thể tái sử dụng một phần văn bản gốc nhưng không phải sử dụng toàn bộ nó, sử dụng các đoạn hay một phần của câu thay vì sử dụng toàn bộ câu"],[74,"Tuy đã có nhiều nghiên cứu trong lĩnh vực tóm tắt văn bản, nhưng việc ứng dụng các kết quả vào thực tế vẫn đang còn hạn chế"],[75,"Như vậy, mục tiêu của đề tài là nghiên cứu về phương pháp tóm tắt văn bản bằng Deep Learning, sau đó áp dụng kết quả vào ứng dụng thực tế, cụ thể là ứng dụng di động trên nền tảng Android"],[76,"1.3 Định hướng giải pháp Hầu hết các phương pháp tóm tắt văn bản hiện nay là trích xuất"],[77,"Mục đích của tóm tắt tự động là tạo ra những văn bản giống với tóm tắt của con người, mà con người thường không tóm tắt theo kiểu trích xuất"],[78,"Thực tế cho thấy, các phương pháp tóm tắt tóm lược gần với cách tóm tắt của con người hơn so với các phương pháp trích xuất"],[79,"Với sự tiến bộ trong lĩnh vực Machine Learning (Học máy) nói chung và Deep Learning (Học sâu) nói riêng, có rất nhiều phương pháp đã chứng minh được tính hiệu quả trong việc giải quyết những bài toán phức tạp mà các cách tiếp cận truyền thống chưa thể giải quyết triệt để được"],[80,"5 Trong phạm vi khóa luận, sinh viên tập trung nghiên cứu các bài toán tóm tắt đơn văn bản, theo phương pháp tóm tắt tóm lược (Abstractive Summarization) sử dụng công nghệ Deep Learning"],[81,"Cụ thể, sinh viên sử dụng mô hình đang phổ biến hiện nay là Sequence to Sequence cùng với kĩ thuật attention"],[82,"Mô hình được xây dựng dựa trên mạng neural LSTM và kỹ thuật word embeddings"],[83,"Về ứng dụng di động, sinh viên xây dựng trên nền tảng Android, vì đây là hệ điều hành chiếm thị phần lớn nhất của thị trường điện thoại di động"],[84,"Như vậy, ứng dụng có thể dễ dàng tiếp cận với lượng lớn người dùng"],[85,"Kết quả tóm tắt văn bản sẽ xử lý trên server được xây dựng bằng Django"],[86,"1.4 Bố cục đồ án Phần còn lại của báo cáo đồ án tốt nghiệp này được tổ chức như sau"],[87,"Chương 2 trình bày tình hình các nghiên cứu về tóm tắt văn bản tự động theo hai hướng tiếp cận chính là đơn văn bản và đa văn bản"],[88,"Trong đó, mỗi phương pháp tóm tắt mô tả tổng quan về cách thực hiện, bộ dữ liệu sử dụng, các kết quả đạt được và độ chính xác"],[89,"Cùng với đó là phân tích tổng quan về yêu cầu của phần mềm"],[90,"Trong Chương 3, sinh viên giới thiệu về các lý thuyết nền tảng của phương pháp tóm tắt văn bản bằng Deep Learning"],[91,"Chúng ta sẽ tìm hiểu về các khái niệm Machine Learning, Deep Learning, mạng neural nhân tạo, mạng RNN, mạng LSTM"],[92,"Sau đó là trình bày về mô hình sequence to sequence, kỹ thuật attention và word embeddings"],[93,"Sau khi đã tìm hiểu về các phương pháp tóm tắt văn bản, cơ sở lý thuyết của tóm tắt văn bản bằng Deep Learning, Chương 4 trình bày quá trình triển khai model tóm tắt văn bản và các kết quả đạt được"],[94,"Nội dung gồm hai phần chính, trong đó phần 4.1 mô tả model được xây dựng dựa trên thư viện TensorFlow, và phần 4.2 mô tả ứng dụng di động Android với chức năng chính là tóm tắt văn bản"],[95,"6 Chương 5 nêu các đóng góp chính của sinh viên trong đồ án"],[96,"Cụ thể, nội dung chương này trình bày về việc cải tiến word embedding, quá trình xây dựng server và ứng dụng di động Android"],[97,"Kết luận và hướng phát triển của đồ án được trình bày trong Chương 6"],[98,"Trong đó, sinh viên tổng kết lại những kết quả đã đạt được và những gì cần cải tiến trong tương lai của đồ án này"],[99,"7 Chương 2 sẽ trình bày tổng quan về các kết quả nghiên cứu liên quan đến tóm tắt văn bản tự động"],[100,"Với mục đích là một đồ án nghiên cứu, chúng ta cần nắm được lịch sử các phương pháp tóm tắt văn bản đã được xây dựng và phát triển"],[101,"Sinh viên sẽ trình bày từ những nghiên cứu về cách trích xuất văn bản cơ bản cho đến các phương pháp tóm lược phức tạp ngày nay áp dụng Deep Learning"],[102,"Nhìn chung, mỗi phương pháp đều có ưu, nhược điểm riêng, tính hiệu quả của nó thể hiện qua các kết quả được đo đạc, đánh giá cụ thể"],[103,"Cùng với đó, nội dung Chương 2 cũng trình bày tóm tắt về các chức năng của ứng dụng Android"],[104,"Trong đó chú trọng về chức năng Tóm tắt văn bản"],[105,"2.1 Khảo sát hiện trạng Tóm tắt văn bản tự động là một bài toán kinh điển trong lĩnh vực xử lý dữ liệu văn bản"],[106,"Hiện nay trên thế giới, nhiều nhà khoa học và các công ty tỏ ra rất quan tâm đến bài toán này"],[107,"Tại các hội nghị nổi tiếng như: DUC 2001 - 2007, TAC 2008 - 2011, ACL 2001-2015, tóm tắt văn bản tự động đã được đề cập đến nhiều trong các bài báo"],[108,"Ngoài ra, có nhiều hệ thống tóm tắt văn bản độc lập hoặc tích hợp được phát triển như: MEAD, LexRank"],[109,"Các kết quả nghiên cứu của tóm tắt văn bản được ứng dụng trong nhiều lĩnh vực như: Tóm tắt tin tức trong lĩnh vực báo chí Chương 2 Khảo sát và phân tích yêu cầu 8 Tóm tắt kết quả tìm kiếm trong các search engine Thu thập dữ liệu thông minh Tóm tắt bài báo khoa học Tóm tắt nội dung cuộc họp, hội nghị Hệ thống trả lời tự động Mặc dù có 2 dạng tóm tắt là tóm tắt trích xuất (Extractive Text Summarization) và tóm tắt tóm lược (Abstractive Text Summarization), tuy nhiên để thực hiện tóm lược cần có một lượng tri thức đầy đủ về lĩnh vực cần tóm tắt"],[110,"Điều này hiện nay vẫn còn hạn chế nhiều, do đó các hướng tiếp cận đa số tập trung vào dạng tóm tắt trích xuất"],[111,"Một trong những cách phân chia của bài toán tóm tắt là: tóm tắt đơn văn bản và tóm tắt đa văn bản"],[112,"Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn ngọn của văn bản đó"],[113,"Ngược lại tóm tắt đa văn bản là từ một văn bản nguồn cũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng thời cho nhiều văn bản khác nhau"],[114,"2.2 Tình hình nghiên cứu hiện nay 2.2.1 Hướng tiếp cận cho tóm tắt đơn văn bản 2.2.1.1 Phương pháp thống kê Hầu hết các nghiên cứu đầu tiên cho tóm tắt đơn văn bản đều tập trung trên những văn bản kỹ thuật (các bài báo khoa học)"],[115,"Các phương pháp cổ điển thường tập trung vào các đặc trưng hình thái để tính điểm cho các câu và trích rút các câu quan trọng để đưa vào tóm tắt"],[116,"Ý tưởng chính của hướng tiếp cận gồm các bước (i) thu thập dữ liệu, (ii) tạo các văn bản tóm tắt thủ công, (iii) thiết kế các công thức toán học hay logic để tính điểm cho các câu, (iv) tính điểm cho từng câu để tạo ra bản tóm tắt cho từng văn bản trong dữ liệu dựa vào các đặc trưng về hình thái, (v) so sánh tóm tắt được tạo tự động với tóm 9 tắt được tạo thủ công, và (vi) cải thiện lại phương thức tính điểm"],[117,"Các bước (iv), (v) và (vi) sẽ được lặp lại cho đến khi tóm tắt tự động đạt được tính tương đương với tóm tắt thủ công"],[118,"Các nghiên cứu đại diện cho phương pháp này gồm: Luhn (1958): dùng phương pháp so khớp từng ký tự để giải quyết stemming; sử dụng các đặc trưng như word frequency, stop words, word distance"],[119,"Baxendale (1958): phương pháp khá chính xác nhưng mang tính chủ quan và đơn giản, được sử dụng khá nhiều vào các hệ thống học máy sau này; sử dụng các đặc trưng như sentence position"],[120,"Thử nghiệm 200 đoạn văn, 85% các câu đầu là câu chính và 7% các câu cuối và câu chính"],[121,"Edmundson (1969): điển hình nhất trong các phương pháp cổ điển; sử dụng phương pháp kết nối tuyến tính để kết hợp các điểm đặc trưng lại với nhau; sử dụng các đặc trưng như: word frequency, stop words, position, cue words, title; đã được thử nghiệm với 400 văn bản kỹ thuật và kết quả đạt 44%"],[122,"2.2.1.2 Phương pháp thống kê trên TF.IDF Phương pháp này còn gọi là mô hình túi từ (bag-of-words), sử dụng mô hình trọng số TF.IDF (term frequency và inverse sentence frequence)"],[123,"Ở mô hình này, giá trị IDF được tính trên câu"],[124,"Trong đó, TF là số lần xuất hiện của term trong 1 câu"],[125,"Và DF là số câu có chứa term"],[126,"Cùng với phương pháp tính độ đo TF.IDF và phương pháp biểu diễn văn bản bằng vector không gian sử dụng Vector Space Model (Saton 1975)"],[127,"Tuy nhiên, phương pháp dùng độ đo TF.IDF không được dùng độc lập, mà thường được kết hợp với các phương pháp khác như máy học, đồ thị"],[128,"để đạt được hiệu quả cao hơn"],[129,"10 2.2.1.3 Phương pháp Nave-Bayes Các hướng tiếp cận theo phương pháp này giả định rằng các đặc trưng của văn bản độc lập nhau"],[130,"Sử dụng bộ phân lớp Nave-Bayes để xác định câu nào thuộc về tóm tắt và ngược lại"],[131,"Tính xác suất các câu thuộc về tóm tắt, n câu có xác suất cao nhất sẽ được trích rút"],[132,"Các nghiên cứu đại điện cho phương pháp này: Kupiec (1995): các đặc trưng sử dụng gồm word frequency, location, cue word, title & leading, sentence length, uppercase words"],[133,"Ngữ liệu: 188 cặp văn bản khoa học và tóm tắt"],[134,"Tổng số câu: 568 câu"],[135,"Số câu khớp trực tiếp với tóm tắt 451 (79%)"],[136,"Aone (1999): kết hợp thêm nhiều đặc trưng phong phú hơn: TF.IDF (single word, two-noun word, named-entities), discourse (cohension) (sử dụng WordNet và kỹ thuật sử lý ngôn ngữ tự nhiên để phân tích sự tham chiếu đối với các thực thể)"],[137,"Ngữ liệu được sử dụng của TREC"],[138,"Hệ thống được xây dựng mang tên DimSum"],[139,"2.2.1.4 Phương pháp Decision Tree Lin & Hovy (1999) đại diện của phương pháp này giả định rằng, các đặc trưng không độc lập với nhau"],[140,"Tác giả đã kiểm tra nhiều đặc trưng và ảnh hưởng của chúng lên quá trình rút trích"],[141,"Hệ thống tóm tắt của Lin là loại tóm tắt hướng về truy vấn (query- based)"],[142,"Các đặc trưng: position (OOP), numeric data, proper name, pronoun & adjective, weekday hoặc month"],[143,"Cùng với 2 đăc trưng mới: query signature (số từ truy vấn có trong câu) và IR signature (những từ nổi bật, quan trọng ~ tf*idf)"],[144,"Hệ thống Summarist của Lin và Hovy sử dụng thuật toán C4.5 để huấn luyện cây quyết định"],[145,"Hệ thống sử dụng tập ngữ liệu của TIPSTER-SUMMAC"],[146,"11 2.2.1.5 Phương pháp Hidden Makov Model Những hướng tiếp cận trước đều dựa trên những đặc trưng và không tuần tự"],[147,"Conroy và Oleary (2001) đã đưa ra hướng tiếp cận dựa trên mô hình HMM với ý tưởng cơ bản là sử dụng một chuỗi tuần tự các câu"],[148,"Tác giả đưa ra khái niệm về sự phụ thuộc cục bộ (local dependencies) giữa các câu và sử dụng mô hình HMM để xác định sự phụ thuộc này"],[149,"Các đặc trưng sử dụng: position, number of term, likelihood of sentence"],[150,"Mô hình HMM bao gồm 2s + 1 trạng thái, trong đó s là số trạng thái tóm tắt (câu thuộc tóm tắt) và s+1 là câu không thuộc tóm tắt"],[151,"Mô hình HMM xây dựng ma trận chuyển vị M, coi các đặc trưng là đa biến và tính xác suất của các câu qua từng trạng thái"],[152,"Sử dụng tập ngữ liệu của TREC và được đánh giá với 2 hệ thống khác là DimSum và QR, kết quả đều cho độ đo Precision cao hơn"],[153,"2.2.1.6 Phương pháp Log-Linear Osborne (2002) đại diện cho mô hình này cũng coi các đặc trưng là không độc lập với nhau và sử dụng mô hình Log-Linear khắc phục giả định này"],[154,"Các đặc trưng sử dụng: word pair, sentence length, sentence position và discourse features (nằm trong introduction, hay conclusion)"],[155,"2.2.1.7 Phương pháp mạng neural DUC 2002 đã đưa ra một baseline rất mạnh cho tóm tắt đơn văn bản bằng phương pháp rút trích n câu đầu tiên của các báo tin tức và dường như kết thúc hướng nghiên cứu này"],[156,"Nhưng Svore (2007) đã đưa ra một hướng tiếp cận mới sử dụng mạng neural để huấn luyện, kết quả cho thấy đã vượt qua baseline của DUC 2002"],[157,"12 Các đặc trưng sử dụng: position, n-grams frequency"],[158,"Ngoài ra, còn sử dụng thêm nhật ký truy vấn của bộ máy tìm kiếm Microsoft và WordNet"],[159,"Tác giả cho rằng, những câu có chứa từ khoá trong các các câu truy vấn thì sẽ có kết quả tốt hơn, và tìm từ khoá đó trên WordNet"],[160,"Mô hình được huấn luyện từ các đặc trưng và các nhãn trong các bài báo"],[161,"Sau đó được xếp hạng bằng hệ thống RankNet"],[162,"Ngữ liệu được lấy từ CNN.com và được đánh giá bằng độ đo ROUGE-1 và ROUGE-2 (hai độ đo phổ biến hiện tại cho tóm tắt văn bản)"],[163,"2.2.1.8 Phương pháp phân tích ngôn ngữ tự nhiên Phương pháp tiếp theo sử dụng các kỹ thuật phân tích ngôn ngữ tự nhiên phức tạp"],[164,"Không phải tất cả các phương pháp phân tích ngôn ngữ tự nhiên đều sử dụng máy học, đôi khi phương pháp chỉ sử dụng một số các heuristic để tạo trích rút"],[165,"Hầu hết các phương pháp này đều dựa trên cấu trúc diễn ngôn (discourse tructure) hay cấu trúc diễn đạt (thể hiện) của văn bản, như: cấu trúc các section của văn bản, liên kết ngữ pháp (trùng lặp, tĩnh lược, liên hợp), liên kết từ vựng (đồng nghĩa, bao hàm, lặp lại), cấu trúc chính phụ"],[166,"Các nghiên cứu đại điện cho phương pháp này: Ono (1994) xây dựng một thủ tục để rút trích các cấu trúc chính phụ (rhetorical structure) từ các văn bản tiếng Nhật, và xây dựng một cây nhị phân để thể hiện"],[167,"Các bước để trích rút cấu trúc: phân tích câu, trích rút một quan hệ chính phụ, phân đoạn, tạo ứng viên và đánh giá độ ưu tiên"],[168,"Sau khi xây dựng cây sẽ thực hiện tỉa nhánh để giảm bớt câu và tạo tóm tắt"],[169,"Kết quả đạt được 51% các câu chính được xác định, và 74% các câu quan trọng nhất được xác định"],[170,"Barzilay và Elhadad (1997): hai tác giả cũng đã sử dụng một lượng đáng kể những phân tích ngôn ngữ trong tóm tắt văn bản dựa trên chuỗi từ vựng (lexical chain)"],[171,"Chuỗi từ vựng là chuỗi các từ liên quan trong văn bản"],[172,"Các bước thực hiện: phân đoạn văn bản, xác định các chuỗi từ vựng và sử dụng 13 các chuỗi từ vựng tốt nhất để xác định câu được chèn vào tóm tắt"],[173,"Để tìm các chuỗi từ vựng, tác giả sử dụng WordNet"],[174,"Các từ có liên quan với nhau sẽ được đưa vào chuỗi"],[175,"Sự liên quan được tính bằng khoảng cách trong WordNet"],[176,"Chuỗi sẽ được tính điểm dựa vào chiều dài và sự đồng nhất của nó"],[177,"Kết quả đạt được tốt hơn hệ thống tóm tắt của Microsoft"],[178,"Với độ precious là 61 và độ recall 67 (Microsoft là 33 và 27)"],[179,"Hạn chế: không thể kiểm được chiều dài và mức độ chi tiết của tóm tắt do số chuỗi còn ít"],[180,"Tóm tắt thiếu sự kết dính và chưa chi tiết do chọn cả câu"],[181,"Marcu (1998): sử dụng các heuristic dựa trên cấu trúc diễn đạt với các đặc trưng truyền thống"],[182,"Lý thuyết về cấu trúc diễn đạt được tác giả thể hiện thông qua lý thuyết cấu trúc chính phụ (Rhetorical Structure Theory)"],[183,"Lý thuyết cho rằng hai khoảng văn bản không trùng lặp có quan hệ trung tâm (nucleus) và vệ tinh (satellite)"],[184,"Trong đó trung tâm quan trọng hơn vệ tinh và độc lập hoàn toàn trong cấu trúc chính phụ"],[185,"Cấu trúc trọng tâm và vệ tinh được biểu diễn thành cây nhị phân"],[186,"Để tính điểm cho các cấu trúc, tác giả sử dụng nhiều độ đo khác nhau như: clustering based metric, marker based metric, rhetorical clustering based technique, shape based metric, title based metric, position based metric, connectedness based metric và sử dụng phương pháp kết hợp tuyến tính"],[187,"Lấy ra n câu chứa cấu trúc có điểm cao nhất"],[188,"Hệ thống đat được kết quả độ đo F 75.42% cao hơn 3.5% so với baseline bằng phương pháp lấy n câu đầu"],[189,"Ngữ liệu được sử dụng là từ TREC"],[190,"2.2.2 Hướng tiếp cận cho tóm tắt đa văn bản Các vấn đề phát sinh trong tóm tắt đa văn bản là tính trùng lặp và bổ sung thông tin trong các nguồn văn bản"],[191,"Do đó, nhiệm vụ trong tóm tắt đa văn bản không chỉ bao gồm việc sao chép dữ liệu từ những văn bản gốc sang bản tóm tắt mà còn đảm bảo tính mới, không dư thừa của thông tin, cũng như đảm bảo tóm tắt có tính kết dính và hoàn chỉnh"],[192,"14 2.2.2.1 Phương pháp dùng template McKeown và Radev (1995, 1998) đã xây dựng hệ thống SUMMONS dựa trên hướng tiếp cận dùng template cho tóm tắt đa văn bản"],[193,"Hệ thống đọc trong CSDL các tập mẫu được xây dựng sẵn bởi một hệ thống khác"],[194,"Trước tiên, hệ thống sẽ điền vào các chỗ trống trong template các thông tin từ các văn bản nguồn"],[195,"Sau dó, hệ thống tổng hợp thành một bản tóm tắt và cho ra kết quả"],[196,"Hệ thống SUMMONS bao gồm 2 thành phần chính: content planner (lập nội dung) và linguistic generator (tạo ngôn ngữ)"],[197,"Tuy nhiên, hệ thống chỉ có thể phục vụ cho một miền dữ liệu nhỏ"],[198,"2.2.2.2 Phương pháp gom cụm chủ đề và hợp nhất thông tin McKeown (1999) đã cải tiến hệ thống SUMMONS cũng như Barzilay (1999) bằng một hướng tiếp cận dựa trên gom cụm và hợp nhất thông tin"],[199,"Hướng tiếp cận mới bao gồm 2 giai đoạn: Gom cụm các đơn vị văn bản (clustering): các đơn vị văn bản được biểu diễn bằng vector với các đặc trưng như TF-IDF, noun-phrase, proper noun, synset (tập đồng nghĩa từ Wordnet)"],[200,"Từng cặp đơn vị văn bản sẽ được tính độ tương đồng với nhau để phân loại cho các các cụm theo từng chủ đề (themes)"],[201,"Hợp nhất thông tin: sau khi phân cụm, các cụm sẽ được so sánh với nhau bằng một giải thuật để tìm sự trùng lặp thông tin"],[202,"Sau cùng hệ thống trích rút câu nổi bật trong từng cụm để làm tóm tắt, nếu trùng lặp thì câu xuất hiện ở văn bản mới hơn sẽ được trích rút"],[203,"Giải thuật để tìm sự trùng lặp là sử dụng bộ phân tích thống kê của Collin (1999) xây dựng cây phụ thuộc (dependency tree)"],[204,"15 2.2.2.3 Phương pháp gom cụm (cluster-based) với MMR Các văn bản thường được viết để giải quyết nhiều chủ đề khác nhau, mỗi chủ đề sẽ được viết sau chủ đề khác theo một cách có tổ chức"],[205,"Mỗi chủ đề cũng có thể được viết vào những phần riêng biệt hoặc không"],[206,"Các chủ đề này cũng cần được viết vào tóm tắt theo thứ tự như trong văn bản"],[207,"Vấn đề đặt ra là làm thế nào xác định được các cụm chủ đề của văn bản"],[208,"Phương pháp gom cụm là nhằm phân loại các câu vào các cụm theo từng chủ đề mà chúng nói đến"],[209,"Có nhiều phương pháp gom cụm khác nhau"],[210,"Một trong số đó là phương pháp MMR (Maximal Marginal Relevance) của Carbonell và Jade Goldstein (1998)"],[211,"Mô hình MMR đã được áp dụng cho Text Summarization bởi Ganapathiraju (2002)"],[212,"Hệ thống tóm tắt với MMR bao gồm các chức năng (i) phân đoạn văn bản thành các câu, (ii) phân cụm các câu, và (iii) tính điểm MMR cho các câu để chọn câu thích hợp được đưa vào tóm tắt"],[213,"Tập dữ liệu huấn luyện được lấy từ DUC 2002"],[214,"2.2.2.4 Phương pháp gom cụm với lý thuyết đồ thị Vấn đề chủ yếu của tóm tắt đa văn bản là gom cụm các câu để tránh sự dư thừa trong tóm tắt"],[215,"Một hướng tiếp cận mới là ứng dụng lý thuyết đồ thị"],[216,"Sau khi đã tiền xử lý văn bản như: loại bỏ stopword, xử lý dẫn suất (stemming), các câu được thể hiện thành các node trong một đồ thị vô hướng"],[217,"Mỗi câu một node"],[218,"Hai câu có những từ chung sẽ được nối một cạnh"],[219,"Hoặc sử dụng độ đo cosin, tính độ tương đồng giữa 2 câu, nếu lớn hơn một ngưỡng Q thì sẽ có một cạnh nối giữa 2 node"],[220,"Sau khi biểu diễn thành đồ thị, đồ thị sẽ được phân hoạch thành các đồ thị con dựa vào các cạnh nối"],[221,"Nếu tóm tắt cần tạo là tóm tắt dựa vào truy vấn, thì đồ thị nào gần với truy vấn nhất sẽ được dùng để tạo tóm tắt"],[222,"Nếu tóm tắt là chung, thì tất cả các đồ thị con đều tham gia vào tóm tắt"],[223,"16 Để tạo tóm tắt, mỗi đồ thị con sẽ đưa ra các node (câu) ứng viên cao nhất (các node có nhiều cạnh nối nhất) để include vào truy vấn"],[224,"2.2.2.5 Phương pháp kích hoạt lan truyền trên đồ thị Mani và Bloedorn (1997) đã đề xuất một framework cho tóm tắt văn bản dựa trên đồ thị để tìm sự tương đồng hoặc không tương đồng giữa các cặp văn bản"],[225,"Phương pháp này không tạo ra văn bản tóm tắt nhưng highlight thông tin trên văn bản gốc"],[226,"Văn bản được thể hiện thành đồ thị như sau: mỗi node biểu diễn sự xuất hiện của một từ đơn trong văn bản, mỗi node có nhiều loại liên kết với các node khác như: SAME, ALPHA, PHRASE, NAME, COREF"],[227,"Sau khi tạo đồ thị, các node chủ đề sẽ được xác định bằng phương pháp phân tích dẫn xuất (stemming) và trở thành entry node"],[228,"Các node sẽ được đánh trọng số bằng phương pháp TF*IDF"],[229,"Một sự tìm kiếm văn bản liên quan ngữ nghĩa giữa các node sẽ được lan truyền"],[230,"Trọng số của các node sẽ được thay đổi trong quá trình lan truyền"],[231,"Các cặp đồ thị (các văn bản) sẽ được so sánh với nhau để tìm những node chung dựa vào dẫn xuất cũng như đồng ngữ nghĩa"],[232,"Điểm của các node chung cũng sẽ được tính lại"],[233,"Quá trình lan truyền lại tiếp tục cho đến khi không còn cập nhật trọng số điểm cho các node"],[234,"Sau cùng những câu chứa các node có điểm chung và riêng cao sẽ được đánh dấu"],[235,"2.2.2.6 Phương pháp dựa trên trọng tâm Radev (2004) đã đề xuất phương pháp sử dụng các trọng tâm của cụm đề làm trung tâm cho tóm tắt"],[236,"Hướng tiếp cận này đã được phát triển trong hệ thống MEAD"],[237,"Các văn bản trong hướng tiếp cận này sử dụng mô hình túi từ"],[238,"Bao gồm 2 giai đoạn: Giai đoạn xác định chủ đề: Các văn bản được biểu diễn dưới vector và một thuật toán gom cụm tích tụ (an agglomerative clustering) được sử dụng để thực 17 hiện nhiệm vụ này"],[239,"Văn bản liên quan nhất với trọng tâm cluster sẽ được thêm vào, và cluster sẽ được tính lại trọng tâm"],[240,"Giai đoạn chọn câu: Trong mỗi cluster, chọn các câu là trung tâm của chủ đề trong cụm"],[241,"Hai độ đo tương tự MMR là cluster-based relative utility (CBRU) and cross-sentence informational subsumption (CSIS) được sử dụng để độ liên quan của câu với chủ đề của cụm và độ dư thừa giữa các câu"],[242,"Tuy nhiên, hai độ đo này không phụ thuộc truy vấn như MMR"],[243,"Để tính độ tương đồng, mỗi câu được biểu diễn bởi các đặc trưng: centroid value, positional value, first- sentence overlap"],[244,"2.3 Phân tích yêu cầu phần mềm 2.3.1 Biểu đồ use case tổng quan 18 Phần mềm có một tác nhân chính là Người dùng, người có thể tương tác với phần mềm"],[245,"Ban đầu, người dùng có thể chọn toàn bộ văn bản xuất hiện trên màn hình hoặc chỉ chọn một phần văn bản mà mình muốn"],[246,"Phần văn bản đã chọn sẽ được đọc bằng text-to-speech"],[247,"Trong trường hợp chọn một phần văn bản, người dùng có thể tuỳ chọn tóm tắt phần văn bản mà mình đã chọn"],[248,"Kết quả tóm tắt sẽ được xử lý trên server và hiển thị trên màn hình"],[249,"2.3.2 Đặc tả chức năng 2.3.2.1 Đặc tả use case TTS toàn bộ văn bản Mã use case UC001 Tên use case TTS toàn bộ văn bản Tác nhân Người dùng Tiền điều kiện Người dùng đã mở giao diện tương tác Luồng sự kiện chính (Thành công) STT Tác nhân Hành động 1 Người dùng Chọn chức năng TTS toàn bộ văn bản 2 Hệ thống Lấy dữ liệu toàn bộ văn bản đang hiển thị trên màn hình, thực hiện TTS Luồng sự kiện thay thế STT Tác nhân Hành động 2a Hệ thống Hệ thống thông báo không có văn bản Hậu điều kiện Không 19 2.3.2.2 Đặc tả use case TTS văn bản được chọn Mã use case UC002 Tên use case TTS văn bản được chọn Tác nhân Người dùng Tiền điều kiện Người dùng đã mở giao diện tương tác Luồng sự kiện chính (Thành công) STT Tác nhân Hành động 1 Người dùng Chọn chức năng TTS văn bản được chọn 2 Người dùng Vẽ trên màn hình để chọn văn bản 3 Hệ thống Lấy dữ liệu văn bản trong vùng được chọn trên màn hình, thực hiện TTS Luồng sự kiện thay thế STT Tác nhân Hành động 3a Hệ thống Hệ thống thông báo không có văn bản nào được chọn Hậu điều kiện Không 20 2.3.2.3 Đặc tả use case Tóm tắt văn bản Mã use case UC003 Tên use case Tóm tắt văn bản Tác nhân Người dùng Tiền điều kiện Người dùng đã chọn một vùng văn bản Luồng sự kiện chính (Thành công) STT Tác nhân Hành động 1 Người dùng Chọn chức năng Tóm tắt văn bản 2 Hệ thống Thực hiện tóm tắt văn bản và trả về kết quả hiển thị trên màn hình 3 Người dùng Xác nhận kết quả trả về Luồng sự kiện thay thế STT Tác nhân Hành động 2a Hệ thống Hệ thống thông báo không có văn bản được chọn 2b Hệ thống Hệ thống thông báo không có kết nối Internet Hậu điều kiện Không 21 STT Trường dữ liệu Mô tả Bắt buộc Điều kiện hợp lệ Ví dụ 1 Văn bản Nội dung văn bản cần tóm tắt Có Dạng text Hello World STT Trường dữ liệu Mô tả Bắt buộc Điều kiện hợp lệ Ví dụ 1 Văn bản Nội dung văn bản đã được tóm tắt Có Dạng text Hello World 2.3.3 Yêu cầu phi chức năng Về hiệu năng, hệ thống phải đảm bảo hoạt động liên tục 24/24, giúp người dùng có thể tương tác bất cứ lúc nào"],[250,"Hệ thống cũng phải đảm bảo tính dễ dùng, giúp người dùng nhận biết được hệ thống đã lấy được dữ liệu hay chưa, thao tác thành công hay không"],[251,"Như vậy, Chương 2 cho chúng ta cái nhìn tổng quan về các phương pháp tóm tắt văn bản cũng như ưu, nhược điểm của chúng"],[252,"Có thể nhận thấy rằng, tóm tắt văn bản bằng Deep Learning đang là phương pháp tiên tiến nhất hiện nay"],[253,"Để tìm hiểu về 22 phương pháp này, Chương 3 sẽ trình bày về các lý thuyết nền tảng mà chúng ta cần nắm rõ"],[254,"Ngoài ra, chúng ta cũng đã làm rõ những yêu cầu tổng quan cũng như đặc tả các use case của phần mềm"],[255,"Đây là tiền đề để sinh viên xây dựng ứng dụng di động Android"],[256,"23 Trải qua nhiều tiến bộ của khoa học máy tính, Deep Learning đang nổi lên như là một công nghệ tiên tiến giúp con người giải quyết nhiều bài toán phức tạp với độ chính xác cao"],[257,"Theo như những gì đã trình bày ở Chương 2, Deep Learning cũng đã được ứng dụng trong bài toán tóm tắt văn bản và đạt được những kết quả khả quan"],[258,"Chương này sẽ đi sâu vào trình bày các khái niệm liên quan đến công nghệ tóm tắt văn bản bằng Deep Learning"],[259,"3.1 Công nghệ Deep Learning 3.1.1 Machine Learning Chương 3 Cơ sở lý thuyết 24 Những năm gần đây, AI - Artificial Intelligence (Trí Tuệ Nhân Tạo), và cụ thể hơn là Machine Learning (Học Máy) nổi lên như một bằng chứng của cuộc cách mạng công nghiệp lần thứ tư"],[260,"Trí Tuệ Nhân Tạo đang len lỏi vào mọi lĩnh vực trong đời sống mà có thể chúng ta không nhận ra"],[261,"Xe tự hành của Google và Tesla, hệ thống tự tag khuôn mặt trong ảnh của Facebook, trợ lý ảo Siri của Apple, hệ thống gợi ý sản phẩm của Amazon, hệ thống gợi ý phim của Netflix, máy chơi cờ vây AlphaGo của Google DeepMind"],[262,"chỉ là một vài trong vô vàn những ứng dụng của AI/Machine Learning"],[263,"Machine Learning là một tập con của AI"],[264,"Nói đơn giản, Machine Learning là một lĩnh vực nhỏ của Khoa Học Máy Tính, nó có khả năng tự học hỏi dựa trên dữ liệu đưa vào mà không cần phải được lập trình cụ thể"],[265,"Những năm gần đây, khi mà khả năng tính toán của các máy tính được nâng lên một tầm cao mới và lượng dữ liệu khổng lồ được thu thập bởi các hãng công nghệ lớn, Machine Learning đã tiến thêm một bước dài và một lĩnh vực mới được ra đời gọi là Deep Learning"],[266,"Deep Learning đã giúp máy tính thực thi những việc tưởng chừng như không thể vào 10 năm trước: phân loại cả ngàn vật thể khác nhau trong các bức ảnh, tự tạo chú thích cho ảnh, bắt chước giọng nói và chữ viết của con người, giao tiếp với con người, hay thậm chí cả sáng tác văn hay âm nhạc"],[267,"Ngược dòng lịch sử, Machine Learning đã xuất hiện từ rất lâu trước khi mạng Internet ra đời"],[268,"Một trong những thuật toán Machine Learning đầu tiên là thuật toán Perceptron được phát minh ra bởi Frank Rosenblatt vào năm 1957"],[269,"Đây là một thuật toán kinh điển dùng để phân loại hai khái niệm"],[270,"Một ví dụ đơn giản là phân loại thư rác và thư bình thường"],[271,"Perceptron là một thuật toán supervised learning: ta đưa cho máy tính hàng loạt các ví dụ cùng câu trả lời mẫu với hy vọng máy tính sẽ tìm được những đặc điểm cần thiết để đưa ra dự đoán cho những ví dụ khác chưa có câu trả lời trong tương lai"],[272,"Ngoài ra, cũng có những thuật toán Machine Learning không cần câu trả lời mẫu, được gọi là unsupervised learning"],[273,"Trong trường hợp này, máy tính cố gắng khai thác ra cấu trúc ẩn của một tập dữ liệu mà không cần câu trả lời mẫu"],[274,"Một loại Machine Learning khác được gọi là reinforcement learning"],[275,"Trong dạng này, 25 cũng không hề có câu trả lời mẫu, nhưng thay vì đó máy tính nhận được phản hồi cho mỗi hành động"],[276,"Dựa vào phản hồi tích cực hay tiêu cực mà máy tính sẽ điều chỉnh hoạt động cho phù hợp"],[277,"3.1.2 Deep Learning Nếu coi ta Machine Learning là công nghệ tiên tiến nhất, thì Deep Learning là \"tiên tiến của tiên tiến\""],[278,"Machine Learning lấy một vài ý tưởng cốt lõi của trí tuệ nhân tạo và tập trung vào việc giải quyết các vấn đề thế giới thực với các mạng thần kinh được thiết kế để bắt chước khả năng đưa ra quyết định của chúng ta"],[279,"Deep Learning, đúng như tên gọi của nó, đi sâu hơn nữa vào một tập hợp các công cụ và kỹ thuật học máy, từ đó áp dụng chúng để giải quyết bất kỳ vấn đề nào đòi hỏi \"khả năng tư duy\" con người hay nhân tạo"],[280,"Về cơ bản, Deep Learning là cho một hệ thống máy tính \"ăn\" rất nhiều dữ liệu, để chúng có thể sử dụng và đưa ra các quyết định về những dữ liệu khác"],[281,"Dữ liệu này được nạp thông qua các mạng thần kinh, tương tự như học máy"],[282,"Những mạng lưới này các cấu trúc logic yêu cầu một loạt các câu hỏi đúng/sai, hoặc trích xuất một giá trị số, của mỗi bit dữ liệu đi qua chúng và phân loại theo các câu trả lời nhận được"],[283,"Vì công việc của Deep Learning là tập trung phát triển những mạng lưới này, chúng đã trở thành \"mạng thần kinh sâu\" (Deep Neural Network) những mạng logic phức tạp cần thiết để xử lý các bộ dữ liệu lớn, như thư viện hình ảnh của Google hay Instagram"],[284,"Với các bộ dữ liệu toàn diện như vậy, và các mạng logic phức tạp để xử lý phân loại chúng, việc một chiếc máy tính lấy một hình ảnh và nhận dạng với độ chính xác cao trở nên \"quá đỗi bình thường\""],[285,"Các hình ảnh là ví dụ tuyệt vời nhất về cách thức hoạt động của Deep Learning, vì chúng có chứa nhiều yếu tố khác nhau và để hiểu rõ được làm thế nào để máy tính, với não bộ một chiều chủ yếu dựa trên sự tính toán, có thể học cách giải thích chúng giống như con người"],[286,"Tuy vậy, Deep Learning có thể được áp dụng cho bất kỳ hình 26 thức dữ liệu nào âm thanh, video, lời nói, chữ viết.."],[287,"để đưa ra những kết luận như thể do con người thực hiện với tốc độ rất nhanh"],[288,"Chúng ta hãy thử xem xét một số ví dụ thực tiễn"],[289,"Giả sử một hệ thống được thiết kế để tự động ghi nhận và báo cáo có bao nhiêu chiếc xe của một mẫu xe nhất định đã đi ngang qua một con đường"],[290,"Trước tiên, nó sẽ được quyền truy cập vào một cơ sở dữ liệu khổng lồ về các loại xe, bao gồm hình dáng, kích thước và thậm chí là tiếng của động cơ"],[291,"Điều này có thể được biên soạn theo cách thủ công hoặc, trong các điều kiện tiên tiến hơn, được thu thập tự động bởi hệ thống nếu như nó được lập trình để tìm kiếm trên internet và lấy dữ liệu mà nó tìm thấy ở đó"],[292,"Tiếp theo, nó sẽ lấy dữ liệu cần được xử lý dữ liệu trong thế giới thực có chứa thông tin chi tiết cần nắm bắt, trong trường hợp này là bởi các camera và microphone bên đường"],[293,"Bằng cách so sánh dữ liệu từ cảm biến với những dữ liệu mà nó đã \"học được\", nó có thể phân loại, với một độ chính xác nhất định, từng loại xe đã đi qua con đường đó"],[294,"Trên đây là một ví dụ cụ thể, ngoài ra Deep Learning còn có thể ứng dụng ở trong rất nhiều các lĩnh vực khác như: Cung cấp khả năng điều hướng cho xe tự lái: Với hệ thống cảm biến và phần mềm phân tích trên buồng lái, các xe tự lái có thể học cách nhận dạng những chướng ngại vật có trên đường và có giải pháp xử lý thích hợp bằng cách sử dụng Deep Learning"],[295,"Phục chế màu cho ảnh đen trắng: thông qua việc dạy cho máy tính cách nhận biết các vật thể và cách mà mắt người nhìn chúng, các hình ảnh và video đen trắng sẽ có thể được tái hiện lại với đầy đủ các màu sắc phù hợp"],[296,"Dự đoán kết quả của các thủ tục pháp lý: Một nhóm các nhà nghiên cứu người Anh và Mỹ đã có thể dự đoán chính xác kết quả của một phiên tòa, sau khi hệ thống máy tính của họ được nạp sẵn những thông tin cơ bản của vụ án"],[297,"Thuốc đặc trị: Các kỹ thuật Deep Learning hiện đang được dùng để phát triển các loại thuốc đã được chỉnh sửa sao cho phù hợp với bộ gen của bệnh nhân"],[298,"27 Phân tích và báo cáo tự động: Các hệ thống có thể phân tích dữ liệu và báo cáo những thông tin chi tiết của chúng dưới dạng âm thanh tự nhiên hoặc ngôn ngữ của con người"],[299,"Chơi trò chơi: Các hệ thống Deep Learning đã và đang được dạy cách chơi (và giành chiến thắng) các trò chơi như cờ vây, Breakout của Atari hay Starcraft"],[300,"3.2 Neural Network 3.2.1 Mạng neural nhân tạo Mạng neural nhân tạo (Artificial Neurol Network - ANN) là mạng các neural kết nối với nhau"],[301,"Mỗi neural là một mô hình tính toán và NN là một hệ thống tính toán"],[302,"Đầu ra của mỗi neural lại là đầu vào của một neural khác"],[303,"Kiến trúc của mạng được quyết định bởi sự kết nối của các neural trong mạng"],[304,"Một trong những yếu tố chính của mạng neural là khả năng học hỏi"],[305,"Mạng neural không chỉ là một hệ thống phức tạp, mà còn là một hệ thống thích nghi phức tạp, có nghĩa là nó có thể thay đổi cấu trúc nội bộ của nó trong quá trình huấn luyện"],[306,"Thông thường, việc huấn luyện là việc thay đổi các trọng số"],[307,"Hai kiến trúc mạng phổ biến: Mạng truyền thẳng (feed-forward network) 28 Mạng phản hồi (feed-back network hay recurrent neural network) Thuật toán được sử dụng phổ biến để huấn luyện mạng neural là thuật toán lan truyền ngược (backpropagation algorithm)"],[308,"Thuật toán này sẽ sử dụng tập giá trị đầu ra và tập giá trị mong muốn để tìm ra các trọng số của mạng làm cực tiểu hàm lỗi"],[309,"Sai số của mạng trên một bộ dữ liệu huấn luyện được tính tổng bình phương của độ sai lệch giữa các đầu ra của mạng và các giá trị mong muốn"],[310,"Hàm lỗi tổng bình phương trên toàn tập dữ liệu sẽ được tính bằng tổng hàm lỗi trên mỗi bộ dữ liệu của tập dữ liệu"],[311,"Ta cần tìm trọng số của mạng sao cho hàm tổng bình phương lỗi đạt giá trị nhỏ nhất"],[312,"Backpropagation được xây dựng dựa trên thuật toán lặp là kĩ thuật gradient descent"],[313,"Theo kĩ thuật này, vector trọng số của lần lặp này sẽ được điều chỉnh dựa vào vector trọng số ở lần lặp trước, tỷ lệ học (learning rate) và vector gradient (vector các đạo hàm riêng) của hàm lỗi tại đó"],[314,"Theo đó, đạo hàm riêng của một tầng được tính dựa vào tầng trước đó theo hướng đầu ra ngược về đầu vào"],[315,"Đạo hàm riêng của hàm lỗi trên toàn tập dữ liệu bằng tổng đạo hàm riêng của hàm lỗi trên từng bộ dữ liệu của toàn tập dữ liệu"],[316,"Đạo hàm riêng của hàm lỗi theo trọng số của đường truyền từ neural i tới neural j bằng tích của của sai số tại neural j với đầu ra tại i, trong đó sai số ở neural j là đạo hàm riêng của của hàm lỗi theo tổng trọng số của neural j"],[317,"Sai số ở neural j lại được tính dựa trên sự sai khác của đầu ra tại neural này và giá trị đầu ra mong muốn"],[318,"Tóm lại, thuật toán lan truyền ngược gồm giai đoạn: giai đoạn đầu các thông tin được truyền theo thẳng qua mạng để tìm tổng trọng số đầu vào và đầu ra, giai đoạn tiếp theo các sai sẽ được tính và truyền ngược lại"],[319,"29 3.2.2 Mạng RNN Mô hình mạng neural hồi quy (Recurrent Neural Networks) được sử dụng phổ biến trong các bài toán xử lí ngôn ngữ tự nhiên, mô hình hóa được bản chất của của ngôn ngữ tự nhiên"],[320,"Dữ liệu trong NLP có sự phụ thuộc lẫn nhau giữa các thành phần trong dữ liệu và chúng thường ở dạng chuỗi"],[321,"RNN thường được sử dụng cho các bài toán NLP vì chúng là mô hình mạng sử dụng đầu vào là thông tin dạng chuỗi"],[322,"Một số mạng neural truyền thống được giả định rằng các đầu vào độc lập với nhau, các mô hình không phù hợp với nhiều bài toán"],[323,"Ví dụ với bào toán dự đoán từ, ta phải biết được các từ trước đó thì mới có thể dự đoán được từ tiếp theo"],[324,"Mạng RNN có khả năng nhớ các thông tin trước đó dựa vào việc thực hiện cùng một tác vụ tính toán cho mỗi phần tử của chuỗi đầu vào"],[325,"Trên lí thuyết, RNN có thể nhớ tất cả các thông tin trước đó, có khả năng sử dụng một đoạn văn bản rất dài"],[326,"Tuy nhiên, mạng chỉ có thể nhớ được trong vài bước tính toán ban đầu, thông tin được tính toán trước đó dần mất trong quá trình truyền"],[327,"Một mạng neural được duỗi ra giống như một chuỗi tuần tự"],[328,"Ví dụ đầu vào là một chuỗi gồm năm từ, mạng sẽ duỗi ra với năm tầng mạng, mỗi tầng cho một từ"],[329,"Mỗi tầng thể hiện mạng tại một thời điểm gọi là bước thời gian (time-step)"],[330,"Mạng RNN khi được duỗi ra thường có mô hình dạng sau: 30 Việc tính toán bên trong RNN sẽ được thực hiện như sau: t là đầu vào tại bước thời gian thứ t"],[331,"Ví dụ 1 là one-hot vector biểu diễn từ thứ hai trong câu"],[332,"t là trạng thái ẩn tại bước thời gian thứ t"],[333,"Nó được coi là bộ nhớ của mạng"],[334,"t được tính dựa trên các trạng thái ẩn trước đó và đầu vào hiện tại theo công thức: = ( + 1)"],[335,"Hàm f thường là hàm sigmoid hoặc ReLU"],[336,"Để tính trạng thái ẩn cho mạng ở phần tử đầu tiên, ta cần khởi tạo một giá trị -1"],[337,"-1 thường được khởi tạo là -1"],[338,"t là đầu ra tại bước thời gian thứ t"],[339,"Thông thường được tính theo hàm softmax"],[340,"Ví dụ, ta muốn dự đoán một từ có xuất hiện không thì t là vector xác suất trong tập từ điển của ta: = ( )"],[341,"Trạng thái ẩn như là bộ nhớ của mạng"],[342,"Thu thập thông tin về những gì đã xảy ra trong tất cả các bước thời gian trước đó"],[343,"Đầu ra ở bước được tính toán chỉ dựa trên bộ nhớ vào thời gian"],[344,"Tuy nhiên, mạng không thể nhớ được nhiều thông tin"],[345,"Thông tin đồng thời bị mất dần qua các bước thời gian"],[346,"Không giống như mạng thần kinh sâu truyền thống, sử dụng các tham số khác nhau ở mỗi lớp, một RNN chia sẻ các tham số giống nhau qua tất cả các bước"],[347,"Tức là, ta đang thực hiện cùng một công việc ở từng bước, chỉ với các đầu vào khác nhau"],[348,"Điều này làm giảm tổng số các tham số chúng ta cần phải học"],[349,"Sơ đồ trên có đầu ra ở mỗi bước thời gian, nhưng tùy thuộc vào các bài toán khác nhau mà đầu ra này có thể không cần thiết"],[350,"Ví dụ, khi dự đoán tình cảm của một câu chúng ta chỉ có thể quan tâm đến kết quả cuối cùng chứ không phải tình cảm sau mỗi từ"],[351,"Tương tự như vậy, chúng ta có thể không cần đầu vào ở từng thời điểm"],[352,"Các tính năng chính của một RNN là trạng thái ẩn của nó, trong đó nắm bắt một số thông tin về một chuỗi"],[353,"Huấn luyện mạng RNN tương tự như mạng neural thông thường"],[354,"Mạng vẫn sử dụng thuật toán lan truyền ngược nhưng có chút thay đổi"],[355,"Đạo hàm tại mỗi đầu ra sẽ được 31 tính dựa trên tất cả cả bước thời gian vì tham số được sử dụng chung cho toàn mạng"],[356,"Đạo hàm tại đầu ra được tính bằng tổng của các bước trước đó"],[357,"Giải thuật này còn được gọi là lan truyền ngược liên hồi (Backpropagation Through Time BPTT)"],[358,"Qua nhiều năm nghiên cứu và phát triển, một số loại mạng RNN được sinh ra để khác phục các nhược điểm của RNN truyền thống"],[359,"Một số mô hình tiêu biểu: RNN hai chiều (Bidirectional RNNs) dựa trên ý tưởng rằng tại mỗi bước thời gian, trạng thái ẩn không chỉ phụ thuộc vào các yếu tố trước đó trong chuỗi, mà còn các yếu tố trong tương lai"],[360,"Ví dụ: để dự đoán một từ bị thiếu trong một chuỗi ta phải biết cả ngữ cảnh trái và phải"],[361,"RNN hai chiều khá đơn giản"],[362,"Họ chỉ là hai RNN xếp chồng lên nhau"],[363,"Đầu ra sau đó được tính dựa trên trạng thái ẩn của cả hai RNN"],[364,"Đầu vào của của mạng tại timestep thứ i bao gồm cả trạng thái ẩn tại bước thời gian thứ i 1 cùng RNN và trạng thái ẩn của bước thời gian thứ i + 1 của RNN chồng lên nó"],[365,"Nhờ đó, tại mỗi bước thời gian sẽ nhớ được thông tin toàn mạng"],[366,"RNN sâu (Deep (Bidirectional) RNN) tương tự như mạng RNN hai chiều, nhưng tại mỗi bước thời gian thay vì có một trạng thái ẩn thì mạng lại có nhiều trạng thái ẩn"],[367,"Nhờ có nhiều trạng thái ẩn mà khả năng học của mạng cũng cao hơn"],[368,"32 LSTM (Long short term memory networks) có kiến trúc giống với RNN thông thường"],[369,"Nhưng chúng sử dụng nhiều hàm tính toán khác ở trạng thái ẩn"],[370,"Điểm nổi bật của mạng là nó khắc phục được các vấn đề phụ thuộc xa (long-term dependency problem) của RNN"],[371,"3.2.3 Mạng LSTM Mạng bộ nhớ dài-ngắn (Long Short Term Memory networks), thường được gọi là LSTM - là một dạng đặc biệt của RNN, nó có khả năng học được các phụ thuộc xa"],[372,"LSTM được giới thiệu bởi Hochreiter & Schmidhuber (1997), và sau đó đã được cải tiến và phổ biến bởi rất nhiều người trong ngành"],[373,"Chúng hoạt động cực kì hiệu quả trên nhiều bài toán khác nhau nên dần đã trở nên phổ biến như hiện nay"],[374,"LSTM được thiết kế để tránh được vấn đề phụ thuộc xa (long-term dependency)"],[375,"Việc nhớ thông tin trong suốt thời gian dài là đặc tính mặc định của chúng, chứ ta không cần phải huấn luyện nó để có thể nhớ được"],[376,"Tức là ngay nội tại của nó đã có thể ghi nhớ được mà không cần bất kì can thiệp nào"],[377,"33 Mọi mạng hồi quy đều có dạng là một chuỗi các mô-đun lặp đi lặp lại của mạng neural"],[378,"Với mạng RNN chuẩn, các mô-dun này có cấu trúc rất đơn giản, thường là một tầng tanh"],[379,"LSTM cũng có kiến trúc dạng chuỗi như vậy, nhưng các mô-đun trong nó có cấu trúc khác với mạng RNN chuẩn"],[380,"Thay vì chỉ có một tầng mạng neural, chúng có tới 4 tầng tương tác với nhau một cách rất đặc biệt"],[381,"Ở sơ đồ trên, mỗi một đường mang một véc-tơ từ đầu ra của một nút tới đầu vào của một nút khác"],[382,"Các hình trong màu hồng biểu diễn các phép toán như phép cộng véc- tơ chẳng hạn, còn các ô màu vàng được sử dụng để học trong các từng mạng neural"],[383,"Các đường hợp nhau kí hiệu việc kết hợp, còn các đường rẽ nhánh ám chỉ nội dung của nó được sao chép và chuyển tới các nơi khác nhau"],[384,"34 3.3 Mô hình tóm tắt văn bản 3.3.1 Mô hình Sequence to Sequence Mô hình sequence to sequence hay encoder-decoder (seq2seq) là mô hình sinh ra để giải quyết các bài toán sinh chuỗi đầu ra từ câu đầu vào cho trước"],[385,"Mô hình seq2seq gồm một bộ mã hóa (encoder) và một bộ giải mã (decoder)"],[386,"Mô hình mã hóa một dãy có độ dài biến đổi thành một biểu diễn vector chiều dài cố định và để giải mã một sự biểu diễn cố định trở lại thành một dãy có độ dài biến đổi"],[387,"Từ góc độ xác suất, mô hình mới này là một phương pháp tổng quát để tìm hiểu sự phân bố có điều kiện đối với một dãy có độ dài thay đổi theo một dãy có độ dài thay đổi khác"],[388,"Bộ mã hóa là một RNN đọc mỗi từ của một chuỗi đầu vào x tuần tự"],[389,"Khi nó đọc từng từ, trạng thái ẩn của RNN thay đổi"],[390,"Sau khi đọc kết thúc chuỗi (được đánh dấu bởi một ký hiệu cuối của chuỗi), trạng thái ẩn của một RNN là một vector cố định c được tổng hợp từ chuỗi đầu vào"],[391,"C được dùng như ngữ cảnh cho bộ gải mã"],[392,"Nhờ có vector ngữ cảnh bộ giải mã có thể xác định đầu ra chính xác hơn"],[393,"Ví dụ với một mô hình dự đoán từ, khi gặp từ hạ ta sẽ không thể biết đó là từ chỉ mùa trong năm hay là động từ mang nghĩa hạ xuống, nhưng nếu có một ngữ cảnh cụ thể thì bộ giải mã của ta có thể xác định được từ đó có nghĩa là gì"],[394,"Bộ giải mã của mô hình được đề xuất là một RNN khác được huấn luyện để tạo chuỗi đầu ra bằng cách dự đoán từ tiếp theo với trạng thái ẩn"],[395,"Tuy nhiên, không giống như RNN thông thường, cả và cùng bị điều khiển bởi 1 và vector ngữ cảnh c của dãy đầu vào"],[396,"Do đó, trạng thái ẩn của bộ giải mã tại thời điểm t được tính như sau: = (1, 1, ) Công thức 1 Trạng thái ẩn của bộ giải mã tại thời điểm t 35 Tương tự, xác xuất phân bố của từ tiếp theo là: (| 1, 2,"],[397,", , ) = ( , 1, ) Công thức 2 Xác suất phân bố từ tiếp theo Trong đó, f, g là các hàm tính xác suất (thường là hàm softmax) Ví dụ: = (1,"],[398,", | 1,"],[399,", ), trong đó độ dài các chuỗi đầu vào và đầu ra T, T có thể khác nhau"],[400,"Bộ mã hóa và giải mã được huấn luyện đồng thời và kiểm tra hàm mất mát ở bộ giải mã"],[401,"Khi bộ RNN Encoder-Decoder được đào tạo, mô hình có thể được sử dụng theo hai cách"],[402,"Một cách là sử dụng mô hình để tạo một chuỗi đích từ chuỗi đầu vào"],[403,"Mặt khác, mô hình có thể được sử dụng để tính điểm cho cặp chuỗi đầu vào và chuỗi đầu ra theo xác suất ( ), là tập tham số của mô hình"],[404,"3.3.2 Kỹ thuật Attention Khi sử dụng mô hình seq2seq ta thấy có các vấn đề: Mô hình yêu cầu phải sử dụng toàn bộ thông tin chuỗi đầu để bộ mã hóa tạo ra vectơ c dù cho chuỗi đầu vào dài hay ngắn"],[405,"Việc này không hợp lí vì trong một số trường hợp nhất định ta chỉ cần thông tin của một thành phần của chuỗi"],[406,"Ví dụ như việc dịch một từ thì ta chỉ cần quan tâm tới ngữ cảnh của các từ xung quanh nó trong câu"],[407,"Yêu cầu bộ giải mã phải trích xuất được thông tin từ vector vì tất cả các đầu ra của bộ giải mã đều sử dụng chung một vector ngữ cảnh c"],[408,"Vector ngữ cảnh c phải chứa đầy đủ thông tin cho bộ giải mã"],[409,"36 Trong thực tế, con người chúng ta tiếp nhận rất nhiều thông tin"],[410,"Nhưng chỉ những thông tin quan trọng và cần thiết được sử dụng để đưa ra quyết định nào đó"],[411,"Kĩ thuật attention dựa trên ý tưởng này để giải quyết các vấn đề của mô hình seq2seq"],[412,"Kĩ thuật này được được đề xuất lần đầu tiên bởi Bahdanau và cộng sự vào năm 2014 lấy cảm hứng từ mô hình visual attention trong ngành công nghiệp computer vision"],[413,"Với kĩ thuật này, thay vì mã hóa toàn bộ chuỗi đầu vào thành một vector ngữ cảnh duy nhất bằng một dãy vector"],[414,"Dãy vector này được tính trung bình và là đầu vào của các thành phần trong bộ giải mã"],[415,"Bộ mã hóa, giải mã và cơ chế attention được huấn luyện đồng thời cùng nhau (join training)"],[416,"Chuỗi đầu vào được mã hóa bằng RNN hai chiều (bidirectional RNN) và sinh ra một chuỗi các vector"],[417,"Tại mỗi thời điểm, bộ giải mã sẽ chọn một thành phần trong chuỗi vector để tập trung vào và sinh ra một vector ngữ cảnh để sinh ra đầu ra tại thời điểm đó"],[418,"3.3.3 Word vector Word vector là vector có trọng số, số chiều nhất định và được sử dụng để biểu diễn một từ"],[419,"Đầu vào khi sử dụng học sâu cho NLP là vector chứa giá trị số"],[420,"Tùy theo cách chọn đơn vị đầu vào mà có các cách biểu diễn khác nhau"],[421,"Đơn vị đầu vào thường được chia làm hai loại: ký tự (character) và từ (token)"],[422,"Biểu diễn dưới dạng ký tự (character) là một cách biểu diễn đơn giản vì số lượng kí tự không lớn, có giới hạn"],[423,"Do đó, số chiều của vector biểu diễn cũng nhỏ, không sợ các vấn đề về lưu trữ và xử lí"],[424,"Giữa các kí tự không có mối quan hệ về ngữ nghĩa, nên hai kí tự khác nhau thì chỉ cần hai vector khác nhau là có thể biểu diễn được"],[425,"Khi cần biểu diễn một kí tự chúng ta có thể biểu diễn bằng một one-hot vector"],[426,"Số chiều của one-hot vector phụ thuộc vào số lượng phần tử có trong tập hợp mà chúng ta cần biểu diễn"],[427,"Ví dụ chúng ta cần biểu diễn cho 102 kí tự trên bàn phím thì chúng ta cần vector 102 chiều"],[428,"37 Tuy nhiên, chúng ta có thể sử dụng nhiều cách để biểu diễn một từ (token)"],[429,"Sử dụng một số nguyên để biểu diễn: cách này đơn giản nhưng không hiệu quả vì nó không biểu diễn được mối quan giữa các từ và đầu vào là một vector"],[430,"Sử dụng one-hot vector: Giống với cách biểu diễn kí tự, ta coi mỗi token là một phần tử và một triệu từ được coi là một triệu phần tử trong tập hợp"],[431,"Khi đó, mỗi từ sẽ đc biểu diễn bằng một vector một triệu chiều"],[432,"Do đó, khi phải lưu một triệu phần tử thì chúng ta cần phải sử dụng một ma trận 1.000.000x1000.000 để biểu diễn"],[433,"Điều này dẫn đến những vẫn đề về lưu trữ và xử lí"],[434,"Mặt khác, việc dùng one-hot vector cũng không thể biểu diễn được mối quan hệ giữa các từ"],[435,"Sử dụng các vector random: khắc phục được nhược điểm về số chiều của vector"],[436,"Mỗi từ được coi là một điểm trong không gian với số chiều nhất định"],[437,"Tuy nhiên, cách này vẫn không biểu diễn được mối quan hệ giữa các từ"],[438,"Sử dụng word embeddings: Đây được xem là cách biểu diễn hiệu quả nhất với số chiều biểu diễn một từ thấp và biểu diễn được mối quan hệ giữa các từ với nhau"],[439,"3.3.4 Word Empeddings Word embeddings là một trong những phương diện nghiên cứu thú vị nhất của phương pháp Deep Learning trong xử lý ngôn ngữ tự nhiên"],[440,"Một word embeddings là một hàm ánh xạ từ thành các vector nhiều chiều (200 đến 500 chiều)"],[441,"Ví dụ như: W(cat) = (0.2, -0.4, 0.7, .) W(mat) = (0.0, 0.6, -0.1, .) Thường thì hàm W sẽ là một bảng tra cứu, lưu trữ dưới dạng một ma trận , với () ="],[442,"W khởi tạo một vector random cho mỗi từ, vector này được thay đổi sao cho nó biểu diễn được mối quan hệ với những từ khác liên quan"],[443,"38 Các vector có tính chất (i) số lượng chiều không lớn (200 đến 500 chiều, nhỏ so với tập từ vựng), (ii) các từ có nghĩa gần nhau sẽ gần nhau trong không gian, và (iii) mối quan hệ tương đồng ngữ nghĩa sẽ được chuyển thành mối quan hệ giống nhau giữa các vector"],[444,"Ví dụ việc huấn luyện mạng phát hiện ra cụm 5-gram (chuỗi 5 từ) có hợp lệ hay không"],[445,"Hàm W ánh xạ mỗi từ tới một vector, các vector này được đưa vào một hàm khác là R"],[446,"R sẽ xác định cụm năm từ đó có hợp lệ hay không"],[447,"R(W(cat), W(sat), W(on), W(the), W(mat)) = 1 R(W(cat), W(sat), W(song), W(the), W(mat)) = 0 Bằng cách đổi từ có cùng lớp nghĩa, chúng ta sẽ sinh ra được các câu không hợp lệ và các câu có cùng lớp nghĩa (the wall is blue the wall is red)"],[448,"Hơn thế, chúng ta có thể thay đổi nhiều từ"],[449,"Bằng cách này chúng ta sẽ dịch được vector các từ nghĩa gần nhau tới gần nhau hơn và mối liên hệ giữa các từ cũng dần được mã hóa"],[450,"Ví dụ về sự khác biệt giữa man và woman: W(man) W(woman) W(uncle) W(aunt) W(man) W(woman) W(king) W(queen) 39 Những mối quan hệ phức tạp hơn cũng được mã hóa theo cách này"],[451,"Trong đồ án, sinh viên sử dụng word empedding là ConceptNet Numberbatch, nội dung sẽ được trình bày chi tiết trong phần 5.1"],[452,"3.4 Text-to-Speech Trên máy tính, Text-to-Speech (TTS) là việc tạo ra giọng nói của người từ đầu vào là văn bản hay các mã hóa việc phát âm"],[453,"Tuy rằng không phải hệ thống text-to-speech nào cũng có đầu vào là văn bản (nhiều hệ thống thu nhận mã hóa cách phát âm, ví dụ mã IPA)"],[454,"Hệ thống thực hiện việc này còn gọi là máy tổng hợp giọng nói (text-to- speech engine), có thể là hệ thống phần mềm hoặc phần cứng"],[455,"Các hệ thống TTS có nhiều ứng dụng"],[456,"Ví dụ như có thể giúp người có thị lực kém (hoặc khiếm thị) nghe được máy đọc ra văn bản, đặc biệt là các văn bản có thể xử lý trên máy tính"],[457,"Hệ thống có thể lắp đặt trong phần mềm xử lý văn bản hay trình duyệt mạng"],[458,"Hai tính chất quan trọng của chất lượng hệ thống tổng hợp giọng nói là mức độ tự nhiên và mức độ dễ nghe"],[459,"Mức độ tự nhiên của giọng nói tổng hợp chính là sự giống nhau giữa giọng tổng hợp và giọng nói tự nhiên của người thật"],[460,"Mức độ dễ nghe chỉ 40 đến việc câu phát âm có thể hiểu được dễ dàng không"],[461,"Một hệ thống TTS lý tưởng cần vừa tự nhiên vừa dễ nghe, và mục tiêu xây dựng hệ thống TTS là làm tăng tối đa hai tính chất này"],[462,"Một số hệ thống TTS có thể thiên về mức độ dễ nghe hơn, hoặc mức độ tự nhiên hơn; tùy thuộc vào mục đích mà công nghệ được lựa chọn"],[463,"Có hai công nghệ chính được dùng là tổng hợp ghép nối và tổng hợp cộng hưởng tần số; ngoài ra cũng có một số công nghệ khác"],[464,"Tổng hợp ghép nối dựa trên việc nối vào nhau các đoạn của một giọng nói đã được ghi âm"],[465,"Thông thường, tổng hợp ghép nối tạo ra giọng nói tương đối tự nhiên"],[466,"Tuy nhiên, giọng nói tự nhiên được ghi âm có sự thay đổi từ lần phát âm này sang lần phát âm khác, và công nghệ tự động hóa việc ghép nối các đoạn của sóng âm thỉnh thoảng tạo ra những tiếng cọ xát không tự nhiên ở phần ghép nối"],[467,"Tổng hợp cộng hưởng tần số không sử dụng bất cứ mẫu giọng thật nào khi chạy"],[468,"Thay vào đó, tín hiệu âm thanh cho ra dựa trên một mô hình âm thanh"],[469,"Các thông số như tần số cơ bản, sự phát âm, và mức độ tiếng ồn được thay đổi theo thời gian để tạo ra dạng sóng cho giọng nói nhân tạo"],[470,"Phương pháp này đôi khi còn được gọi là tổng hợp dựa trên quy tắc, dù cho nhiều hệ thống ghép nối mẫu âm thanh thật cũng có dùng các thành phần dựa trên quy tắc"],[471,"Nhiều hệ thống dựa trên tổng hợp cộng hưởng tần số tạo ra giọng nói nhân tạo, như giọng robot"],[472,"Giọng nói nhân tạo thường không tự nhiên, và có thể phân biệt rõ ràng với giọng người thật"],[473,"Tuy nhiên độ tự nhiên cao không phải lúc nào cũng là mục đích của hệ thống và hệ thống này cũng có các ưu điểm riêng của nó"],[474,"Hệ thống tổng hợp giọng nói nhân tạo nói khá dễ nghe, ngay cả ở tốc độ cao, không có tiếng cọ xát do ghép âm tạo ra"],[475,"Các hệ thống này hoạt động ở tốc độ cao, có thể hướng dẫn người khiếm thị nhanh chóng dò dẫm trên máy tính, bằng cách đọc to những gì hiện ra trên màn hình"],[476,"Các hệ thống này cũng nhỏ gọn hơn các hệ thống ghép nối âm, vì không phải chứa cơ sở dữ liệu mẫu âm thanh lớn"],[477,"Nó có thể dùng trong các hệ thống nhúng khi bộ nhớ và tốc độ xử lý có hạn"],[478,"Hệ thống này cũng có khả năng điều khiển mọi khía cạnh của tín hiệu âm thanh đi ra, nó cho ra một dải rộng 41 các lời văn và ngữ điệu, và không chỉ thể hiện được câu nói thường hay câu hỏi, mà cả các trạng thái tình cảm thông qua âm điệu của giọng nói"],[479,"3.5 Android Android là một hệ điều hành dựa trên nền tảng Linux được thiết kế dành cho các thiết bị di động có màn hình cảm ứng như điện thoại thông minh và máy tính bảng"],[480,"Ban đầu, Android được phát triển bởi Tổng công ty Android, với sự hỗ trợ tài chính từ Google và sau này được chính Google mua lại vào năm 2005"],[481,"Android ra mắt vào năm 2007 cùng với tuyên bố thành lập Liên minh thiết bị cầm tay mở: một hiệp hội gồm các công ty phần cứng, phần mềm, và viễn thông với mục tiêu đẩy mạnh các tiêu chuẩn mở cho các thiết bị di động"],[482,"Chiếc điện thoại đầu tiên chạy Android được bán vào năm 2008"],[483,"Android có mã nguồn mở và Google phát hành mã nguồn theo Giấy phép Apache"],[484,"Chính mã nguồn mở cùng với một giấy phép không có nhiều ràng buộc đã cho phép các nhà phát triển thiết bị, mạng di động và các lập trình viên nhiệt huyết được điều chỉnh và phân phối Android một cách tự do"],[485,"Ngoài ra, Android còn có một cộng đồng lập trình viên đông đảo chuyên viết các ứng dụng để mở rộng chức năng của thiết bị, bằng một loại ngôn ngữ lập trình Java có sửa đổi"],[486,"Vào tháng 10 năm 2012, có khoảng 700.000 ứng dụng trên Android, và số lượt tải ứng dụng từ Google Play, cửa hàng ứng dụng chính của Android, ước tính khoảng 25 tỷ lượt"],[487,"Android chiếm 87,7% thị phần điện thoại thông minh trên toàn thế giới vào thời điểm quý 2 năm 2017, với tổng cộng 2 tỷ thiết bị đã được kích hoạt và 1,3 triệu lượt kích hoạt mỗi ngày"],[488,"Sự thành công của hệ điều hành cũng khiến nó trở thành mục tiêu trong các vụ kiện liên quan đến bằng phát minh, góp mặt trong cái gọi là \"cuộc chiến điện thoại thông minh\" giữa các công ty công nghệ"],[489,"Các ứng dụng cho Android được phát triển bằng ngôn ngữ Java sử dụng Bộ phát triển phần mềm Android (SDK)"],[490,"SDK bao gồm một bộ đầy đủ các công cụ dùng để phát triển, gồm có công cụ gỡ lỗi, thư viện phần mềm, bộ giả lập điện thoại dựa trên 42 QEMU, tài liệu hướng dẫn, mã nguồn mẫu, và hướng dẫn từng bước"],[491,"Môi trường phát triển tích hợp (IDE) được hỗ trợ chính thức là Eclipse sử dụng phần bổ sung Android Development Tools (ADT)"],[492,"Các công cụ phát triển khác cũng có sẵn, gồm có Bộ phát triển gốcdành cho các ứng dụng hoặc phần mở rộng viết bằng C hoặc C++, Google App Inventor, một môi trường đồ họa cho những nhà lập trình mới bắt đầu, và nhiều nền tảng ứng dụng web di động đa nền tảng phong phú"],[493,"Android có một hạt nhân dựa trên nhân Linux phiên bản 2.6, kể từ Android 4.0 Ice Cream Sandwich trở về sau, là phiên bản 3.x, với middleware, thư viện và API viết bằng C, còn phần mềm ứng dụng chạy trên một nền tảng ứng dụng gồm các thư viện tương thích với Java dựa trên Apache Harmony"],[494,"Android sử dụng máy ảo Dalvik với một trình biên dịch động để chạy 'mã dex' (Dalvik Executable) của Dalvik, thường được biên dịch sang Java bytecode"],[495,"Nền tảng phần cứng chính của Android là kiến trúc ARM"],[496,"Người ta cũng hỗ trợ x86 thông qua dự án Android x86, và Google TV cũng sử dụng một phiên bản x86 đặc biệt của Android"],[497,"Tổng kết lại, Chương 3 đã trình bày về các kiến thức cơ bản của phương pháp tóm tắt văn bản bằng Deep Learning và kiến thức liên quan đến nền tảng Android cũng như công nghệ Text-to-Speech"],[498,"Trong chương tiếp theo, người viết đồ án sẽ mô tả quy trình xây dựng và phát triển sản phẩm"],[499,"43 Yếu tố quan trọng nhất trong phương pháp tóm tắt văn bản bằng Deep Learning là xây dựng thành công model đã được huấn luyện với một tập dữ liệu tốt"],[500,"Chương 4 sẽ trình bày quy trình xây dựng và huấn luyện model, cùng với đó là trình bày về ứng dụng di động Android tích hợp chức năng tóm tắt văn bản và công nghệ text-to- speech"],[501,"4.1 Mô hình tóm tắt văn bản 4.1.1 Tiền xử lý dữ liệu Tập dữ liệu được sử dụng bao gồm các review về thức ăn trên Amazon được thu thập từ tháng 10/1999 đến tháng 10/2012"],[502,"Có tổng cộng 568.454 bản review về 74.258 sản phẩm được đánh giá từ 256.059 người dùng"],[503,"Mỗi bản review bao gồm thông tin về sản phẩm, người dùng, xếp hạng, tiêu đề và nội dung đánh giá"],[504,"Tuy nhiên, trong phạm vi đồ án này, chúng ta chỉ chú ý đến hai trường dữ liệu là tiêu đề (summary) và nội dung đánh giá (text)"],[505,"Trước tiên, dữ liệu được xử lý theo các bước (i) chuyển chữ viết hoa thành chữ thường, (ii) thay thế các cụm từ viết tắt về dạng chuẩn của nó (ví dụ như cant thành cannot), (iii) xoá bỏ các ký tự không cần thiết, và (iv) xoá bỏ stop words để tiết kiệm bộ nhớ và tăng tốc độ xử lý (stop words là các từ trong tiếng Anh có nghĩa không ảnh hưởng đến nội dung tóm tắt văn bản, ví dụ như mạo từ the)"],[506,"Chương 4 Phát triển và triển khai ứng dụng 44 Chúng ta sẽ sử dụng ConceptNet Numberbatch (CN) như đã được giới thiệu"],[507,"Trong đó, mỗi token từ sẽ được chuyển sang thành vector 300 chiều"],[508,"Với các từ không có trong CN mà có tần suất xuất hiện lớn hơn 20 lần, chúng ta sẽ tạo một vector 300 chiều với các giá trị ngẫu nhiên trong khoảng [-1, 1], sau đó thêm nó vào word empeddings"],[509,"Ngoài ra, token <UNK> dùng để đánh dấu các từ chưa biết, token <EOS> dùng để đánh dấu kết thúc câu"],[510,"Để huấn luyện model nhanh hơn, các đoạn review sẽ được sắp xếp theo độ dài từ nhỏ đến lớn"],[511,"Các review có nhiều hơn 1 token <UNK> sẽ bị loại bỏ để đảm bảo model được huấn luyện với tập dữ liệu tốt"],[512,"4.1.2 Kiến trúc Encoder-Decoder Để xây dựng mô hình seq2seq, kiến trúc Encoder-Decoder với mạng RNN là một phương thức tiếp cận hiệu quả và tiêu chuẩn, gồm 2 phần chính là bộ mã hoá (encoder) và bộ giải mã (decoder)"],[513,"Mỗi từ đầu vào sẽ được đánh số theo hai từ điển là vocab_to_int và int_to_vocab để tương ứng với một số nguyên, giúp cho việc truy xuất dữ liệu nhanh hơn"],[514,"Sau đó, từ được đưa vào word_embedding_matrix, mỗi từ được biểu diễn dưới dạng vector 300 chiều"],[515,"Vector đi lần lượt qua các lớp ẩn, kết hợp với lớp ẩn sinh ra từ token trước đó"],[516,"Sau khi nhận layer ẩn cuối cùng, bộ giải mã kết hợp với token <EOS> để làm đầu vào"],[517,"Sử dụng lớp softmax và kĩ thuật attention, bộ giải mã sẽ sinh lần lượt từng từ cho output"],[518,"Quá trình dừng lại khi sinh đến kí tự <EOS>"],[519,"45 Trong quá trình xử lý dữ liệu, những từ không nằm trong CN hoặc có tần suất xuất hiện dưới 20 lần sẽ bị gán nhãn <UNK> sẽ bị loại bỏ sẽ gây mất mát thông tin"],[520,"Thường những từ này là tên riêng"],[521,"Tuy nhiên tỷ lệ rất nhỏ, chỉ chiếm 0.7%, nên sẽ không ảnh hưởng nhiều đến kết quả tóm tắt văn bản, vậy nên chúng ta có thể bỏ qua"],[522,"Chúng ta sử dụng mạng LSTM với 2 lớp ẩn"],[523,"Mỗi lớp ẩn có kích thước là 256 units"],[524,"Các trọng số trong mô hình được khởi tạo giá trị trong khoảng [-0.1;0.1]"],[525,"Learning rate là 0.005"],[526,"4.1.3 Kỹ thuật attention Kĩ thuật attention là một cơ chế giúp giải quyết hạn chế của kiến trúc Encoder- Decoder trên các chuỗi dài, cụ thể nó sẽ tăng tốc độ học và nâng cao kỹ năng của mô hình trong việc dự đoán từ tiếp theo"],[527,"Nó giúp cho mạng neural có thể chú ý hơn vào những nội dung quan trọng"],[528,"Chuỗi đầu vào 1: được mã hoá bằng mạng RNN 2 chiều, sinh ra n vector 1:"],[529,"1: = (1:) = (1:) Công thức 3 Mã hoá chuỗi đầu vào bằng biRNN Tại mỗi bước , decoder sẽ chọn ra những phần nào trong 1: để tập trung vào, sinh ra vector ngữ cảnh để dùng cho bước dự đoán thứ"],[530,"(+1 = |1: , 1:) = ((+1)) +1 = ( , [; ]) = (1:, 1:) ~ (|1:1, 1:) Công thức 4 Sinh vector ngữ cảnh 46 4.2 Ứng dụng di động Android 4.2.1 Thiết kế kiến trúc Tổng quan, ứng dụng được thiết kế theo mô hình Client - Server"],[531,"Các thiết bị đóng vai trò máy khách gửi yêu cầu (request) tới máy chủ, máy chủ xử lý và gửi phản hồi (response) trở lại cho máy khách"],[532,"Cả phía Client và Server đều được xây dựng theo mô hình MVC"],[533,"MVC là viết tắt của Model View Controller, trong đó Model chứa các đối tượng mô tả dữ liệu, View đảm nhận việc hiển thị thông tin, tương tác người dùng, còn Controller giữ nhiệm vụ nhận điều hướng các yêu cầu từ người dùng và gọi những phương thức xử lý chúng"],[534,"Đối với ứng dụng phía client, phần View là các Activity và View hiển thị đối với người dùng, phần Controller xử lý các thao tác, điều khiển các luồng sự kiện, còn Model lưu trữ thông tin đối tượng của hệ thống"],[535,"47 Thiết kế tổng quan: Tổng quan, phần mềm được chia thành 4 package lớn là Service, Controller, View và Model"],[536,"Trong đó, nhiệm vụ của mỗi package được phân tách rõ ràng"],[537,"Gói Service là gói chính của ứng dụng, giúp người dùng thực hiện các tác vụ ngay cả khi không mở ứng dụng"],[538,"Gói Controller điều khiển các luồng, thực hiện các hành động chính của ứng dụng khi người dùng thao tác"],[539,"Gói View để người dùng có thể vẽ custom view khi chọn vùng văn bản, gồm 2 class là DrawLayout.java và CustomView.java"],[540,"Gói Model chứa các lớp lưu trữ dữ liệu"],[541,"48 4.2.2 Thiết kế giao diện Giao diện chương trình: Khi ở giao diện chính, chúng ta có thể chọn toàn bộ các văn bản xuất hiện trên màn hình hoặc chọn một vùng văn bản"],[542,"Nội dung văn bản đã được chọn sẽ được đọc bằng công cụ text-to-speech"],[543,"Nếu chọn một vùng văn bản, layout được chuyển qua giao diện tóm tắt văn bản"],[544,"49 Ở giao diện này, người dùng có thể chọn chức năng tóm tắt"],[545,"Dữ liệu sẽ được gửi tới server, sau đó trả về kết quả là một đoạn văn bản đã được tóm tắt hiển thị trên Dialog"],[546,"4.3 Xây dựng ứng dụng 4.3.1 Thư viện và công cụ sử dụng Các công cụ, ngôn ngữ lập trình, API, thư viện, IDE được sử dụng để phát triển ứng dụng"],[547,"Mục đích Công cụ Địa chỉ URL Ngôn ngữ lập trình Python 3.6 64-bit https://www.python.org/ IDE lập trình PyCharm 2017.3.4 https://www.jetbrains.com/pycharm/ IDE lập trình Android Studio 2.3.3 https://developer.android.com/studio/ Thư viện Deep Learning TensorFlow 1.7.0 https://www.tensorflow.org/ Framework Django 2.0.4 https://www.djangoproject.com/ 4.3.2 Kết quả đạt được Để đánh giá kết quả của model tóm tắt văn bản, người viết đồ án lựa chọn phương pháp Rouge làm thước đo"],[548,"Recall Oriented Understudy (ROUGE) là một phương 50 pháp do Lin và Hovy đưa ra vào năm 2003 cũng dựa trên các khái niệm tương tự"],[549,"Phương pháp này sử dụng n-gram để đánh giá sự tương quan giữa các kết qủa của mô hình tóm tắt và tập dữ liệu đánh giá"],[550,"Phương pháp này đã cho ra kết quả khả quan và được sự đánh giá cao của cộng đồng nghiên cứu tóm tắt văn bản"],[551,"ROUGE-N là một thu hồi n-gram (n-gram recall) giữa một bản tóm tắt tự động và một tập các tài liệu tóm tắt tham chiếu (ReferenceSummaries)"],[552,"ROUGE-N được tính như sau: = () {} () {} Công thức 5 Công thức tính ROUGE-N Trong đó: n là chiều dài của n-gram () là số lượng tối đa n-gram có thể xảy ra đồng thời trong bản tóm tắt tự động và bản tóm tắt tham chiếu ROUGE-N là một độ đo liên quan đến độ recall bởi vì mẫu số của vế phải trong công thức trên là tổng số n-gram xảy ra ở phía bản tóm tắt tham chiếu"],[553,"Cũng có một lưu ý rằng, số lượng n-gram ở mẫu số trong công thức tính ROUGE-N sẽ tăng lên khi chúng ta cho thêm nhiều tham chiếu"],[554,"Điều này hoàn toàn trực quan và hợp lí bởi vì có thể tồn tại nhiều bản tóm tắt tốt"],[555,"Mỗi khi chúng ta thêm một tham chiếu vào tập các văn bản tham chiếu, chúng ta đã mở rộng không gian các văn bản tóm tắt thay thế (alternative summaries)"],[556,"Bằng cách điều khiển các kiểu tham chiếu mà ta thêm vào tập văn bản tham chiếu, chúng ta có thể thiết kế các đánh giá tập trung vào các khía cạnh khác nhau của việc tóm tắt"],[557,"Ngoài ra, tổng tử số lớn hơn tổng số số bản tóm tắt tham chiếu"],[558,"Điều này hiệu quả vì cung cấp thêm nhiều trọng số để matching các n-grams xảy ra trong đa tham chiếu"],[559,"Do đó, một bản tóm tắt tự động càng chứa nhiều những từ được xuất hiện trong nhiều bản tóm tắt tham chiếu thì sẽ dành được điểm ROUGE-N càng cao"],[560,"Điều này một lần nữa lại rất trực quan và hợp lí bởi vì chúng ta thường ưu tiên các bản tóm tắt tự động 51 càng có nhiều nét giống với các điểm giống nhau giữa các bản tóm tắt tham chiếu càng tốt"],[561,"Khi sử dụng đa tham chiếu, chúng ta tính ROUGE-N theo từng cặp, giữa bản tóm tắt tự động s và từng bản tóm tắt tham chiếu ri trong tập các văn bản tóm tắt tham chiếu"],[562,"Sau đó, kết quả điểm ROUGE-N cuối cùng trong đa tham chiếu sẽ là điểm ROUGE- N cao nhất trong tất cả các cặp được tính"],[563,"Điều này có thể được thể hiện theo công thức sau: = ( , ) Công thức 6 Công thức tính ROUGE-N cuối cùng trong đa tham chiếu Kết quả của model đạt được như sau: ROUGE-1: 26.86% ROUGE-2: 6.71% Chúng ta sẽ so sánh kết quả với một số các model tóm tắt văn bản khác đã được công bố kết quả: Model ROUGE-1 ROUGE-2 Model Lead-3 (Nallapati) [3] 21.90% 7.20% Model SummaRuNNer (Nallapati) [5] 26.20% 10.80% Model Cheng et al 16 [5] 22.70% 8.50% Model ABS+ [5] 26.67% 6.72% Model of Sumit Chopra, Michael Auli [6] 26.90% 6.57% 52 Thông thường, các phương pháp tóm tắt trích xuất sẽ đạt kết quả ROUGE cao hơn các phương pháp tóm tắt tóm lược"],[564,"Bởi vì, phương pháp trích xuất sử dụng các từ xuất hiện trong văn bản để tạo ra bản tóm tắt, còn phương pháp tóm lược thì viết lại câu theo ý hiểu của máy"],[565,"Như vậy, so với các model tóm tắt văn bản bằng Deep Learning khác, model của hệ thống đạt được kết quả gần tương đương"],[566,"Trong đó kết quả ROUGE-1 gần bằng các model khác, còn kết quả ROUGE-2 vẫn khá thấp vì ảnh hưởng bởi tập dữ liệu không được xử lý tốt"],[567,"Một số kết quả thực nghiệm của model tóm tắt văn bản: Văn bản đầu vào Tóm tắt The coffee tasted great and was at such a good price"],[568,"I highly recommend this to everyone"],[569,"great coffee great price This saltwater taffy had great flavors and was very soft and chewy"],[570,"Each candy was individually wrapped well"],[571,"None of the candies were stuck together, which did happen in the expensive version, Fralinger's"],[572,"Would highly recommend this candy"],[573,"I served it at a beach-themed party and everyone loved it"],[574,"great candy Right now I'm mostly just sprouting this so my cats can eat the grass"],[575,"They love it"],[576,"I rotate it around with Wheatgrass and Rye too"],[577,"cats love it This is a very healthy dog food"],[578,"Good for their digestion"],[579,"Also good for small puppies"],[580,"My dog eats her required amount at every feeding"],[581,"healthy dog food 53 Good flavor"],[582,"These came securely packed"],[583,"They were fresh and delicious"],[584,"I love these Twizzlers"],[585,"fresh and delicious Good oatmeal"],[586,"I like the apple cinnamon the best"],[587,"Though I wouldn't follow the directions on the package since it always comes out too soupy for my taste"],[588,"That could just be me since I like my oatmeal really thick to add some milk on top of"],[589,"good oatmeal Deal was awesome"],[590,"Arrived before Halloween as indicated and was enough to satisfy trick or treaters"],[591,"I love the quality of this product and it was much less expensive than the local store's candy"],[592,"great deal This product serves me well as a source of electrolytes during and after a long run or bike ride"],[593,"I have tried all of the flavors but really do like the grapefruit flavor.."],[594,"no after-taste and I actually like the slight carbonation"],[595,"I use other Hammer products and really like their whole product line"],[596,"great flavor These taste really good"],[597,"I have been purchasing a different brand and these are very similar in taste and texture"],[598,"I agree with the other reviewer regarding ordering in the summer"],[599,"There is no insulating packaging with ice packs so they will melt in warm weather like all chocolate food items"],[600,"Order in cold weather and buy enough to last!!"],[601,"great taste We have three dogs and all of them love this food"],[602,"We bought it specifically for one of our dogs who has food allergies and it works great for him, no more hot spots or tummy problems"],[603,"I love that it ships right to our door with free shipping"],[604,"dogs love it 54 Don't buy just a few of these"],[605,"I order these by the case"],[606,"I can't even remember the first time I tasted an anchovy stuffed olive but I have tried several of the brands online and this brand is my favorite"],[607,"best olives ever Fresh, a great way to get a little chocolate in my life without a million calories"],[608,"They taste just like chocolate pudding"],[609,"fresh tasting This is the worst cheese that I have ever bought"],[610,"I will never buy it again and I hope you wont either"],[611,"worst cheese ever 4.4 Kiểm thử Để kiểm thử ứng dụng Android, người viết đồ án sử dụng kỹ thuật Kiểm thử hộp đen và Kiểm thử hộp trắng"],[612,"4.4.1 Kiểm thử hộp đen Kiểm thử hộp đen đối với chức năng Tóm tắt văn bản"],[613,"Chức năng được kiểm thử trong các test-case: không chọn văn bản, chọn vùng không có văn bản, chọn vùng văn bản khi không có kết nối và có kết nối Internet"],[614,"55 4.4.2 Kiểm thử hộp trắng Đồ thị nút của chương trình được thể hiện như sau: Các đường độc lập: 1 2 4 1 3 4 56 Test-case cho đường 1: textSummary = Kết quả mong đợi: hiển thị thông báo No text to summarize"],[615,"Test-case cho đường 2: textSummary = Hello World Kết quả mong đợi: phương thức trả về chuỗi Hello World"],[616,"4.5 Triển khai Chương trình được xây dựng và thử nghiệm trên máy tính cá nhân có cấu hình và các phần mềm cần thiết như sau: Ram: 8Gb Vi xử lý: Intel Core i7 CPU 2.60 GHz Hệ điều hành: Window 7 Phần mềm phát triển: PyCharm, Android Studio Ngôn ngữ sử dụng: Python, Java Card đồ họa: Nvidia geforce 920MX Thư viện: TensorFlow Như vậy, Chương 4 đã trình bày quy trình triển khai mô hình tóm tắt văn bản và ứng dụng di động Android"],[617,"Có thể nhận thấy, kết quả nghiên cứu khi áp dụng vào bài toán thực tế đã đạt được kết quả khả quan"],[618,"57 Để xây dựng nên sản phẩm hoàn chỉnh, trong quá trình làm đồ án, người viết đồ án đã lựa chọn các công nghệ hoặc phương pháp thực hiện phù hợp nhất đảm bảo sản phẩm có thể đạt được kết quả tốt, đồng thời chạy ổn định"],[619,"Chương 5 trình bày về các cải tiến hoặc vấn đề mà sinh viên thấy tâm đắc nhất trong quá trình xây dựng đồ án"],[620,"5.1 Cải tiến word embedding Hiện tại, các hệ thống tóm tắt văn bản bằng Deep Learning thường sử dụng Word2Vec, một trong các công cụ sử dụng word embedding phổ biến nhất"],[621,"Word2vec sử dụng một tầng ẩn, các neural ở tầng này đều là các neural tuyến tính"],[622,"Các neural ở tầng đầu vào có số neural tương ứng với số từ trong tập từ điển để huấn luyện"],[623,"Kích thước của tầng đầu ra bằng với kích thước tầng đầu vào"],[624,"Giả sử ta có tập từ điển để huấn luyện có V từ và N là số chiều của vector từ tương ứng"],[625,"Dữ liệu đầu vào đi từ tầng đầu vào đến tầng ẩn thì đi qua một ma trận WI có kích thước VxN với mỗi hàng đại diện cho một từ vựng"],[626,"Tương tự, khi đi từ tầng ẩn đến đầu ra, dữ liệu sẽ đi qua một ma trận WO có kích thước NxV"],[627,"Đầu vào của mạng là một one-hot vector"],[628,"Trong khóa luận này, sinh viên sử dụng ConceptNet Numberbatch là công cụ chuyển từ sang vector"],[629,"ConceptNet Numberbatch bao gồm các vector ngữ nghĩa tiên tiến có thể được sử dụng trực tiếp như là một biểu diễn ý nghĩa của từ hoặc là điểm xuất phát Chương 5 Các giải pháp và đóng góp nổi bật 58 cho việc học máy tiếp theo"],[630,"ConceptNet Numberbatch là một phần của dự án dữ liệu mở ConceptNet"],[631,"ConceptNet cung cấp nhiều cách để tính toán với ý nghĩa từ, một trong số đó là từ embeddings"],[632,"ConceptNet Numberbatch là một bản chụp chỉ những từ nhúng"],[633,"Nó được xây dựng bằng cách sử dụng một tổ hợp kết hợp dữ liệu từ ConceptNet, Word2Vec, GloVe, và OpenSubtitles 2016, sử dụng một biến thể cho việc trang bị thêm"],[634,"Dữ liệu được xây dựng dựa trên: ConceptNet 5.5 bao gồm dữ liệu từ Wiktionary, WordNet, và nhiều người đóng góp cho dự án Open Mind Common Sense, do Rob Speer biên soạn"],[635,"Glove bởi Jeffrey Pennington, Richard Socher và Christopher Manning"],[636,"Word2Vec bởi Tomas Mikolov và nghiên cứu của Google"],[637,"Văn bản song song từ OpenSubtitles 2016 của Pierre Lison và Jrg Tiedemann đã phân tích sử dụng fastText của Piotr Bojanowski, Edouard Grave, Armand Joulin và Tomas Mikolov"],[638,"Dữ liệu đa ngôn ngữ trong ConceptNet Numberbatch thể hiện 78 mã ngôn ngữ khác nhau, trong đó có cả tiếng Việt"],[639,"5.2 Xây dựng server với Django Trong quá trình xây dựng đồ án, để tối ưu dung lượng cho ứng dụng bên phía người dùng, người viết đồ án đã xây dựng server để lưu model và thực hiện công việc tóm tắt văn bản"],[640,"Ứng dụng bên phía client sẽ nhận nhiệm vụ gửi request là đoạn text cần tóm tắt và nhận về response là đoạn summary đã được tóm tắt"],[641,"Trong đó, Django là một web framework nổi tiếng được viết hoàn toàn bằng ngôn ngữ Python"],[642,"Nó có nhiều ưu điểm như (i) nhanh và linh hoạt, (ii) đầy đủ các thư viện, module hỗ trợ, (iii) đảm bảo tính bảo mật, và (iv) khả năng mở rộng tốt"],[643,"59 Bên cạnh việc phát triển web nhanh, Django là một framework hỗ trợ việc phát triển các API nhanh chóng, cấu trúc MVC rất rõ ràng"],[644,"Django cho phép tạo các URL của API một cách dễ dàng, đồng thời Django có thể dễ dàng thêm các gói phần mềm để kết nối tới các hệ thống, cơ sở dữ liệu khác"],[645,"Ở đây, chúng ta xây dựng một app đặt tên là api_textsum, thực hiện chức năng tóm tắt văn bản trên server"],[646,"Kiến trúc của app cũng được thiết kế theo mô hình MVC, trong đó file views.py để tương tác với người dùng"],[647,"Tuy nhiên, khả năng web host dường như là chướng ngại lớn nhất khi làm đồ án với Django"],[648,"Đối với PHP, số lượng host rất nhiều và khá rẻ"],[649,"Về Django, chúng ta vẫn có nhiều sự lựa chọn như Heroku hoặc Pythonanywhere"],[650,"Vậy nhưng, Heroku vẫn còn 60 thiếu tính ổn định đối với host free, còn Pythonanywhere thì hạn chế về mặt dung lượng file được phép tải lên"],[651,"Để đảm bảo ứng dụng được chạy ổn định, hiện tại hệ thống vẫn sử dụng localhost"],[652,"5.3 Xây dựng ứng dụng Android Trong quá trình xây dựng ứng dụng Android, một trong những vấn đề sinh viên gặp phải đó là phương thức để người dùng chọn một vùng văn bản"],[653,"Phương thức chọn văn bản cần dễ thực hiện và quen thuộc với người dùng"],[654,"Canvas trong Android đã cung cấp cho chúng ta các phương thức để vẽ tất cả các đối tượng hình học cơ bản như điểm, đường hoặc hình đa giác"],[655,"Chính vì vậy, sinh viên đã dùng canvas để tạo một view tuỳ chỉnh theo hình vẽ từ thao tác của người dùng"],[656,"Những thành phần mà chúng ta vẽ đều sẽ được xử lý trong phương thức onDraw(Canvas canvas) của class View"],[657,"Trong Java, Paint dùng để định nghĩa size, color, kiểu nét vẽ mà chúng ta sẽ sử dụng để vẽ bởi canvas"],[658,"Paint gồm một số phương thức đặc trưng như: setColor(int color): cài đặt màu cho nét vẽ"],[659,"setStyle(Style style): cài đặt style cho nét vẽ, có thể chỉ vẽ đường, chỉ tô đối tượng hoặc kết hợp cả hai"],[660,"setStrokeWidth(float width): cài đặt giá trị độ rộng cho nét vẽ"],[661,"Sau khi đã truyền tham số cho Paint xong, chúng ta vẽ các đối tượng hình học bởi phương thức canvas.drawPoint (vẽ điểm), canvas.drawLine (vẽ đường), can"]],"downloaded":true,"m":[-1,-1],"n":"20130150_Nguyen_Nam_Anh_1527526468353.txt","o":"http://storage.googleapis.com/soict-projects/cnpm/dhcq/20130150_Nguyen_Nam_Anh_1527526468353.pdf\r"},{"saved_path":"temp/20131383_Vu_Thu_Hien_1528204153945.txt","r":0,"s":[],"t":"\n BÀI TOÁN TÓM TẮT VĂN BẢN \r\n\r\n1. Tình hình nghiên cứu tóm tắt văn bản \r\n\r\nTrên thực tế, bài toán tóm tắt văn bản đa xuất hiện từ rất lâu. Những kỹ thuật đầu \r\n\r\ntiên áp dụng để tóm tắt văn bản xuất hiện từ những năm 50 của thế ký trước (như nghiên \r\n\r\ncứu của Luhn năm 1959). Sau đó, chung tiếp tục được nghiên cứu và đạt nhiều kết quả \r\n\r\nngày càng tốt hơn, cho nhiều loại ngôn ngữ như tiếng Anh, Pháp, Nhật, Trung. Các \r\n\r\nnghiên cứu tập trung vào hai hướng chính: tóm tắt trích xuất (Extraction Summarization) \r\n\r\nvà tóm tắt tóm lược (Abstraction Summarization) cho bài toán tóm tắt đơn văn bản và \r\n\r\nđa văn bản. Hầu hết các nghiên cứu về tóm tắt văn bản là trích xuất vì nó dễ thực hiện \r\n\r\nvà có tốc độ nhanh hơn so với tóm tắt tóm lược. Hướng tiếp cận trích xuất chủ yếu là \r\n\r\ndựa vào các đặc trưng quan trọng của văn bản để tính trọng số câu để trích xuất. Trong \r\n\r\nkhi đó, tóm tắt tóm lược là dựa vào các kỹ thuật xử lý ngôn ngữ tự nhiên kết hợp với \r\n\r\nthông tin về ngôn ngữ để tạo ra các tóm tắt cuối cùng. \r\n\r\nHiện nay trên thế giới, nhiều nhà khoa học và các công ty tỏ ra rất quan tâm đến \r\n\r\nbài toán tóm tắt văn bản tự động. Hội nghị DUC (Document Understand Conference, \r\n\r\n2001  2007) [DUC], hội nghị TAC (Text Analysis Conference, 2008  nay) [20], ACL \r\n\r\n(Association for Computational Linguistics, 2001  nay) là một day hội nghị khoa học \r\n\r\ntầm vóc thế giới điển hình về tóm tắt văn bản. Nhiều công trình khoa học về bài toán \r\n\r\ntóm tắt văn bản, về các mô hình, giải pháp tóm tắt văn bản được công bố hàng năm tại \r\n\r\ncác hội nghị này [27].  \r\n\r\nHiện nay trên thế giới, đa có nhiều hệ thống tóm tắt tắt văn bản tiếng Anh được \r\n\r\nxây dựng độc lập như SUMARIST, SWESUM,. Ngoài ra, có nhiều hệ thống tóm tắt \r\n\r\nvăn bản tích hợp được phát triển như: MEAD, LexRank, chức năng tự động tóm tắt trong \r\n\r\nMicrosoft Word. \r\n\r\nỞ Việt Nam những năm gần, Internet có sự phát triển mạnh mẽ. Hiện nay người \r\n\r\ndùng truy nhập và sử dụng các thông tin tiếng Việt trên Internet đa trở nên phổ biến. \r\n\r\nXuất phát từ sự thay đổi đó, hầu như tất cả các bài toán tiếng Việt điển hình của Xử lý \r\n\r\ndữ liệu văn bản đều đa được nghiên cứu và cài đặt thành ứng dụng thực tế như Tìm kiếm, \r\n\r\nPhân lớp & Phân loại văn bản,... đóng góp rất nhiều vào sự phát triển của lĩnh vực Xử lý \r\n\r\nvăn bản tự động tiếng Việt. Tuy nhiên bài toán tóm tắt văn bản thì chưa có nhiều nghiên \r\n\r\ncứu tiến hành đề xuất và xây dựng thành công ứng dụng. Các bài báo công bố kết quả \r\n\r\nnghiên cứu về tóm tắt văn bản phần lớn dựa trên hướng trích xuất cho bài toán tóm tắt \r\n\r\nđơn văn bản. Mặt khác, do chưa có kho ngữ liệu chuẩn phục vụ cho tóm tắt văn bản tiếng \r\n\r\n\r\n\r\n10 \r\n\r\n\r\nViệt nên hầu hết thử nghiệm của các nghiên cứu đều dựa trên các kho ngữ liệu tự xây \r\n\r\ndựng. \r\n\r\nMột số công trình tóm tắt tiếng Việt tiêu biểu như công trình của Nguyễn Lê Minh \r\n\r\n[42], Hà Thành Lê [41]. Nguyễn Lê Minh [42] đề xuất mô hình tóm tắt văn bản theo \r\n\r\nhướng trích xuất sử dụng phương pháp SVM. Các đặc trưng được sử dụng trong việc \r\n\r\nxây dựng mô hình bao gồm vị trí câu, chiều dài câu, độ liên quan chủ đề, tần suất từ, \r\n\r\ncụm từ chính và khoảng cách từ [42]. Hà Thành Lê [41] đề xuất mô hình sử dụng một \r\n\r\nsố đặc trưng trong văn bản như tần số từ, TFIDF, vị trí câu, độ dài câu, từ tiêu đề. Các \r\n\r\nđặc trưng được kết hợp tuyến tính với nhau để tính trọng số mỗi câu trong văn bản gốc. \r\n\r\nTrong phương pháp này, Hà Thành Lê cũng đề cập đến công cụ tách từ cho văn bản tiếng \r\n\r\nViệt [41]. \r\n\r\n \r\n\r\n2. Tầm quan trọng của tóm tắt văn bản \r\n\r\nTrong thời đại internet với sự bùng nổ của thông tin, vấn đề chính mà con người \r\n\r\nphải đối mặt không còn là vấn đề về sự thiếu hụt thông tin mà là làm thế nào để có thể \r\n\r\nxác định, chọn lọc ra những thông tin mà mình cần trong bể thông tin khổng lồ được gia \r\n\r\ntăng hàng ngày trên mạng toàn cầu. Mỗi một cá nhân hay tổ chức đều phải giải quyết bài \r\n\r\ntoán dư thừa thông tin (Information Overload) để có thể hoạt động hiệu quả trong thời \r\n\r\nđại thông tin ngày nay. Vấn đề của chung ta gặp phải hiện nay không chỉ là sự thiếu hụt \r\n\r\nthông tin, mà với lượng thông tin khổng lồ như vậy, làm cách nào có thể xác định và \r\n\r\nchọn lọc các thông tin mà mình cần trong khối lượng thông tin quá lớn như vậy? Mặt \r\n\r\nkhác, Internet tồn tại dưới dạng đa ngôn ngữ, tuy nó không có vấn đề gì nhưng sẽ gây \r\n\r\nkhó khăn rất nhiều cho việc phân tích tài liệu [23]. Do đó, có một nhu cầu rất lớn là giảm \r\n\r\nbớt nhiều dữ liệu văn bản này xuống tóm tắt tập trung ngắn hơn để nắm bắt các chi tiết \r\n\r\nnổi bật, từ đó ta có thể nhanh chóng kiểm tra xem các tài liệu lớn hơn có chứa thông tin \r\n\r\nmà ta đang tìm kiếm hay không. \r\n\r\n Để giải quyết vấn đề quá tải thông tin và dư thừa thông tin, giup chung ta có thể \r\n\r\nxác định nhanh chóng và hiệu quả các thông tin mà mình cần, có khá nhiều cách tiếp cận \r\n\r\nđa được thực hiện: \r\n\r\n Tìm kiểm thông tin (information retrieval). \r\n\r\n Trích rut thông tin (information extraction). \r\n\r\n Phân cụm tài liệu (document clustering). \r\n\r\n Biểu diễn thông tin trực quan (visualization). \r\n\r\n\r\n\r\n11 \r\n\r\n\r\n Các hệ hỏi đáp (Question/Answering System). \r\n\r\n Tóm tắt văn bản tự động (Automatic Text Summarization). \r\n\r\n Trong đó, tóm tắt văn bản tự động là phương pháp chủ đạo giúp còn người giả \r\n\r\nquyết vấn đề trên. Các ưu điểm của việc tóm tắt văn bản tự động: \r\n\r\n Tóm tắt làm giảm thời gian đọc tài liệu mà vẫn nắm bắt được nội dung quan \r\n\r\ntrọng của văn bản. \r\n\r\n Khi nghiên cứu tài liệu, tóm tắt làm cho việc chọn lựa tài liệu một cách dễ \r\n\r\ndàng hơn. \r\n\r\n Tóm tắt văn bản có thể hữu ích trong các hệ thống Q&A (Hỏi  Đáp) \r\n\r\n Tóm tắt tự động sẽ khách quan hơn so với tóm tắt của con người. \r\n\r\n Tóm tắt tự động sẽ cho phép các cá nhân, tổ chức xử lý các văn bản, các tài \r\n\r\nliệu một cách nhanh chóng, dễ dàng và hiệu quả hơn. \r\n\r\nBổ sung cho nhận định trên, Viện Tiêu Chuẩn Quốc Gia Hoa Kì (ANSI) chỉ ra rằng \r\n\r\nmột tóm lược được chuẩn bị tốt giup người đọc xác định được nội dung  cơ bản của tài \r\n\r\nliệu một cách nhanh hơn và chính xác hơn, cũng như dễ dàng xác định nội dung đó có \r\n\r\nliên quan đến vấn đề mà họ đang quan tâm hay không, do đó quyết định nên hay không \r\n\r\nnên đọc toàn bộ tài liệu này. Thực vậy, báo cáo tại hội nghị SUMMAC 2002 đa xác \r\n\r\nnhận điều này bằng cách chứng minh được rằng: Các bản tóm tắt chỉ cần ngắn bằng \r\n\r\nkhoảng 17% độ dài của văn bản gốc thì sẽ làm tăng tốc độ ra quyết định lên 2 lần mà \r\n\r\nkhông có sự suy giảm về độ chính xác trong tỉ lệ xác suất có nghĩa. \r\n\r\n  \r\n\r\n\r\n\r\n12 \r\n\r\n\r\n3. Bài toán tóm tắt văn bản \r\n\r\n3.1. Tóm tắt văn bản là gì? \r\n\r\nBài toán tóm tắt văn bản là một trong những bài toán kinh điển trong lĩnh vực xử \r\n\r\nlý dữ liệu văn bản. Xử lý dữ liệu văn bản bao gồm: \r\n\r\n Kiểm tra lỗi chính tả (spelling-checker) \r\n\r\n Kiểm tra lỗi văn phạm (grammar-checker) \r\n\r\n Từ điển đồng nghĩa (thesaurus) \r\n\r\n Phân tích văn bản (text analyzer) \r\n\r\n Phân loại văn bản (text classification) \r\n\r\n Tóm tắt văn bản (text summarization) \r\n\r\n Tổng hợp tiếng nói (speech synthesis) \r\n\r\n Nhận dạng giọng nói (speech recognization) \r\n\r\n Dịch tự động (automatic translation)  \r\n\r\n . \r\n\r\nCác định nghĩa về tóm tắt văn bản tự động. \r\n\r\n Định nghĩa 1 (Van Dijk) [23]: Chức năng chính của tóm tắt là chỉ ra và dự đoán cấu \r\n\r\ntruc và nội dung của văn bản. \r\n\r\n Định nghĩa 2 (Cleveland) [23]: Bản tóm tắt phải mang các nội dung chủ yếu của tài \r\n\r\nliệu, và nó thực sự là một bản thay thế của tài liệu. \r\n\r\n Định nghĩa 3 [23]: Bản tóm tắt là một phiên bản đặc của tài liệu có một thể loại dễ \r\n\r\nnhận biết và một mục đích rất cụ thể: để cung cấp cho người đọc một ý tưởng chính \r\n\r\nxác và ngắn gọn về nội dung của nguồn. \r\n\r\n Định nghĩa 4 [23]: Một bản tóm tắt tự động là một văn bản được tạo ra bởi một phần \r\n\r\nmềm, nó mạch lạc và có chứa một lượng đáng kể các thông tin có liên quan từ các \r\n\r\nvăn bản nguồn. Tỷ lệ nén của nó là ít hơn một phần ba chiều dài của tài liệu gốc. \r\n\r\n  \r\n\r\n\r\n\r\n13 \r\n\r\n\r\n3.2. Phân loại tóm tắt văn bản \r\n\r\n3.2.1. Phân loại theo kết quả \r\n\r\n3.2.1.1. Tóm tắt trích xuất (Extract) \r\n\r\nĐối với tóm tắt trích xuất, chương trình tóm tắt tự động sẽ trích xuất ra các thành \r\n\r\nphần của văn bản mà không chỉnh sửa nội dung của nó rồi ghép lại thành một văn bản \r\n\r\nhoàn chỉnh. Loại tóm tắt này bao gồm trích xuất câu và trích xuất cụm từ. Như vậy, tóm \r\n\r\ntắt trích xuất chỉ sử dụng các thông tin có sẵn trong văn bản như: từ, cụm từ, câu để tạo \r\n\r\nra văn bản tóm tắt [23]. \r\n\r\n Phương pháp trích xuất bao gồm việc lựa chọn đơn vị của văn bản (câu hay đoạn \r\n\r\nvăn), được coi là có chứa lượng thông tin cốt tử của văn bản (informative content, \r\n\r\ninformativity), và kết nối các đơn vị này theo một trình tự thích hợp. Một trích xuất là \r\n\r\nsự lắp ghép các đoạn được trích xuất ra từ văn bản nguồn. Mục tiêu của trích xuất là \r\n\r\ncung cấp một cái nhìn tổng quan về nội dung của văn bản gốc. Độ dài của văn bản tóm \r\n\r\ntắt bằng trích xuất có thể được xác định bởi tỉ lệ nén, hay nói cách khác Văn bản tóm \r\n\r\ntắt ngắn hơn bao nhiêu so với văn bản gốc. \r\n\r\n Thuật toán tóm tắt tự động bằng trích xuất có thể chia ra làm 3 mức: surface-level \r\n\r\n(mức bề mặt), intermediate-level (mức trung bình) và deep parsing techniques (các kĩ \r\n\r\nthuật phân tích sâu). \r\n\r\n Tóm tắt trích xuất xuất phát từ ý tưởng: Một tài liệu được chia nhỏ thành các đơn \r\n\r\nvị ngữ pháp (các câu văn), sau đó được đánh trọng số theo kinh nghiệm (heuristic); Các \r\n\r\nđơn vị ngữ pháp có điểm cao nhất sẽ được trích xuất và liên kết với nhau để tạo nên văn \r\n\r\nbản tóm tắt [23]. \r\n\r\n Thuật toán tiếp cận ở mức bề mặt: Không đào sâu vào chiều sâu ngôn ngữ của \r\n\r\nvăn bản, thay vào đó là sử dụng các phần tử ngôn ngữ nhất định để xác định các \r\n\r\nđoạn có liên hệ với nhau trong văn bản [23]. Kĩ thuật của mức bề mặt dựa vào sự \r\n\r\nxuất hiện của từ để đánh trọng số cho các câu. Một kĩ thuật khác dựa trên ý tưởng: \r\n\r\nNhững từ được sử dụng trong tiêu đề của văn bản là quan trọng. Trong khi đó, \r\n\r\nmột số kĩ thuật dựa vào vị trí của các đoạn trong văn bản. Kĩ thuật này được áp \r\n\r\ndụng với nhưng văn bản có cấu truc cố định, như tiêu đề, các mục và các đoạn,... \r\n\r\nMột số nghiên cứu còn chỉ ra rằng: Dòng đầu tiên luôn là dòng quan trọng nhất \r\n\r\ntrong văn bản đối với các thể loại báo chí. \r\n\r\n Thuật toán tiếp cận mức trung bình: Sử dụng thông tin về ngôn ngữ học phức \r\n\r\ntạp hơn thuật toán tiếp cận mức bề mặt nhưng lại ít phức tạp hơn mức phân tích \r\n\r\n\r\n\r\n14 \r\n\r\n\r\nsâu. Một kĩ thuật của dạng này là phát hiện các chuỗi từ vựng. Chuỗi từ vựng là \r\n\r\nmột day các từ kết nối với nhau theo quan hệ về ngữ nghĩa. Một cách tổng quát, \r\n\r\nquá trình tóm tắt bao gồm 4 giai đoạn. Bốn giai đoạn đó bao gồm: \r\n\r\n- Chia văn bản gốc thành các đoạn (segments). Xây dựng các chuỗi từ  vựng  \r\n\r\nlexical chain [23]. \r\n\r\n- Xác định các strong chain  chuỗi từ mạnh [23] \r\n\r\n- Trích xuất các câu chứa các strong chain [23] \r\n\r\n- Lắp ghép các câu được trích xuất thành văn bản tóm tắt [23] \r\n\r\n Thuật toán phân tích sâu: Dựa trên ý tưởng rằng sử dụng các kĩ thuật chuyên \r\n\r\nsâu về ngôn ngữ để phát hiện ra các cấu truc rời rạc của văn bản [23]. Những hệ \r\n\r\nthống tóm tắt văn bản tự động dựa trên phân tích diễn ngôn bắt nguồn từ ý tưởng: \r\n\r\nVăn bản được định nghĩa bởi cấu truc trong của nó và các mối quan hệ diễn ngôn \r\n\r\n- phụ thuộc vào ngôn ngữ mà văn bản sử dụng. Những hệ thống này cung cấp độ \r\n\r\nquan trọng nhiều hơn cho các thành phần cốt tử của các quan hệ rời rạc. \r\n\r\n3.2.1.2. Tóm tắt tóm lược (Abstract) \r\n\r\nTuy tóm tắt bằng trích xuất đa thành công trong việc xác định câu nào trong văn \r\n\r\nbản đầu vào mang nội dung quan trọng nhưng dường như những phương pháp này rất \r\n\r\nxa với việc tạo ra một bản tóm tắt tối ưu theo nghĩa cả về nội dung và chất lượng trong \r\n\r\nngôn ngữ học. Trong khi đó, hệ thống tạo ra văn bản tóm tắt bằng tóm lược dựa trên \r\n\r\nviệc hiểu văn bản gốc và đạt tới việc sinh ra một văn bản mới một cách chính xác về \r\n\r\nngữ pháp, suc tích và mạch lạc về nội dung, bằng cách sinh ra văn bản tóm tắt bằng \r\n\r\nnhững từ vựng không xuất hiện trong văn bản gốc. \r\n\r\n Trong tóm lược, việc diễn giải, viết lại các câu phức tạp sẽ nhằm mục đích tạo ra \r\n\r\nphiên bản suc tích của nội dung ban đầu. Mặc dù con người có thể tái sử dụng một phần \r\n\r\nvăn bản gốc nhưng không phải sử dụng toàn bộ nó; sử dụng các đoạn hay một phần của \r\n\r\ncâu thay vì sử dụng toàn bộ câu. \r\n\r\n \r\n\r\n3.2.2. Phân loại theo số lượng \r\n\r\n Tóm tắt đơn văn bản: là một bản tóm tắt được tạo thành từ một văn bản riêng lẻ. \r\n\r\n Tóm tắt đa văn bản: là một bản tóm tắt được tạo thành từ nhiều văn bản cùng liên \r\n\r\nquan tới một chủ đề riêng lẻ. \r\n\r\n\r\n\r\n15 \r\n\r\n\r\n3.2.3. Phân loại theo mục đích \r\n\r\n Tóm tắt sơ lược (Indicative): tóm tắt nhằm đưa ra những thông tin ngắn gọn về chủ \r\n\r\nđề chính củavăn bản (ứng dụng trong tóm tắt kết quả tìm kiếm). Thông thường, độ \r\n\r\ndài của văn bản tóm tắt loại này chỉ từ 5 đến 10% độ dài của toàn bộ văn bản. \r\n\r\n Tóm tắt thông tin (Information): tóm tắt bao gồm tất cả các thông tin nổi bật có \r\n\r\ntrong văn bản nguồn tại nhiều mức độ chi tiết khác nhau. Kiểu tóm tắt này có độ \r\n\r\ndài từ 20-30% văn bản gốc. \r\n\r\n Tóm tắt đánh giá (Evaluation): tóm tắt nhằm mục đích đánh giá vấn đề chính của \r\n\r\nvăn bản nguồn, thể hiện quan điểm của người tóm tắt đối với chủ đề được đưa ra. \r\n\r\nTuy nhiên, kiểu tóm tắt này dường như vượt qua tầm của các hệ thống tóm tắt tự \r\n\r\nđộng hiện này. \r\n\r\n3.2.4. Phân loại theo nội dung \r\n\r\n Tóm tắt chung (Generalized): tóm tắt nhằm mục đích đưa ra các nội dung quan \r\n\r\ntrọng bao quát văn bản gốc. \r\n\r\n Tóm tắt hướng truy vấn (Querybased): tóm tắt nhằm mục đích  đưa ra kết quả dựa \r\n\r\nvào câu truy vấn của người. Tóm tắt này thường được sử dụng trong quá trình tìm \r\n\r\nkiếm thông tin (information retreival). \r\n\r\n3.2.5. Phân loại theo mức độ chi tiết \r\n\r\n Tóm tắt tổng quan (overview): tóm tắt miêu tả tổng quan tất cả các nội dung nổi \r\n\r\nbật trong văn bản nguồn. \r\n\r\n Tóm tắt tập trung sự kiện (event): tóm tắt miêu tả một sự kiện cụ thể nào đó trong \r\n\r\nvăn bản nguồn. \r\n\r\n  \r\n\r\n\r\n\r\n16 \r\n\r\n\r\n3.3. Các đặc trưng sử dụng trong tóm tắt văn bản \r\n\r\nTóm tắt văn bản là bài toán của thuộc lĩnh vực xử lý ngôn ngữ tự nhiên (Natural \r\n\r\nLanguage Processing  NLP) và lĩnh vực khai phá dữ liệu văn bản (Text Minning  TM). \r\n\r\nTương tự như bài toán xử lý ngôn ngữ tự nhiên, tóm tắt văn bản sử dụng các đặc trưng \r\n\r\nở 3 mức độ: mức độ hình thái, mức độ cu pháp và mức độ ngữ nghĩa. \r\n\r\n Mức độ hình thái \r\n\r\n Đặc trưng về chủ đề (Thematic): tần suất từ, stop words, TF.IDF. \r\n\r\n Đặc trưng về vị trí (Location): vị trí câu trong văn bản hay đoạn văn (câu đầu tiên \r\n\r\nmỗi đoạn, n câu đầu tiên của văn bản), phương pháp tiêu đề (câu chứa từ có trong \r\n\r\ntiêu đề), cue-words, hay fixed-phrased (câu chứa những ngữ cố định). \r\n\r\n Đặc trưng đồng xuất hiện (co-ocurrence): từ xuất hiện trong nhiều văn bản. \r\n\r\n Đặc trưng về tên riêng (proper name). \r\n\r\n Đặc trưng về chiều dài câu (short-length cutoff): bỏ nhưng câu ngắn. \r\n\r\n Mức độ cú pháp \r\n\r\n Đặc trưng về định dạng (format).  \r\n\r\n Đặc trưng về chủ đề trong văn bản (Threads of topic). \r\n\r\n Đặc trưng về cấu truc chuỗi từ vựng (Lexical chains). \r\n\r\n Đặc trưng về cấu truc lý luận (Rhetorical structure). \r\n\r\n Mức độ ngữ nghĩa \r\n\r\n Đặc trưng về mối liên quan giữa các từ theo từ điển (lexical cohension): đồng \r\n\r\nnghĩa (synonymy), bao hàm (hypernymy), lặp lại (repetition). \r\n\r\n Đặc trưng về sự tương tự (similarity): các từ có cùng dẫn xuất (common stem), \r\n\r\nđộ tương đồng giữa các câu. \r\n\r\n Đặc trưng về đồng tham chiếu (coreference) \r\n\r\n Đặc trưng về mối quan hệ logic. \r\n\r\n Đặc trưng về mối quan hệ biểu diễn ngữ nghĩa. \r\n\r\n Đặc trưng về mối quan hệ cu pháp (grammatical cohesion): trùng lặp (anaphora), \r\n\r\ntĩnh lược (ellipsis), liên từ (conjuction). \r\n\r\n \r\n\r\n\r\n\r\n17 \r\n\r\n\r\n3.4. Các hướng tiếp cận tóm tắt văn bản \r\n\r\n3.4.1. Phương pháp thống kê \r\n\r\nCác phương pháp thống kê là những phương pháp đầu tiên được sử dụng trong \r\n\r\ntóm tắt văn bản. Nó sử dụng các dữ liệu thống kê về độ quan trọng của các từ, ngữ, câu \r\n\r\nhay đoạn để tạo ra bản tóm tắt. Các dữ liệu này thường được thu thập dựa trên các tập \r\n\r\nvăn bản mẫu. Phương pháp thống kê sử dụng các đặc trưng như: \r\n\r\n Dựa trên vị trí câu. \r\n\r\n Dựa trên ngữ cố định: gồm ngữ nhấn mạnh và ngữ dư thừa.  \r\n\r\n Dựa trên tần suất từ. \r\n\r\n3.4.2. Phương pháp cấu trúc \r\n\r\nTrong các nghiên cứu gần đây có rất nhiều các đặc trưng hiệu quả của câu văn \r\n\r\nđược đề xuất để dùng cho tóm tắt trích xuất, ví dụ như signature word, event hay sentence \r\n\r\nrelevance. Phương pháp câu truc sử dụng các mối liên hệ đặc trưng hình thái - ngữ pháp \r\n\r\n- ngữ nghĩa để xác định các đơn vị ngữ liệu quan trọng, những đơn vị ngữ liệu nào có \r\n\r\nchứa các thành phần liên quan nhiều với các thành phần khác sẽ có mức độ quan trọng \r\n\r\ncao. Trong mục này sẽ trình bày chi tiết các đặc trưng được xem xét. \r\n\r\n Surface Features  Đặc trưng hình thái: Nhóm đặc trưng này xem xét đến đặc \r\n\r\nđiểm hình thái của câu. Bao gồm: vị trí của câu trong văn bản - thông thường các \r\n\r\ncâu đầu văn bản thường là các câu chứa đựng chủ đề khái quát của cả bài văn; số \r\n\r\nlượng từ trong câu - căn cứ vào các kiểu văn bản khác nhau, văn bản báo chí, xa \r\n\r\nluận, hay bài báo khoa học thì câu văn thường có một độ dài trung bình nhất định, \r\n\r\nnhững câu văn có số lượng từ nhỏ hơn ngưỡng đó sẽ là các câu không quan trọng; \r\n\r\nsố lượng trích dẫn trong câu - một câu chứa quá nhiều trích dẫn là câu không quan \r\n\r\ntrọng. \r\n\r\n Content Features  Đặc trưng nội dung: bao gồm các đặc trưng nội dung như \r\n\r\ntần suất từ, giá trị TF-IDF, . \r\n\r\n Relevance Features  Đặc trưng độ liên quan: Đặc trưng này được sử dụng để \r\n\r\ntìm ra mối liên hệ giữa các câu. Dựa trên quan hệ giữa các câu/đoạn trong văn \r\n\r\nbản: xác định mối quan hệ giữa các đoạn trong văn bản hay các câu trong đoạn \r\n\r\nthông qua các độ đo như Cosine hay PageRank. \r\n\r\n  \r\n\r\n  \r\n\r\n\r\n\r\n18 \r\n\r\n\r\n3.4.3. Phương pháp máy học \r\n\r\n3.4.3.1. Học có giám sát \r\n\r\n Phương pháp Nave-Bayes \r\n\r\nCác hướng tiếp cận theo phương pháp này giả định rằng các đặc trưng của văn \r\n\r\nbản độc lập nhau. Sử dụng bộ phân lớp Nave-Bayes để xác định câu nào thuộc về tóm \r\n\r\ntắt và ngược lại. \r\n\r\nCho s là các câu cần xác định. F1.Fk là các đặc trưng đa được chọn, và giả định \r\n\r\ncác thuộc tính độc lập nhau. Tính xác suất của câu s thuộc về tóm tắt. Sau khi tính xác \r\n\r\nsuất các câu, n câu có xác suất cao nhất sẽ được trích xuất. \r\n\r\nCác nghiên cứu đại điện cho phương pháp này:  \r\n\r\n Kupiec và cộng sự [Kupiec95] sử dụng phân lớp Bayes để kết hợp các đặc trưng \r\n\r\nlại với nhau [26]: \r\n\r\no Các đặc trưng sử dụng : word frequency, location, cue word, title & leading, \r\n\r\nsentence length, uppercase words. \r\n\r\no Ngữ liệu : 188 cặp văn bản khoa học và tóm tắt. Tổng số câu:  568 câu. Số câu \r\n\r\nkhớp trực tiếp với tóm tắt 451 (79%). \r\n\r\n Aone (1999) [2] \r\n\r\no Kết hợp thêm nhiều đặc trưng phong phu hơn : tf.idf (single word, two-noun \r\n\r\nword, named-entities), discourse (cohension) (sử dụng Wordnet và kỹ thuật \r\n\r\nsử lý ngôn ngữ tự nhiên để phân tích sự tham chiếu đối với các thực thể). \r\n\r\no Ngữ liệu : sử dụng ngữ liệu của TREC. \r\n\r\no Hệ thống : DimSum. \r\n\r\n Phương pháp Decision Tree \r\n\r\nLin & Hovy [Lin97] áp dụng phương pháp này nhằm xác định vị trí của các câu \r\n\r\nquan trọng trong văn bản [10]. Lin giả định rằng, các đặc trưng không độc lập với nhau. \r\n\r\nTác giả đa kiểm tra nhiều đặc trưng và ảnh hưởng của chung lên quá trình rut trích. Hệ \r\n\r\nthống tóm tắt của Lin là loại tóm tắt hướng về truy vấn (query-based). \r\n\r\nCác đặc trưng: position (OOP), numeric data, proper name, pronoun & adjective, \r\n\r\nweekday hoặc month, cùng với 2 đăc trưng mới: Query signature (số từ truy vấn có trong \r\n\r\ncâu) và IR signature (những từ nổi bật, quan trọng ~ TFIDF) [10]. \r\n\r\n Support Vector Machine (SVM  Máy vector hỗ trợ) \r\n\r\nSVM nhận dữ liệu vào và xây dựng (learn) một siêu phẳng (hyperplane) để phân \r\n\r\nlớp (classify) tập dữ liệu thành 2 lớp riêng biệt. Về ý tưởng, SVM sử dụng thủ thuật để \r\n\r\nánh xạ tập dữ liệu ban đầu vào không gian nhiều chiều hơn. Khi đa ánh xạ sang không \r\n\r\n\r\n\r\n19 \r\n\r\n\r\ngian nhiều chiều, SVM sẽ xem xét và chọn ra siêu phẳng phù hợp nhất để phân lớp tập \r\n\r\ndữ liệu đó. \r\n\r\nSVM [4] đa được biết đến là một trong số các phương pháp phân lớp tốt nhất đối \r\n\r\nvới các bài toán phân lớp văn bản (text/document classification). SVM [4] xác định một \r\n\r\nhàm phân tách tuyến tính: \r\n\r\nf(x) = w. x + b  \r\nTrong đó, w là vector trọng số, b là tham số điều chỉnh bias, x là vector đặc trưng. \r\n\r\n Mặt siêu phẳng xác định được được dùng để phân tách các ví dụ đầu vào. Nên \r\n\r\nvới ví dụ đầu vào có vector đặc trưng xi sẽ được gán vào lớp dương nếu f(xi)  0 tức \r\n\r\nnhan lớp (ti) là 1 hoặc được gán vào lớp âm, nhan lớp là 1  nếu ngược lại . \r\n\r\nti = {\r\n1, w. xi + b < 0\r\n\r\n1, w. xi + b  0\r\n \r\n\r\nw.x+b=0 là mặt siêu phẳng phân tách các ví dụ huấn luyện lớp dương và các ví dụ \r\n\r\nhuấn luyện lớp âm.  \r\n\r\n \r\n\r\n\r\nTrong tóm tắt văn bản, sử dụng SVM kết hợp các đặc trưng câu để gắn nhan cho câu vào \r\n\r\nhai lớp có trong bản tóm tắt hoặc không có trong tóm tắt. \r\n\r\n  \r\n\r\n\r\n\r\n20 \r\n\r\n\r\n3.4.3.2. Học không giám sát \r\n\r\nLà kỹ thuật học sử dụng cho các bài toán phân cụm, gom cụm (Clustering). Để \r\n\r\nsử dụng kỹ thuật này cần có tập đặc trưng học được từ tập dữ liệu huấn luyện. Điểm khác \r\n\r\nbiệt so với học có giám sát là trước khi phân cụm thì không biết trong tập dữ liệu mục \r\n\r\ntiêu có bao nhiêu cụm và những cụm gì. \r\n\r\n Hệ thống học không có giám sát tạo ra các bản tóm tắt bằng cách chỉ truy cập các \r\n\r\ndữ liệu mục tiêu. Nó cố gắng khám phá ra cấu truc bí ẩn trong dữ liệu không dán nhan \r\n\r\n(chưa được phân lớp). Do đó, chung thích hợp cho bất kỳ dữ liệu mới được quan sát mà \r\n\r\nkhông cần bất kỳ sửa đổi tiên tiến. \r\n\r\n Một số phương pháp học không giám sát: \r\n\r\n Clustering (gom cụm, phân cụm) \r\n\r\n Phương pháp Hidden Makov Model (Mô hình Makov ẩn) \r\n\r\nCác đặc trưng sử dụng: position, number of term, likelihood of sentence. \r\n\r\nMô hình HMM bao gồm 2s + 1 trạng thái, trong đó s là số trạng thái tóm tắt (câu \r\n\r\nthuộc tóm tắt) và s+1 là câu không thuộc tóm tắt. \r\n\r\nMô hình HMM xây dựng ma trận chuyển vị M, coi các đặc trưng là đa biến và tính \r\n\r\nxác suất của các câu qua từng trạng thái. \r\n\r\n Phương pháp phân tích ma trận không âm NMF: \r\n\r\nPhân tích ma trận không âm - Non-negative matrix factorization là một nhóm các \r\n\r\nthuật toán phân tích đa biến trong đại số tuyến tính [24]. Ma trận A được phân tích thành \r\n\r\n2 ma trận W và H với điều kiện là cả 3 ma trận này đều chỉ mang các thuộc tính không \r\n\r\nâm, \r\n \r\n\r\n\r\n Ma trận A được phân tích thành 2 ma trận W và H: \r\n\r\nA = WH \r\n\r\n\r\n\r\n21 \r\n\r\n\r\n Với A là một ma trận mxn, W là một ma trận mxk, và H là một ma trận kxn, k \r\n\r\nluôn được chọn có giá trị nhỏ hơn m và n, do đó cả 2 ma trận W và H đều có cỡ nhỏ hơn \r\n\r\nma trận A. \r\n\r\n Áp dụng phân tích ma trận NMF vào tóm tắt văn bản: Một thể hiện tự nhiên của \r\n\r\ncác câu trong văn bản tóm tắt chính là một vector. Như vậy thể hiện tự nhiên của một \r\n\r\nvăn bản chính là một ma trận. Ma trận A là ma trận boolean terms x sentences thu được \r\n\r\nbằng cách xử lý sơ bộ tập các câu trong văn bản, với term là từ trong văn bản, mỗi câu \r\n\r\nlà một vector trong ma trận, giá trị phần tử của vector câu bằng 1 nếu từ có trong câu. \r\n\r\nMa trận W là ma trận có giá trị các phần tử bằng giá trị các đặc trưng ngữ nghĩa của câu. \r\n\r\nPhương pháp NMF trích xuất câu có trọng số lớn nhất theo nghĩa: câu đó phản ánh nhiều \r\n\r\nnhất tới chủ đề chính của tài liệu, điều đó được biểu diễn bởi các đặc trưng ngữ nghĩa. \r\n\r\n3.4.3.3. Học nửa giám sát \r\n\r\nHọc nửa giám sát sử dụng cả dữ liệu đa gán nhan và chưa gán nhan để huấn luyện \r\n\r\n- điển hình là một lượng nhỏ dữ liệu có gán nhan cùng với lượng lớn dữ liệu chưa gán \r\n\r\nnhan. Học nửa giám sát đứng giữa học không giám sát (không có bất kì dữ liệu có nhan \r\n\r\nnào) và có giám sát (toàn bộ dữ liệu đều được gán nhan). \r\n\r\nTuỳ vào từng mục đích cụ thể, học nửa giám sát có thể được áp dụng cho bài toán \r\n\r\nphân lớp hoặc phân cụm. Trong tóm tắt văn bản, học bán giám sát thường được sử dụng \r\n\r\nđể gắn nhan trong văn bản. \r\n\r\n Một số phương pháp học nửa giám sát: \r\n\r\n Các phương pháp dựa trên đồ thị (Graph-based) \r\n\r\n Cực đại kỳ vọng (EM - Expectation Maximization) \r\n\r\n Co-training \r\n\r\n   \r\n\r\n\r\n\r\n22 \r\n\r\n\r\n3.4.4. Phương pháp Deep Learning \r\n\r\nTrong những năm qua, thuật ngữ deep learning (học sâu) đa dần len lỏi mỗi khi \r\n\r\ncó cuộc hội thoại nào bàn về trí tuệ nhân tạo (AI), dữ liệu lớn (Big Data) và phân tích \r\n\r\n(Analytics). Và với lý do chính đáng  đây là một cách tiếp cận đầy hứa hẹn tới AI khi \r\n\r\nphát triển các hệ thống tự trị, tự học, những thứ đang cách mạng hóa nhiều ngành công \r\n\r\nnghiệp. \r\n\r\nVề cơ bản, Deep Learning là một là một chi của ngành máy học dựa trên một tập \r\n\r\nhợp các thuật toán để cố gắng mô hình dữ liệu trừu tượng hóa ở mức cao bằng cách sử \r\n\r\ndụng nhiều lớp xử lý với cấu trúc phức tạp, hoặc bằng cách khác bao gồm nhiều biến đổi \r\n\r\nphi tuyến. Mỗi lớp kế tiếp dùng đầu ra từ lớp trước làm đầu vào. Các thuật toán này có \r\n\r\nthể được giám sát hoặc không cần giám sát và các ứng dụng bao gồm các mô hình phân \r\n\r\ntích (không có giám sát) và phân loại (giám sát) [3].  \r\n\r\nCốt lõi của Deep Learning bao gồm mô hình mạng neural (Neural Network) nhiều \r\n\r\nlớp và quá trình huấn luyện mạng để xác định các tham số cho mô hình. Một kiến trúc \r\n\r\nmạng phổ biến nhất trong Deep Learning là mạng Neural hồi quy (Recurrent Neural \r\n\r\nNetwork  RNN) [36]. \r\n\r\nTrong các ứng dụng xử lý ngôn ngữ tự nhiên, dữ liệu có tính chất chuỗi: ví dụ sự \r\n\r\nxuất hiện của một từ trong 1 câu phụ thuộc vào các từ trước đó. Kiến trúc mạng hồi quy \r\n\r\nđa được đề xuất để tận dụng đặc trưng đó. Trong kiến trúc RNN, đầu ra của mỗi tầng sẽ \r\n\r\nđược truyền lại bản thân tầng đó trong 1 số bước nhất định. \r\nhồi quy ở dạng thức trải dài. Trong ví dụ này, ta xem xét một câu bao gồm 3 từ. Tầng \r\n\r\nhồi quy sẽ được trải thành 3 tầng tính toán, mỗi tầng tương ứng với 1 từ. \r\n\r\n \r\n\r\n\r\nTrong hình 1.3, với đầu vào x là một chuỗi các từ, ta có: \r\n\r\n\r\n\r\n23 \r\n\r\n\r\n xt là một từ đơn (đầu vào tại bước t).  \r\n\r\n st là trạng thái ẩn tại bước t. Nó chính là bộ nhớ của mạng. st được tính toán dựa \r\n\r\ntrên cả các trạng thái ẩn phía trước và đầu vào tại bước đó.  \r\n\r\n ot là đầu ra tại bước t (kết quả dự đoán từ tiếp theo) \r\n\r\nMột trong các mô hình ứng dụng kiến trúc RNN trong xử lý ngôn ngữ tự nhiên là \r\n\r\nmô hình seq2seq (sequence-to-sequence hay tên gọi khác là encoder-decoder). Về cơ \r\n\r\nbản, mô hình seq2seq được xây dựng dựa trên hai mạng RNN đóng vai trò là các bộ mã \r\n\r\nhóa, giải mã. \r\n\r\nÁp dụng mô hình seq2seq vào bài toán tóm tắt văn bản: \r\n\r\n Bộ mã hoá (encoder) sẽ truyền vào từng từ một trong văn bản đầu vào. Mỗi từ \r\n\r\n(token) sau đó sẽ được đi qua một lớp embedding để biểu diễn từ đó về dạng vector \r\n\r\nsố. Vector này sau đó sẽ được đi qua các lớp ẩn, ở mỗi lớp nó lại được kết hợp với \r\n\r\nnhững lớp ẩn được sinh ra từ token phía trước, đối với từ đầu tiên thì tất cả các giá \r\n\r\ntrị này đều bằng 0.  \r\n\r\n Bộ giải mã (decoder) sẽ nhận layer ẩn cuối cùng của bộ mã hoá kết hợp với token \r\n\r\n<eos> (kí tự kết thuc câu) là đầu vào. Sau đó bộ giải mã sẽ sinh từng từ một và dừng \r\n\r\nlại khi sinh đến kí tự <eos>. \r\n\r\nĐể xây dựng mô hình sử dụng phương pháp Deep Learning, chung ta cần một bộ dữ \r\n\r\nliệu đầu vào lớn và một máy tính mạnh để tính toán. Tuy nhiên, hiện tại, đối với bài toán \r\n\r\ntóm tắt văn bản, chưa có bô dữ liệu đủ lớn vào đầu vào chuẩn thỏa mãn yêu cầu.  \r\n\r\n\r\n\r\n24 \r\n\r\n\r\n3.5. Đánh giá tóm tắt văn bản \r\n\r\n Độ đo chính xác (precision) [30]: là tỉ số giữa số lượng các câu được cả hệ thống \r\n\r\nvà con người trích xuất trên số các câu được hệ thống trích xuất. \r\n\r\nrecision = \r\n|SM|\r\n\r\n| SM | | SH |\r\n \r\n\r\n Độ đo hồi tưởng (recall) [30]: là tỉ số giữa số lượng các câu được trích xuất bởi cả \r\n\r\nhệ thống và con người trích xuất trên số các câu chỉ được lựa chọn bởi con người. \r\n\r\nRecall =  \r\n|SH|\r\n\r\n| SM | | SH |\r\n \r\n\r\n| SM | là số lượng câu của bản tóm tắt do hệ thống trích xuất \r\n\r\n| H | là số lượng câu của bản tóm tắt do con người trích xuất (lý tưởng) \r\n\r\n| H  M | là số lượng câu được cả hệ thống và con người trích xuất. \r\n\r\n Đánh giá dựa trên nội dung \r\n\r\nĐộ đo ROUGE (Recall-Oriented Understudy for Gisting Evaluation) [29]: là \r\n\r\nmột tập các độ đo so sánh sự tương đồng của bản tóm tắt của một hệ thống tóm tắt tự \r\n\r\nđộng và bản tóm tắt lý tưởng (do con người tóm tắt). \r\n\r\n ROUGE  N  \r\n\r\nn-gram là một dãy gồm n ký tự (hoặc âm tiết, từ) liên tiếp nhau trong văn bản. \r\n\r\nROUGE  N sử dụng n-gram đánh giá sự tương quan giữa các kết quả của văn \r\n\r\nbản tóm tắt và tập dữ liệu đánh giá. Công thức:  \r\n\r\n( )\r\n\r\n( )\r\n\r\n\r\nmatch\r\n\r\nS RS n gram S\r\n\r\nS RS n gram S\r\n\r\nCount n gram\r\n\r\nCount\r\nROUGE\r\n\r\nam\r\nN\r\n\r\nn gr\r\n\r\n  \r\n\r\n  \r\n\r\n\r\n\r\n\r\n\r\n\r\n \r\n\r\n   \r\n\r\n S: là bản tóm tắt của hệ thống \r\n\r\n RS: Reference Summaries - tập bản tóm tắt lý tưởng \r\n\r\n  (n-): là số lượng n-gram trùng nhau lớn nhất giữa bản tóm tắt \r\n\r\nhệ thống và tập bản tóm tắt lý tưởng. \r\n\r\n (n-): Số lượng n-gram có trong tập bản tóm tắt lý tưởng. \r\n\r\nNhư vậy, độ đo ROUGE-N thuộc dạng độ đo hồi tưởng (recall-related). \r\n\r\n\r\n\r\n25 \r\n\r\n\r\nROUGE-1 là độ trùng lặp unigrams giữa bản tóm tắt của hệ thống và tập bản tóm \r\n\r\ntắt mẫu. ROUGE-2 là độ trùng lặp bigrams giữa bản tóm tắt của hệ thống và tập bản \r\n\r\ntóm tắt mẫu. \r\n\r\nCũng có một lưu ý rằng, số lượng n-gram ở mẫu số trong công thức tính ROUGE-\r\n\r\nN sẽ tăng lên khi chung ta cho thêm nhiều tham chiếu. Điều này hoàn toàn trực quan và \r\n\r\nhợp lí bởi vì có thể tồn tại nhiều bản tóm tắt tốt. \r\n\r\n Mỗi khi chúng ta thêm một tham chiếu vào tập các văn bản tham chiếu, chúng ta \r\n\r\nđa mở rộng không gian các văn bản tóm tắt thay thế (alternative summaries). Bằng cách \r\n\r\nđiều khiển các kiểu tham chiếu mà ta thêm vào tập văn bản tham chiếu, chúng ta có thể \r\n\r\nthiết kế các đánh giá tập trung vào các khía cạnh khác nhau của việc tóm tắt. Ngoài ra, \r\n\r\ntổng tử số lớn hơn tổng số số bản tóm tắt tham chiếu. Điều này hiệu quả vì cung cấp \r\n\r\nthêm nhiều trọng số để so khớp các n-grams xảy ra trong đa tham chiếu. Do đó, một bản \r\n\r\ntóm tắt tự động càng chứa nhiều những từ được xuất hiện trong nhiều bản tóm tắt tham \r\n\r\nchiếu thì sẽ dành được điểm ROUGE-N càng cao. Điều này một lần nữa lại rất trực quan \r\n\r\nvà hợp lí bởi vì chung ta thường ưu tiên các bản tóm tắt tự động càng có nhiều nét giống \r\n\r\nvới các điểm giống nhau giữa các bản tóm tắt tham chiếu càng tốt. \r\n\r\n Khi sử dụng đa tham chiếu, chúng ta tính ROUGE-N theo từng cặp, giữa bản tóm \r\n\r\ntắt tự động s và từng bản tóm tắt tham chiếu ri trong tập các văn bản tóm tắt tham chiếu. \r\n\r\nSau đó, kết quả điểm ROUGE-N cuối cùng trong đa tham chiếu sẽ là điểm ROUGE-N \r\n\r\ncao nhất trong tất cả các cặp được tính. Điều này được thể hiện theo công thức sau: \r\n\r\n   =   ( , ) \r\n Trong quá trình khởi tạo, thuật toán đánh giá sử dụng thủ tục Jackknifing. Cho \r\n\r\nM tham chiếu, chung ta tính điểm tốt nhất khi duyệt qua M tập tham chiếu M-1; điểm \r\n\r\nROUGE-N cuối cùng là trung bình cộng của M điểm ROUGE-N đối với các tham chiếu \r\n\r\nM-1. Thủ tục Jackknifing được chọn bởi chung ta thường cần so sánh hiệu suất giữa \r\n\r\ncon người và hệ thống và bản tóm tắt tham chiếu thường chỉ do con người tạo ra. \r\n\r\n Bằng cách áp dụng thủ tục này, chúng ta có thể ước lượng hiệu suất trung bình \r\n\r\ncủa con người bằng việc lấy trung bình cộng M điểm ROUGE-N của một bản tham chiếu \r\n\r\nvới toàn bộ M-1 tham chiếu. \r\n\r\n ROUGE  L (Longest Common Subsequence  Chuỗi con chung dài nhất) \r\n\r\nĐộ đo này tính tỷ lệ giữa độ dài chuỗi chung dài nhất của bản tóm tắt hệ thống và \r\n\r\nbản tóm tắt lý tưởng. \r\n\r\nLCS tìm ra độ dài của chuỗi con chung dài nhất giữa văn bản X và Y, độ dài của \r\n\r\nchuỗi con chung dài nhất càng lớn thì 2 văn bản X, Y càng giống nhau. \r\n\r\n\r\n\r\n26 \r\n\r\n\r\n \r\n\r\n ength() là độ dài của X; ength() là độ dài của Y;  \r\n\r\n dit(,) là khoảng cách biên tập giữa X và Y (là số lượng tối thiểu của việc xóa và \r\n\r\nchèn thêm cần thiết để biến đổi X thành Y). \r\n\r\n \r\n\r\n m là độ dài của bản tóm tắt lý tưởng X, n là độ dài của bản tóm tắt hệ thống Y. \r\n\r\n R là độ đo recall của X và Y, P là độ đo precision giữa X và Y. \r\n\r\n ROUGE-W (Weighted Longest Common Subsequence) \r\n\r\nTrọng số của chuỗi chiều dài lớn nhất, là mở rộng của ROUGE-L. \r\n\r\n ROUGE S (Skip-Bigram Co-Occurrence Statistics) \r\n\r\n \r\n\r\n SKIP2(X,Y) là số lượng bigram chung giữa X và Y.  \r\n\r\n R là độ hồi tưởng giữa X và Y, P là độ chính xác giữa X và Y.  \r\n\r\n\r\n\r\n27 \r\n\r\n\r\nCHƯƠNG 2: HƯỚNG GIẢI QUYẾT ĐỀ TÀI \r\n\r\n1. Bài toán cụ thể \r\n\r\nTrong các nghiên cứu gần đây, bài toán tóm tắt văn bản thường được tiếp cận bởi \r\n\r\ncác phương pháp học máy không giám sát. Phương pháp này thường giảm chi phí khi \r\n\r\nxây dựng bộ dữ liệu, giảm độ phức tạp tính toán thông qua mô hình học máy. Tuy nhiên, \r\n\r\nđộ chính xác phương pháp tiếp cận này của tóm tắt văn bản không cao, vì phương pháp \r\n\r\nnày chỉ chọn câu vào văn bản tóm tắt bằng cách tính toán điểm của câu dựa trên kết hợp \r\n\r\ncác đặc trưng rồi chọn câu có điểm số cao. \r\n\r\nVì vậy, để giảm thời gian tính toán, nâng cao chất lượng, độ chính xác tóm tắt \r\n\r\nthông qua việc lựa chọn bộ dữ liệu được huấn luyện bởi các chuyên gia, em lựa chọn mô \r\n\r\nhình học có giám sát Naive Bayes áp dụng cho bài toán tóm tắt đơn văn bản theo hướng \r\n\r\ntrích xuất. Hiện nay chưa có bộ dữ liệu huấn luyện chuẩn phục vụ tóm tắt trích xuất cho \r\n\r\ntiếng Việt, nên em xây dựng hệ thống tóm tắt văn bản tiếng Anh. \r\n\r\nNave Bayes là một phương pháp học máy có giám sát, tốc độ xử lý nhanh và cho \r\n\r\nkết quả có độ chính xác tương đối cao. Để cải thiện độ chính xác của mô hình, em sử \r\n\r\ndụng giải thuật AdaBoost. \r\n\r\nĐồ án sử dụng tập dữ liệu của DUC [13] để huấn luyện và thực nghiệm. DUC \r\n\r\n(Document Understanding Conference) là một hội nghị quốc tế để đánh giá hiệu suất \r\n\r\ncủa hệ thống tóm tắt bằng cách so sánh bản tóm tắt bằng tay của các chuyên gia với bản \r\n\r\ntóm tắt tự động của máy tính.  \r\n\r\nCác bộ dữ liệu phục vụ tóm tắt đơn văn bản của DUC như DUC2004, DUC2003 \r\n\r\nchỉ đưa ra bản tóm tắt rất ngắn (khoảng 100 ký tự) không phù hợp với yêu cầu bài toán, \r\n\r\nnên không thể sử dụng các bộ dữ liệu này.  \r\n\r\nDo đó, em sử dụng bộ dữ liệu DUC2007. Đây là bộ dữ liệu dùng cho tác vụ tóm \r\n\r\ntắt đa văn bản, gồm 45 cụm văn bản, mỗi cụm gồm 25 văn bản là các bài báo có cùng \r\n\r\nchủ đề. Để phù hợp với bài toán tóm tắt đơn văn bản, ta ghép các văn bản trong mỗi cụm \r\n\r\nvăn bản đó thành một đơn văn bản. Tập bản tóm tắt mẫu sử dụng cho hệ thống là bản \r\n\r\ntóm tắt của 4 chuyên gia, mỗi bản dài 250 từ, do đó bản tóm tắt của hệ thống cũng có độ \r\n\r\ndài không quá 250 từ. Độ chính xác văn bản tóm tắt của hệ thống được so với cả 4 văn \r\n\r\nbản của chuyên gia. \r\n\r\nBộ dữ liệu huấn luyện của DUC2007 gồm các văn bản dạng SCU, được hỗ trợ \r\n\r\nđánh dấu các câu quan trọng có liên quan đến các câu trong bản tóm tắt của chuyên gia.  \r\n\r\n\r\n\r\n28 \r\n\r\n\r\n2. Cơ sở lý thuyết \r\n\r\n2.1. Phương pháp Nave Bayes \r\n\r\nXét bài toán phân lớp với C classes: 1,2,.,C.  \r\n\r\nGiả sử có một điểm dữ liệu x  Rd. Tính xác suất để điểm dữ liệu này rơi vào \r\n\r\nclass c. Nói cách khác, cần tính xác suất p(y=c|x) hay p(c|x) (xác suất có điều kiện cho \r\n\r\nmỗi lớp với mỗi giá trị x) để đầu ra là class c biết rằng đầu vào là vector x [8]. \r\n\r\nXác định được xác suất để điểm dữ liệu rơi vào mỗi class sẽ giup chung ta xác \r\n\r\nđịnh class của điểm dữ liệu đó bằng cách chọn ra class có xác suất cao nhất: \r\n\r\n \r\n{1,...,C}\r\n\r\narg |max\r\nc\r\n\r\nc p c\r\n\r\n\r\n x     (1) \r\n\r\nBiểu thức (1) thường khó được tính trực tiếp. Thay vào đó, quy tắc Bayes thường \r\n\r\nđược sử dụng: \r\n\r\n arg |max\r\nc\r\n\r\nc p c x  \r\n\r\nÁp dụng quy tắc Bayes p(c|x).p(x) = p(x|c).p(c) ta có: \r\n\r\n \r\n   |\r\n\r\narg\r\n( )\r\n\r\nmax\r\nc\r\n\r\np c p c\r\nc\r\n\r\np\r\n\r\n\r\nx\r\n\r\nx\r\n \r\n\r\nDo mẫu số p(x) không phụ thuộc vào c nên: \r\n\r\n   arg |max\r\nc\r\n\r\nc p c p c x   \r\n\r\nXác suất của mỗi lớp p(c) có thể được hiểu là xác suất để một điểm rơi vào class c. \r\n\r\nGiá trị này có thể được tính tỉ lệ số điểm dữ liệu trong tập training rơi vào class c chia \r\n\r\ncho tổng số lượng dữ liệu trong tập training. \r\n\r\nThành phần còn lại p(x|c), tức phân phối của các điểm dữ liệu trong class c, \r\n\r\nthường rất khó tính toán vì x là một biến ngẫu nhiên nhiều chiều, cần rất rất nhiều dữ \r\n\r\nliệu training để có thể xây dựng được phân phối đó. Để giup cho việc tính toán được đơn \r\n\r\ngiản, người ta thường giả sử một cách đơn giản nhất rằng các thành phần của biến ngẫu \r\n\r\nnhiên x là độc lập, nếu biết c. Tức là: \r\n\r\n   1\r\n1\r\n\r\n2| | (, |, , )d\r\n\r\nd\r\n\r\ni\r\n\r\ni\r\n\r\np x cp c p x x x c\r\n\r\n\r\n  x   \r\n\r\nGiả thiết các chiều của dữ liệu độc lập với nhau, nếu biết c, là quá chặt và ít khi \r\n\r\ntìm được dữ liệu mà các thành phần hoàn toàn độc lập với nhau. Tuy nhiên, giả thiết này \r\n\r\n\r\n\r\n29 \r\n\r\n\r\nlại mang lại những kết quả tốt bất ngờ. Cách xác định class của dữ liệu dựa trên giả thiết \r\n\r\nnày có tên là Naive Bayes Classifier. \r\n\r\nNaive Bayes Classifier là một thuật toán đơn giản nhưng mạnh mẽ về mô hình \r\n\r\ndự đoán. Naive Bayes Classifier được gọi là naive vì nó giả định rằng mỗi biến đầu vào \r\n\r\nlà độc lập. Đây là một giả định mạnh mẽ và không thực tế đối với dữ liệu thực, tuy nhiên, \r\n\r\nkĩ thuật này rất hiệu quả trên một phạm vi rộng lớn với các vấn đề phức tạp. \r\n\r\n \r\n\r\n\r\nNaive Bayes Classifier có tốc độ training và test rất nhanh. Việc này giup nó \r\n\r\nmang lại hiệu quả cao trong các bài toán large-scale. \r\n\r\nỞ bước training, các phân phối p(c) và p(xi|c), i=1,., d sẽ được xác định dựa \r\n\r\nvào training data. \r\n\r\nỞ bước test, với một điểm dữ liệu mới x, class của nó được xác định bởi: \r\n\r\n \r\n{1,...,C}\r\n\r\n1\r\n\r\narg ( | )max\r\nd\r\n\r\ni\r\nc\r\n\r\ni\r\n\r\nc p p x cc\r\n\r\n\r\n\r\n\r\n   (2) \r\n\r\nKhi d lớn và các xác suất nhỏ, biểu thức ở vế phải của (2) sẽ là một số rất nhỏ, \r\n\r\nkhi tính toán có thể gặp sai số. Để giải quyết việc này, (2) thường được viết lại dưới dạng \r\n\r\ntương đương bằng cách lấy log của vế phải: \r\n\r\n\r\n\r\n30 \r\n\r\n\r\n  \r\n{1,...,C}\r\n\r\n1\r\n\r\narg log ( ( | ))max\r\nd\r\n\r\nX i\r\nc\r\n\r\ni\r\n\r\nc log p p x cc\r\n\r\n\r\n\r\n\r\n    \r\n\r\nViệc này không ảnh hưởng tới kết quả vì loglog là một hàm đồng biến trên tập \r\n\r\ncác số dương. \r\n\r\nCả việc training và test của NBC là cực kỳ nhanh khi so với các phương pháp \r\n\r\nclassification phức tạp khác. Việc giả sử các thành phần trong dữ liệu là độc lập với nhau, \r\n\r\nnếu biết class, khiến cho việc tính toán mỗi phân phối p(xi|c) trở nên cực kỳ nhanh. \r\n\r\nMỗi giá trị p(c), c = 1, 2,., C có thể được xác định như là tần suất xuất hiện của \r\n\r\nclass c trong training data. \r\n\r\nViệc tính toán p(xi|c) phụ thuộc vào loại dữ liệu. Có ba loại được sử dụng phổ \r\n\r\nbiến là: Gaussian Naive Bayes, Multinomial Naive Bayes, và Bernoulli Naive. \r\n\r\n \r\n\r\n2.1.1. Gaussian Naive Bayes \r\n\r\nMô hình này được sử dụng chủ yếu trong loại dữ liệu mà các thành phần là các biến \r\n\r\nliên tục. Với mỗi chiều dữ liệu i và một class ci, xi tuân theo một phân phối chuẩn có kỳ \r\n\r\nvọng ci  và phương sai \r\n2\r\n\r\nci [8]: \r\n\r\n2\r\n2\r\n\r\n22\r\n\r\n( )1\r\n( | ) ( | , ) exp\r\n\r\n22\r\n\r\nci\r\ni i ci ci\r\n\r\ncici\r\n\r\nx\r\np x c p x\r\n\r\n\r\n \r\n\r\n\r\n\r\n \r\n   \r\n\r\n \r\n \r\n\r\nTrong đó, bộ tham số  = { ci , \r\n2\r\n\r\nci } được xác định bằng: \r\n\r\n2\r\n\r\n2 ( ) 2\r\n\r\n,\r\n1\r\n\r\n( , ) arg ( | )max\r\nci ci\r\n\r\nN\r\nn\r\n\r\nci ci i ci\r\n\r\ni\r\n\r\np x\r\n \r\n\r\n  \r\n\r\n\r\n   \r\n\r\n2.1.2. Multinomial Naive Bayes \r\n\r\nMô hình này chủ yếu được sử dụng trong phân loại văn bản mà feature vectors được \r\n\r\ntính bằng Bags of Words. Luc này, mỗi văn bản được biểu diễn bởi một vector có độ dài \r\n\r\nd chính là số từ trong từ điển. Giá trị của thành phần thứ i trong mỗi vector chính là số \r\n\r\nlần từ thứ i xuất hiện trong văn bản đó. \r\n\r\nKhi đó, p(xi|c) tỉ lệ với tần suất từ thứ i (hay feature thứ i cho trường hợp tổng \r\n\r\nquát) xuất hiện trong các văn bản của class c. Giá trị này có thể được tính bằng cách: \r\n\r\n | cici\r\nc\r\n\r\nip x c\r\nN\r\n\r\nN\r\n    \r\n\r\n \r\n\r\nhttp://scikit-learn.org/dev/modules/classes.html#module-sklearn.naive_bayes\r\nhttp://scikit-learn.org/dev/modules/classes.html#module-sklearn.naive_bayes\r\n\r\n\r\n31 \r\n\r\n\r\nTrong đó: \r\n\r\n- ciN  là tổng số lần từ thứ i xuất hiện trong các văn bản của class c, nó được tính là tổng \r\n\r\ncủa tất cả các thành phần thứ i của các feature vectors ứng với class c. \r\n\r\n- cN  là tổng số từ (kể cả lặp) xuất hiện trong class c. Nói cách khác, nó bằng tổng độ \r\n\r\ndài của toàn bộ các văn bản thuộc vào class c. Có thể suy ra rằng: \r\n\r\n1\r\n\r\nd\r\n\r\nc ci\r\n\r\ni\r\n\r\nN N\r\n\r\n\r\n  từ đó \r\n1\r\n\r\n1\r\nd\r\n\r\nci\r\n\r\ni\r\n\r\n\r\n\r\n\r\n  [8] \r\n\r\nCách tính này có một hạn chế là nếu có một từ mới chưa bao giờ xuất hiện trong \r\n\r\nclass c thì biểu thức (1) sẽ bằng 0. Việc này sẽ dẫn đến kết quả không chính xác. Để giải \r\n\r\nquyết việc này, một kỹ thuật được gọi là Laplace smoothing được áp dụng: \r\n\r\n' ci\r\ni\r\n\r\nc\r\n\r\nc\r\n\r\nN d\r\n\r\nN\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n \r\n\r\nVới  là một số dương, thường bằng 1, để tránh trường hợp tử số bằng 0. Mẫu số được \r\n\r\ncộng với d để đảm bảo tổng xác suất  \r\n1\r\n\r\n1\r\nd\r\n\r\nci\r\n\r\ni\r\n\r\n\r\n\r\n\r\n  \r\n\r\nNhư vậy, mỗi class c sẽ được mô tả bởi bộ các số dương có tổng bằng 1: \r\n\r\n' ' '\r\n\r\n1,  { },ci c cd    . \r\n\r\n2.1.3. Bernoulli Naive Bayes \r\n\r\nMô hình này được áp dụng cho các loại dữ liệu mà mỗi thành phần là một giá trị \r\n\r\nbinary - bẳng 0 hoặc 1. Ví dụ: cũng với loại văn bản nhưng thay vì đếm tổng số lần xuất \r\n\r\nhiện của 1 từ trong văn bản, ta chỉ cần quan tâm từ đó có xuất hiện hay không. Khi đó, \r\n\r\np(xi|c) được tính bằng: \r\n\r\np(xi|c) = p(i|c)xi + (1p(i|c)(1xi) \r\n\r\nvới p(i|c) là xác suất từ thứ i xuất hiện trong các văn bản của class c [8]. \r\n\r\n  \r\n\r\n\r\n\r\n32 \r\n\r\n\r\n2.2. Thuật toán AdaBoost \r\n\r\n2.2.1. Giới thiệu về thuật toán boosting \r\n\r\nVề lịch sử, boosting bắt nguồn từ câu hỏi nổi tiếng được đưa ra bơi Kearns vào \r\n\r\nnăm 1989: Liệu có thể tạo ra một strong classifier từ một tập các weak learner?. Năm \r\n\r\n1990, Robert Schaire và Simard kiểm nghiệm trong các chương trình nhận dạng [26]. \r\n\r\nFreund đa tiếp tục các nghiên cứu của Schaprire, và đến năm 1995 thì ông cùng Schaprire \r\n\r\nphát triển boosting thành AdaBoost. \r\n\r\nBoosting là thuật toán đồng bộ (ensemble algorithms) bằng cách xây dựng nhiều \r\n\r\nthuật toán học cùng lúc (gọi là các weak learner) và kết hợp chúng lại để tạo ra một \r\n\r\nstrong learner duy nhất [40]. Các weak learner chỉ cần có độ chính xác trên 50%, được \r\n\r\nhuấn luyện độc lập và kết quả dự đoán cuối cùng mô hình boosting dựa trên kết quả bỏ \r\n\r\nphiếu của từng mô hình con đó cho kết quả đầu ra. Bằng cách này, chúng ta nói bộ phân \r\n\r\nloại đa được boost. \r\n\r\nĐể hiểu cách hoạt động của thuật toán boosting, ta xét một bài toán phân loại 2 \r\n\r\nlớp (mẫu cần nhận dạng chỉ thuộc một trong hai lớp) với D là tập huấn luyện gồm có n \r\n\r\nmẫu. Trước tiên, chúng ta sẽ chọn ngẫu nhiên ra n1 mẫu từ tập D tạo thành tập D1. Sau \r\n\r\nđó, chung ta sẽ xây dựng weak learner đầu tiên C1 từ tập D1. Tiếp theo, chúng ta xây \r\n\r\ndựng tập D2 để huấn luyện bộ phân loại C2. D2 sẽ được xây dựng sao cho một nửa số \r\n\r\nmẫu của nó được phân loại đung bởi C1 và nửa còn lại bị phân loại sai bởi C1. Bằng cách \r\n\r\nnày, D2 chứa đựng những thông tin bổ sung cho C1. Bây giờ chung ta sẽ xây huấn luyện \r\n\r\nC2 từ D2. Tiếp theo, chúng ta sẽ xây dựng tập D3 từ những mẫu không được phân loại tốt \r\n\r\nbởi sự kết hợp giữa C1 và C2: những mẫu còn lại trong D mà C1 và C2 cho kết quả khác \r\n\r\nnhau. Như vậy, D3 sẽ gồm những mẫu mà C1 và C2 hoạt động không hiệu quả. Sau cùng, \r\n\r\nchúng ta sẽ huấn luyện bộ phân loại C3 từ D3. Bây giờ chung ta đa có một strong \r\n\r\nclassifier: sự kết hợp C1, C2 và C3. Khi tiến hành nhận dạng một mẫu X, kết quả sẽ được \r\n\r\nquyết định bởi sự thỏa thuận của 3 bộ C1, C2 và C3: Nếu cả C1 và C2 đều phân X vào \r\n\r\ncùng một lớp thì lớp này chính là kết quả phân loại của X; ngược lại, nếu C1 và C2 phân \r\n\r\nX vào 2 lớp khác nhau, C3 sẽ quyết định X thuộc về lớp nào. \r\n\r\n\r\n\r\n33 \r\n\r\n\r\n \r\n\r\n\r\nMột số phương pháp boosting đáng chu ý: \r\n\r\n- Adaboost (Adaptive Boosting) \r\n\r\n- Gradient Boosting \r\n\r\n- XGBoost \r\n\r\n \r\n\r\n2.2.2. Thuật toán AdaBoost \r\n\r\nAdaBoost là thuật toán boosting thành công đầu tiên được phát triển để phân loại \r\n\r\nnhị phân, được Freund và Schapire đưa ra vào năm 1995 [35]. Đây là điểm khởi đầu tốt \r\n\r\nnhất để hiểu về boosting.  \r\n\r\n Tư tưởng của thuật toán AdaBoost đấy là kết hợp các weak learner thành một \r\n\r\nstrong learner. Trong quá trình xây dựng, weak learner tiếp theo sẽ được xây dựng dựa \r\n\r\ntrên các đánh giá về các weak learner trước, cuối cùng các weak learner sẽ được kết hợp \r\n\r\nđể trở thành strong learner. \r\n\r\nĐể có thể kết hợp các weak learner, AdaBoost sử dụng một trọng số (weight) để \r\n\r\nđánh dấu các mẫu khó nhận dạng. Trong quá trình huấn luyện, cứ mỗi weak learner được \r\n\r\nxây dựng, thuật toán sẽ tiến hành cập nhật lại trọng số để chuẩn bị cho việc xây dựng \r\n\r\nweak learner tiếp theo: tăng trọng số của các mẫu bị nhận dạng sai và giảm trọng số của \r\n\r\ncác mẫu được nhận dạng đung bởi weak learner vừa xây dựng. Bằng cách này, các weak \r\n\r\nlearner sau có thể tập trung vào các mẫu mà các weak learner trước đó chưa thực hiện \r\n\r\ntốt. Sau cùng các weak learner sẽ được kết hợp tùy theo mức độ tốt của chung để tạo \r\n\r\nnên một strong classifier.  \r\n\r\n\r\n\r\n34 \r\n\r\n\r\n \r\n\r\n\r\n Các bước xây dựng mô hình AdaBoost: \r\n\r\n(1) Xét tập dữ liệu huấn luyện gồm n mẫu có đánh dấu (x1,y1), (x2,y2),. (xn,yn) với \r\n\r\nxk  (xk1, xk2, ., xkm) là vector đặc trưng, yi {+1,1} là lớp của mẫu. \r\n\r\nTrọng số khởi tạo cho mỗi mẫu có giá trị: \r\n\r\nw(xi) = \r\n1\r\n\r\n\r\n, i = 1, ., n \r\n\r\n(2) Xây dựng mô hình M weak classifiers h, h cho kết quả phân loại là +1 hoặc  -1. \r\n\r\nLặp m = 1,., M: \r\n\r\n Với mỗi đặc trưng trong vector đặc trưng, xây dựng một weak classifier hj với \r\n\r\ntrọng số phân loại sai j . j  được tính bằng công thức: \r\n\r\n\r\n\r\n35 \r\n\r\n\r\n: ( )\r\n\r\nw( )\r\ni i\r\n\r\ni\r\n\r\ni h\r\n\r\nj\r\n\r\nx y\r\n\r\nx\r\n\r\n\r\n   \r\n\r\n Chọn hm có trọng số phân loại sai m   thấp nhất. \r\n\r\n Cập nhật lại trọng số của mẫu: \r\n\r\n1\r\n\r\nw ( )*exp( h ( ))\r\nw ( ) m i m i m im i\r\n\r\nm\r\n\r\nx y x\r\nx\r\n\r\nZ\r\n\r\n\r\n\r\n\r\n\r\n  \r\n\r\nVới: \r\n\r\nZm là hệ số chuẩn hóa để đảm bảo tổng trọng số các mẫu bằng 1. \r\n\r\n11\r\nln\r\n\r\n2\r\n\r\nm\r\n\r\nm\r\n\r\nm\r\n \r\n\r\n  \r\n \r\n\r\n \r\n\r\nTa thấy, hàm lũy thừa exp( h ( ))m i m iy x  trên tử số sẽ luôn có giá trị lớn hơn 1 \r\n\r\n(do với mẫu phân loại sai thì tích h ( ) 1i m iy x   , m > 0 nên h ( )i m i my x   < 0 ).  \r\n\r\nVì vậy, các trường hợp mẫu phân loại sai sẽ được cập nhật với trọng số lớn hơn \r\n\r\nsau mỗi lần lặp. \r\n\r\n(3) Sau khi lặp M weak classifier, chung ta có thể nhận được dự đoán cuối cùng bằng \r\n\r\ncách tổng kết dự đoán trọng số của mỗi weak classifier. Strong classifier H(x) \r\n\r\nđược xây dựng như sau: \r\n\r\n1\r\n\r\n( ) ( )\r\nM\r\n\r\nm m\r\n\r\nm\r\n\r\nH x sign h x\r\n\r\n\r\n \r\n  \r\n\r\n \r\n  \r\n\r\n \r\n\r\n Giải thích \r\n\r\nQuá trình huấn luyện bộ phân loại được thực hiện bằng một vòng lặp mà ở mỗi \r\n\r\nbước lặp, thuật toán sẽ chọn ra bộ phân loại yếu hm có trọng số phân loại sai nhỏ nhất \r\n\r\nm  (do đó sẽ là weak classifier) để bổ sung vào strong classifier. Mỗi khi chọn được 1 \r\n\r\nweak classifier hm, AdaBoost sẽ tính giá trị m theo công thức ở trên, m  cũng được chọn \r\n\r\ntrên nguyên tắc làm giảm giá trị trọng số phân loại sai m . \r\n\r\n\r\n\r\n36 \r\n\r\n\r\nHệ số m  nói lên mức độ quan trọng của hm. Thật vậy: \r\n\r\n- Trong công thức phân loại H(x): \r\n\r\n1\r\n\r\n( ) ( )\r\nM\r\n\r\nm m\r\n\r\nm\r\n\r\nH x sign h x\r\n\r\n\r\n \r\n  \r\n\r\n \r\n  \r\n\r\nTa thấy tất cả các weak classifier hm đều có đóng góp vào kết quả phân loại của \r\n\r\nH(x), và mức độ đóng góp của chung phụ thuộc vào giá trị m  tương ứng: hm với m  \r\n\r\ncàng lớn thì nó càng có vai trò quan trọng H(x). \r\n\r\n- Trong công thức tính m : \r\n\r\n11\r\nln\r\n\r\n2\r\n\r\nm\r\n\r\nm\r\n\r\nm\r\n \r\n\r\n  \r\n \r\n\r\n \r\n\r\nTa thấy giá trị m  tỉ lệ nghịch với m . Bởi hm được chọn với tiêu chí đạt trọng số \r\n\r\nphân loại sai nhỏ nhất, do đó nó sẽ đảm bảo giá trị m  lớn nhất. Công thức này do Fruend \r\n\r\nvà Schapire đưa ra. \r\n\r\nSau khi tính được giá trị m , AdaBoost tiến hành cập nhật lại trọng số của các \r\n\r\nmẫu thông qua việc tăng trọng số các mẫu mà hm phân loại sai, giảm trọng số mà các hm \r\n\r\nphân loại đung. Bằng cách này, trọng số của mẫu phản ảnh được mức độ khó nhận dạng \r\n\r\ncủa mẫu đó và hm+1 sẽ ưu tiên học cách phân loại những mẫu này. \r\n\r\nAdaBoost là thuật toán đơn giản và dễ dàng cài đặt. Thêm vào đó, tốc độ học rất \r\n\r\nnhanh. Các weak learner đơn giản hơn rất nhiều các strong learner, nhờ vậy thuật toán \r\n\r\nchạy nhanh hơn. \r\n\r\nMột điều nữa, AdaBoost là phương pháp có khả năng điều chỉnh các classifier rất \r\n\r\ntinh tế. Vì mỗi hiệp AdaBoost lại tinh chỉnh lại các trọng số cho các learner tốt nhất. \r\n\r\nĐiều bạn cần làm đó là xác định số hiệp để lặp. \r\n\r\nCuối cùng, đây là thuật toán linh hoạt và đa năng. AdaBoost có thể kết hợp với \r\n\r\nbất kỳ thuật toán học máy nào và nó có thể làm việc với một lượng lớn dữ liệu khác nhau.   \r\n\r\n\r\n\r\n37 \r\n\r\n\r\n3. Mô hình đề xuất \r\n\r\nTóm tắt đơn văn bản là một quá trình tóm tắt tự động với đầu vào là một văn bản, \r\n\r\nđầu ra là một đoạn văn bản ngắn gọn mô tả nội dung chính của văn bản đầu. Đơn văn \r\n\r\nbản có thể là một trang Web, một bài báo, một tài liệu dạng văn bản (ví dụ: .doc, .txt)... \r\n\r\nTóm tắt văn bản đơn là bước làm cơ sở cho việc xử lý tóm tắt đa văn bản và các bài toán \r\n\r\ntóm tắt phức tạp hơn. \r\n\r\n \r\n\r\n\r\n  \r\n\r\n\r\n\r\n38 \r\n\r\n\r\n3.1. Khối tiền xử lý văn bản \r\n\r\nBước tiền xử lý gồm 2 hoạt động chính là Chuẩn hoá từ và Loại bỏ các cấu \r\n\r\ntruc ngữ pháp của từ, đưa về dạng nguyên thể trong tiếng Anh. \r\n\r\nCả hai hoạt động này đều đóng vai trò quan trọng trong việc vec-tơ hóa tài liệu \r\n\r\nbởi vì nó sẽ làm giảm không gian biểu diễn của văn bản xuống, do đó làm giảm khối \r\n\r\nlượng cần tính toán. \r\n\r\nCụ thể, quá trình tiền xử lí văn bản đầu vào bao gồm các công việc sau: \r\n\r\n Chia văn bản đầu vào thành tập các câu. \r\n\r\n Loại bỏ từ dừng (stopwords) \r\n\r\nTrong quá trình tính toán, stopwords là những từ được lọc trước hoặc sau quá \r\n\r\ntrình xử lý dữ liệu ngôn ngữ tự nhiên (văn bản). Stopwords thường là những từ xuất hiện \r\n\r\nvới tần suất lớn trong một ngôn ngữ, do đó không có một danh sách các stopwords thống \r\n\r\nnhất và được sử dụng bởi tất cả các công cụ xử lý ngôn ngữ tự nhiên. \r\n\r\nMột nhóm bất kì các từ có thể được chọn là một stopwords để thực hiện một mục \r\n\r\nđích nhất định. Đối với một search engine, có một số từ được xếp vào loại stop words \r\n\r\ndo sự xuất hiện thường xuyên trong các trường hợp tìm kiếm như: the, is, at, which và \r\n\r\non. Trong trường hợp này, stopwords có thể là nguyên nhân gây ra vấn đề khi tìm kiếm \r\n\r\ntheo phrases mà bao gồm những function word này, đặc biệt là khi tìm kiếm một số tên \r\n\r\nnhư: The Who, The The, hoặc Take That. Ngoài ra, một số search engine loại bỏ \r\n\r\ncác từ common words, bao gồm cả lexical words như want khỏi câu truy vấn nhằm \r\n\r\nmục đích cải thiện hiệu suất của search engine. \r\n\r\nSự phân biệt giữa function words và lexical words được đề xuất bởi C. Fries vào năm \r\n\r\n1952 và có một tầm ảnh hưởng lớn đến việc dạy tiếng Anh. \r\n\r\n Function words: Còn gọi là functors là những từ có một chut lexical meaning hoặc \r\n\r\ncó sự nhập nhằng về nghĩa và chung nhấn mạnh mối quan hệ ngữ pháp với các từ \r\n\r\nkhác trong cùng một câu, một quan điểm cụ thể hay tâm trạng của người nói. Một \r\n\r\nsố trường hợp của function words: Pronouns  đại từ (he  him, she-her,.); \r\n\r\nconjunction  liên từ hoặc auxiliary verb - trợ động từ \r\n\r\n Lexical words: Từ thực, những từ mà không phải là function word. Lexical word \r\n\r\nbao gôm: danh từ, động từ, tính từ và hầu hết trạng từ vì có một số trạng từ là \r\n\r\nfunction word như: then, why. Từ điển có thể định nghĩa một cách cụ thể một \r\n\r\nlexical word, nhưng chỉ có thể miêu tả một cách sử dụng tổng quát của function \r\n\r\nword. Ngược lại, ngữ pháp có thể miêu tả cách sử dụng của function words một \r\n\r\ncách chi tiết, nhưng lại chỉ có thể xem lexical words trong các thuật ngữ chung \r\n\r\n(general term). \r\n\r\n\r\n\r\n39 \r\n\r\n\r\n Chuẩn hóa từ bằng lemmatizing và stemming \r\n\r\no Stemming: Stemming là kĩ thuật dùng để biến đổi một từ về dạng gốc (được \r\n\r\ngọi là stem hoặc root form) bằng cách cực kì đơn giản là loại bỏ một số kí tự \r\n\r\nnằm ở cuối từ mà nó nghĩ rằng là biến thể của từ. Người ta gọi các bộ xử lí \r\n\r\nstemming là stemmer [7].  \r\n\r\nVí dụ như chung ta thấy các từ như walked, walking, walks chỉ khác nhau \r\n\r\nlà ở những ký tự cuối cùng, bằng cách bỏ đi các hậu tố -ed, -ing hoặc -s, \r\n\r\nchung ta sẽ được từ nguyên gốc là walk. \r\n\r\nBởi vì nguyên tắc hoạt động của stemmer rất đơn giản nên tốc độ xử lí của \r\n\r\nnó rất nhanh nhưng đôi khi lại cho ra kết quả không như ý muốn. \r\n\r\nVí dụ từ goes sẽ được stem thành từ goe (bỏ chữ s cuối từ) trong khi đó stem \r\n\r\ncủa từ go vẫn là go, kết quả là 2 từ goes và go sau khi được stem thì vẫn \r\n\r\nkhông giống nhau.  \r\n\r\nMột nhược điểm khác là nếu các từ dạng bất quy tắt như went hay spoke thì \r\n\r\nstemmer sẽ không thể đưa các từ này về dạng gốc là go hay speak. \r\n\r\no Lemmatization: là một kĩ thuật chuẩn hóa từ khác: Không giống với \r\n\r\nStemming là xử lí bằng cách loại bỏ các kí tự cuối từ một cách kinh nghiệm \r\n\r\n(heuristic), Lemmatization sẽ xử lí thông minh hơn bằng một bộ từ điển hoặc \r\n\r\nontology (hệ thống nhan ngữ nghĩa) nào đó. Điều này đảm bảo đưa chính xác \r\n\r\ncác dạng biến thể của từ về nguyên gốc trong từ điển. Người ta gọi bộ xử lí \r\n\r\nlemmatization là lemmatizer. Nhược điểm của lemmatization là tốc độ xử lí \r\n\r\nkhá chậm vì phải thực hiện tra cứu từ trong cơ sở dữ liệu. Trong các ứng dụng \r\n\r\nxử lí ngôn ngữ tự nhiên mà cần độ chính xác cao hơn và thời gian không quan \r\n\r\ntrọng, người ta có thể sử dụng Lemmatization [7].  \r\n\r\nVí dụ: Các từ như gose, wentsẽ được đưa chính xác về go. Các danh \r\n\r\ntừ như mouse, mice cũng được đưa về cùng một dạng như nhau. \r\n\r\n \r\n\r\n3.2. Khối tính giá trị các đặc trưng \r\n\r\n3.2.1. Đặc trưng hình thái \r\n\r\n Là các đặc trưng dựa trên cấu truc văn bản hoặc câu. Tầm quan trọng của câu dựa \r\n\r\ntrên các đặc điểm như: \r\n\r\n Câu đầu văn bản hoặc đầu đoạn văn thường quan trọng [25] \r\n\r\n Các câu ở phần trước văn bản thường quan trọng hơn những câu ở phần sau [25] \r\n\r\n Câu có số từ (không tính các từ dừng) trong một giới hạn xác định (đối với từng loại \r\n\r\nvăn bản) thường là câu quan trọng [25]. \r\n\r\n \r\n\r\n\r\n\r\n40 \r\n\r\n\r\nTrong phạm vi đồ án, em sẽ tính giá trị các đặc trưng hình thái sau: \r\n\r\n Position: Vị trí của câu trong văn bản. \r\n\r\n DocFirst: Câu có là câu đầu văn bản hay không. DocFirst bằng 1 nếu câu là câu đầu \r\n\r\nvăn bản và bằng 0 trong các tường hợp còn lại.  \r\n\r\n Length : Độ dài của câu. Ngưỡng độ dài trung bình (giá trị cutoff) được quy định cho \r\n\r\ncâu văn thuộc chủ đề báo chí là 10. Như vậy, trọng số độ dài câu tính bằng công thức: \r\n\r\nLength\r\n10S\r\n\r\nS\r\n\r\nlength\r\n\r\nlength\r\n\r\n\r\n   \r\n\r\n Với lengthS là độ dài câu S. Nếu lengthS < 10 thì coi Length = 0. \r\n\r\n \r\n\r\n3.2.2. Đặc trưng nội dung \r\n\r\nĐặc trưng nội dung thường xét: từ trọng tâm và từ có tần suất xuất hiện cao. Các \r\n\r\nđặc trưng sẽ sử dụng: \r\n\r\n Đặc trưng frequence words (từ có tần suất xuất hiện lớn): dựa vào giá trị TF của \r\n\r\ncác từ trong câu. Ở đây, em sẽ lấy ngưỡng 30% từ có tần suất xuất hiện nhiều nhất trong \r\n\r\nvăn bản. \r\n\r\nTF (term frequency) [9]  tần số xuất hiện của 1 từ trong 1 văn bản, được tính \r\n\r\nbằng công thức: \r\n\r\n \r\n \r\n\r\n \r\n\r\nf\r\n\r\nmax{f\r\n\r\n,\r\n,\r\n\r\n, : }\r\n\r\nt d\r\nt d\r\n\r\nw d w d\r\n\r\n\r\n\r\ntf   \r\n\r\nTrong đó: \r\n\r\n Thương của số lần xuất hiện 1 từ trong văn bản và số lần xuất hiện nhiều nhất của một \r\n\r\ntừ bất kỳ trong văn bản đó. (giá trị sẽ thuộc khoảng [0, 1]) \r\n\r\n f(t, d) - số lần xuất hiện từ t trong văn bản d. \r\n\r\n max{f(w, d): wd} - số lần xuất hiện nhiều nhất của một từ bất kỳ trong văn bản. \r\n\r\nTrong phạm vi đồ án, em sẽ tính đặc trưng tần suất từ đối với uni-gram và bi-\r\n\r\ngram của từng câu trong văn bản: \r\n\r\n+ FreqWordUni: tổng trọng số các uni-gram có tần suất xuất hiện cao nhất của câu S \r\n\r\ntrong văn bản d: \r\n\r\nuni\r\n\r\n(uni, )\r\nS\r\n\r\ntf dFreqWordUni\r\n\r\n\r\n   \r\n\r\nVới uni thuộc tập các uni-grams trong top 30% uni-grams có giá trị tf cao nhất trong văn \r\n\r\nbản d. \r\n\r\n+ FreqWordBi: tổng trọng số các bi-grams có tần suất xuất hiện cao nhất  \r\n\r\n\r\n\r\n41 \r\n\r\n\r\nbi\r\n\r\n(bi, )\r\nS\r\n\r\ntf dFreqWordBi\r\n\r\n\r\n  \r\n\r\nVới bi thuộc tập các bi-grams trong top 30% bi-grams có giá trị tf cao nhất trong văn \r\n\r\nbản d. \r\n\r\n Đặc trưng centroid (từ trọng tâm): dựa vào giá trị TF-IDF của các từ trong câu. \r\n\r\nTừ trọng tâm là các từ xuất hiện nhiều trong 1 văn bản nhưng xuất hiện ít trong các văn \r\n\r\nbản khác. Ở đây, em sẽ lấy ngưỡng 30% từ có giá trị TF-IDF cao nhất trong văn bản. \r\n\r\nXét khái niệm IDF (inverse document frequency) [33]  tần số nghịch của 1 từ \r\n\r\ntrong tập văn bản (corpus). Tính IDF để giảm giá trị của những từ phổ biến. Mỗi từ chỉ \r\n\r\ncó 1 giá trị IDF duy nhất trong tập văn bản. \r\n\r\n \r\n| |\r\n\r\nlog\r\n|{ :\r\n\r\n,\r\n } |\r\n\r\nt D\r\nd\r\n\r\nD\r\n\r\nD t d\r\n\r\n\r\n\r\nidf  \r\n\r\nTrong đó: \r\n\r\n |D| - tổng số văn bản trong tập D \r\n\r\n |{dD: td}| - số văn bản chứa từ nhất định, với điều kiện t xuất hiện trong văn bản \r\n\r\nd (i.e., tf(t,d) khác 0). Nếu từ đó không xuất hiện ở bất cứ 1 văn bản nào trong tập thì \r\n\r\nmẫu số sẽ bằng 0 => phép chia cho không không hợp lệ, vì thế người ta thường thay \r\n\r\nbằng mẫu thức 1+|{dD: td}|. \r\n\r\nCơ số logarit trong công thức này không thay đổi giá trị của 1 từ mà chỉ thu hẹp \r\n\r\nkhoảng giá trị của từ đó. Vì thay đổi cơ số sẽ dẫn đến việc giá trị của các từ thay đổi bởi \r\n\r\nmột số nhất định và tỷ lệ giữa các trọng lượng với nhau sẽ không thay đổi. (nói cách \r\n\r\nkhác, thay đổi cơ số sẽ không ảnh hưởng đến tỷ lệ giữa các giá trị IDF). Tuy nhiên việc \r\n\r\nthay đổi khoảng giá trị sẽ giup tỷ lệ giữa IDF và TF tương đồng để dùng cho công thức \r\n\r\nTF-IDF như bên dưới. \r\n\r\ntfidf(t, d, D)= tf(t, d) idf(t, D) \r\n\r\nNhững từ có giá trị TF-IDF cao là những từ xuất hiện nhiều trong văn bản này, \r\n\r\nvà xuất hiện ít trong các văn bản khác. Việc này giup lọc ra những từ phổ biến và giữ lại \r\n\r\nnhững từ có giá trị cao (từ trọng tâm của văn bản đó). \r\n\r\nTrong phạm vị đồ án, em sẽ tính đặc trưng từ trọng tâm đối uni-gram và bi-grams \r\n\r\ncủa từng câu trong văn bản: \r\n\r\n+ CentroidUni: tổng trọng số tfidf của các uni-gram trọng tâm trong câu S của văn bản \r\n\r\nd trong tập văn bản D: \r\n\r\n\r\n\r\n42 \r\n\r\n\r\nuni\r\n\r\n(uni, , )\r\nS\r\n\r\ntfidf d DCentroidUni\r\n\r\n\r\n   \r\n\r\nVới uni thuộc tập các uni-grams trong top 30% uni-grams có giá trị tfidf cao nhất trong \r\n\r\nvăn bản d. \r\n\r\n+ CentroidBi: tổng trọng số tfidf của các bi-grams trọng tâm trong câu S của văn bản d \r\n\r\ntrong tập văn bản D:  \r\n\r\nbi\r\n\r\n(bi, , )\r\nS\r\n\r\ntfidCentroidB f d Di\r\n\r\n\r\n  \r\n\r\nVới bi thuộc tập các bi-grams trong top 30% bi-grams có giá trị tfidf cao nhất trong văn \r\n\r\nbản d. \r\n\r\n \r\n\r\n3.2.3. Đặc trưng độ liên quan \r\n\r\nĐặc trưng này khai thác mối quan hệ giữa các câu. Giả thiết rằng: \r\n\r\n Các câu liên quan đến câu quan trọng là câu quan trọng. \r\n\r\n Các câu liên quan đến nhiều câu khác là câu quan trọng. \r\n\r\nCâu đầu văn bản hoặc đầu đoạn là câu quan trọng, và những câu khác trong văn \r\n\r\nbản được so sánh với câu đầu. Có 2 loại đặc trưng độ liên quan giữa các câu được đo \r\n\r\nbằng cách so sánh độ tương đồng các cặp câu: FirstRel và PageRankRel. \r\n\r\n \r\n\r\n3.2.3.1. FirstRel \r\n\r\nLà độ tương đồng với câu đầu văn bản: \r\n\r\n = ( , 1) \r\nVới i là vị trí các câu trong văn bản. \r\n\r\nTính độ tương đồng ngữ nghĩa câu sử dụng mạng ngữ nghĩa WordNet \r\n\r\nWordNet (mạng từ) là một cơ sở dữ liệu từ vựng tiếng Anh. Nó nhóm các từ \r\n\r\ntiếng Anh thành các tập hợp đồng nghĩa gọi là loạt đồng nghĩa (synsets), cung cấp các \r\n\r\nđịnh nghĩa ngắn gọn và các ví dụ sử dụng, và ghi lại số lượng các quan hệ giữa các loạt \r\n\r\nđồng nghĩa này hay các thành viên của chung [12]. Theo cách đó WordNet có thể được \r\n\r\nxem như là một sự kết hợp của từ điển và từ điển đồng nghĩa và trái nghĩa. \r\n\r\nQuan hệ về ngữ nghĩa chia làm hai loại chính là quan hệ thứ tự và quan hệ tương \r\n\r\nđương. Các từ đồng nghĩa, trái nghĩa, đồng âm, đa nghĩa là các từ có mối quan hệ tương \r\n\r\nđương hay quan hệ ngang hàng. Các quan hệ còn lại là các quan hệ thứ tự và phân thành \r\n\r\ncác cặp như từ A là bao (has-a) của từ B thì từ B sẽ là thuộc (is-a) của từ A. \r\n\r\n\r\n\r\n43 \r\n\r\n\r\nNếu ta biểu diễn các ngữ nghĩa của từ thành một nut và các quan hệ giữa chung \r\n\r\nlà các path thì ta sẽ có một mạng ngữ nghĩa với các từ có quan hệ tương đương thì sẽ \r\n\r\nnằm trong một lớp và các lớp này nối với nhau thành từng tầng dựa theo quan hệ thứ tự. \r\n\r\nĐó chính là mạng ngữ nghĩa WordNet. \r\n\r\nWordNet được tổ chức theo mô hình cây như hình 2.3, mỗi node chứa một từ \r\n\r\nnguyên mẫu (lemma) cùng với tập các từ đồng nghĩa với nó (synset). WordNet chỉ thể \r\n\r\nhiện quan hệ về ngữ nghĩa chứ không thể hiện quan hệ về ngữ âm hay hình thái. Trong \r\n\r\ncác ngôn ngữ biến cách như tiếng Anh, một từ có nhiều biến thể theo thì (tense), số lượng \r\n\r\n(plural) như eats, mice, teeth, .. Xét về mặt ngữ nghĩa thì các từ này và các từ \r\n\r\nnguyên mẫu tương ứng của chung nói đến cùng một khái niệm nên trong bộ dữ liệu \r\n\r\nWordNet thì các từ biến cách được gộp chung vào từ nguyên mẫu của chung và cùng \r\n\r\nnằm trong một node. \r\n\r\n \r\n\r\n\r\nTrong phạm vi đồ án, em sẽ truy cập WordNet bằng thư viện nltk trong Python. \r\n\r\nThư viện nltk của Python cung cấp các phương thức để truy cập vào bộ dữ liệu WordNet \r\n\r\ntiếng Anh một cách đơn giản và hiệu quả.  \r\n\r\nWordNet cung cấp phương thức truy cập synset của một từ cho trước: \r\n\r\n>>> wn.synsets('dog') \r\n\r\n[Synset('dog.n.01'), Synset('frump.n.01'), \r\n\r\nSynset('dog.n.03'), Synset('cad.n.01'), \r\n\r\nSynset('frank.n.02'), Synset('pawl.n.01'), \r\n\r\nSynset('andiron.n.01'), Synset('chase.v.01')] \r\n\r\n>>> wn.synsets('dog', pos=wn.VERB) \r\n\r\n[Synset('chase.v.01')] \r\n\r\n\r\n\r\n44 \r\n\r\n\r\nSử dụng WordNer để tính giá trị độ tương đồng giữa hai từ  word_1, word_2 bằng \r\n\r\nhàm path_similarity(synset_1, synset_2) với synset_1, synset_2 lần lượt là loạt từ đồng \r\n\r\nnghĩa của word_1 và word_2. \r\n\r\nBiểu diễn mỗi câu trong văn bản dưới dạng một vector ngữ nghĩa. Độ tương đồng \r\n\r\nngữ nghĩa giữa hai câu được tính bằng độ đo Cosine giữa hai vector đại diện cho từng \r\n\r\ncâu: \r\n\r\n- Chuẩn hóa từ của câu: thay các từ của câu bằng từ chung tương ứng. \r\n\r\n- Kích thước của vector ngữ nghĩa là kích thước của tập từ chung của hai câu. \r\n\r\n- Giá trị một chiều của vector ngữ nghĩa của một câu bằng 1 nếu từ trong câu xuất \r\n\r\nhiện trong tập từ chung và bằng 0 nếu không xuất hiện. \r\n\r\nCông thức tính độ đo Cosine giữa hai vector a  và b : \r\n\r\n1\r\n\r\n2 2\r\n\r\n1 1\r\n\r\ncos\r\n|| || . || ||\r\n\r\nn\r\n\r\ni i\r\n\r\ni\r\n\r\nn n\r\n\r\ni i\r\n\r\ni i\r\n\r\na b\r\nab\r\n\r\na b\r\nsimilarity\r\n\r\na b\r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n\r\n \r\n \r\n\r\nVới ai, bi là các phần tử của a  và b  \r\nĐộ tương đồng cosine sẽ sinh ra một số, số này sẽ cho chung ta biết 2 câu liên quan \r\n\r\nđến nhau như thế nào trong không gian bằng cách xem xét góc giữa chung, thay vì so \r\n\r\nsánh về độ lớn. \r\n\r\n \r\n\r\n \r\n  \r\n\r\n       a)  Cùng hướng                      b) Vuông góc                         c) Đối diện \r\n\r\n \r\n\r\n\r\n  \r\n\r\n\r\n\r\n45 \r\n\r\n\r\n3.2.3.2. PageRankRel \r\n\r\na) Giải thuật tính độ tương đồng TF-IDF \r\n\r\nĐây là giải thuật cho ta độ tương đồng giữa các cặp nut trong đồ thị dựa vào tần \r\n\r\nsố của một từ đối với một câu. \r\n\r\nĐộ tương tự sử dụng độ tương đồng TF-IDF. Có nhiều phương pháp để tính độ \r\n\r\ntương tự như Jaccard [28], Dice [9] có thể áp dụng cho tiếng Anh. Nhưng em chọn TF-\r\n\r\nIDF vì phương pháp này chu ý tới độ quan trọng của từ dựa vào tần suất từ khi tính độ \r\n\r\ntương tự giữa hai câu. Công thức tính TF-IDF đa được nêu trong mục 3.2.2 bên trên. Từ \r\n\r\nđó, ta tính trọng số tương ứng của một từ thứ i trong câu thứ j như sau: \r\n\r\nWij = tfidfij \r\n\r\nMỗi câu được biểu diễn như một vector có giá trị các chiều là giá trị trọng số của \r\n\r\ncác từ trong câu. \r\n\r\nKhi biểu diễn trên đồ thị câu, trọng số cạnh giữa 2 đỉnh tương ứng độ tương đồng \r\n\r\ngiữa 2 câu Sm và Sn được tính theo công thức Cosine như sau: \r\n\r\n1\r\n\r\n2 2\r\n\r\n1 1\r\n\r\n.\r\n\r\n.\r\n\r\nt\r\n\r\nim in\r\n\r\ni\r\nmn\r\n\r\nt t\r\n\r\nim in\r\n\r\ni i\r\n\r\nW W\r\n\r\nSim\r\n\r\nW W\r\n\r\n\r\n\r\n \r\n\r\n\r\n\r\n\r\n \r\n \r\n\r\nVới t là số từ của văn bản đầu vào. \r\n\r\nb) Giải thuật PageRank \r\n\r\nPageRank là giải thuật xếp hạng (ranking) nổi tiếng được Google sử dụng trong \r\n\r\nviệc xếp hạng các trang web dựa vào link liên kết bao gồm: link liên kết với trang web \r\n\r\n(incoming link) và link trang web liên kết tới (outcoming link). Trang web nào càng có \r\n\r\nnhiều liên kết, đồng thời liên kết với các trang có xếp hạng càng cao thì hạng của nó \r\n\r\ncàng cao [1]. \r\n\r\n Giá trị PageRank hình thành từ giải thuật học dựa trên Webgraph: các trang World \r\n\r\nWide Web được coi như các đỉnh và các đường link là các cạnh. Giá trị xếp hạng cho \r\n\r\nthấy tầm quan trọng của từng trang cụ thể. Mỗi đường link tới trang web sẽ được tính \r\n\r\nnhư một sự hỗ trợ làm tăng thêm giá trị PageRank. Giá trị PageRank của trang được định \r\n\r\nnghĩa đệ quy và phụ thuộc vào số lượng và giá trị của các trang mà có link dẫn đến trang \r\n\r\nđó. Trang web có chứa nhiều link liên kết từ các trang web có giá trị PageRank cao thì \r\n\r\ngiá trị PageRank của trang đó cũng sẽ cao [5].  \r\n\r\n\r\n\r\n46 \r\n\r\n\r\n \r\n\r\n\r\nCông thức được sử dụng để tính trọng số của một nut trên đồ thị liên kết các trang \r\n\r\nweb như sau : \r\n\r\nV (V )\r\n\r\nPR(V )\r\nPR(V ) (1 ) *\r\n\r\n(V )\r\nj i\r\n\r\nj\r\n\r\ni\r\n\r\nM i\r\n\r\nd d\r\nL\r\n\r\n     \r\n\r\nTrong đó: \r\n\r\n PR(Vi) là xếp hạng của đỉnh Vi. \r\n\r\n M(Vi) là tất cả các đỉnh đi tới đỉnh Vi. \r\n\r\n L(Vi) là tập các đỉnh mà đỉnh Vi đi tới. \r\n\r\n d (DAMPING_FACTOR) là một hệ số trong giải thuật PageRank, giá trị được tùy \r\n\r\nchọn trong khoảng (0,1). Hệ số này là xác suất một người truy cập vào một trang web \r\n\r\nvà tiếp tục kích trong bất cứ bước nào. Nhiều nghiên cứu đa thử các giá trị damping \r\n\r\nvà thấy rằng nếu giá trị này  0.85 thì có nghĩa là người dùng sẽ tiếp tục lướt web. \r\n\r\n \r\n\r\nÁp dụng giải thuật PageRank cho văn bản, ta coi mỗi văn bản là một đồ thị câu \r\n\r\nvô hướng có trọng số, trong đó: \r\n\r\n Các đỉnh biểu diễn các câu. \r\n\r\n Các cạnh biểu diễn độ tương đồng giữa các câu. Một cặp câu có liên quan được \r\n\r\nnối bằng một liên kết vô hướng, có trọng số của cạnh là độ tương đồng giữa hai câu. \r\n\r\n\r\n\r\n47 \r\n\r\n\r\n Giá trị PageRank của câu được tính bằng công thức:  \r\n\r\nV (V )\r\n\r\nPR(V )\r\nPR(V ) (1 ) *\r\n\r\n(V )\r\nj i\r\n\r\nj\r\n\r\ni ij\r\n\r\nM j\r\n\r\nd d Sim\r\nM\r\n\r\n     (1) \r\n\r\nVới: \r\n\r\n PR(Vi) là giá trị PageRank của nut Vi. \r\n\r\n M(Vi) là tất cả các nut trong đồ thị trừ nút i; \r\n\r\n M(Vj) là tất cả các nut trong đồ thị trừ nút j; \r\n\r\n Simij là độ tương đồng giữa 2 câu; \r\n\r\n d là tham số nằm trong khoảng [0,1]. Trong hệ thống tóm tắt đơn văn bản, em \r\n\r\nchọn hệ số này là 0.85 \r\n\r\n \r\n\r\nViệc tính toán PR (điểm của nut trong đồ thị) được thực hiện như sau: \r\n\r\n Đầu tiên, điểm của tất cả các nut được khởi tạo giá trị 1.  \r\n\r\n Sau đó biểu thức (1) được áp dụng để tính điểm lần lượt cho từng nut trên đồ \r\n\r\nthị có trọng số. Việc tính toán này sẽ được lặp đi lặp lại cho đến khi và được \r\n\r\nlặp cho đến khi sự khác biệt về điểm giữa hai lần lặp nhở hơn ngưỡng 0.0001 \r\n\r\nở tất cả các nut.  \r\n\r\n Điểm của các nut chính là điểm của các câu trong văn bản. Các câu có điểm \r\n\r\ncao thì sẽ quan trọng hơn các câu có điểm thấp hơn và độ tương tự với các \r\n\r\ncâu khác lớn.  \r\n\r\n  \r\n\r\n\r\n\r\n48 \r\n\r\n\r\n3.3. Khối tính điểm cho câu  \r\n\r\n3.3.1. Áp dụng mô hình Nave Bayes \r\n\r\nGọi F = {f1, f2, ., f10} là tập các đặc trưng của câu đa nói đến ở mục 3.2. \r\n\r\nTa sẽ sử dụng mô hình Nave Bayes để phân loại các câu thành hai lớp: lớp câu \r\n\r\nquan trọng (lớp 1) và lớp câu không quan trọng (lớp 0) dựa vào giá trị các đặc trưng đa \r\n\r\ntính của từng câu. Để phân loại câu thuộc vào lớp nào, ta cần phải tính: \r\n\r\n{0;1}\r\narg max ( ) ( | )\r\n\r\ni\r\n\r\nNB i i i\r\nc\r\n\r\nc\r\n\r\nc P c P f c\r\n\r\n\r\n   \r\n\r\nVới fi   F. Ta cần tính các giá trị ( | )i iP f c  \r\n\r\n \r\n\r\n3.3.1.1. Xử lý dữ liệu train \r\n\r\n- Mỗi câu trong các văn bản thuộc tập train đa được đánh dấu là câu quan trọng hay \r\n\r\ncâu không quan trọng. \r\n\r\n  Sau khi tính toán giá trị các đặc trưng fi đề cập ở mục 3.2 của các câu trong tập \r\n\r\ntrain, mỗi câu này được biểu diễn bởi các vector đại diện X = (x1, x2,., xn, c), với xi, i = \r\n\r\n1,.,n là giá trị của đặc trưng fi; c là lớp của vector, c = 1 với câu quan trọng và c = 0 \r\n\r\nvới câu không quan trọng. Các vector được lưu vào file txt, mỗi vector một dòng, dùng \r\n\r\nlàm dữ liệu train cho mô hình Nave Bayes. \r\n\r\n- Tính toán các giá trị: \r\n\r\nTrong đồ án này, em sử dụng mô hình Gaussian Naive Bayes để tính các giá trị \r\n\r\n( | )i iP f c . Trước hết, ta phân loại các vector câu trong tập train thành 2 class: class 1 \r\n\r\nnếu câu quan trọng và class 0 nếu câu không quan trọng class 0. Tiếp theo tính giá trị \r\n\r\ntrung bình ci  ( X ) và độ lệch chuẩn ci  (s) của từng class.  \r\n\r\nXét các vector thuộc class c, c {0; 1}, ta đi tính giá trị trung bình từng chiều của \r\n\r\ncác vector này. \r\n\r\n- Công thức tính giá trị trung bình chiều i của các vector trong mỗi class: \r\n\r\n1\r\n\r\n1\r\ni\r\n\r\nN\r\n\r\nci k\r\n\r\nk\r\n\r\nX x\r\nN \r\n\r\n   \r\n\r\nVới \r\nik\r\n\r\nx là giá trị chiều i của vector kx , N là số lượng vector. \r\n\r\n- Công thức tính độ lệch chuẩn chiều i của các vector: \r\n\r\n\r\n\r\n49 \r\n\r\n\r\n2\r\n\r\n1\r\n\r\n( )\r\n\r\n1\r\n\r\ni\r\n\r\nN\r\n\r\nk ci\r\n\r\nk\r\nci\r\n\r\nx X\r\n\r\ns\r\nN\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n \r\n\r\nVới ciX là giá trị trung bình chiều i của các vector, ikx là giá trị chiều i của vector \r\n\r\nkx , N là số lượng vector. \r\n\r\n \r\n\r\n3.3.1.2. Tính xác suất câu trong tập test thuộc vào từng class \r\n\r\n Sau khi tính toán các giá trị đặc trưng của các câu trong tập test tương tự như khi \r\n\r\ntính toán với tập train, mỗi câu trong văn bản test được biểu diễn dưới dạng một vector \r\n\r\nđại diện Xk = (x1, x2,., xn), với xi, i = 1,.,n là giá trị của đặc trưng fi tương ứng. \r\n\r\nXét class c, chiều i của các vector trong class này có giá trị trung bình ciX và độ \r\n\r\nlệch chuẩn cis  . Ta tính giá trị ( | )ip x c  sử dụng hàm mật độ xác suất Gaussian: \r\n\r\n2( )1\r\n( | ) exp\r\n\r\n2.2 .\r\n\r\ni i\r\ni\r\n\r\nii\r\n\r\nx X\r\np x\r\n\r\ns\r\nc\r\n\r\ns\r\n\r\n \r\n  \r\n\r\n \r\n \r\n\r\n \r\n\r\nKết hợp các xác suất p(xi|c) đa tính ở trên, ta tính được xác suất của câu thuộc vào \r\n\r\nmỗi class. Công thức tính xác suất câu thuộc vào từng class: \r\n\r\n   1 2\r\n1\r\n\r\n| | (, |, ),\r\nn\r\n\r\nn i\r\n\r\ni\r\n\r\np c p x px xx c c\r\n\r\n\r\n  x   \r\n\r\n \r\n\r\nĐiểm của câu si là xác suất của câu thuộc vào class 1 (câu quan trọng). \r\n\r\n \r\n(x |1)\r\n\r\n*100\r\n(x |1) (x | 0)\r\n\r\ni\r\n\r\np\r\n\r\np p\r\nScore s\r\n\r\n\r\n  \r\n\r\n  \r\n\r\n\r\n\r\n50 \r\n\r\n\r\n3.3.2. Tiếp cận theo phương pháp cấu trúc \r\n\r\nĐầu ra của khối các đặc trưng cấu trúc: chọn được tập các đặc trưng mang lại kết quả \r\n\r\ntốt nhất để áp dụng cho bài toán tóm tắt văn bản. Các đặc trưng đó bao gồm: \r\n\r\n Đặc trưng bề mặt \r\n\r\n Đặc trưng nội dung \r\n\r\n Đặc trưng độ liên quan \r\n\r\n Trong đó, trọng số cho từng nhóm đặc trưng được xác định như sau: \r\n\r\n Đặc trưng bề mặt:  \r\n\r\n Câu văn đứng ở vị trí đầu tài liệu nhận trọng số FirstDoc bằng 1. Các câu phía \r\n\r\nsau sẽ có trọng số bằng 0. \r\n\r\n Trọng số cho Vị trí thuộc đoạn [0, 1]: \r\n\r\nPosition\r\n1\r\n\r\ni\r\n  \r\n\r\n Với i là vị trí của câu trong văn bản (i > 0). \r\n\r\n Ngưỡng độ dài trung bình (giá trị cutoff) được quy định cho câu văn thuộc chủ \r\n\r\nđề báo chí là 10. Như vậy, trọng số độ dài câu tính bằng công thức: \r\n\r\nLength\r\n10S\r\n\r\nS\r\n\r\nlength\r\n\r\nlength\r\n\r\n\r\n  \r\n\r\nVới length là độ dài câu, nếu độ dài câu nhỏ hơn 10 thì tính điểm độ dài câu là 0. \r\n\r\nTổng điểm đặc trưng bề mặt: \r\n\r\nSurface = FirstDoc + Position + Length \r\n\r\n Đặc trưng nội dung \r\n\r\n Trọng số cho Centroid thuộc đoạn [0, 1], được tính bằng tổng tf-idf của của 30% \r\n\r\ntừ có trọng số TF-IDF cao nhất từ trong câu. \r\n\r\n Trọng số cho Frequence thuộc đoạn [0, 1], được tính bằng tổng tf của 30% từ có \r\n\r\ntrọng số TF cao nhất trong câu. \r\n\r\n Ta xét Centroid và Frequence của uni-gram và bi-gram. Công thức Centroid \r\n\r\nvà Frequence đa trình bày ở mục 3.2 \r\n\r\n \r\n\r\nTổng điểm đặc trưng nội dung: \r\n\r\nContent = Centroid + Frequence \r\n\r\n \r\n\r\n \r\n\r\n\r\n\r\n51 \r\n\r\n\r\n Đặc trưng độ liên quan \r\n\r\n Trọng số FirstRel (độ liên quan đến câu đầu đoạn): câu đầu đoạn có điểm bằng \r\n\r\n1, các câu tiếp theo thuộc đoạn [0, 1). \r\n\r\n Trọng số PageRankRel thuộc đoạn [0, 1] \r\n\r\n Công thức FirstRel và PageRankRel đa trình bày ở mục 3.2 \r\n\r\nTổng điểm đặc trưng độ liên quan: \r\n\r\nRelevance = FirstRel + PageRankRel \r\n\r\n \r\n\r\nCông thức tính điểm cấu trúc: \r\n\r\nĐiểm cấu trúc = Surface + Content + Relevance \r\n\r\n Content: Điểm cho đặc trưng Content \r\n\r\n Surface: Điểm cho đặc trưng Surface \r\n\r\n Relevance: Điểm cho đặc trưng Relevance. \r\n\r\n \r\n\r\n3.4. Khối trích xuất câu \r\n\r\nTừ văn bản đầu vào, các câu được phân chia và nhận một trọng số tương ứng \r\n\r\n(điểm của câu) với mức độ quan trọng trong văn bản sau quá trính tính toán và phân loại. \r\n\r\nTập hợp các câu này được sắp xếp trong một danh sách theo thự giảm dần của giá trị \r\n\r\nđiểm của câu. Lần lượt chọn ra các câu quan trong nhất (các câu có điểm cao nhât) cho \r\n\r\nđến khi văn bản đạt ngưỡng độ dài yêu cầu (không quá 250 từ), sau đó sắp xếp các câu \r\n\r\nđược trích xuất theo thứ tự xuất hiện trong văn bản đầu vào, ta thu được văn bản tóm tắt \r\n\r\ncuối cùng. \r\n\r\n  \r\n\r\n\r\n\r\n52 \r\n\r\n\r\nCHƯƠNG 3: XÂY DỰNG VÀ THỰC NGHIỆM \r\n\r\nVới mô hình tính toán được đưa ra từ những chương trước, chương này em sẽ \r\n\r\ntrình bày chi tiết việc phát triển hệ thống tóm tắt dựa trên mô hình đề xuất để giải quyết \r\n\r\nbài toán tóm tắt văn bản báo chí tiếng Anh. Từ đó, tiến hành các thực nghiệm kiểm tra \r\n\r\nviệc áp dụng hệ thống được xây dựng.  \r\n\r\n Đồ án sử dụng ngôn ngữ lập trình Python để thực hiện. \r\n\r\n1.  Xây dựng hệ thống tóm tắt văn bản \r\n\r\n Từ kết quả thu được từ các bước trước, em đa tìm hiểu và lựa chọn các công cụ \r\n\r\nđể xây dựng hệ thống theo chức năng của từng mô-đun trong mô hình. \r\n\r\n1.1.  Khối tiền xử lý \r\n\r\n Tiền xử lý đối với văn bản tóm tắt tiếng Anh, em sử dụng bộ công cụ NLTK \r\n\r\n(Natural Language Toolkit) [17] chuyên dùng để xử lý các vấn đề liên quan đến ngôn \r\n\r\nngữ tự nhiên. \r\n\r\n NLTK (Natural Language Toolkit) là một bộ công cụ dành riêng cho xử lý ngôn \r\n\r\nngữ tự nhiên (NLP - Natural Language Processing) cho tiếng Anh và được tích hợp vào \r\n\r\nPython [18]. Nó được phát triển bởi bởi Steven Bird và Edward Loper tại Khoa Máy tính \r\n\r\nvà Thông tin tại Đại học Pennsylvania. Nó đang ngày càng hoàn thiện và tích hợp các \r\n\r\ncông cụ mới bởi hàng nghìn lập trình viên và cộng tác viên trên khắp thế giới. NLTK \r\n\r\nbao gồm những thư viện hàm, các công cụ phân tích, nguồn ngữ liệu, WordNet,. giup \r\n\r\nđơn giản hóa, tiết kiệm thời gian và công sức cho các lập trình viên.  \r\n\r\n NLTK cung cấp một giao diện dễ sử dụng với hơn 50 bộ ngữ liệu và lexical \r\n\r\nresources với các thư viện hỗ trợ tiền xử lý văn bản dành cho các tác vụ phân loại, \r\n\r\ntokenization, stemming, gán nhan từ loại, phân tích cu pháp và suy diễn ngữ nghĩa  \r\n\r\nsematic reasoning. Một số ví dụ về chức năng trong bộ công cụ NLTK: \r\n\r\n \r\n\r\n\r\n\r\n\r\n53 \r\n\r\n\r\n \r\n\r\n\r\n \r\n\r\n\r\n1.2. Khối tính giá trị đặc trưng \r\n\r\nSử dụng các thư viện Math, NumPy [19] của Python để tính toán các giá trị đặc \r\n\r\ntrưng. Trong phần tính toán các giá trị đặc trưng độ liên quan, em sử dụng WordNet có \r\n\r\nsẵn trong bộ NLTK của Python [18] để tính toán độ tương đồng ngữ nghĩa với câu đầu \r\n\r\nđoạn và sử dụng hàm PageRank tích hợp trong thư viện NetworkX [16] của Python. \r\n\r\n \r\n\r\n1.3. Khối tính điểm cho câu  \r\n\r\nThiết kế mô hình phân loại và tính điểm cho câu, em sử dụng thư viện Scikit-\r\n\r\nlearn [14] tích hợp sẵn của Python. \r\n\r\nScikit-learn là một thư viện miễn phí hỗ trợ học máy, được tích hơp vào ngôn ngữ \r\n\r\nlập trình Python. Nó hỗ trợ các thuật toán phân loại, hồi quy và phân cụm bao gồm \r\n\r\n\r\n\r\n54 \r\n\r\n\r\nSupport Vector Machines, Random Forests, Gradient Boosting, k-means cùng nhiều \r\n\r\nthuật toán khác. Scikit-learn được thiết kế để tương thích với các thư viện số học và khoa \r\n\r\nhọc của Python như NumPy và SciPy [11]. \r\n\r\n Có thể nói, thư viện Scikit-learn chính là một trong số những nền tảng phổ biến \r\n\r\nnhất hiện nay dành cho lĩnh vực học máy và khoa học dữ liệu. Scikit-learn được xây \r\n\r\ndựng trên nền Python, một ngôn ngữ lập trình với sự hỗ trợ đầy đủ và mạnh mẽ. Scikit-\r\n\r\nlearn cung cấp một số lượng lớn các thuật toán hiệu quả, bao phủ trọn lĩnh vực học máy \r\n\r\nvà khoa học dữ liệu. Ngoài ra, nó còn được biết đến với sự rõ ràng, nhất quán và hợp lý \r\n\r\ntrong API của mình. Điểm lợi của tính nhất quán trong trường hợp này là: một khi người \r\n\r\nđọc hiểu được ký pháp và cách sử dụng căn bản của Scikit-learn cho một mô hình thì \r\n\r\nviệc chuyển đổi sang một mô hình mới hoặc thuật toán mới là vô cùng dễ dàng. Ngoài \r\n\r\nra, song song với đó là nguồn tài liệu online luôn đầy đủ và thuận tiện. \r\n\r\n Ở bước boosting, em sử giải thuật Adaboost trong module sklearn.ensemble [15] \r\n\r\ncủa Scikit-learn. \r\n\r\n \r\n\r\n\r\n  \r\n\r\n\r\n\r\n55 \r\n\r\n\r\n2. Dữ liệu thực nghiệm  \r\n\r\n Đồ án sử dụng tập dữ liệu DUC 2007 như là một tập dữ liệu để kiểm tra. \r\n\r\nDocument Understanding Conference (DUC) [13] là một hội nghị quốc tế để đánh giá \r\n\r\nhiệu suất của hệ thống tóm tắt bằng cách so sánh bản tóm tắt bằng tay của các chuyên \r\n\r\ngia với bản tóm tắt tự động của máy tính.  \r\n\r\nDUC2007 là bộ dữ liệu dùng cho tác vụ tóm tắt đa văn bản, gồm 45 cụm văn bản, \r\n\r\nmỗi cụm gồm 25 văn bản là các bài báo có cùng chủ đề. 45 cụm văn bản này được chia \r\n\r\nthành 2 tập : tập dữ liệu huấn luyện 2007 SCU-marked và tập dữ liệu dùng để thử nghiệm \r\n\r\n2007 test_docs. \r\n\r\nTác vụ Cụm Nguồn \r\n\r\n2007 SCU-\r\n\r\nmarked \r\n\r\n23 văn bản định \r\n\r\ndạng SCU  \r\n\r\nTiếng Anh \r\n\r\nThời báo AP, \r\n\r\nThời báo \r\n\r\nNewYorkTimes, \r\n\r\nTân Hoa Xã \r\n\r\n2007 \r\n\r\ntest_docs \r\n\r\n22 văn bản  \r\n\r\nTiếng Anh \r\n\r\nThời báo AP, \r\n\r\nThời báo \r\n\r\nNewYorkTimes, \r\n\r\nTân Hoa Xã \r\n\r\n\r\nĐể phù hợp với bài toán tóm tắt đơn văn bản, ta ghép các văn bản trong từng cụm \r\n\r\nvăn bản thành một đơn văn bản. Tập bản tóm tắt mẫu tương ứng của từng cụm văn bản \r\n\r\nbao gồm 4 văn bản dài không quá 250 từ do 4 chuyên gia tóm tắt, do đó bản tóm tắt của \r\n\r\nhệ thống cũng có độ dài không quá 250 từ. \r\n\r\nCác văn bản để huấn luyện của DUC2007 có định dạng SCU (Summary Content \r\n\r\nUnits) có cấu truc như sau: \r\n\r\n\r\n\r\n56 \r\n\r\n\r\n \r\n\r\n\r\n Các câu gán thẻ <annotation> thường là các câu quan trọng. Trong thẻ <scu>, \r\n\r\ntrọng số weight chỉ số lượng văn bản do chuyên gia tóm tắt có liên quan đến câu. Để \r\n\r\nphù hợp với các đánh giá văn bản đầu ra so với văn bản tóm tắt của chuyên gia, em lựa \r\n\r\nchọn các câu quan trọng là các câu có trọng số weight lớn hơn 0. \r\n\r\n \r\n\r\n3. Đánh giá chất lượng tóm tắt \r\n\r\n Đồ án sử dụng độ đánh giá ROUGE cho sự so sánh giữa các bản tóm tắt tự động \r\n\r\nvà 4 bản tóm tắt tham chiếu bởi các chuyên gia có trong tập dữ liệu thử nghiệm.  \r\n\r\nROUGE  viết tắt của Recall-Oriented Understudy for Gisting Evaluation. \r\n\r\nROUGE bao gồm bộ các độ đo để đánh giá tự động chất lượng của văn bản tóm tắt bằng \r\n\r\ncách so sánh bản tóm tắt sinh ra bởi hệ thống với những bản tóm tắt được tạo ra bởi con \r\n\r\nngười. Các độ đo cơ bản ROUGE bao gồm : ROUGE-N, ROUGE-L, ROUGE-W và \r\n\r\nROUGE-SU. Các độ đo trên được sử dụng trong DUC 2007. \r\n\r\nTrong phạm vi nghiên cứu, em sử dụng 2 độ đo ROUGE-1 và ROUGE-2 tương \r\n\r\nứng với n = 1 và n = 2 trong ROUGE-N để đánh giá chất lượng của văn bản tóm tắt. \r\n\r\nNhư đa trình bày ở mục 3.5 chương 1, do có 4 văn bản tóm tắt tham chiếu, ta tính \r\n\r\nROUGE-N theo từng cặp, giữa bản tóm tắt tự động s và từng bản tóm tắt tham chiếu ri \r\n\r\ntrong tập 4 văn bản tóm tắt tham chiếu. Sau đó, kết quả điểm ROUGE-N cuối cùng trong \r\n\r\n4 tham chiếu sẽ là điểm ROUGE-N cao nhất trong tất cả các cặp được tính. \r\n\r\n  \r\n\r\n\r\n\r\n57 \r\n\r\n\r\n4. Kết quả thực nghiệm \r\n\r\n Đồ án tập trung vào việc nghiên cứu kết hợp phương pháp tóm tắt văn bản áp \r\n\r\ndụng học máy có giám sát  đại diện là phương pháp Naive Bayes kết hợp boosting bằng \r\n\r\nAdaboost. \r\n\r\n Các thí nghiệm được thiết kế bao gồm 2 mục tiêu chính: \r\n\r\n Đánh giá và lựa chọn hướng tiếp cận tóm tắt: tiếp cận theo phương pháp \r\n\r\ncấu truc và phương pháp học máy nhằm so sánh độ chính xác giữa hai \r\n\r\nhướng tiếp cận. \r\n\r\n Đánh giá và lựa chọn đặc trưng: lựa chọn các loại đặc trưng để đánh giá \r\n\r\ntầm quan trọng của từng loại đặc trưng đối với độ chính xác của mô hình. \r\n\r\n \r\n\r\n4.1. Kết quả lựa chọn hướng tiếp cận \r\n\r\n  \r\n\r\n                                ROUGE ROUGE-1 ROUGE-2 \r\n\r\n3 features 38.78 9.01 \r\n\r\nNave Bayes + 3 features 40.75 9.71 \r\n\r\nNave Bayes + Adaboost + 3 \r\n\r\nfeatures \r\n41.12 9.92 \r\n\r\n\r\n\r\n\r\n58 \r\n\r\n\r\n \r\n\r\n\r\nTừ kết quả thí nghiệm 1 ta có nhận xét : \r\n\r\nKhi kết hợp cả phương pháp Nave Bayes boosting bằng Adaboost hệ thống cho \r\n\r\nkết qủa tốt nhất với điểm Rouge-2 là 9.92% và Rouge-1 là 41.12%. Thuật toán Adaboost \r\n\r\ncải thiện độ chính xác của mô hình Nave Bayes đơn thuần 41.12% so với 40.75%. Từ \r\n\r\nbảng trên ta cũng có thể thấy phương pháp Nave Bayes cho kết quả cao hơn với phương \r\n\r\npháp đặc trưng cấu truc 40.75% với 38.78%. \r\n\r\n Qua kết quả trên ta có thể rut ra nhận xét: \r\n\r\n Trong phạm vi nghiên cứu, đồ án đa chứng minh được hướng tiếp cận phương \r\n\r\npháp học máy mang kết qủa tốt hơn khi sử dụng phương pháp cấu truc. \r\n\r\n Thuật toán Adaboost đa hoạt động hiệu quả trong việc tăng cường độ chính xác \r\n\r\ncủa mô hình Nave Bayes. \r\n\r\n Do tính đặc trưng của ngôn ngữ học, sự kết hợp các đặc trưng cấu truc không phải \r\n\r\nluôn tuân theo quy luật tỉ lệ thuận giữa điểm ROUGE-1 và ROUGE-2. \r\n\r\n  \r\n\r\n0\r\n\r\n5\r\n\r\n10\r\n\r\n15\r\n\r\n20\r\n\r\n25\r\n\r\n30\r\n\r\n35\r\n\r\n40\r\n\r\n45\r\n\r\n3 features Nave Bayes + 3 features Nave Bayes + 3 features + Adaboost\r\n\r\nROUGE-1 ROUGE-2\r\n\r\n\r\n\r\n59 \r\n\r\n\r\n4.2. Kết quả lựa chọn đặc trưng \r\n\r\n                                    ROUGE ROUGE-1 ROUGE-2 \r\n\r\nAdaboost + Nave Bayes + \r\n\r\nRelevance + Content \r\n39.14 9.12 \r\n\r\nAdaboost + Nave Bayes + \r\n\r\nSurface + Content \r\n40.31 9.30 \r\n\r\nAdaboost + Nave Bayes + \r\n\r\nRelevance + Surface \r\n39.09 9.17 \r\n\r\n\r\n \r\n\r\n\r\n \r\n\r\n Từ kết quả trên kết hợp với kết quả của thí nghiệm 1, ta có thể rut ra nhận xét: \r\n\r\n- Sử dụng mô hình Naive Bayes sử dụng 2 trong 3 loại đặc trưng cho kết quả \r\n\r\nkém hơn kết hợp cả 3 loại đặc trưng. \r\n\r\n- Mô hình Naive Bayes sử dụng tập đặc trưng Surface và Content mang lại kết \r\n\r\nquả tốt nhất với điểm Rouge-2 là 9.31% và Rouge-1 là 40.31%. \r\n\r\n0\r\n\r\n5\r\n\r\n10\r\n\r\n15\r\n\r\n20\r\n\r\n25\r\n\r\n30\r\n\r\n35\r\n\r\n40\r\n\r\n45\r\n\r\nAdaboost + Nave Bayes + Content +\r\nRelevance\r\n\r\nAdaboost + Nave Bayes + Content +\r\nSurface\r\n\r\nAdaboost + Nave Bayes + Surface +\r\nRelevance\r\n\r\nROUGE-1 ROUGE-2\r\n\r\n\r\n\r\n60 \r\n\r\n\r\n- Kết quả thí nghiệm 2 chứng tỏ, trong thể loại văn bản báo chí được tóm tắt, \r\n\r\nđặc trưng bề mặt (vị trí, độ dài câu văn) cùng đặc trưng nội dung (giá trị TF-\r\n\r\nIDF, tần suất từ) là quan trọng. \r\n\r\n \r\n\r\n4.3. So sánh, đánh giá với phương pháp khác \r\n\r\nKết quả thực nghiệm của 1 số hướng tiếp cận khác trên cùng tập dữ liệu DUC \r\n\r\n2007:  \r\n\r\n                               \r\n\r\n                               ROUGE ROUGE-1 ROUGE-2 \r\n\r\nNtMF với ma trận Log \r\n\r\nEntropi  \r\n35.82 7.22 \r\n\r\nNMF với ma trận TFIDF 36.18 7.28 \r\n\r\nNMF kết hợp các đặc trưng \r\n\r\ncấu trúc sử dụng Word2Vec \r\n41.67 9.99 \r\n\r\nSVM 39.71 10.08 \r\n\r\n\r\n Từ bảng 3.4 ta có nhận xét : \r\n\r\n- Kết quả độ đo Rouge của mô hình Naive Bayes kết hợp giải thuật AdaBoost \r\n\r\ncao hơn hẳn so với mô hình NMF thuần, chỉ thấp hơn so với mô hình NMF \r\n\r\nkết hợp các đặc trưng cấu trúc sử dụng Word2Vec (độ Rouge-1 thấp hơn \r\n\r\n0.52%, độ Rouge-2 thấp hơn 0.07%). \r\n\r\n- So với mô hình SVM, mô hình cho kết quả Rouge-1 tốt hơn và Rouge-2 thấp \r\n\r\nhơn không đáng kể (0.16%).  \r\n\r\n- Như vậy, nhìn chung, trong bài toán tóm tắt văn bản, mô hình phân loại Naive \r\n\r\nBayes sử dụng tập đặc trưng cấu trúc câu và kết hợp giải thuật AdaBoost mang \r\n\r\nlại kết quả tương đối tốt so với các mô hình khác.   \r\n\r\n\r\n\r\n61 \r\n\r\n\r\nCHƯƠNG 4: KẾT LUẬN VÀ HƯỚNG PHÁT TRIỂN \r\n\r\n1. Ưu - nhược điểm của  \r\n\r\nTrong đồ án này, em đa đề xuất một phương pháp mới để giải quyết bài toán tóm \r\n\r\ntắt văn bản tự động, đồng thời tập trung xây dựng một hệ thống tóm tắt văn bản cho tiếng \r\n\r\nAnh.  \r\n\r\nHệ thống đề xuất dựa vào mô hình Nave Bayes kết hợp các đặc trưng cấu truc \r\n\r\ncủa câu để chọn các câu quan trọng trong văn bản và trích xuất thành văn bản tóm tắt. \r\n\r\nHệ thống có một số ưu và nhược điểm sau: \r\n\r\n1.1. Ưu điểm \r\n\r\n- Mô hình Nave Bayes là một mô hình dễ cài đặt, dễ thực thi, thời gian tính toán và \r\n\r\nphân loại nhanh, có độ chính xác tương đối cao. \r\n\r\nMột nghiên cứu so sánh toàn diện với các phương pháp phân loại khác trong năm \r\n\r\n2006 [6] cho thấy phân loại Nave Bayes được cải thiện tốt hơn bằng các phương \r\n\r\npháp boosting, chẳng hạn như AdaBoost. Kết quả thực hiện của mô hình cũng đa \r\n\r\ncho thấy điều này. \r\n\r\n- Thực tế, với bất kỳ mô hình học máy nào, bộ dữ liệu huấn luyện càng lớn thì mô \r\n\r\nhình càng đưa ra kết quả có độ chính xác cao. Tuy nhiên, kể cả đối với bộ dữ liệu \r\n\r\nhuấn luyện nhỏ, mô hình Nave Bayes hoạt động khá hiệu quả. Hơn nữa, mô hình \r\n\r\ncũng nhanh chóng cập nhật nếu có dữ liệu mới được thêm vào. \r\n\r\n \r\n\r\n1.2. Nhược điểm \r\n\r\n- Trong mô hình Nave Bayes, giả thiết về tính độc lập của các biến là không thực tế. \r\n\r\nCụ thể, trong mô hình đề xuất, các đặc trưng cấu trúc câu không hoàn toàn độc lập \r\n\r\nvới nhau.  \r\n\r\n- Mô hình Nave Bayes coi các đặc trưng là độc lập nên nó không thể phát hiện ra \r\n\r\nmối quan hệ giữa các loại đặc trưng. Hơn nữa, không thể thiết lập đặc trưng ưu tiên \r\n\r\ncho mô hình. \r\n\r\n- Mô hình chưa áp dụng được cho bài toán tóm tắt văn bản tiếng Việt. \r\n\r\n \r\n\r\n2. Đóng góp của đồ án \r\n\r\n Đồ án đưa ra một cái nhìn tổng quan về áp dụng phương pháp học máy và kĩ thuật \r\n\r\nphân tích các đặc trưng cấu truc câu trong vấn đề xử lý dữ liệu văn bản mà cụ thể là bài \r\n\r\ntoán Tóm tắt văn bản tự động. \r\n\r\n\r\n\r\n62 \r\n\r\n\r\nĐồ án đa đề xuất một cách tiếp với bài toán tóm tắt văn bản dựa vào trích xuất \r\n\r\nbằng cách sử dụng mô hình Naive Bayes sử dụng tập đặc trưng câu, kết hợp giải thuật \r\n\r\ntăng cường AdaBoost. Đồ án cũng đa chứng minh được tính hiệu quả của phương pháp \r\n\r\nkhi áp dụng trên tiếng Anh. Các thí nghiệm của em được thực hiện với các kịch bản khác \r\n\r\nnhau bằng bộ dữ liệu DUC2007 cho tiếng Anh. Kết quả thí nghiệm cho thấy khi Naive \r\n\r\nBayes kết hợp với ba loại đặc trưng câu (đặc trưng bề mặt, đặc trưng độ liên quan, đặc \r\n\r\ntrưng nội dung) và boosting bằng Adaboost cho kết quả tốt nhất. Các phép đo Rouge-1 \r\n\r\nvà Rouge-2 c","u":"http://202.191.57.85:8000/InternetData/Data/DATN/20131383_Vu_Thu_Hien_1528204153945.txt","sentences":[[1,"Tình hình nghiên cứu tóm tắt văn bản Trên thực tế, bài toán tóm tắt văn bản đa xuất hiện từ rất lâu"],[2,"Những kỹ thuật đầu tiên áp dụng để tóm tắt văn bản xuất hiện từ những năm 50 của thế ký trước (như nghiên cứu của Luhn năm 1959)"],[3,"Sau đó, chung tiếp tục được nghiên cứu và đạt nhiều kết quả ngày càng tốt hơn, cho nhiều loại ngôn ngữ như tiếng Anh, Pháp, Nhật, Trung"],[4,"Các nghiên cứu tập trung vào hai hướng chính: tóm tắt trích xuất (Extraction Summarization) và tóm tắt tóm lược (Abstraction Summarization) cho bài toán tóm tắt đơn văn bản và đa văn bản"],[5,"Hầu hết các nghiên cứu về tóm tắt văn bản là trích xuất vì nó dễ thực hiện và có tốc độ nhanh hơn so với tóm tắt tóm lược"],[6,"Hướng tiếp cận trích xuất chủ yếu là dựa vào các đặc trưng quan trọng của văn bản để tính trọng số câu để trích xuất"],[7,"Trong khi đó, tóm tắt tóm lược là dựa vào các kỹ thuật xử lý ngôn ngữ tự nhiên kết hợp với thông tin về ngôn ngữ để tạo ra các tóm tắt cuối cùng"],[8,"Hiện nay trên thế giới, nhiều nhà khoa học và các công ty tỏ ra rất quan tâm đến bài toán tóm tắt văn bản tự động"],[9,"Hội nghị DUC (Document Understand Conference, 2001 2007) [DUC], hội nghị TAC (Text Analysis Conference, 2008 nay) [20], ACL (Association for Computational Linguistics, 2001 nay) là một day hội nghị khoa học tầm vóc thế giới điển hình về tóm tắt văn bản"],[10,"Nhiều công trình khoa học về bài toán tóm tắt văn bản, về các mô hình, giải pháp tóm tắt văn bản được công bố hàng năm tại các hội nghị này [27]"],[11,"Hiện nay trên thế giới, đa có nhiều hệ thống tóm tắt tắt văn bản tiếng Anh được xây dựng độc lập như SUMARIST, SWESUM,"],[12,"Ngoài ra, có nhiều hệ thống tóm tắt văn bản tích hợp được phát triển như: MEAD, LexRank, chức năng tự động tóm tắt trong Microsoft Word"],[13,"Ở Việt Nam những năm gần, Internet có sự phát triển mạnh mẽ"],[14,"Hiện nay người dùng truy nhập và sử dụng các thông tin tiếng Việt trên Internet đa trở nên phổ biến"],[15,"Xuất phát từ sự thay đổi đó, hầu như tất cả các bài toán tiếng Việt điển hình của Xử lý dữ liệu văn bản đều đa được nghiên cứu và cài đặt thành ứng dụng thực tế như Tìm kiếm, Phân lớp & Phân loại văn bản,.."],[16,"đóng góp rất nhiều vào sự phát triển của lĩnh vực Xử lý văn bản tự động tiếng Việt"],[17,"Tuy nhiên bài toán tóm tắt văn bản thì chưa có nhiều nghiên cứu tiến hành đề xuất và xây dựng thành công ứng dụng"],[18,"Các bài báo công bố kết quả nghiên cứu về tóm tắt văn bản phần lớn dựa trên hướng trích xuất cho bài toán tóm tắt đơn văn bản"],[19,"Mặt khác, do chưa có kho ngữ liệu chuẩn phục vụ cho tóm tắt văn bản tiếng 10 Việt nên hầu hết thử nghiệm của các nghiên cứu đều dựa trên các kho ngữ liệu tự xây dựng"],[20,"Một số công trình tóm tắt tiếng Việt tiêu biểu như công trình của Nguyễn Lê Minh [42], Hà Thành Lê [41]"],[21,"Nguyễn Lê Minh [42] đề xuất mô hình tóm tắt văn bản theo hướng trích xuất sử dụng phương pháp SVM"],[22,"Các đặc trưng được sử dụng trong việc xây dựng mô hình bao gồm vị trí câu, chiều dài câu, độ liên quan chủ đề, tần suất từ, cụm từ chính và khoảng cách từ [42]"],[23,"Hà Thành Lê [41] đề xuất mô hình sử dụng một số đặc trưng trong văn bản như tần số từ, TFIDF, vị trí câu, độ dài câu, từ tiêu đề"],[24,"Các đặc trưng được kết hợp tuyến tính với nhau để tính trọng số mỗi câu trong văn bản gốc"],[25,"Trong phương pháp này, Hà Thành Lê cũng đề cập đến công cụ tách từ cho văn bản tiếng Việt [41]"],[26,"2"],[27,"Tầm quan trọng của tóm tắt văn bản Trong thời đại internet với sự bùng nổ của thông tin, vấn đề chính mà con người phải đối mặt không còn là vấn đề về sự thiếu hụt thông tin mà là làm thế nào để có thể xác định, chọn lọc ra những thông tin mà mình cần trong bể thông tin khổng lồ được gia tăng hàng ngày trên mạng toàn cầu"],[28,"Mỗi một cá nhân hay tổ chức đều phải giải quyết bài toán dư thừa thông tin (Information Overload) để có thể hoạt động hiệu quả trong thời đại thông tin ngày nay"],[29,"Vấn đề của chung ta gặp phải hiện nay không chỉ là sự thiếu hụt thông tin, mà với lượng thông tin khổng lồ như vậy, làm cách nào có thể xác định và chọn lọc các thông tin mà mình cần trong khối lượng thông tin quá lớn như vậy"],[30,"Mặt khác, Internet tồn tại dưới dạng đa ngôn ngữ, tuy nó không có vấn đề gì nhưng sẽ gây khó khăn rất nhiều cho việc phân tích tài liệu [23]"],[31,"Do đó, có một nhu cầu rất lớn là giảm bớt nhiều dữ liệu văn bản này xuống tóm tắt tập trung ngắn hơn để nắm bắt các chi tiết nổi bật, từ đó ta có thể nhanh chóng kiểm tra xem các tài liệu lớn hơn có chứa thông tin mà ta đang tìm kiếm hay không"],[32,"Để giải quyết vấn đề quá tải thông tin và dư thừa thông tin, giup chung ta có thể xác định nhanh chóng và hiệu quả các thông tin mà mình cần, có khá nhiều cách tiếp cận đa được thực hiện: Tìm kiểm thông tin (information retrieval)"],[33,"Trích rut thông tin (information extraction)"],[34,"Phân cụm tài liệu (document clustering)"],[35,"Biểu diễn thông tin trực quan (visualization)"],[36,"11 Các hệ hỏi đáp (Question/Answering System)"],[37,"Tóm tắt văn bản tự động (Automatic Text Summarization)"],[38,"Trong đó, tóm tắt văn bản tự động là phương pháp chủ đạo giúp còn người giả quyết vấn đề trên"],[39,"Các ưu điểm của việc tóm tắt văn bản tự động: Tóm tắt làm giảm thời gian đọc tài liệu mà vẫn nắm bắt được nội dung quan trọng của văn bản"],[40,"Khi nghiên cứu tài liệu, tóm tắt làm cho việc chọn lựa tài liệu một cách dễ dàng hơn"],[41,"Tóm tắt văn bản có thể hữu ích trong các hệ thống Q&A (Hỏi Đáp) Tóm tắt tự động sẽ khách quan hơn so với tóm tắt của con người"],[42,"Tóm tắt tự động sẽ cho phép các cá nhân, tổ chức xử lý các văn bản, các tài liệu một cách nhanh chóng, dễ dàng và hiệu quả hơn"],[43,"Bổ sung cho nhận định trên, Viện Tiêu Chuẩn Quốc Gia Hoa Kì (ANSI) chỉ ra rằng một tóm lược được chuẩn bị tốt giup người đọc xác định được nội dung cơ bản của tài liệu một cách nhanh hơn và chính xác hơn, cũng như dễ dàng xác định nội dung đó có liên quan đến vấn đề mà họ đang quan tâm hay không, do đó quyết định nên hay không nên đọc toàn bộ tài liệu này"],[44,"Thực vậy, báo cáo tại hội nghị SUMMAC 2002 đa xác nhận điều này bằng cách chứng minh được rằng: Các bản tóm tắt chỉ cần ngắn bằng khoảng 17% độ dài của văn bản gốc thì sẽ làm tăng tốc độ ra quyết định lên 2 lần mà không có sự suy giảm về độ chính xác trong tỉ lệ xác suất có nghĩa"],[45,"12 3"],[46,"Bài toán tóm tắt văn bản 3.1"],[47,"Tóm tắt văn bản là gì"],[48,"Bài toán tóm tắt văn bản là một trong những bài toán kinh điển trong lĩnh vực xử lý dữ liệu văn bản"],[49,"Xử lý dữ liệu văn bản bao gồm: Kiểm tra lỗi chính tả (spelling-checker) Kiểm tra lỗi văn phạm (grammar-checker) Từ điển đồng nghĩa (thesaurus) Phân tích văn bản (text analyzer) Phân loại văn bản (text classification) Tóm tắt văn bản (text summarization) Tổng hợp tiếng nói (speech synthesis) Nhận dạng giọng nói (speech recognization) Dịch tự động (automatic translation)"],[50,"Các định nghĩa về tóm tắt văn bản tự động"],[51,"Định nghĩa 1 (Van Dijk) [23]: Chức năng chính của tóm tắt là chỉ ra và dự đoán cấu truc và nội dung của văn bản"],[52,"Định nghĩa 2 (Cleveland) [23]: Bản tóm tắt phải mang các nội dung chủ yếu của tài liệu, và nó thực sự là một bản thay thế của tài liệu"],[53,"Định nghĩa 3 [23]: Bản tóm tắt là một phiên bản đặc của tài liệu có một thể loại dễ nhận biết và một mục đích rất cụ thể: để cung cấp cho người đọc một ý tưởng chính xác và ngắn gọn về nội dung của nguồn"],[54,"Định nghĩa 4 [23]: Một bản tóm tắt tự động là một văn bản được tạo ra bởi một phần mềm, nó mạch lạc và có chứa một lượng đáng kể các thông tin có liên quan từ các văn bản nguồn"],[55,"Tỷ lệ nén của nó là ít hơn một phần ba chiều dài của tài liệu gốc"],[56,"13 3.2"],[57,"Phân loại tóm tắt văn bản 3.2.1"],[58,"Phân loại theo kết quả 3.2.1.1"],[59,"Tóm tắt trích xuất (Extract) Đối với tóm tắt trích xuất, chương trình tóm tắt tự động sẽ trích xuất ra các thành phần của văn bản mà không chỉnh sửa nội dung của nó rồi ghép lại thành một văn bản hoàn chỉnh"],[60,"Loại tóm tắt này bao gồm trích xuất câu và trích xuất cụm từ"],[61,"Như vậy, tóm tắt trích xuất chỉ sử dụng các thông tin có sẵn trong văn bản như: từ, cụm từ, câu để tạo ra văn bản tóm tắt [23]"],[62,"Phương pháp trích xuất bao gồm việc lựa chọn đơn vị của văn bản (câu hay đoạn văn), được coi là có chứa lượng thông tin cốt tử của văn bản (informative content, informativity), và kết nối các đơn vị này theo một trình tự thích hợp"],[63,"Một trích xuất là sự lắp ghép các đoạn được trích xuất ra từ văn bản nguồn"],[64,"Mục tiêu của trích xuất là cung cấp một cái nhìn tổng quan về nội dung của văn bản gốc"],[65,"Độ dài của văn bản tóm tắt bằng trích xuất có thể được xác định bởi tỉ lệ nén, hay nói cách khác Văn bản tóm tắt ngắn hơn bao nhiêu so với văn bản gốc"],[66,"Thuật toán tóm tắt tự động bằng trích xuất có thể chia ra làm 3 mức: surface-level (mức bề mặt), intermediate-level (mức trung bình) và deep parsing techniques (các kĩ thuật phân tích sâu)"],[67,"Tóm tắt trích xuất xuất phát từ ý tưởng: Một tài liệu được chia nhỏ thành các đơn vị ngữ pháp (các câu văn), sau đó được đánh trọng số theo kinh nghiệm (heuristic); Các đơn vị ngữ pháp có điểm cao nhất sẽ được trích xuất và liên kết với nhau để tạo nên văn bản tóm tắt [23]"],[68,"Thuật toán tiếp cận ở mức bề mặt: Không đào sâu vào chiều sâu ngôn ngữ của văn bản, thay vào đó là sử dụng các phần tử ngôn ngữ nhất định để xác định các đoạn có liên hệ với nhau trong văn bản [23]"],[69,"Kĩ thuật của mức bề mặt dựa vào sự xuất hiện của từ để đánh trọng số cho các câu"],[70,"Một kĩ thuật khác dựa trên ý tưởng: Những từ được sử dụng trong tiêu đề của văn bản là quan trọng"],[71,"Trong khi đó, một số kĩ thuật dựa vào vị trí của các đoạn trong văn bản"],[72,"Kĩ thuật này được áp dụng với nhưng văn bản có cấu truc cố định, như tiêu đề, các mục và các đoạn,.."],[73,"Một số nghiên cứu còn chỉ ra rằng: Dòng đầu tiên luôn là dòng quan trọng nhất trong văn bản đối với các thể loại báo chí"],[74,"Thuật toán tiếp cận mức trung bình: Sử dụng thông tin về ngôn ngữ học phức tạp hơn thuật toán tiếp cận mức bề mặt nhưng lại ít phức tạp hơn mức phân tích 14 sâu"],[75,"Một kĩ thuật của dạng này là phát hiện các chuỗi từ vựng"],[76,"Chuỗi từ vựng là một day các từ kết nối với nhau theo quan hệ về ngữ nghĩa"],[77,"Một cách tổng quát, quá trình tóm tắt bao gồm 4 giai đoạn"],[78,"Bốn giai đoạn đó bao gồm: - Chia văn bản gốc thành các đoạn (segments)"],[79,"Xây dựng các chuỗi từ vựng lexical chain [23]"],[80,"- Xác định các strong chain chuỗi từ mạnh [23] - Trích xuất các câu chứa các strong chain [23] - Lắp ghép các câu được trích xuất thành văn bản tóm tắt [23] Thuật toán phân tích sâu: Dựa trên ý tưởng rằng sử dụng các kĩ thuật chuyên sâu về ngôn ngữ để phát hiện ra các cấu truc rời rạc của văn bản [23]"],[81,"Những hệ thống tóm tắt văn bản tự động dựa trên phân tích diễn ngôn bắt nguồn từ ý tưởng: Văn bản được định nghĩa bởi cấu truc trong của nó và các mối quan hệ diễn ngôn - phụ thuộc vào ngôn ngữ mà văn bản sử dụng"],[82,"Những hệ thống này cung cấp độ quan trọng nhiều hơn cho các thành phần cốt tử của các quan hệ rời rạc"],[83,"3.2.1.2"],[84,"Tóm tắt tóm lược (Abstract) Tuy tóm tắt bằng trích xuất đa thành công trong việc xác định câu nào trong văn bản đầu vào mang nội dung quan trọng nhưng dường như những phương pháp này rất xa với việc tạo ra một bản tóm tắt tối ưu theo nghĩa cả về nội dung và chất lượng trong ngôn ngữ học"],[85,"Trong khi đó, hệ thống tạo ra văn bản tóm tắt bằng tóm lược dựa trên việc hiểu văn bản gốc và đạt tới việc sinh ra một văn bản mới một cách chính xác về ngữ pháp, suc tích và mạch lạc về nội dung, bằng cách sinh ra văn bản tóm tắt bằng những từ vựng không xuất hiện trong văn bản gốc"],[86,"Trong tóm lược, việc diễn giải, viết lại các câu phức tạp sẽ nhằm mục đích tạo ra phiên bản suc tích của nội dung ban đầu"],[87,"Mặc dù con người có thể tái sử dụng một phần văn bản gốc nhưng không phải sử dụng toàn bộ nó; sử dụng các đoạn hay một phần của câu thay vì sử dụng toàn bộ câu"],[88,"3.2.2"],[89,"Phân loại theo số lượng Tóm tắt đơn văn bản: là một bản tóm tắt được tạo thành từ một văn bản riêng lẻ"],[90,"Tóm tắt đa văn bản: là một bản tóm tắt được tạo thành từ nhiều văn bản cùng liên quan tới một chủ đề riêng lẻ"],[91,"15 3.2.3"],[92,"Phân loại theo mục đích Tóm tắt sơ lược (Indicative): tóm tắt nhằm đưa ra những thông tin ngắn gọn về chủ đề chính củavăn bản (ứng dụng trong tóm tắt kết quả tìm kiếm)"],[93,"Thông thường, độ dài của văn bản tóm tắt loại này chỉ từ 5 đến 10% độ dài của toàn bộ văn bản"],[94,"Tóm tắt thông tin (Information): tóm tắt bao gồm tất cả các thông tin nổi bật có trong văn bản nguồn tại nhiều mức độ chi tiết khác nhau"],[95,"Kiểu tóm tắt này có độ dài từ 20-30% văn bản gốc"],[96,"Tóm tắt đánh giá (Evaluation): tóm tắt nhằm mục đích đánh giá vấn đề chính của văn bản nguồn, thể hiện quan điểm của người tóm tắt đối với chủ đề được đưa ra"],[97,"Tuy nhiên, kiểu tóm tắt này dường như vượt qua tầm của các hệ thống tóm tắt tự động hiện này"],[98,"3.2.4"],[99,"Phân loại theo nội dung Tóm tắt chung (Generalized): tóm tắt nhằm mục đích đưa ra các nội dung quan trọng bao quát văn bản gốc"],[100,"Tóm tắt hướng truy vấn (Querybased): tóm tắt nhằm mục đích đưa ra kết quả dựa vào câu truy vấn của người"],[101,"Tóm tắt này thường được sử dụng trong quá trình tìm kiếm thông tin (information retreival)"],[102,"3.2.5"],[103,"Phân loại theo mức độ chi tiết Tóm tắt tổng quan (overview): tóm tắt miêu tả tổng quan tất cả các nội dung nổi bật trong văn bản nguồn"],[104,"Tóm tắt tập trung sự kiện (event): tóm tắt miêu tả một sự kiện cụ thể nào đó trong văn bản nguồn"],[105,"16 3.3"],[106,"Các đặc trưng sử dụng trong tóm tắt văn bản Tóm tắt văn bản là bài toán của thuộc lĩnh vực xử lý ngôn ngữ tự nhiên (Natural Language Processing NLP) và lĩnh vực khai phá dữ liệu văn bản (Text Minning TM)"],[107,"Tương tự như bài toán xử lý ngôn ngữ tự nhiên, tóm tắt văn bản sử dụng các đặc trưng ở 3 mức độ: mức độ hình thái, mức độ cu pháp và mức độ ngữ nghĩa"],[108,"Mức độ hình thái Đặc trưng về chủ đề (Thematic): tần suất từ, stop words, TF.IDF"],[109,"Đặc trưng về vị trí (Location): vị trí câu trong văn bản hay đoạn văn (câu đầu tiên mỗi đoạn, n câu đầu tiên của văn bản), phương pháp tiêu đề (câu chứa từ có trong tiêu đề), cue-words, hay fixed-phrased (câu chứa những ngữ cố định)"],[110,"Đặc trưng đồng xuất hiện (co-ocurrence): từ xuất hiện trong nhiều văn bản"],[111,"Đặc trưng về tên riêng (proper name)"],[112,"Đặc trưng về chiều dài câu (short-length cutoff): bỏ nhưng câu ngắn"],[113,"Mức độ cú pháp Đặc trưng về định dạng (format)"],[114,"Đặc trưng về chủ đề trong văn bản (Threads of topic)"],[115,"Đặc trưng về cấu truc chuỗi từ vựng (Lexical chains)"],[116,"Đặc trưng về cấu truc lý luận (Rhetorical structure)"],[117,"Mức độ ngữ nghĩa Đặc trưng về mối liên quan giữa các từ theo từ điển (lexical cohension): đồng nghĩa (synonymy), bao hàm (hypernymy), lặp lại (repetition)"],[118,"Đặc trưng về sự tương tự (similarity): các từ có cùng dẫn xuất (common stem), độ tương đồng giữa các câu"],[119,"Đặc trưng về đồng tham chiếu (coreference) Đặc trưng về mối quan hệ logic"],[120,"Đặc trưng về mối quan hệ biểu diễn ngữ nghĩa"],[121,"Đặc trưng về mối quan hệ cu pháp (grammatical cohesion): trùng lặp (anaphora), tĩnh lược (ellipsis), liên từ (conjuction)"],[122,"17 3.4"],[123,"Các hướng tiếp cận tóm tắt văn bản 3.4.1"],[124,"Phương pháp thống kê Các phương pháp thống kê là những phương pháp đầu tiên được sử dụng trong tóm tắt văn bản"],[125,"Nó sử dụng các dữ liệu thống kê về độ quan trọng của các từ, ngữ, câu hay đoạn để tạo ra bản tóm tắt"],[126,"Các dữ liệu này thường được thu thập dựa trên các tập văn bản mẫu"],[127,"Phương pháp thống kê sử dụng các đặc trưng như: Dựa trên vị trí câu"],[128,"Dựa trên ngữ cố định: gồm ngữ nhấn mạnh và ngữ dư thừa"],[129,"Dựa trên tần suất từ"],[130,"3.4.2"],[131,"Phương pháp cấu trúc Trong các nghiên cứu gần đây có rất nhiều các đặc trưng hiệu quả của câu văn được đề xuất để dùng cho tóm tắt trích xuất, ví dụ như signature word, event hay sentence relevance"],[132,"Phương pháp câu truc sử dụng các mối liên hệ đặc trưng hình thái - ngữ pháp - ngữ nghĩa để xác định các đơn vị ngữ liệu quan trọng, những đơn vị ngữ liệu nào có chứa các thành phần liên quan nhiều với các thành phần khác sẽ có mức độ quan trọng cao"],[133,"Trong mục này sẽ trình bày chi tiết các đặc trưng được xem xét"],[134,"Surface Features Đặc trưng hình thái: Nhóm đặc trưng này xem xét đến đặc điểm hình thái của câu"],[135,"Bao gồm: vị trí của câu trong văn bản - thông thường các câu đầu văn bản thường là các câu chứa đựng chủ đề khái quát của cả bài văn; số lượng từ trong câu - căn cứ vào các kiểu văn bản khác nhau, văn bản báo chí, xa luận, hay bài báo khoa học thì câu văn thường có một độ dài trung bình nhất định, những câu văn có số lượng từ nhỏ hơn ngưỡng đó sẽ là các câu không quan trọng; số lượng trích dẫn trong câu - một câu chứa quá nhiều trích dẫn là câu không quan trọng"],[136,"Content Features Đặc trưng nội dung: bao gồm các đặc trưng nội dung như tần suất từ, giá trị TF-IDF,"],[137,"Relevance Features Đặc trưng độ liên quan: Đặc trưng này được sử dụng để tìm ra mối liên hệ giữa các câu"],[138,"Dựa trên quan hệ giữa các câu/đoạn trong văn bản: xác định mối quan hệ giữa các đoạn trong văn bản hay các câu trong đoạn thông qua các độ đo như Cosine hay PageRank"],[139,"18 3.4.3"],[140,"Phương pháp máy học 3.4.3.1"],[141,"Học có giám sát Phương pháp Nave-Bayes Các hướng tiếp cận theo phương pháp này giả định rằng các đặc trưng của văn bản độc lập nhau"],[142,"Sử dụng bộ phân lớp Nave-Bayes để xác định câu nào thuộc về tóm tắt và ngược lại"],[143,"Cho s là các câu cần xác định"],[144,"F1.Fk là các đặc trưng đa được chọn, và giả định các thuộc tính độc lập nhau"],[145,"Tính xác suất của câu s thuộc về tóm tắt"],[146,"Sau khi tính xác suất các câu, n câu có xác suất cao nhất sẽ được trích xuất"],[147,"Các nghiên cứu đại điện cho phương pháp này: Kupiec và cộng sự [Kupiec95] sử dụng phân lớp Bayes để kết hợp các đặc trưng lại với nhau [26]: o Các đặc trưng sử dụng : word frequency, location, cue word, title & leading, sentence length, uppercase words"],[148,"o Ngữ liệu : 188 cặp văn bản khoa học và tóm tắt"],[149,"Tổng số câu: 568 câu"],[150,"Số câu khớp trực tiếp với tóm tắt 451 (79%)"],[151,"Aone (1999) [2] o Kết hợp thêm nhiều đặc trưng phong phu hơn : tf.idf (single word, two-noun word, named-entities), discourse (cohension) (sử dụng Wordnet và kỹ thuật sử lý ngôn ngữ tự nhiên để phân tích sự tham chiếu đối với các thực thể)"],[152,"o Ngữ liệu : sử dụng ngữ liệu của TREC"],[153,"o Hệ thống : DimSum"],[154,"Phương pháp Decision Tree Lin & Hovy [Lin97] áp dụng phương pháp này nhằm xác định vị trí của các câu quan trọng trong văn bản [10]"],[155,"Lin giả định rằng, các đặc trưng không độc lập với nhau"],[156,"Tác giả đa kiểm tra nhiều đặc trưng và ảnh hưởng của chung lên quá trình rut trích"],[157,"Hệ thống tóm tắt của Lin là loại tóm tắt hướng về truy vấn (query-based)"],[158,"Các đặc trưng: position (OOP), numeric data, proper name, pronoun & adjective, weekday hoặc month, cùng với 2 đăc trưng mới: Query signature (số từ truy vấn có trong câu) và IR signature (những từ nổi bật, quan trọng ~ TFIDF) [10]"],[159,"Support Vector Machine (SVM Máy vector hỗ trợ) SVM nhận dữ liệu vào và xây dựng (learn) một siêu phẳng (hyperplane) để phân lớp (classify) tập dữ liệu thành 2 lớp riêng biệt"],[160,"Về ý tưởng, SVM sử dụng thủ thuật để ánh xạ tập dữ liệu ban đầu vào không gian nhiều chiều hơn"],[161,"Khi đa ánh xạ sang không 19 gian nhiều chiều, SVM sẽ xem xét và chọn ra siêu phẳng phù hợp nhất để phân lớp tập dữ liệu đó"],[162,"SVM [4] đa được biết đến là một trong số các phương pháp phân lớp tốt nhất đối với các bài toán phân lớp văn bản (text/document classification)"],[163,"SVM [4] xác định một hàm phân tách tuyến tính: f(x) = w"],[164,"x + b Trong đó, w là vector trọng số, b là tham số điều chỉnh bias, x là vector đặc trưng"],[165,"Mặt siêu phẳng xác định được được dùng để phân tách các ví dụ đầu vào"],[166,"Nên với ví dụ đầu vào có vector đặc trưng xi sẽ được gán vào lớp dương nếu f(xi) 0 tức nhan lớp (ti) là 1 hoặc được gán vào lớp âm, nhan lớp là 1 nếu ngược lại"],[167,"ti = { 1, w"],[168,"xi + b < 0 1, w"],[169,"xi + b 0 w.x+b=0 là mặt siêu phẳng phân tách các ví dụ huấn luyện lớp dương và các ví dụ huấn luyện lớp âm"],[170,"Trong tóm tắt văn bản, sử dụng SVM kết hợp các đặc trưng câu để gắn nhan cho câu vào hai lớp có trong bản tóm tắt hoặc không có trong tóm tắt"],[171,"20 3.4.3.2"],[172,"Học không giám sát Là kỹ thuật học sử dụng cho các bài toán phân cụm, gom cụm (Clustering)"],[173,"Để sử dụng kỹ thuật này cần có tập đặc trưng học được từ tập dữ liệu huấn luyện"],[174,"Điểm khác biệt so với học có giám sát là trước khi phân cụm thì không biết trong tập dữ liệu mục tiêu có bao nhiêu cụm và những cụm gì"],[175,"Hệ thống học không có giám sát tạo ra các bản tóm tắt bằng cách chỉ truy cập các dữ liệu mục tiêu"],[176,"Nó cố gắng khám phá ra cấu truc bí ẩn trong dữ liệu không dán nhan (chưa được phân lớp)"],[177,"Do đó, chung thích hợp cho bất kỳ dữ liệu mới được quan sát mà không cần bất kỳ sửa đổi tiên tiến"],[178,"Một số phương pháp học không giám sát: Clustering (gom cụm, phân cụm) Phương pháp Hidden Makov Model (Mô hình Makov ẩn) Các đặc trưng sử dụng: position, number of term, likelihood of sentence"],[179,"Mô hình HMM bao gồm 2s + 1 trạng thái, trong đó s là số trạng thái tóm tắt (câu thuộc tóm tắt) và s+1 là câu không thuộc tóm tắt"],[180,"Mô hình HMM xây dựng ma trận chuyển vị M, coi các đặc trưng là đa biến và tính xác suất của các câu qua từng trạng thái"],[181,"Phương pháp phân tích ma trận không âm NMF: Phân tích ma trận không âm - Non-negative matrix factorization là một nhóm các thuật toán phân tích đa biến trong đại số tuyến tính [24]"],[182,"Ma trận A được phân tích thành 2 ma trận W và H với điều kiện là cả 3 ma trận này đều chỉ mang các thuộc tính không âm, Ma trận A được phân tích thành 2 ma trận W và H: A = WH 21 Với A là một ma trận mxn, W là một ma trận mxk, và H là một ma trận kxn, k luôn được chọn có giá trị nhỏ hơn m và n, do đó cả 2 ma trận W và H đều có cỡ nhỏ hơn ma trận A"],[183,"Áp dụng phân tích ma trận NMF vào tóm tắt văn bản: Một thể hiện tự nhiên của các câu trong văn bản tóm tắt chính là một vector"],[184,"Như vậy thể hiện tự nhiên của một văn bản chính là một ma trận"],[185,"Ma trận A là ma trận boolean terms x sentences thu được bằng cách xử lý sơ bộ tập các câu trong văn bản, với term là từ trong văn bản, mỗi câu là một vector trong ma trận, giá trị phần tử của vector câu bằng 1 nếu từ có trong câu"],[186,"Ma trận W là ma trận có giá trị các phần tử bằng giá trị các đặc trưng ngữ nghĩa của câu"],[187,"Phương pháp NMF trích xuất câu có trọng số lớn nhất theo nghĩa: câu đó phản ánh nhiều nhất tới chủ đề chính của tài liệu, điều đó được biểu diễn bởi các đặc trưng ngữ nghĩa"],[188,"3.4.3.3"],[189,"Học nửa giám sát Học nửa giám sát sử dụng cả dữ liệu đa gán nhan và chưa gán nhan để huấn luyện - điển hình là một lượng nhỏ dữ liệu có gán nhan cùng với lượng lớn dữ liệu chưa gán nhan"],[190,"Học nửa giám sát đứng giữa học không giám sát (không có bất kì dữ liệu có nhan nào) và có giám sát (toàn bộ dữ liệu đều được gán nhan)"],[191,"Tuỳ vào từng mục đích cụ thể, học nửa giám sát có thể được áp dụng cho bài toán phân lớp hoặc phân cụm"],[192,"Trong tóm tắt văn bản, học bán giám sát thường được sử dụng để gắn nhan trong văn bản"],[193,"Một số phương pháp học nửa giám sát: Các phương pháp dựa trên đồ thị (Graph-based) Cực đại kỳ vọng (EM - Expectation Maximization) Co-training 22 3.4.4"],[194,"Phương pháp Deep Learning Trong những năm qua, thuật ngữ deep learning (học sâu) đa dần len lỏi mỗi khi có cuộc hội thoại nào bàn về trí tuệ nhân tạo (AI), dữ liệu lớn (Big Data) và phân tích (Analytics)"],[195,"Và với lý do chính đáng đây là một cách tiếp cận đầy hứa hẹn tới AI khi phát triển các hệ thống tự trị, tự học, những thứ đang cách mạng hóa nhiều ngành công nghiệp"],[196,"Về cơ bản, Deep Learning là một là một chi của ngành máy học dựa trên một tập hợp các thuật toán để cố gắng mô hình dữ liệu trừu tượng hóa ở mức cao bằng cách sử dụng nhiều lớp xử lý với cấu trúc phức tạp, hoặc bằng cách khác bao gồm nhiều biến đổi phi tuyến"],[197,"Mỗi lớp kế tiếp dùng đầu ra từ lớp trước làm đầu vào"],[198,"Các thuật toán này có thể được giám sát hoặc không cần giám sát và các ứng dụng bao gồm các mô hình phân tích (không có giám sát) và phân loại (giám sát) [3]"],[199,"Cốt lõi của Deep Learning bao gồm mô hình mạng neural (Neural Network) nhiều lớp và quá trình huấn luyện mạng để xác định các tham số cho mô hình"],[200,"Một kiến trúc mạng phổ biến nhất trong Deep Learning là mạng Neural hồi quy (Recurrent Neural Network RNN) [36]"],[201,"Trong các ứng dụng xử lý ngôn ngữ tự nhiên, dữ liệu có tính chất chuỗi: ví dụ sự xuất hiện của một từ trong 1 câu phụ thuộc vào các từ trước đó"],[202,"Kiến trúc mạng hồi quy đa được đề xuất để tận dụng đặc trưng đó"],[203,"Trong kiến trúc RNN, đầu ra của mỗi tầng sẽ được truyền lại bản thân tầng đó trong 1 số bước nhất định"],[204,"hồi quy ở dạng thức trải dài"],[205,"Trong ví dụ này, ta xem xét một câu bao gồm 3 từ"],[206,"Tầng hồi quy sẽ được trải thành 3 tầng tính toán, mỗi tầng tương ứng với 1 từ"],[207,"Trong hình 1.3, với đầu vào x là một chuỗi các từ, ta có: 23 xt là một từ đơn (đầu vào tại bước t)"],[208,"st là trạng thái ẩn tại bước t"],[209,"Nó chính là bộ nhớ của mạng"],[210,"st được tính toán dựa trên cả các trạng thái ẩn phía trước và đầu vào tại bước đó"],[211,"ot là đầu ra tại bước t (kết quả dự đoán từ tiếp theo) Một trong các mô hình ứng dụng kiến trúc RNN trong xử lý ngôn ngữ tự nhiên là mô hình seq2seq (sequence-to-sequence hay tên gọi khác là encoder-decoder)"],[212,"Về cơ bản, mô hình seq2seq được xây dựng dựa trên hai mạng RNN đóng vai trò là các bộ mã hóa, giải mã"],[213,"Áp dụng mô hình seq2seq vào bài toán tóm tắt văn bản: Bộ mã hoá (encoder) sẽ truyền vào từng từ một trong văn bản đầu vào"],[214,"Mỗi từ (token) sau đó sẽ được đi qua một lớp embedding để biểu diễn từ đó về dạng vector số"],[215,"Vector này sau đó sẽ được đi qua các lớp ẩn, ở mỗi lớp nó lại được kết hợp với những lớp ẩn được sinh ra từ token phía trước, đối với từ đầu tiên thì tất cả các giá trị này đều bằng 0"],[216,"Bộ giải mã (decoder) sẽ nhận layer ẩn cuối cùng của bộ mã hoá kết hợp với token <eos> (kí tự kết thuc câu) là đầu vào"],[217,"Sau đó bộ giải mã sẽ sinh từng từ một và dừng lại khi sinh đến kí tự <eos>"],[218,"Để xây dựng mô hình sử dụng phương pháp Deep Learning, chung ta cần một bộ dữ liệu đầu vào lớn và một máy tính mạnh để tính toán"],[219,"Tuy nhiên, hiện tại, đối với bài toán tóm tắt văn bản, chưa có bô dữ liệu đủ lớn vào đầu vào chuẩn thỏa mãn yêu cầu"],[220,"24 3.5"],[221,"Đánh giá tóm tắt văn bản Độ đo chính xác (precision) [30]: là tỉ số giữa số lượng các câu được cả hệ thống và con người trích xuất trên số các câu được hệ thống trích xuất"],[222,"recision = |SM| | SM | | SH | Độ đo hồi tưởng (recall) [30]: là tỉ số giữa số lượng các câu được trích xuất bởi cả hệ thống và con người trích xuất trên số các câu chỉ được lựa chọn bởi con người"],[223,"Recall = |SH| | SM | | SH | | SM | là số lượng câu của bản tóm tắt do hệ thống trích xuất | H | là số lượng câu của bản tóm tắt do con người trích xuất (lý tưởng) | H M | là số lượng câu được cả hệ thống và con người trích xuất"],[224,"Đánh giá dựa trên nội dung Độ đo ROUGE (Recall-Oriented Understudy for Gisting Evaluation) [29]: là một tập các độ đo so sánh sự tương đồng của bản tóm tắt của một hệ thống tóm tắt tự động và bản tóm tắt lý tưởng (do con người tóm tắt)"],[225,"ROUGE N n-gram là một dãy gồm n ký tự (hoặc âm tiết, từ) liên tiếp nhau trong văn bản"],[226,"ROUGE N sử dụng n-gram đánh giá sự tương quan giữa các kết quả của văn bản tóm tắt và tập dữ liệu đánh giá"],[227,"Công thức: ( ) ( ) match S RS n gram S S RS n gram S Count n gram Count ROUGE am N n gr S: là bản tóm tắt của hệ thống RS: Reference Summaries - tập bản tóm tắt lý tưởng (n-): là số lượng n-gram trùng nhau lớn nhất giữa bản tóm tắt hệ thống và tập bản tóm tắt lý tưởng"],[228,"(n-): Số lượng n-gram có trong tập bản tóm tắt lý tưởng"],[229,"Như vậy, độ đo ROUGE-N thuộc dạng độ đo hồi tưởng (recall-related)"],[230,"25 ROUGE-1 là độ trùng lặp unigrams giữa bản tóm tắt của hệ thống và tập bản tóm tắt mẫu"],[231,"ROUGE-2 là độ trùng lặp bigrams giữa bản tóm tắt của hệ thống và tập bản tóm tắt mẫu"],[232,"Cũng có một lưu ý rằng, số lượng n-gram ở mẫu số trong công thức tính ROUGE- N sẽ tăng lên khi chung ta cho thêm nhiều tham chiếu"],[233,"Điều này hoàn toàn trực quan và hợp lí bởi vì có thể tồn tại nhiều bản tóm tắt tốt"],[234,"Mỗi khi chúng ta thêm một tham chiếu vào tập các văn bản tham chiếu, chúng ta đa mở rộng không gian các văn bản tóm tắt thay thế (alternative summaries)"],[235,"Bằng cách điều khiển các kiểu tham chiếu mà ta thêm vào tập văn bản tham chiếu, chúng ta có thể thiết kế các đánh giá tập trung vào các khía cạnh khác nhau của việc tóm tắt"],[236,"Ngoài ra, tổng tử số lớn hơn tổng số số bản tóm tắt tham chiếu"],[237,"Điều này hiệu quả vì cung cấp thêm nhiều trọng số để so khớp các n-grams xảy ra trong đa tham chiếu"],[238,"Do đó, một bản tóm tắt tự động càng chứa nhiều những từ được xuất hiện trong nhiều bản tóm tắt tham chiếu thì sẽ dành được điểm ROUGE-N càng cao"],[239,"Điều này một lần nữa lại rất trực quan và hợp lí bởi vì chung ta thường ưu tiên các bản tóm tắt tự động càng có nhiều nét giống với các điểm giống nhau giữa các bản tóm tắt tham chiếu càng tốt"],[240,"Khi sử dụng đa tham chiếu, chúng ta tính ROUGE-N theo từng cặp, giữa bản tóm tắt tự động s và từng bản tóm tắt tham chiếu ri trong tập các văn bản tóm tắt tham chiếu"],[241,"Sau đó, kết quả điểm ROUGE-N cuối cùng trong đa tham chiếu sẽ là điểm ROUGE-N cao nhất trong tất cả các cặp được tính"],[242,"Điều này được thể hiện theo công thức sau: = ( , ) Trong quá trình khởi tạo, thuật toán đánh giá sử dụng thủ tục Jackknifing"],[243,"Cho M tham chiếu, chung ta tính điểm tốt nhất khi duyệt qua M tập tham chiếu M-1; điểm ROUGE-N cuối cùng là trung bình cộng của M điểm ROUGE-N đối với các tham chiếu M-1"],[244,"Thủ tục Jackknifing được chọn bởi chung ta thường cần so sánh hiệu suất giữa con người và hệ thống và bản tóm tắt tham chiếu thường chỉ do con người tạo ra"],[245,"Bằng cách áp dụng thủ tục này, chúng ta có thể ước lượng hiệu suất trung bình của con người bằng việc lấy trung bình cộng M điểm ROUGE-N của một bản tham chiếu với toàn bộ M-1 tham chiếu"],[246,"ROUGE L (Longest Common Subsequence Chuỗi con chung dài nhất) Độ đo này tính tỷ lệ giữa độ dài chuỗi chung dài nhất của bản tóm tắt hệ thống và bản tóm tắt lý tưởng"],[247,"LCS tìm ra độ dài của chuỗi con chung dài nhất giữa văn bản X và Y, độ dài của chuỗi con chung dài nhất càng lớn thì 2 văn bản X, Y càng giống nhau"],[248,"26 ength() là độ dài của X; ength() là độ dài của Y; dit(,) là khoảng cách biên tập giữa X và Y (là số lượng tối thiểu của việc xóa và chèn thêm cần thiết để biến đổi X thành Y)"],[249,"m là độ dài của bản tóm tắt lý tưởng X, n là độ dài của bản tóm tắt hệ thống Y"],[250,"R là độ đo recall của X và Y, P là độ đo precision giữa X và Y"],[251,"ROUGE-W (Weighted Longest Common Subsequence) Trọng số của chuỗi chiều dài lớn nhất, là mở rộng của ROUGE-L"],[252,"ROUGE S (Skip-Bigram Co-Occurrence Statistics) SKIP2(X,Y) là số lượng bigram chung giữa X và Y"],[253,"R là độ hồi tưởng giữa X và Y, P là độ chính xác giữa X và Y"],[254,"27 CHƯƠNG 2: HƯỚNG GIẢI QUYẾT ĐỀ TÀI 1"],[255,"Bài toán cụ thể Trong các nghiên cứu gần đây, bài toán tóm tắt văn bản thường được tiếp cận bởi các phương pháp học máy không giám sát"],[256,"Phương pháp này thường giảm chi phí khi xây dựng bộ dữ liệu, giảm độ phức tạp tính toán thông qua mô hình học máy"],[257,"Tuy nhiên, độ chính xác phương pháp tiếp cận này của tóm tắt văn bản không cao, vì phương pháp này chỉ chọn câu vào văn bản tóm tắt bằng cách tính toán điểm của câu dựa trên kết hợp các đặc trưng rồi chọn câu có điểm số cao"],[258,"Vì vậy, để giảm thời gian tính toán, nâng cao chất lượng, độ chính xác tóm tắt thông qua việc lựa chọn bộ dữ liệu được huấn luyện bởi các chuyên gia, em lựa chọn mô hình học có giám sát Naive Bayes áp dụng cho bài toán tóm tắt đơn văn bản theo hướng trích xuất"],[259,"Hiện nay chưa có bộ dữ liệu huấn luyện chuẩn phục vụ tóm tắt trích xuất cho tiếng Việt, nên em xây dựng hệ thống tóm tắt văn bản tiếng Anh"],[260,"Nave Bayes là một phương pháp học máy có giám sát, tốc độ xử lý nhanh và cho kết quả có độ chính xác tương đối cao"],[261,"Để cải thiện độ chính xác của mô hình, em sử dụng giải thuật AdaBoost"],[262,"Đồ án sử dụng tập dữ liệu của DUC [13] để huấn luyện và thực nghiệm"],[263,"DUC (Document Understanding Conference) là một hội nghị quốc tế để đánh giá hiệu suất của hệ thống tóm tắt bằng cách so sánh bản tóm tắt bằng tay của các chuyên gia với bản tóm tắt tự động của máy tính"],[264,"Các bộ dữ liệu phục vụ tóm tắt đơn văn bản của DUC như DUC2004, DUC2003 chỉ đưa ra bản tóm tắt rất ngắn (khoảng 100 ký tự) không phù hợp với yêu cầu bài toán, nên không thể sử dụng các bộ dữ liệu này"],[265,"Do đó, em sử dụng bộ dữ liệu DUC2007"],[266,"Đây là bộ dữ liệu dùng cho tác vụ tóm tắt đa văn bản, gồm 45 cụm văn bản, mỗi cụm gồm 25 văn bản là các bài báo có cùng chủ đề"],[267,"Để phù hợp với bài toán tóm tắt đơn văn bản, ta ghép các văn bản trong mỗi cụm văn bản đó thành một đơn văn bản"],[268,"Tập bản tóm tắt mẫu sử dụng cho hệ thống là bản tóm tắt của 4 chuyên gia, mỗi bản dài 250 từ, do đó bản tóm tắt của hệ thống cũng có độ dài không quá 250 từ"],[269,"Độ chính xác văn bản tóm tắt của hệ thống được so với cả 4 văn bản của chuyên gia"],[270,"Bộ dữ liệu huấn luyện của DUC2007 gồm các văn bản dạng SCU, được hỗ trợ đánh dấu các câu quan trọng có liên quan đến các câu trong bản tóm tắt của chuyên gia"],[271,"28 2"],[272,"Cơ sở lý thuyết 2.1"],[273,"Phương pháp Nave Bayes Xét bài toán phân lớp với C classes: 1,2,.,C"],[274,"Giả sử có một điểm dữ liệu x Rd"],[275,"Tính xác suất để điểm dữ liệu này rơi vào class c"],[276,"Nói cách khác, cần tính xác suất p(y=c|x) hay p(c|x) (xác suất có điều kiện cho mỗi lớp với mỗi giá trị x) để đầu ra là class c biết rằng đầu vào là vector x [8]"],[277,"Xác định được xác suất để điểm dữ liệu rơi vào mỗi class sẽ giup chung ta xác định class của điểm dữ liệu đó bằng cách chọn ra class có xác suất cao nhất: {1,...,C} arg |max c c p c x (1) Biểu thức (1) thường khó được tính trực tiếp"],[278,"Thay vào đó, quy tắc Bayes thường được sử dụng: arg |max c c p c x Áp dụng quy tắc Bayes p(c|x).p(x) = p(x|c).p(c) ta có: | arg ( ) max c p c p c c p x x Do mẫu số p(x) không phụ thuộc vào c nên: arg |max c c p c p c x Xác suất của mỗi lớp p(c) có thể được hiểu là xác suất để một điểm rơi vào class c"],[279,"Giá trị này có thể được tính tỉ lệ số điểm dữ liệu trong tập training rơi vào class c chia cho tổng số lượng dữ liệu trong tập training"],[280,"Thành phần còn lại p(x|c), tức phân phối của các điểm dữ liệu trong class c, thường rất khó tính toán vì x là một biến ngẫu nhiên nhiều chiều, cần rất rất nhiều dữ liệu training để có thể xây dựng được phân phối đó"],[281,"Để giup cho việc tính toán được đơn giản, người ta thường giả sử một cách đơn giản nhất rằng các thành phần của biến ngẫu nhiên x là độc lập, nếu biết c"],[282,"Tức là: 1 1 2| | (, |, , )d d i i p x cp c p x x x c x Giả thiết các chiều của dữ liệu độc lập với nhau, nếu biết c, là quá chặt và ít khi tìm được dữ liệu mà các thành phần hoàn toàn độc lập với nhau"],[283,"Tuy nhiên, giả thiết này 29 lại mang lại những kết quả tốt bất ngờ"],[284,"Cách xác định class của dữ liệu dựa trên giả thiết này có tên là Naive Bayes Classifier"],[285,"Naive Bayes Classifier là một thuật toán đơn giản nhưng mạnh mẽ về mô hình dự đoán"],[286,"Naive Bayes Classifier được gọi là naive vì nó giả định rằng mỗi biến đầu vào là độc lập"],[287,"Đây là một giả định mạnh mẽ và không thực tế đối với dữ liệu thực, tuy nhiên, kĩ thuật này rất hiệu quả trên một phạm vi rộng lớn với các vấn đề phức tạp"],[288,"Naive Bayes Classifier có tốc độ training và test rất nhanh"],[289,"Việc này giup nó mang lại hiệu quả cao trong các bài toán large-scale"],[290,"Ở bước training, các phân phối p(c) và p(xi|c), i=1,., d sẽ được xác định dựa vào training data"],[291,"Ở bước test, với một điểm dữ liệu mới x, class của nó được xác định bởi: {1,...,C} 1 arg ( | )max d i c i c p p x cc (2) Khi d lớn và các xác suất nhỏ, biểu thức ở vế phải của (2) sẽ là một số rất nhỏ, khi tính toán có thể gặp sai số"],[292,"Để giải quyết việc này, (2) thường được viết lại dưới dạng tương đương bằng cách lấy log của vế phải: 30 {1,...,C} 1 arg log ( ( | ))max d X i c i c log p p x cc Việc này không ảnh hưởng tới kết quả vì loglog là một hàm đồng biến trên tập các số dương"],[293,"Cả việc training và test của NBC là cực kỳ nhanh khi so với các phương pháp classification phức tạp khác"],[294,"Việc giả sử các thành phần trong dữ liệu là độc lập với nhau, nếu biết class, khiến cho việc tính toán mỗi phân phối p(xi|c) trở nên cực kỳ nhanh"],[295,"Mỗi giá trị p(c), c = 1, 2,., C có thể được xác định như là tần suất xuất hiện của class c trong training data"],[296,"Việc tính toán p(xi|c) phụ thuộc vào loại dữ liệu"],[297,"Có ba loại được sử dụng phổ biến là: Gaussian Naive Bayes, Multinomial Naive Bayes, và Bernoulli Naive"],[298,"2.1.1"],[299,"Gaussian Naive Bayes Mô hình này được sử dụng chủ yếu trong loại dữ liệu mà các thành phần là các biến liên tục"],[300,"Với mỗi chiều dữ liệu i và một class ci, xi tuân theo một phân phối chuẩn có kỳ vọng ci và phương sai 2 ci [8]: 2 2 22 ( )1 ( | ) ( | , ) exp 22 ci i i ci ci cici x p x c p x Trong đó, bộ tham số = { ci , 2 ci } được xác định bằng: 2 2 ( ) 2 , 1 ( , ) arg ( | )max ci ci N n ci ci i ci i p x 2.1.2"],[301,"Multinomial Naive Bayes Mô hình này chủ yếu được sử dụng trong phân loại văn bản mà feature vectors được tính bằng Bags of Words"],[302,"Luc này, mỗi văn bản được biểu diễn bởi một vector có độ dài d chính là số từ trong từ điển"],[303,"Giá trị của thành phần thứ i trong mỗi vector chính là số lần từ thứ i xuất hiện trong văn bản đó"],[304,"Khi đó, p(xi|c) tỉ lệ với tần suất từ thứ i (hay feature thứ i cho trường hợp tổng quát) xuất hiện trong các văn bản của class c"],[305,"Giá trị này có thể được tính bằng cách: | cici c ip x c N N http://scikit-learn.org/dev/modules/classes.html#module-sklearn.naive_bayes http://scikit-learn.org/dev/modules/classes.html#module-sklearn.naive_bayes 31 Trong đó: - ciN là tổng số lần từ thứ i xuất hiện trong các văn bản của class c, nó được tính là tổng của tất cả các thành phần thứ i của các feature vectors ứng với class c"],[306,"- cN là tổng số từ (kể cả lặp) xuất hiện trong class c"],[307,"Nói cách khác, nó bằng tổng độ dài của toàn bộ các văn bản thuộc vào class c"],[308,"Có thể suy ra rằng: 1 d c ci i N N từ đó 1 1 d ci i [8] Cách tính này có một hạn chế là nếu có một từ mới chưa bao giờ xuất hiện trong class c thì biểu thức (1) sẽ bằng 0"],[309,"Việc này sẽ dẫn đến kết quả không chính xác"],[310,"Để giải quyết việc này, một kỹ thuật được gọi là Laplace smoothing được áp dụng: ' ci i c c N d N Với là một số dương, thường bằng 1, để tránh trường hợp tử số bằng 0"],[311,"Mẫu số được cộng với d để đảm bảo tổng xác suất 1 1 d ci i Như vậy, mỗi class c sẽ được mô tả bởi bộ các số dương có tổng bằng 1: ' ' ' 1, { },ci c cd"],[312,"2.1.3"],[313,"Bernoulli Naive Bayes Mô hình này được áp dụng cho các loại dữ liệu mà mỗi thành phần là một giá trị binary - bẳng 0 hoặc 1"],[314,"Ví dụ: cũng với loại văn bản nhưng thay vì đếm tổng số lần xuất hiện của 1 từ trong văn bản, ta chỉ cần quan tâm từ đó có xuất hiện hay không"],[315,"Khi đó, p(xi|c) được tính bằng: p(xi|c) = p(i|c)xi + (1p(i|c)(1xi) với p(i|c) là xác suất từ thứ i xuất hiện trong các văn bản của class c [8]"],[316,"32 2.2"],[317,"Thuật toán AdaBoost 2.2.1"],[318,"Giới thiệu về thuật toán boosting Về lịch sử, boosting bắt nguồn từ câu hỏi nổi tiếng được đưa ra bơi Kearns vào năm 1989: Liệu có thể tạo ra một strong classifier từ một tập các weak learner?"],[319,"Năm 1990, Robert Schaire và Simard kiểm nghiệm trong các chương trình nhận dạng [26]"],[320,"Freund đa tiếp tục các nghiên cứu của Schaprire, và đến năm 1995 thì ông cùng Schaprire phát triển boosting thành AdaBoost"],[321,"Boosting là thuật toán đồng bộ (ensemble algorithms) bằng cách xây dựng nhiều thuật toán học cùng lúc (gọi là các weak learner) và kết hợp chúng lại để tạo ra một strong learner duy nhất [40]"],[322,"Các weak learner chỉ cần có độ chính xác trên 50%, được huấn luyện độc lập và kết quả dự đoán cuối cùng mô hình boosting dựa trên kết quả bỏ phiếu của từng mô hình con đó cho kết quả đầu ra"],[323,"Bằng cách này, chúng ta nói bộ phân loại đa được boost"],[324,"Để hiểu cách hoạt động của thuật toán boosting, ta xét một bài toán phân loại 2 lớp (mẫu cần nhận dạng chỉ thuộc một trong hai lớp) với D là tập huấn luyện gồm có n mẫu"],[325,"Trước tiên, chúng ta sẽ chọn ngẫu nhiên ra n1 mẫu từ tập D tạo thành tập D1"],[326,"Sau đó, chung ta sẽ xây dựng weak learner đầu tiên C1 từ tập D1"],[327,"Tiếp theo, chúng ta xây dựng tập D2 để huấn luyện bộ phân loại C2"],[328,"D2 sẽ được xây dựng sao cho một nửa số mẫu của nó được phân loại đung bởi C1 và nửa còn lại bị phân loại sai bởi C1"],[329,"Bằng cách này, D2 chứa đựng những thông tin bổ sung cho C1"],[330,"Bây giờ chung ta sẽ xây huấn luyện C2 từ D2"],[331,"Tiếp theo, chúng ta sẽ xây dựng tập D3 từ những mẫu không được phân loại tốt bởi sự kết hợp giữa C1 và C2: những mẫu còn lại trong D mà C1 và C2 cho kết quả khác nhau"],[332,"Như vậy, D3 sẽ gồm những mẫu mà C1 và C2 hoạt động không hiệu quả"],[333,"Sau cùng, chúng ta sẽ huấn luyện bộ phân loại C3 từ D3"],[334,"Bây giờ chung ta đa có một strong classifier: sự kết hợp C1, C2 và C3"],[335,"Khi tiến hành nhận dạng một mẫu X, kết quả sẽ được quyết định bởi sự thỏa thuận của 3 bộ C1, C2 và C3: Nếu cả C1 và C2 đều phân X vào cùng một lớp thì lớp này chính là kết quả phân loại của X; ngược lại, nếu C1 và C2 phân X vào 2 lớp khác nhau, C3 sẽ quyết định X thuộc về lớp nào"],[336,"33 Một số phương pháp boosting đáng chu ý: - Adaboost (Adaptive Boosting) - Gradient Boosting - XGBoost 2.2.2"],[337,"Thuật toán AdaBoost AdaBoost là thuật toán boosting thành công đầu tiên được phát triển để phân loại nhị phân, được Freund và Schapire đưa ra vào năm 1995 [35]"],[338,"Đây là điểm khởi đầu tốt nhất để hiểu về boosting"],[339,"Tư tưởng của thuật toán AdaBoost đấy là kết hợp các weak learner thành một strong learner"],[340,"Trong quá trình xây dựng, weak learner tiếp theo sẽ được xây dựng dựa trên các đánh giá về các weak learner trước, cuối cùng các weak learner sẽ được kết hợp để trở thành strong learner"],[341,"Để có thể kết hợp các weak learner, AdaBoost sử dụng một trọng số (weight) để đánh dấu các mẫu khó nhận dạng"],[342,"Trong quá trình huấn luyện, cứ mỗi weak learner được xây dựng, thuật toán sẽ tiến hành cập nhật lại trọng số để chuẩn bị cho việc xây dựng weak learner tiếp theo: tăng trọng số của các mẫu bị nhận dạng sai và giảm trọng số của các mẫu được nhận dạng đung bởi weak learner vừa xây dựng"],[343,"Bằng cách này, các weak learner sau có thể tập trung vào các mẫu mà các weak learner trước đó chưa thực hiện tốt"],[344,"Sau cùng các weak learner sẽ được kết hợp tùy theo mức độ tốt của chung để tạo nên một strong classifier"],[345,"34 Các bước xây dựng mô hình AdaBoost: (1) Xét tập dữ liệu huấn luyện gồm n mẫu có đánh dấu (x1,y1), (x2,y2),"],[346,"(xn,yn) với xk (xk1, xk2, ., xkm) là vector đặc trưng, yi {+1,1} là lớp của mẫu"],[347,"Trọng số khởi tạo cho mỗi mẫu có giá trị: w(xi) = 1 , i = 1, ., n (2) Xây dựng mô hình M weak classifiers h, h cho kết quả phân loại là +1 hoặc -1"],[348,"Lặp m = 1,., M: Với mỗi đặc trưng trong vector đặc trưng, xây dựng một weak classifier hj với trọng số phân loại sai j"],[349,"j được tính bằng công thức: 35 : ( ) w( ) i i i i h j x y x Chọn hm có trọng số phân loại sai m thấp nhất"],[350,"Cập nhật lại trọng số của mẫu: 1 w ( )*exp( h ( )) w ( ) m i m i m im i m x y x x Z Với: Zm là hệ số chuẩn hóa để đảm bảo tổng trọng số các mẫu bằng 1"],[351,"11 ln 2 m m m Ta thấy, hàm lũy thừa exp( h ( ))m i m iy x trên tử số sẽ luôn có giá trị lớn hơn 1 (do với mẫu phân loại sai thì tích h ( ) 1i m iy x , m > 0 nên h ( )i m i my x < 0 )"],[352,"Vì vậy, các trường hợp mẫu phân loại sai sẽ được cập nhật với trọng số lớn hơn sau mỗi lần lặp"],[353,"(3) Sau khi lặp M weak classifier, chung ta có thể nhận được dự đoán cuối cùng bằng cách tổng kết dự đoán trọng số của mỗi weak classifier"],[354,"Strong classifier H(x) được xây dựng như sau: 1 ( ) ( ) M m m m H x sign h x Giải thích Quá trình huấn luyện bộ phân loại được thực hiện bằng một vòng lặp mà ở mỗi bước lặp, thuật toán sẽ chọn ra bộ phân loại yếu hm có trọng số phân loại sai nhỏ nhất m (do đó sẽ là weak classifier) để bổ sung vào strong classifier"],[355,"Mỗi khi chọn được 1 weak classifier hm, AdaBoost sẽ tính giá trị m theo công thức ở trên, m cũng được chọn trên nguyên tắc làm giảm giá trị trọng số phân loại sai m"],[356,"36 Hệ số m nói lên mức độ quan trọng của hm"],[357,"Thật vậy: - Trong công thức phân loại H(x): 1 ( ) ( ) M m m m H x sign h x Ta thấy tất cả các weak classifier hm đều có đóng góp vào kết quả phân loại của H(x), và mức độ đóng góp của chung phụ thuộc vào giá trị m tương ứng: hm với m càng lớn thì nó càng có vai trò quan trọng H(x)"],[358,"- Trong công thức tính m : 11 ln 2 m m m Ta thấy giá trị m tỉ lệ nghịch với m"],[359,"Bởi hm được chọn với tiêu chí đạt trọng số phân loại sai nhỏ nhất, do đó nó sẽ đảm bảo giá trị m lớn nhất"],[360,"Công thức này do Fruend và Schapire đưa ra"],[361,"Sau khi tính được giá trị m , AdaBoost tiến hành cập nhật lại trọng số của các mẫu thông qua việc tăng trọng số các mẫu mà hm phân loại sai, giảm trọng số mà các hm phân loại đung"],[362,"Bằng cách này, trọng số của mẫu phản ảnh được mức độ khó nhận dạng của mẫu đó và hm+1 sẽ ưu tiên học cách phân loại những mẫu này"],[363,"AdaBoost là thuật toán đơn giản và dễ dàng cài đặt"],[364,"Thêm vào đó, tốc độ học rất nhanh"],[365,"Các weak learner đơn giản hơn rất nhiều các strong learner, nhờ vậy thuật toán chạy nhanh hơn"],[366,"Một điều nữa, AdaBoost là phương pháp có khả năng điều chỉnh các classifier rất tinh tế"],[367,"Vì mỗi hiệp AdaBoost lại tinh chỉnh lại các trọng số cho các learner tốt nhất"],[368,"Điều bạn cần làm đó là xác định số hiệp để lặp"],[369,"Cuối cùng, đây là thuật toán linh hoạt và đa năng"],[370,"AdaBoost có thể kết hợp với bất kỳ thuật toán học máy nào và nó có thể làm việc với một lượng lớn dữ liệu khác nhau"],[371,"37 3"],[372,"Mô hình đề xuất Tóm tắt đơn văn bản là một quá trình tóm tắt tự động với đầu vào là một văn bản, đầu ra là một đoạn văn bản ngắn gọn mô tả nội dung chính của văn bản đầu"],[373,"Đơn văn bản có thể là một trang Web, một bài báo, một tài liệu dạng văn bản (ví dụ: .doc, .txt).."],[374,"Tóm tắt văn bản đơn là bước làm cơ sở cho việc xử lý tóm tắt đa văn bản và các bài toán tóm tắt phức tạp hơn"],[375,"38 3.1"],[376,"Khối tiền xử lý văn bản Bước tiền xử lý gồm 2 hoạt động chính là Chuẩn hoá từ và Loại bỏ các cấu truc ngữ pháp của từ, đưa về dạng nguyên thể trong tiếng Anh"],[377,"Cả hai hoạt động này đều đóng vai trò quan trọng trong việc vec-tơ hóa tài liệu bởi vì nó sẽ làm giảm không gian biểu diễn của văn bản xuống, do đó làm giảm khối lượng cần tính toán"],[378,"Cụ thể, quá trình tiền xử lí văn bản đầu vào bao gồm các công việc sau: Chia văn bản đầu vào thành tập các câu"],[379,"Loại bỏ từ dừng (stopwords) Trong quá trình tính toán, stopwords là những từ được lọc trước hoặc sau quá trình xử lý dữ liệu ngôn ngữ tự nhiên (văn bản)"],[380,"Stopwords thường là những từ xuất hiện với tần suất lớn trong một ngôn ngữ, do đó không có một danh sách các stopwords thống nhất và được sử dụng bởi tất cả các công cụ xử lý ngôn ngữ tự nhiên"],[381,"Một nhóm bất kì các từ có thể được chọn là một stopwords để thực hiện một mục đích nhất định"],[382,"Đối với một search engine, có một số từ được xếp vào loại stop words do sự xuất hiện thường xuyên trong các trường hợp tìm kiếm như: the, is, at, which và on"],[383,"Trong trường hợp này, stopwords có thể là nguyên nhân gây ra vấn đề khi tìm kiếm theo phrases mà bao gồm những function word này, đặc biệt là khi tìm kiếm một số tên như: The Who, The The, hoặc Take That"],[384,"Ngoài ra, một số search engine loại bỏ các từ common words, bao gồm cả lexical words như want khỏi câu truy vấn nhằm mục đích cải thiện hiệu suất của search engine"],[385,"Sự phân biệt giữa function words và lexical words được đề xuất bởi C"],[386,"Fries vào năm 1952 và có một tầm ảnh hưởng lớn đến việc dạy tiếng Anh"],[387,"Function words: Còn gọi là functors là những từ có một chut lexical meaning hoặc có sự nhập nhằng về nghĩa và chung nhấn mạnh mối quan hệ ngữ pháp với các từ khác trong cùng một câu, một quan điểm cụ thể hay tâm trạng của người nói"],[388,"Một số trường hợp của function words: Pronouns đại từ (he him, she-her,.); conjunction liên từ hoặc auxiliary verb - trợ động từ Lexical words: Từ thực, những từ mà không phải là function word"],[389,"Lexical word bao gôm: danh từ, động từ, tính từ và hầu hết trạng từ vì có một số trạng từ là function word như: then, why"],[390,"Từ điển có thể định nghĩa một cách cụ thể một lexical word, nhưng chỉ có thể miêu tả một cách sử dụng tổng quát của function word"],[391,"Ngược lại, ngữ pháp có thể miêu tả cách sử dụng của function words một cách chi tiết, nhưng lại chỉ có thể xem lexical words trong các thuật ngữ chung (general term)"],[392,"39 Chuẩn hóa từ bằng lemmatizing và stemming o Stemming: Stemming là kĩ thuật dùng để biến đổi một từ về dạng gốc (được gọi là stem hoặc root form) bằng cách cực kì đơn giản là loại bỏ một số kí tự nằm ở cuối từ mà nó nghĩ rằng là biến thể của từ"],[393,"Người ta gọi các bộ xử lí stemming là stemmer [7]"],[394,"Ví dụ như chung ta thấy các từ như walked, walking, walks chỉ khác nhau là ở những ký tự cuối cùng, bằng cách bỏ đi các hậu tố -ed, -ing hoặc -s, chung ta sẽ được từ nguyên gốc là walk"],[395,"Bởi vì nguyên tắc hoạt động của stemmer rất đơn giản nên tốc độ xử lí của nó rất nhanh nhưng đôi khi lại cho ra kết quả không như ý muốn"],[396,"Ví dụ từ goes sẽ được stem thành từ goe (bỏ chữ s cuối từ) trong khi đó stem của từ go vẫn là go, kết quả là 2 từ goes và go sau khi được stem thì vẫn không giống nhau"],[397,"Một nhược điểm khác là nếu các từ dạng bất quy tắt như went hay spoke thì stemmer sẽ không thể đưa các từ này về dạng gốc là go hay speak"],[398,"o Lemmatization: là một kĩ thuật chuẩn hóa từ khác: Không giống với Stemming là xử lí bằng cách loại bỏ các kí tự cuối từ một cách kinh nghiệm (heuristic), Lemmatization sẽ xử lí thông minh hơn bằng một bộ từ điển hoặc ontology (hệ thống nhan ngữ nghĩa) nào đó"],[399,"Điều này đảm bảo đưa chính xác các dạng biến thể của từ về nguyên gốc trong từ điển"],[400,"Người ta gọi bộ xử lí lemmatization là lemmatizer"],[401,"Nhược điểm của lemmatization là tốc độ xử lí khá chậm vì phải thực hiện tra cứu từ trong cơ sở dữ liệu"],[402,"Trong các ứng dụng xử lí ngôn ngữ tự nhiên mà cần độ chính xác cao hơn và thời gian không quan trọng, người ta có thể sử dụng Lemmatization [7]"],[403,"Ví dụ: Các từ như gose, wentsẽ được đưa chính xác về go"],[404,"Các danh từ như mouse, mice cũng được đưa về cùng một dạng như nhau"],[405,"3.2"],[406,"Khối tính giá trị các đặc trưng 3.2.1"],[407,"Đặc trưng hình thái Là các đặc trưng dựa trên cấu truc văn bản hoặc câu"],[408,"Tầm quan trọng của câu dựa trên các đặc điểm như: Câu đầu văn bản hoặc đầu đoạn văn thường quan trọng [25] Các câu ở phần trước văn bản thường quan trọng hơn những câu ở phần sau [25] Câu có số từ (không tính các từ dừng) trong một giới hạn xác định (đối với từng loại văn bản) thường là câu quan trọng [25]"],[409,"40 Trong phạm vi đồ án, em sẽ tính giá trị các đặc trưng hình thái sau: Position: Vị trí của câu trong văn bản"],[410,"DocFirst: Câu có là câu đầu văn bản hay không"],[411,"DocFirst bằng 1 nếu câu là câu đầu văn bản và bằng 0 trong các tường hợp còn lại"],[412,"Length : Độ dài của câu"],[413,"Ngưỡng độ dài trung bình (giá trị cutoff) được quy định cho câu văn thuộc chủ đề báo chí là 10"],[414,"Như vậy, trọng số độ dài câu tính bằng công thức: Length 10S S length length Với lengthS là độ dài câu S"],[415,"Nếu lengthS < 10 thì coi Length = 0"],[416,"3.2.2"],[417,"Đặc trưng nội dung Đặc trưng nội dung thường xét: từ trọng tâm và từ có tần suất xuất hiện cao"],[418,"Các đặc trưng sẽ sử dụng: Đặc trưng frequence words (từ có tần suất xuất hiện lớn): dựa vào giá trị TF của các từ trong câu"],[419,"Ở đây, em sẽ lấy ngưỡng 30% từ có tần suất xuất hiện nhiều nhất trong văn bản"],[420,"TF (term frequency) [9] tần số xuất hiện của 1 từ trong 1 văn bản, được tính bằng công thức: f max{f , , , : } t d t d w d w d tf Trong đó: Thương của số lần xuất hiện 1 từ trong văn bản và số lần xuất hiện nhiều nhất của một từ bất kỳ trong văn bản đó"],[421,"(giá trị sẽ thuộc khoảng [0, 1]) f(t, d) - số lần xuất hiện từ t trong văn bản d"],[422,"max{f(w, d): wd} - số lần xuất hiện nhiều nhất của một từ bất kỳ trong văn bản"],[423,"Trong phạm vi đồ án, em sẽ tính đặc trưng tần suất từ đối với uni-gram và bi- gram của từng câu trong văn bản: + FreqWordUni: tổng trọng số các uni-gram có tần suất xuất hiện cao nhất của câu S trong văn bản d: uni (uni, ) S tf dFreqWordUni Với uni thuộc tập các uni-grams trong top 30% uni-grams có giá trị tf cao nhất trong văn bản d"],[424,"+ FreqWordBi: tổng trọng số các bi-grams có tần suất xuất hiện cao nhất 41 bi (bi, ) S tf dFreqWordBi Với bi thuộc tập các bi-grams trong top 30% bi-grams có giá trị tf cao nhất trong văn bản d"],[425,"Đặc trưng centroid (từ trọng tâm): dựa vào giá trị TF-IDF của các từ trong câu"],[426,"Từ trọng tâm là các từ xuất hiện nhiều trong 1 văn bản nhưng xuất hiện ít trong các văn bản khác"],[427,"Ở đây, em sẽ lấy ngưỡng 30% từ có giá trị TF-IDF cao nhất trong văn bản"],[428,"Xét khái niệm IDF (inverse document frequency) [33] tần số nghịch của 1 từ trong tập văn bản (corpus)"],[429,"Tính IDF để giảm giá trị của những từ phổ biến"],[430,"Mỗi từ chỉ có 1 giá trị IDF duy nhất trong tập văn bản"],[431,"| | log |{ : , } | t D d D D t d idf Trong đó: |D| - tổng số văn bản trong tập D |{dD: td}| - số văn bản chứa từ nhất định, với điều kiện t xuất hiện trong văn bản d (i.e., tf(t,d) khác 0)"],[432,"Nếu từ đó không xuất hiện ở bất cứ 1 văn bản nào trong tập thì mẫu số sẽ bằng 0 => phép chia cho không không hợp lệ, vì thế người ta thường thay bằng mẫu thức 1+|{dD: td}|"],[433,"Cơ số logarit trong công thức này không thay đổi giá trị của 1 từ mà chỉ thu hẹp khoảng giá trị của từ đó"],[434,"Vì thay đổi cơ số sẽ dẫn đến việc giá trị của các từ thay đổi bởi một số nhất định và tỷ lệ giữa các trọng lượng với nhau sẽ không thay đổi"],[435,"(nói cách khác, thay đổi cơ số sẽ không ảnh hưởng đến tỷ lệ giữa các giá trị IDF)"],[436,"Tuy nhiên việc thay đổi khoảng giá trị sẽ giup tỷ lệ giữa IDF và TF tương đồng để dùng cho công thức TF-IDF như bên dưới"],[437,"tfidf(t, d, D)= tf(t, d) idf(t, D) Những từ có giá trị TF-IDF cao là những từ xuất hiện nhiều trong văn bản này, và xuất hiện ít trong các văn bản khác"],[438,"Việc này giup lọc ra những từ phổ biến và giữ lại những từ có giá trị cao (từ trọng tâm của văn bản đó)"],[439,"Trong phạm vị đồ án, em sẽ tính đặc trưng từ trọng tâm đối uni-gram và bi-grams của từng câu trong văn bản: + CentroidUni: tổng trọng số tfidf của các uni-gram trọng tâm trong câu S của văn bản d trong tập văn bản D: 42 uni (uni, , ) S tfidf d DCentroidUni Với uni thuộc tập các uni-grams trong top 30% uni-grams có giá trị tfidf cao nhất trong văn bản d"],[440,"+ CentroidBi: tổng trọng số tfidf của các bi-grams trọng tâm trong câu S của văn bản d trong tập văn bản D: bi (bi, , ) S tfidCentroidB f d Di Với bi thuộc tập các bi-grams trong top 30% bi-grams có giá trị tfidf cao nhất trong văn bản d"],[441,"3.2.3"],[442,"Đặc trưng độ liên quan Đặc trưng này khai thác mối quan hệ giữa các câu"],[443,"Giả thiết rằng: Các câu liên quan đến câu quan trọng là câu quan trọng"],[444,"Các câu liên quan đến nhiều câu khác là câu quan trọng"],[445,"Câu đầu văn bản hoặc đầu đoạn là câu quan trọng, và những câu khác trong văn bản được so sánh với câu đầu"],[446,"Có 2 loại đặc trưng độ liên quan giữa các câu được đo bằng cách so sánh độ tương đồng các cặp câu: FirstRel và PageRankRel"],[447,"3.2.3.1"],[448,"FirstRel Là độ tương đồng với câu đầu văn bản: = ( , 1) Với i là vị trí các câu trong văn bản"],[449,"Tính độ tương đồng ngữ nghĩa câu sử dụng mạng ngữ nghĩa WordNet WordNet (mạng từ) là một cơ sở dữ liệu từ vựng tiếng Anh"],[450,"Nó nhóm các từ tiếng Anh thành các tập hợp đồng nghĩa gọi là loạt đồng nghĩa (synsets), cung cấp các định nghĩa ngắn gọn và các ví dụ sử dụng, và ghi lại số lượng các quan hệ giữa các loạt đồng nghĩa này hay các thành viên của chung [12]"],[451,"Theo cách đó WordNet có thể được xem như là một sự kết hợp của từ điển và từ điển đồng nghĩa và trái nghĩa"],[452,"Quan hệ về ngữ nghĩa chia làm hai loại chính là quan hệ thứ tự và quan hệ tương đương"],[453,"Các từ đồng nghĩa, trái nghĩa, đồng âm, đa nghĩa là các từ có mối quan hệ tương đương hay quan hệ ngang hàng"],[454,"Các quan hệ còn lại là các quan hệ thứ tự và phân thành các cặp như từ A là bao (has-a) của từ B thì từ B sẽ là thuộc (is-a) của từ A"],[455,"43 Nếu ta biểu diễn các ngữ nghĩa của từ thành một nut và các quan hệ giữa chung là các path thì ta sẽ có một mạng ngữ nghĩa với các từ có quan hệ tương đương thì sẽ nằm trong một lớp và các lớp này nối với nhau thành từng tầng dựa theo quan hệ thứ tự"],[456,"Đó chính là mạng ngữ nghĩa WordNet"],[457,"WordNet được tổ chức theo mô hình cây như hình 2.3, mỗi node chứa một từ nguyên mẫu (lemma) cùng với tập các từ đồng nghĩa với nó (synset)"],[458,"WordNet chỉ thể hiện quan hệ về ngữ nghĩa chứ không thể hiện quan hệ về ngữ âm hay hình thái"],[459,"Trong các ngôn ngữ biến cách như tiếng Anh, một từ có nhiều biến thể theo thì (tense), số lượng (plural) như eats, mice, teeth, ."],[460,"Xét về mặt ngữ nghĩa thì các từ này và các từ nguyên mẫu tương ứng của chung nói đến cùng một khái niệm nên trong bộ dữ liệu WordNet thì các từ biến cách được gộp chung vào từ nguyên mẫu của chung và cùng nằm trong một node"],[461,"Trong phạm vi đồ án, em sẽ truy cập WordNet bằng thư viện nltk trong Python"],[462,"Thư viện nltk của Python cung cấp các phương thức để truy cập vào bộ dữ liệu WordNet tiếng Anh một cách đơn giản và hiệu quả"],[463,"WordNet cung cấp phương thức truy cập synset của một từ cho trước: >>> wn.synsets('dog') [Synset('dog.n.01'), Synset('frump.n.01'), Synset('dog.n.03'), Synset('cad.n.01'), Synset('frank.n.02'), Synset('pawl.n.01'), Synset('andiron.n.01'), Synset('chase.v.01')] >>> wn.synsets('dog', pos=wn.VERB) [Synset('chase.v.01')] 44 Sử dụng WordNer để tính giá trị độ tương đồng giữa hai từ word_1, word_2 bằng hàm path_similarity(synset_1, synset_2) với synset_1, synset_2 lần lượt là loạt từ đồng nghĩa của word_1 và word_2"],[464,"Biểu diễn mỗi câu trong văn bản dưới dạng một vector ngữ nghĩa"],[465,"Độ tương đồng ngữ nghĩa giữa hai câu được tính bằng độ đo Cosine giữa hai vector đại diện cho từng câu: - Chuẩn hóa từ của câu: thay các từ của câu bằng từ chung tương ứng"],[466,"- Kích thước của vector ngữ nghĩa là kích thước của tập từ chung của hai câu"],[467,"- Giá trị một chiều của vector ngữ nghĩa của một câu bằng 1 nếu từ trong câu xuất hiện trong tập từ chung và bằng 0 nếu không xuất hiện"],[468,"Công thức tính độ đo Cosine giữa hai vector a và b : 1 2 2 1 1 cos || ||"],[469,"|| || n i i i n n i i i i a b ab a b similarity a b Với ai, bi là các phần tử của a và b Độ tương đồng cosine sẽ sinh ra một số, số này sẽ cho chung ta biết 2 câu liên quan đến nhau như thế nào trong không gian bằng cách xem xét góc giữa chung, thay vì so sánh về độ lớn"],[470,"a) Cùng hướng b) Vuông góc c) Đối diện 45 3.2.3.2"],[471,"PageRankRel a) Giải thuật tính độ tương đồng TF-IDF Đây là giải thuật cho ta độ tương đồng giữa các cặp nut trong đồ thị dựa vào tần số của một từ đối với một câu"],[472,"Độ tương tự sử dụng độ tương đồng TF-IDF"],[473,"Có nhiều phương pháp để tính độ tương tự như Jaccard [28], Dice [9] có thể áp dụng cho tiếng Anh"],[474,"Nhưng em chọn TF- IDF vì phương pháp này chu ý tới độ quan trọng của từ dựa vào tần suất từ khi tính độ tương tự giữa hai câu"],[475,"Công thức tính TF-IDF đa được nêu trong mục 3.2.2 bên trên"],[476,"Từ đó, ta tính trọng số tương ứng của một từ thứ i trong câu thứ j như sau: Wij = tfidfij Mỗi câu được biểu diễn như một vector có giá trị các chiều là giá trị trọng số của các từ trong câu"],[477,"Khi biểu diễn trên đồ thị câu, trọng số cạnh giữa 2 đỉnh tương ứng độ tương đồng giữa 2 câu Sm và Sn được tính theo công thức Cosine như sau: 1 2 2 1 1"],[478,""],[479,"t im in i mn t t im in i i W W Sim W W Với t là số từ của văn bản đầu vào"],[480,"b) Giải thuật PageRank PageRank là giải thuật xếp hạng (ranking) nổi tiếng được Google sử dụng trong việc xếp hạng các trang web dựa vào link liên kết bao gồm: link liên kết với trang web (incoming link) và link trang web liên kết tới (outcoming link)"],[481,"Trang web nào càng có nhiều liên kết, đồng thời liên kết với các trang có xếp hạng càng cao thì hạng của nó càng cao [1]"],[482,"Giá trị PageRank hình thành từ giải thuật học dựa trên Webgraph: các trang World Wide Web được coi như các đỉnh và các đường link là các cạnh"],[483,"Giá trị xếp hạng cho thấy tầm quan trọng của từng trang cụ thể"],[484,"Mỗi đường link tới trang web sẽ được tính như một sự hỗ trợ làm tăng thêm giá trị PageRank"],[485,"Giá trị PageRank của trang được định nghĩa đệ quy và phụ thuộc vào số lượng và giá trị của các trang mà có link dẫn đến trang đó"],[486,"Trang web có chứa nhiều link liên kết từ các trang web có giá trị PageRank cao thì giá trị PageRank của trang đó cũng sẽ cao [5]"],[487,"46 Công thức được sử dụng để tính trọng số của một nut trên đồ thị liên kết các trang web như sau : V (V ) PR(V ) PR(V ) (1 ) * (V ) j i j i M i d d L Trong đó: PR(Vi) là xếp hạng của đỉnh Vi"],[488,"M(Vi) là tất cả các đỉnh đi tới đỉnh Vi"],[489,"L(Vi) là tập các đỉnh mà đỉnh Vi đi tới"],[490,"d (DAMPING_FACTOR) là một hệ số trong giải thuật PageRank, giá trị được tùy chọn trong khoảng (0,1)"],[491,"Hệ số này là xác suất một người truy cập vào một trang web và tiếp tục kích trong bất cứ bước nào"],[492,"Nhiều nghiên cứu đa thử các giá trị damping và thấy rằng nếu giá trị này 0.85 thì có nghĩa là người dùng sẽ tiếp tục lướt web"],[493,"Áp dụng giải thuật PageRank cho văn bản, ta coi mỗi văn bản là một đồ thị câu vô hướng có trọng số, trong đó: Các đỉnh biểu diễn các câu"],[494,"Các cạnh biểu diễn độ tương đồng giữa các câu"],[495,"Một cặp câu có liên quan được nối bằng một liên kết vô hướng, có trọng số của cạnh là độ tương đồng giữa hai câu"],[496,"47 Giá trị PageRank của câu được tính bằng công thức: V (V ) PR(V ) PR(V ) (1 ) * (V ) j i j i ij M j d d Sim M (1) Với: PR(Vi) là giá trị PageRank của nut Vi"],[497,"M(Vi) là tất cả các nut trong đồ thị trừ nút i; M(Vj) là tất cả các nut trong đồ thị trừ nút j; Simij là độ tương đồng giữa 2 câu; d là tham số nằm trong khoảng [0,1]"],[498,"Trong hệ thống tóm tắt đơn văn bản, em chọn hệ số này là 0.85 Việc tính toán PR (điểm của nut trong đồ thị) được thực hiện như sau: Đầu tiên, điểm của tất cả các nut được khởi tạo giá trị 1"],[499,"Sau đó biểu thức (1) được áp dụng để tính điểm lần lượt cho từng nut trên đồ thị có trọng số"],[500,"Việc tính toán này sẽ được lặp đi lặp lại cho đến khi và được lặp cho đến khi sự khác biệt về điểm giữa hai lần lặp nhở hơn ngưỡng 0.0001 ở tất cả các nut"],[501,"Điểm của các nut chính là điểm của các câu trong văn bản"],[502,"Các câu có điểm cao thì sẽ quan trọng hơn các câu có điểm thấp hơn và độ tương tự với các câu khác lớn"],[503,"48 3.3"],[504,"Khối tính điểm cho câu 3.3.1"],[505,"Áp dụng mô hình Nave Bayes Gọi F = {f1, f2, ., f10} là tập các đặc trưng của câu đa nói đến ở mục 3.2"],[506,"Ta sẽ sử dụng mô hình Nave Bayes để phân loại các câu thành hai lớp: lớp câu quan trọng (lớp 1) và lớp câu không quan trọng (lớp 0) dựa vào giá trị các đặc trưng đa tính của từng câu"],[507,"Để phân loại câu thuộc vào lớp nào, ta cần phải tính: {0;1} arg max ( ) ( | ) i NB i i i c c c P c P f c Với fi F"],[508,"Ta cần tính các giá trị ( | )i iP f c 3.3.1.1"],[509,"Xử lý dữ liệu train - Mỗi câu trong các văn bản thuộc tập train đa được đánh dấu là câu quan trọng hay câu không quan trọng"],[510,"Sau khi tính toán giá trị các đặc trưng fi đề cập ở mục 3.2 của các câu trong tập train, mỗi câu này được biểu diễn bởi các vector đại diện X = (x1, x2,., xn, c), với xi, i = 1,.,n là giá trị của đặc trưng fi; c là lớp của vector, c = 1 với câu quan trọng và c = 0 với câu không quan trọng"],[511,"Các vector được lưu vào file txt, mỗi vector một dòng, dùng làm dữ liệu train cho mô hình Nave Bayes"],[512,"- Tính toán các giá trị: Trong đồ án này, em sử dụng mô hình Gaussian Naive Bayes để tính các giá trị ( | )i iP f c"],[513,"Trước hết, ta phân loại các vector câu trong tập train thành 2 class: class 1 nếu câu quan trọng và class 0 nếu câu không quan trọng class 0"],[514,"Tiếp theo tính giá trị trung bình ci ( X ) và độ lệch chuẩn ci (s) của từng class"],[515,"Xét các vector thuộc class c, c {0; 1}, ta đi tính giá trị trung bình từng chiều của các vector này"],[516,"- Công thức tính giá trị trung bình chiều i của các vector trong mỗi class: 1 1 i N ci k k X x N Với ik x là giá trị chiều i của vector kx , N là số lượng vector"],[517,"- Công thức tính độ lệch chuẩn chiều i của các vector: 49 2 1 ( ) 1 i N k ci k ci x X s N Với ciX là giá trị trung bình chiều i của các vector, ikx là giá trị chiều i của vector kx , N là số lượng vector"],[518,"3.3.1.2"],[519,"Tính xác suất câu trong tập test thuộc vào từng class Sau khi tính toán các giá trị đặc trưng của các câu trong tập test tương tự như khi tính toán với tập train, mỗi câu trong văn bản test được biểu diễn dưới dạng một vector đại diện Xk = (x1, x2,., xn), với xi, i = 1,.,n là giá trị của đặc trưng fi tương ứng"],[520,"Xét class c, chiều i của các vector trong class này có giá trị trung bình ciX và độ lệch chuẩn cis"],[521,"Ta tính giá trị ( | )ip x c sử dụng hàm mật độ xác suất Gaussian: 2( )1 ( | ) exp 2.2"],[522,"i i i ii x X p x s c s Kết hợp các xác suất p(xi|c) đa tính ở trên, ta tính được xác suất của câu thuộc vào mỗi class"],[523,"Công thức tính xác suất câu thuộc vào từng class: 1 2 1 | | (, |, ), n n i i p c p x px xx c c x Điểm của câu si là xác suất của câu thuộc vào class 1 (câu quan trọng)"],[524,"(x |1) *100 (x |1) (x | 0) i p p p Score s 50 3.3.2"],[525,"Tiếp cận theo phương pháp cấu trúc Đầu ra của khối các đặc trưng cấu trúc: chọn được tập các đặc trưng mang lại kết quả tốt nhất để áp dụng cho bài toán tóm tắt văn bản"],[526,"Các đặc trưng đó bao gồm: Đặc trưng bề mặt Đặc trưng nội dung Đặc trưng độ liên quan Trong đó, trọng số cho từng nhóm đặc trưng được xác định như sau: Đặc trưng bề mặt: Câu văn đứng ở vị trí đầu tài liệu nhận trọng số FirstDoc bằng 1"],[527,"Các câu phía sau sẽ có trọng số bằng 0"],[528,"Trọng số cho Vị trí thuộc đoạn [0, 1]: Position 1 i Với i là vị trí của câu trong văn bản (i > 0)"],[529,"Ngưỡng độ dài trung bình (giá trị cutoff) được quy định cho câu văn thuộc chủ đề báo chí là 10"],[530,"Như vậy, trọng số độ dài câu tính bằng công thức: Length 10S S length length Với length là độ dài câu, nếu độ dài câu nhỏ hơn 10 thì tính điểm độ dài câu là 0"],[531,"Tổng điểm đặc trưng bề mặt: Surface = FirstDoc + Position + Length Đặc trưng nội dung Trọng số cho Centroid thuộc đoạn [0, 1], được tính bằng tổng tf-idf của của 30% từ có trọng số TF-IDF cao nhất từ trong câu"],[532,"Trọng số cho Frequence thuộc đoạn [0, 1], được tính bằng tổng tf của 30% từ có trọng số TF cao nhất trong câu"],[533,"Ta xét Centroid và Frequence của uni-gram và bi-gram"],[534,"Công thức Centroid và Frequence đa trình bày ở mục 3.2 Tổng điểm đặc trưng nội dung: Content = Centroid + Frequence 51 Đặc trưng độ liên quan Trọng số FirstRel (độ liên quan đến câu đầu đoạn): câu đầu đoạn có điểm bằng 1, các câu tiếp theo thuộc đoạn [0, 1)"],[535,"Trọng số PageRankRel thuộc đoạn [0, 1] Công thức FirstRel và PageRankRel đa trình bày ở mục 3.2 Tổng điểm đặc trưng độ liên quan: Relevance = FirstRel + PageRankRel Công thức tính điểm cấu trúc: Điểm cấu trúc = Surface + Content + Relevance Content: Điểm cho đặc trưng Content Surface: Điểm cho đặc trưng Surface Relevance: Điểm cho đặc trưng Relevance"],[536,"3.4"],[537,"Khối trích xuất câu Từ văn bản đầu vào, các câu được phân chia và nhận một trọng số tương ứng (điểm của câu) với mức độ quan trọng trong văn bản sau quá trính tính toán và phân loại"],[538,"Tập hợp các câu này được sắp xếp trong một danh sách theo thự giảm dần của giá trị điểm của câu"],[539,"Lần lượt chọn ra các câu quan trong nhất (các câu có điểm cao nhât) cho đến khi văn bản đạt ngưỡng độ dài yêu cầu (không quá 250 từ), sau đó sắp xếp các câu được trích xuất theo thứ tự xuất hiện trong văn bản đầu vào, ta thu được văn bản tóm tắt cuối cùng"],[540,"52 CHƯƠNG 3: XÂY DỰNG VÀ THỰC NGHIỆM Với mô hình tính toán được đưa ra từ những chương trước, chương này em sẽ trình bày chi tiết việc phát triển hệ thống tóm tắt dựa trên mô hình đề xuất để giải quyết bài toán tóm tắt văn bản báo chí tiếng Anh"],[541,"Từ đó, tiến hành các thực nghiệm kiểm tra việc áp dụng hệ thống được xây dựng"],[542,"Đồ án sử dụng ngôn ngữ lập trình Python để thực hiện"],[543,"1"],[544,"Xây dựng hệ thống tóm tắt văn bản Từ kết quả thu được từ các bước trước, em đa tìm hiểu và lựa chọn các công cụ để xây dựng hệ thống theo chức năng của từng mô-đun trong mô hình"],[545,"1.1"],[546,"Khối tiền xử lý Tiền xử lý đối với văn bản tóm tắt tiếng Anh, em sử dụng bộ công cụ NLTK (Natural Language Toolkit) [17] chuyên dùng để xử lý các vấn đề liên quan đến ngôn ngữ tự nhiên"],[547,"NLTK (Natural Language Toolkit) là một bộ công cụ dành riêng cho xử lý ngôn ngữ tự nhiên (NLP - Natural Language Processing) cho tiếng Anh và được tích hợp vào Python [18]"],[548,"Nó được phát triển bởi bởi Steven Bird và Edward Loper tại Khoa Máy tính và Thông tin tại Đại học Pennsylvania"],[549,"Nó đang ngày càng hoàn thiện và tích hợp các công cụ mới bởi hàng nghìn lập trình viên và cộng tác viên trên khắp thế giới"],[550,"NLTK bao gồm những thư viện hàm, các công cụ phân tích, nguồn ngữ liệu, WordNet,"],[551,"giup đơn giản hóa, tiết kiệm thời gian và công sức cho các lập trình viên"],[552,"NLTK cung cấp một giao diện dễ sử dụng với hơn 50 bộ ngữ liệu và lexical resources với các thư viện hỗ trợ tiền xử lý văn bản dành cho các tác vụ phân loại, tokenization, stemming, gán nhan từ loại, phân tích cu pháp và suy diễn ngữ nghĩa sematic reasoning"],[553,"Một số ví dụ về chức năng trong bộ công cụ NLTK: 53 1.2"],[554,"Khối tính giá trị đặc trưng Sử dụng các thư viện Math, NumPy [19] của Python để tính toán các giá trị đặc trưng"],[555,"Trong phần tính toán các giá trị đặc trưng độ liên quan, em sử dụng WordNet có sẵn trong bộ NLTK của Python [18] để tính toán độ tương đồng ngữ nghĩa với câu đầu đoạn và sử dụng hàm PageRank tích hợp trong thư viện NetworkX [16] của Python"],[556,"1.3"],[557,"Khối tính điểm cho câu Thiết kế mô hình phân loại và tính điểm cho câu, em sử dụng thư viện Scikit- learn [14] tích hợp sẵn của Python"],[558,"Scikit-learn là một thư viện miễn phí hỗ trợ học máy, được tích hơp vào ngôn ngữ lập trình Python"],[559,"Nó hỗ trợ các thuật toán phân loại, hồi quy và phân cụm bao gồm 54 Support Vector Machines, Random Forests, Gradient Boosting, k-means cùng nhiều thuật toán khác"],[560,"Scikit-learn được thiết kế để tương thích với các thư viện số học và khoa học của Python như NumPy và SciPy [11]"],[561,"Có thể nói, thư viện Scikit-learn chính là một trong số những nền tảng phổ biến nhất hiện nay dành cho lĩnh vực học máy và khoa học dữ liệu"],[562,"Scikit-learn được xây dựng trên nền Python, một ngôn ngữ lập trình với sự hỗ trợ đầy đủ và mạnh mẽ"],[563,"Scikit- learn cung cấp một số lượng lớn các thuật toán hiệu quả, bao phủ trọn lĩnh vực học máy và khoa học dữ liệu"],[564,"Ngoài ra, nó còn được biết đến với sự rõ ràng, nhất quán và hợp lý trong API của mình"],[565,"Điểm lợi của tính nhất quán trong trường hợp này là: một khi người đọc hiểu được ký pháp và cách sử dụng căn bản của Scikit-learn cho một mô hình thì việc chuyển đổi sang một mô hình mới hoặc thuật toán mới là vô cùng dễ dàng"],[566,"Ngoài ra, song song với đó là nguồn tài liệu online luôn đầy đủ và thuận tiện"],[567,"Ở bước boosting, em sử giải thuật Adaboost trong module sklearn.ensemble [15] của Scikit-learn"],[568,"55 2"],[569,"Dữ liệu thực nghiệm Đồ án sử dụng tập dữ liệu DUC 2007 như là một tập dữ liệu để kiểm tra"],[570,"Document Understanding Conference (DUC) [13] là một hội nghị quốc tế để đánh giá hiệu suất của hệ thống tóm tắt bằng cách so sánh bản tóm tắt bằng tay của các chuyên gia với bản tóm tắt tự động của máy tính"],[571,"DUC2007 là bộ dữ liệu dùng cho tác vụ tóm tắt đa văn bản, gồm 45 cụm văn bản, mỗi cụm gồm 25 văn bản là các bài báo có cùng chủ đề"],[572,"45 cụm văn bản này được chia thành 2 tập : tập dữ liệu huấn luyện 2007 SCU-marked và tập dữ liệu dùng để thử nghiệm 2007 test_docs"],[573,"Tác vụ Cụm Nguồn 2007 SCU- marked 23 văn bản định dạng SCU Tiếng Anh Thời báo AP, Thời báo NewYorkTimes, Tân Hoa Xã 2007 test_docs 22 văn bản Tiếng Anh Thời báo AP, Thời báo NewYorkTimes, Tân Hoa Xã Để phù hợp với bài toán tóm tắt đơn văn bản, ta ghép các văn bản trong từng cụm văn bản thành một đơn văn bản"],[574,"Tập bản tóm tắt mẫu tương ứng của từng cụm văn bản bao gồm 4 văn bản dài không quá 250 từ do 4 chuyên gia tóm tắt, do đó bản tóm tắt của hệ thống cũng có độ dài không quá 250 từ"],[575,"Các văn bản để huấn luyện của DUC2007 có định dạng SCU (Summary Content Units) có cấu truc như sau: 56 Các câu gán thẻ <annotation> thường là các câu quan trọng"],[576,"Trong thẻ <scu>, trọng số weight chỉ số lượng văn bản do chuyên gia tóm tắt có liên quan đến câu"],[577,"Để phù hợp với các đánh giá văn bản đầu ra so với văn bản tóm tắt của chuyên gia, em lựa chọn các câu quan trọng là các câu có trọng số weight lớn hơn 0"],[578,"3"],[579,"Đánh giá chất lượng tóm tắt Đồ án sử dụng độ đánh giá ROUGE cho sự so sánh giữa các bản tóm tắt tự động và 4 bản tóm tắt tham chiếu bởi các chuyên gia có trong tập dữ liệu thử nghiệm"],[580,"ROUGE viết tắt của Recall-Oriented Understudy for Gisting Evaluation"],[581,"ROUGE bao gồm bộ các độ đo để đánh giá tự động chất lượng của văn bản tóm tắt bằng cách so sánh bản tóm tắt sinh ra bởi hệ thống với những bản tóm tắt được tạo ra bởi con người"],[582,"Các độ đo cơ bản ROUGE bao gồm : ROUGE-N, ROUGE-L, ROUGE-W và ROUGE-SU"],[583,"Các độ đo trên được sử dụng trong DUC 2007"],[584,"Trong phạm vi nghiên cứu, em sử dụng 2 độ đo ROUGE-1 và ROUGE-2 tương ứng với n = 1 và n = 2 trong ROUGE-N để đánh giá chất lượng của văn bản tóm tắt"],[585,"Như đa trình bày ở mục 3.5 chương 1, do có 4 văn bản tóm tắt tham chiếu, ta tính ROUGE-N theo từng cặp, giữa bản tóm tắt tự động s và từng bản tóm tắt tham chiếu ri trong tập 4 văn bản tóm tắt tham chiếu"],[586,"Sau đó, kết quả điểm ROUGE-N cuối cùng trong 4 tham chiếu sẽ là điểm ROUGE-N cao nhất trong tất cả các cặp được tính"],[587,"57 4"],[588,"Kết quả thực nghiệm Đồ án tập trung vào việc nghiên cứu kết hợp phương pháp tóm tắt văn bản áp dụng học máy có giám sát đại diện là phương pháp Naive Bayes kết hợp boosting bằng Adaboost"],[589,"Các thí nghiệm được thiết kế bao gồm 2 mục tiêu chính: Đánh giá và lựa chọn hướng tiếp cận tóm tắt: tiếp cận theo phương pháp cấu truc và phương pháp học máy nhằm so sánh độ chính xác giữa hai hướng tiếp cận"],[590,"Đánh giá và lựa chọn đặc trưng: lựa chọn các loại đặc trưng để đánh giá tầm quan trọng của từng loại đặc trưng đối với độ chính xác của mô hình"],[591,"4.1"],[592,"Kết quả lựa chọn hướng tiếp cận ROUGE ROUGE-1 ROUGE-2 3 features 38.78 9.01 Nave Bayes + 3 features 40.75 9.71 Nave Bayes + Adaboost + 3 features 41.12 9.92 58 Từ kết quả thí nghiệm 1 ta có nhận xét : Khi kết hợp cả phương pháp Nave Bayes boosting bằng Adaboost hệ thống cho kết qủa tốt nhất với điểm Rouge-2 là 9.92% và Rouge-1 là 41.12%"],[593,"Thuật toán Adaboost cải thiện độ chính xác của mô hình Nave Bayes đơn thuần 41.12% so với 40.75%"],[594,"Từ bảng trên ta cũng có thể thấy phương pháp Nave Bayes cho kết quả cao hơn với phương pháp đặc trưng cấu truc 40.75% với 38.78%"],[595,"Qua kết quả trên ta có thể rut ra nhận xét: Trong phạm vi nghiên cứu, đồ án đa chứng minh được hướng tiếp cận phương pháp học máy mang kết qủa tốt hơn khi sử dụng phương pháp cấu truc"],[596,"Thuật toán Adaboost đa hoạt động hiệu quả trong việc tăng cường độ chính xác của mô hình Nave Bayes"],[597,"Do tính đặc trưng của ngôn ngữ học, sự kết hợp các đặc trưng cấu truc không phải luôn tuân theo quy luật tỉ lệ thuận giữa điểm ROUGE-1 và ROUGE-2"],[598,"0 5 10 15 20 25 30 35 40 45 3 features Nave Bayes + 3 features Nave Bayes + 3 features + Adaboost ROUGE-1 ROUGE-2 59 4.2"],[599,"Kết quả lựa chọn đặc trưng ROUGE ROUGE-1 ROUGE-2 Adaboost + Nave Bayes + Relevance + Content 39.14 9.12 Adaboost + Nave Bayes + Surface + Content 40.31 9.30 Adaboost + Nave Bayes + Relevance + Surface 39.09 9.17 Từ kết quả trên kết hợp với kết quả của thí nghiệm 1, ta có thể rut ra nhận xét: - Sử dụng mô hình Naive Bayes sử dụng 2 trong 3 loại đặc trưng cho kết quả kém hơn kết hợp cả 3 loại đặc trưng"],[600,"- Mô hình Naive Bayes sử dụng tập đặc trưng Surface và Content mang lại kết quả tốt nhất với điểm Rouge-2 là 9.31% và Rouge-1 là 40.31%"],[601,"0 5 10 15 20 25 30 35 40 45 Adaboost + Nave Bayes + Content + Relevance Adaboost + Nave Bayes + Content + Surface Adaboost + Nave Bayes + Surface + Relevance ROUGE-1 ROUGE-2 60 - Kết quả thí nghiệm 2 chứng tỏ, trong thể loại văn bản báo chí được tóm tắt, đặc trưng bề mặt (vị trí, độ dài câu văn) cùng đặc trưng nội dung (giá trị TF- IDF, tần suất từ) là quan trọng"],[602,"4.3"],[603,"So sánh, đánh giá với phương pháp khác Kết quả thực nghiệm của 1 số hướng tiếp cận khác trên cùng tập dữ liệu DUC 2007: ROUGE ROUGE-1 ROUGE-2 NtMF với ma trận Log Entropi 35.82 7.22 NMF với ma trận TFIDF 36.18 7.28 NMF kết hợp các đặc trưng cấu trúc sử dụng Word2Vec 41.67 9.99 SVM 39.71 10.08 Từ bảng 3.4 ta có nhận xét : - Kết quả độ đo Rouge của mô hình Naive Bayes kết hợp giải thuật AdaBoost cao hơn hẳn so với mô hình NMF thuần, chỉ thấp hơn so với mô hình NMF kết hợp các đặc trưng cấu trúc sử dụng Word2Vec (độ Rouge-1 thấp hơn 0.52%, độ Rouge-2 thấp hơn 0.07%)"],[604,"- So với mô hình SVM, mô hình cho kết quả Rouge-1 tốt hơn và Rouge-2 thấp hơn không đáng kể (0.16%)"],[605,"- Như vậy, nhìn chung, trong bài toán tóm tắt văn bản, mô hình phân loại Naive Bayes sử dụng tập đặc trưng cấu trúc câu và kết hợp giải thuật AdaBoost mang lại kết quả tương đối tốt so với các mô hình khác"],[606,"61 CHƯƠNG 4: KẾT LUẬN VÀ HƯỚNG PHÁT TRIỂN 1"],[607,"Ưu - nhược điểm của Trong đồ án này, em đa đề xuất một phương pháp mới để giải quyết bài toán tóm tắt văn bản tự động, đồng thời tập trung xây dựng một hệ thống tóm tắt văn bản cho tiếng Anh"],[608,"Hệ thống đề xuất dựa vào mô hình Nave Bayes kết hợp các đặc trưng cấu truc của câu để chọn các câu quan trọng trong văn bản và trích xuất thành văn bản tóm tắt"],[609,"Hệ thống có một số ưu và nhược điểm sau: 1.1"],[610,"Ưu điểm - Mô hình Nave Bayes là một mô hình dễ cài đặt, dễ thực thi, thời gian tính toán và phân loại nhanh, có độ chính xác tương đối cao"],[611,"Một nghiên cứu so sánh toàn diện với các phương pháp phân loại khác trong năm 2006 [6] cho thấy phân loại Nave Bayes được cải thiện tốt hơn bằng các phương pháp boosting, chẳng hạn như AdaBoost"],[612,"Kết quả thực hiện của mô hình cũng đa cho thấy điều này"],[613,"- Thực tế, với bất kỳ mô hình học máy nào, bộ dữ liệu huấn luyện càng lớn thì mô hình càng đưa ra kết quả có độ chính xác cao"],[614,"Tuy nhiên, kể cả đối với bộ dữ liệu huấn luyện nhỏ, mô hình Nave Bayes hoạt động khá hiệu quả"],[615,"Hơn nữa, mô hình cũng nhanh chóng cập nhật nếu có dữ liệu mới được thêm vào"],[616,"1.2"],[617,"Nhược điểm - Trong mô hình Nave Bayes, giả thiết về tính độc lập của các biến là không thực tế"],[618,"Cụ thể, trong mô hình đề xuất, các đặc trưng cấu trúc câu không hoàn toàn độc lập với nhau"],[619,"- Mô hình Nave Bayes coi các đặc trưng là độc lập nên nó không thể phát hiện ra mối quan hệ giữa các loại đặc trưng"],[620,"Hơn nữa, không thể thiết lập đặc trưng ưu tiên cho mô hình"],[621,"- Mô hình chưa áp dụng được cho bài toán tóm tắt văn bản tiếng Việt"],[622,"2"],[623,"Đóng góp của đồ án Đồ án đưa ra một cái nhìn tổng quan về áp dụng phương pháp học máy và kĩ thuật phân tích các đặc trưng cấu truc câu trong vấn đề xử lý dữ liệu văn bản mà cụ thể là bài toán Tóm tắt văn bản tự động"],[624,"62 Đồ án đa đề xuất một cách tiếp với bài toán tóm tắt văn bản dựa vào trích xuất bằng cách sử dụng mô hình Naive Bayes sử dụng tập đặc trưng câu, kết hợp giải thuật tăng cường AdaBoost"],[625,"Đồ án cũng đa chứng minh được tính hiệu quả của phương pháp khi áp dụng trên tiếng Anh"],[626,"Các thí nghiệm của em được thực hiện với các kịch bản khác nhau bằng bộ dữ liệu DUC2007 cho tiếng Anh"],[627,"Kết quả thí nghiệm cho thấy khi Naive Bayes kết hợp với ba loại đặc trưng câu (đặc trưng bề mặt, đặc trưng độ liên quan, đặc trưng nội dung) và boosting bằng Adaboost cho kết quả tốt nhất"],[628,"Các phép đo Rouge-1 và Rouge-2 c"]],"downloaded":true,"m":[-1,-1],"n":"20131383_Vu_Thu_Hien_1528204153945.txt","o":"http://storage.googleapis.com/soict-projects/httt/hedspi-a/20131383_Vu_Thu_Hien_1528204153945.pdf\r"},{"saved_path":"temp/20132320_Tran_Thi_Dieu_Linh_1528176806088.txt","r":0,"s":[],"t":"\n \r\n\r\n1. Đặt vấn đề \r\n\r\nTrong những năm gần đây, chung ta được chứng kiến sự phát triển như vũ bao của \r\n\r\nWorld-Wide-Web. Theo thống kê của WorldWideWebSize.com vào cuối tháng 4 \r\n\r\nnằm 2018 có khoảng 50 tỷ trang web đa được indexed bởi Google, khoảng 2500TB \r\n\r\ndữ liệu trên Web.  \r\n\r\n \r\n\r\n\r\n \r\n\r\nTrước sự phát triển đó thì vấn đề đặt ra là làm thế nào để con người có thể sử dụng \r\n\r\nmột cách hiệu quả lượng thông tin khổng lồ trên Internet? \r\n\r\nViệc tóm tắt thông tin giúp ta có thể quyết định xem tiếp tục tập trung vào \r\n\r\nphần nào, nhất là trong các văn bản phức tạp như bài báo khoa học hay toàn bộ nội \r\n\r\ndung một cuốn sách. Ngoài ra nó còn có thể ứng dụng trong rất nhiều các lĩnh vực \r\n\r\nkhác mà con người cần phải tóm tắt một lượng rất lớn các dữ liệu như tài chính, dữ \r\n\r\nliệu thuốc của bệnh nhân trong y học. \r\n\r\nBài toán tóm tắt văn bản là một trong những bài toán kinh điển trong lĩnh \r\n\r\nvực xử lý dữ liệu văn bản. Xử lý dữ liệu văn bản bao gồm: \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n Kiểm tra lỗi chính tả (spelling-checker) \r\n\r\n Kiểm tra lỗi văn phạm (grammar-checker) \r\n\r\n Từ điển đồng nghĩa (thesaurus) \r\n\r\n Phân tích văn bản (text analyzer) \r\n\r\n Phân loại văn bản (text classification) \r\n\r\n Tóm tắt văn bản (text summarization) \r\n\r\n Tổng hợp tiếng  nói (speech synthesis) \r\n\r\n Nhận dạng giọng nói (speech recognization) \r\n\r\n Dịch tự động (automatic translation) \r\n\r\n . \r\nTóm tắt văn bản là công việc phân tích nội dung của văn bản và sau đó sinh \r\n\r\nra một văn bản tóm tắt có kích thước nhỏ hơn văn bản ban đầu, loại bỏ đi những \r\n\r\nthông tin không quan trọng nhưng vẫn đảm bảo giữ được những nội dung cốt lõi \r\n\r\ncủa văn bản. Do đó để công việc tóm tắt văn bản chính xác cần phải đáp ứng được \r\n\r\ncác yêu cầu sau: \r\n\r\n Các văn bản khi phân tích thì phải hiểu được nội dung để xác định \r\nđược các tiêu chuẩn trong văn bản. \r\n\r\n Các văn bản tóm tắt cần được kiểm tra bằng một thang đo tiêu chuẩn.  \r\n \r\n\r\n Rõ ràng việc tóm tắt văn bản chính là công việc khai phá dữ liệu văn bản \r\n\r\n(text data mining).  \r\n\r\n \r\n\r\n2. Lịch sử phát triển của tóm tắt văn bản \r\n\r\nTóm tắt văn bản bắt đầu từ những năm cuối thập kỉ 1950 với nghiên cứu của \r\n\r\nLuhn(1958) dựa trên tần số từ. Ý tưởng cơ bản của phương pháp tần số từ dựa trên \r\n\r\nkiến thức cho rằng tần số của từng từ trong văn bản là một độ đo hữu dụng để đánh \r\n\r\ngiá tầm quan trọng của chúng. \r\n\r\n Tiếp theo đó là phương pháp tóm tắt dựa trên vị trí của các câu trong văn bản \r\n\r\ncủa Baxendale (1958) và những nghiên cứu của Edmundson(1969) về vị trí của các \r\n\r\ncâu trong văn bản và các từ/cụm từ mang ý nghĩa tổng quát. Theo đó, những câu bắt \r\n\r\nđầu và kết thúc của đoạn văn bài viết hay những câu chưa những từ như important \r\n\r\n(đặc biệt), result are (kết qủa là) . là những câu có ý nghĩa quan trọng. \r\n\r\n Đầu những năm 1970, tiếp tục có những nghiên cứu với hướng tiếp cận \r\n\r\nngoài (sử dụng các cụm từ dấu hiệu) và được ứng dụng trong các phần mềm thương \r\n\r\nmại \r\n\r\n Những năm 1980, phát triển nhiều nghiên cứu với nhiều hướng khác nhau, \r\n\r\nđặc biệt là hướng tiếp cận mức thực thể dựa trên trí tuệ nhân tạo  như sử dụng script \r\n\r\n(Lehnert 1981), các luật sản xuất mạng và logic (Fum 1985), mạng ngữ nghĩa \r\n\r\n(Reimer và Hahn 1988) cũng như các hướng tiếp cận kết hợp (Rau 1989) hay \r\n\r\n(Aretoulaki 1994). \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n Willam B. Cavnar (1994) : biểu diễn văn bản dựa trên n-gram thay cho cách \r\n\r\nbiểu diễn truyền thống bằng từ khoá. \r\n\r\n Chinatsu Anoe (1997) đa phát triển hệ DimSum để tóm tắt văn bản sử dụng \r\n\r\nxử lý ngôn ngữ tự nhiên và kĩ thuật thống kê dựa trên hệ thống tf-idf, sử dụng \r\n\r\nWordNet để xem xét ngữ nghĩa của từ và đề xuất một số kĩ thuật lượng giá. \r\n\r\n Jaine Carbonell (1998) đa tóm tắt văn bản bằng cách xếp hạng các câu trội \r\n\r\n(câu chưa các ý chính của văn bản) và rút ra các câu trội. \r\n\r\n Jade Goldstein (1999) : phân loại tóm tắt dựa trên độ đo liên quan, phương \r\n\r\nphpas sử dụng kết hợp giữa ngữ học, thống kê. Một câu được đặc trưng bằng các \r\n\r\nđặc tính ngữ học và độ đo thống kê. \r\n\r\n J.Larocca Neto (2000) đa tạo tóm tắt văn bản dựa trên các dãy từ trong câu \r\n\r\nđược chọn theo hệ số tf, sau đó dùng kỹ thuật gom cụm (clustering) để tạo tóm tắt. \r\n\r\n Yoshio (2001) đa tạo tóm tắt văn bản tiếng Nhật. Có 2 phương pháp là rut \r\n\r\ncâu dựa trên từ khoá và rút câu dựa trên kiến trúc ngữ nghĩa trong đó có xây dựng \r\n\r\nđộ đo mối liên kiết giữa hai từ. \r\n\r\n Hiện nay, một số nghiên cứu về xử lý ngôn ngữ tự nhiên cũng bước đầu \r\n\r\nđược áp dụng trong tóm tắt văn bản. Mặt khác, các nghiên cứu về tóm tắt đa văn \r\n\r\nbản, đa ngôn ngữ và tóm tắt đa phương tiện cũng bắt đầu phát triển. \r\n\r\n \r\n\r\n3. Phân loại các hệ thống tóm tắt văn bản \r\n\r\n3.1. Phân loại theo kết quả (output) \r\n\r\nTóm tắt theo hướng trích rút (Extract): là một bản tóm tắt  bao gồm các nội \r\n\r\ndung được rút trích từ văn bản gốc. Nói cách khác, văn bản tóm tắt được tạo ra bằng \r\n\r\ncách bỏ đi các từ, cụm từ hoặc câu không quan trọng và giữ lại các từ, cụm từ hoặc \r\n\r\ncâu quan trọng trong văn bản gốc. \r\n\r\nTóm tắt theo hướng tóm lược (Abstract): là một bản tóm tắt có chứa cả các nội \r\n\r\ndung, từ ngữ không được thể hiện trong văn bản gốc. Hoặc có thể hiểu văn bản tóm \r\n\r\ntắt đa được biên tập lại bằng các từ ngữ, nội dung khác đi (có thể không nằm trong \r\n\r\nvăn bản gốc) mà vẫn thể hiện được ý nghĩa quan trọng mà văn bản gốc thể hiện. \r\n\r\n \r\n\r\n3.2. Phân loại theo số lượng tài liệu : \r\n\r\nTóm tắt đơn văn bản : \r\n\r\nBài toán tóm tắt văn bản đơn cũng giống như các bài toán tóm tắt khác, là một \r\n\r\nquá trình tóm tắt tự động với đầu vào là một văn bản, đầu ra là một đoạn mô tả ngắn \r\n\r\ngọn nội dung chính của văn bản đầu vào đó. Văn bản đơn có thể là một trang Web, \r\n\r\nmột bài báo, hoặc một tài liệu với định dạng xác định (ví dụ : .doc, .txt). Tóm tắt \r\n\r\nvăn bản đơn là bước đệm cho việc xử lý tóm tắt đa văn bản và các bài toán tóm tắt \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\nphức tạp hơn. Chính vì thế những phương pháp tóm tắt văn bản ra đời đầu tiên đều \r\n\r\nlà các phương pháp tóm tắt cho văn bản đơn.  \r\n\r\nCác phương pháp nhằm giải quyết bài toán tóm tắt văn bản đơn cũng tập trung \r\n\r\nvào hai loại tóm tắt là: tóm tắt theo trích xuất và tóm tắt theo tóm lược. \r\n\r\nTóm tắt đa văn bản : \r\n\r\nTóm tắt đa văn bản có thể được coi như là một mở rộng của tóm tắt đơn văn bản.  \r\n\r\nMục đích của tóm tắt đa văn bản: Là quá trình trích xuất nội dung từ một tập các \r\n\r\nvăn bản có liên quan đến nhau, trong quá trình đó các thông tin dư thừa sẽ được loại \r\n\r\nbỏ và những thông tin quan trọng sẽ được biểu diễn dưới hình thức cô đọng, suc \r\n\r\ntích và giàu cảm suc đến người sử dụng hoặc chương trình cần dùng [MM99].  \r\n\r\nTóm tắt đa văn bản được xác định là một bài toán có độ phức tạp cao, ngoài \r\n\r\nnhững thách thức đa được biết đến đối với tóm tắt đơn văn bản như sự cô đọng của \r\n\r\nthông tin và mạch lạc về nội dung, tóm tắt đa văn bản còn có những thách thức như \r\n\r\ncần phải xác định những thông tin trùng lặp giữa các văn bản, xác định thông tin \r\n\r\nquan trọng trong nhiều văn bản hay việc sắp xếp các thông tin trong văn bản tóm \r\n\r\ntắt.  \r\n\r\n \r\n\r\n3.3. Phân loại theo mục đích, chức năng tóm tắt (Function) \r\n\r\nTóm tắt chỉ thị (Indicative): tóm tắt nhằm cung cấp một chức năng tham khảo để \r\n\r\nchọn tài liệu dựa vào nội dung quan trọng. Ví dụ: Trong tóm tắt tin tức, tóm tắt đưa \r\n\r\nra chi tiết chính của từng sự kiện. \r\n\r\nTóm tắt thông tin (Information): tóm tắt bao gồm tất cả các thông tin nổi bật có \r\n\r\ntrong văn bản nguồn tại nhiều mức độ chi tiết khác nhau, tùy theo tỷ lệ nén được chỉ \r\n\r\nthị. \r\n\r\nTóm tắt đánh giá (Evaluation): tóm tắt nhằm mục đích đánh giá vấn đề chính \r\n\r\ncủa văn bản nguồn. Tóm tắt dạng này tập chung lấy ra các quan điểm, ý kiến chủ \r\n\r\nquan của tác giả nói đến trong văn bản. \r\n\r\n \r\n\r\n3.4. Phân loại theo nội dung \r\n\r\nTóm tắt chung (Generalized): tóm tắt nhằm mục đích đưa ra các nội dung quan \r\n\r\ntrọng bao quát nhất từ văn bản gốc. \r\n\r\nTóm tắt hướng truy vấn (Query-based): tóm tắt nhằm mục đích đưa ra kết quả \r\n\r\ndựa vào câu truy vấn của người dùng. Tóm tắt này thường được sử dụng trong quá \r\n\r\ntrình tìm kiếm thông tin (information retreival). Đầu vào của tóm tắt dạng này \r\n\r\nkhông chỉ là văn bản gốc mà còn thêm vào truy vấn thể hiện thông tin mà người \r\n\r\ndùng quan tâm. \r\n\r\n \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n3.5.  Phân loại theo miền dữ liệu \r\n\r\nTóm tắt trên một miền dữ liệu (Domain): tóm tắt nhắm vào một miền nội dung \r\n\r\nnào đó, như tin tức khủng bố, tin tức tài chính, tin khoa học công nghệ. \r\n\r\nTóm tắt trên một thể loại (Genre): tóm tắt nhắm vào một thể loại văn bản nào \r\n\r\nđó, như báo chí, email, web, bài báo. \r\n\r\nTóm tắt độc lập (Independent): tóm tắt thực hiện trên nhiều thể loại văn bản và \r\n\r\nnhiều miền dữ liệu khác nhau. \r\n\r\n \r\n\r\n3.6. Phân loại theo mức độ chi tiết \r\n\r\nTóm tắt tổng quan (overview): tóm tắt miêu tả tổng quan tất cả các nội dung nổi \r\n\r\nbật trong văn bản nguồn. \r\n\r\nTóm tắt tập trung sự kiện (event): tóm tắt miêu tả một sự kiện cụ thể nào đó \r\n\r\ntrong văn bản nguồn. Sự kiện được quan tâm đến được coi như một đầu vào trong \r\n\r\nquá trình xử lý tóm tắt tự động. Mục tiêu là chỉ đưa ra những nội dung có liên quan \r\n\r\nđến sự kiện đang được quan tâm mà thôi. \r\n\r\n \r\n\r\n4. Ứng dụng của bài toán tóm tắt văn bản \r\n\r\nBài toán tóm tắt văn bản có thể ứng dụng vào rất nhiều hệ thống xử lý ngôn ngữ \r\n\r\ntự động khác nhau. Có thể kể tới một vài ứng dụng tiêu biểu sau đây: \r\n\r\n Tóm tắt tin tức.  \r\n\r\n Tóm tắt kết quả tìm kiếm trong các máy tìm kiếm (search engine). \r\n\r\n Thu thập dữ liệu thông minh. \r\n\r\n Tóm tắt các văn bản, bài báo khoa học. \r\n\r\n Tóm tắt nội dung hội nghị, cuộc họp. \r\n\r\n Ứng dụng trong hệ thống trả lời tự động.  \r\n\r\n \r\n\r\n5. Lý do chọn đề tài \r\n\r\nVới xu thế phát triển bùng nổ của internet hiện nay kéo theo một lượng thông \r\n\r\ntin khổng lồ về tất cả các lĩnh vực trong xã hội sinh ra trong mỗi giờ mỗi phut. Điều \r\n\r\nđó, một mặt tạo điều kiện cho con người có thể tiếp cận một cách nhanh chóng hơn \r\n\r\nvới thông tin nhưng mặt khác lại làm cho con người chìm ngập trong biển thông tin \r\n\r\nkhổng lồ khiến họ không thể xác định được thông tin nào là cần thiết, thông tin nào \r\n\r\nlà vô ích. Nhu cầu cần có một phương án giải quyết vấn đề đó được đặt ra cấp thiết \r\n\r\nđối với mỗi con người. Bởi vậy, tóm tắt văn bản đa ra đời nhằm phục vụ nhu cầu đó \r\n\r\ncủa con người, giup cho con người có thể tiếp cận thông tin một cách nhanh chóng \r\n\r\nvà chính xác nhất. \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\nTóm tắt văn bản (TTVB) đa xuất hiện từ rất lâu, nhưng thường được thực hiện \r\n\r\nmột cách truyền thống do con người. Những nghiên cứu về TTVB bắt đầu từ những \r\n\r\nnăm 60 tại các phòng thí nghiệm nghiên cứu của Mỹ. Từ đó có nhiều phương pháp \r\n\r\nđa được đề xuất, nhiều hệ thống đa được xây dựng. Các phương pháp này thường dựa \r\n\r\ntrên những kỹ thuật cơ bản được đề xuất bởi Luhn, Sdmundson và Salton là trích rút \r\n\r\ncác câu quan trọng từ trong văn bản gốc và kết hợp lại thành văn bản tóm tắt. Với sự \r\n\r\nphát triển của internet, chủ đề về TTVB đa thu hút sự quan tâm của nhiều nhà nghiên \r\n\r\ncứu trong lĩnh vực xử lý ngôn ngữ tự nhiên và tra cứu thông tin (WAS 2000, 2001, \r\n\r\n2002), nhiều các chủ đề đặc biệt trong các phiên của các hội thảo ACL, COLING, \r\n\r\nSINGIR đa được tổ chức.  \r\n\r\nHiện nay, tóm tắt văn bản là một lĩnh vực quan trọng trong xử lý văn bản thu hút \r\n\r\nnhiều nhà nghiên cứu quan tâm. Ứng dụng của TTVB trong nhiều lĩnh vực khác nhau \r\n\r\nnhư sinh tiêu đề tự động (headline generation), rút gọn thông tin sử dụng trong các \r\n\r\nthiết bị cầm tay như PDA, điện thoại di động,.Trong TTVB có lĩnh vực nhỏ hơn \r\n\r\nđược coi là mở đầu của TTVB, nó là tiền đề cho các hình thức tóm tắt phực tạp hiện \r\n\r\nnay, đó chính là tóm tắt đơn văn bản. Hiện nay đa có nhiều phương pháp tóm tắt văn \r\n\r\nbản được đề xuất, tuy nhiên, mỗi phương pháp đều có điểm mạnh và điểm yếu riêng. \r\n\r\nTrong phạm vi bài toàn tóm tắt đơn văn bản theo hướng trích rút các câu quan trọng, \r\n\r\nhay nói cách khác là phân loại câu quan trọng và không quan trọng trong văn bản để \r\n\r\nđưa các câu quan trọng vào văn bản tóm tắt, phương pháp học máy có giám sát \r\n\r\nSVM[2]  là một công cụ tính toán hiệu quả trong không gian chiều cao, trong đó đặc \r\n\r\nbiệt áp dụng cho các bài toán phân loại với số chiều có thể cực lớn. Khả năng áp dụng \r\n\r\nKernel mới cho phép linh động giữa các phương pháp tuyến tính và phi tuyến tính từ \r\n\r\nđó khiến cho hiệu suất phân loại lớn hơn. Việc ứng dụng phương pháp SVM[2] rất \r\n\r\nphù hợp cho bài toán tóm tắt văn bản theo hướng trích rút. \r\n\r\nChính vì vậy, em chọn để tài nghiên cứu phương pháp tóm tắt đơn văn bản tự \r\n\r\nđộng sử dụng mô hình svm ước lượng xác suất làm đồ án tốt nghiệp của mình, \r\n\r\nnhằm mục đích muốn tìm hiểu về một phương pháp mới cho bài toán tóm tắt đơn \r\n\r\nvăn bản, đồng thời cũng muốn so sánh hiệu quả của phương pháp xây dựng với các \r\n\r\nphương pháp đa có. Để có thể mở ra một hướng đi mới hiệu quả hơn cho bài toán \r\n\r\ntóm tắt đơn văn bản nói riêng và bài toán tóm tắt văn bản nói chung. \r\n\r\n  \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\nCHƯƠNG II: TỔNG QUAN VỀ BÀI TOÁN TÓM TẮT VĂN \r\n\r\nBẢN \r\n\r\n1. Bài toán tóm tắt văn bản \r\n\r\nTTVB là quá trình thực hiện giảm đi độ dài, sự phức tạp của một văn bản trong \r\n\r\nkhi vẫn giữ lại được các nội dung có giá trị của nó. TTVB nhằm đưa ra thể hiện về \r\n\r\nnội dung một cách ngắn gọn của văn bản. \r\n\r\nCó thể phát biểu bài toán TTVB trong phạm vi nghiên cứu của đồ án như sau: \r\n\r\n \r\n\r\nĐầu vào : Một văn bản có độ dài trên 5000 từ \r\n\r\nĐầu ra : Nội dung ngắn gọn khoảng 250 từ \r\n\r\n\r\n \r\n\r\n2. Các phương pháp giải quyết bài toán tóm tắt đơn văn bản \r\n\r\nHiện nay, có rất nhiều phương pháp nhằm giải quyết bài toán tóm tắt đơn văn bản \r\n\r\nnhưng đa phần đều tập trung vào hai loại tóm tắt là: tóm tắt trích rút và tóm tắt tóm \r\n\r\nlược. \r\n\r\n2.1. Tóm tắt theo trích rút \r\n\r\nĐa số các phương pháp tóm tắt theo loại này đều tập trung vào việc trích rút ra \r\n\r\ncác câu hay các ngữ nổi bật từ các đoạn văn bản và kết hợp chúng lại thành một văn \r\n\r\nbản tóm tắt.  \r\n\r\n Một số nghiên cứu giai đoạn đầu thường sử dụng các đặc trưng như vị trí của \r\n\r\ncâu trong văn bản, tần suất xuất hiện của từ, ngữ hay sử dụng các cụm từ khóa để \r\n\r\ntính toán trọng số của mỗi câu, qua đó chọn ra các câu có trọng số cao nhất cho văn \r\n\r\nbản tóm  tắt.  \r\n\r\nCác kỹ thuật tóm tắt gần đây sử dụng các phương pháp học máy và xử lý ngôn \r\n\r\nngữ tự nhiên nhằm phân tích để tìm ra các thành phần quan trọng của văn bản. Sử \r\n\r\ndụng các phương pháp học máy có thể kể đến các phương pháp của Kupiec, \r\n\r\nPenderson and Chan năm 1995 sử dụng phân lớp Bayes để kết hợp các đặc trưng lại \r\n\r\nvới nhau hay nghiên cứu của Lin và Hovy năm 1997 áp dụng phương pháp học máy \r\n\r\nnhằm xác định vị trí của các câu quan trọng trong văn bản.  \r\n\r\nBên cạnh đó việc áp dụng các phương pháp phân tích ngôn ngữ tự nhiên như sử \r\n\r\ndụng mạng từ Wordnet của Bazilay và Elhadad vào năm 1997 \r\n\r\n2.2. Tóm tắt theo tóm lược \r\n\r\nCác phương pháp tóm tắt không sử dụng trích rut để tạo ra tóm tắt có thể xem \r\n\r\nnhư là một phương pháp tiếp cận tóm tắt theo tóm lược. Các hướng tiếp cận có thể \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\nkể đến như dựa vào trích rút thông tin (information extraction), ontology, hợp nhất \r\n\r\nvà nén thông tin,. Một trong những phương pháp tóm tắt theo tóm lược cho kết \r\n\r\nquả tốt là các phương pháp dựa vào trích rut thông tin, phương pháp dạng này sử \r\n\r\ndụng các mẫu đa được định nghĩa trước về một sự kiện hay là cốt truyện và hệ \r\n\r\nthống sẽ tự động điền các thông tin trong mẫu có sẵn rồi sinh ra kết quả tóm tắt.  \r\n\r\nTuy nhiên hiện nay các kỹ thuật sinh ra văn bản từ văn bản gốc còn hạn chế, mới \r\n\r\nchỉ dừng ở mức nghiên cứu, kết quả chưa được cao.  \r\n\r\n \r\n\r\n3. Các hướng tiếp cận đối với tóm tắt đơn văn bản \r\n\r\nMặc dù có 2 loại tóm tắt là tóm tắt trích rút và tóm tắt tóm lược, tuy nhiên để \r\n\r\nthực hiện tóm tắt tóm lược cần có một lượng tri thức đầy đủ về lĩnh vực cần tóm tắt. \r\n\r\nĐiều này hiện nay còn hạn chế nhiều, do đó các hướng tiếp cận đa số tập trung vào \r\n\r\ndạng tóm tắt trích rút câu. \r\n\r\nSau đây là một số hướng tiếp cận cho bài toán tóm tắt đơn văn bản: \r\n\r\n3.1. Phương pháp thống kê \r\n\r\nHầu hết các nghiên cứu đầu tiên cho tóm tắt đơn văn bản đều tập trung trên \r\n\r\nnhững văn bản kỹ thuật ( các bài báo khoa học). Các phương pháp cổ điển thường \r\n\r\ntập trung vào các đặc trưng hình thái để tính điểm cho các câu và trích rút các câu \r\n\r\nquan trọng để đưa vào tóm tắt. \r\n\r\n \r\n\r\n \r\n\r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\nÝ tưởng của hướng tiếp cận này: \r\n\r\n Thu thập dữ liệu \r\n\r\n Tạo các bản tóm tắt thủ công \r\n\r\n Thiết kế các công thức toán hay logic để tính điểm cho các câu. \r\n\r\n Lặp cho đến khi tóm tắt tự động đạt được tính tương đương với tóm tắt \r\n\r\nthủ công: \r\n\r\no Tính điểm cho từng câu để tạo ra bản tóm tắt cho từng văn bản \r\n\r\ntrong ngữ liệu dựa vào các đặc trưng về hình thái. \r\n\r\no So sánh tóm tắt được tạo tự động với tóm tắt được tạo thủ công. \r\n\r\no Cải thiện lại phương thức tính điểm cho câu. \r\n\r\nCác nghiên cứu đại diện cho phương pháp này: \r\n\r\n Luhn(1958)  \r\n\r\no Sử dụng các đặc trưng như: word frequency, stop words, word distance. \r\n\r\no Dùng phương pháp so khớp từng kí tự để giải quyết stemming. \r\n\r\n Baxendale(1958) \r\n\r\no Sử dụng các đặc trưng như: sentence position. \r\n\r\no Thử nghiệm 200 đoạn câu, 85% các câu đầu là câu chính và 7% các câu \r\n\r\ncuối và câu chính. \r\n\r\no Phương pháp khá chính xác nhưng quá chủ quan và ngây ngô. Phương \r\n\r\npháp này được sử dụng khá nhiều vào các hệ thống học máy sau này. \r\n\r\n Edmundson(1969)  \r\n\r\no Điển hình nhất trong phương pháp cổ điển. \r\n\r\no Sử dụng các đặc trưng như: word frequency, stop words, position, cue \r\n\r\nwords, title. \r\n\r\no Sử dụng phương pháp kết nối tuyến tính để kết hợp các điểm đặc trưng \r\n\r\nlại với nhau:  \r\n\r\nSi = w1*Ci + w2*Ki + w3*Ti + w4*Li \r\n\r\no Thử nghiệm với 400 văn bản kỹ thuật và kết quả đạt 44%. \r\n\r\n \r\n\r\n3.2. Phương pháp máy học (machine learning) \r\n\r\nNăm 1990, với sự phát triển của nhiều kỹ thuật học máy trong xử lý ngôn ngữ, \r\n\r\nmột số nhà nghiên cứu đa ứng dụng các kỹ thuật này vào trong TTVB tự động. Một \r\n\r\nsố nghiên cứu điển hình của phương pháp này là: Navie  Bayes, Decision Tree, \r\n\r\nHidden Makov Model, Log  Linear, Neural Network, SVM. \r\n\r\nFramework chung cho hệ thống tóm tắt văn bản bằng phương pháp máy học: \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n \r\n\r\n\r\n  \r\n\r\n3.2.1. Phương pháp Nave-Bayes \r\n\r\nCác hướng tiếp cận theo phương pháp này giả định rằng các đặc trưng của văn \r\n\r\nbản độc lập nhau. Sử dụng bộ phân lớp Navie  Bayes để xác định câu nào thuộc về \r\n\r\ntóm tắt và ngược lại: \r\n\r\nCho s là các câu cần xác định. F1...Fk là các đặc trưng đa được chọn và giả \r\n\r\nđịnh các thuộc tính độc lập với nhau. Xác suất của câu s thuộc về tóm tắt được tính \r\n\r\nnhư sau:  \r\n\r\n \r\n\r\nSau khi tính xác suất các câu, n câu có xác suất cao nhất sẽ được trích rút. \r\n\r\nCác nghiên cứu đại diện cho phương pháp này: \r\n\r\n Kupiec(1995) \r\n\r\no Các đặc trưng sử dụng: word frequency, location, cue word, title & \r\n\r\nleading, sentence length, uppercase words. \r\n\r\no Ngữ liệu: 188 cặp văn bản khoa học và tóm tắt. Tổng số câu: 568 câu.Số \r\n\r\ncâu khớp trực tiếp với tóm tắt 451 (79%). \r\n\r\n Aone(1999) \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\no Kết hợp thêm nhiều đặc trưng phong phu hơn: tf.idf( single word, two-\r\n\r\nnoun word, named-entities), discourse (cohension) (sử dụng Wordnet \r\n\r\nvà kỹ thuật xử lý ngôn ngữ tự nhiên để phân tích sự tham chiếu đối với \r\n\r\ncác thực thể). \r\n\r\no Ngữ liệu: sử dụng ngữ liệu của TREC. \r\n\r\no Hệ thống: DimSum. \r\n\r\n Phương pháp OPP (Optimal Position Policy) \r\n\r\nLin và Hovy (1997) đa nghiên cứu tính quan trọng của đặc trưng vị trí \r\n\r\ncâu(sentence position) và cho rằng các câu trong văn bản tuân theo một cấu trúc \r\n\r\ndiễn ngôn ( diễn giải) có thể dự đoán được. Và do cấu trúc trong các loại văn bản \r\n\r\nkhác nhau, nên đặc trưng về vị trí câu không thể định nghĩa đơn giản như trong \r\n\r\nphương pháp Navie  Bayes. \r\n\r\nLin và Hovy đa đề ra phương pháp Optimal Position Policy cho một thể loại văn \r\n\r\nbản ( văn bản tin tức của Zif-Davis về máy tính và phần cứng). Phương pháp thực \r\n\r\nhiện:  \r\n\r\n Với mỗi văn bản, tính năng suất của mỗi vị trí câu với các từ khóa chủ đề. \r\n\r\n Xếp hạng các vị trí câu với năng suất trung bình bằng thủ tục OPP. \r\n\r\n Lấy ra n vị trí câu trong bảng xếp hạng làm tóm tắt. \r\n\r\n \r\n\r\n3.2.2. Phương pháp SVM \r\n\r\nPhương pháp SVM được coi là công cụ mạnh cho những bài toán phân lớp phi \r\n\r\ntuyến tính được các tác giả Vapnik và Chervonenkis phát triển mạnh mẽ năm 1995.  \r\n\r\nSVM là phương pháp học có giám sát được sử dụng rộng rai trong lĩnh vực phân \r\n\r\nlớp mẫu và nhận dạng mẫu. SVM là một họ các phương pháp dựa trên cơ sở các \r\n\r\nhàm nhân (kernel methods) để tối thiểu hoá rủi ro ước lượng. Phương pháp này \r\n\r\nđược Boser, Guyon, và Vapnik giới thiệu lần đầu tiên vào năm 1995 để giải quyết \r\n\r\nvấn đề phân lớp mẫu hai lớp sử dụng nguyên tắc cực tiểu hóa rủi ro cấu trúc \r\n\r\n(Structural Risk Minimization). Phương pháp tiếp cận này dựa trên lý thuyết toán \r\n\r\nhọc thống kê nên có một nền tảng toán học chặt chẽ để đảm bảo rằng kết quả đạt \r\n\r\nđược là tối ưu. SVM là một trong những phương pháp máy học trong đó các khái \r\n\r\nniệm dựa trên dữ liệu đa thu thập được trước đó. Phương pháp này cho phép tận \r\n\r\ndụng được nguồn dữ liệu rất nhiều và sẵn có. \r\n\r\nLà thuật toán học giám sát (supervied learning) được sử dụng cho phân lớp dữ \r\n\r\nliệu.  \r\n\r\nLà 1 phương pháp thử nghiệm, đưa ra 1 trong những phương pháp mạnh và \r\n\r\nchính xác nhất trong số các thuật toán nổi tiếng về phân lớp dữ liệu  \r\n\r\nSVM là một phương pháp có tính tổng quát cao nên có thể được áp dụng cho \r\n\r\nnhiều loại bài toán nhận dạng và phân loại \r\n\r\nCơ sở lý thuyết: \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n \r\n\r\n\r\nSupport vector machine (SVM) xây dựng (learn) một siêu phẳng (hyperplane) để \r\n\r\nphân lớp (classify) tập dữ liệu thành 2 lớp hay nhiều lớp riêng biệt. \r\n\r\n Một siêu phẳng là một hàm tương tự như phương trình đường thẳng, y = ax + b. \r\n\r\nTrong thực tế, nếu ta cần phân lớp tập dữ liệu chỉ gồm 2 feature, siêu phẳng luc này \r\n\r\nchính là một đường thẳng. \r\n\r\nVề ý tưởng thì SVM sử dụng thủ thuật để ánh xạ tập dữ liệu ban đầu vào không \r\n\r\ngian nhiều chiều hơn. Khi đa ánh xạ sang không gian nhiều chiều, SVM sẽ xem xét \r\n\r\nvà chọn ra siêu phẳng phù hợp nhất để phân lớp tập dữ liệu đó. \r\n\r\nBằng cách sử dụng một kernel, SVM ánh xạ tập dữ liệu ban đầu vào không gian \r\n\r\nnhiều chiều \r\n\r\na. Thuật ngữ margin trong SVM: \r\n\r\nMargin là khoảng cách giữa siêu phẳng đến 2 điểm dữ liệu gần nhất tương ứng \r\n\r\nvới các phân lớp.  \r\n\r\n \r\n\r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\nSVM cố gắng maximize margin này, từ đó thu được một siêu phẳng tạo khoảng \r\n\r\ncách xa nhất so với phần tử của 2 lớp. Nhờ vậy, SVM có thể giảm thiểu việc phân \r\n\r\nlớp sai (misclassification) đối với điểm dữ liệu mới đưa vào. \r\n\r\nb. Bài toán tối ưu của SVM \r\n\r\n-  Dữ liệu huấn luyện của SVM là tập các điểm dữ liệu  \r\n\r\n-  D = {(x1,y1), (x2,y2), ., (x1,y1)}, trong đó, xi là vector dữ liệu biểu diễn đối \r\n\r\ntượng cần phân lớp di (xiRn), yi {+1,-1}, cặp (xi, yi) được hiểu là vector xi được \r\n\r\ngán nhãn là yi. \r\n\r\n- Một siêu phẳng phân chia dữ liệu được gọi là tốt nhất, nếu khoảng cách từ \r\n\r\nđiểm dữ liệu gần nhất đến siêu phẳng là lớn nhất. Phương trình tổng quát của một \r\n\r\nsiêu phẳng phân chia như vậy được biểu diễn có dạng như sau: \r\n\r\nwTx + b = 0   (1) \r\n\r\nTrong đó:  \r\n\r\nWT: Vector trọng số, WT = {w1, w2,.,wn}. \r\n\r\nn: Số thuộc tính (hay còn gọi là số chiều của dữ liệu). \r\n\r\nb: Bộ trọng số. \r\n\r\nVới T = 2 (dữ liệu hai chiều)  siêu phẳng phân chia là đường thẳng. \r\n\r\nVới T = 3 (dữ liệu ba chiều)  siêu phẳng phân chia là mặt phẳng. \r\n\r\n-  Tổng quát cho dữ liệu n chiều thì sẽ được phân cách bởi một siêu phẳng. \r\n\r\n-  Siêu phẳng phân chia có vai trò quan trọng trong việc phân lớp, nó quyết định \r\n\r\nxem một bộ dữ liệu sẽ thuộc về lớp nào. Ta xét trên ví dụ sau:  \r\n\r\n-   Với bộ dữ liệu huấn luyện hai chiều, ta có 2 thuộc tính A1 và A2: X={x1, x2}, \r\n\r\nvới x1, x2 là giá trị của thuộc tính A1, A2 và W = {w1, w2}. Phương trình siêu phẳng \r\n\r\ncó thể viết lại như sau: \r\n\r\n: 0 +  11 +  22 = 0   \r\n\r\nTrong đó: w0 tương đương với hằng số b trong PT tổng quát của siêu phẳng. \r\n\r\nVì vậy mỗi điểm nằm trên siêu phẳng phân cách thỏa mãn: \r\n\r\n1: 0 +  11 +  22 > 0   \r\n\r\nTương tự, những điểm nằm dưới siêu phẳng phân cách phải thỏa mãn: \r\n\r\n2: 0 +  11 +  22 < 0   \r\n\r\nBằng cách điều chỉnh trọng số w0 ta có: \r\n\r\n1: 0 + 11 + 22  1 ớ = +1 \r\n\r\n2: 0 + 11 + 22  1 ớ = 1 \r\n\r\n \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n \r\n\r\n\r\nTrong đó: \r\n\r\nĐường màu đỏ là khoảng cách Euclidean của hai điểm 1 và 2. \r\n\r\nĐường màu xanh là khoảng cách Euclidean nhỏ nhất. \r\n\r\n-  Điều này có nghĩa là nếu bất kì bộ nào nằm tại hoặc trên H1 đều thuộc về lớp \r\n\r\n+1, và bất kì bộ nào nằm tại hoặc dưới H2 đều thuộc về lớp -1. Kết hợp 2 bất đẳng \r\n\r\nthức trên ta có: \r\n\r\n(0 + 11 + 22)  1,   (5) \r\n\r\n-  Mỗi bộ huấn luyện nằm tại các mặt biên H1 hay H2thỏa man phương trình trên \r\n\r\nđược gọi là support vectors. Support vectors là những bộ gần với siêu phẳng phân \r\n\r\nchia tuyến tính nhất. \r\n\r\n-  Tuy nhiên trong thực tế có thể tìm được vô số những siêu phẳng phân chia trên \r\n\r\ncùng một tập dữ liệu. Do đó mục tiêu của phương pháp phân lớp SVM là tìm một \r\n\r\nsiêu phẳng phân cách giữa hai lớp sao cho khoảng cách lề giữa hai lớp đạt cực đại, \r\n\r\nnghĩa là có sai sót phân loại bé nhất trên bộ dữ liệu. \r\n\r\n-  Siêu phẳng có biên độ lớn nhất sẽ được chọn như là siêu phẳng phân chia tập \r\n\r\ndữ liệu một cách tốt nhất. Tức là, nếu có 2 siêu phẳng có thể phân chia được tất cả \r\n\r\nnhững bộ dữ liệu cho trước với biên độ của nó. Siêu phẳng với biên độ lớn hơn sẽ \r\n\r\nchính xác hơn trong việc phân loại các bộ dữ liệu trong tương lai so với siêu phẳng \r\n\r\ncó biên độ nhỏ hơn. Điều này là lý do tại sao (trong suốt giai đoạn học hay huấn \r\n\r\nluyện), SVM tìm những siêu phẳng có biên độ lớn nhất, gọi là MMH (maximum \r\n\r\nmarginal hyperlane).Siêu phẳng có biên độ lớn nhất là siêu phẳng có khoảng cách \r\n\r\ntừ nó tới hai mặt bên của nó thì bằng nhau (mặt bên song song với siêu phẳng). \r\n\r\nKhoảng cách đó là khoảng cách ngắn nhất từ MMH tới bộ dữ liệu huấn luyện gần \r\n\r\nnhất của mỗi lớp. Siêu phẳng có biên độ lớn nhất này cho chúng ta một sự phân loại \r\n\r\ntốt nhất giữa các lớp. \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n- Việc huấn luyện SVM với mục đích trên có thể được sử dụng để phân lớp dữ \r\n\r\nliệu mà dữ liệu đó có thể phân chia tuyến tính. Chung ta xem SVM được huấn luyện \r\n\r\nlà SVM tuyến tính. \r\n\r\n-  Ngoài ra hướng tiếp cận của SVM tuyến tính có thể được mở rộng để tạo ra \r\n\r\nSVM không tuyến tính cho việc phân lớp các dữ liệu không thể phân chia tuyến \r\n\r\ntính (hay gọi tắt là dữ liệu không tuyến tính). Những SVM như vậy có khả năng tìm \r\n\r\nnhững ranh giới quyết định không tuyến tính (những mặt không tuyến tính) trong \r\n\r\nkhông gian đầu vào. Những SVM như vậy được gọi là SVM phi tuyến.  \r\n\r\n-  Để tìm ra các support vectors và MMH, đồng nghĩa với việc tìm được bộ phân \r\n\r\nlớp trên bộ dữ liệu đa cho. Có ba trường hợp có thể xảy ra đối với từng bộ dữ liệu, \r\n\r\nmỗi trường hợp sẽ đưa ra một bài toán tối ưu. Việc cần làm là giải quyết bài toán tối \r\n\r\nưu đó. \r\n\r\n \r\n\r\n3.2.3. Phương pháp Decision Tree \r\n\r\nLin và Hovy (1999) đại diện của phương pháp này giả định rằng, các đặc trưng \r\n\r\nkhông độc lập nhau. Tác giả đa kiểm tra nhiều đặc trưng và ảnh hưởng của chúng \r\n\r\nlên quá trình trích rút. Hệ thống tóm tắt của Lin là loại tóm tắt hướng về truy vấn \r\n\r\n(Query - based). \r\n\r\nCác đặc trưng: position (OPP), numeric data, proper name, pronoun & adjective, \r\n\r\nweekday hoặc month. Cùng với 2 đặc trưng mới: query signature ( số từ truy vấn có \r\n\r\ntrong câu) và IR signature ( những từ nổi bật, quan trọng ~ tf*idf). \r\n\r\nHệ thống Summarist của Lin và Hovy sử dụng thuật toán C4.5 để huấn luyện cây \r\n\r\nquyết định. Hệ thống sử dụng tập ngữ liệu của TIPSTER-SUMMAC \r\n\r\n \r\n\r\n3.2.4. Phương pháp Hidden Makov Model \r\n\r\nNhững hướng tiếp cận trước đều không dựa trên những đặc trưng và không \r\n\r\ntuần tự. Conroy và Oleary (2001) đa đưa ra hướng tiếp cận dựa trên mô hình HMM \r\n\r\nvới ý tưởng cơ bản là sử dụng một chuỗi tuần tự các câu. Tác giả đưa ra khái niệm về \r\n\r\nsự phụ thuộc cục bộ (local dependencies) giữa các câu và sử dụng mô hình HMM để \r\n\r\nxác định sự phụ thuộc này. \r\n\r\nCác đặc trưng sử dụng: position, number of term, likelihood of sentence. \r\n\r\nMô hình HMM bao gồm 2s + 1 trạng thái, trong đó s là số trạng thái tóm tắt \r\n\r\n(câu thuộc tóm tắt) và s + 1 là câu không thuộc tóm tắt. \r\n\r\n \r\n\r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\nMô hình HMM xây dựng ma trận chuyển vị trí M, coi các đặc trưng là đa biến \r\n\r\nvà tính xác suất của các câu qua từng trạng thái. \r\n\r\nSử dụng tập ngữ liệu của TREC và được đánh giá với 2 hệ thống khác là \r\n\r\nDimSum và QR, kết quả đều cho độ đo Precision cao hơn. \r\n\r\n \r\n\r\n3.2.5. Phương pháp Log-Linear \r\n\r\nOsborne (2002) đại diện cho mô hình này cũng coi các đặc trưng là không độc \r\n\r\nlập với nhau và sử dụng mô hình Log-Linear khắc phục giả định này. \r\n\r\nCác đặc trưng sử dụng: word pair, sentence length, sentence position và \r\n\r\ndiscourse features (nằm trong introduction hay conclusion). \r\n\r\nMô hình huấn luyện của Log-Linear được thực hiện như sau: \r\n\r\n \r\n\r\nTrong đó, c là nhan muốn gán cho câu s, fi là đặc trưng thứ i và i là trọng số \r\n\r\nkết nối các đặc trưng. Nhan c có 2 khả năng: thuộc tóm tắt hoặc không thuộc tóm tắt. \r\n\r\nGiai đoạn phân lớp câu mới được thực hiện như sau: \r\n\r\n \r\n\r\nKết quả được đo bằng độ đo f2 = 2pr/(p+r). Tác giả đa đánh giá với hướng tiếp cận \r\n\r\nBayes và kết quả luôn cho độ đo f2 cao hơn. \r\n\r\n \r\n\r\n3.3. Phương pháp phân tích ngôn ngữ tự nhiên \r\n\r\nPhương pháp tiếp theo sử dụng các kỹ thuật phân tích ngôn ngữ tự nhiên phức \r\n\r\ntạp. Không phải tất cả các phương pháp phân tích ngôn ngữ tự nhiên đều sử dụng \r\n\r\nhọc máy, đôi khi phương pháp chỉ sử dụng một số các heuristic để tạo trích rút. \r\n\r\nHầu hết các phương pháp này đều dựa trên cấu trúc diễn ngôn (discourse \r\n\r\nstructure) hay cấu trúc diễn đạt ( thể hiện) của văn bản, như: cấu trúc các section \r\n\r\ncủa văn bản, liên kết ngữ pháp ( trùng lặp, tỉnh lược, liên hợp), liên kết từ vựng \r\n\r\n( đồng nghĩa, bao hàm, lặp lại), cấu trúc chính phụ. \r\n\r\nCác nghiên cứu đại diện cho phương pháp này: \r\n\r\n Rhetorical Structure(Cấu trúc văn bản, ngữ pháp): Ono (1994) \r\n\r\no Xây dựng một thủ tục để trích rút các cấu trúc chính phụ (rhetorical \r\n\r\nstructure) từ các văn bản tiếng Nhật và xây dựng một cây nhị phân để \r\n\r\nthể hiện. \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\no Các bước để trích rút cấu trúc: phân tích câu, trích rút một quan hệ \r\n\r\nchính phụ, phân đoạn,  tạo ứng viên và đánh giá độ ưu tiên. \r\n\r\no Sau khi xây dựng cây sẽ thực hiện tỉa nhánh để giảm bớt câu và tạo tóm \r\n\r\ntắt. \r\n\r\no Kết quả đạt được 51% các câu chính được xác định và 74% các câu \r\n\r\nquan trọng nhất được xác định. \r\n\r\n Lexical Chain(Cấu trúc, ngữ nghĩa chuỗi từ vựng): Barzilay và \r\n\r\nElhadad(1997) \r\n\r\no Hai tác giả cũng đa sử dụng một lượng đáng kể những phân tích ngôn \r\n\r\nngữ trong TTVB dựa trên chuỗi từ vựng (lexical chain). Chuỗi từ vựng \r\n\r\nlà chuỗi các từ liên quan trong văn bản. \r\n\r\no Các bước thực hiện: phân tích đoạn văn bản, xác định các chuỗi từ vựng \r\n\r\nvà sử dụng các từ vựng tốt nhất để xác định câu được chèn vào tóm tắt. \r\n\r\no Để tìm các chuỗi từ vựng tác giả sử dụng Wordnet. Các từ có liên quan \r\n\r\nvới nhau sẽ được  đưa vào chuỗi. Sự liên quan được tính bằng khoảng \r\n\r\ncách trong Wordnet. Chuỗi sẽ được tính điểm dựa vào chiều dài và sự \r\n\r\nđồng nhất của nó. \r\n\r\no Kết quả đạt được tốt hơn hệ thống tóm tắt của Microssoft với độ \r\n\r\nPrecision là 61 và recall 67 (Microsoft là 33 và 27). \r\n\r\no Hạn chế: Không thể kiểm được chiều dài và mức độ chi tiết của tóm tắt \r\n\r\ndo số chuỗi còn ít. Tóm tắt thiếu sự kết dính và chưa chi tiết so chọn cả \r\n\r\ncâu. \r\n\r\n Rhetorical Structure(Cấu trúc ngữ nghĩa, đoạn văn): Marcu (1998) \r\n\r\nSử dụng các heuristic dựa trên cấu trúc diễn đạt với các đặc trưng truyền thống. Lý \r\n\r\nthuyết về cấu trúc diễn đạt được tác giả thể hiện thông qua lý thuyết cấu trúc chính \r\n\r\nphụ(Rhetorical Structure Theory). Lý thuyết cho rằng hai khoảng văn bản không \r\n\r\ntrùng lặp có mối quan hệ trung tâm (nucleus) và vệ tinh (satellite). Trong đó, trung \r\n\r\ntâm quan trọng hơn vệ tinh và độc lập hoàn toàn trong cấu trúc chính phụ. Cấu trúc \r\n\r\ntrọng tâm và vệ tinh được biểu diễn thành cây nhị phân. \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n \r\n\r\n\r\nĐể tính điểm cho các cấu trúc, tác giả sử dụng nhiều độ đo khác nhau như: \r\n\r\nclustering-based metric, marker-based metric, rhetorical clustering-based technique, \r\n\r\nshape-based metric, title-based metric, position-based metric, connectedness-based \r\n\r\nmetric và sử dụng phương pháp kết hợp tuyến tính. Lấy ra n câu chứa cấu trúc có \r\n\r\nđiểm cao nhất. \r\n\r\nHệ thống đạt được hiệu quả độ đo F 75.42% cao hơn 3.5% so với baseline bằng \r\n\r\nphương pháp lấy n câu đầu. Ngữ liệu được sử dụng là từ TREC \r\n\r\n \r\n\r\n3.4. Phương pháp học sâu (deep learning) \r\n\r\nTrong những năm qua, thuật ngữ \"deep learning\" (học sâu) đa dần len lỏi mỗi khi \r\n\r\ncó cuộc hội thoại nào bàn về trí tuệ nhân tạo (AI), dữ liệu lớn (Big Data) và phân \r\n\r\ntích (Analytics). Và với lý do chính đáng  đây là một cách tiếp cận đầy hứa hẹn tới \r\n\r\nAI khi phát triển các hệ thống tự trị, tự học, những thứ đang cách mạng hóa nhiều \r\n\r\nngành công nghiệp. \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\nHọc sâu là cho một hệ thống máy tính \"ăn\" rất nhiều dữ liệu, để chúng có thể \r\n\r\nsử dụng và đưa ra các quyết định về những dữ liệu khác. Dữ liệu này được nạp \r\n\r\nthông qua các mạng thần kinh, tương tự như học máy. Những mạng lưới này  các \r\n\r\ncấu trúc logic yêu cầu một loạt các câu hỏi đung/sai, hoặc trích xuất một giá trị số, \r\n\r\ncủa mỗi bit dữ liệu đi qua chung và phân loại theo các câu trả lời nhận được. \r\n\r\nVì công việc của học sâu là tập trung phát triển những mạng lưới này, chúng \r\n\r\nđa trở thành \"mạng thần kinh sâu\" (Deep Neural Network)  những mạng logic \r\n\r\nphức tạp cần thiết để xử lý các bộ dữ liệu lớn, như thư viện hình ảnh của Google \r\n\r\nhay Instagram. \r\n\r\nMạng neural nhân tạo (Artificial neural network) \r\n\r\nMạng Nơron nhân tạo (Artificial Neural Network- ANN) là mô hình xử lý thông \r\n\r\ntin được mô phỏng dựa trên hoạt động của hệ thống thần kinh của sinh vật, bao gồm \r\n\r\nsố lượng lớn các Nơron được gắn kết để xử lý thông tin. ANN giống như bộ não \r\n\r\ncon người, được học bởi kinh nghiệm (thông qua huấn luyện), có khả năng lưu giữ \r\n\r\nnhững kinh nghiệm hiểu biết (tri thức) và sử dụng những tri thức đó trong việc dự \r\n\r\nđoán các dữ liệu chưa biết (unseen data). \r\n\r\n Kiến trúc chung của một mạng nơron nhân tạo (ANN) gồm 3 thành phần đó \r\n\r\nlà: Input Layer, Hidden Layer và Output Layer (Xem \r\nTrong đó, lớp ẩn (Hidden Layer) gồm các Nơron nhận dữ liệu input từ các Nơron \r\n\r\nở lớp (Layer) trước đó và chuyển đổi các input này cho các lớp xử lý tiếp theo. \r\n\r\nTrong một ANN có thể có nhiều lớp ẩn. \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n \r\n\r\nTrong đó các Processing Elements (PE) của ANN gọi là Nơron, mỗi \r\n\r\nNơron nhận các dữ liệu vào (Inputs) xử lý chúng và cho ra một kết quả (Output) \r\n\r\nduy nhất. Kết quả xử lý của một Nơron có thể làm Input cho các Nơron khác. \r\n\r\nBên trên là tổng quan về kiến trúc mạng ANN cơ bản. Để phục vụ những bài \r\n\r\ntoán phức tạp ta cũng cần những kiến trúc mạng phức tạp hơn. Một số kiến trức \r\n\r\nmạng phổ biến hiện nay như:  \r\n\r\n Deep Neural Network (DNN) \r\n\r\n Deep Belief Network (DBN) \r\n\r\n Deep Boltzmann Machine (DBM) \r\n\r\n Recurrent Neural Network (RNN) \r\n\r\n Convolution Neural Network (CNN) \r\n\r\n Multi-modal/multi-tasking \r\n\r\n Deep Stacking Network (DSN)  \r\nTrong các kiến trúc trên mô hình mạng neural hồi quy RNN là mô hình được áp \r\n\r\ndụng rất rộng rãi trong các bài toán xử lý ngôn ngữ tự nhiên (NLP). Do mô hình \r\n\r\nRNN mô hình hoá được bản chất dữ liệu trong NLP. Dữ liệu trong NLP có đặc tính \r\n\r\nchuỗi và có sự phụ thuộc lẫn nhau giữa các thành phần (trạng thái) trong dữ liệu. \r\n\r\n \r\n\r\nHạn chế của hướng tiếp cận học sâu với bài toán đặt ra trong đề tài:  \r\n\r\nVới hướng tiếp cận này, hiện nay chưa có kho dữ liệu phù hợp cho bài toán tóm \r\n\r\ntắt văn bản của đề tài. Trên thế giới, các kết quả được nghiên cứu trên kho dữ liệu \r\n\r\nvới các văn bản có độ dài khoảng 100 từ và đưa ra một headline cho văn bản đó. \r\n\r\n \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n4. Đề xuất hướng giải quyết  \r\n\r\nVới bài toán tóm tắt văn bản theo hướng trích rút các câu quan trọng để đưa vào \r\n\r\nvăn bản tóm tắt. Ý tưởng đưa ra : cần phân tích từng câu trong văn bản, và phân lớp \r\n\r\nchúng thành hai lớp  câu quan trọng và câu không quan trọng.  \r\n\r\nNhận thấy phương pháp học máy SVM là 1 trong những phương pháp mạnh và \r\n\r\nchính xác nhất trong số các thuật toán nổi tiếng về phân lớp dữ liệu hiện nay.,được \r\n\r\ncoi là công cụ mạnh cho những bài toán phân lớp phi tuyến tính, SVM là phương \r\n\r\npháp học có giám sát được sử dụng rộng rai trong lĩnh vực phân lớp mẫu và nhận \r\n\r\ndạng mẫu. Phương pháp tiếp cận này dựa trên lý thuyết toán học thống kê nên có \r\n\r\nmột nền tảng toán học chặt chẽ để đảm bảo rằng kết quả đạt được là tối ưu. Phương \r\n\r\npháp này cho phép tận dụng được nguồn dữ liệu rất nhiều và sẵn có. \r\n\r\nBên cạnh đó SVM[2]  là một công cụ tính toán hiệu quả trong không gian chiều \r\n\r\ncao, trong đó đặc biệt áp dụng cho các bài toán phân loại với số chiều có thể cực \r\n\r\nlớn. Khả năng áp dụng Kernel mới cho phép linh động giữa các phương pháp tuyến \r\n\r\ntính và phi tuyến tính từ đó khiến cho hiệu suất phân loại lớn hơn. Việc ứng dụng \r\n\r\nphương pháp SVM[2] rất phù hợp cho bài toán tóm tắt văn bản theo hướng trích rút. \r\n\r\nDo đó em giải quyết bài toán phân lớp câu quan trọng và không quan trọng bằng \r\n\r\nhướng tiếp cận sử dụng SVM.  \r\n\r\nCác câu trong các văn bản của bộ dữ liệu huấn luyện sẽ được xử lý, phân tích và \r\n\r\nmô hình hóa cho phù hợp với đầu vào của mô hình huấn luyện. Từ đó cho SVM học \r\n\r\ncác dữ liệu đa được phân lớp với các tùy chọn phù hợp để sinh ra model huấn luyện, \r\n\r\nphục vụ cho đánh dấu câu quan trọng trong các văn bản kiểm thử. \r\n\r\n \r\n\r\n5. Phương pháp đánh giá \r\n\r\nRecall-Oriented Understudy for Gisting Evaluation (ROUGE)[5] là một phương \r\n\r\npháp do Lin và Hovy đưa ra vào năm 2003 cũng dựa trên các khái niệm tương tự. \r\n\r\nPhương pháp này đa cho ra kết quả khả quan và được sự đánh giá cao của cộng \r\n\r\nđồng nghiên cứu tóm tắt văn bản. \r\n\r\nCó 5 đánh giá ROUGE được đưa ra \r\n\r\n5.1.  ROUGE- N (N-gram Co-Occurrence Statistics) \r\n\r\n \r\n\r\nROUGE-N là một thu hồi n-gram giữa một bản tóm tắt tự động và một tập hợp các \r\n\r\ntài liệu tóm tắt tham khảo summaries. ROUGE-N được tính như sau [21]: \r\n\r\n \r\n\r\nTrong đó: n là chiều dài của n-gram, Countmatch(gramn) là số lượng tối đa n-gam có \r\n\r\nthể sảy ra đồng thời trong bản tóm tắt tự động và bản tóm tắt tham khảo. \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n Rõ ràng là ROUGE-N là một biện pháp liên quan đến thu hồi vì mẫu số của \r\n\r\nphương trình là tổng của số n-gram xảy ra ở phía tài liệu tóm tắt tham khảo.  \r\n\r\n \r\n\r\n5.2. ROUGE L (Longest Common Subsequence). \r\n\r\nROUGE-L tính tỷ lệ giữa chiều dài của chung dài nhất 'tóm tắt dãy (LCS) và \r\n\r\nchiều dài của bản tóm tắt tài liệu tham khảo như mô tả bởi phương trình:  \r\n\r\n \r\n\r\n Trong đó: m là độ dài của bản tóm tắt tài liệu tham khảo câu X và n là chiều \r\n\r\ndài của ứng cử viên câu Y. LCS(X,Y) là độ dài LCS của x và Y. R là sự thu hồi của \r\n\r\nX và Y, P là độ chính xác giữa X và Y. Tham số được chọn trong DUC là 8.  \r\n\r\n \r\n\r\n5.3. ROUGE-W (Weighted Longest Common Subsequence) \r\n\r\nROUGE-W: Trọng số của chuỗi chiều dài lớn nhất, là mở rộng của ROUGE-L: \r\n\r\n \r\n\r\nTrong đó: m là độ dài của bản tóm tắt tài liệu tham khảo câu X và n là chiều dài của \r\n\r\nứng cử viên câu Y. LCS(X,Y) là độ dài LCS của x và Y. R là sự thu hồi của X và \r\n\r\nY, P là độ chính xác giữa X và Y. Tham số được chọn trong DUC là 8. \r\n\r\n \r\n\r\n5.4. ROUGE S (Skip-Bigram Co-Occurrence Statistics). \r\n\r\nSử dụng sự chồng chéo của skip-bigram giữa bản tóm tắt ứng cử viên và bản tóm \r\n\r\ntắt tham khảo: \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n \r\n\r\nTrong đó: SKIP2(X,Y) là số lượng bigram giữa X và Y. R là thu hồi giữa X và Y, \r\n\r\ncòn P là độ chính xác giữa X và Y. \r\n \r\n\r\n5.5. ROUGE SU (Extension of ROUGE-S). \r\n\r\nMột vấn đề tiềm năng cho ROUGE-S là nó không cung cấp cho bất kỳ giá trị cho \r\n\r\nmột câu ứng cử viên nếu câu không có bất kỳ cặp từ xảy ra đồng thời với câu tham \r\n\r\nchiếu. Để đạt được điều này, mở rộng ROUGE-S với việc bổ sung unigram là đơn \r\n\r\nvị đếm. Các phiên bản mở rộng được gọi là ROUGE-SU. Cũng có thể có được \r\n\r\nROUGE-SU từ ROUGE-S bằng cách thêm một dấu hiệu bắt đầu của câu vào lúc \r\n\r\nbắt đầu của ứng cử viên và câu tham khảo. \r\n\r\n \r\n\r\n Trong 5 đánh giá ROUGE được đưa ra đối với bài toán tóm tắt văn bản \r\n\r\nthường sử dụng đánh giá ROUGE-N : tương đương với độ đo Recall. Trong \r\n\r\nđồ án, em đánh giá kết quả văn bản tóm tắt bằng đánh giá ROUGE-1 unigram \r\n\r\nvà ROUGE-2 bigram \r\n\r\n \r\n\r\n  \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\nCHƯƠNG III: MÔ HÌNH ĐỀ XUẤT \r\n\r\n1. Tổng quan về mô hình đề xuất \r\n\r\nVới bài toán tóm tắt văn bản tự động tiếng Anh theo hướng trích rút, sử dụng mô \r\n\r\nhình SVM , em đề xuất mô hình sau để thử nghiệm cho phương pháp này :  \r\n\r\n \r\n\r\n \r\n\r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\nCác pha xử lý trong mô hình đề xuất :  \r\n\r\n Tách câu và tiền xử lý \r\n\r\n Tính toán các đặc trưng và mô hình hóa dữ liệu \r\n\r\n Huấn luyện và kiểm thử \r\n\r\n Đánh giá kết quả \r\n\r\n \r\n\r\n2. Bộ dữ liệu huấn luyện \r\n\r\n2.1.  Tổng quan \r\n\r\nTrong quá trình nghiên cứu đồ án, em đa tìm hiểu một số tập dữ liệu huấn luyện, \r\n\r\ntrong đó có 2 bộ dữ liệu phù hợp cho bài toán tóm tắt trích rút của mình:  \r\n\r\n- Bộ dữ liệu Bác Mới:  \r\n\r\nBộ dữ liệu huán luyện với kích thước lớn 3.6GB, bao gồm 1.002.394 bài báo. \r\n\r\nĐộ dài mỗi bài báo từ 300 đến 1500 từ.  \r\n\r\n- Bộ dữ liệu DUC 2007: \r\n\r\nMột tập các bài báo về 45 chủ đề khác nhau, trong đó có 23 chủ đề đa được \r\n\r\ntổng hợp và đánh dấu các câu trọng tâm, kèm theo đó là các bản tóm tắt thủ \r\n\r\ncông của chuyên gia.  \r\n\r\nBộ dữ liệu Báo Mới là tập dữ liệu phong phú về chủ đề, với những bài báo và \r\n\r\nthông tin chân thực, thực tế, có tính linh hoạt và ứng dụng lớn.  Bên cạnh đó các \r\n\r\nchương trình tóm tắt văn bản Tiếng Việt còn khá ít, đạt kết cả chưa cao. Việc nghiên \r\n\r\ncứu thử nghiệm trên bộ dữ liệu Tiếng Việt mang lại nhiều ý nghĩa và ứng dụng trong \r\n\r\nthực tiễn so với bộ dữ liệu tiếng Anh.  \r\n\r\nTuy nhiên các bài báo trong bộ dữ liệu tiếng Việt có độ chênh lệch về độ dài \r\n\r\nkhá lớn, nhiều bài báo có độ dài nhỏ hơn 400 từ, nhiều bài báo có nội dung rời rạc, \r\n\r\ndo đó cần thiết phải lọc và loại bỏ các bài báo không phù hợp với bài toán. Công đoạn \r\n\r\nnày mất nhiều thời gian. Bên cạnh đó, mỗi bài báo chỉ bao gồm 1 câu tiêu đề, có hoặc \r\n\r\nkhông có từ 1 đến 2 câu tóm tắt nội dung của bài báo (câu Description), do đó đặt ra \r\n\r\nvấn đề phải đánh dấu các câu quan trọng trong văn bản dựa vào các câu Description \r\n\r\nđó, dẫn đến giảm độ chính xác của mô hình huấn luyện so với bộ DUC2007 có đánh \r\n\r\ndấu. Bộ dữ liệu Báo Mới không có bản tóm tắt thủ công để đánh giá kết quả.  \r\n\r\nDo đó, trong phạm vi bài toán đưa ra của đồ án, em chọn bộ dữ liệu DUC2007 \r\n\r\nđể huấn luyện và kiểm thử mô hình.  \r\n\r\n  \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n2.2.  Cấu trúc bộ dữ liệu DUC2007 \r\n\r\nDUC2007 bao gồm 2 tập dữ liệu: \r\n\r\n Main task:  \r\n\r\nTập dữ liệu trong main task được chia thành các thư mục theo chủ đề. Mỗi chủ \r\n\r\nđề bao gồm 25 văn bản liên quan. Mỗi chủ đề và cụm tài liệu được gửi cho 4 đơn vị \r\n\r\nđánh giá NIST khác nhau, bao gồm cả nhà phát triển chủ đề đó. Các chuyên gia sẽ \r\n\r\ntạo ra văn bản tóm tắt khoảng 250 từ của cụm tài liệu, đáp ứng được nhu cầu thông \r\n\r\ntin được thể hiện trong chủ đề. Và những văn bản tóm tắt của chuyên gia được dùng \r\n\r\ntrong việc đánh giá nội dung, kết quả của các bài tóm tắt của các hệ thống tự động.  \r\n\r\n==> bộ dữ liệu phù hợp trong phạm vi nghiên cứu của đồ án.  \r\n\r\nMain task bao gồm 3 tệp dữ liệu: \r\n\r\n- Kết quả đánh giá từ chuyên gia \r\n\r\n- Tập hợp các kết quả của các hệ thống tóm tắt tự động đa tham gia \r\n\r\n- Tập các văn bản được đánh dấu kết quả của chuyện gia và các hệ thống tóm \r\n\r\ntắt.  \r\n\r\nEm sử dụng tập (2007 SCU-marked corpus) để huấn luyện trong đồ án của mình. \r\n\r\nUpdate task (pilot): \r\n\r\n Mục đích của bộ dữ liệu là tạo ra những văn bản tóm tắt ngắn khoảng 100 từ \r\n\r\ntheo giả định rằng người đọc đa đọc một số tài liệu trước đó.  \r\n\r\nĐối với mỗi chủ đề, các tài liệu sẽ được sắp xếp theo trình tự thời gian và sau \r\n\r\nđó được chia thành 3 bộ, A,B,C.  \r\n\r\nTrong đó các dấu thời gian trên tất cả các tài liệu trong mỗi bộ được sắp xếp \r\n\r\ntheo thời gian (A) <thời gian (B) <thời gian (C). Sẽ có khoảng 10 tài liệu trong Bộ A, \r\n\r\n8 trong Bộ B và 7 trong Bộ C. \r\n\r\n==> Trong phạm vi nghiên cứu của đồ án, bộ dữ liệu Update task (pilot) không phù \r\n\r\nhợp.  \r\n\r\na. 2007 SCU-marked corpus: \r\n\r\n- Kho dữ liệu bao gồm một file XML (.scu) cho mỗi chủ đề, trong đó các câu được \r\n\r\nxác định bởi trình ranh giới câu cục bộ.  \r\n\r\n- Các câu trong file XML trong mỗi chủ đề được lưu đưới dạng phần tử trong thẻ \r\n\r\n<line>.  \r\n\r\n- Các câu quan trọng được đánh dấu bằng thẻ <annotation> gồm 3 giá trị thuộc \r\n\r\ntính và một hoặc nhiều thẻ <scu> , các trường xuất hiệu trong cấu truc được chú thích \r\n\r\nnhư sau:  \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n \r\n\r\nTrong đó:  \r\n\r\nscu-count: số lượng SCU được nhận bởi câu đó. \r\n\r\nĐịnh dạng:  số nguyên \r\n\r\nCó giá trị bằng với số phần tử SCU \r\n\r\nsum-count: số lượng các văn bản tóm tắt đa sử dụng câu đó. \r\n\r\n  Định dạng:  số nguyên \r\n\r\nsums: số thứ tự nhận dạng người tham gia ẩn danh, phân cách dấu phẩy.  \r\n\r\nSố lượng số nhận dạng người tham gia ẩn danh này bằng giá trị sum-\r\n\r\ncount \r\n\r\nuid: ma định danh SCU \r\n\r\n  Định dạng: số nguyên \r\n\r\nlabel: nội dung của SCU \r\n\r\n  Định dạng: chuỗi \r\n\r\nweight: số lượng bản tóm tắt bằng tay, trong đó có thể hiện các SCU \r\n\r\n  Định dạng: số nguyên. \r\n\r\n\r\n \r\n\r\n2.3. Ưu, nhược điểm của bộ dữ liệu \r\n\r\nƯu điểm của bộ dữ liệu:  \r\n\r\n- Bộ dữ liệu có cấu truc rõ ràng, mạch lạc, dễ phân tích.  \r\n\r\n- Bộ dữ liệu bao gồm các bảng tóm tắt chuẩn của chuyên gia, phù hợp cho đánh \r\n\r\ngiá kết quả thử nghiệm.  \r\n\r\n- SCU-marked corpus là bộ dữ liệu tổng hợp, được gán nhán câu quan trọng và \r\n\r\ncâu không quan trọng, phù hợp cho mô hình huấn luyện phân lớp của SVM. \r\n\r\nNhược điểm:  \r\n\r\n- Kích thước bộ dữ liệu còn khá nhỏ: \r\n\r\n- Số lượng phần tử sau khi đa phân tích: 12.832 phần tử (tương đương với \r\n\r\n12.832 câu trong các văn bản huấn luyện) trong đó 2/3 số phần tử được dùng \r\n\r\ncho huấn luyện. 1/3 số phần tử được dùng cho kiểm tra kết quả.  \r\n\r\n \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n3. Các pha xử lý trong mô hình đề xuất \r\n\r\n3.1. Tách câu và tiền xử lý  \r\n\r\n- Tách câu : \r\n\r\nTách văn bản thành các đoạn, các câu.  \r\n\r\n- Đánh dấu câu quan trọng :  \r\n\r\nDựa vào thông số thống kê  của tập dữ liệu huấn luyện đánh dấu câu quan \r\n\r\ntrọng. \r\n\r\n- Lower case :  \r\n\r\nCác từ trong văn bản của bộ dữ liệu được chuyển đồi về chữ thường.  \r\n\r\n- Loại bỏ dấu câu : \r\n\r\nCác dấu câu như dấu chấm, dấu phẩy, dấu chấm than, dấu chấm hỏi, dấu ba \r\n\r\nchấm được thay bằng khoảng trắng. \r\n\r\n- Loại bỏ stopword : \r\n\r\nSử dụng từ điển từ dừng. \r\n\r\nLoại bỏ các từ dừng khỏi văn bản.  \r\n\r\n \r\n\r\n3.2. Tính toán các đặc trưng và mô hình hóa dữ liệu \r\n\r\nTham khảo bài báo của Kam-Fai Wong, Mingli Wu[1] về tóm tắt văn bản, bài \r\n\r\nbáo đưa ra mô hình chung của tóm tắt văn bản trích rút dựa trên học máy như sau :  \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n \r\n\r\n\r\nTrong đó có chỉ rõ ra 4 đặc trưng của câu :  \r\n\r\n- Surface Feature : đặc trưng bề mặt \r\n\r\n- Content Featute : Đặc trưng về nội dung \r\n\r\n- Event Feature : Đặc trưng sự kiện \r\n\r\n- Relevance Feature : Đặc trưng về mức độ liên quan. \r\n\r\nMột số nhà nghiên cứu đa thử nghiệm nhiều phương pháp tóm tắt văn bản trích \r\n\r\nrút dựa trên học máy, và đưa ra đánh giá. Kết quả đánh giá cho thấy đặc trưng sự \r\n\r\nkiện (Event Feature) không liên quan, không có tác dụng trong tóm tắt văn bản trích \r\n\r\nrút. \r\n\r\nCác đặc trưng bài báo đưa ra :  \r\n\r\n  \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n \r\n\r\nSTT  Tên các đặc trưng \r\n\r\n1 Surface \r\n\r\nFeature  \r\n\r\nPosition \r\n\r\n2 Doc_First \r\n\r\n3 Para_First \r\n\r\n4 Length \r\n\r\n5 Quote \r\n\r\n6 Content \r\n\r\nFeature \r\n\r\nCentroid_Uni \r\n\r\n7 Centroid_Bi \r\n\r\n8 SigTerm_Uni \r\n\r\n9 SigTerm_Bi \r\n\r\n10 FreqWord_Uni \r\n\r\n11 FreqWord_Bi \r\n\r\n12 Relevance \r\n\r\nFeature \r\n\r\nFirstRel_Doc \r\n\r\n13 FirstRel_Para \r\n\r\n\r\nSau quá trình tìm kiếm và phân tích các bộ dữ liệu phù hợp cho mô hình, em sử \r\n\r\ndụng bộ dữ liệu DUC2007 để huấn luyện và thử nghiệm.  \r\n\r\nBộ dữ liệu huấn luyện của DUC2007, các văn bản không được phân chia thành \r\n\r\ncác đoạn văn, do đó em không xét 2 đặc trưng Para_First : câu đang xét có phải câu \r\n\r\nđầu đoạn hay không ? Và  FirstRel_Para : độ liên quan của câu đang xét với câu đầu \r\n\r\nđoạn chứa câu đó.  \r\n\r\nSau đây em xin trình bày chi tiết về 11 đặc trưng em sẽ sử dụng cho mô hình của \r\n\r\nmình bao gồm : Position, Doc_First, Length, Quote, Centroid_Uni, Centroid_Bi, \r\n\r\nSigTerm_Uni, SigTerm_Bi, FreqWord_Uni, FreqWord_Bi, FirstRel_Doc. \r\n\r\n \r\n\r\nSurface features :  \r\n\r\nCác đặc trưng bề mặt dựa trên cấu trúc của tài liệu hoặc câu, bao gồm vị trí \r\n\r\ncâu trong tài liệu, số từ trong câu, và số từ được trích dẫn trong câu. \r\n\r\nTên  Nội dung \r\n\r\nPosition Đặc trưng về vị trí, được tính bằng thương số : 1/vị trí \r\n\r\ncủa câu đó trong văn bản \r\n\r\nDoc_First Cho biết câu đó có phải câu đầu tiên của văn bản hay \r\n\r\nkhông \r\n\r\nLength Số lượng từ trong câu \r\n\r\nQuote Số lượng từ được trích dẫn trong câu  \r\n\r\n\r\n \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n \r\n\r\n Content Features : \r\n\r\nĐặc trưng về nội dung. Các đặc trưng được tính dựa trên các từ mang nội dung chủ \r\n\r\nchốt : từ trung tâm (centroid words), các thuật ngữ chữ ký (signature words) và các \r\n\r\ntừ có tần số cao trong văn bản (frequent words) với cả hai đại diện Unigram và \r\n\r\nBigram. \r\n\r\n\r\n \r\n\r\nTên Nội dung \r\n\r\nCentroid_Uni Tổng khối lượng của các từ centroid unigram trong \r\n\r\ncâu. \r\n\r\nCentroid_Bi Tổng khối lượng của các từ centroid bigram trong \r\n\r\ncâu. \r\n\r\nSigTerm_Uni Số từ thuật ngữ unigram trong câu. \r\n\r\nSigTerm_Bi Số từ thuật ngữ bigram trong câu. \r\n\r\nFreqWord_Uni Tổng khối lượng các từ unigram có tần số cao  trong \r\n\r\ncâu. \r\n\r\nFreqWord_Bi Tổng khối lượng các từ bigram có tần số cao trong \r\n\r\ncâu. \r\n\r\n\r\n \r\n\r\na. Xác định các từ centroid unigram và centroid bigram. \r\n\r\nCác từ trung tâm được xác định là 30% số từ xuất hiện trong văn bản có chỉ \r\n\r\nsố TF-IDF lớn nhất. \r\n\r\nCách tính TF-IDF : \r\n\r\n \r\n\r\n TF (Term Frequency):  \r\n\r\nLà tần suất xuất hiện của một từ trong một đoạn văn bản. Với những đoạn văn \r\n\r\nbản có độ dài khác nhau, sẽ có những từ xuất hiện nhiều ở những đoạn văn bản dài \r\n\r\nthay vì những đoạn văn bản ngắn. Vì thế, tần suất này thường được chia cho độ dài \r\n\r\ncủa đoạn văn bản như một phương thức chuẩn hóa (normalization).  \r\n\r\nTF được tính bởi công thức:  \r\n\r\n()  =  \r\n(, )\r\n\r\n\r\n \r\n\r\nVới t  là một từ trong văn bản. \r\n\r\nf(t,d) là tần số xuất hiện của d trong đoạn văn bản d. \r\n\r\nT là tổng số từ trong văn bản đó. \r\n\r\n \r\n\r\n IDF (Inverse Document Frequency):  \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\nTính toán độ quan trọng của một từ. Khi tính toán TF, mỗi từ đều quan trọng như \r\n\r\nnhau, nhưng có một số từ trong tiếng Anh như \"is\", \"of\", \"that\",... xuất hiện khá \r\n\r\nnhiều nhưng lại rất ít quan trọng.  \r\n\r\nVì vậy, chúng ta cần một phương thức bù trừ những từ xuất hiện nhiều lần và \r\n\r\ntăng độ quan trọng của những từ ít xuất hiện những có ý nghĩa đặc biệt cho một số \r\n\r\nđoạn văn bản hơn bằng cách tính IDF:  \r\n\r\n(, ) = log\r\n||\r\n\r\n1 + |{  :   }|\r\n \r\n\r\nTrong đó :  \r\n\r\n|| tổng số văn bản trong tập D \r\n\r\n |{  :   }| số văn bản chưa từ nhất định, với điều kiền t xuất hiện trong \r\n\r\nvăn bản d (tức là tf(t,d)  0). Nếu từ đó không xuất hiện ở bất kỳ một văn bản nào \r\n\r\ntrong tập thì mẫu số bằng 0 => phép chia không hợp lệ,  vì thế người ta thường thay \r\n\r\nbằng mẫu thức 1 + |{  :   }|. \r\n\r\nCơ số logarit trong công thức này không thay đổi giá trị của 1 từ mà chỉ thu hẹp \r\n\r\nkhoảng giá trị của từ đó. Vì thay đổi cơ số sẽ dẫn đến việc giá trị của các từ thay đổi \r\n\r\nbởi một số nhất định và tỷ lệ giữa các trọng lượng với nhau sẽ không thay đổi. (nói \r\n\r\ncách khác, thay đổi cơ số sẽ không ảnh hưởng đến tỷ lệ giữa các giá trị IDF). Tuy \r\n\r\nnhiên việc thay đổi khoảng giá trị sẽ giúp tỷ lệ giữa IDF và TF tương đồng để dùng \r\n\r\ncho công thức TF-IDF như bên dưới. \r\n\r\n \r\n\r\n TF-IDF \r\n\r\n(, , ) = (, )  (, ) \r\n\r\nNhững từ có giá trị TF-IDF cao là những từ xuất hiện nhiều trong văn bản này, \r\n\r\nvà xuất hiện ít trong các văn bản khác. Việc này giúp lọc ra những từ phổ biến và \r\n\r\ngiữ lại những từ có giá trị cao (từ khoá của văn bản đó). \r\n\r\n \r\n\r\nb. Xác định các frequent words unigram và bigram trong văn bản \r\n\r\nCác từ có tần số cao được xác định là 30% số từ xuất hiện trong văn bản có chỉ \r\n\r\nsố TF lớn nhất. \r\n\r\n \r\n\r\nRelevance Features \r\n\r\nCác tính năng liên quan được kết hợp để khai thác các mối quan hệ giữa các câu. \r\n\r\nNó được cho rằng: \r\n\r\n(1) các câu liên quan đến các câu quan trọng là quan trọng; \r\n\r\n(2) các câu liên quan đến nhiều câu khác là câu quan trọng. \r\n\r\nCâu đầu tiên trong một tài liệu hoặc một đoạn là quan trọng, và các câu khác \r\n\r\ntrong một tài liệu được so sánh với các câu hàng đầu. \r\n\r\nTrong đồ án của mình, em lựa chọn tính đặc trưng FirstRel_Doc : Độ liên quan \r\n\r\ncủa câu hiện tại với câu đầu văn bản, để đại diện cho đặc trưng mức độ liên quan.  \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n Tính độ đương đồng giữa hai câu :  \r\n\r\nSử dụng bộ thư viện mã nguồn mở Nltk-examples/src/semantic :  Sự tương tự \r\n\r\nvề câu dựa trên ngữ nghĩa và các thống kê Corpus[1] \r\n\r\n \r\n\r\n3.3.  Huấn luyện và kiểm thử  \r\n\r\nSVM[2] xác định một hàm phân tách tuyến tính: \r\n\r\n \r\n\r\nf(x) = w. x + b  \r\n\r\n \r\n\r\nTrong đó, w là vector trọng số, b là tham số điều chỉnh bias, x là vector đặc trưng. \r\n\r\nMặt siêu phẳng xác định được được dùng để phân tách các ví dụ đầu vào. Nên với \r\n\r\nví dụ đầu vào có vector đặc trưng xi sẽ được gán vào lớp dương nếu f(xi)  0 tức \r\n\r\nnhãn lớp (ti) là 1 hoặc được gán vào lớp âm, nhãn lớp là 1  nếu ngược lại . \r\n\r\n \r\n\r\n \r\nti = {\r\n\r\n1, w. xi + b < 0\r\n\r\n1, w. xi + b  0\r\n \r\n\r\n \r\n\r\n \r\n\r\nw. x + b = 0 là mặt siêu phẳng phân tách các ví dụ huấn luyện lớp dương và \r\n\r\ncác ví dụ huấn luyện lớp âm. Ví dụ hình 13 \r\n\r\n \r\n\r\n\r\nSVM[2] phân lớp tuyến tính đòi hỏi các ví dụ âm và dương có thể phân tách một \r\n\r\ncách tuyến tính, ranh giới quyết định là mặt siêu phẳng. Tuy nhiên trong nhiều bài \r\n\r\ntoán thực tế, thì các tâp dữ liệu có thể là phân lớp phi tuyến. Để xử lý với dữ liệu phân \r\n\r\ntách phi tuyến, phương pháp tương tự đối trường hợp phân tách tuyến tính. Ta chuyển \r\n\r\ncác ví dụ từ không gian ban đầu sang không gian đặc trưng mà ranh giới quyết định \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\ntuyến tính có thể phân tách các ví dụ âm và dương trong không gian sau chuyển đổi. \r\n\r\nVí dụ hình 14 \r\n\r\n \r\n\r\n\r\n. Tuy nhiên việc chuyển đổi này không được thực hiện rõ ràng mà thay vào đó \r\n\r\nhàm nhân (kernel function) được sử dụng để tính mà không cần biết hàm chuyển đổi. \r\n\r\nTrong đồ án này em sử dụng hàm nhân Gauussian RBF (Gausian radial basis \r\n\r\nfunction) với  (gamma) = 0.03125 \r\n\r\n(, ) = exp (||  ||2 \r\n\r\nEm sử dụng hàm nhân này bởi đánh giá thực nghiệm của em cho thấy hàm nhân \r\n\r\nnày có kết quả tốt nhất. Tập nhãn lớp 0 và 1 lần lượt tương ứng với câu không quan \r\n\r\ntrọng và câu quan trọng.  \r\n\r\n \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\nĐể có thể áp dụng SVM[2] em xác định tập đặc trưng phù hợp với bài toán TTVB \r\n\r\nvà phân tích tập huẩn luyện.Phân tích bộ dữ liệu em trình bài chi tiết trong phần 1 \r\n\r\nchương III. Do SVM[2] chỉ làm việc với đầu vào là số thực vậy nên những giá trị \r\n\r\ntrong vector đặc trưng em cần phải chuyển các đặc trưng không  phải dạng số thực \r\n\r\nvề dạng số thực. Cách để chuyển đổi em sẽ trình bày chi tiết trong phần 4 chương III \r\n\r\n  \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\nCHƯƠNG IV:CÀI ĐẶT VÀ ĐÁNH GIÁ KẾT QUẢ  \r\n\r\n1. Cài đặt \r\n\r\n1.1. Khối tiền xử lý văn bản \r\n\r\n1.1.1 Phân tích các văn bản trong tập huấn luyện \r\n\r\nCác văn bản được lưu trữ trong folder 2007_raw của chương trình có cấu trúc \r\n\r\nnhư hình dưới đây:  \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\nTrong đó \r\n\r\n- Thẻ <documet>: thẻ mở đầu văn bản, thuộc tính name trong thẻ này cho biết \r\ntên (ký hiệu của văn bản) \r\n\r\n- Thẻ <\/ducument>: thẻ kết thuc văn bản. \r\n- Thẻ <line>:thẻ bắt đầu dòng \r\n- Thẻ <\/line>: thẻ kết thuc dòng \r\n- Thẻ <annotation> nhận biết những câu được đánh dấu trong văn bản tóm tắt \r\n\r\ncủa chuyên gia, văn bản tóm tắt của các hệ thống thử nghiệm. \r\n\r\nCác thuộc tính trong thẻ này đa được trình bày chi tiết tại phần 1 của chương. \r\n\r\n \r\n\r\n1.1.2. Tiền xử lý \r\n\r\nTách câu và đánh dấu câu quan trọng:  \r\n\r\n- Chương trình thử nghiệm nhận biết các thẻ <line> và trích rút câu trong thẻ. \r\n\r\n- Nhận biết các câu quan trọng thông qua thẻ <annotation>, trong các thuộc \r\n\r\ntính mà thẻ <annotation> chỉ ra, thuộc tính scu-count cho biết câu đó có \r\n\r\nđược sử dụng trong bản tóm tắt của chuyên gia hay không. Do đó, những câu \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\ncó thẻ <annotation> và thuộc tính scu-count > 0 được đánh dấu là câu quan \r\n\r\ntrọng phục vụ huẩn luyện.  \r\n\r\n- Dữ liệu sau khi tách câu và đánh dấu câu quan trọng được lưu trong folder \r\n\r\n2007_parsed_data với định dạng như hình dưới đây:  \r\n\r\n \r\n\r\nLoại bỏ từ dừng (stop word) và dấu câu: \r\n\r\nDanh sách các từ dừng được lưu trong file stop_words của chương trình.  \r\n\r\nBao gồm 319 từ \r\n\r\n \r\n\r\n\r\nChương trình đọc danh sách các từ trong file này và loại bỏ chúng khỏi các văn \r\n\r\nbản trong folder 2007_parsed_data, đồng thời thay dấu câu như dầu chấm, dấu \r\n\r\nchấm than, dấu chấm hỏi, dấu phẩy thành khoảng trắng.  \r\n\r\nDữ liệu sau khi loại bỏ từ dừng và dấu câu được lưu trong folder \r\n\r\nnon_stopword_data. \r\n\r\n1.2. Mô hình hóa dữ liệu huấn luyện \r\n\r\n1.2.1. Tính đặc trưng \r\n\r\n11 đặc trưng được lựa chọn cho mô hình huấn luyện \r\n\r\n  \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n \r\n\r\nNo Tên đặc trưng No Tên đặc trưng \r\n\r\n1 Position 7 SigTerm_Uni \r\n\r\n2 Doc_First 8 SigTerm_Bi \r\n\r\n3 Length 9 FreqWord_Uni \r\n\r\n4 Quote 10 FreqWord_Bi \r\n\r\n5 Centroid_Uni 11 FirstRel_Doc \r\n\r\n6 Centroid_Bi   \r\n\r\n\r\nĐặc trưng 1: Position  \r\n\r\nCách tính đặc trưng Position: Giá trị nghịch đảo vị trí của câu đó trong văn bản \r\n\r\nchưa nó.  \r\n\r\nGọi đến hàm Feature_Position(sentence, filename) \r\n\r\nĐầu vào: câu và tên file chứa câu đó. \r\n\r\nĐặc trưng này  trả về giá trị: 1/vị trí của câu đó trong văn bản \r\n\r\n \r\n\r\nĐặc trưng 2: Doc_First \r\n\r\nGiá trị của đặc trưng này là 0 hoặc 1. Trả về 1 khi câu đó là câu đầu của văn bản. \r\n\r\nHàm def Feature_docfirst(sentence, docFirsts): \r\n\r\nĐầu vào: một câu trong văn bản, mảng các câu đầu trong văn bản. \r\n\r\nHàm trả về giá trị 0 hoặc 1, là 1 khi câu đó là câu đầu của văn bản.  \r\n\r\nCác hàm hỗ trợ cho tính năng này:  \r\n\r\n- def get_first_doc() \r\nĐọc file xml từ 2007_raw ra file text first_docc_line tất cả các dòng đầu tiên \r\n\r\ncủa văn bản, đầu văn bản  được đánh dấu bằng thẻ <document> \r\n\r\n- def get_docfirst_list(): \r\nTrả về 1 mảng các câu đầu đoạn, đọc từ file first_doc_line \r\n\r\n \r\n\r\nĐăch trưng 3: Length \r\n\r\nGiá trị của đặc trưng: Độ dài của câu. \r\n\r\nHàm Feature_Length(sentence): \r\n\r\nĐầu vào là 1 câu trong văn bản \r\n\r\nHàm trả về độ dài của câu \r\n \r\n\r\nĐặc trưng 4: Quote \r\n\r\nGiá trị của đặc trưng: Số lượng từ trích dẫn nằm trong câu. \r\n\r\nPhương pháp tính: Tìm và tính số lượng của tất cả các từ nằm trong các cặp dấu \r\n\r\nđóng mở ngoặc đơn (), nháy kép , đóng mở ngoặc vuông, dấu *. \r\n\r\nHàm Feature_quote(sentence): \r\n\r\nĐầu vào là 1 câu trong văn bản \r\n\r\nTrả về số từ trích dẫn trong câu đó \r\n \r\n\r\nĐặc trưng 5: Centroid_Uni \r\n\r\nTổng khối lượng của các từ trọng tâm Uni ( từ centroid uni) có trong câu: \r\n\r\nCác từ centroid được xác định bằng độ đo TF-IDF \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\nCác hàm hỗ trợ tính độ đo TF-IDF unigram: \r\n\r\n- def get_bloblist(folder): \r\nHàm trả về 1 mảng các chuỗi, trong đó mỗi chuỗi là 1 văn bản, đầu vào là \r\n\r\nnon-stopword-data hoặc bigram-data \r\n\r\n- def tf(word, blob): \r\nĐầu vào: Một từ trong văn bản và văn bản đó. \r\n\r\nTrả về giá trị tf của từ đó trong văn bản blob. \r\n\r\n- def n_containing(word, bloblist)trả về số lượng văn bản chứa word. bloblist \r\nlà 1 mảng các văn bản. \r\n\r\nĐầu vào: một từ và mảng các văn bản trong tập huấn luyện hoặc tập test. \r\n\r\nTrả về số lượng văn bản chứa từ đó. \r\n\r\n- def idf(word, bloblist): \r\nĐầu vào: Một từ và mảng các văn bản trong tập huấn luyện hoặc tập test. \r\n\r\nTrả về giá trị idf của từ đó trong văn bản blob. \r\n\r\n- def tfidf(word, blob, bloblist): \r\nĐầu vào: Một từ, văn bản chứa từ đó và mảng các văn bản trong tập huấn \r\n\r\nluyện hoặc tập test. \r\n\r\nTrả về giá trị TF-IDF của từ đó. \r\n\r\n- def tfidf_data(ngram): \r\nĐầu vào là lựa chọn unigram(1) hoặc bigram(2) \r\n\r\nHàm ghi lại kết quả chỉ số IF-IDF của 30% tổng số từ có có chỉ số cao nhất \r\n\r\n(các từ centroid words)  vào từng văn bản vào mỗi file riêng biệt trong folder \r\n\r\nTFIDF_UNI hoặc TFIDF_BI \r\n\r\n \r\n\r\n \r\n\r\n\r\nHàm def Centroid(sentence, word_list): \r\n\r\nSẽ đọc trong file lưu chỉ số TF-IDF của từ và tính toán tổng trọng lượng các từ \r\n\r\ncentroid trong câu. \r\n\r\n \r\n\r\nĐặc trưng 6: Centroid_Bi \r\n\r\nTổng khối lượng của các từ trọng tâm Bi ( từ centroid Bi) có trong câu: \r\n\r\nCác hàm hỗ trợ xuất file bigram: \r\n\r\n- def to_bigram(sentence): \r\nĐầ vào: một câu trong văn bản. \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\nTrả về 1 chuỗi thay thế sentence gồm các bigram. \r\n\r\n- def parse_to_bigram_data(): \r\nGhi lại các câu sau khi biến đổi sang bigram vào foder bigram-data \r\n\r\nCác từ centroid-bi được xác định bằng độ đo tf-idf \r\n\r\nCác hàm hỗ trợ tính TF-IDF bigram \r\n\r\n- def get_bloblist(folder): \r\nHàm trả về 1 mảng các chuỗi, trong đó mỗi chuỗi là 1 văn bản, đầu vào là \r\n\r\nnon-stopword-data hoặc bigram-data \r\n\r\n- def tf(word, blob): \r\nĐầu vào: Một từ trong văn bản và văn bản đó. \r\n\r\nTrả về giá trị tf của từ đó trong văn bản blob. \r\n\r\n- def n_containing(word, bloblist)trả về số lượng văn bản chứa word. bloblist \r\nlà 1 mảng các văn bản. \r\n\r\nĐầu vào: một từ và mảng các văn bản trong tập huấn luyện hoặc tập test. \r\n\r\nTrả về số lượng văn bản chứa từ đó. \r\n\r\n- def idf(word, bloblist): \r\nĐầu vào: Một từ và mảng các văn bản trong tập huấn luyện hoặc tập test. \r\n\r\nTrả về giá trị idf của từ đó trong văn bản blob. \r\n\r\n- def tfidf(word, blob, bloblist): \r\nĐầu vào: Một từ, văn bản chứa từ đó và mảng các văn bản trong tập huấn \r\n\r\nluyện hoặc tập test. \r\n\r\nTrả về giá trị TF-IDF của từ đó. \r\n\r\n- def tfidf_data(ngram): \r\nĐầu vào là lựa chọn unigram(1) hoặc bigram(2) \r\n\r\nHàm ghi lại kết quả chỉ số TF-IDF của 30% tổng số từ có có chỉ số cao nhất \r\n\r\n(các từ centroid words)  vào từng văn bản vào mỗi file riêng biệt trong folder \r\n\r\nTFIDF_UNI hoặc TFIDF_BI \r\n\r\n \r\n\r\n \r\n\r\n\r\n \r\n\r\n- Hàm def Centroid(sentence, word_list): \r\nSẽ đọc trong file lưu chỉ số TF-IDF của từ và tính toán tổng trọng lượng các từ \r\n\r\ncentroid trong câu. \r\n\r\n \r\n\r\nĐặc trưng 7: SigTerm_Uni \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\nDánh sách các từ SigTerm _Uni tự tổng hợp \r\n\r\n \r\n\r\nNo SigTerm _Uni No SigTerm _Uni \r\n\r\n1 abstract 5 conclusion \r\n\r\n2 brief 6 outline \r\n\r\n3 highlight 7 summarization \r\n\r\n4 conclude 8 summary \r\n\r\n\r\nHàm hỗ trợ:   \r\n\r\n- def get_signterm_data(filename): \r\nĐầu vào: đọc file sigterm_data \r\n\r\nTrả về 1 mảng các từ sigterm \r\n\r\n- def SigTerm(sentence, sigterms): \r\nĐầu vào: một câu trong văn bản và mảng các từ sigterm \r\n\r\nTrả về số lượng từ signterm trong câu  \r\n \r\n\r\nĐặc trưng 8: SigTerm_Bi \r\n\r\nDánh sách các từ SigTerm _Bi tự tổng hợp \r\n\r\n \r\n\r\nNo SigTerm _Bi \r\n\r\n1 main idea \r\n\r\n2 the best \r\n\r\n3 this article \r\n\r\n4 this document \r\n\r\n5 this paper \r\n\r\n\r\nHàm hỗ trợ:   \r\n\r\n- def get_signterm_data(filename): \r\nĐầu vào: đọc file sigterm_data \r\n\r\nTrả về 1 mảng các từ sigterm \r\n\r\n- def SigTerm(sentence, sigterms): \r\nĐầu vào: một câu trong văn bản và mảng các từ sigterm \r\n\r\nTrả về số lượng từ signterm trong câu  \r\n\r\n \r\n\r\nĐặc trưng 9: FreqWord_Uni \r\n\r\nCác FreqWord_Uni trong mỗi văn bản  được xác định là 30% các từ Unigram có \r\n\r\nchỉ số TF cao nhất trong mỗi văn bản \r\n\r\nCác hàm hỗ trợ tính chỉ số TF unigram \r\n\r\n- def tf(word, blob): \r\nĐầu vào: Một từ trong văn bản, và văn bản chứa từ đó. \r\n\r\nTrả về chỉ số TF của từ đó trong văn bản. \r\n\r\n- def tf_data(ngram): \r\nĐầu vào là lựa chọn unigram(1) hoặc bigram(2) \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\nHàm ghi lại kết quả chỉ số TF của 30% tổng số từ có có chỉ số cao nhất (các \r\n\r\ntừ frequent words)  vào từng văn bản vào mỗi file riêng biệt trong folder \r\n\r\nTF_UNI hoặc TF_BI \r\n\r\n \r\n\r\n\r\n- Hàm def FreqWord(sentence, word_list): \r\nSẽ đọc trong file lưu chỉ số TF của từ và tính toán tổng trọng lượng các từ \r\n\r\nfreq_word trong câu. \r\n  \r\n\r\nĐặc trưng 10: FreqWord_Bi \r\n\r\nCác FreqWord_Bi trong mỗi văn bản  được xác định là 30% các từ Bigram có chỉ \r\n\r\nsố TF cao nhất trong mỗi văn bản \r\n\r\nCác hàm hỗ trợ tính chỉ số TF bigram \r\n\r\n- def tf(word, blob): \r\nĐầu vào: Một từ trong văn bản, và văn bản chứa từ đó. \r\n\r\nTrả về chỉ số TF của từ đó trong văn bản. \r\n\r\n- def tf_data(ngram): \r\nĐầu vào là lựa chọn unigram(1) hoặc bigram(2) \r\n\r\nHàm ghi lại kết quả chỉ số TF của 30% tổng số từ có có chỉ số cao nhất (các \r\n\r\ntừ frequent words)  vào từng văn bản vào mỗi file riêng biệt trong folder \r\n\r\nTF_UNI hoặc TF_BI \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n- Hàm def FreqWord(sentence, word_list): \r\nSẽ đọc trong file lưu chỉ số TF của từ và tính toán tổng trọng lượng các từ \r\n\r\nfreq_word trong câu. \r\n\r\n \r\n\r\nĐặc trưng 11: FirstRel_Doc \r\n\r\nThư viện hỗ trợ \r\n\r\nSử dụng bộ thư viện mã nguồn mở Nltk-examples/src/semantic :  Sự tương tự về \r\n\r\ncâu dựa trên ngữ nghĩa và các thống kê Corpus[1] \r\n\r\nCác hàm hỗ trợ \r\n\r\n- def get_docfirst_list(): \r\nTrả về 1 mảng các câu đầu đoạn, đọc từ file first_doc_line \r\n\r\n- def is_first_doc(sentence, doc_first_list): \r\nĐầu vào: một câu trong văn bản và mảng các câu đầu văn bản \r\n\r\nKiểm tra 1 câu có phải câu đầu đoạn \r\n\r\n- def cal_similarity(): \r\nGhi vào folder similities mỗi câu và độ tương đồng của câu đó với câu tiêu đề \r\n\r\nkết quả được lưu trong folder similities  \r\n\r\n \r\n\r\n \r\n\r\nsimilities \r\n\r\n- Hàm def Feature_firstRelDoc(sentence, filename): \r\nĐầu vào: một câu trong văn bản và tên file văn bản tương ứng trong thư mục \r\n\r\nsimilarties \r\n\r\nTrả về giá trị độ tương đồng của câu đó với câu đầu đoạn. \r\n\r\n \r\n\r\n1.2.2. Xuất file huấn luyện \r\n\r\nNhư đa trình bày, em sử dụng SVM[2] để phân loại từ quan trọng và từ không \r\n\r\nquan trọng. Từ trong quan trong sẽ bị loại bỏ đi, từ quan trọng được đưa vào văn bản \r\n\r\ntóm tắt. Em sử dụng thư viện LIBSVM của Chih-Chung Chang and Chih-Jen Lin \r\n\r\n[4][2]. Trong thư viện này định dạng của ví dụ huấn luyện và ví dụ kiểm thử là: \r\n\r\n<label> <index1>:<value1> <index2>:<value2>. \r\n\r\n \r\n\r\nĐịnh dạng file phù hợp cho mô hình huấn luyện của SVM: \r\n\r\n \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n- Mỗi dòng chứa một đối tương và được kết thuc bằng ký tự xuống dòng '\\n' \r\n\r\n- Trong đó:   \r\n\r\n<label> là một số nguyên cho biết nhan lớp \r\n\r\n  Mỗi cặp <index>: <value> biểu thị cho một tính năng. Giá trị <index> là \r\n\r\nmột số nguyên bắt đầu từ 1 và <value> là một số thực. \r\n\r\nGiải pháp đề xuất đưa ra 11 đặc trưng của câu trong bộ dữ liệu. 11 đặc trưng \r\n\r\nnày sẽ tương ứng với 11 cặp <index>: <value> của mỗi câu. <label> có giá trị bằng \r\n\r\n0 hoặc 1, với 1 là câu được gán nhan quan trọng. \r\n\r\n \r\n\r\n1.3. Chuẩn hóa bộ dữ liệu \r\n\r\nSvm-scale là công cụ thể chuẩn hóa dữ liệu đầu vào về giá trị trong khoảng \r\n\r\n[0;1]. Công thức chuẩn hóa: \r\n\r\nvaluec =\r\nl + (u  l)  (value  f_minindex)\r\n\r\n(f_maxindex  f_minindex)\r\n \r\n\r\nTrong đó, valuec là giá trị sau chuẩn hóa của đặc trưng thứ index, value là giá trị \r\n\r\ntrước chuẩn hóa của đặc trưng thứ index, l, u lần lượt là giá trị nhỏ nhất và lớn nhất \r\n\r\ncó thể sau chuẩn hóa, f_maxindex, f_minindex lần lượt là giá trị lớn nhất và giá trị của \r\n\r\nnhất của đặc trưng ở vị trí thứ index trên toàn bộ tập dữ liệu. Các giá trị f_minindex \r\n\r\nvà f_maxindex sẽ được lưu vào tệp range để phục vụ cho thao tác chuẩn hóa sau \r\n\r\nnày.  \r\n\r\nNhư em đa trình bày trong phần 3.2 của đồ án  \r\n\r\nCặp <index>:<value> là một biểu diễn của một đặc trưng. Trong  đó <index> là \r\n\r\nmột giá trị số nguyên bắt đầu từ 1 và <value> là một số nguyên biểu diễn giá trị của \r\n\r\nđặc trưng đó. Ví dụ day các đặc trưng của một câu trong văn bản huấn luyện: \r\n\r\n \r\n\r\n1:1 2:0 3:106 4:7 5:0.03529 6:0.00196 7:0 8:0 9:0.03713 10:0.00131 11:0.513208063011 \r\n\r\n \r\n\r\nSau khi được chuẩn hóa trở thành: \r\n\r\n \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n1:-0.998261 2:-1 3:-0.448819 4:-0.942623 5:-0.823717 6:-0.962524 7:-1 9:-0.767195 10:-\r\n0.95958 11:0.0264161  \r\n\r\n \r\n\r\n1.4. Học từ bộ dữ liệu huấn luyện \r\n\r\nSvm-train được sử dụng để học các quy tắc, luật từ bộ dữ liệu huấn luyện. Đầu \r\n\r\nvào của svm-train là tập dữ liệu huấn luyện xây dựng đa được chuẩn hóa và đầu ra \r\n\r\nlà một mô hình. Mô hình này được lưu vào tệp train_file.model để gán nhãn lớp cho \r\n\r\ncác ví dụ sau này. \r\n\r\nTuy nhiên, nếu chỉ phân lớp câu thành 2 lớp đơn thuần là câu quan trọng và \r\n\r\nkhông quan trọng sẽ nảy sinh một vấn đề có những văn bản không có câu nào được \r\n\r\ndự đoán là quan trọng.  \r\n\r\nĐể giải quyết vấn đề này, SVM[2]hỗ trợ dự đoán xác suất  \r\n\r\nCấu trúc dòng lệnh train:  \r\n\r\n \r\n\r\nsvm-train [options] training_set_file [model_file] \r\n \r\n\r\nTrong đó với tùy chọn: \r\n\r\n -b probability_estimates: khi cài đặt tùy chọn này là 1 (mặc định là 0), model train \r\n\r\nhỗ trợ ước tính xác suất.  \r\n\r\n \r\n\r\n1.5. Gán nhãn dữ liệu và dự đoán xác suất \r\n\r\nSvm-predict sử dụng mô hình đa học được để gán nhãn lớp cho các câu trong \r\n\r\nvăn bản test. Em  tính các giá trị đặc trưng của từng câu trong các văn bản. Sau đó, \r\n\r\nem chuẩn hóa chung để làm đầu vào của svm-predict với tham số tùy chọn  -b \r\n\r\nprobability_estimates  bằng 1, các câu trong văn bản thử nghiệm đa được gán nhãn \r\n\r\nlớp và ước tính xác suất chính là đầu ra.  \r\n\r\nSau khi các câu trong tập văn bản thử nghiệm được gán nhãn và dự đoán xác suất \r\n\r\nxuất hiện trong các lớp, em sắp xếp chúng theo thứ tự giảm dần của xác suất nằm \r\n\r\ntrong lớp câu quan trọng, từ đó xuất ra văn bản tóm tắt với độ dài khoảng 250 chữ. \r\n\r\n \r\n\r\n2. Đánh giá kết quả \r\n\r\n2.1. Bộ dữ liệu mẫu \r\n\r\nBộ dữ liệu mẫu được sử dụng cho quá trình kiểm thử trong đồ án tốt nghiệp này \r\n\r\nlà các văn bản được tóm tắt thực hiện bởi chuyên gia từ các Viện Tiêu chuẩn và \r\n\r\nCông nghệ Quốc gia (NIST). \r\n\r\nMỗi chuyên gia sẽ có một văn bản tóm tắt thủ công khác nhau. Do đó để đảm \r\n\r\nbảo tính khách quan, mỗi một văn bản trong bộ dữ liệu test cần có 2 đến 4 văn bản \r\n\r\ntóm tắt thủ công tương ứng. \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\nBộ dữ liệu mẫu gồm các bài tóm tắt thủ công của 45 chủ đề.  \r\n\r\nMỗi chủ đề có 3 bản tóm tắt thủ công, mỗi bản tóm tắt có độ dài 250 từ. \r\n\r\n \r\n\r\n2.2. Phương pháp đánh giá \r\n\r\nĐánh giá kết quả tóm tắt văn bản là một việc làm khó khăn trong thời điểm hiện \r\n\r\ntại. Việc sử dụng ý kiến đánh giá của các chuyên giá ngôn ngữ được xem là cách \r\n\r\nđánh giá tốt nhất, tuy nhiên, cách làm này lại tốn rất nhiều chi phí. Bên cạnh các \r\n\r\nphương pháp  đánh giá thủ công do cách chuyên gia thực hiện, vấn đề đánh giá tự \r\n\r\nđộng kết quả tóm tắt cũng nhận được nhiều sự chú ý hiện nay. Ví dụ, Saggion \r\n\r\n(2002)[6] đưa ra ba phương pháp đánh giá tóm tắt văn bản dựa vào nội dung đo độ \r\n\r\ntương tự giữa văn bản tóm tắt bằng tay và văn bản tóm tắt tự động. các phương pháp \r\n\r\nđó là: độ tương tự cosine, sự trùng lặp đơn vị (unit overlap) và chuỗi con chung dài \r\n\r\nnhất. Tuy nhiên, chúng vẫn chưa tương quan với đánh giá của con người. Sau thành \r\n\r\ncông của ứng dụng đánh giá tự động trong đánh giá dịch máy như BLEU (Papineni \r\n\r\n 2001)[7], Lin và Hovy đa đưa ra một phương pháp tương tự BLEU như thống kê \r\n\r\ntrùng lặp n-gram có thể được áp dụng vào đánh giá tóm tắt  tự động. Đó chính là độ \r\n\r\nđo ROUGE-N (Recal-Oriented Understudy for Gisting Evaluation)[5]. Trong đồ án \r\n\r\nnày, em sử dụng độ đo ROUGE-N[5] để đánh giá kết quả của hệ thống tóm tắt văn \r\n\r\nbản tự động. ROUGE-N[5] là độ phủ n-gram giữa văn bản tóm tắt tự động và văn \r\n\r\nbản tóm tắt bằng tay tương ứng. ROUGE-N[5] được tính như sau: \r\n\r\n \r\n\r\n   =\r\n  (){}\r\n\r\n  (){}\r\n \r\n\r\n \r\n\r\nTrong đó: \r\n\r\n   là bộ n từ liên tiếp trong văn bản S. \r\n\r\n () là số trùng lặp  tối đa giữa văn bản tóm tắt \r\n\r\ntự động và văn bản tóm tắt bằng tay. \r\n\r\n \r\n\r\n2.3. Các kết quả kiểm thử \r\n\r\n \r\n\r\nTrong phần này, em thực hiện kiểm thử với 10 văn bản trong tập dữ liệu DUC2007 \r\n\r\n Để hiểu rõ hơn cho hệ thống của mình em xin đưa ra một ví dụ minh họa đầu \r\n\r\nvào, đầu ra của hệ thống tóm tắt đơn văn bản theo phương pháp SVM ước lượng xác \r\n\r\nsuất:  \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\nVăn bản đầu vào: \r\n\r\nVăn bản D0730 \r\n\r\nVăn bản có độ dài khoảng 10.000 từ.  \r\n\r\n \r\n\r\nVăn bản mẫu kiểm thử1: \r\n\r\nIn the words of President Clinton the line item veto \"is very important in \r\n\r\nhelping to preserve the integrity of federal spending\". \r\n\r\nThe line item veto has been sought by presidents since Grant and was \r\n\r\npopularized by Reagan. \r\n\r\nIt was part of Republican \"Contract with America\" led by Speaker Newt \r\n\r\nGingrich that enacted it. \r\n\r\nThe line item veto allows the president to veto particular items in spending bills \r\n\r\nand certain limited tax provisions passed by Congress. \r\n\r\nPreviously the president could only veto entire bills. \r\n\r\nBill Clinton is the only president to have had line item veto authority. \r\n\r\nHe has said that it should be used sparingly. \r\n\r\nHe used it 163 times, mostly to delete items from the military construction bill. \r\n\r\nThe line item veto was challenged by a group of most Democratic senators but \r\n\r\nwas dismissed by the Supreme Court. \r\n\r\nHowever, another challenge led by New York Mayor Giuliani and Idaho \r\n\r\nfarmers resulted in a federal judge declaring the line item veto unconstitutional. \r\n\r\nThe Justice Department appealed that decision to the Supreme Court. \r\n\r\nThe Supreme Court rejected the line item veto as a departure from the basic \r\n\r\nconstitutional requirement that presidents accept or reject bills in their entirety. \r\n\r\nThe Court found that the line item veto violates the \"presentment clause\" of \r\n\r\nArticle I that establishes the process by which a bill becomes law. \r\n\r\nThe Court vote was 6-3 with Justice Stevens writing for the majority. \r\n\r\n \r\n\r\nVăn bản mẫu kiểm thử2: \r\n\r\nThe line-item veto (LIV) has been sought by nearly every president this century \r\n\r\nas a tool to limit pork barrel spending which is traditionally reviled as the most \r\n\r\ncynically deployed and least utilitarian form of largess. \r\n\r\nThe 1998 budget included $300,000 for enhancing the flavor of peanuts, \r\n\r\n$150,000 for peanut competitiveness and $250,000 for pickle research. \r\n\r\nPresident Clinton said the LIV is an important tool for striking unnecessary \r\n\r\nspending, for preserving the integrity of federal spending and enlivening the \r\n\r\npublic debate over how to make the best use of public funds. \r\n\r\nThe Solicitor General contended that the LIV represents a presidential exercise \r\n\r\nof spending authority delegated by Congress. \r\n\r\n\r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n110 years ago, Lord Bryce said the LIV was \"desired by enlightened men and \r\n\r\nwould save the nation millions of dollars a year\". \r\n\r\nThe LIV is a prerogative given to 43","u":"http://202.191.57.85:8000/InternetData/Data/DATN/20132320_Tran_Thi_Dieu_Linh_1528176806088.txt","sentences":[[1,"Đặt vấn đề Trong những năm gần đây, chung ta được chứng kiến sự phát triển như vũ bao của World-Wide-Web"],[2,"Theo thống kê của WorldWideWebSize.com vào cuối tháng 4 nằm 2018 có khoảng 50 tỷ trang web đa được indexed bởi Google, khoảng 2500TB dữ liệu trên Web"],[3,"Trước sự phát triển đó thì vấn đề đặt ra là làm thế nào để con người có thể sử dụng một cách hiệu quả lượng thông tin khổng lồ trên Internet"],[4,"Việc tóm tắt thông tin giúp ta có thể quyết định xem tiếp tục tập trung vào phần nào, nhất là trong các văn bản phức tạp như bài báo khoa học hay toàn bộ nội dung một cuốn sách"],[5,"Ngoài ra nó còn có thể ứng dụng trong rất nhiều các lĩnh vực khác mà con người cần phải tóm tắt một lượng rất lớn các dữ liệu như tài chính, dữ liệu thuốc của bệnh nhân trong y học"],[6,"Bài toán tóm tắt văn bản là một trong những bài toán kinh điển trong lĩnh vực xử lý dữ liệu văn bản"],[7,"Xử lý dữ liệu văn bản bao gồm: Kiểm tra lỗi chính tả (spelling-checker) Kiểm tra lỗi văn phạm (grammar-checker) Từ điển đồng nghĩa (thesaurus) Phân tích văn bản (text analyzer) Phân loại văn bản (text classification) Tóm tắt văn bản (text summarization) Tổng hợp tiếng nói (speech synthesis) Nhận dạng giọng nói (speech recognization) Dịch tự động (automatic translation)"],[8,"Tóm tắt văn bản là công việc phân tích nội dung của văn bản và sau đó sinh ra một văn bản tóm tắt có kích thước nhỏ hơn văn bản ban đầu, loại bỏ đi những thông tin không quan trọng nhưng vẫn đảm bảo giữ được những nội dung cốt lõi của văn bản"],[9,"Do đó để công việc tóm tắt văn bản chính xác cần phải đáp ứng được các yêu cầu sau: Các văn bản khi phân tích thì phải hiểu được nội dung để xác định được các tiêu chuẩn trong văn bản"],[10,"Các văn bản tóm tắt cần được kiểm tra bằng một thang đo tiêu chuẩn"],[11,"Rõ ràng việc tóm tắt văn bản chính là công việc khai phá dữ liệu văn bản (text data mining)"],[12,"2"],[13,"Lịch sử phát triển của tóm tắt văn bản Tóm tắt văn bản bắt đầu từ những năm cuối thập kỉ 1950 với nghiên cứu của Luhn(1958) dựa trên tần số từ"],[14,"Ý tưởng cơ bản của phương pháp tần số từ dựa trên kiến thức cho rằng tần số của từng từ trong văn bản là một độ đo hữu dụng để đánh giá tầm quan trọng của chúng"],[15,"Tiếp theo đó là phương pháp tóm tắt dựa trên vị trí của các câu trong văn bản của Baxendale (1958) và những nghiên cứu của Edmundson(1969) về vị trí của các câu trong văn bản và các từ/cụm từ mang ý nghĩa tổng quát"],[16,"Theo đó, những câu bắt đầu và kết thúc của đoạn văn bài viết hay những câu chưa những từ như important (đặc biệt), result are (kết qủa là)"],[17,"là những câu có ý nghĩa quan trọng"],[18,"Đầu những năm 1970, tiếp tục có những nghiên cứu với hướng tiếp cận ngoài (sử dụng các cụm từ dấu hiệu) và được ứng dụng trong các phần mềm thương mại Những năm 1980, phát triển nhiều nghiên cứu với nhiều hướng khác nhau, đặc biệt là hướng tiếp cận mức thực thể dựa trên trí tuệ nhân tạo như sử dụng script (Lehnert 1981), các luật sản xuất mạng và logic (Fum 1985), mạng ngữ nghĩa (Reimer và Hahn 1988) cũng như các hướng tiếp cận kết hợp (Rau 1989) hay (Aretoulaki 1994)"],[19,"Willam B"],[20,"Cavnar (1994) : biểu diễn văn bản dựa trên n-gram thay cho cách biểu diễn truyền thống bằng từ khoá"],[21,"Chinatsu Anoe (1997) đa phát triển hệ DimSum để tóm tắt văn bản sử dụng xử lý ngôn ngữ tự nhiên và kĩ thuật thống kê dựa trên hệ thống tf-idf, sử dụng WordNet để xem xét ngữ nghĩa của từ và đề xuất một số kĩ thuật lượng giá"],[22,"Jaine Carbonell (1998) đa tóm tắt văn bản bằng cách xếp hạng các câu trội (câu chưa các ý chính của văn bản) và rút ra các câu trội"],[23,"Jade Goldstein (1999) : phân loại tóm tắt dựa trên độ đo liên quan, phương phpas sử dụng kết hợp giữa ngữ học, thống kê"],[24,"Một câu được đặc trưng bằng các đặc tính ngữ học và độ đo thống kê"],[25,"J.Larocca Neto (2000) đa tạo tóm tắt văn bản dựa trên các dãy từ trong câu được chọn theo hệ số tf, sau đó dùng kỹ thuật gom cụm (clustering) để tạo tóm tắt"],[26,"Yoshio (2001) đa tạo tóm tắt văn bản tiếng Nhật"],[27,"Có 2 phương pháp là rut câu dựa trên từ khoá và rút câu dựa trên kiến trúc ngữ nghĩa trong đó có xây dựng độ đo mối liên kiết giữa hai từ"],[28,"Hiện nay, một số nghiên cứu về xử lý ngôn ngữ tự nhiên cũng bước đầu được áp dụng trong tóm tắt văn bản"],[29,"Mặt khác, các nghiên cứu về tóm tắt đa văn bản, đa ngôn ngữ và tóm tắt đa phương tiện cũng bắt đầu phát triển"],[30,"3"],[31,"Phân loại các hệ thống tóm tắt văn bản 3.1"],[32,"Phân loại theo kết quả (output) Tóm tắt theo hướng trích rút (Extract): là một bản tóm tắt bao gồm các nội dung được rút trích từ văn bản gốc"],[33,"Nói cách khác, văn bản tóm tắt được tạo ra bằng cách bỏ đi các từ, cụm từ hoặc câu không quan trọng và giữ lại các từ, cụm từ hoặc câu quan trọng trong văn bản gốc"],[34,"Tóm tắt theo hướng tóm lược (Abstract): là một bản tóm tắt có chứa cả các nội dung, từ ngữ không được thể hiện trong văn bản gốc"],[35,"Hoặc có thể hiểu văn bản tóm tắt đa được biên tập lại bằng các từ ngữ, nội dung khác đi (có thể không nằm trong văn bản gốc) mà vẫn thể hiện được ý nghĩa quan trọng mà văn bản gốc thể hiện"],[36,"3.2"],[37,"Phân loại theo số lượng tài liệu : Tóm tắt đơn văn bản : Bài toán tóm tắt văn bản đơn cũng giống như các bài toán tóm tắt khác, là một quá trình tóm tắt tự động với đầu vào là một văn bản, đầu ra là một đoạn mô tả ngắn gọn nội dung chính của văn bản đầu vào đó"],[38,"Văn bản đơn có thể là một trang Web, một bài báo, hoặc một tài liệu với định dạng xác định (ví dụ : .doc, .txt)"],[39,"Tóm tắt văn bản đơn là bước đệm cho việc xử lý tóm tắt đa văn bản và các bài toán tóm tắt phức tạp hơn"],[40,"Chính vì thế những phương pháp tóm tắt văn bản ra đời đầu tiên đều là các phương pháp tóm tắt cho văn bản đơn"],[41,"Các phương pháp nhằm giải quyết bài toán tóm tắt văn bản đơn cũng tập trung vào hai loại tóm tắt là: tóm tắt theo trích xuất và tóm tắt theo tóm lược"],[42,"Tóm tắt đa văn bản : Tóm tắt đa văn bản có thể được coi như là một mở rộng của tóm tắt đơn văn bản"],[43,"Mục đích của tóm tắt đa văn bản: Là quá trình trích xuất nội dung từ một tập các văn bản có liên quan đến nhau, trong quá trình đó các thông tin dư thừa sẽ được loại bỏ và những thông tin quan trọng sẽ được biểu diễn dưới hình thức cô đọng, suc tích và giàu cảm suc đến người sử dụng hoặc chương trình cần dùng [MM99]"],[44,"Tóm tắt đa văn bản được xác định là một bài toán có độ phức tạp cao, ngoài những thách thức đa được biết đến đối với tóm tắt đơn văn bản như sự cô đọng của thông tin và mạch lạc về nội dung, tóm tắt đa văn bản còn có những thách thức như cần phải xác định những thông tin trùng lặp giữa các văn bản, xác định thông tin quan trọng trong nhiều văn bản hay việc sắp xếp các thông tin trong văn bản tóm tắt"],[45,"3.3"],[46,"Phân loại theo mục đích, chức năng tóm tắt (Function) Tóm tắt chỉ thị (Indicative): tóm tắt nhằm cung cấp một chức năng tham khảo để chọn tài liệu dựa vào nội dung quan trọng"],[47,"Ví dụ: Trong tóm tắt tin tức, tóm tắt đưa ra chi tiết chính của từng sự kiện"],[48,"Tóm tắt thông tin (Information): tóm tắt bao gồm tất cả các thông tin nổi bật có trong văn bản nguồn tại nhiều mức độ chi tiết khác nhau, tùy theo tỷ lệ nén được chỉ thị"],[49,"Tóm tắt đánh giá (Evaluation): tóm tắt nhằm mục đích đánh giá vấn đề chính của văn bản nguồn"],[50,"Tóm tắt dạng này tập chung lấy ra các quan điểm, ý kiến chủ quan của tác giả nói đến trong văn bản"],[51,"3.4"],[52,"Phân loại theo nội dung Tóm tắt chung (Generalized): tóm tắt nhằm mục đích đưa ra các nội dung quan trọng bao quát nhất từ văn bản gốc"],[53,"Tóm tắt hướng truy vấn (Query-based): tóm tắt nhằm mục đích đưa ra kết quả dựa vào câu truy vấn của người dùng"],[54,"Tóm tắt này thường được sử dụng trong quá trình tìm kiếm thông tin (information retreival)"],[55,"Đầu vào của tóm tắt dạng này không chỉ là văn bản gốc mà còn thêm vào truy vấn thể hiện thông tin mà người dùng quan tâm"],[56,"3.5"],[57,"Phân loại theo miền dữ liệu Tóm tắt trên một miền dữ liệu (Domain): tóm tắt nhắm vào một miền nội dung nào đó, như tin tức khủng bố, tin tức tài chính, tin khoa học công nghệ"],[58,"Tóm tắt trên một thể loại (Genre): tóm tắt nhắm vào một thể loại văn bản nào đó, như báo chí, email, web, bài báo"],[59,"Tóm tắt độc lập (Independent): tóm tắt thực hiện trên nhiều thể loại văn bản và nhiều miền dữ liệu khác nhau"],[60,"3.6"],[61,"Phân loại theo mức độ chi tiết Tóm tắt tổng quan (overview): tóm tắt miêu tả tổng quan tất cả các nội dung nổi bật trong văn bản nguồn"],[62,"Tóm tắt tập trung sự kiện (event): tóm tắt miêu tả một sự kiện cụ thể nào đó trong văn bản nguồn"],[63,"Sự kiện được quan tâm đến được coi như một đầu vào trong quá trình xử lý tóm tắt tự động"],[64,"Mục tiêu là chỉ đưa ra những nội dung có liên quan đến sự kiện đang được quan tâm mà thôi"],[65,"4"],[66,"Ứng dụng của bài toán tóm tắt văn bản Bài toán tóm tắt văn bản có thể ứng dụng vào rất nhiều hệ thống xử lý ngôn ngữ tự động khác nhau"],[67,"Có thể kể tới một vài ứng dụng tiêu biểu sau đây: Tóm tắt tin tức"],[68,"Tóm tắt kết quả tìm kiếm trong các máy tìm kiếm (search engine)"],[69,"Thu thập dữ liệu thông minh"],[70,"Tóm tắt các văn bản, bài báo khoa học"],[71,"Tóm tắt nội dung hội nghị, cuộc họp"],[72,"Ứng dụng trong hệ thống trả lời tự động"],[73,"5"],[74,"Lý do chọn đề tài Với xu thế phát triển bùng nổ của internet hiện nay kéo theo một lượng thông tin khổng lồ về tất cả các lĩnh vực trong xã hội sinh ra trong mỗi giờ mỗi phut"],[75,"Điều đó, một mặt tạo điều kiện cho con người có thể tiếp cận một cách nhanh chóng hơn với thông tin nhưng mặt khác lại làm cho con người chìm ngập trong biển thông tin khổng lồ khiến họ không thể xác định được thông tin nào là cần thiết, thông tin nào là vô ích"],[76,"Nhu cầu cần có một phương án giải quyết vấn đề đó được đặt ra cấp thiết đối với mỗi con người"],[77,"Bởi vậy, tóm tắt văn bản đa ra đời nhằm phục vụ nhu cầu đó của con người, giup cho con người có thể tiếp cận thông tin một cách nhanh chóng và chính xác nhất"],[78,"Tóm tắt văn bản (TTVB) đa xuất hiện từ rất lâu, nhưng thường được thực hiện một cách truyền thống do con người"],[79,"Những nghiên cứu về TTVB bắt đầu từ những năm 60 tại các phòng thí nghiệm nghiên cứu của Mỹ"],[80,"Từ đó có nhiều phương pháp đa được đề xuất, nhiều hệ thống đa được xây dựng"],[81,"Các phương pháp này thường dựa trên những kỹ thuật cơ bản được đề xuất bởi Luhn, Sdmundson và Salton là trích rút các câu quan trọng từ trong văn bản gốc và kết hợp lại thành văn bản tóm tắt"],[82,"Với sự phát triển của internet, chủ đề về TTVB đa thu hút sự quan tâm của nhiều nhà nghiên cứu trong lĩnh vực xử lý ngôn ngữ tự nhiên và tra cứu thông tin (WAS 2000, 2001, 2002), nhiều các chủ đề đặc biệt trong các phiên của các hội thảo ACL, COLING, SINGIR đa được tổ chức"],[83,"Hiện nay, tóm tắt văn bản là một lĩnh vực quan trọng trong xử lý văn bản thu hút nhiều nhà nghiên cứu quan tâm"],[84,"Ứng dụng của TTVB trong nhiều lĩnh vực khác nhau như sinh tiêu đề tự động (headline generation), rút gọn thông tin sử dụng trong các thiết bị cầm tay như PDA, điện thoại di động,.Trong TTVB có lĩnh vực nhỏ hơn được coi là mở đầu của TTVB, nó là tiền đề cho các hình thức tóm tắt phực tạp hiện nay, đó chính là tóm tắt đơn văn bản"],[85,"Hiện nay đa có nhiều phương pháp tóm tắt văn bản được đề xuất, tuy nhiên, mỗi phương pháp đều có điểm mạnh và điểm yếu riêng"],[86,"Trong phạm vi bài toàn tóm tắt đơn văn bản theo hướng trích rút các câu quan trọng, hay nói cách khác là phân loại câu quan trọng và không quan trọng trong văn bản để đưa các câu quan trọng vào văn bản tóm tắt, phương pháp học máy có giám sát SVM[2] là một công cụ tính toán hiệu quả trong không gian chiều cao, trong đó đặc biệt áp dụng cho các bài toán phân loại với số chiều có thể cực lớn"],[87,"Khả năng áp dụng Kernel mới cho phép linh động giữa các phương pháp tuyến tính và phi tuyến tính từ đó khiến cho hiệu suất phân loại lớn hơn"],[88,"Việc ứng dụng phương pháp SVM[2] rất phù hợp cho bài toán tóm tắt văn bản theo hướng trích rút"],[89,"Chính vì vậy, em chọn để tài nghiên cứu phương pháp tóm tắt đơn văn bản tự động sử dụng mô hình svm ước lượng xác suất làm đồ án tốt nghiệp của mình, nhằm mục đích muốn tìm hiểu về một phương pháp mới cho bài toán tóm tắt đơn văn bản, đồng thời cũng muốn so sánh hiệu quả của phương pháp xây dựng với các phương pháp đa có"],[90,"Để có thể mở ra một hướng đi mới hiệu quả hơn cho bài toán tóm tắt đơn văn bản nói riêng và bài toán tóm tắt văn bản nói chung"],[91,"CHƯƠNG II: TỔNG QUAN VỀ BÀI TOÁN TÓM TẮT VĂN BẢN 1"],[92,"Bài toán tóm tắt văn bản TTVB là quá trình thực hiện giảm đi độ dài, sự phức tạp của một văn bản trong khi vẫn giữ lại được các nội dung có giá trị của nó"],[93,"TTVB nhằm đưa ra thể hiện về nội dung một cách ngắn gọn của văn bản"],[94,"Có thể phát biểu bài toán TTVB trong phạm vi nghiên cứu của đồ án như sau: Đầu vào : Một văn bản có độ dài trên 5000 từ Đầu ra : Nội dung ngắn gọn khoảng 250 từ 2"],[95,"Các phương pháp giải quyết bài toán tóm tắt đơn văn bản Hiện nay, có rất nhiều phương pháp nhằm giải quyết bài toán tóm tắt đơn văn bản nhưng đa phần đều tập trung vào hai loại tóm tắt là: tóm tắt trích rút và tóm tắt tóm lược"],[96,"2.1"],[97,"Tóm tắt theo trích rút Đa số các phương pháp tóm tắt theo loại này đều tập trung vào việc trích rút ra các câu hay các ngữ nổi bật từ các đoạn văn bản và kết hợp chúng lại thành một văn bản tóm tắt"],[98,"Một số nghiên cứu giai đoạn đầu thường sử dụng các đặc trưng như vị trí của câu trong văn bản, tần suất xuất hiện của từ, ngữ hay sử dụng các cụm từ khóa để tính toán trọng số của mỗi câu, qua đó chọn ra các câu có trọng số cao nhất cho văn bản tóm tắt"],[99,"Các kỹ thuật tóm tắt gần đây sử dụng các phương pháp học máy và xử lý ngôn ngữ tự nhiên nhằm phân tích để tìm ra các thành phần quan trọng của văn bản"],[100,"Sử dụng các phương pháp học máy có thể kể đến các phương pháp của Kupiec, Penderson and Chan năm 1995 sử dụng phân lớp Bayes để kết hợp các đặc trưng lại với nhau hay nghiên cứu của Lin và Hovy năm 1997 áp dụng phương pháp học máy nhằm xác định vị trí của các câu quan trọng trong văn bản"],[101,"Bên cạnh đó việc áp dụng các phương pháp phân tích ngôn ngữ tự nhiên như sử dụng mạng từ Wordnet của Bazilay và Elhadad vào năm 1997 2.2"],[102,"Tóm tắt theo tóm lược Các phương pháp tóm tắt không sử dụng trích rut để tạo ra tóm tắt có thể xem như là một phương pháp tiếp cận tóm tắt theo tóm lược"],[103,"Các hướng tiếp cận có thể kể đến như dựa vào trích rút thông tin (information extraction), ontology, hợp nhất và nén thông tin,"],[104,"Một trong những phương pháp tóm tắt theo tóm lược cho kết quả tốt là các phương pháp dựa vào trích rut thông tin, phương pháp dạng này sử dụng các mẫu đa được định nghĩa trước về một sự kiện hay là cốt truyện và hệ thống sẽ tự động điền các thông tin trong mẫu có sẵn rồi sinh ra kết quả tóm tắt"],[105,"Tuy nhiên hiện nay các kỹ thuật sinh ra văn bản từ văn bản gốc còn hạn chế, mới chỉ dừng ở mức nghiên cứu, kết quả chưa được cao"],[106,"3"],[107,"Các hướng tiếp cận đối với tóm tắt đơn văn bản Mặc dù có 2 loại tóm tắt là tóm tắt trích rút và tóm tắt tóm lược, tuy nhiên để thực hiện tóm tắt tóm lược cần có một lượng tri thức đầy đủ về lĩnh vực cần tóm tắt"],[108,"Điều này hiện nay còn hạn chế nhiều, do đó các hướng tiếp cận đa số tập trung vào dạng tóm tắt trích rút câu"],[109,"Sau đây là một số hướng tiếp cận cho bài toán tóm tắt đơn văn bản: 3.1"],[110,"Phương pháp thống kê Hầu hết các nghiên cứu đầu tiên cho tóm tắt đơn văn bản đều tập trung trên những văn bản kỹ thuật ( các bài báo khoa học)"],[111,"Các phương pháp cổ điển thường tập trung vào các đặc trưng hình thái để tính điểm cho các câu và trích rút các câu quan trọng để đưa vào tóm tắt"],[112,"Ý tưởng của hướng tiếp cận này: Thu thập dữ liệu Tạo các bản tóm tắt thủ công Thiết kế các công thức toán hay logic để tính điểm cho các câu"],[113,"Lặp cho đến khi tóm tắt tự động đạt được tính tương đương với tóm tắt thủ công: o Tính điểm cho từng câu để tạo ra bản tóm tắt cho từng văn bản trong ngữ liệu dựa vào các đặc trưng về hình thái"],[114,"o So sánh tóm tắt được tạo tự động với tóm tắt được tạo thủ công"],[115,"o Cải thiện lại phương thức tính điểm cho câu"],[116,"Các nghiên cứu đại diện cho phương pháp này: Luhn(1958) o Sử dụng các đặc trưng như: word frequency, stop words, word distance"],[117,"o Dùng phương pháp so khớp từng kí tự để giải quyết stemming"],[118,"Baxendale(1958) o Sử dụng các đặc trưng như: sentence position"],[119,"o Thử nghiệm 200 đoạn câu, 85% các câu đầu là câu chính và 7% các câu cuối và câu chính"],[120,"o Phương pháp khá chính xác nhưng quá chủ quan và ngây ngô"],[121,"Phương pháp này được sử dụng khá nhiều vào các hệ thống học máy sau này"],[122,"Edmundson(1969) o Điển hình nhất trong phương pháp cổ điển"],[123,"o Sử dụng các đặc trưng như: word frequency, stop words, position, cue words, title"],[124,"o Sử dụng phương pháp kết nối tuyến tính để kết hợp các điểm đặc trưng lại với nhau: Si = w1*Ci + w2*Ki + w3*Ti + w4*Li o Thử nghiệm với 400 văn bản kỹ thuật và kết quả đạt 44%"],[125,"3.2"],[126,"Phương pháp máy học (machine learning) Năm 1990, với sự phát triển của nhiều kỹ thuật học máy trong xử lý ngôn ngữ, một số nhà nghiên cứu đa ứng dụng các kỹ thuật này vào trong TTVB tự động"],[127,"Một số nghiên cứu điển hình của phương pháp này là: Navie Bayes, Decision Tree, Hidden Makov Model, Log Linear, Neural Network, SVM"],[128,"Framework chung cho hệ thống tóm tắt văn bản bằng phương pháp máy học: 3.2.1"],[129,"Phương pháp Nave-Bayes Các hướng tiếp cận theo phương pháp này giả định rằng các đặc trưng của văn bản độc lập nhau"],[130,"Sử dụng bộ phân lớp Navie Bayes để xác định câu nào thuộc về tóm tắt và ngược lại: Cho s là các câu cần xác định"],[131,"F1...Fk là các đặc trưng đa được chọn và giả định các thuộc tính độc lập với nhau"],[132,"Xác suất của câu s thuộc về tóm tắt được tính như sau: Sau khi tính xác suất các câu, n câu có xác suất cao nhất sẽ được trích rút"],[133,"Các nghiên cứu đại diện cho phương pháp này: Kupiec(1995) o Các đặc trưng sử dụng: word frequency, location, cue word, title & leading, sentence length, uppercase words"],[134,"o Ngữ liệu: 188 cặp văn bản khoa học và tóm tắt"],[135,"Tổng số câu: 568 câu.Số câu khớp trực tiếp với tóm tắt 451 (79%)"],[136,"Aone(1999) o Kết hợp thêm nhiều đặc trưng phong phu hơn: tf.idf( single word, two- noun word, named-entities), discourse (cohension) (sử dụng Wordnet và kỹ thuật xử lý ngôn ngữ tự nhiên để phân tích sự tham chiếu đối với các thực thể)"],[137,"o Ngữ liệu: sử dụng ngữ liệu của TREC"],[138,"o Hệ thống: DimSum"],[139,"Phương pháp OPP (Optimal Position Policy) Lin và Hovy (1997) đa nghiên cứu tính quan trọng của đặc trưng vị trí câu(sentence position) và cho rằng các câu trong văn bản tuân theo một cấu trúc diễn ngôn ( diễn giải) có thể dự đoán được"],[140,"Và do cấu trúc trong các loại văn bản khác nhau, nên đặc trưng về vị trí câu không thể định nghĩa đơn giản như trong phương pháp Navie Bayes"],[141,"Lin và Hovy đa đề ra phương pháp Optimal Position Policy cho một thể loại văn bản ( văn bản tin tức của Zif-Davis về máy tính và phần cứng)"],[142,"Phương pháp thực hiện: Với mỗi văn bản, tính năng suất của mỗi vị trí câu với các từ khóa chủ đề"],[143,"Xếp hạng các vị trí câu với năng suất trung bình bằng thủ tục OPP"],[144,"Lấy ra n vị trí câu trong bảng xếp hạng làm tóm tắt"],[145,"3.2.2"],[146,"Phương pháp SVM Phương pháp SVM được coi là công cụ mạnh cho những bài toán phân lớp phi tuyến tính được các tác giả Vapnik và Chervonenkis phát triển mạnh mẽ năm 1995"],[147,"SVM là phương pháp học có giám sát được sử dụng rộng rai trong lĩnh vực phân lớp mẫu và nhận dạng mẫu"],[148,"SVM là một họ các phương pháp dựa trên cơ sở các hàm nhân (kernel methods) để tối thiểu hoá rủi ro ước lượng"],[149,"Phương pháp này được Boser, Guyon, và Vapnik giới thiệu lần đầu tiên vào năm 1995 để giải quyết vấn đề phân lớp mẫu hai lớp sử dụng nguyên tắc cực tiểu hóa rủi ro cấu trúc (Structural Risk Minimization)"],[150,"Phương pháp tiếp cận này dựa trên lý thuyết toán học thống kê nên có một nền tảng toán học chặt chẽ để đảm bảo rằng kết quả đạt được là tối ưu"],[151,"SVM là một trong những phương pháp máy học trong đó các khái niệm dựa trên dữ liệu đa thu thập được trước đó"],[152,"Phương pháp này cho phép tận dụng được nguồn dữ liệu rất nhiều và sẵn có"],[153,"Là thuật toán học giám sát (supervied learning) được sử dụng cho phân lớp dữ liệu"],[154,"Là 1 phương pháp thử nghiệm, đưa ra 1 trong những phương pháp mạnh và chính xác nhất trong số các thuật toán nổi tiếng về phân lớp dữ liệu SVM là một phương pháp có tính tổng quát cao nên có thể được áp dụng cho nhiều loại bài toán nhận dạng và phân loại Cơ sở lý thuyết: Support vector machine (SVM) xây dựng (learn) một siêu phẳng (hyperplane) để phân lớp (classify) tập dữ liệu thành 2 lớp hay nhiều lớp riêng biệt"],[155,"Một siêu phẳng là một hàm tương tự như phương trình đường thẳng, y = ax + b"],[156,"Trong thực tế, nếu ta cần phân lớp tập dữ liệu chỉ gồm 2 feature, siêu phẳng luc này chính là một đường thẳng"],[157,"Về ý tưởng thì SVM sử dụng thủ thuật để ánh xạ tập dữ liệu ban đầu vào không gian nhiều chiều hơn"],[158,"Khi đa ánh xạ sang không gian nhiều chiều, SVM sẽ xem xét và chọn ra siêu phẳng phù hợp nhất để phân lớp tập dữ liệu đó"],[159,"Bằng cách sử dụng một kernel, SVM ánh xạ tập dữ liệu ban đầu vào không gian nhiều chiều a"],[160,"Thuật ngữ margin trong SVM: Margin là khoảng cách giữa siêu phẳng đến 2 điểm dữ liệu gần nhất tương ứng với các phân lớp"],[161,"SVM cố gắng maximize margin này, từ đó thu được một siêu phẳng tạo khoảng cách xa nhất so với phần tử của 2 lớp"],[162,"Nhờ vậy, SVM có thể giảm thiểu việc phân lớp sai (misclassification) đối với điểm dữ liệu mới đưa vào"],[163,"b"],[164,"Bài toán tối ưu của SVM - Dữ liệu huấn luyện của SVM là tập các điểm dữ liệu - D = {(x1,y1), (x2,y2), ., (x1,y1)}, trong đó, xi là vector dữ liệu biểu diễn đối tượng cần phân lớp di (xiRn), yi {+1,-1}, cặp (xi, yi) được hiểu là vector xi được gán nhãn là yi"],[165,"- Một siêu phẳng phân chia dữ liệu được gọi là tốt nhất, nếu khoảng cách từ điểm dữ liệu gần nhất đến siêu phẳng là lớn nhất"],[166,"Phương trình tổng quát của một siêu phẳng phân chia như vậy được biểu diễn có dạng như sau: wTx + b = 0 (1) Trong đó: WT: Vector trọng số, WT = {w1, w2,.,wn}"],[167,"n: Số thuộc tính (hay còn gọi là số chiều của dữ liệu)"],[168,"b: Bộ trọng số"],[169,"Với T = 2 (dữ liệu hai chiều) siêu phẳng phân chia là đường thẳng"],[170,"Với T = 3 (dữ liệu ba chiều) siêu phẳng phân chia là mặt phẳng"],[171,"- Tổng quát cho dữ liệu n chiều thì sẽ được phân cách bởi một siêu phẳng"],[172,"- Siêu phẳng phân chia có vai trò quan trọng trong việc phân lớp, nó quyết định xem một bộ dữ liệu sẽ thuộc về lớp nào"],[173,"Ta xét trên ví dụ sau: - Với bộ dữ liệu huấn luyện hai chiều, ta có 2 thuộc tính A1 và A2: X={x1, x2}, với x1, x2 là giá trị của thuộc tính A1, A2 và W = {w1, w2}"],[174,"Phương trình siêu phẳng có thể viết lại như sau: : 0 + 11 + 22 = 0 Trong đó: w0 tương đương với hằng số b trong PT tổng quát của siêu phẳng"],[175,"Vì vậy mỗi điểm nằm trên siêu phẳng phân cách thỏa mãn: 1: 0 + 11 + 22 > 0 Tương tự, những điểm nằm dưới siêu phẳng phân cách phải thỏa mãn: 2: 0 + 11 + 22 < 0 Bằng cách điều chỉnh trọng số w0 ta có: 1: 0 + 11 + 22 1 ớ = +1 2: 0 + 11 + 22 1 ớ = 1 Trong đó: Đường màu đỏ là khoảng cách Euclidean của hai điểm 1 và 2"],[176,"Đường màu xanh là khoảng cách Euclidean nhỏ nhất"],[177,"- Điều này có nghĩa là nếu bất kì bộ nào nằm tại hoặc trên H1 đều thuộc về lớp +1, và bất kì bộ nào nằm tại hoặc dưới H2 đều thuộc về lớp -1"],[178,"Kết hợp 2 bất đẳng thức trên ta có: (0 + 11 + 22) 1, (5) - Mỗi bộ huấn luyện nằm tại các mặt biên H1 hay H2thỏa man phương trình trên được gọi là support vectors"],[179,"Support vectors là những bộ gần với siêu phẳng phân chia tuyến tính nhất"],[180,"- Tuy nhiên trong thực tế có thể tìm được vô số những siêu phẳng phân chia trên cùng một tập dữ liệu"],[181,"Do đó mục tiêu của phương pháp phân lớp SVM là tìm một siêu phẳng phân cách giữa hai lớp sao cho khoảng cách lề giữa hai lớp đạt cực đại, nghĩa là có sai sót phân loại bé nhất trên bộ dữ liệu"],[182,"- Siêu phẳng có biên độ lớn nhất sẽ được chọn như là siêu phẳng phân chia tập dữ liệu một cách tốt nhất"],[183,"Tức là, nếu có 2 siêu phẳng có thể phân chia được tất cả những bộ dữ liệu cho trước với biên độ của nó"],[184,"Siêu phẳng với biên độ lớn hơn sẽ chính xác hơn trong việc phân loại các bộ dữ liệu trong tương lai so với siêu phẳng có biên độ nhỏ hơn"],[185,"Điều này là lý do tại sao (trong suốt giai đoạn học hay huấn luyện), SVM tìm những siêu phẳng có biên độ lớn nhất, gọi là MMH (maximum marginal hyperlane).Siêu phẳng có biên độ lớn nhất là siêu phẳng có khoảng cách từ nó tới hai mặt bên của nó thì bằng nhau (mặt bên song song với siêu phẳng)"],[186,"Khoảng cách đó là khoảng cách ngắn nhất từ MMH tới bộ dữ liệu huấn luyện gần nhất của mỗi lớp"],[187,"Siêu phẳng có biên độ lớn nhất này cho chúng ta một sự phân loại tốt nhất giữa các lớp"],[188,"- Việc huấn luyện SVM với mục đích trên có thể được sử dụng để phân lớp dữ liệu mà dữ liệu đó có thể phân chia tuyến tính"],[189,"Chung ta xem SVM được huấn luyện là SVM tuyến tính"],[190,"- Ngoài ra hướng tiếp cận của SVM tuyến tính có thể được mở rộng để tạo ra SVM không tuyến tính cho việc phân lớp các dữ liệu không thể phân chia tuyến tính (hay gọi tắt là dữ liệu không tuyến tính)"],[191,"Những SVM như vậy có khả năng tìm những ranh giới quyết định không tuyến tính (những mặt không tuyến tính) trong không gian đầu vào"],[192,"Những SVM như vậy được gọi là SVM phi tuyến"],[193,"- Để tìm ra các support vectors và MMH, đồng nghĩa với việc tìm được bộ phân lớp trên bộ dữ liệu đa cho"],[194,"Có ba trường hợp có thể xảy ra đối với từng bộ dữ liệu, mỗi trường hợp sẽ đưa ra một bài toán tối ưu"],[195,"Việc cần làm là giải quyết bài toán tối ưu đó"],[196,"3.2.3"],[197,"Phương pháp Decision Tree Lin và Hovy (1999) đại diện của phương pháp này giả định rằng, các đặc trưng không độc lập nhau"],[198,"Tác giả đa kiểm tra nhiều đặc trưng và ảnh hưởng của chúng lên quá trình trích rút"],[199,"Hệ thống tóm tắt của Lin là loại tóm tắt hướng về truy vấn (Query - based)"],[200,"Các đặc trưng: position (OPP), numeric data, proper name, pronoun & adjective, weekday hoặc month"],[201,"Cùng với 2 đặc trưng mới: query signature ( số từ truy vấn có trong câu) và IR signature ( những từ nổi bật, quan trọng ~ tf*idf)"],[202,"Hệ thống Summarist của Lin và Hovy sử dụng thuật toán C4.5 để huấn luyện cây quyết định"],[203,"Hệ thống sử dụng tập ngữ liệu của TIPSTER-SUMMAC 3.2.4"],[204,"Phương pháp Hidden Makov Model Những hướng tiếp cận trước đều không dựa trên những đặc trưng và không tuần tự"],[205,"Conroy và Oleary (2001) đa đưa ra hướng tiếp cận dựa trên mô hình HMM với ý tưởng cơ bản là sử dụng một chuỗi tuần tự các câu"],[206,"Tác giả đưa ra khái niệm về sự phụ thuộc cục bộ (local dependencies) giữa các câu và sử dụng mô hình HMM để xác định sự phụ thuộc này"],[207,"Các đặc trưng sử dụng: position, number of term, likelihood of sentence"],[208,"Mô hình HMM bao gồm 2s + 1 trạng thái, trong đó s là số trạng thái tóm tắt (câu thuộc tóm tắt) và s + 1 là câu không thuộc tóm tắt"],[209,"Mô hình HMM xây dựng ma trận chuyển vị trí M, coi các đặc trưng là đa biến và tính xác suất của các câu qua từng trạng thái"],[210,"Sử dụng tập ngữ liệu của TREC và được đánh giá với 2 hệ thống khác là DimSum và QR, kết quả đều cho độ đo Precision cao hơn"],[211,"3.2.5"],[212,"Phương pháp Log-Linear Osborne (2002) đại diện cho mô hình này cũng coi các đặc trưng là không độc lập với nhau và sử dụng mô hình Log-Linear khắc phục giả định này"],[213,"Các đặc trưng sử dụng: word pair, sentence length, sentence position và discourse features (nằm trong introduction hay conclusion)"],[214,"Mô hình huấn luyện của Log-Linear được thực hiện như sau: Trong đó, c là nhan muốn gán cho câu s, fi là đặc trưng thứ i và i là trọng số kết nối các đặc trưng"],[215,"Nhan c có 2 khả năng: thuộc tóm tắt hoặc không thuộc tóm tắt"],[216,"Giai đoạn phân lớp câu mới được thực hiện như sau: Kết quả được đo bằng độ đo f2 = 2pr/(p+r)"],[217,"Tác giả đa đánh giá với hướng tiếp cận Bayes và kết quả luôn cho độ đo f2 cao hơn"],[218,"3.3"],[219,"Phương pháp phân tích ngôn ngữ tự nhiên Phương pháp tiếp theo sử dụng các kỹ thuật phân tích ngôn ngữ tự nhiên phức tạp"],[220,"Không phải tất cả các phương pháp phân tích ngôn ngữ tự nhiên đều sử dụng học máy, đôi khi phương pháp chỉ sử dụng một số các heuristic để tạo trích rút"],[221,"Hầu hết các phương pháp này đều dựa trên cấu trúc diễn ngôn (discourse structure) hay cấu trúc diễn đạt ( thể hiện) của văn bản, như: cấu trúc các section của văn bản, liên kết ngữ pháp ( trùng lặp, tỉnh lược, liên hợp), liên kết từ vựng ( đồng nghĩa, bao hàm, lặp lại), cấu trúc chính phụ"],[222,"Các nghiên cứu đại diện cho phương pháp này: Rhetorical Structure(Cấu trúc văn bản, ngữ pháp): Ono (1994) o Xây dựng một thủ tục để trích rút các cấu trúc chính phụ (rhetorical structure) từ các văn bản tiếng Nhật và xây dựng một cây nhị phân để thể hiện"],[223,"o Các bước để trích rút cấu trúc: phân tích câu, trích rút một quan hệ chính phụ, phân đoạn, tạo ứng viên và đánh giá độ ưu tiên"],[224,"o Sau khi xây dựng cây sẽ thực hiện tỉa nhánh để giảm bớt câu và tạo tóm tắt"],[225,"o Kết quả đạt được 51% các câu chính được xác định và 74% các câu quan trọng nhất được xác định"],[226,"Lexical Chain(Cấu trúc, ngữ nghĩa chuỗi từ vựng): Barzilay và Elhadad(1997) o Hai tác giả cũng đa sử dụng một lượng đáng kể những phân tích ngôn ngữ trong TTVB dựa trên chuỗi từ vựng (lexical chain)"],[227,"Chuỗi từ vựng là chuỗi các từ liên quan trong văn bản"],[228,"o Các bước thực hiện: phân tích đoạn văn bản, xác định các chuỗi từ vựng và sử dụng các từ vựng tốt nhất để xác định câu được chèn vào tóm tắt"],[229,"o Để tìm các chuỗi từ vựng tác giả sử dụng Wordnet"],[230,"Các từ có liên quan với nhau sẽ được đưa vào chuỗi"],[231,"Sự liên quan được tính bằng khoảng cách trong Wordnet"],[232,"Chuỗi sẽ được tính điểm dựa vào chiều dài và sự đồng nhất của nó"],[233,"o Kết quả đạt được tốt hơn hệ thống tóm tắt của Microssoft với độ Precision là 61 và recall 67 (Microsoft là 33 và 27)"],[234,"o Hạn chế: Không thể kiểm được chiều dài và mức độ chi tiết của tóm tắt do số chuỗi còn ít"],[235,"Tóm tắt thiếu sự kết dính và chưa chi tiết so chọn cả câu"],[236,"Rhetorical Structure(Cấu trúc ngữ nghĩa, đoạn văn): Marcu (1998) Sử dụng các heuristic dựa trên cấu trúc diễn đạt với các đặc trưng truyền thống"],[237,"Lý thuyết về cấu trúc diễn đạt được tác giả thể hiện thông qua lý thuyết cấu trúc chính phụ(Rhetorical Structure Theory)"],[238,"Lý thuyết cho rằng hai khoảng văn bản không trùng lặp có mối quan hệ trung tâm (nucleus) và vệ tinh (satellite)"],[239,"Trong đó, trung tâm quan trọng hơn vệ tinh và độc lập hoàn toàn trong cấu trúc chính phụ"],[240,"Cấu trúc trọng tâm và vệ tinh được biểu diễn thành cây nhị phân"],[241,"Để tính điểm cho các cấu trúc, tác giả sử dụng nhiều độ đo khác nhau như: clustering-based metric, marker-based metric, rhetorical clustering-based technique, shape-based metric, title-based metric, position-based metric, connectedness-based metric và sử dụng phương pháp kết hợp tuyến tính"],[242,"Lấy ra n câu chứa cấu trúc có điểm cao nhất"],[243,"Hệ thống đạt được hiệu quả độ đo F 75.42% cao hơn 3.5% so với baseline bằng phương pháp lấy n câu đầu"],[244,"Ngữ liệu được sử dụng là từ TREC 3.4"],[245,"Phương pháp học sâu (deep learning) Trong những năm qua, thuật ngữ \"deep learning\" (học sâu) đa dần len lỏi mỗi khi có cuộc hội thoại nào bàn về trí tuệ nhân tạo (AI), dữ liệu lớn (Big Data) và phân tích (Analytics)"],[246,"Và với lý do chính đáng đây là một cách tiếp cận đầy hứa hẹn tới AI khi phát triển các hệ thống tự trị, tự học, những thứ đang cách mạng hóa nhiều ngành công nghiệp"],[247,"Học sâu là cho một hệ thống máy tính \"ăn\" rất nhiều dữ liệu, để chúng có thể sử dụng và đưa ra các quyết định về những dữ liệu khác"],[248,"Dữ liệu này được nạp thông qua các mạng thần kinh, tương tự như học máy"],[249,"Những mạng lưới này các cấu trúc logic yêu cầu một loạt các câu hỏi đung/sai, hoặc trích xuất một giá trị số, của mỗi bit dữ liệu đi qua chung và phân loại theo các câu trả lời nhận được"],[250,"Vì công việc của học sâu là tập trung phát triển những mạng lưới này, chúng đa trở thành \"mạng thần kinh sâu\" (Deep Neural Network) những mạng logic phức tạp cần thiết để xử lý các bộ dữ liệu lớn, như thư viện hình ảnh của Google hay Instagram"],[251,"Mạng neural nhân tạo (Artificial neural network) Mạng Nơron nhân tạo (Artificial Neural Network- ANN) là mô hình xử lý thông tin được mô phỏng dựa trên hoạt động của hệ thống thần kinh của sinh vật, bao gồm số lượng lớn các Nơron được gắn kết để xử lý thông tin"],[252,"ANN giống như bộ não con người, được học bởi kinh nghiệm (thông qua huấn luyện), có khả năng lưu giữ những kinh nghiệm hiểu biết (tri thức) và sử dụng những tri thức đó trong việc dự đoán các dữ liệu chưa biết (unseen data)"],[253,"Kiến trúc chung của một mạng nơron nhân tạo (ANN) gồm 3 thành phần đó là: Input Layer, Hidden Layer và Output Layer (Xem Trong đó, lớp ẩn (Hidden Layer) gồm các Nơron nhận dữ liệu input từ các Nơron ở lớp (Layer) trước đó và chuyển đổi các input này cho các lớp xử lý tiếp theo"],[254,"Trong một ANN có thể có nhiều lớp ẩn"],[255,"Trong đó các Processing Elements (PE) của ANN gọi là Nơron, mỗi Nơron nhận các dữ liệu vào (Inputs) xử lý chúng và cho ra một kết quả (Output) duy nhất"],[256,"Kết quả xử lý của một Nơron có thể làm Input cho các Nơron khác"],[257,"Bên trên là tổng quan về kiến trúc mạng ANN cơ bản"],[258,"Để phục vụ những bài toán phức tạp ta cũng cần những kiến trúc mạng phức tạp hơn"],[259,"Một số kiến trức mạng phổ biến hiện nay như: Deep Neural Network (DNN) Deep Belief Network (DBN) Deep Boltzmann Machine (DBM) Recurrent Neural Network (RNN) Convolution Neural Network (CNN) Multi-modal/multi-tasking Deep Stacking Network (DSN) Trong các kiến trúc trên mô hình mạng neural hồi quy RNN là mô hình được áp dụng rất rộng rãi trong các bài toán xử lý ngôn ngữ tự nhiên (NLP)"],[260,"Do mô hình RNN mô hình hoá được bản chất dữ liệu trong NLP"],[261,"Dữ liệu trong NLP có đặc tính chuỗi và có sự phụ thuộc lẫn nhau giữa các thành phần (trạng thái) trong dữ liệu"],[262,"Hạn chế của hướng tiếp cận học sâu với bài toán đặt ra trong đề tài: Với hướng tiếp cận này, hiện nay chưa có kho dữ liệu phù hợp cho bài toán tóm tắt văn bản của đề tài"],[263,"Trên thế giới, các kết quả được nghiên cứu trên kho dữ liệu với các văn bản có độ dài khoảng 100 từ và đưa ra một headline cho văn bản đó"],[264,"4"],[265,"Đề xuất hướng giải quyết Với bài toán tóm tắt văn bản theo hướng trích rút các câu quan trọng để đưa vào văn bản tóm tắt"],[266,"Ý tưởng đưa ra : cần phân tích từng câu trong văn bản, và phân lớp chúng thành hai lớp câu quan trọng và câu không quan trọng"],[267,"Nhận thấy phương pháp học máy SVM là 1 trong những phương pháp mạnh và chính xác nhất trong số các thuật toán nổi tiếng về phân lớp dữ liệu hiện nay.,được coi là công cụ mạnh cho những bài toán phân lớp phi tuyến tính, SVM là phương pháp học có giám sát được sử dụng rộng rai trong lĩnh vực phân lớp mẫu và nhận dạng mẫu"],[268,"Phương pháp tiếp cận này dựa trên lý thuyết toán học thống kê nên có một nền tảng toán học chặt chẽ để đảm bảo rằng kết quả đạt được là tối ưu"],[269,"Phương pháp này cho phép tận dụng được nguồn dữ liệu rất nhiều và sẵn có"],[270,"Bên cạnh đó SVM[2] là một công cụ tính toán hiệu quả trong không gian chiều cao, trong đó đặc biệt áp dụng cho các bài toán phân loại với số chiều có thể cực lớn"],[271,"Khả năng áp dụng Kernel mới cho phép linh động giữa các phương pháp tuyến tính và phi tuyến tính từ đó khiến cho hiệu suất phân loại lớn hơn"],[272,"Việc ứng dụng phương pháp SVM[2] rất phù hợp cho bài toán tóm tắt văn bản theo hướng trích rút"],[273,"Do đó em giải quyết bài toán phân lớp câu quan trọng và không quan trọng bằng hướng tiếp cận sử dụng SVM"],[274,"Các câu trong các văn bản của bộ dữ liệu huấn luyện sẽ được xử lý, phân tích và mô hình hóa cho phù hợp với đầu vào của mô hình huấn luyện"],[275,"Từ đó cho SVM học các dữ liệu đa được phân lớp với các tùy chọn phù hợp để sinh ra model huấn luyện, phục vụ cho đánh dấu câu quan trọng trong các văn bản kiểm thử"],[276,"5"],[277,"Phương pháp đánh giá Recall-Oriented Understudy for Gisting Evaluation (ROUGE)[5] là một phương pháp do Lin và Hovy đưa ra vào năm 2003 cũng dựa trên các khái niệm tương tự"],[278,"Phương pháp này đa cho ra kết quả khả quan và được sự đánh giá cao của cộng đồng nghiên cứu tóm tắt văn bản"],[279,"Có 5 đánh giá ROUGE được đưa ra 5.1"],[280,"ROUGE- N (N-gram Co-Occurrence Statistics) ROUGE-N là một thu hồi n-gram giữa một bản tóm tắt tự động và một tập hợp các tài liệu tóm tắt tham khảo summaries"],[281,"ROUGE-N được tính như sau [21]: Trong đó: n là chiều dài của n-gram, Countmatch(gramn) là số lượng tối đa n-gam có thể sảy ra đồng thời trong bản tóm tắt tự động và bản tóm tắt tham khảo"],[282,"Rõ ràng là ROUGE-N là một biện pháp liên quan đến thu hồi vì mẫu số của phương trình là tổng của số n-gram xảy ra ở phía tài liệu tóm tắt tham khảo"],[283,"5.2"],[284,"ROUGE L (Longest Common Subsequence)"],[285,"ROUGE-L tính tỷ lệ giữa chiều dài của chung dài nhất 'tóm tắt dãy (LCS) và chiều dài của bản tóm tắt tài liệu tham khảo như mô tả bởi phương trình: Trong đó: m là độ dài của bản tóm tắt tài liệu tham khảo câu X và n là chiều dài của ứng cử viên câu Y"],[286,"LCS(X,Y) là độ dài LCS của x và Y"],[287,"R là sự thu hồi của X và Y, P là độ chính xác giữa X và Y"],[288,"Tham số được chọn trong DUC là 8"],[289,"5.3"],[290,"ROUGE-W (Weighted Longest Common Subsequence) ROUGE-W: Trọng số của chuỗi chiều dài lớn nhất, là mở rộng của ROUGE-L: Trong đó: m là độ dài của bản tóm tắt tài liệu tham khảo câu X và n là chiều dài của ứng cử viên câu Y"],[291,"LCS(X,Y) là độ dài LCS của x và Y"],[292,"R là sự thu hồi của X và Y, P là độ chính xác giữa X và Y"],[293,"Tham số được chọn trong DUC là 8"],[294,"5.4"],[295,"ROUGE S (Skip-Bigram Co-Occurrence Statistics)"],[296,"Sử dụng sự chồng chéo của skip-bigram giữa bản tóm tắt ứng cử viên và bản tóm tắt tham khảo: Trong đó: SKIP2(X,Y) là số lượng bigram giữa X và Y"],[297,"R là thu hồi giữa X và Y, còn P là độ chính xác giữa X và Y"],[298,"5.5"],[299,"ROUGE SU (Extension of ROUGE-S)"],[300,"Một vấn đề tiềm năng cho ROUGE-S là nó không cung cấp cho bất kỳ giá trị cho một câu ứng cử viên nếu câu không có bất kỳ cặp từ xảy ra đồng thời với câu tham chiếu"],[301,"Để đạt được điều này, mở rộng ROUGE-S với việc bổ sung unigram là đơn vị đếm"],[302,"Các phiên bản mở rộng được gọi là ROUGE-SU"],[303,"Cũng có thể có được ROUGE-SU từ ROUGE-S bằng cách thêm một dấu hiệu bắt đầu của câu vào lúc bắt đầu của ứng cử viên và câu tham khảo"],[304,"Trong 5 đánh giá ROUGE được đưa ra đối với bài toán tóm tắt văn bản thường sử dụng đánh giá ROUGE-N : tương đương với độ đo Recall"],[305,"Trong đồ án, em đánh giá kết quả văn bản tóm tắt bằng đánh giá ROUGE-1 unigram và ROUGE-2 bigram CHƯƠNG III: MÔ HÌNH ĐỀ XUẤT 1"],[306,"Tổng quan về mô hình đề xuất Với bài toán tóm tắt văn bản tự động tiếng Anh theo hướng trích rút, sử dụng mô hình SVM , em đề xuất mô hình sau để thử nghiệm cho phương pháp này : Các pha xử lý trong mô hình đề xuất : Tách câu và tiền xử lý Tính toán các đặc trưng và mô hình hóa dữ liệu Huấn luyện và kiểm thử Đánh giá kết quả 2"],[307,"Bộ dữ liệu huấn luyện 2.1"],[308,"Tổng quan Trong quá trình nghiên cứu đồ án, em đa tìm hiểu một số tập dữ liệu huấn luyện, trong đó có 2 bộ dữ liệu phù hợp cho bài toán tóm tắt trích rút của mình: - Bộ dữ liệu Bác Mới: Bộ dữ liệu huán luyện với kích thước lớn 3.6GB, bao gồm 1.002.394 bài báo"],[309,"Độ dài mỗi bài báo từ 300 đến 1500 từ"],[310,"- Bộ dữ liệu DUC 2007: Một tập các bài báo về 45 chủ đề khác nhau, trong đó có 23 chủ đề đa được tổng hợp và đánh dấu các câu trọng tâm, kèm theo đó là các bản tóm tắt thủ công của chuyên gia"],[311,"Bộ dữ liệu Báo Mới là tập dữ liệu phong phú về chủ đề, với những bài báo và thông tin chân thực, thực tế, có tính linh hoạt và ứng dụng lớn"],[312,"Bên cạnh đó các chương trình tóm tắt văn bản Tiếng Việt còn khá ít, đạt kết cả chưa cao"],[313,"Việc nghiên cứu thử nghiệm trên bộ dữ liệu Tiếng Việt mang lại nhiều ý nghĩa và ứng dụng trong thực tiễn so với bộ dữ liệu tiếng Anh"],[314,"Tuy nhiên các bài báo trong bộ dữ liệu tiếng Việt có độ chênh lệch về độ dài khá lớn, nhiều bài báo có độ dài nhỏ hơn 400 từ, nhiều bài báo có nội dung rời rạc, do đó cần thiết phải lọc và loại bỏ các bài báo không phù hợp với bài toán"],[315,"Công đoạn này mất nhiều thời gian"],[316,"Bên cạnh đó, mỗi bài báo chỉ bao gồm 1 câu tiêu đề, có hoặc không có từ 1 đến 2 câu tóm tắt nội dung của bài báo (câu Description), do đó đặt ra vấn đề phải đánh dấu các câu quan trọng trong văn bản dựa vào các câu Description đó, dẫn đến giảm độ chính xác của mô hình huấn luyện so với bộ DUC2007 có đánh dấu"],[317,"Bộ dữ liệu Báo Mới không có bản tóm tắt thủ công để đánh giá kết quả"],[318,"Do đó, trong phạm vi bài toán đưa ra của đồ án, em chọn bộ dữ liệu DUC2007 để huấn luyện và kiểm thử mô hình"],[319,"2.2"],[320,"Cấu trúc bộ dữ liệu DUC2007 DUC2007 bao gồm 2 tập dữ liệu: Main task: Tập dữ liệu trong main task được chia thành các thư mục theo chủ đề"],[321,"Mỗi chủ đề bao gồm 25 văn bản liên quan"],[322,"Mỗi chủ đề và cụm tài liệu được gửi cho 4 đơn vị đánh giá NIST khác nhau, bao gồm cả nhà phát triển chủ đề đó"],[323,"Các chuyên gia sẽ tạo ra văn bản tóm tắt khoảng 250 từ của cụm tài liệu, đáp ứng được nhu cầu thông tin được thể hiện trong chủ đề"],[324,"Và những văn bản tóm tắt của chuyên gia được dùng trong việc đánh giá nội dung, kết quả của các bài tóm tắt của các hệ thống tự động"],[325,"==> bộ dữ liệu phù hợp trong phạm vi nghiên cứu của đồ án"],[326,"Main task bao gồm 3 tệp dữ liệu: - Kết quả đánh giá từ chuyên gia - Tập hợp các kết quả của các hệ thống tóm tắt tự động đa tham gia - Tập các văn bản được đánh dấu kết quả của chuyện gia và các hệ thống tóm tắt"],[327,"Em sử dụng tập (2007 SCU-marked corpus) để huấn luyện trong đồ án của mình"],[328,"Update task (pilot): Mục đích của bộ dữ liệu là tạo ra những văn bản tóm tắt ngắn khoảng 100 từ theo giả định rằng người đọc đa đọc một số tài liệu trước đó"],[329,"Đối với mỗi chủ đề, các tài liệu sẽ được sắp xếp theo trình tự thời gian và sau đó được chia thành 3 bộ, A,B,C"],[330,"Trong đó các dấu thời gian trên tất cả các tài liệu trong mỗi bộ được sắp xếp theo thời gian (A) <thời gian (B) <thời gian (C)"],[331,"Sẽ có khoảng 10 tài liệu trong Bộ A, 8 trong Bộ B và 7 trong Bộ C"],[332,"==> Trong phạm vi nghiên cứu của đồ án, bộ dữ liệu Update task (pilot) không phù hợp"],[333,"a"],[334,"2007 SCU-marked corpus: - Kho dữ liệu bao gồm một file XML (.scu) cho mỗi chủ đề, trong đó các câu được xác định bởi trình ranh giới câu cục bộ"],[335,"- Các câu trong file XML trong mỗi chủ đề được lưu đưới dạng phần tử trong thẻ <line>"],[336,"- Các câu quan trọng được đánh dấu bằng thẻ <annotation> gồm 3 giá trị thuộc tính và một hoặc nhiều thẻ <scu> , các trường xuất hiệu trong cấu truc được chú thích như sau: Trong đó: scu-count: số lượng SCU được nhận bởi câu đó"],[337,"Định dạng: số nguyên Có giá trị bằng với số phần tử SCU sum-count: số lượng các văn bản tóm tắt đa sử dụng câu đó"],[338,"Định dạng: số nguyên sums: số thứ tự nhận dạng người tham gia ẩn danh, phân cách dấu phẩy"],[339,"Số lượng số nhận dạng người tham gia ẩn danh này bằng giá trị sum- count uid: ma định danh SCU Định dạng: số nguyên label: nội dung của SCU Định dạng: chuỗi weight: số lượng bản tóm tắt bằng tay, trong đó có thể hiện các SCU Định dạng: số nguyên"],[340,"2.3"],[341,"Ưu, nhược điểm của bộ dữ liệu Ưu điểm của bộ dữ liệu: - Bộ dữ liệu có cấu truc rõ ràng, mạch lạc, dễ phân tích"],[342,"- Bộ dữ liệu bao gồm các bảng tóm tắt chuẩn của chuyên gia, phù hợp cho đánh giá kết quả thử nghiệm"],[343,"- SCU-marked corpus là bộ dữ liệu tổng hợp, được gán nhán câu quan trọng và câu không quan trọng, phù hợp cho mô hình huấn luyện phân lớp của SVM"],[344,"Nhược điểm: - Kích thước bộ dữ liệu còn khá nhỏ: - Số lượng phần tử sau khi đa phân tích: 12.832 phần tử (tương đương với 12.832 câu trong các văn bản huấn luyện) trong đó 2/3 số phần tử được dùng cho huấn luyện"],[345,"1/3 số phần tử được dùng cho kiểm tra kết quả"],[346,"3"],[347,"Các pha xử lý trong mô hình đề xuất 3.1"],[348,"Tách câu và tiền xử lý - Tách câu : Tách văn bản thành các đoạn, các câu"],[349,"- Đánh dấu câu quan trọng : Dựa vào thông số thống kê của tập dữ liệu huấn luyện đánh dấu câu quan trọng"],[350,"- Lower case : Các từ trong văn bản của bộ dữ liệu được chuyển đồi về chữ thường"],[351,"- Loại bỏ dấu câu : Các dấu câu như dấu chấm, dấu phẩy, dấu chấm than, dấu chấm hỏi, dấu ba chấm được thay bằng khoảng trắng"],[352,"- Loại bỏ stopword : Sử dụng từ điển từ dừng"],[353,"Loại bỏ các từ dừng khỏi văn bản"],[354,"3.2"],[355,"Tính toán các đặc trưng và mô hình hóa dữ liệu Tham khảo bài báo của Kam-Fai Wong, Mingli Wu[1] về tóm tắt văn bản, bài báo đưa ra mô hình chung của tóm tắt văn bản trích rút dựa trên học máy như sau : Trong đó có chỉ rõ ra 4 đặc trưng của câu : - Surface Feature : đặc trưng bề mặt - Content Featute : Đặc trưng về nội dung - Event Feature : Đặc trưng sự kiện - Relevance Feature : Đặc trưng về mức độ liên quan"],[356,"Một số nhà nghiên cứu đa thử nghiệm nhiều phương pháp tóm tắt văn bản trích rút dựa trên học máy, và đưa ra đánh giá"],[357,"Kết quả đánh giá cho thấy đặc trưng sự kiện (Event Feature) không liên quan, không có tác dụng trong tóm tắt văn bản trích rút"],[358,"Các đặc trưng bài báo đưa ra : STT Tên các đặc trưng 1 Surface Feature Position 2 Doc_First 3 Para_First 4 Length 5 Quote 6 Content Feature Centroid_Uni 7 Centroid_Bi 8 SigTerm_Uni 9 SigTerm_Bi 10 FreqWord_Uni 11 FreqWord_Bi 12 Relevance Feature FirstRel_Doc 13 FirstRel_Para Sau quá trình tìm kiếm và phân tích các bộ dữ liệu phù hợp cho mô hình, em sử dụng bộ dữ liệu DUC2007 để huấn luyện và thử nghiệm"],[359,"Bộ dữ liệu huấn luyện của DUC2007, các văn bản không được phân chia thành các đoạn văn, do đó em không xét 2 đặc trưng Para_First : câu đang xét có phải câu đầu đoạn hay không"],[360,"Và FirstRel_Para : độ liên quan của câu đang xét với câu đầu đoạn chứa câu đó"],[361,"Sau đây em xin trình bày chi tiết về 11 đặc trưng em sẽ sử dụng cho mô hình của mình bao gồm : Position, Doc_First, Length, Quote, Centroid_Uni, Centroid_Bi, SigTerm_Uni, SigTerm_Bi, FreqWord_Uni, FreqWord_Bi, FirstRel_Doc"],[362,"Surface features : Các đặc trưng bề mặt dựa trên cấu trúc của tài liệu hoặc câu, bao gồm vị trí câu trong tài liệu, số từ trong câu, và số từ được trích dẫn trong câu"],[363,"Tên Nội dung Position Đặc trưng về vị trí, được tính bằng thương số : 1/vị trí của câu đó trong văn bản Doc_First Cho biết câu đó có phải câu đầu tiên của văn bản hay không Length Số lượng từ trong câu Quote Số lượng từ được trích dẫn trong câu Content Features : Đặc trưng về nội dung"],[364,"Các đặc trưng được tính dựa trên các từ mang nội dung chủ chốt : từ trung tâm (centroid words), các thuật ngữ chữ ký (signature words) và các từ có tần số cao trong văn bản (frequent words) với cả hai đại diện Unigram và Bigram"],[365,"Tên Nội dung Centroid_Uni Tổng khối lượng của các từ centroid unigram trong câu"],[366,"Centroid_Bi Tổng khối lượng của các từ centroid bigram trong câu"],[367,"SigTerm_Uni Số từ thuật ngữ unigram trong câu"],[368,"SigTerm_Bi Số từ thuật ngữ bigram trong câu"],[369,"FreqWord_Uni Tổng khối lượng các từ unigram có tần số cao trong câu"],[370,"FreqWord_Bi Tổng khối lượng các từ bigram có tần số cao trong câu"],[371,"a"],[372,"Xác định các từ centroid unigram và centroid bigram"],[373,"Các từ trung tâm được xác định là 30% số từ xuất hiện trong văn bản có chỉ số TF-IDF lớn nhất"],[374,"Cách tính TF-IDF : TF (Term Frequency): Là tần suất xuất hiện của một từ trong một đoạn văn bản"],[375,"Với những đoạn văn bản có độ dài khác nhau, sẽ có những từ xuất hiện nhiều ở những đoạn văn bản dài thay vì những đoạn văn bản ngắn"],[376,"Vì thế, tần suất này thường được chia cho độ dài của đoạn văn bản như một phương thức chuẩn hóa (normalization)"],[377,"TF được tính bởi công thức: () = (, ) Với t là một từ trong văn bản"],[378,"f(t,d) là tần số xuất hiện của d trong đoạn văn bản d"],[379,"T là tổng số từ trong văn bản đó"],[380,"IDF (Inverse Document Frequency): Tính toán độ quan trọng của một từ"],[381,"Khi tính toán TF, mỗi từ đều quan trọng như nhau, nhưng có một số từ trong tiếng Anh như \"is\", \"of\", \"that\",.."],[382,"xuất hiện khá nhiều nhưng lại rất ít quan trọng"],[383,"Vì vậy, chúng ta cần một phương thức bù trừ những từ xuất hiện nhiều lần và tăng độ quan trọng của những từ ít xuất hiện những có ý nghĩa đặc biệt cho một số đoạn văn bản hơn bằng cách tính IDF: (, ) = log || 1 + |{ : }| Trong đó : || tổng số văn bản trong tập D |{ : }| số văn bản chưa từ nhất định, với điều kiền t xuất hiện trong văn bản d (tức là tf(t,d) 0)"],[384,"Nếu từ đó không xuất hiện ở bất kỳ một văn bản nào trong tập thì mẫu số bằng 0 => phép chia không hợp lệ, vì thế người ta thường thay bằng mẫu thức 1 + |{ : }|"],[385,"Cơ số logarit trong công thức này không thay đổi giá trị của 1 từ mà chỉ thu hẹp khoảng giá trị của từ đó"],[386,"Vì thay đổi cơ số sẽ dẫn đến việc giá trị của các từ thay đổi bởi một số nhất định và tỷ lệ giữa các trọng lượng với nhau sẽ không thay đổi"],[387,"(nói cách khác, thay đổi cơ số sẽ không ảnh hưởng đến tỷ lệ giữa các giá trị IDF)"],[388,"Tuy nhiên việc thay đổi khoảng giá trị sẽ giúp tỷ lệ giữa IDF và TF tương đồng để dùng cho công thức TF-IDF như bên dưới"],[389,"TF-IDF (, , ) = (, ) (, ) Những từ có giá trị TF-IDF cao là những từ xuất hiện nhiều trong văn bản này, và xuất hiện ít trong các văn bản khác"],[390,"Việc này giúp lọc ra những từ phổ biến và giữ lại những từ có giá trị cao (từ khoá của văn bản đó)"],[391,"b"],[392,"Xác định các frequent words unigram và bigram trong văn bản Các từ có tần số cao được xác định là 30% số từ xuất hiện trong văn bản có chỉ số TF lớn nhất"],[393,"Relevance Features Các tính năng liên quan được kết hợp để khai thác các mối quan hệ giữa các câu"],[394,"Nó được cho rằng: (1) các câu liên quan đến các câu quan trọng là quan trọng; (2) các câu liên quan đến nhiều câu khác là câu quan trọng"],[395,"Câu đầu tiên trong một tài liệu hoặc một đoạn là quan trọng, và các câu khác trong một tài liệu được so sánh với các câu hàng đầu"],[396,"Trong đồ án của mình, em lựa chọn tính đặc trưng FirstRel_Doc : Độ liên quan của câu hiện tại với câu đầu văn bản, để đại diện cho đặc trưng mức độ liên quan"],[397,"Tính độ đương đồng giữa hai câu : Sử dụng bộ thư viện mã nguồn mở Nltk-examples/src/semantic : Sự tương tự về câu dựa trên ngữ nghĩa và các thống kê Corpus[1] 3.3"],[398,"Huấn luyện và kiểm thử SVM[2] xác định một hàm phân tách tuyến tính: f(x) = w"],[399,"x + b Trong đó, w là vector trọng số, b là tham số điều chỉnh bias, x là vector đặc trưng"],[400,"Mặt siêu phẳng xác định được được dùng để phân tách các ví dụ đầu vào"],[401,"Nên với ví dụ đầu vào có vector đặc trưng xi sẽ được gán vào lớp dương nếu f(xi) 0 tức nhãn lớp (ti) là 1 hoặc được gán vào lớp âm, nhãn lớp là 1 nếu ngược lại"],[402,"ti = { 1, w"],[403,"xi + b < 0 1, w"],[404,"xi + b 0 w"],[405,"x + b = 0 là mặt siêu phẳng phân tách các ví dụ huấn luyện lớp dương và các ví dụ huấn luyện lớp âm"],[406,"Ví dụ hình 13 SVM[2] phân lớp tuyến tính đòi hỏi các ví dụ âm và dương có thể phân tách một cách tuyến tính, ranh giới quyết định là mặt siêu phẳng"],[407,"Tuy nhiên trong nhiều bài toán thực tế, thì các tâp dữ liệu có thể là phân lớp phi tuyến"],[408,"Để xử lý với dữ liệu phân tách phi tuyến, phương pháp tương tự đối trường hợp phân tách tuyến tính"],[409,"Ta chuyển các ví dụ từ không gian ban đầu sang không gian đặc trưng mà ranh giới quyết định tuyến tính có thể phân tách các ví dụ âm và dương trong không gian sau chuyển đổi"],[410,"Ví dụ hình 14"],[411,"Tuy nhiên việc chuyển đổi này không được thực hiện rõ ràng mà thay vào đó hàm nhân (kernel function) được sử dụng để tính mà không cần biết hàm chuyển đổi"],[412,"Trong đồ án này em sử dụng hàm nhân Gauussian RBF (Gausian radial basis function) với (gamma) = 0.03125 (, ) = exp (|| ||2 Em sử dụng hàm nhân này bởi đánh giá thực nghiệm của em cho thấy hàm nhân này có kết quả tốt nhất"],[413,"Tập nhãn lớp 0 và 1 lần lượt tương ứng với câu không quan trọng và câu quan trọng"],[414,"Để có thể áp dụng SVM[2] em xác định tập đặc trưng phù hợp với bài toán TTVB và phân tích tập huẩn luyện.Phân tích bộ dữ liệu em trình bài chi tiết trong phần 1 chương III"],[415,"Do SVM[2] chỉ làm việc với đầu vào là số thực vậy nên những giá trị trong vector đặc trưng em cần phải chuyển các đặc trưng không phải dạng số thực về dạng số thực"],[416,"Cách để chuyển đổi em sẽ trình bày chi tiết trong phần 4 chương III CHƯƠNG IV:CÀI ĐẶT VÀ ĐÁNH GIÁ KẾT QUẢ 1"],[417,"Cài đặt 1.1"],[418,"Khối tiền xử lý văn bản 1.1.1 Phân tích các văn bản trong tập huấn luyện Các văn bản được lưu trữ trong folder 2007_raw của chương trình có cấu trúc như hình dưới đây: Trong đó - Thẻ <documet>: thẻ mở đầu văn bản, thuộc tính name trong thẻ này cho biết tên (ký hiệu của văn bản) - Thẻ <\/ducument>: thẻ kết thuc văn bản"],[419,"- Thẻ <line>:thẻ bắt đầu dòng - Thẻ <\/line>: thẻ kết thuc dòng - Thẻ <annotation> nhận biết những câu được đánh dấu trong văn bản tóm tắt của chuyên gia, văn bản tóm tắt của các hệ thống thử nghiệm"],[420,"Các thuộc tính trong thẻ này đa được trình bày chi tiết tại phần 1 của chương"],[421,"1.1.2"],[422,"Tiền xử lý Tách câu và đánh dấu câu quan trọng: - Chương trình thử nghiệm nhận biết các thẻ <line> và trích rút câu trong thẻ"],[423,"- Nhận biết các câu quan trọng thông qua thẻ <annotation>, trong các thuộc tính mà thẻ <annotation> chỉ ra, thuộc tính scu-count cho biết câu đó có được sử dụng trong bản tóm tắt của chuyên gia hay không"],[424,"Do đó, những câu có thẻ <annotation> và thuộc tính scu-count > 0 được đánh dấu là câu quan trọng phục vụ huẩn luyện"],[425,"- Dữ liệu sau khi tách câu và đánh dấu câu quan trọng được lưu trong folder 2007_parsed_data với định dạng như hình dưới đây: Loại bỏ từ dừng (stop word) và dấu câu: Danh sách các từ dừng được lưu trong file stop_words của chương trình"],[426,"Bao gồm 319 từ Chương trình đọc danh sách các từ trong file này và loại bỏ chúng khỏi các văn bản trong folder 2007_parsed_data, đồng thời thay dấu câu như dầu chấm, dấu chấm than, dấu chấm hỏi, dấu phẩy thành khoảng trắng"],[427,"Dữ liệu sau khi loại bỏ từ dừng và dấu câu được lưu trong folder non_stopword_data"],[428,"1.2"],[429,"Mô hình hóa dữ liệu huấn luyện 1.2.1"],[430,"Tính đặc trưng 11 đặc trưng được lựa chọn cho mô hình huấn luyện No Tên đặc trưng No Tên đặc trưng 1 Position 7 SigTerm_Uni 2 Doc_First 8 SigTerm_Bi 3 Length 9 FreqWord_Uni 4 Quote 10 FreqWord_Bi 5 Centroid_Uni 11 FirstRel_Doc 6 Centroid_Bi Đặc trưng 1: Position Cách tính đặc trưng Position: Giá trị nghịch đảo vị trí của câu đó trong văn bản chưa nó"],[431,"Gọi đến hàm Feature_Position(sentence, filename) Đầu vào: câu và tên file chứa câu đó"],[432,"Đặc trưng này trả về giá trị: 1/vị trí của câu đó trong văn bản Đặc trưng 2: Doc_First Giá trị của đặc trưng này là 0 hoặc 1"],[433,"Trả về 1 khi câu đó là câu đầu của văn bản"],[434,"Hàm def Feature_docfirst(sentence, docFirsts): Đầu vào: một câu trong văn bản, mảng các câu đầu trong văn bản"],[435,"Hàm trả về giá trị 0 hoặc 1, là 1 khi câu đó là câu đầu của văn bản"],[436,"Các hàm hỗ trợ cho tính năng này: - def get_first_doc() Đọc file xml từ 2007_raw ra file text first_docc_line tất cả các dòng đầu tiên của văn bản, đầu văn bản được đánh dấu bằng thẻ <document> - def get_docfirst_list(): Trả về 1 mảng các câu đầu đoạn, đọc từ file first_doc_line Đăch trưng 3: Length Giá trị của đặc trưng: Độ dài của câu"],[437,"Hàm Feature_Length(sentence): Đầu vào là 1 câu trong văn bản Hàm trả về độ dài của câu Đặc trưng 4: Quote Giá trị của đặc trưng: Số lượng từ trích dẫn nằm trong câu"],[438,"Phương pháp tính: Tìm và tính số lượng của tất cả các từ nằm trong các cặp dấu đóng mở ngoặc đơn (), nháy kép , đóng mở ngoặc vuông, dấu *"],[439,"Hàm Feature_quote(sentence): Đầu vào là 1 câu trong văn bản Trả về số từ trích dẫn trong câu đó Đặc trưng 5: Centroid_Uni Tổng khối lượng của các từ trọng tâm Uni ( từ centroid uni) có trong câu: Các từ centroid được xác định bằng độ đo TF-IDF Các hàm hỗ trợ tính độ đo TF-IDF unigram: - def get_bloblist(folder): Hàm trả về 1 mảng các chuỗi, trong đó mỗi chuỗi là 1 văn bản, đầu vào là non-stopword-data hoặc bigram-data - def tf(word, blob): Đầu vào: Một từ trong văn bản và văn bản đó"],[440,"Trả về giá trị tf của từ đó trong văn bản blob"],[441,"- def n_containing(word, bloblist)trả về số lượng văn bản chứa word"],[442,"bloblist là 1 mảng các văn bản"],[443,"Đầu vào: một từ và mảng các văn bản trong tập huấn luyện hoặc tập test"],[444,"Trả về số lượng văn bản chứa từ đó"],[445,"- def idf(word, bloblist): Đầu vào: Một từ và mảng các văn bản trong tập huấn luyện hoặc tập test"],[446,"Trả về giá trị idf của từ đó trong văn bản blob"],[447,"- def tfidf(word, blob, bloblist): Đầu vào: Một từ, văn bản chứa từ đó và mảng các văn bản trong tập huấn luyện hoặc tập test"],[448,"Trả về giá trị TF-IDF của từ đó"],[449,"- def tfidf_data(ngram): Đầu vào là lựa chọn unigram(1) hoặc bigram(2) Hàm ghi lại kết quả chỉ số IF-IDF của 30% tổng số từ có có chỉ số cao nhất (các từ centroid words) vào từng văn bản vào mỗi file riêng biệt trong folder TFIDF_UNI hoặc TFIDF_BI Hàm def Centroid(sentence, word_list): Sẽ đọc trong file lưu chỉ số TF-IDF của từ và tính toán tổng trọng lượng các từ centroid trong câu"],[450,"Đặc trưng 6: Centroid_Bi Tổng khối lượng của các từ trọng tâm Bi ( từ centroid Bi) có trong câu: Các hàm hỗ trợ xuất file bigram: - def to_bigram(sentence): Đầ vào: một câu trong văn bản"],[451,"Trả về 1 chuỗi thay thế sentence gồm các bigram"],[452,"- def parse_to_bigram_data(): Ghi lại các câu sau khi biến đổi sang bigram vào foder bigram-data Các từ centroid-bi được xác định bằng độ đo tf-idf Các hàm hỗ trợ tính TF-IDF bigram - def get_bloblist(folder): Hàm trả về 1 mảng các chuỗi, trong đó mỗi chuỗi là 1 văn bản, đầu vào là non-stopword-data hoặc bigram-data - def tf(word, blob): Đầu vào: Một từ trong văn bản và văn bản đó"],[453,"Trả về giá trị tf của từ đó trong văn bản blob"],[454,"- def n_containing(word, bloblist)trả về số lượng văn bản chứa word"],[455,"bloblist là 1 mảng các văn bản"],[456,"Đầu vào: một từ và mảng các văn bản trong tập huấn luyện hoặc tập test"],[457,"Trả về số lượng văn bản chứa từ đó"],[458,"- def idf(word, bloblist): Đầu vào: Một từ và mảng các văn bản trong tập huấn luyện hoặc tập test"],[459,"Trả về giá trị idf của từ đó trong văn bản blob"],[460,"- def tfidf(word, blob, bloblist): Đầu vào: Một từ, văn bản chứa từ đó và mảng các văn bản trong tập huấn luyện hoặc tập test"],[461,"Trả về giá trị TF-IDF của từ đó"],[462,"- def tfidf_data(ngram): Đầu vào là lựa chọn unigram(1) hoặc bigram(2) Hàm ghi lại kết quả chỉ số TF-IDF của 30% tổng số từ có có chỉ số cao nhất (các từ centroid words) vào từng văn bản vào mỗi file riêng biệt trong folder TFIDF_UNI hoặc TFIDF_BI - Hàm def Centroid(sentence, word_list): Sẽ đọc trong file lưu chỉ số TF-IDF của từ và tính toán tổng trọng lượng các từ centroid trong câu"],[463,"Đặc trưng 7: SigTerm_Uni Dánh sách các từ SigTerm _Uni tự tổng hợp No SigTerm _Uni No SigTerm _Uni 1 abstract 5 conclusion 2 brief 6 outline 3 highlight 7 summarization 4 conclude 8 summary Hàm hỗ trợ: - def get_signterm_data(filename): Đầu vào: đọc file sigterm_data Trả về 1 mảng các từ sigterm - def SigTerm(sentence, sigterms): Đầu vào: một câu trong văn bản và mảng các từ sigterm Trả về số lượng từ signterm trong câu Đặc trưng 8: SigTerm_Bi Dánh sách các từ SigTerm _Bi tự tổng hợp No SigTerm _Bi 1 main idea 2 the best 3 this article 4 this document 5 this paper Hàm hỗ trợ: - def get_signterm_data(filename): Đầu vào: đọc file sigterm_data Trả về 1 mảng các từ sigterm - def SigTerm(sentence, sigterms): Đầu vào: một câu trong văn bản và mảng các từ sigterm Trả về số lượng từ signterm trong câu Đặc trưng 9: FreqWord_Uni Các FreqWord_Uni trong mỗi văn bản được xác định là 30% các từ Unigram có chỉ số TF cao nhất trong mỗi văn bản Các hàm hỗ trợ tính chỉ số TF unigram - def tf(word, blob): Đầu vào: Một từ trong văn bản, và văn bản chứa từ đó"],[464,"Trả về chỉ số TF của từ đó trong văn bản"],[465,"- def tf_data(ngram): Đầu vào là lựa chọn unigram(1) hoặc bigram(2) Hàm ghi lại kết quả chỉ số TF của 30% tổng số từ có có chỉ số cao nhất (các từ frequent words) vào từng văn bản vào mỗi file riêng biệt trong folder TF_UNI hoặc TF_BI - Hàm def FreqWord(sentence, word_list): Sẽ đọc trong file lưu chỉ số TF của từ và tính toán tổng trọng lượng các từ freq_word trong câu"],[466,"Đặc trưng 10: FreqWord_Bi Các FreqWord_Bi trong mỗi văn bản được xác định là 30% các từ Bigram có chỉ số TF cao nhất trong mỗi văn bản Các hàm hỗ trợ tính chỉ số TF bigram - def tf(word, blob): Đầu vào: Một từ trong văn bản, và văn bản chứa từ đó"],[467,"Trả về chỉ số TF của từ đó trong văn bản"],[468,"- def tf_data(ngram): Đầu vào là lựa chọn unigram(1) hoặc bigram(2) Hàm ghi lại kết quả chỉ số TF của 30% tổng số từ có có chỉ số cao nhất (các từ frequent words) vào từng văn bản vào mỗi file riêng biệt trong folder TF_UNI hoặc TF_BI - Hàm def FreqWord(sentence, word_list): Sẽ đọc trong file lưu chỉ số TF của từ và tính toán tổng trọng lượng các từ freq_word trong câu"],[469,"Đặc trưng 11: FirstRel_Doc Thư viện hỗ trợ Sử dụng bộ thư viện mã nguồn mở Nltk-examples/src/semantic : Sự tương tự về câu dựa trên ngữ nghĩa và các thống kê Corpus[1] Các hàm hỗ trợ - def get_docfirst_list(): Trả về 1 mảng các câu đầu đoạn, đọc từ file first_doc_line - def is_first_doc(sentence, doc_first_list): Đầu vào: một câu trong văn bản và mảng các câu đầu văn bản Kiểm tra 1 câu có phải câu đầu đoạn - def cal_similarity(): Ghi vào folder similities mỗi câu và độ tương đồng của câu đó với câu tiêu đề kết quả được lưu trong folder similities similities - Hàm def Feature_firstRelDoc(sentence, filename): Đầu vào: một câu trong văn bản và tên file văn bản tương ứng trong thư mục similarties Trả về giá trị độ tương đồng của câu đó với câu đầu đoạn"],[470,"1.2.2"],[471,"Xuất file huấn luyện Như đa trình bày, em sử dụng SVM[2] để phân loại từ quan trọng và từ không quan trọng"],[472,"Từ trong quan trong sẽ bị loại bỏ đi, từ quan trọng được đưa vào văn bản tóm tắt"],[473,"Em sử dụng thư viện LIBSVM của Chih-Chung Chang and Chih-Jen Lin [4][2]"],[474,"Trong thư viện này định dạng của ví dụ huấn luyện và ví dụ kiểm thử là: <label> <index1>:<value1> <index2>:<value2>"],[475,"Định dạng file phù hợp cho mô hình huấn luyện của SVM: - Mỗi dòng chứa một đối tương và được kết thuc bằng ký tự xuống dòng '\\n' - Trong đó: <label> là một số nguyên cho biết nhan lớp Mỗi cặp <index>: <value> biểu thị cho một tính năng"],[476,"Giá trị <index> là một số nguyên bắt đầu từ 1 và <value> là một số thực"],[477,"Giải pháp đề xuất đưa ra 11 đặc trưng của câu trong bộ dữ liệu"],[478,"11 đặc trưng này sẽ tương ứng với 11 cặp <index>: <value> của mỗi câu"],[479,"<label> có giá trị bằng 0 hoặc 1, với 1 là câu được gán nhan quan trọng"],[480,"1.3"],[481,"Chuẩn hóa bộ dữ liệu Svm-scale là công cụ thể chuẩn hóa dữ liệu đầu vào về giá trị trong khoảng [0;1]"],[482,"Công thức chuẩn hóa: valuec = l + (u l) (value f_minindex) (f_maxindex f_minindex) Trong đó, valuec là giá trị sau chuẩn hóa của đặc trưng thứ index, value là giá trị trước chuẩn hóa của đặc trưng thứ index, l, u lần lượt là giá trị nhỏ nhất và lớn nhất có thể sau chuẩn hóa, f_maxindex, f_minindex lần lượt là giá trị lớn nhất và giá trị của nhất của đặc trưng ở vị trí thứ index trên toàn bộ tập dữ liệu"],[483,"Các giá trị f_minindex và f_maxindex sẽ được lưu vào tệp range để phục vụ cho thao tác chuẩn hóa sau này"],[484,"Như em đa trình bày trong phần 3.2 của đồ án Cặp <index>:<value> là một biểu diễn của một đặc trưng"],[485,"Trong đó <index> là một giá trị số nguyên bắt đầu từ 1 và <value> là một số nguyên biểu diễn giá trị của đặc trưng đó"],[486,"Ví dụ day các đặc trưng của một câu trong văn bản huấn luyện: 1:1 2:0 3:106 4:7 5:0.03529 6:0.00196 7:0 8:0 9:0.03713 10:0.00131 11:0.513208063011 Sau khi được chuẩn hóa trở thành: 1:-0.998261 2:-1 3:-0.448819 4:-0.942623 5:-0.823717 6:-0.962524 7:-1 9:-0.767195 10:- 0.95958 11:0.0264161 1.4"],[487,"Học từ bộ dữ liệu huấn luyện Svm-train được sử dụng để học các quy tắc, luật từ bộ dữ liệu huấn luyện"],[488,"Đầu vào của svm-train là tập dữ liệu huấn luyện xây dựng đa được chuẩn hóa và đầu ra là một mô hình"],[489,"Mô hình này được lưu vào tệp train_file.model để gán nhãn lớp cho các ví dụ sau này"],[490,"Tuy nhiên, nếu chỉ phân lớp câu thành 2 lớp đơn thuần là câu quan trọng và không quan trọng sẽ nảy sinh một vấn đề có những văn bản không có câu nào được dự đoán là quan trọng"],[491,"Để giải quyết vấn đề này, SVM[2]hỗ trợ dự đoán xác suất Cấu trúc dòng lệnh train: svm-train [options] training_set_file [model_file] Trong đó với tùy chọn: -b probability_estimates: khi cài đặt tùy chọn này là 1 (mặc định là 0), model train hỗ trợ ước tính xác suất"],[492,"1.5"],[493,"Gán nhãn dữ liệu và dự đoán xác suất Svm-predict sử dụng mô hình đa học được để gán nhãn lớp cho các câu trong văn bản test"],[494,"Em tính các giá trị đặc trưng của từng câu trong các văn bản"],[495,"Sau đó, em chuẩn hóa chung để làm đầu vào của svm-predict với tham số tùy chọn -b probability_estimates bằng 1, các câu trong văn bản thử nghiệm đa được gán nhãn lớp và ước tính xác suất chính là đầu ra"],[496,"Sau khi các câu trong tập văn bản thử nghiệm được gán nhãn và dự đoán xác suất xuất hiện trong các lớp, em sắp xếp chúng theo thứ tự giảm dần của xác suất nằm trong lớp câu quan trọng, từ đó xuất ra văn bản tóm tắt với độ dài khoảng 250 chữ"],[497,"2"],[498,"Đánh giá kết quả 2.1"],[499,"Bộ dữ liệu mẫu Bộ dữ liệu mẫu được sử dụng cho quá trình kiểm thử trong đồ án tốt nghiệp này là các văn bản được tóm tắt thực hiện bởi chuyên gia từ các Viện Tiêu chuẩn và Công nghệ Quốc gia (NIST)"],[500,"Mỗi chuyên gia sẽ có một văn bản tóm tắt thủ công khác nhau"],[501,"Do đó để đảm bảo tính khách quan, mỗi một văn bản trong bộ dữ liệu test cần có 2 đến 4 văn bản tóm tắt thủ công tương ứng"],[502,"Bộ dữ liệu mẫu gồm các bài tóm tắt thủ công của 45 chủ đề"],[503,"Mỗi chủ đề có 3 bản tóm tắt thủ công, mỗi bản tóm tắt có độ dài 250 từ"],[504,"2.2"],[505,"Phương pháp đánh giá Đánh giá kết quả tóm tắt văn bản là một việc làm khó khăn trong thời điểm hiện tại"],[506,"Việc sử dụng ý kiến đánh giá của các chuyên giá ngôn ngữ được xem là cách đánh giá tốt nhất, tuy nhiên, cách làm này lại tốn rất nhiều chi phí"],[507,"Bên cạnh các phương pháp đánh giá thủ công do cách chuyên gia thực hiện, vấn đề đánh giá tự động kết quả tóm tắt cũng nhận được nhiều sự chú ý hiện nay"],[508,"Ví dụ, Saggion (2002)[6] đưa ra ba phương pháp đánh giá tóm tắt văn bản dựa vào nội dung đo độ tương tự giữa văn bản tóm tắt bằng tay và văn bản tóm tắt tự động"],[509,"các phương pháp đó là: độ tương tự cosine, sự trùng lặp đơn vị (unit overlap) và chuỗi con chung dài nhất"],[510,"Tuy nhiên, chúng vẫn chưa tương quan với đánh giá của con người"],[511,"Sau thành công của ứng dụng đánh giá tự động trong đánh giá dịch máy như BLEU (Papineni 2001)[7], Lin và Hovy đa đưa ra một phương pháp tương tự BLEU như thống kê trùng lặp n-gram có thể được áp dụng vào đánh giá tóm tắt tự động"],[512,"Đó chính là độ đo ROUGE-N (Recal-Oriented Understudy for Gisting Evaluation)[5]"],[513,"Trong đồ án này, em sử dụng độ đo ROUGE-N[5] để đánh giá kết quả của hệ thống tóm tắt văn bản tự động"],[514,"ROUGE-N[5] là độ phủ n-gram giữa văn bản tóm tắt tự động và văn bản tóm tắt bằng tay tương ứng"],[515,"ROUGE-N[5] được tính như sau: = (){} (){} Trong đó: là bộ n từ liên tiếp trong văn bản S"],[516,"() là số trùng lặp tối đa giữa văn bản tóm tắt tự động và văn bản tóm tắt bằng tay"],[517,"2.3"],[518,"Các kết quả kiểm thử Trong phần này, em thực hiện kiểm thử với 10 văn bản trong tập dữ liệu DUC2007 Để hiểu rõ hơn cho hệ thống của mình em xin đưa ra một ví dụ minh họa đầu vào, đầu ra của hệ thống tóm tắt đơn văn bản theo phương pháp SVM ước lượng xác suất: Văn bản đầu vào: Văn bản D0730 Văn bản có độ dài khoảng 10.000 từ"],[519,"Văn bản mẫu kiểm thử1: In the words of President Clinton the line item veto \"is very important in helping to preserve the integrity of federal spending\""],[520,"The line item veto has been sought by presidents since Grant and was popularized by Reagan"],[521,"It was part of Republican \"Contract with America\" led by Speaker Newt Gingrich that enacted it"],[522,"The line item veto allows the president to veto particular items in spending bills and certain limited tax provisions passed by Congress"],[523,"Previously the president could only veto entire bills"],[524,"Bill Clinton is the only president to have had line item veto authority"],[525,"He has said that it should be used sparingly"],[526,"He used it 163 times, mostly to delete items from the military construction bill"],[527,"The line item veto was challenged by a group of most Democratic senators but was dismissed by the Supreme Court"],[528,"However, another challenge led by New York Mayor Giuliani and Idaho farmers resulted in a federal judge declaring the line item veto unconstitutional"],[529,"The Justice Department appealed that decision to the Supreme Court"],[530,"The Supreme Court rejected the line item veto as a departure from the basic constitutional requirement that presidents accept or reject bills in their entirety"],[531,"The Court found that the line item veto violates the \"presentment clause\" of Article I that establishes the process by which a bill becomes law"],[532,"The Court vote was 6-3 with Justice Stevens writing for the majority"],[533,"Văn bản mẫu kiểm thử2: The line-item veto (LIV) has been sought by nearly every president this century as a tool to limit pork barrel spending which is traditionally reviled as the most cynically deployed and least utilitarian form of largess"],[534,"The 1998 budget included $300,000 for enhancing the flavor of peanuts, $150,000 for peanut competitiveness and $250,000 for pickle research"],[535,"President Clinton said the LIV is an important tool for striking unnecessary spending, for preserving the integrity of federal spending and enlivening the public debate over how to make the best use of public funds"],[536,"The Solicitor General contended that the LIV represents a presidential exercise of spending authority delegated by Congress"],[537,"110 years ago, Lord Bryce said the LIV was \"desired by enlightened men and would save the nation millions of dollars a year\""],[538,"The LIV is a prerogative given to 43"]],"downloaded":true,"m":[-1,-1],"n":"20132320_Tran_Thi_Dieu_Linh_1528176806088.txt","o":"http://storage.googleapis.com/soict-projects/httt/hedspi-a/20132320_Tran_Thi_Dieu_Linh_1528176806088.pdf\r"},{"saved_path":"temp/baocaodatn_8451.txt","r":4.1063232421875,"s":[[41,435,0.9189189076423645,51,0,54,1,55,"Các tiêu chí đánh giá  Độ mạch lạc (Coherence): đánh giá mức độ rõ ràng của văn bản tóm tắt, tính súc tích, khả năng có thể đọc và hiểu được của bài viết\u2026  Độ hàm chứa thông tin (Informationess): tỉ lệ thông tin của văn bản gốc trong văn bản tóm tắt","10 Các tiêu chí đánh giá: - Độ mạch lạc (Coherence): đánh giá mức độ rõ ràng của văn bản tóm tắt, tính súc tích, khả năng có thể đọc và hiểu được của bài viết\u2026 - Độ hàm chứa thông tin (Informationess): tỉ lệ thông tin của văn bản gốc trong văn bản tóm tắt"],[175,425,0.8450704216957092,30,1,35,4,34,"Đánh giá kết quả tóm tắt Đánh giá một bản tóm tắt là một công việc khó bởi không tồn tại một bản tóm tắt lý tưởng cho một (hoặc một tập) văn bản đưa ra","Các phương pháp đánh giá Đánh giá một bản tóm tắt là một công việc khó bởi không tồn tại một bản tóm tắt lý tưởng cho một (hoặc một tập) văn bản đưa ra"],[34,86,0.6666666865348816,7,0,6,3,9,"TỔNG QUAN VỀ TÓM TẮT VĂN BẢN TỰ ĐỘNG 2.1","2 CHƯƠNG 1: TỔNG QUAN VỀ TÓM TẮT VĂN BẢN ........................................"],[176,426,1,13,0,12,0,12,"Hơn nữa, việc đánh giá nội dung tóm tắt cũng rất khó khăn","Hơn nữa, việc đánh giá nội dung tóm tắt cũng rất khó khăn"],[179,429,1,21,0,20,0,20,"Bên cạnh đó, khi việc đánh giá được thực hiện bởi con người thì chi phí đánh giá sẽ rất cao","Bên cạnh đó, khi việc đánh giá được thực hiện bởi con người thì chi phí đánh giá sẽ rất cao"],[180,430,1,44,0,43,0,43,"Mặt khác, tóm tắt văn bản còn liên quan đến tỉ lệ nén văn bản, do đó, việc đánh giá bản tóm tắt cần phải quan tâm đến vấn đề này, khi đó độ phức tạp và chi phí đánh giá sẽ tăng cao","Mặt khác, tóm tắt văn bản còn liên quan đến tỉ lệ nén văn bản, do đó, việc đánh giá bản tóm tắt cần phải quan tâm đến vấn đề này, khi đó độ phức tạp và chi phí đánh giá sẽ tăng cao"],[44,437,0.8541666865348816,41,13,53,1,41,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 14  Độ dễ đọc hiểu (Reading Comprehence): một người được giao việc đọc văn bản kết quả, sau đó trả lời các câu hỏi, hệ thống sẽ phải cho điểm và từ đó đưa ra phần trăm những câu trả lời đúng","- Độ dễ đọc hiểu (Reading Comprehence): một người được giao việc đọc văn bản kết quả, sau đó trả lời các câu hỏi, hệ thống sẽ phải cho điểm và từ đó đưa ra phần trăm những câu trả lời đúng"],[134,390,0.8985507488250732,31,0,32,0,33,"Tư tưởng chính của các phương pháp này là những đơn vị ngữ liệu nào có chứa các thành phần liên kết nhiều với các thành phần khác sẽ có độ quan trọng lớn","Tư tưởng chính của các phương pháp này là những đơn vị ngữ liệu nào có chứa các thành phần liên quan nhiều với các thành phần khác sẽ có mức độ quan trọng cao"],[155,412,0.7428571581840515,13,0,14,0,19,"Công việc này thường dựa trên phân tích cú pháp các thành phần trong câu","Công việc này thường dựa trên phân tích cú pháp và phân tích ngữ nghĩa các thành phần trong câu"],[123,383,0.6538461446762085,17,1,26,1,24," Minh họa - Chú thích (Comments): Trong các câu chú thích, câu minh họa cho ảnh hay đồ thị thường chứa các thông tin quan trọng","+ Minh hoạ, chú thích: trong các câu chú thích, câu minh hoạ cho ảnh hay đồ thị thường chứa các thông tin quan trọng"],[178,428,1,28,0,27,0,27,"Thực tế luôn có khả năng một hệ thống sinh ra một bản tóm tắt tốt nhưng lại sai khác với bản tóm tắt do người thực hiện","Thực tế luôn có khả năng một hệ thống sinh ra một bản tóm tắt tốt nhưng lại sai khác với bản tóm tắt do người thực hiện"],[121,381,0.6769230961799622,22,3,32,6,31," Đầu - cuối đoạn (First - Last Sentence): Xác suất câu đầu đoạn hay câu cuối đoạn chứa ý chính của cả đoạn là rất lớn, đặc biệt là câu đầu đoạn","7 + Câu ở đầu hoặc cuối đoạn: xác suất câu đầu đoạn hay câu cuối đoạn chứa ý chính của cả đoạn là rất lớn, đặc biệt là câu đầu đoạn"],[133,389,0.892307698726654,29,0,31,1,32,"Phương pháp cấu trúc Là các phương pháp sử dụng các mối liên hệ cấu trúc - ngữ pháp - ngữ nghĩa để xác định các đơn vị ngữ liệu quan trọng","b) Phương pháp cấu trúc Các phương pháp này sử dụng các mối liên hệ cấu trúc - ngữ pháp - ngữ nghĩa để xác định các đơn vị ngữ liệu quan trọng"],[170,420,0.6399999856948853,32,0,38,16,55,"Các đơn vị ngữ liệu được trích rút hay giản lược từ các pha trước được liên kết lại thành đoạn theo thứ tự tiền định của chúng, không thêm bớt từ nối và cũng không sắp xếp lại các đơn vị ngữ liệu","Các phương pháp trong pha tổng hợp kết quả a) Phương pháp hiển thị phân đoạn Các đơn vị ngữ liệu được trích xuất hay giản lược từ các pha trước được liên kết lại thành đoạn theo đúng thứ tự trong văn bản gốc, không thêm bớt từ nối và cũng không sắp xếp lại"],[171,421,0.7555555701255798,34,0,48,0,39,"Văn bản kết quả của phương pháp này có độ dễ đọc dễ hiểu kém, thậm chí lủng củng về nghĩa vì các đơn vị ngữ liệu được trích rút mắc phải một số lỗi như mập mờ tham chiếu, không có từ nối hoặc là thừa từ và ngữ","Văn bản kết quả của phương pháp này có độ dễ đọc và dễ hiểu kém, thậm chí lủng củng vì các đơn vị ngữ liệu có thể bị mập mờ tham chiếu, không có từ nối hoặc thừa từ"],[115,101,0.6666666865348816,6,0,7,0,6,"Các phương pháp áp dụng trong các pha 2.7.1","Các phương pháp áp dụng trong pha phân tích"],[115,104,0.6315789222717285,6,0,7,0,6,"Các phương pháp áp dụng trong các pha 2.7.1","Các phương pháp áp dụng trong pha biến đổi ........................................"],[115,375,0.6666666865348816,6,0,7,0,6,"Các phương pháp áp dụng trong các pha 2.7.1","Các phương pháp áp dụng trong pha phân tích"],[177,427,1,47,0,46,0,46,"Trường hợp kết quả là một câu trả lời cho một câu hỏi, ta có thể xác định được câu trả lời đó đúng hay sai, nhưng trong các trường hợp khác, thật khó trả lời liệu đầu ra là phải một kết quả đúng hay không","Trường hợp kết quả là một câu trả lời cho một câu hỏi, ta có thể xác định được câu trả lời đó đúng hay sai, nhưng trong các trường hợp khác, thật khó trả lời liệu đầu ra là phải một kết quả đúng hay không"],[145,401,0.6984127163887024,22,12,34,1,27,"Hoàng Đức Thọ 20082559 Lớp Hệ Thống Thông Tin K53 Trang 20 phương pháp này, các cụm trùng lặp được chọn ra, phân rã xem đâu là từ tham chiếu và từ được tham chiếu","Theo phương pháp này, các cụm trùng lặp được chọn ra, phân rã xem đâu là từ (cụm từ) tham chiếu và từ (cụm từ) được tham chiếu"],[146,402,0.9166666865348816,22,0,22,0,24,"Sau khi phân tách các cụm trùng lặp, chúng ta tạo chuỗi các từ tham chiếu đến cùng một từ được tham chiếu","Sau khi phân tách các cụm trùng lặp, chúng ta tạo chuỗi các từ (cụm từ) tham chiếu đến cùng một từ được tham chiếu"],[139,395,0.767123281955719,28,1,35,1,36," Phương pháp liên kết từ vựng: Phương pháp liên kết từ vựng sử dụng các từ điển quan hệ từ vựng đế xây dựng các chuỗi từ liên kết với nhau vể mặt ngữ nghĩa","+ Phương pháp chuỗi từ vựng (lexical chains) Phương pháp liên kết từ vựng sử dụng các từ điển quan hệ từ vựng để xây dựng các chuỗi từ liên kết với nhau về mặt ngữ nghĩa"],[272,99,0.6666666865348816,6,2,7,0,5,"Hình 3: Mô hình tóm tắt văn bản hướng truy vấn","Mô hình tóm tắt văn bản .............................................................................."],[42,436,0.9666666388511658,29,1,29,1,29," Độ liên quan (Relevance): xác định mức độ phù hợp của văn bản tóm tắt với chủ đề cho trước (chủ đề có thể là một câu truy vấn)","- Độ liên quan (Relevance): xác định mức độ phù hợp của văn bản tóm tắt với chủ đề cho trước (chủ đề có thể là một câu truy vấn)"],[147,403,0.8666666746139526,26,0,29,0,29,"Chuỗi dài nhất sẽ được coi là trọng tâm của đoạn, các câu chứa các từ trong chuỗi này có một độ ưu tiên nào đó khi xét trích chọn","Chuỗi dài nhất sẽ được coi là trọng tâm của đoạn, các câu chứa các từ trong chuỗi này có một độ ưu tiên nào đó thì sẽ được chọn"],[136,392,0.6265060305595398,26,1,38,1,36," Phương pháp quan hệ lẫn nhau: Phương pháp này xác định mối quan hệ giữa các đoạn trong văn bản hay các câu trong đoạn với nhau thông qua các kỹ thuật thu thập thông tin ở mức văn bản","- Phương pháp sử dụng quan hệ giữa câu, đoạn Phương pháp này xác định mối quan hệ giữa các đoạn trong văn bản hay các câu trong đoạn với nhau thông qua việc tính toán mức độ liên quan giữa chúng"],[122,382,0.8484848737716675,14,0,16,0,15,"Ngoài ra, các đoạn đầu và cuối trong văn bản cũng quan trọng hơn các đoạn giữa","Ngoài ra các đoạn đầu và cuối văn bản cũng quan trọng hơn các đoạn giữa"],[135,391,0.692307710647583,18,0,19,0,19,"Việc đánh giá các mối quan hệ sẽ dựa trên các mạng ngữ nghĩa, các quan hệ cú pháp hoặc thông qua các phương pháp xác định độ liên quan truyền thống","Việc đánh giá các mối quan hệ sẽ dựa trên các mạng ngữ nghĩa hoặc các quan hệ cú pháp"],[138,394,0.692307710647583,9,0,11,0,13,"Sau đó chọn ra đoạn (câu) có độ liên quan lớn nhất","Sau đó, ta chọn ra đoạn hay câu có độ liên quan lớn nhất"],[127,385,0.6666666865348816,10,0,13,0,12,"Sau các ngữ này thường là các câu hay từ có độ quan trọng là xác định","Sau các cụm từ này thường là các từ hay câu quan trọng"],[142,398,0.6341463327407837,13,5,21,1,18,"Sau khi xây dựng được các chuỗi từ này, đánh giá độ mạnh của chúng và có những trích chọn phù hợp","8 các từ vựng này, ta đánh giá độ mạnh của chúng và chọn ra những câu phù hợp"]],"t":"\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\nTRƯỜNG ĐẠI HỌC SPKT HƯNG YÊN CỘNG HÒA XÃ HỘI CHỦ NGHĨA VIỆT NAM \n\nKHOA CÔNG NGHỆ THÔNG TIN Độc lập \u2013 Tự do \u2013 Hạnh phúc \n\nĐỀ TÀI TỐT NGHIỆP ĐẠI HỌC \n\n \n\n \n\nHọ và tên sinh viên: \n\n1. Nguyễn Văn Thuấn  25/01/1991 TK7.2 \n\n2. Trần Quang Vinh 21/06/1990 TK7.2 \n\n    \n\nNgành đào tạo: Công Nghệ Thông Tin \n\nChuyên ngành: Mạng máy tính và Truyền thông \n\nKhóa học:   2009-2013 \n\nTên đề tài: TÓM TẮT VĂN BẢN DỰA VÀO TRÍCH XUẤT CÂU VÀ XÂY \n\nDỰNG ỨNG DỤNG MINH HỌA \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\nMục tiêu đề tài:  \n\n- Tìm hiểu cơ sở lý thuyết của phương pháp tóm tắt văn bản dựa vào trích xuất câu \n\nbao gồm: Tổng quan về tóm tắt văn bản, các mô hình tóm tắt, đặc điểm Tiếng Việt, \n\nphương pháp sử dụng trong tóm tắt văn bản. \n\n- Xây dựng được phần mềm tóm tắt văn bản dựa vào trích xuất các câu quan trọng \n\ntrong văn bản theo một tỷ lệ nén nhất định. \n\nNội dung cần hoàn thành: \n\n1. Phần thuyết minh: \n\n- Cuốn báo cáo Đồ án tốt nghiệp được trình bày theo đúng quy định. Báo \n\ncáo được trình bày được ý tưởng và cách giải quyết các bài toán trong \n\nquá trình thực hiện đề tài, các phương pháp đánh giá văn bản tóm tắt với \n\ncác phương pháp tóm tắt khác. \n\n- Báo các được trình bày gồm 3 phần:  \n\nPhần 1: Mở đầu \n\n- Lý do chọn đề tài. \n\n- Mục đích nghiên cứu. \n\n- Nhiệm vụ nghiên cứu. \n\n- Phươn pháp nghiên cứu. \n\n Phần 2: Nội dung \n\n- Tổng quan về tóm tắt văn bản. \n\n- Bài toán tóm tắt văn bản tiếng việt. \n\n- Ứng dụng phương pháp cấu trúc để tóm tắt văn bản Tiếng Việt. \n\n- Xây dựng ứng dụng minh họa. \n\n- Thực nghiệm và đánh giá. \n\nPhần 3: Kết luận. \n\n- Kết quả đạt được. \n\n- Những hạn chế của đề tài. \n\n- Hướng phát triển của đề tài. \n\n2. Phần thực hành, cài đặt: \n\n- Xây dựng phần mềm giải quyết được bài toán trong tóm tắt văn bản áp \n\ndụng phương pháp trích xuất câu. \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\n- Cài đặt các công cự hỗ trợ tách từ tách câu. \n\n- Trích xuất ra được văn bản tóm tắt theo tỉ lệ % tùy chọn với độ chính xác \n\nvà đáng tin cậy cao. \n\n3. Sản phẩm chính: \n\n- Phần mềm Tóm tắt văn bản áp dụng phương pháp trích xuất câu hoàn \n\nchỉnh. \n\nDự kiến kính phí:  \n\nThời gian thực hiện:  Ngày giao:...../...../..........., ngày hoàn \n\nthành ....../....../.......... \n\nNgười hướng dẫn: \n\n- Thứ nhất: Nguyễn Thị Thanh Huệ                Ký xác \n\nnhận:.............................. \n\n- Thứ hai:........................................................Ký xác \n\nnhận:.............................. \n\nĐề tài đã được Hội đồng Khoa học và Đào tạo Khoa thông qua. \n\n \nTRƯỞNG KHOA \n\n(Ký, ghi rõ họ và tên) \n\nHưng Yên, ngày .... tháng .... năm ........ \nTRƯỞNG BỘ MÔN \n(Ký, ghi rõ họ và tên) \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\n \n\nMỞ ĐẦU \n\n \n\nNgày nay, với sự phát triển như vũ bão của công nghệ thông tin, \n\nInternet cũng như các dịch vụ trực tuyến, ngày càng có nhiều thông tin được \n\ntạo ra. Ta có thể truy cập các thông tin đó qua sách, báo, Internet và các \n\nphương tiện truyền thông. Hơn nữa, nhu cầu đọc, tìm kiếm và lưu trữ thông \n\ntin của con người cũng ngày càng tăng lên. Tuy nhiên, với một lượng lớn \n\nthông tin như vậy thì người ta không thể nào có đủ thời gian và sức lực để \n\nđọc hết được chúng. Giải pháp là tóm tắt lại các văn bản đó, từ đó giúp tiết \n\nkiệm thời gian và công sức nhưng vẫn có thể đọc và xử lý được nhiều văn \n\nbản.  \n\nTóm tắt văn bản tự động đã bắt đầu được nghiên cứu từ những năm 50 \n\ncủa thế kỉ trước. Đã có nhiều công trình nghiên cứu về lĩnh vực này và có \n\nđược những kết quả đáng kể. Tóm tắt văn bản đã được sử dụng trong các \n\nphần mềm xử lý văn bản (Microsoft Office Word\u2026), trong khai phá cơ sở \n\ndữ liệu văn bản (Oracle\u2026), trong các ứng dụng tìm kiếm thông tin trực tuyến \n\n(hệ thống tìm kiếm Google, Yahoo\u2026) và đều thu được những kết quả rất \n\nđáng khích lệ . Vì vậy, chúng em chọn đề tài: \u201cTóm tắt văn bản dựa vào \n\ntrích xuất câu và xây dựng ứng dụng minh họa\u201d nhằm nghiên cứu những \n\nvấn đề tổng quan về xử lý ngôn ngữ tự nhiên và một số phương pháp tóm tắt \n\nvăn bản. Với sự hướng dẫn của cô Nguyễn Thị Thanh Huệ. \n\n \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\nLỜI CẢM ƠN \n\n \n\nSau một thời gian tìm hiểu và thực hiện đến nay đề tài \u201cTÓM TẮT VĂN \n\nBẢN DỰA VÀO TRÍCH XUẤT CÂU VÀ XÂY DỰNG ỨNG DỤNG MINH \n\nHỌA\u201d đã hoàn thành. Trong suốt quá trình thực hiện đề tài, chúng em đã nhận \n\nđược rất nhiều sự giúp đỡ nhiệt tình. \n\nChúng em xin chân thành cảm ơn các thầy các cô đã trang bị những kiến thức \n\nquý báu cho chúng em trong suốt quá trình học tập tại trường Đại học Sư phạm Kỹ \n\nthuật Hưng Yên. Đặc biệt là các thầy các cô trong khoa Công nghệ thông tinđã tận \n\ntình giảng dạy, chỉ bảo, trang bị cho chúng em những kiến thức cần thiết nhất trong \n\nsuốt quá trình học tập và nghiên cứu tại khoa, đã tạo mọi điều kiện thuận lợi giúp \n\nchúng em thực hiện đề tài này.  \n\nChúng em xin cảm ơn cô Nguyễn Thị Thanh Huệ đã tận tình hướng dẫn, chỉ \n\nbảo chúng em trong suốt thời gian thực hiện đề tài, giúp chúng em có thể hoàn \n\nthành đề tài này. \n\nMặc dù đã cố gắng nỗ lực thực hiện đề tài với quyết tâm cao nhưng chắc hẳn \n\nđề tài không thể tránh khỏi thiếu sót, kính mong sự đóng góp và hướng dẫn của các \n\nthầy cô. \n\n \n\n                                                        Chúng em xin chân thành cảm ơn! \n\n                                                            Hưng Yên, tháng 08 năm 2013 \n\n                                                               Nhóm sinh viên thực hiện \n\n                                                 Nguyễn Văn Thuấn \n\n                                                               Trần Quang Vinh \n\n  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\nNHẬN XÉT CỦA GIẢNG VIÊN HƯỚNG DẪN \n\n \n\n \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026..\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026..\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026..\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026..\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026.\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026..\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\nNHẬN XÉT CỦA GIẢNG VIÊN PHẢN BIỆN \n\n \n\n \n\n \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026.. \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \n\n  \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\nNHẬN XÉT CỦA GIẢNG VIÊN PHẢN BIỆN \n\n \n\n \n\n \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026.. \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \n\n  \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\nMỤC LỤC \n\nPHẦN 1: MỞ ĐẦU ................................................................................................. 1 \n\n1. Lý do chọn đề tài. ........................................................................................ 1 \n\n2. Khách thể và đối tượng nghiên cứu .................................................................. 1 \n\n3. Giới hạn và phạm vi nghiên cứu ...................................................................... 1 \n\n4. Mục đích nghiên cứu ....................................................................................... 1 \n\n5. Nhiệm vụ nghiên cứu ....................................................................................... 1 \n\n6. Phương pháp nghiên cứu ................................................................................. 1 \n\n7. Ý nghĩa lý luận và thực tiễn của đề tài ............................................................. 1 \n\nPHẦN 2: NỘI DUNG ............................................................................................. 2 \n\nCHƯƠNG 1: TỔNG QUAN VỀ TÓM TẮT VĂN BẢN ......................................... 2 \n\n1.1. Tổng quan. .................................................................................................... 2 \n\n1.1.1. Khái niệm. ............................................................................................. 2 \n\n1.1.2. Lịch sử phát triển của tóm tắt văn bản .................................................... 2 \n\n1.1.3. Phân loại các phương pháp tóm tắt văn bản. ........................................... 4 \n\n1.2. Mô hình tóm tắt văn bản ............................................................................... 6 \n\n1.2.1. Các phương pháp áp dụng trong pha phân tích. ...................................... 6 \n\n1.2.2. Các phương pháp áp dụng trong pha biến đổi ......................................... 8 \n\n1.2.3. Các phương pháp trong pha tổng hợp kết quả......................................... 9 \n\n1.3. Các phương pháp đánh giá ............................................................................ 9 \n\n1.3.1. Các phương pháp đánh giá trong .......................................................... 10 \n\n1.3.2. Các phương pháp đánh giá ngoài ......................................................... 11 \n\n1.4. Kết luận ...................................................................................................... 12 \n\nCHƯƠNG 2 : BÀI TOÁN TÓM TẮT VĂN BẢN  TIẾNG VIỆT ..................... 13 \n\n2.1. Một số hướng tiếp cận bài toán tóm tắt văn bản .......................................... 13 \n\n2.2. Đặc điểm tiếng Việt .................................................................................... 13 \n\n2.2.1. Đặc điểm chung ................................................................................... 14 \n\n2.2.2. Yếu tố ngoại lai trong từ tiếng Việt ...................................................... 15 \n\n2.2.3. Từ dừng. .............................................................................................. 15 \n\n2.2.4. Từ đồng nghĩa. ..................................................................................... 15 \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\n2.2.5. Đặc điểm chính tả ................................................................................ 17 \n\n2.3. Phương pháp cho bài toán tóm tắt văn bản tiếng Việt. ................................. 18 \n\n2.4. Kết luận. ..................................................................................................... 20 \n\nCHƯƠNG 3: ỨNG DỤNG PHƯƠNG PHÁP CẤU TRÚC ĐỂ TÓM TẮT VĂN \n\nBẢN TIẾNG VIỆT ............................................................................................... 22 \n\n3.1. Mô hình tóm tắt sử dụng phương pháp cấu trúc .......................................... 22 \n\n3.2. Tiền xử lý văn bản ...................................................................................... 23 \n\n3.3. Xử lý từ ...................................................................................................... 24 \n\n3.4. Xây dựng đồ thị liên kết. ............................................................................. 25 \n\n3.5. Sinh văn bản tóm tắt. .................................................................................. 28 \n\n3.6. Kết luận. ..................................................................................................... 34 \n\nCHƯƠNG 4: XÂY DỰNG ỨNG DỤNG MINH HỌA ......................................... 35 \n\n4.1. Một số giao diện chính của hệ thống. .......................................................... 35 \n\n4.1.1. Giao diện chính của chương trình. ........................................................ 35 \n\n4.1.2. Giao diện form quản lý từ điển từ dừng, từ đồng nghĩa. ....................... 35 \n\n4.1.3. Giao diện form tách từ, tách câu. .......................................................... 36 \n\n4.1.4. Giao diện form loại từ dừng, từ đồng nghĩa. ......................................... 36 \n\n4.1.5. Giao diện form xây dựng đồ thị liên kết. .............................................. 37 \n\n4.1.6. Giao diện form tóm tắt văn bản. ........................................................... 37 \n\n4.1.7. Giao diện form đánh giá độ chính xác. ................................................. 38 \n\n4.2. Một số module chính của chương trình. ...................................................... 38 \n\n4.2.1. Module tóm tắt văn bản. ....................................................................... 38 \n\n4.2.2. Module quản lý từ dừng, từ đồng nghĩa ................................................ 39 \n\n4.2.3. Module đánh giá hệ thống tóm tắt. ....................................................... 39 \n\n4.3. Kết luận. ..................................................................................................... 39 \n\nCHƯƠNG 5: THỰC NGHIỆM VÀ ĐÁNH GIÁ ............................................... 40 \n\n5.1. Môi trường thử nghiệm. .............................................................................. 40 \n\n5.2. Dữ liệu thử nghiệm ..................................................................................... 40 \n\n5.3. Phương pháp đánh giá. ................................................................................ 40 \n\n5.4. Kết quả thực nghiệm. .................................................................................. 43 \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\n5.4.1. Thử nghiệm xác định ngưỡng. .............................................................. 43 \n\n5.4.2. Đánh giá kết quả thử nghiệm đối với từng phiên bản. ........................... 44 \n\n5.5. Kết luận. ..................................................................................................... 48 \n\nPHẦN 3: KẾT LUẬN ........................................................................................... 49 \n\n1. Kết quả đạt được. ....................................................................................... 49 \n\n2. Những hạn chế của đề tài. .......................................................................... 49 \n\n3. Hướng phát triển của đề tài. ....................................................................... 49 \n\nTÀI LIỆU THAM KHẢO ..................................................................................... 51 \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\nDANH MỤC CÁC TỪ VIẾT TẮT \n\n \n\nTừ viết tắt Viết đầy đủ Ý nghĩa \n\nCSDL Cơ sở dữ liệu  \n\nIR Information Retrieval Trích xuất thông tin \n\nISF \nInverse sentence \n\nfrequency \n\nNghịch đảo tần số câu \n\nLRMM \nLeft Right Maximum \n\nMatching \n\nPhương pháp so khớp \n\ncực đại \n\nTF \nTerm frequency Tần số từ khóa \n\n \n\nWFST \n\nWeighted Finite State \n\nTransducer \n\nPhương pháp sử dụng \n\nbộ chuyển trạng thái \n\nhữu hạn có trọng số \n\n \n\n \n\n \n\n  \n\n \n\n \n\n \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\nDANH MỤC BẢNG BIỂU \n\nBảng 3.1: Bậc của các đỉnh sắp xếp theo thứ tự giảm dần của văn bản input1.txt... 30 \n\nBảng 3.2: Phân chia đoạn của văn bản input1.txt ................................................... 33 \n\nBảng 5.1: Đánh giá sự liên quan của văn bản tóm tắt và văn bản đối sánh. ............ 41 \n\nBảng 5.2: Kết quả đánh giá thử nghiệm với các ngưỡng khác nhau. ...................... 43 \n\nBảng 5.3: Đánh giá kết quả tóm tắt của Microsoft office 2007............................... 45 \n\nBảng 5.4: Kết quả thử nghiệm phiên bản 1. ........................................................... 45 \n\nBảng 5.5:  Kết quả thử nghiệm phiên bản 2. .......................................................... 46 \n\nBảng 5.6: Kết quả thử nghiệm phiên bản 3 ............................................................ 47 \n\nBảng 5.7: Bảng so sánh kết quả giữa MS Office 2007 với các phiên bản ............... 47 \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n \n\n \n\nDANH MỤC HÌNH ẢNH \n\nHình 1.1  Kiến trúc của hệ thống tóm tắt văn bản tự động ....................................... 6 \n\nHình  2.1  Đồ thị liên kết các câu trong văn bản. .................................................... 20 \n\nHình 3.1  Mô hình tóm tắt văn bản sử dụng phương pháp cấu trúc ........................ 22 \n\nHinh 3.2: Đồ thị liên kết của văn bản input1.txt ..................................................... 28 \n\nHình 4.1: Giao diện chính của chương trình. ......................................................... 35 \n\nHình 4.2: Giao diện quản lý từ dừng. ..................................................................... 35 \n\nHình 4.3: Giao diện tách từ tách câu ...................................................................... 36 \n\nHình 4.4: Loại bỏ từ dừng, từ đồng nghĩa trong văn bản ........................................ 36 \n\nHình 4.5: Giao diện form xây dựng đồ thị liên kết cho văn bản. ............................ 37 \n\nHình 4.6: Giao diện tóm tắt văn bản. ..................................................................... 37 \n\nHình 4.7: Đánh giá độ chính xác của văn bản tóm tắt ............................................ 38 \n\nHình 5.1: Tóm tắt văn bản input1.txt bởi con người. .............................................. 42 \n\nHình 5.2: Đồ thị hàm điều hòa với các ngưỡng. ..................................................... 44 \n\nHình 5.3: Đồ thị so sánh hàm điều hòa của MS Office 2007 với các phiên bản ...... 48 \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n1 \n\n \n\nPHẦN 1: MỞ ĐẦU \n\n1. Lý do chọn đề tài. \n\nNgày nay, với sự phát triển như vũ bão của công nghệ thông tin, Internet \n\ncũng như các dịch vụ trực tuyến, ngày càng có nhiều thông tin được tạo ra. Ta có \n\nthể truy cập các thông tin đó qua sách, báo, Internet và các phương tiện truyền \n\nthông. Hơn nữa, nhu cầu đọc, tìm kiếm và lưu trữ thông tin của con người cũng \n\nngày càng tăng lên. Tuy nhiên, với một lượng lớn thông tin như vậy thì người ta \n\nkhông thể nào có đủ thời gian và sức lực để đọc hết được chúng. Giải pháp là tóm \n\ntắt lại các văn bản đó, từ đó giúp tiết kiệm thời gian và công sức nhưng vẫn có thể \n\nđọc và xử lý được nhiều văn bản.  \n\nTóm tắt văn bản tự động đã bắt đầu được nghiên cứu từ những năm 50 của \n\nthế kỉ trước. Đã có nhiều công trình nghiên cứu về lĩnh vực này và có được những \n\nkết quả đáng kể. Tóm tắt văn bản đã được sử dụng trong các phần mềm xử lý văn \n\nbản (Microsoft Office Word\u2026), trong khai phá cơ sở dữ liệu văn bản (Oracle\u2026), \n\ntrong các ứng dụng tìm kiếm thông tin trực tuyến (hệ thống tìm kiếm Google, \n\nYahoo\u2026) và đều thu được những kết quả rất đáng khích lệ . Vì vậy, chúng tôi chọn \n\nđề tài: \u201cTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa\u201d \n\nnhằm nghiên cứu những vấn đề tổng quan về xử lý ngôn ngữ tự nhiên và một số \n\nphương pháp tóm tắt văn bản.  \n\n2. Khách thể và đối tượng nghiên cứu \n\nCác văn bản, các kỹ thuật tóm tắt văn bản, các phương pháp tóm tắt văn bản. \n\n3. Giới hạn và phạm vi nghiên cứu \n\nNghiên cứu các kỹ thuật tóm tắt văn bản dựa vào trích xuất câu. \n\nTóm tắt văn bản trên ngôn ngữ Tiếng Việt \n\n4. Mục đích nghiên cứu \n\nVới đề tài \u201cTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng \n\nminh họa\u201d sẽ trích xuất được các nội dung chính của văn bản mà người dùng nhập \n\nvào, giảm thời gian tìm kiếm thông tin trên đoạn văn bản dài của người đọc. \n\n5. Nhiệm vụ nghiên cứu\n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n1 \n\n \n\n \n\nVận dụng các kiến thức về tóm tắt văn bản để xây dựng ứng dụng minh họa \n\ntóm tắt văn bản. \n\n6. Phương pháp nghiên cứu \n\n- Nghiên cứu tài liệu trên internet, các kĩ thuật tóm tắt văn bản đã có. \n\n- Tham khảo ý kiến của các thầy cô trong trường. \n\n7. Ý nghĩa lý luận và thực tiễn của đề tài   \n\n- Ý nghĩa lý luận của đề tài \n\nChương trình cùng với lý thuyết tổng quan về Tóm tắt văn bản sẽ trở thành một \n\ntài liệu nghiên cứu, tham khảo nhanh, dễ hiểu, thiết thực cho người đọc. \n\n- Ý nghĩa thực tiễn của đề tài \n\nVề mặt ứng dụng sẽ cung cấp cho người dùng một phần mềm giúp cho người \n\nđọc có thể tóm tắt nội dung chính của văn bản một cách nhanh chóng, dễ dàng \n\nkhông tốn thời gian cần đọc cả đoạn văn bản dài. \n\n \n\n \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n2 \n\n \n\nPHẦN 2: NỘI DUNG \n\nCHƯƠNG 1: TỔNG QUAN VỀ TÓM TẮT VĂN BẢN \n\n1.1.  Tổng quan. \n\n1.1.1.  Khái niệm.  \n\nTóm tắt văn bản là một lĩnh vực của xử lý ngôn ngữ tự nhiên, đã được bắt \n\nđầu nghiên cứu từ những năm 50 của thế kỉ trước. Có nhiều định nghĩa về tóm tắt \n\nvăn bản:  \n\nĐịnh nghĩa tóm tắt văn bản là quá trình rút trích ra các thông tin quan trọng \n\ntừ một hoặc nhiều văn bản để tạo ra văn bản ngắn gọn cho mỗi hoặc nhóm người \n\ndùng, cho từng tác vụ hay nhiều tác vụ khác nhau. \n\nĐịnh nghĩa hệ thống tóm tắt văn bản là hệ thống đưa ra dạng biểu diễn ngắn \n\ngọn của thông tin đầu vào căn cứ theo yêu cầu của người dùng. \n\n Radev (2002) định nghĩa văn bản tóm tắt là văn bản được tạo từ một hoặc \n\nnhiều văn bản khác mà truyền tải được những thông tin quan trọng trong văn bản \n\ngốc nhưng có độ dài không quá ½ văn bản gốc (thường ngắn hơn đáng kể). \n\nTheo Partha Lal (2002)  thì tóm tắt văn bản là việc thể hiện nội dung văn bản dưới \n\ndạng giản lược một cách tự động nhằm đáp ứng yêu cầu nào đó từ phía người dùng.  \n\nĐỗ Phúc, Hoàng Kiếm (2006)  định nghĩa tóm tắt văn bản tự động là việc tìm \n\ncác ý chính của văn bản. Tựu chung lại, có ba đặc điểm quan trọng cần phải xem \n\nxét trong hệ thống tóm tắt văn bản:  \n\n1) Bản tóm tắt có thể được tạo ra từ một hoặc nhiều văn bản. \n\n2) Bản tóm tắt cần truyền tải các thông tin quan trọng.  \n\n3) Bản tóm tắt cần phải ngắn.  \n\n1.1.2. Lịch sử phát triển của tóm tắt văn bản  \n\nTóm tắt văn bản bắt đầu từ những năm cuối thập kỉ 1950 với nghiên cứu của \n\nLuhn (1958)  dựa trên tần số từ. Ý tưởng cơ bản của phương pháp tần số từ dựa trên \n\nkiến thức cho rằng tần số của từng từ trong văn bản là một độ đo hữu dụng để đánh \n\ngiá tầm quan trọng của chúng.  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n3 \n\n \n\nTiếp theo đó là phương pháp tóm tắt dựa trên vị trí của các câu trong văn bản \n\ncủa Baxendale (1958), và những nghiên cứu của Edmundson (1969)  về vị trí của \n\ncác câu trong văn bản và các từ/cụm từ mang ý nghĩa tổng quát (từ/cụm từ dấu hiệu). \n\nTheo đó, những câu bắt đầu và kết thúc của đoạn văn/bài viết hay những câu chứa \n\nnhững từ như \u201cimportant\u201d (đặc biệt), \u201cresult are\u201d (kết quả là), \u201cpaper introduce\u201d \n\n(bài báo giới thiệu về)\u2026 là những câu có ý nghĩa quan trọng.  \n\nĐầu những năm 1970, tiếp tục có những nghiên cứu với hướng tiếp cận \n\nngoài (sử dụng các cụm từ dấu hiệu) và được ứng dụng trong các phần mềm thương \n\nmại (Pollock và Zamora). \n\n Những năm 1980, phát triển nhiều nghiên cứu với nhiều hướng khác nhau, \n\nđặc biệt là hướng tiếp cận mức thực thể dựa trên trí tuệ nhân tạo như sử dụng script \n\n(Lehnert 1981), (DeJong 1982), các luật sản xuất và logic (Fum 1985), mạng ngữ \n\nnghĩa (Reimer và Hahn 1988), cũng như các hướng tiếp cận kết hợp (Rau 1989) hay \n\n(Aretoulaki 1994). Willam B. Cavnar (1994): biểu diễn văn bản dựa trên n-gram \n\nthay cho cách biểu diễn truyền thống bằng từ khoá.  \n\nChinatsu Anoe (1997) đã phát triển hệ DimSum để tóm tắt văn bản sử dụng \n\nxử lý ngôn ngữ tự nhiên và kĩ thuật thống kê dựa trên hệ thống tf-idf, sử dụng \n\nWordNet để xem xét ngữ nghĩa của từ và đề xuất một số kĩ thuật lượng giá.  \n\nJaine Carbonell (1998) đã tóm tắt văn bản bằng cách xếp hạng các câu trội \n\n(câu chứa các ý chính của văn bản) và rút ra các câu trội.  \n\nJade Goldstein (1999): phân loại tóm tắt dựa trên độ đo liên quan, phương \n\npháp sử dụng kết hợp giữa ngữ học, thống kê. Mỗi câu được đặc trưng bằng các đặc \n\ntính ngữ học và độ đo thống kê.  \n\nJ.Larocca Neto (2000) đã tạo tóm tắt văn bản dựa trên các dãy từ trong câu \n\nđược chọn theo hệ số tf, sau đó dùng kỹ thuật gom cụm (clustering) để tạo tóm tắt. \n\n Yoshio (2001) đã tạo tóm tắt văn bản tiếng Nhật. Có 2 phương pháp là rút \n\ncâu dựa trên từ khoá và rút câu dựa trên kiến trúc ngữ nghĩa trong đó có xây dựng \n\nđộ đo mối liên kết giữa hai từ.  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n4 \n\n \n\nHiện nay, một số nghiên cứu về xử lý ngôn ngữ tự nhiên cũng bước đầu \n\nđược áp dụng trong tóm tắt văn bản. Mặt khác, các nghiên cứu về tóm tắt đa văn \n\nbản, đa ngôn ngữ và tóm tắt đa phương tiện cũng bắt đầu phát triển. \n\n1.1.3. Phân loại các phương pháp tóm tắt văn bản. \n\n Có nhiều tiêu chí để phân loại các phương pháp tóm tắt văn bản, sau đây là \n\nmột số cách phân loại tiêu biểu:  \n\nCăn cứ vào dạng tóm tắt, ta có thể chia thành:  \n\n- Trích xuất (extract): bản tóm tắt hoàn toàn chứa các \u201cdãy từ\u201d được sao chép \n\nnguyên dạng từ văn bản nguồn. \u201cDãy từ\u201d ở đây có thể là cụm từ, câu hoặc đoạn văn. \n\nTuy nhiên, với dạng trích xuất thì văn bản tóm tắt thiếu cấu kết cần thiết, các câu \n\nđược trích ra có thể không phản ánh nội dung. Nói chung văn bản tóm tắt không \n\nđược \u201ctrơn\u201d do được \u201clắp ghép\u201d từ các câu, đoạn văn được trích ra. \n\n - Tóm tắt (abstracts): văn bản tóm tắt nói chung là không chứa các \u201cdãy từ\u201d \n\ntrong văn bản nguồn mà là được \u201cviết lại\u201d một cách tự động. Với dạng này, người ta \n\ncần nhiều kĩ thuật xử lý ngôn ngữ. Hiện tại, đây vẫn là vấn đề khó, chưa thể giải \n\nquyết được một cách triệt để. \n\n Căn cứ vào mức độ xử lý, có thể chia thành 2 dạng:  \n\n- Tiếp cận mức ngoài (surface-level): thông tin được miêu tả dưới dạng khái \n\nniệm về các đặc trưng nông (shallow feature). Các đặc trưng nông bao gồm các \n\nthuật ngữ (term) quan trọng qua thống kê (dựa vào tần số của các thuật ngữ trong \n\nvăn bản), các thuật ngữ quan trọng dựa vào vị trí, các thuật ngữ trong các cụm từ \n\ndấu hiệu hay các thuật ngữ trong câu truy vấn của người dùng. Kết quả là một bản \n\ntóm tắt dạng trích xuất (extract). \n\n - Tiếp cận mức sâu (deeper-level): ở mức này, bản tóm tắt có thể là dạng \n\ntrích xuất hoặc dạng tóm tắt (abstract) và cần phải sử dụng đến sinh tổng hợp ngôn \n\nngữ tự nhiên. Với dạng tiếp cận này, phải cần đến những phân tích về mặt ngữ \n\nnghĩa, chẳng hạn sử dụng hướng tiếp cận thực thể để xây dựng dạng biểu diễn của \n\ncác thực thể văn bản (đơn vị văn bản) và mối quan hệ giữa các thực thể rồi từ đó tìm \n\nra phần quan trọng. Mối quan hệ giữa các thực thể gồm quan hệ ngữ nghĩa như: \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n5 \n\n \n\nđồng nghĩa, trái nghĩa, nghĩa hẹp, nghĩa rộng\u2026, quan hệ cú pháp: dựa trên cây phân \n\ntích cú pháp và các mối quan hệ khác.  \n\nCăn cứ vào mục đích của bản tóm tắt, có thể chia làm 3 dạng: \n\n - Trình bày sơ lược (indicative): Đưa ra những thông tin ngắn gọn về chủ đề \n\nchính của văn bản. Dạng tóm tắt này thường được sử dụng trong các hệ thống tìm \n\nkiếm thông tin. Thông thường, độ dài của văn bản tóm tắt loại này chỉ từ 5 đến 10% \n\nđộ dài của toàn bộ văn bản.  \n\n- Tóm tắt cung cấp tin tức (Informative): Cung cấp các chủ đề con của toàn \n\nbộ văn bản, kiểu tóm tắt này có độ dài từ 20-30% văn bản gốc.  \n\n- Phê bình và đánh giá: Văn bản tóm tắt đưa ra những quan điểm của người \n\ntóm tắt về chủ đề được đưa ra. Tuy nhiên, kiểu tóm tắt này dường như vượt quá tầm \n\ncủa các hệ thống tóm tắt tự động hiện nay.  \n\nViệc phân loại tóm tắt dựa theo mục đích như trên không loại trừ lẫn nhau, \n\ncó thể một bản tóm tắt vừa có chức năng cung cấp tin tức lại vừa là kiểu trình bày \n\nsơ lược.  \n\nCăn cứ vào người sử dụng, có thể chia thành các dạng: \n\n- Tóm tắt chung: với kiểu tóm tắt này thì mọi chủ đề chính trong văn bản đều \n\ncó tầm quan trọng như nhau, văn bản tóm tắt hướng đến một cộng đồng đông đảo \n\nngười đọc. \n\n - Tóm tắt dựa trên câu truy vấn: kết quả trả về dựa trên câu truy vấn của \n\nngười dùng.  \n\n- Tóm tắt hướng đến người dùng hoặc chủ đề: văn bản tóm tắt đáp ứng nhu \n\ncầu của người dùng cụ thể hoặc chủ đề cụ thể nào đó.  \n\nCăn cứ vào số lượng văn bản tóm tắt:  \n\nTóm tắt đơn văn bản: thực hiện tóm tắt trên một văn bản hoặc tóm tắt đa văn \n\nbản: thực hiện tóm tắt trên nhiều văn bản khác nhau.  \n\nCăn cứ vào ngôn ngữ tóm tắt:  \n\nTóm tắt trên một ngôn ngữ hoặc tóm tắt trên nhiều ngôn ngữ khác nhau. \n\n \n\n  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n6 \n\n \n\n1.2.  Mô hình tóm tắt văn bản       \n\n \n\n \n\n                                        \n\n \n\n \n\n \n\n \n\nHình 1.1  Kiến trúc của hệ thống tóm tắt văn bản tự động  \n\nĐầu vào của hệ thống có thể là một hoặc nhiều tài liệu, văn bản hay các \n\nthông tin đa phương tiện như ảnh, âm thanh, video. Hệ thống tóm tắt hiện nay \n\nthường tập trung vào việc xử lý đầu là văn bản (có thể mở rộng cho các thông tin \n\ndạng khác). Điều quan trọng trong việc tóm tắt văn bản là mức độ nén, tức là tỉ lệ \n\ngiữa độ dài của văn bản tóm tắt so với văn bản gốc. Thông thường, tỉ lệ nén được \n\ntính dựa trên độ dài của văn bản, hoặc có thể tính bằng nội dung thông tin. Tỉ lệ nén \n\ncó thể dao động từ 10% đến 50% hoặc lớn hơn, nếu tỉ lệ nén giảm thì thông tin sẽ bị \n\nmất nhiều hơn. Văn bản tóm tắt có thể là văn bản liền mạch hoặc văn bản rời rạc. \n\nQuá trình tóm tắt có thể chia thành 3 pha: phân tích văn bản đầu vào, biến đổi, tổng \n\nhợp chỉnh sửa cho phù hợp với yêu cầu đầu ra. \n\n1.2.1. Các phương pháp áp dụng trong pha phân tích. \n\nTrong pha này, văn bản nguồn được phân tích để xác định các đơn vị ngữ liệu \n\nvà các đặc trưng của chúng, kết quả của pha này là đầu vào cho pha biến đổi. Các \n\nphương pháp áp dụng trong pha này bao gồm: \n\na) Phương pháp thống kê  \n\nCác phương pháp thuộc loại này sử dụng các số liệu thống kê về độ quan trọng \n\ncủa các từ, cụm từ, câu hoặc đoạn văn. Các phương pháp thống kê gồm: \n\n - Dựa vào vị trí:  \n\n+ Chủ đề, tiêu đề: tiêu đề hay chủ đề của các đoạn văn thường chứa các từ và \n\nngữ quan trọng. \n\n \n\nP\nhân tích\n\n \n\nB\niến đổi \n\nT\nổng h\n\nợ\np \n\nVăn bản được \n\ntóm tắt Văn bản gốc \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n7 \n\n \n\n + Câu ở đầu hoặc cuối đoạn: xác suất câu đầu đoạn hay câu cuối đoạn chứa \n\ný chính của cả đoạn là rất lớn, đặc biệt là câu đầu đoạn. Ngoài ra các đoạn đầu và \n\ncuối văn bản cũng quan trọng hơn các đoạn giữa.  \n\n+ Minh hoạ, chú thích: trong các câu chú thích, câu minh hoạ cho ảnh hay đồ \n\nthị thường chứa các thông tin quan trọng.  \n\n- Dựa vào cụm từ dấu hiệu: Các cụm từ dấu hiệu có đặc điểm thống kê rất tốt. \n\nSau các cụm từ này thường là các từ hay câu quan trọng. Có hai loại cụm từ dấu \n\nhiệu : thứ nhất là các cụm từ mang ý nhấn mạnh, sau cụm từ này đoạn văn quan \n\ntrọng; chẳng hạn \u201cnói chung là\u201d, \u201cđặc biệt là\u201d, \u201ctóm lại\u201d, \u201ccuối cùng thì\u201d, \u201ctrong \n\nbài viết này tôi muốn chỉ ra\u201d, \u201cbài viết nói về\u201d, \u201cnội dung gồm\u201d... Thứ hai là các \n\ncụm từ không quan trọng, sau cụm từ này là các thành phần không có nhiều giá trị \n\ntrong việc tóm tắt, chẳng hạn: \u201chiếm khi mà\u201d, \u201cbài này không nói đến\u201d, \u201ckhông thể \n\nnào\u2026\u201d  \n\n- Dựa vào thống kê tần suất từ: Độ quan trọng của từ phụ thuộc vào số lần \n\nxuất hiện của từ đó trong văn bản. Có thể dùng các kĩ thuật như tf-idf, tập thuật ngữ \n\nthường xuyên (frequent item set) để xác định tần suất từ. \n\nb) Phương pháp cấu trúc  \n\nCác phương pháp này sử dụng các mối liên hệ cấu trúc - ngữ pháp - ngữ \n\nnghĩa để xác định các đơn vị ngữ liệu quan trọng. Tư tưởng chính của các phương \n\npháp này là những đơn vị ngữ liệu nào có chứa các thành phần liên quan nhiều với \n\ncác thành phần khác sẽ có mức độ quan trọng cao. Việc đánh giá các mối quan hệ \n\nsẽ dựa trên các mạng ngữ nghĩa hoặc các quan hệ cú pháp.  \n\n- Phương pháp sử dụng quan hệ giữa câu, đoạn  \n\nPhương pháp này xác định mối quan hệ giữa các đoạn trong văn bản hay các \n\ncâu trong đoạn với nhau thông qua việc tính toán mức độ liên quan giữa chúng. Các \n\nđộ Cosine, Jaccard\u2026 được chọn để xác định độ tương đồng giữa các câu hay đoạn \n\nvăn bản đó. Sau đó, ta chọn ra đoạn hay câu có độ liên quan lớn nhất.  \n\n+ Phương pháp chuỗi từ vựng (lexical chains) \n\n Phương pháp liên kết từ vựng sử dụng các từ điển quan hệ từ vựng để xây \n\ndựng các chuỗi từ liên kết với nhau về mặt ngữ nghĩa. Sau khi xây dựng được chuỗi \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n8 \n\n \n\ncác từ vựng này, ta đánh giá độ mạnh của chúng và chọn ra những câu phù hợp. \n\nMorris và Hirst (1991) là những người đưa ra mô hình tính chuỗi từ vựng đầu tiên. \n\nChuỗi từ vựng không những chỉ dùng trong tóm tắt văn bản mà còn được coi là lý \n\nthuyết tổng quát của vấn đề ngữ nghĩa trong xử lý ngôn ngữ tự nhiên  \n\n+ Phương pháp liên kết tham chiếu (word coreferences) Phương pháp này \n\ngọi là phương pháp trích chọn trùng lặp (anaphora-based method). Theo phương \n\npháp này, các cụm trùng lặp được chọn ra, phân rã xem đâu là từ (cụm từ) tham \n\nchiếu và từ (cụm từ) được tham chiếu. Sau khi phân tách các cụm trùng lặp, chúng \n\nta tạo chuỗi các từ (cụm từ) tham chiếu đến cùng một từ được tham chiếu. Chuỗi dài \n\nnhất sẽ được coi là trọng tâm của đoạn, các câu chứa các từ trong chuỗi này có một \n\nđộ ưu tiên nào đó thì sẽ được chọn.  \n\nKết thúc pha phân tích sẽ là việc tổng hợp các chỉ số đánh giá độ quan trọng \n\ncủa các đơn vị ngữ liệu và thực hiện việc chọn các đơn vị ngữ liệu nào có độ quan \n\ntrọng lớn làm đầu vào cho pha sau. Có thể nhận thấy các phương pháp thống kê dễ \n\ncài đặt hơn các phương pháp cấu trúc. Việc cài đặt các phương pháp thống kê đơn \n\nthuần chỉ là các công thức toán học, còn để cài đặt các phương pháp cấu trúc thì lại \n\ncần thực hiện rất nhiều kĩ thuật về cấu trúc dữ liệu và thậm chí là các kĩ thuật trong \n\nlĩnh vực trí tuệ nhân tạo. \n\n1.2.2.  Các phương pháp áp dụng trong pha biến đổi \n\n Pha biến đổi có nhiệm vụ biến đổi đơn vị ngữ liệu được trích xuất trong pha phân \n\ntích như cụm từ, câu, đoạn văn. Thông thường pha biến đổi thực hiện rút gọn bản \n\nthân bên trong một câu, rồi có thể rút gọn đoạn mà không gây ảnh hưởng đến độ \n\nchính xác. Các phương pháp trong pha biến đổi gồm:  \n\na) Giản lược về cấu trúc câu. \n\n Lược bỏ các thành phần thừa, ít mang ý nghĩa trong câu, giúp cấu trúc câu \n\nđược thu gọn lại. Công việc này thường dựa trên phân tích cú pháp và phân tích ngữ \n\nnghĩa các thành phần trong câu. Áp dụng phân tích cú pháp chúng ta được các cấu \n\ntrúc của câu, qua đó ta có thể thay thế thành phần bằng những thành phần tương \n\nđương, ghép thành phần có nghĩa tương đương theo một luật nào đó. Phương pháp \n\nnày có thể làm câu ngắn gọn hơn, tuy nhiên khó bảo toàn được văn phong.  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n9 \n\n \n\nb) Giản lược về mặt ngữ nghĩa \n\nThay thế hoặc loại bỏ các từ, cụm từ có ý nghĩa cụ thể bằng những từ, cụm \n\ntừ ý nghĩa lúc này sẽ tổng quát, điển hình là: - Trừu trượng hoá khái niệm: thay thế \n\ncác khái niệm cụ thể bằng khái niệm chung. - Thay thế ngữ tương đương: thay thế \n\ncác ngữ đóng vai trò như nhau trong câu bằng một ngữ chung.  \n\n1.2.3.  Các phương pháp trong pha tổng hợp kết quả  \n\na) Phương pháp hiển thị phân đoạn  \n\nCác đơn vị ngữ liệu được trích xuất hay giản lược từ các pha trước được liên kết \n\nlại thành đoạn theo đúng thứ tự trong văn bản gốc, không thêm bớt từ nối và cũng \n\nkhông sắp xếp lại. Văn bản kết quả của phương pháp này có độ dễ đọc và dễ hiểu \n\nkém, thậm chí lủng củng vì các đơn vị ngữ liệu có thể bị mập mờ tham chiếu, không \n\ncó từ nối hoặc thừa từ.  \n\nb) Phương pháp hiển thị liên kết \n\n  Với phương pháp này, ta sẽ đưa thêm các thông tin bổ sung vào văn bản tóm \n\ntắt. Hai phương pháp thường được áp dụng trong sử dụng mẫu (template) ngữ liệu \n\nhuấn luyện (corpus).  \n\n1.3.  Các phương pháp đánh giá \n\n Đánh giá một bản tóm tắt là một công việc khó bởi không tồn tại một bản \n\ntóm tắt lý tưởng cho một (hoặc một tập) văn bản đưa ra. Hơn nữa, việc đánh giá nội \n\ndung tóm tắt cũng rất khó khăn. Trường hợp kết quả là một câu trả lời cho một câu \n\nhỏi, ta có thể xác định được câu trả lời đó đúng hay sai, nhưng trong các trường hợp \n\nkhác, thật khó trả lời liệu đầu ra là phải một kết quả đúng hay không? Thực tế luôn \n\ncó khả năng một hệ thống sinh ra một bản tóm tắt tốt nhưng lại sai khác với bản tóm \n\ntắt do người thực hiện. Bên cạnh đó, khi việc đánh giá được thực hiện bởi con người \n\nthì chi phí đánh giá sẽ rất cao. Mặt khác, tóm tắt văn bản còn liên quan đến tỉ lệ nén \n\nvăn bản, do đó, việc đánh giá bản tóm tắt cần phải quan tâm đến vấn đề này, khi đó \n\nđộ phức tạp và chi phí đánh giá sẽ tăng cao. Có nhiều kiểu đánh giá khác nhau tuỳ \n\nthuộc vào kiểu tóm tắt của hệ thống. Có thể là đánh giá trong (intrinsic) \u2013 tập trung \n\nvào chất lượng bản tóm tắt và đánh giá ngoài (extrinsic) \u2013 tập trung vào nhiệm vụ \n\n(McKeown 1998).  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n10 \n\n \n\nCác tiêu chí đánh giá:  \n\n- Độ mạch lạc (Coherence): đánh giá mức độ rõ ràng của văn bản tóm tắt, \n\ntính súc tích, khả năng có thể đọc và hiểu được của bài viết\u2026 \n\n- Độ hàm chứa thông tin (Informationess): tỉ lệ thông tin của văn bản gốc \n\ntrong văn bản tóm tắt.  \n\n- Độ liên quan (Relevance): xác định mức độ phù hợp của văn bản tóm tắt \n\nvới chủ đề cho trước (chủ đề có thể là một câu truy vấn).  \n\n- Độ dễ đọc hiểu (Reading Comprehence): một người được giao việc đọc văn \n\nbản kết quả, sau đó trả lời các câu hỏi, hệ thống sẽ phải cho điểm và từ đó đưa ra \n\nphần trăm những câu trả lời đúng. \n\n1.3.1.   Các phương pháp đánh giá trong  \n\na) So sánh với văn bản tóm tắt khác \n\n Ý tưởng cơ bản của phương pháp này là đem văn bản do hệ thống tóm tắt so \n\nsánh với các bản tóm tắt khác (có thể do hệ thống tóm tắt khác thực hiện hoặc do \n\ncon người thực hiện). Thông thường là đem so sánh với văn bản tóm tắt do con \n\nngười thực hiện. Việc so sánh giữa các bản tóm tắt này có thể do con người thực \n\nhiện hoặc có thể thực hiện tự động. Khi so sánh, có thể sử dụng một số độ đo sau: \n\n - Độ chính xác (Precision) và độ bao phủ (Recall). Tuy nhiên, 2 độ đo này \n\nchưa đủ để phân biệt các bản tóm tắt, các bản tóm tắt khác nội dung nhưng vẫn có \n\ncùng độ đo.  \n\n - Độ đo hạng câu (Sentence Rank): thay thế cho độ bao phủ, khi đó, một bản \n\ntóm tắt được đặc trưng bởi hạng của các câu trong các bản tóm tắt thích hợp. Hạng \n\ncủa các câu trong bản tóm tắt do hệ thống thực hiện và trong các bản tóm tắt dùng \n\nđể so sánh có thể tính bằng độ đo tương quan. Độ do này áp dụng đối với hệ thống \n\ntóm tắt dạng trích xuất. \n\n- Độ đo dựa trên nội dung (Content-Based): dựa trên sự tương tự về mặt từ \n\nvựng, và có thể áp dụng đối với cả 2 dạng tóm tắt. Tuy nhiên, độ đo này hữu dụng \n\nvới các bản tóm tắt trích xuất, hoặc với các bản tóm tắt dạng abstract nhưng có mức \n\nđộ cắt-dán cao (tức là văn bản tóm tắt được tạo bởi nhiều từ, cụm từ, câu nguyên \n\ndạng trong văn bản nguồn).  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n11 \n\n \n\nb) So sánh với văn bản nguồn \n\n Với phương pháp này, ta đem so sánh văn bản tóm tắt với văn bản nguồn để \n\nxác định mức độ hàm chứa thông tin của văn bản tóm tắt. Các độ đo dựa trên nội \n\ndung như trên có thể sử dụng để đánh giá. Paice và Jones (1993) đã đưa ra phương \n\npháp sử dụng thống kê để xác định mỗi thuật ngữ có phải là thuật ngữ trung tâm hay \n\nkhông phải thuật ngữ trung tâm. Tiếp đó, phân loại vào các nhóm Chính xác \n\n(Correct), không chính xác (Incorrect) và thiếu (Missing). \n\nHệ thống tóm tắt TIPSTER SUMMAC đánh giá các bản tóm tắt dạng Q&A \n\n(Question and Answer \u2013 Hỏi và trả lời) (Mani, Firmin, House, Chrzanowski, Klein, \n\nHirschman, Sundhem, Obrst (1998). Hệ thống này thay vì biểu diễn các khái niệm ở \n\nmức sâu thì chỉ xác định xem trong văn bản tóm tắt có hay không những khái niệm \n\nthen chốt trong văn bản nguồn. Theo phương pháp tóm tắt này thì ta đưa vào một \n\nvăn bản nguồn và một chủ đề, rồi thực hiện tóm tắt dựa trên chủ đề đó để trả lời cho \n\ncâu hỏi. Khi đó, ta có thể xác định xem câu trả lời có Chính xác (chứa câu trả lời \n\nđúng), hoặc Đúng một phần (chứa một phần câu trả lời) hay Thiếu (không chứa câu \n\ntrả lời). \n\n1.3.2.  Các phương pháp đánh giá ngoài \n\n Ý tưởng cơ bản của các phương pháp đánh giá ngoài là đánh giá tác dụng \n\ncủa bản tóm tắt với các nhiệm vụ khác nhau.  \n\n- Đánh giá mức độ liên quan (relevance): ý tưởng của phương pháp này là \n\nđưa ra một văn bản và một chủ đề, đánh giá xem mức độ liên quan của văn bản với \n\nchủ đề đó.  \n\n - Đánh giá mức độ đọc hiểu: trước tiên, một người được đọc các văn bản \n\ntóm tắt từ một hoặc nhiều văn bản, sau đó trả lời các câu hỏi kiểm tra. Hệ thống tự \n\nđộng tính điểm các câu trả lời và đánh giá tỉ lệ trả lời đúng. Nếu bản tóm tắt cho \n\nphép trả lời các câu hỏi giống như khi đọc toàn bộ văn bản nguồn thì bản tóm tắt đó \n\ncó khả năng cung cấp thông tin cao.  \n\nHovey và Marcu (1998) thực hiện đo mức độ cung cấp thông tin dựa trên \n\nviệc người ta có thể khôi phục lại các thông tin quan trọng trong văn bản khi đọc \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n12 \n\n \n\nbản tóm tắt của văn bản đó. Bằng thực nghiệm, tác giả tiến hành dựng lại văn bản \n\ngốc dựa trên việc đọc văn bản tóm tắt kết hợp phỏng đoán. \n\n1.4. Kết luận \n\nTrong chương này nhóm đồ án đã trình bày tổng quan về tóm tắt văn bản, \n\nđưa ra mô hình tóm tắt văn bản, các phương pháp sử dụng trong các pha của mô \n\nhình tóm tắt, các phương pháp đánh giá. \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n13 \n\n \n\nCHƯƠNG 2 : BÀI TOÁN TÓM TẮT VĂN BẢN  TIẾNG VIỆT \n\n2.1.  Một số hướng tiếp cận bài toán tóm tắt văn bản  \n\nTại Việt Nam hiện nay, lĩnh vực xử lý ngôn ngữ tự nhiên đã có được thành \n\ntích trong các bài toán phân tách từ, phân lớp và phân nhóm văn bản. Tuy nhiên bài \n\ntoán tóm tắt văn bản chưa có nhiều nghiên cứu và đa phần các công trình nghiên \n\ncứu đều sử dụng hoặc cải tiến các phương pháp dựa trên thống kê. \n\nCó thể kể đến một số công trình nghiên cứu như:  \n\nĐỗ Phúc, Hoàng Kiếm (2006) đã sử dụng cây hậu tố để phát hiện các dãy từ \n\nphổ biến trong các câu của văn bản, dùng từ điển đồng nghĩa và WordNet tiếng Việt \n\nđể giải quyết vấn đề nghĩa của từ, rồi dùng kĩ thuật gom cụm để gom các câu trong \n\nvăn bản (vector đặc trưng cho câu) và hình thành các vector đặc trưng cụm, sau đó \n\nrút ra câu chứa nhiều thành phần của các vector đặc trưng cụm.  \n\nVương Toàn (2007) đã đề xuất quy trình tóm tắt văn bản khoa học. Theo đó, \n\nđầu tiên cho máy đọc lướt văn bản và tìm xem có sẵn những đoạn văn mang tính \n\nchất \u201ctóm tắt\u201d hay không; tiếp theo là định chủ đề, xác định 4-5 tiêu đề đề mục hoặc \n\ntừ khoá để máy tự động chọn lưu tất cả những câu có các từ khoá đó.  \n\nCông trình nghiên cứu của Nguyễn Trọng Phúc, Lê Thanh Hương (2008) lại \n\nsử dụng cấu trúc diễn ngôn để tóm tắt văn bản. Theo đó, xây dựng cây cấu trúc diễn \n\nngôn biểu diễn mỗi quan hệ diễn ngôn giữa các đoạn văn bản (như các quan hệ \n\nnhân-quả, liệt kê, diễn giải,\u2026), rồi từ cây cấu trúc diễn ngôn này đánh giá được độ \n\nquan trọng của các đoạn văn bản và tiến hành trích xuất tạo ra tóm tắt nội dung cho \n\nvăn bản.  \n\nVới hướng tiếp cận tóm tắt đa văn bản dựa vào trích xuất câu, Trần Mai Vũ \n\n(2009) đã xây dựng đồ thị quan hệ thực thể để tăng cường tính ngữ nghĩa cho độ \n\ntương đồng câu để áp dụng cho tóm tắt đa văn bản tiếng Việt.  \n\nNguyễn Việt Cường (2007) đã sử dụng phương pháp phân đoạn văn bản dựa \n\ntrên chuỗi từ vựng kết hợp với phương pháp sinh tiêu đề dựa trên chủ đề của câu \n\nchủ đề nhằm thực hiện sinh tự động mục lục cho văn bản. \n\n2.2. Đặc điểm tiếng Việt  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n14 \n\n \n\n2.2.1. Đặc điểm chung  \n\nTiếng Việt là ngôn ngữ không biến hình từ và âm tiết tính tức là mỗi một \n\ntiếng (âm tiết) được phát âm tách rời nhau và được thể hiện bằng một chữ viết. Hai \n\nđặc trưng này chi phối toàn bộ tổ chức bên trong của hệ thống ngôn ngữ Việt và cần \n\nđược chú ý khi xử lý tiếng Việt trên máy tính.  \n\nTiếng là đơn vị cơ sở của cấu tạo ngữ pháp Việt Nam. Tiếng có thể có nghĩa, \n\nphai nghĩa và không có nghĩa; hơn nữa giữa 3 hiện tượng này có thể xuất hiện sự \n\nchuyển hoá lẫn nhau. Tiếng tham gia vào hệ thống ngôn ngữ với tư cách một thành \n\ntố trong các cơ chế cấu tạo từ (từ đơn, từ láy, từ ghép\u2026). Theo Từ điển tiếng Việt \u2013 \n\nHoàng Phê (1998) thì tiếng Việt hiện đại sử dụng 6718 âm tiết.  \n\nHiện nay, có nhiều tranh luận khi định nghĩa từ trong tiếng Việt. Theo Ngữ \n\npháp tiếng Việt thì xét ở phương diện ngữ pháp có thể định nghĩa từ là đơn vị nhỏ \n\nnhất mà có nghĩa và có thể hoạt động tự do (trong câu), từ là đơn vị trung tâm của \n\nngữ pháp Việt Nam, chi phối toàn bộ cú pháp tiếng Việt, đảm nhận và san sẻ các \n\nchức năng năng cú pháp trong câu và góp phần đưa câu vào các cấu tạo ngôn ngữ \n\nlớn hơn câu. Từ đây trở đi, khái niệm từ được dùng với nghĩa trên khi nói về tiếng \n\nViệt, còn đối với các ngôn ngữ châu Âu (ví dụ tiếng Anh), từ (word) vẫn được hiểu \n\ntheo nghĩa là \u201ccụm kí tự được ngăn cách bởi một hoặc nhiều dấu cách\u201d.  \n\nCụm từ là những kiến trúc gồm hai từ trở lên kết hợp \u201ctự do\u201d với nhau theo \n\nnhững quan hệ ngữ pháp hiển hiện nhất định và không chứa kết từ ở đầu. Cụm từ \n\nhoạt động trong câu mới mọi chức vụ ngữ pháp nhất định. Câu là sự tổng hợp của \n\ncác từ biểu thị một tư tưởng trọn vẹn. Ví dụ: Từ \u2018học\u2019 là một từ gồm một tiếng Từ \n\n\u2018đại học\u2019 là một từ gồm hai tiếng Cụm từ \u2018khoa học máy tính\u2019 gồm 2 từ hay 4 tiếng \n\nTrong các hệ thống xử lý ngôn ngữ trên các tiếng châu Âu, để xác định các từ đặc \n\ntrưng cho văn bản người ta có thể đơn giản lấy khoảng trắng làm ranh giới phân \n\ntách từ. Đối với tiếng Việt thì ta lại không thể làm tương tự bởi nếu ta chỉ dựa vào \n\nkhoảng trắng để phân tách thì kết quả ta chỉ có được các \u201ctiếng\u201d vô nghĩa và do đó \n\nđộ chính xác của hệ thống có thể sẽ rất thấp. Theo Ngữ pháp tiếng Việt - Nguyễn \n\nHữu Quỳnh (2001) thì tiếng Việt có đến 80% là các từ 2 tiếng. Từ tiếng Việt không \n\ncó hiện tượng biến hình (ngôn ngữ đơn lập) bằng những phụ tố mang ý nghĩa ngữ \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n15 \n\n \n\npháp bên trong từ như các ngôn ngữ Ấn \u2013 Âu. Dĩ nhiên, tiếng Việt cũng có một số \n\nhình thức biến hình như trường hợp thêm tiếng \u201csự  trước một động từ để biến nó \n\nthành danh từ tương đương, ví dụ như động từ \u201clựa chọn\u201d và danh từ \u201csự lựa chọn\u201d \n\nhay thêm tiếng \u201choá\u201d sau một danh từ để biến nó thành động từ tương đương như \n\ndanh từ \u201ctin học\u201d và động từ \u201ctin học hoá\u201d. Phụ tố cấu tạo từ tồn tại hiển nhiên hơn \n\nở cơ chế láy với những quy tắc ngữ âm khái quát chứ không hẳn là những dạng thức \n\ncụ thể đồng loạt (ở những từ láy có phần gốc là yếu tố còn rõ nghĩa, phần láy là yếu \n\ntố không rõ nghĩa).   \n\n2.2.2. Yếu tố ngoại lai trong từ tiếng Việt \n\n Tiếng Việt có các yếu tố ngoại lai thuộc gốc Hán, gốc Pháp, Anh trong đó \n\nyếu tố Hán vừa chiếm đa số vừa giữ vai trò khá quan trọng trong vốn từ và trong \n\ncấu tạo từ Việt.  Các yếu tố gốc Ấn \u2013 Âu đi vào tiếng Việt phải chịu áp lực rất mạnh \n\ncủa sự âm tiết hoá theo kiểu tiếng Việt. Sự Việt hoá về mặt âm tiết: − Cắt từ nhiều \n\nâm tiết thành những âm tiết rời; − Âm tiết hoá các tổ hợp phụ âm; − Mỗi âm tiết \n\nnhận một thanh điệu thích hợp; − Cấu tạo lại âm tiết theo các âm của tiếng Việt \n\n(như không chấp nhận l, h, s\u2026 ở cuối âm tiết).  \n\nNgoài ra, khi Việt hoá các từ ngoại lai Ấn \u2013 Âu có sự đơn tố hoá từ nhiều \n\nhình vị (từ tố), tức là một số từ vốn là đa tố ở ngôn ngữ Ấn \u2013 Âu vào tiếng Việt \n\nđược coi như từ đơn tố, ví dụ: sulơ, xuyết vôn tơ, mát xa\u2026; và có sự giản hoá về \n\nphát âm như sứ (đại sứ quán), lốp (vỏ bánh xe) từ enveloppe\u2026 \n\n2.2.3. Từ dừng. \n\nTừ dừng (stop-words) là các từ xuất hiện nhiều trong các văn bản mà thường \n\nthì không giúp ích trong việc phân biệt nội dung của các tài liệu. Do đó, khi xây \n\ndựng chương trình tóm tắt, cần tìm ra các từ dừng trong văn bản và loại bỏ chúng. \n\nViệc xác định các từ dừng trong văn bản được thông qua một từ điển từ dừng. Từ \n\ndừng bao gồm một số liên từ như: và, thì, là... \n\n2.2.4. Từ đồng nghĩa.  \n\nTheo Cơ sở ngôn ngữ học và tiếng Việt - Mai Ngọc Chừ (1997) từ đồng \n\nnghĩa là những từ tương đồng với nhau về nghĩa, khác nhau về âm thanh và có phân \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n16 \n\n \n\nbiệt với nhau về một vài sắc thái ngữ nghĩa hoặc sắc thái phong cách,... nào đó, \n\nhoặc đồng thời cả hai. Những từ đồng nghĩa với nhau tập hợp thành một nhóm gọi \n\nlà nhóm đồng nghĩa. Ví dụ: dễ, dễ dàng, dễ dãi là những nhóm từ đồng nghĩa. Thực \n\nra, từ đồng nghĩa không phải là những từ trùng nhau hoàn toàn về nghĩa. Chúng \n\nnhất định có những dị biệt nào đó bên cạnh sự tương đồng (mặc dù phát hiện sự dị \n\nbiệt đó không phải lúc nào cũng dễ dàng). Những từ đồng nghĩa với nhau không \n\nnhất thiết phải tương đương với nhau về số lượng nghĩa, tức là các từ trong một \n\nnhóm đồng nghĩa không nhất thiết phải có dung lượng nghĩa bằng nhau: Từ này có \n\nthể có một hoặc hai nghĩa, nhưng từ kia có thể có tới dăm bảy nghĩa. Thông thường, \n\ncác từ chỉ đồng nghĩa ở một nghĩa nào đó. Chính vì thế nên một từ đa nghĩa có thể \n\ntham gia vào nhiều nhóm đồng nghĩa khác nhau: Ở nhóm này nó tham gia với nghĩa \n\nnày, ở nhóm khác nó tham gia với nghĩa khác. Ví dụ: Từ \u201ccoi\u201d trong tiếng Việt là \n\nmột từ đa nghĩa. Tuỳ theo từng nghĩa được nêu lên để tập hợp các từ, mà \u201ccoi\u201d có \n\nthể tham gia vào các nhóm như: + coi \u2013 xem: coi hát \u2013 xem hát + coi \u2013 giữ: coi nhà \n\n\u2013 giữ nhà Trong mỗi nhóm từ đồng nghĩa thường có một từ mang nghĩa chung, \n\nđược dùng phổ biến và trung hoà về mặt phong cách, được lấy làm cơ sở để tập hợp \n\nvà so sánh, phân tích các từ khác. Từ đó gọi là từ trung tâm của nhóm. Ví dụ: Trong \n\nnhóm từ  \u201cyếu, yếu đuối, yếu ớt\u201d, từ \u201cyếu\u201d được gọi là từ trung tâm.  \n\nTuy nhiên, việc xác định từ trung tâm của nhóm không phải lúc nào cũng dễ \n\nvà đối với nhóm nào cũng làm được. Nhiều khi ta không thể xác định một cách dứt \n\nkhoát được theo những tiêu chí vừa nêu trên, mà phải dựa vào những tiêu chí phụ \n\nnhư: tần số xuất hiện cao (hay được sử dụng) hoặc khả năng kết hợp rộng. Chẳng \n\nhạn, trong các nhóm từ đồng nghĩa tiếng Việt như: hồi, thuở, thời; hoặc chờ, đợi; \n\nhoặc chỗ, nơi, chốn,... rất khó xác định từ nào là trung tâm. Với bài toán tóm tắt văn \n\nbản thì từ đồng nghĩa cũng có một ý nghĩa khá quan trọng bởi trong các câu, đoạn \n\nvăn trong văn bản có các từ đồng nghĩa hoặc gần nghĩa nhau và việc sử dụng từ \n\nđồng nghĩa sẽ làm nâng cao tính chính xác khi so sánh về độ tương đồng ngữ nghĩa \n\ngiữa các đơn vị văn bản.  \n\n \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n17 \n\n \n\n2.2.5.  Đặc điểm chính tả  \n\nĐặc điểm chính tả tiếng Việt có ý nghĩa quan trọng tiền xử lý dữ liệu văn bản. \n\nMột số đặc điểm chính tả tiếng Việt cần quan tâm như:  \n\n− Các tiếng đồng âm: như kĩ/kỹ, lí, lý\u2026 thường bị sử dụng lẫn nhau như: lý \n\nluận, lí luận, kĩ thuật, kỹ thuật\u2026  \n\n− Các từ địa phương: một số từ địa phương sử dụng thay cho các từ phổ \n\nthông, chẳng hạn: cây kiểng/cây cảnh, đờn/đàn, đậu phộng/lạc\u2026  \n\n− Vị trí dấu thanh: theo quy định đánh dấu tiếng Việt, dấu được đặt trên \n\nnguyên âm có ưu tiên cao nhất. Tuy nhiên, khi viết văn bản nhiều bộ gõ văn bản \n\nkhông tuân thủ theo đúng nguyên tắc trên nên xảy ra hiện tượng dấu được đặt ở các \n\nvị trí khác nhau, chẳng hạn: toán, tóan, thuý, thúy\u2026  \n\n− Cách viết hoa: theo quy định, chữ cái đầu câu và tên riêng phải viết hoa, \n\ntuy nhiên vẫn tồn tại một số cách viết tuỳ tiện.  \n\n− Phiên âm tiếng nước ngoài: hiện nay, vẫn còn nhiều tranh cãi giữa việc \n\nphiên âm tiếng nước ngoài thành tiếng Việt (Việt hoá), nên tồn tại nhiều cách viết \n\n(giữ nguyên gốc tiếng nước ngoài, phiên âm ra tiếng Việt), ví dụ: \n\nSingapore/Xin−ga−po. \n\n − Từ gạch nối: do cách viết dấu gạch nối tuỳ tiện, không phân biệt được \n\ngiữa nối tên riêng hay chú thích. − Kí tự ngắt câu: các kí tự đặc biệt như \u201c.\u201d, \u201c;\u201d, \u201c!\u201d, \n\n\u201c?\u201d, \u201c\u2026\u201d ngăn cách giữa các câu hoặc các vế câu trong câu ghép.  \n\nTóm tại, tiếng Việt là ngôn ngữ không biến hình từ và âm tiết tính, do đó, \n\nviệc phân loại từ (danh từ, động từ, tính từ\u2026) và ý nghĩa từ là vấn đề khó, cần có \n\nnhiều  nghiên cứu thêm. Do vậy, tiền xử lý văn bản (tách từ, tách đoạn, tách câu\u2026) \n\ntrở nên rất phức tạp với việc xử lý các hư từ, phụ từ, từ láy\u2026; hơn nữa, phương \n\nthức ngữ pháp chủ yếu là trật tự từ nên nếu áp dụng phương pháp tính xác suất xuất \n\nhiện của từ có thể không chính xác như mong đợi. Mặt khác, ranh giới xác định từ \n\nkhông phải là khoảng trắng, khiến cho việc tách từ trở nên khó khăn, dẫn đến khó \n\nkhăn cho các giai đoạn tiếp theo như kiểm lỗi chính tả, gán nhãn từ loại, thống kê \n\ntần suất từ\u2026 Như thế, các phương pháp xử lý ngôn ngữ đang áp dụng cho tiếng \n\nAnh không thể áp dụng trực tiếp cho tiếng Việt mà cần có sự thay đổi cho phù hợp.  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n18 \n\n \n\n2.3.  Phương pháp cho bài toán tóm tắt văn bản tiếng Việt. \n\n Trong IR, mỗi văn bản được biểu diễn dưới dạng vector, chẳng hạn như Di=(di1, \n\ndi2, \u2026, din) trong đó dik biểu diễn trọng số của từ Tk trong tài liệu Di. Tính toán độ \n\ntương tự giữa hai văn bản Di và Dj là Sim(Di, Dj) \u2013 theo các công thức tính độ tương \n\ntự. Nếu độ tương tự này đạt đến một ngưỡng đủ lớn thì ta nói rằng chúng có \u201cliên \n\nquan về mặt ngữ nghĩa\u201d, và ta có thể thiết lập một liên kết giữa hai văn bản này. Áp \n\ndụng phương pháp này vào việc tóm tắt văn bản tự động, thay vì tìm liên kết giữa \n\ncác văn bản, ta sẽ tìm liên kết trong nội bộ văn bản (liên kết giữa các câu trong văn \n\nbản). Sau khi xây dựng được đồ thị quan hệ, ta có được hình vẽ trực quan cấu trúc \n\ncủa văn bản. Từ cấu trúc này, ta có thể xây dựng văn bản tóm tắt bằng cách trích \n\nxuất ra các câu phù hợp. Trong việc xác định ngưỡng để quyết định hai câu trong \n\nvăn bản có quan hệ với nhau về mặt ngữ nghĩa hay không có một ý nghĩa quan \n\ntrọng, bởi lẽ ngưỡng này có thể là tốt cho một dạng văn bản nào đó nhưng lại không \n\ntốt cho văn bản khác.  Như vậy, trong quá trình xây dựng và đánh giá kết quả của \n\nchương trình tóm tắt văn bản, cần phải thực nghiệm với nhiều ngưỡng khác nhau để \n\nchọn ra một ngưỡng thích hợp. Khi áp dụng phương pháp cấu trúc văn bản này đối \n\nvới văn bản tiếng Việt do có những khác biệt đối với văn bản tiếng Anh nên cần \n\nphải có một số cải tiến để nâng cao độ chính xác. \n\nTrước hết, đối với việc phân tách từ vựng tiếng Việt. Có thể sử dụng các phương \n\npháp như:   \n\n+ Phương pháp so khớp cực đại hay còn gọi là phương pháp Left Right \n\nMaximum Matching (LRMM).  Theo đó, ta thực hiện duyệt một ngữ hoặc một câu \n\ntừ trái sang phải và chọn từ có nhiều âm tiết có mặt trong từ điển, rồi cứ thế tiếp tục \n\ncho đến khi hết câu.  \n\n+ Phương pháp sử dụng bộ chuyển trạng thái hữu hạn có trọng số WFST \n\n(Weighted Finite State Transducer) kết hợp với mạng Neural do Đinh Điền (2001) \n\nđưa ra. Với ý tưởng cơ bản là áp dụng WFST kết hợp với trọng số là xác suất xuất \n\nhiện của mỗi từ trong ngữ liệu. Dùng WFST để duyệt qua câu cần xét. Cách duyệt \n\ncó trọng số lớn nhất sẽ là cách từ được chọn. Ngoài ra sử dụng mạng Neural để khử \n\nnhập nhằng nếu có. Do việc xây dựng bộ tách từ khá phức tạp và nằm ngoài phạm \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n19 \n\n \n\nvi của luận văn này nên chúng tôi sử dụng bộ tách từ đã được viết sẵn và cung cấp \n\nmiễn phí để thực hiện bước tiền xử lý các văn bản.  \n\nTiếp theo đó là cần loại bỏ các từ dừng. Từ dừng (stop-words) là các từ xuất \n\nhiện nhiều trong các văn bản mà thường thì không giúp ích trong việc phân biệt nội \n\ndung của các tài liệu. Do đó, khi xây dựng chương trình tóm tắt, cần tìm ra các từ \n\ndừng trong văn bản và loại bỏ chúng. Việc xác định các từ dừng trong văn bản được \n\nthông qua một từ điển từ dừng. \n\nKhi đã loại bỏ các từ dừng, cần phải xác định tiếp các từ đồng nghĩa trong văn \n\nbản. Đối với tiếng Việt, do có một số lượng lớn các từ đồng nghĩa nên khi thực hiện \n\nđo độ tương tự giữa các câu trong văn bản, ta sử dụng thêm một từ điển đồng nghĩa \n\nđể xác định các từ có ý nghĩa tương đồng giữa các câu, để có thể nâng cao phần nào \n\nđộ chính xác. Trong chương tiếp theo, chúng tôi sẽ trình bày chi tiết việc xây dựng \n\nứng dụng tóm tắt văn bản và kĩ thuật sử dụng từ điển đồng nghĩa này. Ngoài ra, \n\ntrong bước tiền xử lý, các vấn đề như bảng mã, chính tả, dấu câu\u2026 cũng cần được \n\nxử lý để đảm bảo tính khách quan và chính xác cho các bước tiếp theo. Hình vẽ \n\ndưới đây mô tả một đồ thị quan hệ của các câu trong văn bản \u201cHỗ trợ 400 USD cho \n\nsinh viên mua laptop\u201d, bỏ qua các liên kết có độ tương tự dưới 0,2. \n\nSau khi đã có được đồ thị quan hệ giữa các câu trong văn bản, tiến hành duyệt \n\nđồ thị và chọn ra các câu quan trọng theo một số phương pháp sau:  \n\nCách 1. Dựa vào bậc của các nút trên đồ thị  \n\nBậc của một nút trên đồ thị là số lượng liên kết tới các nút khác. Khi một nút có \n\nbậc lớn thì câu tương ứng nút đó sẽ phủ một lượng lớn từ vựng  và có thể chứa chủ \n\nđề của nhiều câu khác.  \n\n+ Chọn n nút có bậc cao nhất trong đồ thị (với n là số câu cần chọn trong văn \n\nbản tóm tắt).  \n\n+ Sắp xếp các câu được chọn ra theo thứ tự xuất hiện trong văn bản gốc. \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n20 \n\n \n\n \n\nHình  2.1  Đồ thị liên kết các câu trong văn bản. \n\nCách 2. Duyệt theo chiều sâu \n\n + Chọn một nút quan trọng (thường chọn nút đầu tiên hoặc nút có bậc cao). \n\n+ Chọn nút tiếp theo tương tự nhất với nút trước đó, và cứ như thế. Khi đã duyệt \n\nhết mà vẫn chưa đủ số câu mong muốn, ta sử dụng tiếp cách 1 với các câu còn lại.  \n\nCách 3. Phân đoạn văn bản  \n\n+ Chia văn bản thành từng đoạn.  \n\n+ Áp dụng cách 1 cho mỗi đoạn, số đoạn của văn bản được chia phải đảm bảo \n\nđể chọn được ít nhất một câu trong mỗi đoạn. Trong chương này, chúng tôi đã trình \n\nbày về những hướng tiếp cận với bài toán tóm tắt văn bản tiếng Việt, đồng thời \n\ncũng nêu ra những đặc trưng cần chú ý của tiếng Việt và cuối cùng đưa ra cách tiếp \n\ncận của chúng tôi về việc sử dụng phương pháp cấu trúc để tóm tắt văn bản. \n\n2.4. Kết luận. \n\nTrong chương này nhóm đồ án đã trình bày về một số hướng tiếp cận bài \n\ntoán tóm tắt văn bản tiếng Việt. Đồng thời cũng đưa ra những đặc trưng quan trọng \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n21 \n\n \n\ncần chú ý của tiếng Việt dưới góc độ của lĩnh vực xử lý ngôn ngữ tự nhiên, từ đó \n\nlựa chọn phương pháp cho bài toán tóm tắt văn bản tiếng Việt. \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n22 \n\n \n\nCHƯƠNG 3: ỨNG DỤNG PHƯƠNG PHÁP CẤU TRÚC ĐỂ TÓM TẮT \n\nVĂN BẢN TIẾNG VIỆT \n\n3.1.  Mô hình tóm tắt sử dụng phương pháp cấu trúc \n\n \n\nHình 3.1  Mô hình tóm tắt văn bản sử dụng phương pháp cấu trúc \n\nTrong mô hình này, đầu vào là các văn bản tiếng Việt thuộc nhiều thể loại \n\nkhác nhau, và để cho đơn giản thì chúng tôi chi sử dụng các văn bản thuần. Các văn \n\nbản được xử lý qua 4 giai đoạn. \n\n1. Tiền xử lý  \n\nGiai đoạn này nhằm chuẩn hoá văn bản về bảng mã, các lỗi chính tả, các lỗi \n\nvề dấu câu, v.v\u2026 ; sau đó, sử dụng bộ tách từ để tách ra các từ và các câu.  \n\n2. Xử lý từ \n\nPha này nhằm mục đích loại bỏ các từ dừng dựa trên một từ điển từ dừng có \n\ntrước ; sau đó với mỗi từ trong câu, căn cứ vào từ điển đồng nghĩa để lập ra danh \n\nsách các từ đồng nghĩa.  \n\n3. Xây dựng đồ thị liên kết  \n\nTrong pha này, chúng tôi sử dụng kỹ thuật tf-idf để tính toán và vector hoá \n\ncác câu của văn bản, sau đó tính toán độ tương đồng giữa các vector này. Nếu độ \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n23 \n\n \n\ntương đồng giữa hai vector đạt đến một ngưỡng nào đó thì 2 câu sẽ được đưa vào đồ \n\nthị liên kết. Giá trị của ngưỡng này cũng sẽ được chúng tôi thử nghiệm và đánh giá \n\nhiệu lực.  \n\n4. Sinh văn bản tóm tắt \n\nTrong pha này, chúng tôi sử dụng 3 kỹ thuật ở mục 2.3 để tạo ra văn bản tóm \n\ntắt. Như vậy, mỗi văn bản đầu vào sẽ có 3 văn bản tóm tắt tương ứng với từng kỹ \n\nthuật sau đây: \n\n + Dựa vào bậc của các nút trên đồ thị. \n\n + Duyệt theo chiều sâu.  \n\n+ Phân đoạn văn bản. \n\n3.2. Tiền xử lý văn bản \n\n Nội dung của mỗi văn bản được lưu trữ trong một file text và được mã hoá \n\nbằng mã Unicode UTF-8.  \n\nTiếp đó, công cụ JvnTextPro-v.2.0  được sử dụng để phân tách ra các từ và \n\ncác câu. Kết quả ta sẽ thu được 2 file: một file chứa các từ được phân tách (dấu \u201c \u201d \n\nđược sử dụng để ngăn cách giữa các từ, các từ ghép được nối với nhau bằng dấu \n\ngạch dưới \u201c_\u201d), và một file chứa các câu (Các câu được phân cách bởi dấu \u201c .\u201d)  \n\nVí dụ: Đoạn văn bản sau: \n\n Trong thời gian gần đây, các diễn đàn công nghệ trên toàn thế giới luôn xôn \n\nxao vì lỗi ăng-ten của iPhone 4 cùng những hệ lụy xung quanh nó. Hàng loạt khách \n\nhàng đã phàn nàn, thậm chí đâm đơn kiện Quả táo vì bán sản phẩm lỗi. Không \n\nnhững vậy, tạp chí tiêu dùng uy tín Consumer Reports của Mỹ còn lên tiếng chê bai \n\niPhone 4 và khuyến cáo người dùng không nên mua sản phẩm này. Lỗi ăng-ten của \n\niPhone 4 khiến chủ tịch Steve Jobs mất ăn mất ngủ trong thời gian vừa qua. \n\n Khi tách từ xong ta sẽ được kết quả: \n\nTrong thời_gian gần_đây , các diễn_đàn công_nghệ trên toàn thế_giới luôn \n\nxôn_xao vì lỗi ăng - ten của iPhone 4 cùng những hệ_lụy xung_quanh nó . \n\nHàng_loạt khách_hàng đã phàn_nàn , thậm_chí đâm_đơn_kiện Quả táo vì \n\nbán sản_phẩm lỗi .Không những vậy , tạp_chí tiêu_dùng uy_tín Consumer Reports \n\ncủa Mỹ còn lên_tiếng chê_bai iPhone 4 và khuyến_cáo người_dùng không nên mua \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n24 \n\n \n\nsản_phẩm này .Lỗi ăng - ten của iPhone 4 khiến chủ_tịch Steve Jobs mất ăn \n\nmất_ngủ trong thời_gian vừa qua \n\nVà danh sách các câu: \n\nTrong thời gian gần đây, các diễn đàn công nghệ trên toàn thế giới luôn xôn \n\nxao vì lỗi ăng-ten của iPhone 4 cùng những hệ lụy xung quanh nó . \n\nHàng loạt khách hàng đã phàn nàn, thậm chí đâm đơn kiện Quả táo vì bán \n\nsản phẩm lỗi . \n\nKhông những vậy, tạp chí tiêu dùng uy tín Consumer Reports của Mỹ còn \n\nlên tiếng chê bai iPhone 4 và khuyến cáo người dùng không nên mua sản phẩm này . \n\nLỗi ăng-ten của iPhone 4 khiến chủ tịch Steve Jobs mất ăn mất ngủ trong \n\nthời gian vừa qua . \n\nKết quả của bước tiền xử lý này sẽ là đầu vào cho bước xử lý từ tiếp theo.  \n\n3.3. Xử lý từ \n\nPha này có đầu vào là tập tin văn bản đã được thêm dấu phân tách từ ở bước \n\ntrên và có nhiệm vụ xác định các câu. Ranh giới để phân định các câu là các dấu kết \n\nthúc câu bao gồm: dấu chấm câu (.), dấu hỏi chấm (?), dấu chấm than (!) và dấu ba \n\nchấm (...). Đồng thời, chương trình có nhiệm vụ xác định các từ, ranh giới để xác \n\nđịnh là dấu \u201c \u201d. Thuật toán dưới đây thể hiện việc chọn ra các từ, các câu, các từ \n\nđồng nghĩa và loại bỏ các từ dừng. \n\nThuật toán 1 \n\n Input: Tập tin văn bản đã tách từ.  \n\nOutput: Tập các từ T, Tập các câu Cau.  \n\n            1. Mở tập tin văn bản \n\n                ST=Nội dung file \n            2. Tách ra các câu \n\n                n=0; //Đếm số lượng câu \n                k=1; \n                while k<length(st) \n                { \n                    if(ST(k)=Dấu kết thúc câu) \n                    { \n                        n=n+1; \n                        cau()=câu kết thúc tại vị trí k; \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n25 \n\n \n\n                    } \n                    k++; \n                } \n            3. Tách ra các từ \n\n                k=1; \n                while k<length(st)  \n                { \n                    if ST(k)= ' '  \n                    {   \n                        word=Chọn ra từ kết thúc tại k;   \n                        Chuẩn hoá word; {Loại bỏ dấu cách, các kí hiệu vô ích, chuyển về chữ \nthường} \n                        Đưa word Tập từ Term; \n                        Else Đưa word vào Tập từ T; \n                    } \n                    k=k+1; \n                } \n            4. return T, Cau; \n\n3.4. Xây dựng đồ thị liên kết. \n\nPha này có nhiệm vụ xây dựng đồ thị liên kết giữa các câu trong văn bản với \n\nđầu vào là danh sách các câu và các từ đã được xử lý ở pha trước đó. Ta thực hiện \n\nvector hoá các câu trong văn bản và thực hiện tính toán độ tương đồng giữa 2 câu \n\nbất kì trong văn bản. Trong mô hình không gian vector, ta coi mỗi văn bản như một \n\nvector (hay một điểm) trong không gian Euclide nhiều chiều, trong đó mỗi chiều là \n\ntừ. Có 3 cách để biểu diễn vector tuỳ thuộc vào kiểu của các thành phần trong \n\nvector: nhị phân, tần số từ tf, và tf-isf. \n\nGiả sử văn bản cần tóm tắt có n câu được đánh số là cau1, cau2,\u2026, caun và m \n\ntừ t1, t2,\u2026, tm gọi nij là số lần xuất hiện của từ ti trong câu cauj. Trong phương pháp \n\nnày sẽ sử dụng cách biểu diễn tf-idf để biểu diễn các vector văn bản. \n\n Mỗi thành phần thứ i của vector văn bản cauj được tính bằng: \n\n \n\nTrong đó: -  , j=  \n\n- Giá trị TF(ti , cauj) được tính bằng nhiều cách: \n\n                 + Tính bằng tổng số lần xuất hiện của các từ trong tài liệu: \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n26 \n\n \n\n                  TF(ti ,cauj)=          (1) \n\n       + Tính bằng số lần xuất hiện lớn nhất của các từ. \n\n                   TF(ti ,cauj)=              (2) \n\n                  + Tính bằng ln số lần xuất hiện số từ: \n\n                  TF(ti ,cauj )=        (3) \n\nTrong cài đặt thử nghiệm, công thức (3) được sử dụng để tính giá trị  TF(ti,cauj). \n\n- Với mỗi từ ti giá trị ISF(ti) được tính bằng tỉ lệ thức của các câu mà xuất \n\nhiện từ ti với tổng số câu có được. \n\nGọi S là tập hợp các câu Sti là tập hợp các câu có chứa từ ti. \n\nS=  \n\nSti ={cau j | nij >0} \n\nGiá trị ISF(ti) có thể tính theo một số cách: \n\n+ Tính bằng thương số của |S| và | Sti |: \n\n                                               \n\n+ Tính bằng hàm logarit: \n\n                                               \n\nSau khi vector hoá các câu trong văn bản, ta tính độ tương quan giữa từng cặp câu \n\nvới nhau theo công thức tính độ tương đồng Cosine đã nêu ở trên. Khi đó, độ tương \n\nđồng giữa 2 câu caui và cauj bất kì được tính bằng:  \n\n \n\nTrong đó: sim(caui,cauj) là độ tương tự của 2 câu caui và cauj. \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n27 \n\n \n\n m: là số từ của 1 câu trong văn bản. \n\nTiếp đó ta xây dựng đồ thị liên kết giữa các câu trong văn bản. Đồ thị được biểu \n\ndiễn bằng một ma trậ D như sau:  \n\n \n\nTrong đó: ngưỡng là một ngưỡng được cho trước và được tính toán bằng thực \n\nnghiệm đối với các loại văn bản. Trong thử nghiệm này của chúng tôi chọn ngưỡng \n\nbằng 0,4. \n\nThuật toán 2: Xây dựng đồ thị liên kết. \n\nInput: Tập từ T, số lượng từ m, tập các câu Cau, số lượng câu n. \n\nOutput: Đồ thị liên kết các câu. D(i,j), i=1..m, j=1..n \n\n1.{Tính tf-isf}  \n\nfor i = 1 to m  \n\n     for j = 1 to n    \n\nif T(i)=T(j) then N(i,j) = N(i,j) + 1;  \n\n{Tính TF}  \n\nfor i = 1 to m   \n\n     for j = 1 to n begin   \n\n tf(i,j) = 0;   \n\n if N(i,j) > 0 then tf(i,j) = 1 + ln(1+ln(N(i,j)))   \n\n     end;  \n\n{Tính ISF}  \n\nfor i = 1 to m begin  \n\ncount = 0; \n\nfor j = 1 to n   \n\n      if N(i,j) > 0 then count = count + 1;  \n\n isf(i) = ln((1+n)/count) \n\n end;  \n\n2.{Tính toán độ tương đồng}  \n\nfor i = 1 to m   \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n28 \n\n \n\nfor j = 1 to n begin    \n\n        sim = cos(caui, cauj)   \n\n         if  sim > threshold then D(i,j) = sim;  \n\n return D(i,j) \n\n \n\nHinh 3.2: Đồ thị liên kết của văn bản input1.txt \n\n \n\n3.5.  Sinh văn bản tóm tắt. \n\nGiả sử văn bản cần tóm tắt có độ dài là p% độ dài của văn bản gốc. \n\nChúng tôi xây dựng thủ tục duyệt đồ thị để chọn ra những câu quan trọng theo 3 \n\nphương pháp: \n\na) Phương pháp 1. Dựa vào bậc của các nút trên đồ thị.  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n29 \n\n \n\nBước 1: Tính bậc của mỗi nút trong đồ thị (bậc được tính bằng số liên kết của nút \n\nvới các nút khác).  \n\nBước 2: Sắp xếp các nút theo thứ tự bậc giảm dần.  \n\nBước 3: Chọn ra các nút có bậc cao nhất, ngừng chọn khi số câu đủ yêu cầu.  \n\nThuật toán 3 \n\nInput: Đồ thị liên kết D(i,j), tỉ lệ nén p%, số câu n. \n\nOutput: Tập các câu được chọn Selection.  \n\n1. {Tính số câu cần chọn}  \n\nNumberOfSent = Round(n * p);  \n\n2. {Tính bậc của các nút}  \n\nfor i = 1 to n begin   \n\nDegree(i) = 0;   \n\nfor j = 1 to n    \n\n if D(i,j) <> 0 then Degree(i) = Degree(i) + 1; \n\nend;  \n\n3. Sắp xếp Degree(i), i = 1..n theo chiều giảm dần  \n\n4. {Chọn ra các câu}  \n\nfor i = 1 to NumberOfSent  \n\n selection(i) = Số thứ tự của câu tương ứng;  \n\n5. Sắp xếp selection theo chiều tăng dần; \n\n6. return selection; \n\nVí dụ: Với văn bản input1.txt, tỉ lệ nén được chọn là 20%, số câu cần chọn ra là 5. \n\nTheo thuật toán 3, thứ tự của các nút được sắp xếp theo bậc giảm dần là (bỏ qua các \n\nnút có bậc bằng 0: \n\n \n\n \n\n \n\n \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n30 \n\n \n\nĐỉnh Bậc  Đỉnh Bậc \n\n \n\nĐỉnh Bậc \n\n \n\nĐỉnh Bậc \n\n11 14 17 9 9 4 7 2 \n\n8 13 23 9 18 4 14 2 \n\n10 13 12 8 21 4 15 2 \n\n1 12 22 8 6 3 24 1 \n\n4 12 20 7 13 3 \n\n 2 10 0 6 16 3 \n\n3 10 5 5 19 3 \n\nBảng 3.1: Bậc của các đỉnh sắp xếp theo thứ tự giảm dần của văn bản input1.txt \n\nKết quả các câu được chọn ra là: 11, 8, 10, 1, 4 \n\nVăn bản tóm tắt là:  \n\n[1]Những người này khuyến cáo Quả táo cần nhanh chóng đưa ra biện pháp khắc \n\nphục hậu quả để lấy lại lòng tin từ khách hàng, cho dù chi phí bỏ ra sẽ rất lớn. \n\n[4]Không những vậy, tạp chí tiêu dùng uy tín Consumer Reports của Mỹ còn lên \n\ntiếng chê bai iPhone 4 và khuyến cáo người dùng không nên mua sản phẩm này. \n\n[8]Tuy nhiên, ít lâu sau, \"Quả táo\" lại khẳng định lỗi sóng yếu là do phần cứng và \n\nsẽ mất rất nhiều thời gian để khắc phục khi mà hãng đã bán ra một số lượng lớn sản \n\nphẩm. \n\n[10]Không những thế, họ còn buộc Quả táo phải bồi thường chi phí mua điện thoại, \n\nkể cả những tổn thất phát sinh khác mà khách hàng phải gánh chịu. \n\n[11]Từ khi xảy ra lỗi mất sóng trên iPhone 4, các chuyên gia quốc tế cùng nhiều \n\ntrang công nghệ lớn như Engadget, Cnet\u2026 đã vào cuộc nhằm tìm ra nguyện nhân \n\nsự việc. \n\nb) Phương pháp 2. Duyệt theo chiều sâu  \n\nBước 1: Chọn nút bắt đầu là nút đầu tiên (theo thứ tự xuất hiện trong văn bản).  \n\nBước 2: Duyệt đồ thị theo chiều sâu bắt đầu từ nút xuất phát, chọn các nút theo số \n\nbậc cao nhất. Quá trình duyệt dừng lại khi nút cuối cùng được chọn không liên kết \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n31 \n\n \n\nvới nút nào về sau.                                                                                                                         \n\nBước 3: Nếu vẫn chưa đủ số câu cần thiết, thực hiện phương pháp 1 đối với các câu \n\ncòn lại chưa được chọn.  \n\nThuật toán 4 \n\nInput: Đồ thị liên kết D(i,j), tỉ lệ nén p%, số câu n.  \n\nOutput: Tập các câu được chọn Selection.  \n\n1. Tính số câu cần chọn;  \n\n2. Tính bậc của các nút;  \n\n3. {Chọn nút đầu tiên}  \n\nCount = 1; selected = 1;  \n\nSelection(count) = selected;  \n\n4. {Tạo danh sách kề với nút được chọn}  \n\nfor i = 1 to n   \n\nif (D(selected,i) > 0 then Đưa i vào danh sách kề;  \n\n5. {Chọn nút có bậc cao nhất trong danh sách kề}  \n\nSelected = nút có bậc cao nhất trong danh sách kề;  \n\nCount = Count + 1;  \n\nQuay lại bước 4.  \n\n6. {Nếu chưa đủ số câu} \n\n If count < NumberOfSent then begin   \n\nfor i = 1 to n    \n\nif sent(i) chưa được chọn then Đưa i vào Danh sách còn lại;   \n\nChọn (NumberOfSent \u2013 count) câu trong Danh sách còn lại;  \n\n7. Sắp xếp selection theo chiều tăng dần;  \n\n8. return selection; \n\nVới ví dụ tệp input1.txt áp dụng thuật toán 4 các câu được chọn là: 11, 8, 10, 4, 1 \n\nVăn bản được tóm tắt: \n\n[1]Những người này khuyến cáo Quả táo cần nhanh chóng đưa ra biện pháp khắc \n\nphục hậu quả để lấy lại lòng tin từ khách hàng, cho dù chi phí bỏ ra sẽ rất lớn. \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n32 \n\n \n\n[4]Không những vậy, tạp chí tiêu dùng uy tín Consumer Reports của Mỹ còn lên \n\ntiếng chê bai iPhone 4 và khuyến cáo người dùng không nên mua sản phẩm này. \n\n[8]Tuy nhiên, ít lâu sau, \"Quả táo\" lại khẳng định lỗi sóng yếu là do phần cứng và \n\nsẽ mất rất nhiều thời gian để khắc phục khi mà hãng đã bán ra một số lượng lớn sản \n\nphẩm. \n\n[10]Không những thế, họ còn buộc Quả táo phải bồi thường chi phí mua điện thoại, \n\nkể cả những tổn thất phát sinh khác mà khách hàng phải gánh chịu. \n\n[11]Từ khi xảy ra lỗi mất sóng trên iPhone 4, các chuyên gia quốc tế cùng nhiều \n\ntrang công nghệ lớn như Engadget, Cnet\u2026 đã vào cuộc nhằm tìm ra nguyện nhân \n\nsự việc. \n\nc) Phương pháp 3. Phân đoạn văn bản  \n\nBước 1: Tách văn bản thành những phân đoạn, căn cứ vào độ dài của văn bản và tỉ \n\nlệ nén p%.  \n\nBước 2: Áp dụng phương pháp 1 đối với từng phân đoạn, ở mỗi phân đoạn chọn ít \n\nnhất một câu. Các câu còn lại được chọn là các nút có bậc cao trong các phân đoạn. \n\nQuá trình chọn sẽ dừng lại khi đạt đủ số câu cần thiết.  \n\nThuật toán 5  \n\nInput: Đồ thị liên kết D(i,j), tỉ lệ nén p%, số câu n.  \n\nOutput: Tập các câu được chọn Selection.  \n\n1. Tính số câu cần chọn;  \n\n2. Tính bậc của các nút;  \n\n3. {Tính toán số đoạn, số câu chọn mỗi đoạn}  \n\nSố_câu = 1;  \n\nSố_đoạn = n/ Số_câu; \n\nwhile NumberOfSeg > số_đoạn begin                 \n\n Số_câu = Số_câu + 1                  \n\nSố_câu = n/ Số_câu  \n\nend;  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n33 \n\n \n\nsố_câu_mỗi_đoạn = số_đoạn / Số_câu \n\n4. {Chọn ra các câu trong từng đoạn} \n\n First = 1; Last = Số_câu;  \n\nwhile last < n begin \n\nSắp xếp bậc của các nút trong đoạn [First, Last];   \n\nfor i = 1 to SelectSentPerSeg chọn câu có bậc lớn nhất;  \n\n First = Last + 1;   \n\nLast = Last + Số_câu;  \n\nend;  \n\n5. Sắp xếp selection theo chiều tăng dần;  \n\n6. return selection; \n\nVới văn bản input1.txt có 25 câu, với tỷ lệ nén là 20% số câu cần trích xuất ra là 5. \n\nVì vậy văn bản sẽ được chia làm 5 đoạn nhỏ. Ta chọn trong mỗi đoạn 1 câu có số \n\nbậc lớn nhất. \n\nĐoạn 1  Đoạn 2  Đoạn 3  Đoạn 4  Đoạn 5 \n\nĐỉnh Bậc  Đỉnh Bậc  Đỉnh Bậc \n\n \n\nĐỉnh Bậc \n\n \n\nĐỉnh Bậc \n\n0 6 5 5 10 13 15 2 20 7 \n\n1 12 6 3 11 14 16 3 21 4 \n\n2 10 7 2 12 8 17 9 22 8 \n\n3 10 8 13 13 3 18 4 23 9 \n\n4 12 9 4 14 2 19 3 24 1 \n\n Bảng 3.2: Phân chia đoạn của văn bản input1.txt \n\nThứ tự các câu sau khi phân đoạn là: 1, 8, 11, 17, 23 \n\n[1]Những người này khuyến cáo Quả táo cần nhanh chóng đưa ra biện pháp khắc \n\nphục hậu quả để lấy lại lòng tin từ khách hàng, cho dù chi phí bỏ ra sẽ rất lớn. \n\n[8]Tuy nhiên, ít lâu sau, \"Quả táo\" lại khẳng định lỗi sóng yếu là do phần cứng và \n\nsẽ mất rất nhiều thời gian để khắc phục khi mà hãng đã bán ra một số lượng lớn sản \n\nphẩm.                                                                                                                       \n\n[11]Từ khi xảy ra lỗi mất sóng trên iPhone 4, các chuyên gia quốc tế cùng nhiều \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n34 \n\n \n\ntrang công nghệ lớn như Engadget, Cnet\u2026 đã vào cuộc nhằm tìm ra nguyện nhân \n\nsự việc. \n\n[17]Tuy nhiên chính điều đó mới thể hiện Quả táo là một tập đoàn đẳng cấp và luôn \n\nđặt chất lượng sản phẩm lên hàng đầu. \n\n[23]Trên thực tế, nếu giải pháp này được thực hiện, Apple sẽ chỉ thiệt hại 1 \n\nUSD/chiếc. \n\n3.6. Kết luận. \n\nTrong chương này, chúng tôi đã giới thiệu mô hình tóm tắt văn bản sử dụng \n\nphương pháp cấu trúc và trình bày chi tiết về việc xây dựng chương trình tóm tắt \n\nvăn bản. Nhằm mục đích kiểm nghiệm tác dụng của bộ tách từ tiếng Việt, từ điển \n\nđồng nghĩa, chúng tôi đã cài đặt 3 phiên bản cho ứng dụng này. \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n35 \n\n \n\nCHƯƠNG 4: XÂY DỰNG ỨNG DỤNG MINH HỌA \n\n4.1. Một số giao diện chính của hệ thống. \n\n4.1.1. Giao diện chính của chương trình. \n\n \n\nHình 4.1: Giao diện chính của chương trình. \n\n4.1.2. Giao diện form quản lý từ điển từ dừng, từ đồng nghĩa. \n\n \n\nHình 4.2: Giao diện quản lý từ dừng. \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n36 \n\n \n\n4.1.3. Giao diện form tách từ, tách câu. \n\n \n\nHình 4.3: Giao diện tách từ tách câu \n\n4.1.4. Giao diện form loại từ dừng, từ đồng nghĩa. \n\n \n\nHình 4.4: Loại bỏ từ dừng, từ đồng nghĩa trong văn bản \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n37 \n\n \n\n4.1.5. Giao diện form xây dựng đồ thị liên kết. \n\n \n\nHình 4.5: Giao diện form xây dựng đồ thị liên kết cho văn bản. \n\n4.1.6. Giao diện form tóm tắt văn bản. \n\n \n\nHình 4.6: Giao diện tóm tắt văn bản. \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n38 \n\n \n\n4.1.7. Giao diện form đánh giá độ chính xác. \n\n \n\nHình 4.7: Đánh giá độ chính xác của văn bản tóm tắt \n\n4.2. Một số module chính của chương trình. \n\n4.2.1. Module tóm tắt văn bản. \n\nĐầu vào: đầu vào của module là một văn bản dạng tệp text được công cụ \n\nJvnTextPro tách thành 2 file một file chứa các câu được ngăn cách bởi dấu chấm (.) \n\nvà một file lưu tập các từ với các từ ghép được ghép lại với nhau bởi dấu gạch dưới. \n\nĐầu ra: một đoạn văn ngắn gọn được tóm tắt từ tệp văn bản đầu vào với một tỷ lệ \n\nnén nhất định. \n\nQuá trình xử lý: \n\n- Đối với phiên bản 1: không sử dụng bộ tách từ tách câu, không sử dụng \n\ntừ điển từ dừng, từ đồng nghĩa. Từ tệp văn bản gốc tách ra các từ dựa vào \n\nkhoảng trắng. Tách tập các câu dựa vào dấu chấm. Sau đó tính tần số xuất \n\nhiện của các từ trong văn bản, tính độ tương tự của các câu và cho vào đồ \n\nthị liên kết. Tính bậc của các câu để tìm ra câu quan trọng, tùy vào tỷ lệ \n\nnén là bao nhiêu phần trăm để lấy ra số câu tương ứng. \n\n- Đối với phiên bản 2: sử dụng bộ tách từ tách câu. Chọn đầu vào là tệp \n\nvăn bản .txt dùng công cụ JvnTextPro để tách ra tập các từ và các câu. \n\nTính tần số của các từ, vector từ của mỗi câu, tính độ tương tự của mỗi \n\ncâu trong văn bản để cho vào đồ thị liên kết. Căn cứ vào số câu lấy ra ta \n\nchọn trong CSDL những câu có bậc lớp nhất. \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n39 \n\n \n\n- Đối với phiên bản 3: sử dụng bộ tách từ, tách câu, sử dụng từ điển từ \n\ndừng, từ đồng nghĩa. Từ tệp văn bản đầu vào tiến hành tách từ, tách câu \n\ndựa vào công cụ JVnTextPro, loại bỏ từ dừng, từ đồng nghĩa của văn bản. \n\nTính tần số xuất hiện của mỗi từ trong câu, tính vector từ của văn bản. \n\nTính toán độ tương tự của các câu, so sánh với ngưỡng để đưa câu vào đồ \n\nthị liên kết. Dựa vào số câu lấy ra để chọn ra những câu có bậc lớn trong \n\nCSDL. \n\n4.2.2. Module quản lý từ dừng, từ đồng nghĩa \n\nĐầu vào: Dữ liệu đầu vào là các từ dừng, từ đồng nghĩa. \n\nĐầu ra: Từ được lưu vào trong CSDL hoặc được sửa đổi, xóa bỏ khỏi CSDL \n\nQuá trình xử lý: Kết nối đến cơ sở dữ liệu nhập đầy đủ dữ liệu vào các ô Textbox \n\nsau đó ấn Thêm để thể thêm vào CSDL, sửa để cập nhật các từ hoặc ấn Xóa để loại \n\nbỏ các từ dừng, từ đồng nghĩa. Cập nhật các thay đổi vào trong CSDL, báo cho \n\nngười dùng biết kết quả. \n\n4.2.3. Module đánh giá hệ thống tóm tắt. \n\nĐầu vào: Nhập các câu mà phần mềm tóm tắt ra vào ô textbox thứ nhất. Nhập số \n\ncâu của ghệ thống tóm tắt đối sánh vào ô textbox thứ 2 sau đó nhấn nút để kiểm tra \n\nđể thực hiện đánh giá. \n\nĐầu ra: Đầu ra của module là các thong số độ chính xác, độ bao phủ, hàm điều hòa \n\ncủa hệ thống tóm tắt so với hệ thống tóm tắt đối sánh. \n\nQuá trình xử lý: Nhập các câu mà hệ thống tóm tắt sinh ra và ô textbox thứ nhất. \n\nNhập các câu mà hệ thống đối sánh sinh ra và nhấp nút đánh giá. Hệ thống sẽ tiến \n\nhành lựa chọn các câu giống nhau của 2 hệ thống, tính toán kết quả và trả ra các \n\nthong số tương ứng. \n\n4.3. Kết luận. \n\nTrong chương này nhóm đồ án đã trình bày một số giao diện chính của hệ thống và \n\nmô tả một số module của chương trình. \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n40 \n\n \n\nCHƯƠNG 5: THỰC NGHIỆM VÀ ĐÁNH GIÁ \n\n5.1. Môi trường thử nghiệm.  \n\nChương trình được xây dựng và thử nghiệm trên máy tính cá nhân có cấu hình và \n\ncác phần mềm cần thiết như sau:  \n\n- Vi xử lý: Intel Dual Core T2390 1.86GHz  \n\n- Bộ nhớ: 2GB  \n\n- Hệ điều hành: Windows 7.  \n\n- Phần mềm phát triển: Microsoft Visual Studio 2008 \n\n - Bộ công cụ JVnTextPro-v.2.0 của tác giả Nguyễn Cẩm Tú \u2013 Phan Xuân Hiếu \n\nnhằm thực hiện tách từ, tách câu của văn bản đầu vào. \n\n5.2. Dữ liệu thử nghiệm  \n\na) Tập văn bản thử nghiệm  \n\nGồm 20 văn bản có nội dung với nhiều lĩnh vực khác nhau, phần lớn được lấy từ \n\nwebsite vnexpress, dantri.com và một số bài báo khoa học khác. Mỗi văn bản được \n\nlưu trong một tập tin được đặt tên theo thứ tự từ  input1.txt đến Text20.txt. Văn bản \n\ncó kích thước lớn nhất là 27KB với 179 câu, văn bản có kích thước nhỏ nhất là \n\n1,45KB với 9 câu. \n\nb) Từ điển  \n\n- Từ điển từ dừng gồm 235 từ. \n\n- Từ điển đồng nghĩa gồm 1000 mục từ. \n\n5.3. Phương pháp đánh giá. \n\nNhư trên đã trình bày, có nhiều phương pháp khác nhau để đánh giá kết quả \n\ncủa một hệ thống tóm tắt. Trong đó, phương pháp so sánh văn bản của hệ thống tóm \n\ntắt với văn bản do con người thực hiện được sử dụng nhiều. Trong thử nghiệm của \n\nchúng tôi, phương pháp này cũng được sử dụng để đánh giá độ chính xác của hệ \n\nthống tóm tắt. \n\nGọi hệ thống tóm tắt cần đánh giá là S, hệ thống tóm tắt đối sánh là CS thì ta \n\ncó bảng đánh giá mức độ liên quan của S và CS như sau: \n\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n41 \n\n \n\n \n\n \n\n                       Hệ thống S \n\nHệ thống CS \nHệ thống S chọn Hệ thống S không chọn \n\nHệ thống CS chọn A B \n\nHệ thống CS không chọn C D \n\nBảng 5.1: Đánh giá sự liên quan của văn bản tóm tắt và văn bản đối sánh. \n\nTrong đó: \n\n A là tổng số câu được cả 2 hệ thống tóm tắt chọn. \n\nB là tổng số câu S không chọn nhưng CS chọn. \n\nC là tổng số câu S chọn nhưng CS không chọn. \n\nD  là tổng số câu mà cả 2 hệ thống đều không chọn. \n\nKhi đó, độ chính xác Precision (P) được tính bằng:  \n\n \n\nĐộ chính xác P cho biết tỉ lệ giữa các câu S chọn ra chính xác so với tổng số những \n\ncâu có trong văn bản tóm tắt do S thực hiện.  \n\nĐộ bao phủ Recall (R) được tính bằng:  \n\n \n\nĐộ bao phủ R cho biết tỉ lệ giữa các S chọn ra chính xác so với tổng số câu trong \n\nvăn bản do CS thực hiện.  \n\nĐộ đo F: là tiêu chí đánh giá chung cho kết quả tóm tắt của hệ thống, độ đo này là \n\nhàm điều hoà của độ chính xác và độ hồi quy và được tính bằng:  \n\n \n\nNhư trên đã trình bày, tỉ lệ nén của văn bản tóm tắt là tỉ lệ giữa tổng số câu do hệ \n\nthống tóm tắt lựa chọn so với tổng số câu của văn bản ban đầu. Chúng tôi thử \n\nnghiệm hệ thống tóm tắt với 3 mức độ nén: 10%, 20% và 30%.  \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n42 \n\n \n\nTập văn bản thử nghiệm trên được tóm tắt bởi con người, mỗi văn bản được tóm tắt \n\nthành 3 văn bản với mức độ nén lần lượt là 10%, 20% và 30%. Các văn bản được \n\nchuyển cho người tóm tắt để chọn ra các câu có ý nghĩa quan trọng. Việc lựa chọn \n\ncác câu sẽ là chọn ra số thứ tự của câu đó trong văn bản gốc. Mỗi câu được chọn sẽ \n\nđược ghi trên một dòng. \n\nChẳng hạn, với văn bản input1.txt trong tập văn bản thử nghiệm, văn bản này có 25 \n\ncâu. Giả sử, với tỉ lệ nén là 10% thì người tóm tắt sẽ thực hiện chọn ra 3 câu, các \n\ncâu được chọn được ghi trong một tập tin văn bản viết theo dạng: \n\n \n\nHình 5.1: Tóm tắt văn bản input1.txt bởi con người. \n\nVăn bản tóm tắt của input1.txt \n\n[8]Tuy nhiên, ít lâu sau, \"Quả táo\" lại khẳng định lỗi sóng yếu là do phần cứng và \n\nsẽ mất rất nhiều thời gian để khắc phục khi mà hãng đã bán ra một số lượng lớn sản \n\nphẩm. \n\n[10]Không những thế, họ còn buộc Quả táo phải bồi thường chi phí mua điện thoại, \n\nkể cả những tổn thất phát sinh khác mà khách hàng phải gánh chịu. \n\n[11]Từ khi xảy ra lỗi mất sóng trên iPhone 4, các chuyên gia quốc tế cùng nhiều \n\ntrang công nghệ lớn như Engadget, Cnet\u2026 đã vào cuộc nhằm tìm ra nguyện nhân \n\nsự việc. \n\nĐồng thời, để so sánh kết quả tóm tắt của hệ thống với các hệ thống khác, nhóm đồ \n\nán lựa chọn Microsoft Office Word 2007 làm hệ tóm tắt đối sánh. Sử dụng công cụ \n\nAuto Summarize trong Microsoft Office để tóm tắt văn bản, Auto Summarize tóm \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n43 \n\n \n\ntắt theo nguyên tắc tính điểm cho các câu chứa từ được lặp lại nhiều lần. Những câu \n\nđược nhiều điểm nhất sẽ được đưa vào văn bản tóm tắt. \n\n5.4. Kết quả thực nghiệm. \n\n5.4.1. Thử nghiệm xác định ngưỡng. \n\n Ngưỡng là giá trị dùng để quyết định xem 2 câu của văn bản có được đưa vào đồ \n\nthị liên kết hay không? Nếu độ tương tự giữa hai câu đạt đến ngưỡng thì 2 câu đó \n\nđược đưa vào đồ thị. Nhóm đồ án đã tiến hành thử nghiệm các phiên bản với những \n\nngưỡng khác nhau để chọn ra một ngưỡng phù hợp. \n\nĐơn vị: % \n\nNgưỡng \n\nPhiên bản 1 Phiên bản 2 Phiên bản 3 \n\nĐộ \n\nchính \n\nxác \n\nĐộ \n\nbao \n\nphủ \n\nHàm \n\nđiều \n\nhòa \n\nĐộ \n\nchính \n\nxác \n\nĐộ \n\nbao \n\nphủ \n\nHàm \n\nđiều \n\nhòa \n\nĐộ \n\nchính \n\nxác \n\nĐộ \n\nbao \n\nphủ \n\nHàm \n\nđiều \n\nhòa \n\n0.1 36.94 47.61 41.48 30.27 37.61 33.33 34.44 44.04 38.33 \n\n0.2 30.27 41.66 34.95 34.44 42.38 37.72 41.11 43.44 42.22 \n\n0.3 39.06 50 43.69 36.94 40.27 38.42 41.11 43.49 42.22 \n\n0.4 38.61 43.25 40.73 41.11 43.44 42.22 44.44 46.82 45.55 \n\n0.5 30.27 32.06 31.11 41.11 41.11 41.11 41.11 41.11 41.11 \n\nBảng 5.2: Kết quả đánh giá thử nghiệm với các ngưỡng khác nhau. \n\nĐồ thị dưới đây mô tả giá trị hàm điều hoà trong việc thử nghiệm các ngưỡng đối \n\nvới từng phiên bản \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n44 \n\n \n\n \n\n0\n\n5\n\n10\n\n15\n\n20\n\n25\n\n30\n\n35\n\n40\n\n45\n\n50\n\n0.1 0.2 0.3 0.4 0.5\n\nPhiên b n 1\n\nPhiên b n 2\n\nPhiên b n 3\n\n \n\nHình 5.2: Đồ thị hàm điều hòa với các ngưỡng. \n\nQua kết quả này, ta có thể nhận thấy, với ngưỡng 0.2, 0.3, 0.4 thì chương trình tóm \n\ntắt cho kết quả khả quan nhất. Khi ngưỡng tăng dần thì giá trị hàm điều hoà lại giảm \n\nrất nhanh do khi độ tương tự giữa hai câu không đạt đến ngưỡng đó thì hai câu đó \n\nkhông thể được đưa vào đồ thị liên kết, từ đó hai câu này sẽ không được chọn vào \n\nvăn bản tóm tắt (mà rất có thể hai câu này chứa nội dung chính và sẽ được chọn). \n\nViệc xác định ngưỡng có một vị trí quan trọng trong chương trình tóm tắt. Bởi lẽ \n\nngưỡng còn phụ thuộc vào từng loại văn bản, một ngưỡng này có thể là tốt với loại \n\nvăn bản nhưng có thể lại không tốt với loại văn bản khác. Trong thử nghiệm kết quả \n\ntóm tắt đối với từng văn bản dưới đây chúng tôi sử dụng ngưỡng 0,4 để đánh giá. \n\n5.4.2. Đánh giá kết quả thử nghiệm đối với từng phiên bản. \n\na) Đánh giá chất lượng tóm tắt của Microsoft Word. \n\n Bảng dưới đây là kết quả đối sánh của các bản tóm tắt do Microsoft Word thực \n\nhiện. \n\n \n\n \n\n \n\nT\nỷ \n\nlệ\n p\n\nh\nần\n\n t\nră\n\nm\n \n\n\n\n \n\nTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa. \n\n45 \n\n \n\nĐơn vị: % \n\nTỷ lệ nén Độ chính xác Độ bao phủ Hàm điều hòa \n\n10% 33.33 25 28.57 \n\n20% 40 33.33 36.36 \n\n30% 50 44.44 47.05 \n\nTrung bình 41.11 34.25 37.32 \n\nBảng 5.3: Đánh giá kết quả tóm tắt của Microsoft office 2007 \n\nb) Phiên bản 1 \n\nTrong phiên bản này, chúng tôi không sử dụng bộ tách từ mà chỉ sử dụng dấu trắng \n\nlàm dấu hiệu phân tách từ. Ngưỡng threshold được chọn đối với cả 3 phiên bản để \n\nđưa 2 câu vào đồ thị liên kết được chọn là 0,4. Dưới đây là kết quả đánh giá độ \n\nchính xác và độ bao phủ trun","u":"http://202.191.57.85:8000/InternetData/Data/tailieu.vn/docview/tailieu/2014/20140421/nguyenthuan9191/baocaodatn_8451.txt","sentences":[[1,"TRƯỜNG ĐẠI HỌC SPKT HƯNG YÊN CỘNG HÒA XÃ HỘI CHỦ NGHĨA VIỆT NAM KHOA CÔNG NGHỆ THÔNG TIN Độc lập \u2013 Tự do \u2013 Hạnh phúc ĐỀ TÀI TỐT NGHIỆP ĐẠI HỌC Họ và tên sinh viên: 1"],[2,"Nguyễn Văn Thuấn 25/01/1991 TK7.2 2"],[3,"Trần Quang Vinh 21/06/1990 TK7.2 Ngành đào tạo: Công Nghệ Thông Tin Chuyên ngành: Mạng máy tính và Truyền thông Khóa học: 2009-2013 Tên đề tài: TÓM TẮT VĂN BẢN DỰA VÀO TRÍCH XUẤT CÂU VÀ XÂY DỰNG ỨNG DỤNG MINH HỌA"],[4,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[5,"Mục tiêu đề tài: - Tìm hiểu cơ sở lý thuyết của phương pháp tóm tắt văn bản dựa vào trích xuất câu bao gồm: Tổng quan về tóm tắt văn bản, các mô hình tóm tắt, đặc điểm Tiếng Việt, phương pháp sử dụng trong tóm tắt văn bản"],[6,"- Xây dựng được phần mềm tóm tắt văn bản dựa vào trích xuất các câu quan trọng trong văn bản theo một tỷ lệ nén nhất định"],[7,"Nội dung cần hoàn thành: 1"],[8,"Phần thuyết minh: - Cuốn báo cáo Đồ án tốt nghiệp được trình bày theo đúng quy định"],[9,"Báo cáo được trình bày được ý tưởng và cách giải quyết các bài toán trong quá trình thực hiện đề tài, các phương pháp đánh giá văn bản tóm tắt với các phương pháp tóm tắt khác"],[10,"- Báo các được trình bày gồm 3 phần: Phần 1: Mở đầu - Lý do chọn đề tài"],[11,"- Mục đích nghiên cứu"],[12,"- Nhiệm vụ nghiên cứu"],[13,"- Phươn pháp nghiên cứu"],[14,"Phần 2: Nội dung - Tổng quan về tóm tắt văn bản"],[15,"- Bài toán tóm tắt văn bản tiếng việt"],[16,"- Ứng dụng phương pháp cấu trúc để tóm tắt văn bản Tiếng Việt"],[17,"- Xây dựng ứng dụng minh họa"],[18,"- Thực nghiệm và đánh giá"],[19,"Phần 3: Kết luận"],[20,"- Kết quả đạt được"],[21,"- Những hạn chế của đề tài"],[22,"- Hướng phát triển của đề tài"],[23,"2"],[24,"Phần thực hành, cài đặt: - Xây dựng phần mềm giải quyết được bài toán trong tóm tắt văn bản áp dụng phương pháp trích xuất câu"],[25,""],[26,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[27,"- Cài đặt các công cự hỗ trợ tách từ tách câu"],[28,"- Trích xuất ra được văn bản tóm tắt theo tỉ lệ % tùy chọn với độ chính xác và đáng tin cậy cao"],[29,"3"],[30,"Sản phẩm chính: - Phần mềm Tóm tắt văn bản áp dụng phương pháp trích xuất câu hoàn chỉnh"],[31,"Dự kiến kính phí: Thời gian thực hiện: Ngày giao:...../...../..........., ngày hoàn thành ....../....../........."],[32,"Người hướng dẫn: - Thứ nhất: Nguyễn Thị Thanh Huệ Ký xác nhận:............................."],[33,"- Thứ hai:........................................................Ký xác nhận:............................."],[34,"Đề tài đã được Hội đồng Khoa học và Đào tạo Khoa thông qua"],[35,"TRƯỞNG KHOA (Ký, ghi rõ họ và tên) Hưng Yên, ngày ..."],[36,"tháng ..."],[37,"năm ......."],[38,"TRƯỞNG BỘ MÔN (Ký, ghi rõ họ và tên)"],[39,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[40,"MỞ ĐẦU Ngày nay, với sự phát triển như vũ bão của công nghệ thông tin, Internet cũng như các dịch vụ trực tuyến, ngày càng có nhiều thông tin được tạo ra"],[41,"Ta có thể truy cập các thông tin đó qua sách, báo, Internet và các phương tiện truyền thông"],[42,"Hơn nữa, nhu cầu đọc, tìm kiếm và lưu trữ thông tin của con người cũng ngày càng tăng lên"],[43,"Tuy nhiên, với một lượng lớn thông tin như vậy thì người ta không thể nào có đủ thời gian và sức lực để đọc hết được chúng"],[44,"Giải pháp là tóm tắt lại các văn bản đó, từ đó giúp tiết kiệm thời gian và công sức nhưng vẫn có thể đọc và xử lý được nhiều văn bản"],[45,"Tóm tắt văn bản tự động đã bắt đầu được nghiên cứu từ những năm 50 của thế kỉ trước"],[46,"Đã có nhiều công trình nghiên cứu về lĩnh vực này và có được những kết quả đáng kể"],[47,"Tóm tắt văn bản đã được sử dụng trong các phần mềm xử lý văn bản (Microsoft Office Word\u2026), trong khai phá cơ sở dữ liệu văn bản (Oracle\u2026), trong các ứng dụng tìm kiếm thông tin trực tuyến (hệ thống tìm kiếm Google, Yahoo\u2026) và đều thu được những kết quả rất đáng khích lệ"],[48,"Vì vậy, chúng em chọn đề tài: \u201cTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa\u201d nhằm nghiên cứu những vấn đề tổng quan về xử lý ngôn ngữ tự nhiên và một số phương pháp tóm tắt văn bản"],[49,"Với sự hướng dẫn của cô Nguyễn Thị Thanh Huệ"],[50,""],[51,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[52,"LỜI CẢM ƠN Sau một thời gian tìm hiểu và thực hiện đến nay đề tài \u201cTÓM TẮT VĂN BẢN DỰA VÀO TRÍCH XUẤT CÂU VÀ XÂY DỰNG ỨNG DỤNG MINH HỌA\u201d đã hoàn thành"],[53,"Trong suốt quá trình thực hiện đề tài, chúng em đã nhận được rất nhiều sự giúp đỡ nhiệt tình"],[54,"Chúng em xin chân thành cảm ơn các thầy các cô đã trang bị những kiến thức quý báu cho chúng em trong suốt quá trình học tập tại trường Đại học Sư phạm Kỹ thuật Hưng Yên"],[55,"Đặc biệt là các thầy các cô trong khoa Công nghệ thông tinđã tận tình giảng dạy, chỉ bảo, trang bị cho chúng em những kiến thức cần thiết nhất trong suốt quá trình học tập và nghiên cứu tại khoa, đã tạo mọi điều kiện thuận lợi giúp chúng em thực hiện đề tài này"],[56,"Chúng em xin cảm ơn cô Nguyễn Thị Thanh Huệ đã tận tình hướng dẫn, chỉ bảo chúng em trong suốt thời gian thực hiện đề tài, giúp chúng em có thể hoàn thành đề tài này"],[57,"Mặc dù đã cố gắng nỗ lực thực hiện đề tài với quyết tâm cao nhưng chắc hẳn đề tài không thể tránh khỏi thiếu sót, kính mong sự đóng góp và hướng dẫn của các thầy cô"],[58,"Chúng em xin chân thành cảm ơn"],[59,"Hưng Yên, tháng 08 năm 2013 Nhóm sinh viên thực hiện Nguyễn Văn Thuấn Trần Quang Vinh"],[60,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[61,"NHẬN XÉT CỦA GIẢNG VIÊN HƯỚNG DẪN \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026..\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026..\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026..\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026..\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026.\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026..\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026"],[62,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[63,"NHẬN XÉT CỦA GIẢNG VIÊN PHẢN BIỆN \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026."],[64,"\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026"],[65,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[66,"NHẬN XÉT CỦA GIẢNG VIÊN PHẢN BIỆN \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026."],[67,"\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026"],[68,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[69,"MỤC LỤC PHẦN 1: MỞ ĐẦU ................................................................................................"],[70,"1 1"],[71,"Lý do chọn đề tài"],[72,"......................................................................................."],[73,"1 2"],[74,"Khách thể và đối tượng nghiên cứu ................................................................."],[75,"1 3"],[76,"Giới hạn và phạm vi nghiên cứu ....................................................................."],[77,"1 4"],[78,"Mục đích nghiên cứu ......................................................................................"],[79,"1 5"],[80,"Nhiệm vụ nghiên cứu ......................................................................................"],[81,"1 6"],[82,"Phương pháp nghiên cứu ................................................................................"],[83,"1 7"],[84,"Ý nghĩa lý luận và thực tiễn của đề tài ............................................................"],[85,"1 PHẦN 2: NỘI DUNG ............................................................................................"],[86,"2 CHƯƠNG 1: TỔNG QUAN VỀ TÓM TẮT VĂN BẢN ........................................"],[87,"2 1.1"],[88,"Tổng quan"],[89,"..................................................................................................."],[90,"2 1.1.1"],[91,"Khái niệm"],[92,"............................................................................................"],[93,"2 1.1.2"],[94,"Lịch sử phát triển của tóm tắt văn bản ..................................................."],[95,"2 1.1.3"],[96,"Phân loại các phương pháp tóm tắt văn bản"],[97,".........................................."],[98,"4 1.2"],[99,"Mô hình tóm tắt văn bản .............................................................................."],[100,"6 1.2.1"],[101,"Các phương pháp áp dụng trong pha phân tích"],[102,"....................................."],[103,"6 1.2.2"],[104,"Các phương pháp áp dụng trong pha biến đổi ........................................"],[105,"8 1.2.3"],[106,"Các phương pháp trong pha tổng hợp kết quả........................................"],[107,"9 1.3"],[108,"Các phương pháp đánh giá ..........................................................................."],[109,"9 1.3.1"],[110,"Các phương pháp đánh giá trong ........................................................."],[111,"10 1.3.2"],[112,"Các phương pháp đánh giá ngoài ........................................................"],[113,"11 1.4"],[114,"Kết luận ....................................................................................................."],[115,"12 CHƯƠNG 2 : BÀI TOÁN TÓM TẮT VĂN BẢN TIẾNG VIỆT ...................."],[116,"13 2.1"],[117,"Một số hướng tiếp cận bài toán tóm tắt văn bản ........................................."],[118,"13 2.2"],[119,"Đặc điểm tiếng Việt ..................................................................................."],[120,"13 2.2.1"],[121,"Đặc điểm chung .................................................................................."],[122,"14 2.2.2"],[123,"Yếu tố ngoại lai trong từ tiếng Việt ....................................................."],[124,"15 2.2.3"],[125,"Từ dừng"],[126,"............................................................................................."],[127,"15 2.2.4"],[128,"Từ đồng nghĩa"],[129,"...................................................................................."],[130,"15"],[131,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[132,"2.2.5"],[133,"Đặc điểm chính tả ..............................................................................."],[134,"17 2.3"],[135,"Phương pháp cho bài toán tóm tắt văn bản tiếng Việt"],[136,"................................"],[137,"18 2.4"],[138,"Kết luận"],[139,"...................................................................................................."],[140,"20 CHƯƠNG 3: ỨNG DỤNG PHƯƠNG PHÁP CẤU TRÚC ĐỂ TÓM TẮT VĂN BẢN TIẾNG VIỆT .............................................................................................."],[141,"22 3.1"],[142,"Mô hình tóm tắt sử dụng phương pháp cấu trúc ........................................."],[143,"22 3.2"],[144,"Tiền xử lý văn bản ....................................................................................."],[145,"23 3.3"],[146,"Xử lý từ ....................................................................................................."],[147,"24 3.4"],[148,"Xây dựng đồ thị liên kết"],[149,"............................................................................"],[150,"25 3.5"],[151,"Sinh văn bản tóm tắt"],[152,"................................................................................."],[153,"28 3.6"],[154,"Kết luận"],[155,"...................................................................................................."],[156,"34 CHƯƠNG 4: XÂY DỰNG ỨNG DỤNG MINH HỌA ........................................"],[157,"35 4.1"],[158,"Một số giao diện chính của hệ thống"],[159,"........................................................."],[160,"35 4.1.1"],[161,"Giao diện chính của chương trình"],[162,"......................................................."],[163,"35 4.1.2"],[164,"Giao diện form quản lý từ điển từ dừng, từ đồng nghĩa"],[165,"......................"],[166,"35 4.1.3"],[167,"Giao diện form tách từ, tách câu"],[168,"........................................................."],[169,"36 4.1.4"],[170,"Giao diện form loại từ dừng, từ đồng nghĩa"],[171,"........................................"],[172,"36 4.1.5"],[173,"Giao diện form xây dựng đồ thị liên kết"],[174,"............................................."],[175,"37 4.1.6"],[176,"Giao diện form tóm tắt văn bản"],[177,".........................................................."],[178,"37 4.1.7"],[179,"Giao diện form đánh giá độ chính xác"],[180,"................................................"],[181,"38 4.2"],[182,"Một số module chính của chương trình"],[183,"....................................................."],[184,"38 4.2.1"],[185,"Module tóm tắt văn bản"],[186,"......................................................................"],[187,"38 4.2.2"],[188,"Module quản lý từ dừng, từ đồng nghĩa ..............................................."],[189,"39 4.2.3"],[190,"Module đánh giá hệ thống tóm tắt"],[191,"......................................................"],[192,"39 4.3"],[193,"Kết luận"],[194,"...................................................................................................."],[195,"39 CHƯƠNG 5: THỰC NGHIỆM VÀ ĐÁNH GIÁ .............................................."],[196,"40 5.1"],[197,"Môi trường thử nghiệm"],[198,"............................................................................."],[199,"40 5.2"],[200,"Dữ liệu thử nghiệm ...................................................................................."],[201,"40 5.3"],[202,"Phương pháp đánh giá"],[203,"..............................................................................."],[204,"40 5.4"],[205,"Kết quả thực nghiệm"],[206,"................................................................................."],[207,"43"],[208,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[209,"5.4.1"],[210,"Thử nghiệm xác định ngưỡng"],[211,"............................................................."],[212,"43 5.4.2"],[213,"Đánh giá kết quả thử nghiệm đối với từng phiên bản"],[214,".........................."],[215,"44 5.5"],[216,"Kết luận"],[217,"...................................................................................................."],[218,"48 PHẦN 3: KẾT LUẬN .........................................................................................."],[219,"49 1"],[220,"Kết quả đạt được"],[221,"......................................................................................"],[222,"49 2"],[223,"Những hạn chế của đề tài"],[224,"........................................................................."],[225,"49 3"],[226,"Hướng phát triển của đề tài"],[227,"......................................................................"],[228,"49 TÀI LIỆU THAM KHẢO ...................................................................................."],[229,"51"],[230,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[231,"DANH MỤC CÁC TỪ VIẾT TẮT Từ viết tắt Viết đầy đủ Ý nghĩa CSDL Cơ sở dữ liệu IR Information Retrieval Trích xuất thông tin ISF Inverse sentence frequency Nghịch đảo tần số câu LRMM Left Right Maximum Matching Phương pháp so khớp cực đại TF Term frequency Tần số từ khóa WFST Weighted Finite State Transducer Phương pháp sử dụng bộ chuyển trạng thái hữu hạn có trọng số"],[232,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[233,"DANH MỤC BẢNG BIỂU Bảng 3.1: Bậc của các đỉnh sắp xếp theo thứ tự giảm dần của văn bản input1.txt.."],[234,"30 Bảng 3.2: Phân chia đoạn của văn bản input1.txt .................................................."],[235,"33 Bảng 5.1: Đánh giá sự liên quan của văn bản tóm tắt và văn bản đối sánh"],[236,"..........."],[237,"41 Bảng 5.2: Kết quả đánh giá thử nghiệm với các ngưỡng khác nhau"],[238,"....................."],[239,"43 Bảng 5.3: Đánh giá kết quả tóm tắt của Microsoft office 2007.............................."],[240,"45 Bảng 5.4: Kết quả thử nghiệm phiên bản 1"],[241,".........................................................."],[242,"45 Bảng 5.5: Kết quả thử nghiệm phiên bản 2"],[243,"........................................................."],[244,"46 Bảng 5.6: Kết quả thử nghiệm phiên bản 3 ..........................................................."],[245,"47 Bảng 5.7: Bảng so sánh kết quả giữa MS Office 2007 với các phiên bản .............."],[246,"47"],[247,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[248,"DANH MỤC HÌNH ẢNH Hình 1.1 Kiến trúc của hệ thống tóm tắt văn bản tự động ......................................"],[249,"6 Hình 2.1 Đồ thị liên kết các câu trong văn bản"],[250,"..................................................."],[251,"20 Hình 3.1 Mô hình tóm tắt văn bản sử dụng phương pháp cấu trúc ......................."],[252,"22 Hinh 3.2: Đồ thị liên kết của văn bản input1.txt ...................................................."],[253,"28 Hình 4.1: Giao diện chính của chương trình"],[254,"........................................................"],[255,"35 Hình 4.2: Giao diện quản lý từ dừng"],[256,"...................................................................."],[257,"35 Hình 4.3: Giao diện tách từ tách câu ....................................................................."],[258,"36 Hình 4.4: Loại bỏ từ dừng, từ đồng nghĩa trong văn bản ......................................."],[259,"36 Hình 4.5: Giao diện form xây dựng đồ thị liên kết cho văn bản"],[260,"..........................."],[261,"37 Hình 4.6: Giao diện tóm tắt văn bản"],[262,"...................................................................."],[263,"37 Hình 4.7: Đánh giá độ chính xác của văn bản tóm tắt ..........................................."],[264,"38 Hình 5.1: Tóm tắt văn bản input1.txt bởi con người"],[265,"............................................."],[266,"42 Hình 5.2: Đồ thị hàm điều hòa với các ngưỡng"],[267,"...................................................."],[268,"44 Hình 5.3: Đồ thị so sánh hàm điều hòa của MS Office 2007 với các phiên bản ....."],[269,"48"],[270,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[271,"1 PHẦN 1: MỞ ĐẦU 1"],[272,"Lý do chọn đề tài"],[273,"Ngày nay, với sự phát triển như vũ bão của công nghệ thông tin, Internet cũng như các dịch vụ trực tuyến, ngày càng có nhiều thông tin được tạo ra"],[274,"Ta có thể truy cập các thông tin đó qua sách, báo, Internet và các phương tiện truyền thông"],[275,"Hơn nữa, nhu cầu đọc, tìm kiếm và lưu trữ thông tin của con người cũng ngày càng tăng lên"],[276,"Tuy nhiên, với một lượng lớn thông tin như vậy thì người ta không thể nào có đủ thời gian và sức lực để đọc hết được chúng"],[277,"Giải pháp là tóm tắt lại các văn bản đó, từ đó giúp tiết kiệm thời gian và công sức nhưng vẫn có thể đọc và xử lý được nhiều văn bản"],[278,"Tóm tắt văn bản tự động đã bắt đầu được nghiên cứu từ những năm 50 của thế kỉ trước"],[279,"Đã có nhiều công trình nghiên cứu về lĩnh vực này và có được những kết quả đáng kể"],[280,"Tóm tắt văn bản đã được sử dụng trong các phần mềm xử lý văn bản (Microsoft Office Word\u2026), trong khai phá cơ sở dữ liệu văn bản (Oracle\u2026), trong các ứng dụng tìm kiếm thông tin trực tuyến (hệ thống tìm kiếm Google, Yahoo\u2026) và đều thu được những kết quả rất đáng khích lệ"],[281,"Vì vậy, chúng tôi chọn đề tài: \u201cTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa\u201d nhằm nghiên cứu những vấn đề tổng quan về xử lý ngôn ngữ tự nhiên và một số phương pháp tóm tắt văn bản"],[282,"2"],[283,"Khách thể và đối tượng nghiên cứu Các văn bản, các kỹ thuật tóm tắt văn bản, các phương pháp tóm tắt văn bản"],[284,"3"],[285,"Giới hạn và phạm vi nghiên cứu Nghiên cứu các kỹ thuật tóm tắt văn bản dựa vào trích xuất câu"],[286,"Tóm tắt văn bản trên ngôn ngữ Tiếng Việt 4"],[287,"Mục đích nghiên cứu Với đề tài \u201cTóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa\u201d sẽ trích xuất được các nội dung chính của văn bản mà người dùng nhập vào, giảm thời gian tìm kiếm thông tin trên đoạn văn bản dài của người đọc"],[288,"5"],[289,"Nhiệm vụ nghiên cứu"],[290,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[291,"1 Vận dụng các kiến thức về tóm tắt văn bản để xây dựng ứng dụng minh họa tóm tắt văn bản"],[292,"6"],[293,"Phương pháp nghiên cứu - Nghiên cứu tài liệu trên internet, các kĩ thuật tóm tắt văn bản đã có"],[294,"- Tham khảo ý kiến của các thầy cô trong trường"],[295,"7"],[296,"Ý nghĩa lý luận và thực tiễn của đề tài - Ý nghĩa lý luận của đề tài Chương trình cùng với lý thuyết tổng quan về Tóm tắt văn bản sẽ trở thành một tài liệu nghiên cứu, tham khảo nhanh, dễ hiểu, thiết thực cho người đọc"],[297,"- Ý nghĩa thực tiễn của đề tài Về mặt ứng dụng sẽ cung cấp cho người dùng một phần mềm giúp cho người đọc có thể tóm tắt nội dung chính của văn bản một cách nhanh chóng, dễ dàng không tốn thời gian cần đọc cả đoạn văn bản dài"],[298,""],[299,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[300,"2 PHẦN 2: NỘI DUNG CHƯƠNG 1: TỔNG QUAN VỀ TÓM TẮT VĂN BẢN 1.1"],[301,"Tổng quan"],[302,"1.1.1"],[303,"Khái niệm"],[304,"Tóm tắt văn bản là một lĩnh vực của xử lý ngôn ngữ tự nhiên, đã được bắt đầu nghiên cứu từ những năm 50 của thế kỉ trước"],[305,"Có nhiều định nghĩa về tóm tắt văn bản: Định nghĩa tóm tắt văn bản là quá trình rút trích ra các thông tin quan trọng từ một hoặc nhiều văn bản để tạo ra văn bản ngắn gọn cho mỗi hoặc nhóm người dùng, cho từng tác vụ hay nhiều tác vụ khác nhau"],[306,"Định nghĩa hệ thống tóm tắt văn bản là hệ thống đưa ra dạng biểu diễn ngắn gọn của thông tin đầu vào căn cứ theo yêu cầu của người dùng"],[307,"Radev (2002) định nghĩa văn bản tóm tắt là văn bản được tạo từ một hoặc nhiều văn bản khác mà truyền tải được những thông tin quan trọng trong văn bản gốc nhưng có độ dài không quá ½ văn bản gốc (thường ngắn hơn đáng kể)"],[308,"Theo Partha Lal (2002) thì tóm tắt văn bản là việc thể hiện nội dung văn bản dưới dạng giản lược một cách tự động nhằm đáp ứng yêu cầu nào đó từ phía người dùng"],[309,"Đỗ Phúc, Hoàng Kiếm (2006) định nghĩa tóm tắt văn bản tự động là việc tìm các ý chính của văn bản"],[310,"Tựu chung lại, có ba đặc điểm quan trọng cần phải xem xét trong hệ thống tóm tắt văn bản: 1) Bản tóm tắt có thể được tạo ra từ một hoặc nhiều văn bản"],[311,"2) Bản tóm tắt cần truyền tải các thông tin quan trọng"],[312,"3) Bản tóm tắt cần phải ngắn"],[313,"1.1.2"],[314,"Lịch sử phát triển của tóm tắt văn bản Tóm tắt văn bản bắt đầu từ những năm cuối thập kỉ 1950 với nghiên cứu của Luhn (1958) dựa trên tần số từ"],[315,"Ý tưởng cơ bản của phương pháp tần số từ dựa trên kiến thức cho rằng tần số của từng từ trong văn bản là một độ đo hữu dụng để đánh giá tầm quan trọng của chúng"],[316,""],[317,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[318,"3 Tiếp theo đó là phương pháp tóm tắt dựa trên vị trí của các câu trong văn bản của Baxendale (1958), và những nghiên cứu của Edmundson (1969) về vị trí của các câu trong văn bản và các từ/cụm từ mang ý nghĩa tổng quát (từ/cụm từ dấu hiệu)"],[319,"Theo đó, những câu bắt đầu và kết thúc của đoạn văn/bài viết hay những câu chứa những từ như \u201cimportant\u201d (đặc biệt), \u201cresult are\u201d (kết quả là), \u201cpaper introduce\u201d (bài báo giới thiệu về)\u2026 là những câu có ý nghĩa quan trọng"],[320,"Đầu những năm 1970, tiếp tục có những nghiên cứu với hướng tiếp cận ngoài (sử dụng các cụm từ dấu hiệu) và được ứng dụng trong các phần mềm thương mại (Pollock và Zamora)"],[321,"Những năm 1980, phát triển nhiều nghiên cứu với nhiều hướng khác nhau, đặc biệt là hướng tiếp cận mức thực thể dựa trên trí tuệ nhân tạo như sử dụng script (Lehnert 1981), (DeJong 1982), các luật sản xuất và logic (Fum 1985), mạng ngữ nghĩa (Reimer và Hahn 1988), cũng như các hướng tiếp cận kết hợp (Rau 1989) hay (Aretoulaki 1994)"],[322,"Willam B"],[323,"Cavnar (1994): biểu diễn văn bản dựa trên n-gram thay cho cách biểu diễn truyền thống bằng từ khoá"],[324,"Chinatsu Anoe (1997) đã phát triển hệ DimSum để tóm tắt văn bản sử dụng xử lý ngôn ngữ tự nhiên và kĩ thuật thống kê dựa trên hệ thống tf-idf, sử dụng WordNet để xem xét ngữ nghĩa của từ và đề xuất một số kĩ thuật lượng giá"],[325,"Jaine Carbonell (1998) đã tóm tắt văn bản bằng cách xếp hạng các câu trội (câu chứa các ý chính của văn bản) và rút ra các câu trội"],[326,"Jade Goldstein (1999): phân loại tóm tắt dựa trên độ đo liên quan, phương pháp sử dụng kết hợp giữa ngữ học, thống kê"],[327,"Mỗi câu được đặc trưng bằng các đặc tính ngữ học và độ đo thống kê"],[328,"J.Larocca Neto (2000) đã tạo tóm tắt văn bản dựa trên các dãy từ trong câu được chọn theo hệ số tf, sau đó dùng kỹ thuật gom cụm (clustering) để tạo tóm tắt"],[329,"Yoshio (2001) đã tạo tóm tắt văn bản tiếng Nhật"],[330,"Có 2 phương pháp là rút câu dựa trên từ khoá và rút câu dựa trên kiến trúc ngữ nghĩa trong đó có xây dựng độ đo mối liên kết giữa hai từ"],[331,""],[332,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[333,"4 Hiện nay, một số nghiên cứu về xử lý ngôn ngữ tự nhiên cũng bước đầu được áp dụng trong tóm tắt văn bản"],[334,"Mặt khác, các nghiên cứu về tóm tắt đa văn bản, đa ngôn ngữ và tóm tắt đa phương tiện cũng bắt đầu phát triển"],[335,"1.1.3"],[336,"Phân loại các phương pháp tóm tắt văn bản"],[337,"Có nhiều tiêu chí để phân loại các phương pháp tóm tắt văn bản, sau đây là một số cách phân loại tiêu biểu: Căn cứ vào dạng tóm tắt, ta có thể chia thành: - Trích xuất (extract): bản tóm tắt hoàn toàn chứa các \u201cdãy từ\u201d được sao chép nguyên dạng từ văn bản nguồn"],[338,"\u201cDãy từ\u201d ở đây có thể là cụm từ, câu hoặc đoạn văn"],[339,"Tuy nhiên, với dạng trích xuất thì văn bản tóm tắt thiếu cấu kết cần thiết, các câu được trích ra có thể không phản ánh nội dung"],[340,"Nói chung văn bản tóm tắt không được \u201ctrơn\u201d do được \u201clắp ghép\u201d từ các câu, đoạn văn được trích ra"],[341,"- Tóm tắt (abstracts): văn bản tóm tắt nói chung là không chứa các \u201cdãy từ\u201d trong văn bản nguồn mà là được \u201cviết lại\u201d một cách tự động"],[342,"Với dạng này, người ta cần nhiều kĩ thuật xử lý ngôn ngữ"],[343,"Hiện tại, đây vẫn là vấn đề khó, chưa thể giải quyết được một cách triệt để"],[344,"Căn cứ vào mức độ xử lý, có thể chia thành 2 dạng: - Tiếp cận mức ngoài (surface-level): thông tin được miêu tả dưới dạng khái niệm về các đặc trưng nông (shallow feature)"],[345,"Các đặc trưng nông bao gồm các thuật ngữ (term) quan trọng qua thống kê (dựa vào tần số của các thuật ngữ trong văn bản), các thuật ngữ quan trọng dựa vào vị trí, các thuật ngữ trong các cụm từ dấu hiệu hay các thuật ngữ trong câu truy vấn của người dùng"],[346,"Kết quả là một bản tóm tắt dạng trích xuất (extract)"],[347,"- Tiếp cận mức sâu (deeper-level): ở mức này, bản tóm tắt có thể là dạng trích xuất hoặc dạng tóm tắt (abstract) và cần phải sử dụng đến sinh tổng hợp ngôn ngữ tự nhiên"],[348,"Với dạng tiếp cận này, phải cần đến những phân tích về mặt ngữ nghĩa, chẳng hạn sử dụng hướng tiếp cận thực thể để xây dựng dạng biểu diễn của các thực thể văn bản (đơn vị văn bản) và mối quan hệ giữa các thực thể rồi từ đó tìm ra phần quan trọng"],[349,"Mối quan hệ giữa các thực thể gồm quan hệ ngữ nghĩa như:"],[350,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[351,"5 đồng nghĩa, trái nghĩa, nghĩa hẹp, nghĩa rộng\u2026, quan hệ cú pháp: dựa trên cây phân tích cú pháp và các mối quan hệ khác"],[352,"Căn cứ vào mục đích của bản tóm tắt, có thể chia làm 3 dạng: - Trình bày sơ lược (indicative): Đưa ra những thông tin ngắn gọn về chủ đề chính của văn bản"],[353,"Dạng tóm tắt này thường được sử dụng trong các hệ thống tìm kiếm thông tin"],[354,"Thông thường, độ dài của văn bản tóm tắt loại này chỉ từ 5 đến 10% độ dài của toàn bộ văn bản"],[355,"- Tóm tắt cung cấp tin tức (Informative): Cung cấp các chủ đề con của toàn bộ văn bản, kiểu tóm tắt này có độ dài từ 20-30% văn bản gốc"],[356,"- Phê bình và đánh giá: Văn bản tóm tắt đưa ra những quan điểm của người tóm tắt về chủ đề được đưa ra"],[357,"Tuy nhiên, kiểu tóm tắt này dường như vượt quá tầm của các hệ thống tóm tắt tự động hiện nay"],[358,"Việc phân loại tóm tắt dựa theo mục đích như trên không loại trừ lẫn nhau, có thể một bản tóm tắt vừa có chức năng cung cấp tin tức lại vừa là kiểu trình bày sơ lược"],[359,"Căn cứ vào người sử dụng, có thể chia thành các dạng: - Tóm tắt chung: với kiểu tóm tắt này thì mọi chủ đề chính trong văn bản đều có tầm quan trọng như nhau, văn bản tóm tắt hướng đến một cộng đồng đông đảo người đọc"],[360,"- Tóm tắt dựa trên câu truy vấn: kết quả trả về dựa trên câu truy vấn của người dùng"],[361,"- Tóm tắt hướng đến người dùng hoặc chủ đề: văn bản tóm tắt đáp ứng nhu cầu của người dùng cụ thể hoặc chủ đề cụ thể nào đó"],[362,"Căn cứ vào số lượng văn bản tóm tắt: Tóm tắt đơn văn bản: thực hiện tóm tắt trên một văn bản hoặc tóm tắt đa văn bản: thực hiện tóm tắt trên nhiều văn bản khác nhau"],[363,"Căn cứ vào ngôn ngữ tóm tắt: Tóm tắt trên một ngôn ngữ hoặc tóm tắt trên nhiều ngôn ngữ khác nhau"],[364,""],[365,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[366,"6 1.2"],[367,"Mô hình tóm tắt văn bản Hình 1.1 Kiến trúc của hệ thống tóm tắt văn bản tự động Đầu vào của hệ thống có thể là một hoặc nhiều tài liệu, văn bản hay các thông tin đa phương tiện như ảnh, âm thanh, video"],[368,"Hệ thống tóm tắt hiện nay thường tập trung vào việc xử lý đầu là văn bản (có thể mở rộng cho các thông tin dạng khác)"],[369,"Điều quan trọng trong việc tóm tắt văn bản là mức độ nén, tức là tỉ lệ giữa độ dài của văn bản tóm tắt so với văn bản gốc"],[370,"Thông thường, tỉ lệ nén được tính dựa trên độ dài của văn bản, hoặc có thể tính bằng nội dung thông tin"],[371,"Tỉ lệ nén có thể dao động từ 10% đến 50% hoặc lớn hơn, nếu tỉ lệ nén giảm thì thông tin sẽ bị mất nhiều hơn"],[372,"Văn bản tóm tắt có thể là văn bản liền mạch hoặc văn bản rời rạc"],[373,"Quá trình tóm tắt có thể chia thành 3 pha: phân tích văn bản đầu vào, biến đổi, tổng hợp chỉnh sửa cho phù hợp với yêu cầu đầu ra"],[374,"1.2.1"],[375,"Các phương pháp áp dụng trong pha phân tích"],[376,"Trong pha này, văn bản nguồn được phân tích để xác định các đơn vị ngữ liệu và các đặc trưng của chúng, kết quả của pha này là đầu vào cho pha biến đổi"],[377,"Các phương pháp áp dụng trong pha này bao gồm: a) Phương pháp thống kê Các phương pháp thuộc loại này sử dụng các số liệu thống kê về độ quan trọng của các từ, cụm từ, câu hoặc đoạn văn"],[378,"Các phương pháp thống kê gồm: - Dựa vào vị trí: + Chủ đề, tiêu đề: tiêu đề hay chủ đề của các đoạn văn thường chứa các từ và ngữ quan trọng"],[379,"P hân tích B iến đổi T ổng h ợ p Văn bản được tóm tắt Văn bản gốc"],[380,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[381,"7 + Câu ở đầu hoặc cuối đoạn: xác suất câu đầu đoạn hay câu cuối đoạn chứa ý chính của cả đoạn là rất lớn, đặc biệt là câu đầu đoạn"],[382,"Ngoài ra các đoạn đầu và cuối văn bản cũng quan trọng hơn các đoạn giữa"],[383,"+ Minh hoạ, chú thích: trong các câu chú thích, câu minh hoạ cho ảnh hay đồ thị thường chứa các thông tin quan trọng"],[384,"- Dựa vào cụm từ dấu hiệu: Các cụm từ dấu hiệu có đặc điểm thống kê rất tốt"],[385,"Sau các cụm từ này thường là các từ hay câu quan trọng"],[386,"Có hai loại cụm từ dấu hiệu : thứ nhất là các cụm từ mang ý nhấn mạnh, sau cụm từ này đoạn văn quan trọng; chẳng hạn \u201cnói chung là\u201d, \u201cđặc biệt là\u201d, \u201ctóm lại\u201d, \u201ccuối cùng thì\u201d, \u201ctrong bài viết này tôi muốn chỉ ra\u201d, \u201cbài viết nói về\u201d, \u201cnội dung gồm\u201d.."],[387,"Thứ hai là các cụm từ không quan trọng, sau cụm từ này là các thành phần không có nhiều giá trị trong việc tóm tắt, chẳng hạn: \u201chiếm khi mà\u201d, \u201cbài này không nói đến\u201d, \u201ckhông thể nào\u2026\u201d - Dựa vào thống kê tần suất từ: Độ quan trọng của từ phụ thuộc vào số lần xuất hiện của từ đó trong văn bản"],[388,"Có thể dùng các kĩ thuật như tf-idf, tập thuật ngữ thường xuyên (frequent item set) để xác định tần suất từ"],[389,"b) Phương pháp cấu trúc Các phương pháp này sử dụng các mối liên hệ cấu trúc - ngữ pháp - ngữ nghĩa để xác định các đơn vị ngữ liệu quan trọng"],[390,"Tư tưởng chính của các phương pháp này là những đơn vị ngữ liệu nào có chứa các thành phần liên quan nhiều với các thành phần khác sẽ có mức độ quan trọng cao"],[391,"Việc đánh giá các mối quan hệ sẽ dựa trên các mạng ngữ nghĩa hoặc các quan hệ cú pháp"],[392,"- Phương pháp sử dụng quan hệ giữa câu, đoạn Phương pháp này xác định mối quan hệ giữa các đoạn trong văn bản hay các câu trong đoạn với nhau thông qua việc tính toán mức độ liên quan giữa chúng"],[393,"Các độ Cosine, Jaccard\u2026 được chọn để xác định độ tương đồng giữa các câu hay đoạn văn bản đó"],[394,"Sau đó, ta chọn ra đoạn hay câu có độ liên quan lớn nhất"],[395,"+ Phương pháp chuỗi từ vựng (lexical chains) Phương pháp liên kết từ vựng sử dụng các từ điển quan hệ từ vựng để xây dựng các chuỗi từ liên kết với nhau về mặt ngữ nghĩa"],[396,"Sau khi xây dựng được chuỗi"],[397,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[398,"8 các từ vựng này, ta đánh giá độ mạnh của chúng và chọn ra những câu phù hợp"],[399,"Morris và Hirst (1991) là những người đưa ra mô hình tính chuỗi từ vựng đầu tiên"],[400,"Chuỗi từ vựng không những chỉ dùng trong tóm tắt văn bản mà còn được coi là lý thuyết tổng quát của vấn đề ngữ nghĩa trong xử lý ngôn ngữ tự nhiên + Phương pháp liên kết tham chiếu (word coreferences) Phương pháp này gọi là phương pháp trích chọn trùng lặp (anaphora-based method)"],[401,"Theo phương pháp này, các cụm trùng lặp được chọn ra, phân rã xem đâu là từ (cụm từ) tham chiếu và từ (cụm từ) được tham chiếu"],[402,"Sau khi phân tách các cụm trùng lặp, chúng ta tạo chuỗi các từ (cụm từ) tham chiếu đến cùng một từ được tham chiếu"],[403,"Chuỗi dài nhất sẽ được coi là trọng tâm của đoạn, các câu chứa các từ trong chuỗi này có một độ ưu tiên nào đó thì sẽ được chọn"],[404,"Kết thúc pha phân tích sẽ là việc tổng hợp các chỉ số đánh giá độ quan trọng của các đơn vị ngữ liệu và thực hiện việc chọn các đơn vị ngữ liệu nào có độ quan trọng lớn làm đầu vào cho pha sau"],[405,"Có thể nhận thấy các phương pháp thống kê dễ cài đặt hơn các phương pháp cấu trúc"],[406,"Việc cài đặt các phương pháp thống kê đơn thuần chỉ là các công thức toán học, còn để cài đặt các phương pháp cấu trúc thì lại cần thực hiện rất nhiều kĩ thuật về cấu trúc dữ liệu và thậm chí là các kĩ thuật trong lĩnh vực trí tuệ nhân tạo"],[407,"1.2.2"],[408,"Các phương pháp áp dụng trong pha biến đổi Pha biến đổi có nhiệm vụ biến đổi đơn vị ngữ liệu được trích xuất trong pha phân tích như cụm từ, câu, đoạn văn"],[409,"Thông thường pha biến đổi thực hiện rút gọn bản thân bên trong một câu, rồi có thể rút gọn đoạn mà không gây ảnh hưởng đến độ chính xác"],[410,"Các phương pháp trong pha biến đổi gồm: a) Giản lược về cấu trúc câu"],[411,"Lược bỏ các thành phần thừa, ít mang ý nghĩa trong câu, giúp cấu trúc câu được thu gọn lại"],[412,"Công việc này thường dựa trên phân tích cú pháp và phân tích ngữ nghĩa các thành phần trong câu"],[413,"Áp dụng phân tích cú pháp chúng ta được các cấu trúc của câu, qua đó ta có thể thay thế thành phần bằng những thành phần tương đương, ghép thành phần có nghĩa tương đương theo một luật nào đó"],[414,"Phương pháp này có thể làm câu ngắn gọn hơn, tuy nhiên khó bảo toàn được văn phong"],[415,""],[416,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[417,"9 b) Giản lược về mặt ngữ nghĩa Thay thế hoặc loại bỏ các từ, cụm từ có ý nghĩa cụ thể bằng những từ, cụm từ ý nghĩa lúc này sẽ tổng quát, điển hình là: - Trừu trượng hoá khái niệm: thay thế các khái niệm cụ thể bằng khái niệm chung"],[418,"- Thay thế ngữ tương đương: thay thế các ngữ đóng vai trò như nhau trong câu bằng một ngữ chung"],[419,"1.2.3"],[420,"Các phương pháp trong pha tổng hợp kết quả a) Phương pháp hiển thị phân đoạn Các đơn vị ngữ liệu được trích xuất hay giản lược từ các pha trước được liên kết lại thành đoạn theo đúng thứ tự trong văn bản gốc, không thêm bớt từ nối và cũng không sắp xếp lại"],[421,"Văn bản kết quả của phương pháp này có độ dễ đọc và dễ hiểu kém, thậm chí lủng củng vì các đơn vị ngữ liệu có thể bị mập mờ tham chiếu, không có từ nối hoặc thừa từ"],[422,"b) Phương pháp hiển thị liên kết Với phương pháp này, ta sẽ đưa thêm các thông tin bổ sung vào văn bản tóm tắt"],[423,"Hai phương pháp thường được áp dụng trong sử dụng mẫu (template) ngữ liệu huấn luyện (corpus)"],[424,"1.3"],[425,"Các phương pháp đánh giá Đánh giá một bản tóm tắt là một công việc khó bởi không tồn tại một bản tóm tắt lý tưởng cho một (hoặc một tập) văn bản đưa ra"],[426,"Hơn nữa, việc đánh giá nội dung tóm tắt cũng rất khó khăn"],[427,"Trường hợp kết quả là một câu trả lời cho một câu hỏi, ta có thể xác định được câu trả lời đó đúng hay sai, nhưng trong các trường hợp khác, thật khó trả lời liệu đầu ra là phải một kết quả đúng hay không"],[428,"Thực tế luôn có khả năng một hệ thống sinh ra một bản tóm tắt tốt nhưng lại sai khác với bản tóm tắt do người thực hiện"],[429,"Bên cạnh đó, khi việc đánh giá được thực hiện bởi con người thì chi phí đánh giá sẽ rất cao"],[430,"Mặt khác, tóm tắt văn bản còn liên quan đến tỉ lệ nén văn bản, do đó, việc đánh giá bản tóm tắt cần phải quan tâm đến vấn đề này, khi đó độ phức tạp và chi phí đánh giá sẽ tăng cao"],[431,"Có nhiều kiểu đánh giá khác nhau tuỳ thuộc vào kiểu tóm tắt của hệ thống"],[432,"Có thể là đánh giá trong (intrinsic) \u2013 tập trung vào chất lượng bản tóm tắt và đánh giá ngoài (extrinsic) \u2013 tập trung vào nhiệm vụ (McKeown 1998)"],[433,""],[434,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[435,"10 Các tiêu chí đánh giá: - Độ mạch lạc (Coherence): đánh giá mức độ rõ ràng của văn bản tóm tắt, tính súc tích, khả năng có thể đọc và hiểu được của bài viết\u2026 - Độ hàm chứa thông tin (Informationess): tỉ lệ thông tin của văn bản gốc trong văn bản tóm tắt"],[436,"- Độ liên quan (Relevance): xác định mức độ phù hợp của văn bản tóm tắt với chủ đề cho trước (chủ đề có thể là một câu truy vấn)"],[437,"- Độ dễ đọc hiểu (Reading Comprehence): một người được giao việc đọc văn bản kết quả, sau đó trả lời các câu hỏi, hệ thống sẽ phải cho điểm và từ đó đưa ra phần trăm những câu trả lời đúng"],[438,"1.3.1"],[439,"Các phương pháp đánh giá trong a) So sánh với văn bản tóm tắt khác Ý tưởng cơ bản của phương pháp này là đem văn bản do hệ thống tóm tắt so sánh với các bản tóm tắt khác (có thể do hệ thống tóm tắt khác thực hiện hoặc do con người thực hiện)"],[440,"Thông thường là đem so sánh với văn bản tóm tắt do con người thực hiện"],[441,"Việc so sánh giữa các bản tóm tắt này có thể do con người thực hiện hoặc có thể thực hiện tự động"],[442,"Khi so sánh, có thể sử dụng một số độ đo sau: - Độ chính xác (Precision) và độ bao phủ (Recall)"],[443,"Tuy nhiên, 2 độ đo này chưa đủ để phân biệt các bản tóm tắt, các bản tóm tắt khác nội dung nhưng vẫn có cùng độ đo"],[444,"- Độ đo hạng câu (Sentence Rank): thay thế cho độ bao phủ, khi đó, một bản tóm tắt được đặc trưng bởi hạng của các câu trong các bản tóm tắt thích hợp"],[445,"Hạng của các câu trong bản tóm tắt do hệ thống thực hiện và trong các bản tóm tắt dùng để so sánh có thể tính bằng độ đo tương quan"],[446,"Độ do này áp dụng đối với hệ thống tóm tắt dạng trích xuất"],[447,"- Độ đo dựa trên nội dung (Content-Based): dựa trên sự tương tự về mặt từ vựng, và có thể áp dụng đối với cả 2 dạng tóm tắt"],[448,"Tuy nhiên, độ đo này hữu dụng với các bản tóm tắt trích xuất, hoặc với các bản tóm tắt dạng abstract nhưng có mức độ cắt-dán cao (tức là văn bản tóm tắt được tạo bởi nhiều từ, cụm từ, câu nguyên dạng trong văn bản nguồn)"],[449,""],[450,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[451,"11 b) So sánh với văn bản nguồn Với phương pháp này, ta đem so sánh văn bản tóm tắt với văn bản nguồn để xác định mức độ hàm chứa thông tin của văn bản tóm tắt"],[452,"Các độ đo dựa trên nội dung như trên có thể sử dụng để đánh giá"],[453,"Paice và Jones (1993) đã đưa ra phương pháp sử dụng thống kê để xác định mỗi thuật ngữ có phải là thuật ngữ trung tâm hay không phải thuật ngữ trung tâm"],[454,"Tiếp đó, phân loại vào các nhóm Chính xác (Correct), không chính xác (Incorrect) và thiếu (Missing)"],[455,"Hệ thống tóm tắt TIPSTER SUMMAC đánh giá các bản tóm tắt dạng Q&A (Question and Answer \u2013 Hỏi và trả lời) (Mani, Firmin, House, Chrzanowski, Klein, Hirschman, Sundhem, Obrst (1998)"],[456,"Hệ thống này thay vì biểu diễn các khái niệm ở mức sâu thì chỉ xác định xem trong văn bản tóm tắt có hay không những khái niệm then chốt trong văn bản nguồn"],[457,"Theo phương pháp tóm tắt này thì ta đưa vào một văn bản nguồn và một chủ đề, rồi thực hiện tóm tắt dựa trên chủ đề đó để trả lời cho câu hỏi"],[458,"Khi đó, ta có thể xác định xem câu trả lời có Chính xác (chứa câu trả lời đúng), hoặc Đúng một phần (chứa một phần câu trả lời) hay Thiếu (không chứa câu trả lời)"],[459,"1.3.2"],[460,"Các phương pháp đánh giá ngoài Ý tưởng cơ bản của các phương pháp đánh giá ngoài là đánh giá tác dụng của bản tóm tắt với các nhiệm vụ khác nhau"],[461,"- Đánh giá mức độ liên quan (relevance): ý tưởng của phương pháp này là đưa ra một văn bản và một chủ đề, đánh giá xem mức độ liên quan của văn bản với chủ đề đó"],[462,"- Đánh giá mức độ đọc hiểu: trước tiên, một người được đọc các văn bản tóm tắt từ một hoặc nhiều văn bản, sau đó trả lời các câu hỏi kiểm tra"],[463,"Hệ thống tự động tính điểm các câu trả lời và đánh giá tỉ lệ trả lời đúng"],[464,"Nếu bản tóm tắt cho phép trả lời các câu hỏi giống như khi đọc toàn bộ văn bản nguồn thì bản tóm tắt đó có khả năng cung cấp thông tin cao"],[465,"Hovey và Marcu (1998) thực hiện đo mức độ cung cấp thông tin dựa trên việc người ta có thể khôi phục lại các thông tin quan trọng trong văn bản khi đọc"],[466,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[467,"12 bản tóm tắt của văn bản đó"],[468,"Bằng thực nghiệm, tác giả tiến hành dựng lại văn bản gốc dựa trên việc đọc văn bản tóm tắt kết hợp phỏng đoán"],[469,"1.4"],[470,"Kết luận Trong chương này nhóm đồ án đã trình bày tổng quan về tóm tắt văn bản, đưa ra mô hình tóm tắt văn bản, các phương pháp sử dụng trong các pha của mô hình tóm tắt, các phương pháp đánh giá"],[471,""],[472,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[473,"13 CHƯƠNG 2 : BÀI TOÁN TÓM TẮT VĂN BẢN TIẾNG VIỆT 2.1"],[474,"Một số hướng tiếp cận bài toán tóm tắt văn bản Tại Việt Nam hiện nay, lĩnh vực xử lý ngôn ngữ tự nhiên đã có được thành tích trong các bài toán phân tách từ, phân lớp và phân nhóm văn bản"],[475,"Tuy nhiên bài toán tóm tắt văn bản chưa có nhiều nghiên cứu và đa phần các công trình nghiên cứu đều sử dụng hoặc cải tiến các phương pháp dựa trên thống kê"],[476,"Có thể kể đến một số công trình nghiên cứu như: Đỗ Phúc, Hoàng Kiếm (2006) đã sử dụng cây hậu tố để phát hiện các dãy từ phổ biến trong các câu của văn bản, dùng từ điển đồng nghĩa và WordNet tiếng Việt để giải quyết vấn đề nghĩa của từ, rồi dùng kĩ thuật gom cụm để gom các câu trong văn bản (vector đặc trưng cho câu) và hình thành các vector đặc trưng cụm, sau đó rút ra câu chứa nhiều thành phần của các vector đặc trưng cụm"],[477,"Vương Toàn (2007) đã đề xuất quy trình tóm tắt văn bản khoa học"],[478,"Theo đó, đầu tiên cho máy đọc lướt văn bản và tìm xem có sẵn những đoạn văn mang tính chất \u201ctóm tắt\u201d hay không; tiếp theo là định chủ đề, xác định 4-5 tiêu đề đề mục hoặc từ khoá để máy tự động chọn lưu tất cả những câu có các từ khoá đó"],[479,"Công trình nghiên cứu của Nguyễn Trọng Phúc, Lê Thanh Hương (2008) lại sử dụng cấu trúc diễn ngôn để tóm tắt văn bản"],[480,"Theo đó, xây dựng cây cấu trúc diễn ngôn biểu diễn mỗi quan hệ diễn ngôn giữa các đoạn văn bản (như các quan hệ nhân-quả, liệt kê, diễn giải,\u2026), rồi từ cây cấu trúc diễn ngôn này đánh giá được độ quan trọng của các đoạn văn bản và tiến hành trích xuất tạo ra tóm tắt nội dung cho văn bản"],[481,"Với hướng tiếp cận tóm tắt đa văn bản dựa vào trích xuất câu, Trần Mai Vũ (2009) đã xây dựng đồ thị quan hệ thực thể để tăng cường tính ngữ nghĩa cho độ tương đồng câu để áp dụng cho tóm tắt đa văn bản tiếng Việt"],[482,"Nguyễn Việt Cường (2007) đã sử dụng phương pháp phân đoạn văn bản dựa trên chuỗi từ vựng kết hợp với phương pháp sinh tiêu đề dựa trên chủ đề của câu chủ đề nhằm thực hiện sinh tự động mục lục cho văn bản"],[483,"2.2"],[484,"Đặc điểm tiếng Việt"],[485,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[486,"14 2.2.1"],[487,"Đặc điểm chung Tiếng Việt là ngôn ngữ không biến hình từ và âm tiết tính tức là mỗi một tiếng (âm tiết) được phát âm tách rời nhau và được thể hiện bằng một chữ viết"],[488,"Hai đặc trưng này chi phối toàn bộ tổ chức bên trong của hệ thống ngôn ngữ Việt và cần được chú ý khi xử lý tiếng Việt trên máy tính"],[489,"Tiếng là đơn vị cơ sở của cấu tạo ngữ pháp Việt Nam"],[490,"Tiếng có thể có nghĩa, phai nghĩa và không có nghĩa; hơn nữa giữa 3 hiện tượng này có thể xuất hiện sự chuyển hoá lẫn nhau"],[491,"Tiếng tham gia vào hệ thống ngôn ngữ với tư cách một thành tố trong các cơ chế cấu tạo từ (từ đơn, từ láy, từ ghép\u2026)"],[492,"Theo Từ điển tiếng Việt \u2013 Hoàng Phê (1998) thì tiếng Việt hiện đại sử dụng 6718 âm tiết"],[493,"Hiện nay, có nhiều tranh luận khi định nghĩa từ trong tiếng Việt"],[494,"Theo Ngữ pháp tiếng Việt thì xét ở phương diện ngữ pháp có thể định nghĩa từ là đơn vị nhỏ nhất mà có nghĩa và có thể hoạt động tự do (trong câu), từ là đơn vị trung tâm của ngữ pháp Việt Nam, chi phối toàn bộ cú pháp tiếng Việt, đảm nhận và san sẻ các chức năng năng cú pháp trong câu và góp phần đưa câu vào các cấu tạo ngôn ngữ lớn hơn câu"],[495,"Từ đây trở đi, khái niệm từ được dùng với nghĩa trên khi nói về tiếng Việt, còn đối với các ngôn ngữ châu Âu (ví dụ tiếng Anh), từ (word) vẫn được hiểu theo nghĩa là \u201ccụm kí tự được ngăn cách bởi một hoặc nhiều dấu cách\u201d"],[496,"Cụm từ là những kiến trúc gồm hai từ trở lên kết hợp \u201ctự do\u201d với nhau theo những quan hệ ngữ pháp hiển hiện nhất định và không chứa kết từ ở đầu"],[497,"Cụm từ hoạt động trong câu mới mọi chức vụ ngữ pháp nhất định"],[498,"Câu là sự tổng hợp của các từ biểu thị một tư tưởng trọn vẹn"],[499,"Ví dụ: Từ \u2018học\u2019 là một từ gồm một tiếng Từ \u2018đại học\u2019 là một từ gồm hai tiếng Cụm từ \u2018khoa học máy tính\u2019 gồm 2 từ hay 4 tiếng Trong các hệ thống xử lý ngôn ngữ trên các tiếng châu Âu, để xác định các từ đặc trưng cho văn bản người ta có thể đơn giản lấy khoảng trắng làm ranh giới phân tách từ"],[500,"Đối với tiếng Việt thì ta lại không thể làm tương tự bởi nếu ta chỉ dựa vào khoảng trắng để phân tách thì kết quả ta chỉ có được các \u201ctiếng\u201d vô nghĩa và do đó độ chính xác của hệ thống có thể sẽ rất thấp"],[501,"Theo Ngữ pháp tiếng Việt - Nguyễn Hữu Quỳnh (2001) thì tiếng Việt có đến 80% là các từ 2 tiếng"],[502,"Từ tiếng Việt không có hiện tượng biến hình (ngôn ngữ đơn lập) bằng những phụ tố mang ý nghĩa ngữ"],[503,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[504,"15 pháp bên trong từ như các ngôn ngữ Ấn \u2013 Âu"],[505,"Dĩ nhiên, tiếng Việt cũng có một số hình thức biến hình như trường hợp thêm tiếng \u201csự trước một động từ để biến nó thành danh từ tương đương, ví dụ như động từ \u201clựa chọn\u201d và danh từ \u201csự lựa chọn\u201d hay thêm tiếng \u201choá\u201d sau một danh từ để biến nó thành động từ tương đương như danh từ \u201ctin học\u201d và động từ \u201ctin học hoá\u201d"],[506,"Phụ tố cấu tạo từ tồn tại hiển nhiên hơn ở cơ chế láy với những quy tắc ngữ âm khái quát chứ không hẳn là những dạng thức cụ thể đồng loạt (ở những từ láy có phần gốc là yếu tố còn rõ nghĩa, phần láy là yếu tố không rõ nghĩa)"],[507,"2.2.2"],[508,"Yếu tố ngoại lai trong từ tiếng Việt Tiếng Việt có các yếu tố ngoại lai thuộc gốc Hán, gốc Pháp, Anh trong đó yếu tố Hán vừa chiếm đa số vừa giữ vai trò khá quan trọng trong vốn từ và trong cấu tạo từ Việt"],[509,"Các yếu tố gốc Ấn \u2013 Âu đi vào tiếng Việt phải chịu áp lực rất mạnh của sự âm tiết hoá theo kiểu tiếng Việt"],[510,"Sự Việt hoá về mặt âm tiết: − Cắt từ nhiều âm tiết thành những âm tiết rời; − Âm tiết hoá các tổ hợp phụ âm; − Mỗi âm tiết nhận một thanh điệu thích hợp; − Cấu tạo lại âm tiết theo các âm của tiếng Việt (như không chấp nhận l, h, s\u2026 ở cuối âm tiết)"],[511,"Ngoài ra, khi Việt hoá các từ ngoại lai Ấn \u2013 Âu có sự đơn tố hoá từ nhiều hình vị (từ tố), tức là một số từ vốn là đa tố ở ngôn ngữ Ấn \u2013 Âu vào tiếng Việt được coi như từ đơn tố, ví dụ: sulơ, xuyết vôn tơ, mát xa\u2026; và có sự giản hoá về phát âm như sứ (đại sứ quán), lốp (vỏ bánh xe) từ enveloppe\u2026 2.2.3"],[512,"Từ dừng"],[513,"Từ dừng (stop-words) là các từ xuất hiện nhiều trong các văn bản mà thường thì không giúp ích trong việc phân biệt nội dung của các tài liệu"],[514,"Do đó, khi xây dựng chương trình tóm tắt, cần tìm ra các từ dừng trong văn bản và loại bỏ chúng"],[515,"Việc xác định các từ dừng trong văn bản được thông qua một từ điển từ dừng"],[516,"Từ dừng bao gồm một số liên từ như: và, thì, là.."],[517,"2.2.4"],[518,"Từ đồng nghĩa"],[519,"Theo Cơ sở ngôn ngữ học và tiếng Việt - Mai Ngọc Chừ (1997) từ đồng nghĩa là những từ tương đồng với nhau về nghĩa, khác nhau về âm thanh và có phân"],[520,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[521,"16 biệt với nhau về một vài sắc thái ngữ nghĩa hoặc sắc thái phong cách,.."],[522,"nào đó, hoặc đồng thời cả hai"],[523,"Những từ đồng nghĩa với nhau tập hợp thành một nhóm gọi là nhóm đồng nghĩa"],[524,"Ví dụ: dễ, dễ dàng, dễ dãi là những nhóm từ đồng nghĩa"],[525,"Thực ra, từ đồng nghĩa không phải là những từ trùng nhau hoàn toàn về nghĩa"],[526,"Chúng nhất định có những dị biệt nào đó bên cạnh sự tương đồng (mặc dù phát hiện sự dị biệt đó không phải lúc nào cũng dễ dàng)"],[527,"Những từ đồng nghĩa với nhau không nhất thiết phải tương đương với nhau về số lượng nghĩa, tức là các từ trong một nhóm đồng nghĩa không nhất thiết phải có dung lượng nghĩa bằng nhau: Từ này có thể có một hoặc hai nghĩa, nhưng từ kia có thể có tới dăm bảy nghĩa"],[528,"Thông thường, các từ chỉ đồng nghĩa ở một nghĩa nào đó"],[529,"Chính vì thế nên một từ đa nghĩa có thể tham gia vào nhiều nhóm đồng nghĩa khác nhau: Ở nhóm này nó tham gia với nghĩa này, ở nhóm khác nó tham gia với nghĩa khác"],[530,"Ví dụ: Từ \u201ccoi\u201d trong tiếng Việt là một từ đa nghĩa"],[531,"Tuỳ theo từng nghĩa được nêu lên để tập hợp các từ, mà \u201ccoi\u201d có thể tham gia vào các nhóm như: + coi \u2013 xem: coi hát \u2013 xem hát + coi \u2013 giữ: coi nhà \u2013 giữ nhà Trong mỗi nhóm từ đồng nghĩa thường có một từ mang nghĩa chung, được dùng phổ biến và trung hoà về mặt phong cách, được lấy làm cơ sở để tập hợp và so sánh, phân tích các từ khác"],[532,"Từ đó gọi là từ trung tâm của nhóm"],[533,"Ví dụ: Trong nhóm từ \u201cyếu, yếu đuối, yếu ớt\u201d, từ \u201cyếu\u201d được gọi là từ trung tâm"],[534,"Tuy nhiên, việc xác định từ trung tâm của nhóm không phải lúc nào cũng dễ và đối với nhóm nào cũng làm được"],[535,"Nhiều khi ta không thể xác định một cách dứt khoát được theo những tiêu chí vừa nêu trên, mà phải dựa vào những tiêu chí phụ như: tần số xuất hiện cao (hay được sử dụng) hoặc khả năng kết hợp rộng"],[536,"Chẳng hạn, trong các nhóm từ đồng nghĩa tiếng Việt như: hồi, thuở, thời; hoặc chờ, đợi; hoặc chỗ, nơi, chốn,.."],[537,"rất khó xác định từ nào là trung tâm"],[538,"Với bài toán tóm tắt văn bản thì từ đồng nghĩa cũng có một ý nghĩa khá quan trọng bởi trong các câu, đoạn văn trong văn bản có các từ đồng nghĩa hoặc gần nghĩa nhau và việc sử dụng từ đồng nghĩa sẽ làm nâng cao tính chính xác khi so sánh về độ tương đồng ngữ nghĩa giữa các đơn vị văn bản"],[539,""],[540,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[541,"17 2.2.5"],[542,"Đặc điểm chính tả Đặc điểm chính tả tiếng Việt có ý nghĩa quan trọng tiền xử lý dữ liệu văn bản"],[543,"Một số đặc điểm chính tả tiếng Việt cần quan tâm như: − Các tiếng đồng âm: như kĩ/kỹ, lí, lý\u2026 thường bị sử dụng lẫn nhau như: lý luận, lí luận, kĩ thuật, kỹ thuật\u2026 − Các từ địa phương: một số từ địa phương sử dụng thay cho các từ phổ thông, chẳng hạn: cây kiểng/cây cảnh, đờn/đàn, đậu phộng/lạc\u2026 − Vị trí dấu thanh: theo quy định đánh dấu tiếng Việt, dấu được đặt trên nguyên âm có ưu tiên cao nhất"],[544,"Tuy nhiên, khi viết văn bản nhiều bộ gõ văn bản không tuân thủ theo đúng nguyên tắc trên nên xảy ra hiện tượng dấu được đặt ở các vị trí khác nhau, chẳng hạn: toán, tóan, thuý, thúy\u2026 − Cách viết hoa: theo quy định, chữ cái đầu câu và tên riêng phải viết hoa, tuy nhiên vẫn tồn tại một số cách viết tuỳ tiện"],[545,"− Phiên âm tiếng nước ngoài: hiện nay, vẫn còn nhiều tranh cãi giữa việc phiên âm tiếng nước ngoài thành tiếng Việt (Việt hoá), nên tồn tại nhiều cách viết (giữ nguyên gốc tiếng nước ngoài, phiên âm ra tiếng Việt), ví dụ: Singapore/Xin−ga−po"],[546,"− Từ gạch nối: do cách viết dấu gạch nối tuỳ tiện, không phân biệt được giữa nối tên riêng hay chú thích"],[547,"− Kí tự ngắt câu: các kí tự đặc biệt như \u201c.\u201d, \u201c;\u201d, \u201c!\u201d, \u201c?\u201d, \u201c\u2026\u201d ngăn cách giữa các câu hoặc các vế câu trong câu ghép"],[548,"Tóm tại, tiếng Việt là ngôn ngữ không biến hình từ và âm tiết tính, do đó, việc phân loại từ (danh từ, động từ, tính từ\u2026) và ý nghĩa từ là vấn đề khó, cần có nhiều nghiên cứu thêm"],[549,"Do vậy, tiền xử lý văn bản (tách từ, tách đoạn, tách câu\u2026) trở nên rất phức tạp với việc xử lý các hư từ, phụ từ, từ láy\u2026; hơn nữa, phương thức ngữ pháp chủ yếu là trật tự từ nên nếu áp dụng phương pháp tính xác suất xuất hiện của từ có thể không chính xác như mong đợi"],[550,"Mặt khác, ranh giới xác định từ không phải là khoảng trắng, khiến cho việc tách từ trở nên khó khăn, dẫn đến khó khăn cho các giai đoạn tiếp theo như kiểm lỗi chính tả, gán nhãn từ loại, thống kê tần suất từ\u2026 Như thế, các phương pháp xử lý ngôn ngữ đang áp dụng cho tiếng Anh không thể áp dụng trực tiếp cho tiếng Việt mà cần có sự thay đổi cho phù hợp"],[551,""],[552,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[553,"18 2.3"],[554,"Phương pháp cho bài toán tóm tắt văn bản tiếng Việt"],[555,"Trong IR, mỗi văn bản được biểu diễn dưới dạng vector, chẳng hạn như Di=(di1, di2, \u2026, din) trong đó dik biểu diễn trọng số của từ Tk trong tài liệu Di"],[556,"Tính toán độ tương tự giữa hai văn bản Di và Dj là Sim(Di, Dj) \u2013 theo các công thức tính độ tương tự"],[557,"Nếu độ tương tự này đạt đến một ngưỡng đủ lớn thì ta nói rằng chúng có \u201cliên quan về mặt ngữ nghĩa\u201d, và ta có thể thiết lập một liên kết giữa hai văn bản này"],[558,"Áp dụng phương pháp này vào việc tóm tắt văn bản tự động, thay vì tìm liên kết giữa các văn bản, ta sẽ tìm liên kết trong nội bộ văn bản (liên kết giữa các câu trong văn bản)"],[559,"Sau khi xây dựng được đồ thị quan hệ, ta có được hình vẽ trực quan cấu trúc của văn bản"],[560,"Từ cấu trúc này, ta có thể xây dựng văn bản tóm tắt bằng cách trích xuất ra các câu phù hợp"],[561,"Trong việc xác định ngưỡng để quyết định hai câu trong văn bản có quan hệ với nhau về mặt ngữ nghĩa hay không có một ý nghĩa quan trọng, bởi lẽ ngưỡng này có thể là tốt cho một dạng văn bản nào đó nhưng lại không tốt cho văn bản khác"],[562,"Như vậy, trong quá trình xây dựng và đánh giá kết quả của chương trình tóm tắt văn bản, cần phải thực nghiệm với nhiều ngưỡng khác nhau để chọn ra một ngưỡng thích hợp"],[563,"Khi áp dụng phương pháp cấu trúc văn bản này đối với văn bản tiếng Việt do có những khác biệt đối với văn bản tiếng Anh nên cần phải có một số cải tiến để nâng cao độ chính xác"],[564,"Trước hết, đối với việc phân tách từ vựng tiếng Việt"],[565,"Có thể sử dụng các phương pháp như: + Phương pháp so khớp cực đại hay còn gọi là phương pháp Left Right Maximum Matching (LRMM)"],[566,"Theo đó, ta thực hiện duyệt một ngữ hoặc một câu từ trái sang phải và chọn từ có nhiều âm tiết có mặt trong từ điển, rồi cứ thế tiếp tục cho đến khi hết câu"],[567,"+ Phương pháp sử dụng bộ chuyển trạng thái hữu hạn có trọng số WFST (Weighted Finite State Transducer) kết hợp với mạng Neural do Đinh Điền (2001) đưa ra"],[568,"Với ý tưởng cơ bản là áp dụng WFST kết hợp với trọng số là xác suất xuất hiện của mỗi từ trong ngữ liệu"],[569,"Dùng WFST để duyệt qua câu cần xét"],[570,"Cách duyệt có trọng số lớn nhất sẽ là cách từ được chọn"],[571,"Ngoài ra sử dụng mạng Neural để khử nhập nhằng nếu có"],[572,"Do việc xây dựng bộ tách từ khá phức tạp và nằm ngoài phạm"],[573,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[574,"19 vi của luận văn này nên chúng tôi sử dụng bộ tách từ đã được viết sẵn và cung cấp miễn phí để thực hiện bước tiền xử lý các văn bản"],[575,"Tiếp theo đó là cần loại bỏ các từ dừng"],[576,"Từ dừng (stop-words) là các từ xuất hiện nhiều trong các văn bản mà thường thì không giúp ích trong việc phân biệt nội dung của các tài liệu"],[577,"Do đó, khi xây dựng chương trình tóm tắt, cần tìm ra các từ dừng trong văn bản và loại bỏ chúng"],[578,"Việc xác định các từ dừng trong văn bản được thông qua một từ điển từ dừng"],[579,"Khi đã loại bỏ các từ dừng, cần phải xác định tiếp các từ đồng nghĩa trong văn bản"],[580,"Đối với tiếng Việt, do có một số lượng lớn các từ đồng nghĩa nên khi thực hiện đo độ tương tự giữa các câu trong văn bản, ta sử dụng thêm một từ điển đồng nghĩa để xác định các từ có ý nghĩa tương đồng giữa các câu, để có thể nâng cao phần nào độ chính xác"],[581,"Trong chương tiếp theo, chúng tôi sẽ trình bày chi tiết việc xây dựng ứng dụng tóm tắt văn bản và kĩ thuật sử dụng từ điển đồng nghĩa này"],[582,"Ngoài ra, trong bước tiền xử lý, các vấn đề như bảng mã, chính tả, dấu câu\u2026 cũng cần được xử lý để đảm bảo tính khách quan và chính xác cho các bước tiếp theo"],[583,"Hình vẽ dưới đây mô tả một đồ thị quan hệ của các câu trong văn bản \u201cHỗ trợ 400 USD cho sinh viên mua laptop\u201d, bỏ qua các liên kết có độ tương tự dưới 0,2"],[584,"Sau khi đã có được đồ thị quan hệ giữa các câu trong văn bản, tiến hành duyệt đồ thị và chọn ra các câu quan trọng theo một số phương pháp sau: Cách 1"],[585,"Dựa vào bậc của các nút trên đồ thị Bậc của một nút trên đồ thị là số lượng liên kết tới các nút khác"],[586,"Khi một nút có bậc lớn thì câu tương ứng nút đó sẽ phủ một lượng lớn từ vựng và có thể chứa chủ đề của nhiều câu khác"],[587,"+ Chọn n nút có bậc cao nhất trong đồ thị (với n là số câu cần chọn trong văn bản tóm tắt)"],[588,"+ Sắp xếp các câu được chọn ra theo thứ tự xuất hiện trong văn bản gốc"],[589,""],[590,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[591,"20 Hình 2.1 Đồ thị liên kết các câu trong văn bản"],[592,"Cách 2"],[593,"Duyệt theo chiều sâu + Chọn một nút quan trọng (thường chọn nút đầu tiên hoặc nút có bậc cao)"],[594,"+ Chọn nút tiếp theo tương tự nhất với nút trước đó, và cứ như thế"],[595,"Khi đã duyệt hết mà vẫn chưa đủ số câu mong muốn, ta sử dụng tiếp cách 1 với các câu còn lại"],[596,"Cách 3"],[597,"Phân đoạn văn bản + Chia văn bản thành từng đoạn"],[598,"+ Áp dụng cách 1 cho mỗi đoạn, số đoạn của văn bản được chia phải đảm bảo để chọn được ít nhất một câu trong mỗi đoạn"],[599,"Trong chương này, chúng tôi đã trình bày về những hướng tiếp cận với bài toán tóm tắt văn bản tiếng Việt, đồng thời cũng nêu ra những đặc trưng cần chú ý của tiếng Việt và cuối cùng đưa ra cách tiếp cận của chúng tôi về việc sử dụng phương pháp cấu trúc để tóm tắt văn bản"],[600,"2.4"],[601,"Kết luận"],[602,"Trong chương này nhóm đồ án đã trình bày về một số hướng tiếp cận bài toán tóm tắt văn bản tiếng Việt"],[603,"Đồng thời cũng đưa ra những đặc trưng quan trọng"],[604,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[605,"21 cần chú ý của tiếng Việt dưới góc độ của lĩnh vực xử lý ngôn ngữ tự nhiên, từ đó lựa chọn phương pháp cho bài toán tóm tắt văn bản tiếng Việt"],[606,""],[607,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[608,"22 CHƯƠNG 3: ỨNG DỤNG PHƯƠNG PHÁP CẤU TRÚC ĐỂ TÓM TẮT VĂN BẢN TIẾNG VIỆT 3.1"],[609,"Mô hình tóm tắt sử dụng phương pháp cấu trúc Hình 3.1 Mô hình tóm tắt văn bản sử dụng phương pháp cấu trúc Trong mô hình này, đầu vào là các văn bản tiếng Việt thuộc nhiều thể loại khác nhau, và để cho đơn giản thì chúng tôi chi sử dụng các văn bản thuần"],[610,"Các văn bản được xử lý qua 4 giai đoạn"],[611,"1"],[612,"Tiền xử lý Giai đoạn này nhằm chuẩn hoá văn bản về bảng mã, các lỗi chính tả, các lỗi về dấu câu, v.v\u2026 ; sau đó, sử dụng bộ tách từ để tách ra các từ và các câu"],[613,"2"],[614,"Xử lý từ Pha này nhằm mục đích loại bỏ các từ dừng dựa trên một từ điển từ dừng có trước ; sau đó với mỗi từ trong câu, căn cứ vào từ điển đồng nghĩa để lập ra danh sách các từ đồng nghĩa"],[615,"3"],[616,"Xây dựng đồ thị liên kết Trong pha này, chúng tôi sử dụng kỹ thuật tf-idf để tính toán và vector hoá các câu của văn bản, sau đó tính toán độ tương đồng giữa các vector này"],[617,"Nếu độ"],[618,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[619,"23 tương đồng giữa hai vector đạt đến một ngưỡng nào đó thì 2 câu sẽ được đưa vào đồ thị liên kết"],[620,"Giá trị của ngưỡng này cũng sẽ được chúng tôi thử nghiệm và đánh giá hiệu lực"],[621,"4"],[622,"Sinh văn bản tóm tắt Trong pha này, chúng tôi sử dụng 3 kỹ thuật ở mục 2.3 để tạo ra văn bản tóm tắt"],[623,"Như vậy, mỗi văn bản đầu vào sẽ có 3 văn bản tóm tắt tương ứng với từng kỹ thuật sau đây: + Dựa vào bậc của các nút trên đồ thị"],[624,"+ Duyệt theo chiều sâu"],[625,"+ Phân đoạn văn bản"],[626,"3.2"],[627,"Tiền xử lý văn bản Nội dung của mỗi văn bản được lưu trữ trong một file text và được mã hoá bằng mã Unicode UTF-8"],[628,"Tiếp đó, công cụ JvnTextPro-v.2.0 được sử dụng để phân tách ra các từ và các câu"],[629,"Kết quả ta sẽ thu được 2 file: một file chứa các từ được phân tách (dấu \u201c \u201d được sử dụng để ngăn cách giữa các từ, các từ ghép được nối với nhau bằng dấu gạch dưới \u201c_\u201d), và một file chứa các câu (Các câu được phân cách bởi dấu \u201c .\u201d) Ví dụ: Đoạn văn bản sau: Trong thời gian gần đây, các diễn đàn công nghệ trên toàn thế giới luôn xôn xao vì lỗi ăng-ten của iPhone 4 cùng những hệ lụy xung quanh nó"],[630,"Hàng loạt khách hàng đã phàn nàn, thậm chí đâm đơn kiện Quả táo vì bán sản phẩm lỗi"],[631,"Không những vậy, tạp chí tiêu dùng uy tín Consumer Reports của Mỹ còn lên tiếng chê bai iPhone 4 và khuyến cáo người dùng không nên mua sản phẩm này"],[632,"Lỗi ăng-ten của iPhone 4 khiến chủ tịch Steve Jobs mất ăn mất ngủ trong thời gian vừa qua"],[633,"Khi tách từ xong ta sẽ được kết quả: Trong thời_gian gần_đây , các diễn_đàn công_nghệ trên toàn thế_giới luôn xôn_xao vì lỗi ăng - ten của iPhone 4 cùng những hệ_lụy xung_quanh nó"],[634,"Hàng_loạt khách_hàng đã phàn_nàn , thậm_chí đâm_đơn_kiện Quả táo vì bán sản_phẩm lỗi .Không những vậy , tạp_chí tiêu_dùng uy_tín Consumer Reports của Mỹ còn lên_tiếng chê_bai iPhone 4 và khuyến_cáo người_dùng không nên mua"],[635,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[636,"24 sản_phẩm này .Lỗi ăng - ten của iPhone 4 khiến chủ_tịch Steve Jobs mất ăn mất_ngủ trong thời_gian vừa qua Và danh sách các câu: Trong thời gian gần đây, các diễn đàn công nghệ trên toàn thế giới luôn xôn xao vì lỗi ăng-ten của iPhone 4 cùng những hệ lụy xung quanh nó"],[637,"Hàng loạt khách hàng đã phàn nàn, thậm chí đâm đơn kiện Quả táo vì bán sản phẩm lỗi"],[638,"Không những vậy, tạp chí tiêu dùng uy tín Consumer Reports của Mỹ còn lên tiếng chê bai iPhone 4 và khuyến cáo người dùng không nên mua sản phẩm này"],[639,"Lỗi ăng-ten của iPhone 4 khiến chủ tịch Steve Jobs mất ăn mất ngủ trong thời gian vừa qua"],[640,"Kết quả của bước tiền xử lý này sẽ là đầu vào cho bước xử lý từ tiếp theo"],[641,"3.3"],[642,"Xử lý từ Pha này có đầu vào là tập tin văn bản đã được thêm dấu phân tách từ ở bước trên và có nhiệm vụ xác định các câu"],[643,"Ranh giới để phân định các câu là các dấu kết thúc câu bao gồm: dấu chấm câu (.), dấu hỏi chấm (?), dấu chấm than (!) và dấu ba chấm (...)"],[644,"Đồng thời, chương trình có nhiệm vụ xác định các từ, ranh giới để xác định là dấu \u201c \u201d"],[645,"Thuật toán dưới đây thể hiện việc chọn ra các từ, các câu, các từ đồng nghĩa và loại bỏ các từ dừng"],[646,"Thuật toán 1 Input: Tập tin văn bản đã tách từ"],[647,"Output: Tập các từ T, Tập các câu Cau"],[648,"1"],[649,"Mở tập tin văn bản ST=Nội dung file 2"],[650,"Tách ra các câu n=0; //Đếm số lượng câu k=1; while k<length(st) { if(ST(k)=Dấu kết thúc câu) { n=n+1; cau()=câu kết thúc tại vị trí k;"],[651,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[652,"25 } k++; } 3"],[653,"Tách ra các từ k=1; while k<length(st) { if ST(k)= ' ' { word=Chọn ra từ kết thúc tại k; Chuẩn hoá word; {Loại bỏ dấu cách, các kí hiệu vô ích, chuyển về chữ thường} Đưa word Tập từ Term; Else Đưa word vào Tập từ T; } k=k+1; } 4"],[654,"return T, Cau; 3.4"],[655,"Xây dựng đồ thị liên kết"],[656,"Pha này có nhiệm vụ xây dựng đồ thị liên kết giữa các câu trong văn bản với đầu vào là danh sách các câu và các từ đã được xử lý ở pha trước đó"],[657,"Ta thực hiện vector hoá các câu trong văn bản và thực hiện tính toán độ tương đồng giữa 2 câu bất kì trong văn bản"],[658,"Trong mô hình không gian vector, ta coi mỗi văn bản như một vector (hay một điểm) trong không gian Euclide nhiều chiều, trong đó mỗi chiều là từ"],[659,"Có 3 cách để biểu diễn vector tuỳ thuộc vào kiểu của các thành phần trong vector: nhị phân, tần số từ tf, và tf-isf"],[660,"Giả sử văn bản cần tóm tắt có n câu được đánh số là cau1, cau2,\u2026, caun và m từ t1, t2,\u2026, tm gọi nij là số lần xuất hiện của từ ti trong câu cauj"],[661,"Trong phương pháp này sẽ sử dụng cách biểu diễn tf-idf để biểu diễn các vector văn bản"],[662,"Mỗi thành phần thứ i của vector văn bản cauj được tính bằng: Trong đó: - , j= - Giá trị TF(ti , cauj) được tính bằng nhiều cách: + Tính bằng tổng số lần xuất hiện của các từ trong tài liệu:"],[663,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[664,"26 TF(ti ,cauj)= (1) + Tính bằng số lần xuất hiện lớn nhất của các từ"],[665,"TF(ti ,cauj)= (2) + Tính bằng ln số lần xuất hiện số từ: TF(ti ,cauj )= (3) Trong cài đặt thử nghiệm, công thức (3) được sử dụng để tính giá trị TF(ti,cauj)"],[666,"- Với mỗi từ ti giá trị ISF(ti) được tính bằng tỉ lệ thức của các câu mà xuất hiện từ ti với tổng số câu có được"],[667,"Gọi S là tập hợp các câu Sti là tập hợp các câu có chứa từ ti"],[668,"S= Sti ={cau j | nij >0} Giá trị ISF(ti) có thể tính theo một số cách: + Tính bằng thương số của |S| và | Sti |: + Tính bằng hàm logarit: Sau khi vector hoá các câu trong văn bản, ta tính độ tương quan giữa từng cặp câu với nhau theo công thức tính độ tương đồng Cosine đã nêu ở trên"],[669,"Khi đó, độ tương đồng giữa 2 câu caui và cauj bất kì được tính bằng: Trong đó: sim(caui,cauj) là độ tương tự của 2 câu caui và cauj"],[670,""],[671,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[672,"27 m: là số từ của 1 câu trong văn bản"],[673,"Tiếp đó ta xây dựng đồ thị liên kết giữa các câu trong văn bản"],[674,"Đồ thị được biểu diễn bằng một ma trậ D như sau: Trong đó: ngưỡng là một ngưỡng được cho trước và được tính toán bằng thực nghiệm đối với các loại văn bản"],[675,"Trong thử nghiệm này của chúng tôi chọn ngưỡng bằng 0,4"],[676,"Thuật toán 2: Xây dựng đồ thị liên kết"],[677,"Input: Tập từ T, số lượng từ m, tập các câu Cau, số lượng câu n"],[678,"Output: Đồ thị liên kết các câu"],[679,"D(i,j), i=1..m, j=1..n 1.{Tính tf-isf} for i = 1 to m for j = 1 to n if T(i)=T(j) then N(i,j) = N(i,j) + 1; {Tính TF} for i = 1 to m for j = 1 to n begin tf(i,j) = 0; if N(i,j) > 0 then tf(i,j) = 1 + ln(1+ln(N(i,j))) end; {Tính ISF} for i = 1 to m begin count = 0; for j = 1 to n if N(i,j) > 0 then count = count + 1; isf(i) = ln((1+n)/count) end; 2.{Tính toán độ tương đồng} for i = 1 to m"],[680,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[681,"28 for j = 1 to n begin sim = cos(caui, cauj) if sim > threshold then D(i,j) = sim; return D(i,j) Hinh 3.2: Đồ thị liên kết của văn bản input1.txt 3.5"],[682,"Sinh văn bản tóm tắt"],[683,"Giả sử văn bản cần tóm tắt có độ dài là p% độ dài của văn bản gốc"],[684,"Chúng tôi xây dựng thủ tục duyệt đồ thị để chọn ra những câu quan trọng theo 3 phương pháp: a) Phương pháp 1"],[685,"Dựa vào bậc của các nút trên đồ thị"],[686,""],[687,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[688,"29 Bước 1: Tính bậc của mỗi nút trong đồ thị (bậc được tính bằng số liên kết của nút với các nút khác)"],[689,"Bước 2: Sắp xếp các nút theo thứ tự bậc giảm dần"],[690,"Bước 3: Chọn ra các nút có bậc cao nhất, ngừng chọn khi số câu đủ yêu cầu"],[691,"Thuật toán 3 Input: Đồ thị liên kết D(i,j), tỉ lệ nén p%, số câu n"],[692,"Output: Tập các câu được chọn Selection"],[693,"1"],[694,"{Tính số câu cần chọn} NumberOfSent = Round(n * p); 2"],[695,"{Tính bậc của các nút} for i = 1 to n begin Degree(i) = 0; for j = 1 to n if D(i,j) <> 0 then Degree(i) = Degree(i) + 1; end; 3"],[696,"Sắp xếp Degree(i), i = 1..n theo chiều giảm dần 4"],[697,"{Chọn ra các câu} for i = 1 to NumberOfSent selection(i) = Số thứ tự của câu tương ứng; 5"],[698,"Sắp xếp selection theo chiều tăng dần; 6"],[699,"return selection; Ví dụ: Với văn bản input1.txt, tỉ lệ nén được chọn là 20%, số câu cần chọn ra là 5"],[700,"Theo thuật toán 3, thứ tự của các nút được sắp xếp theo bậc giảm dần là (bỏ qua các nút có bậc bằng 0:"],[701,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[702,"30 Đỉnh Bậc Đỉnh Bậc Đỉnh Bậc Đỉnh Bậc 11 14 17 9 9 4 7 2 8 13 23 9 18 4 14 2 10 13 12 8 21 4 15 2 1 12 22 8 6 3 24 1 4 12 20 7 13 3 2 10 0 6 16 3 3 10 5 5 19 3 Bảng 3.1: Bậc của các đỉnh sắp xếp theo thứ tự giảm dần của văn bản input1.txt Kết quả các câu được chọn ra là: 11, 8, 10, 1, 4 Văn bản tóm tắt là: [1]Những người này khuyến cáo Quả táo cần nhanh chóng đưa ra biện pháp khắc phục hậu quả để lấy lại lòng tin từ khách hàng, cho dù chi phí bỏ ra sẽ rất lớn"],[703,"[4]Không những vậy, tạp chí tiêu dùng uy tín Consumer Reports của Mỹ còn lên tiếng chê bai iPhone 4 và khuyến cáo người dùng không nên mua sản phẩm này"],[704,"[8]Tuy nhiên, ít lâu sau, \"Quả táo\" lại khẳng định lỗi sóng yếu là do phần cứng và sẽ mất rất nhiều thời gian để khắc phục khi mà hãng đã bán ra một số lượng lớn sản phẩm"],[705,"[10]Không những thế, họ còn buộc Quả táo phải bồi thường chi phí mua điện thoại, kể cả những tổn thất phát sinh khác mà khách hàng phải gánh chịu"],[706,"[11]Từ khi xảy ra lỗi mất sóng trên iPhone 4, các chuyên gia quốc tế cùng nhiều trang công nghệ lớn như Engadget, Cnet\u2026 đã vào cuộc nhằm tìm ra nguyện nhân sự việc"],[707,"b) Phương pháp 2"],[708,"Duyệt theo chiều sâu Bước 1: Chọn nút bắt đầu là nút đầu tiên (theo thứ tự xuất hiện trong văn bản)"],[709,"Bước 2: Duyệt đồ thị theo chiều sâu bắt đầu từ nút xuất phát, chọn các nút theo số bậc cao nhất"],[710,"Quá trình duyệt dừng lại khi nút cuối cùng được chọn không liên kết"],[711,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[712,"31 với nút nào về sau"],[713,"Bước 3: Nếu vẫn chưa đủ số câu cần thiết, thực hiện phương pháp 1 đối với các câu còn lại chưa được chọn"],[714,"Thuật toán 4 Input: Đồ thị liên kết D(i,j), tỉ lệ nén p%, số câu n"],[715,"Output: Tập các câu được chọn Selection"],[716,"1"],[717,"Tính số câu cần chọn; 2"],[718,"Tính bậc của các nút; 3"],[719,"{Chọn nút đầu tiên} Count = 1; selected = 1; Selection(count) = selected; 4"],[720,"{Tạo danh sách kề với nút được chọn} for i = 1 to n if (D(selected,i) > 0 then Đưa i vào danh sách kề; 5"],[721,"{Chọn nút có bậc cao nhất trong danh sách kề} Selected = nút có bậc cao nhất trong danh sách kề; Count = Count + 1; Quay lại bước 4"],[722,"6"],[723,"{Nếu chưa đủ số câu} If count < NumberOfSent then begin for i = 1 to n if sent(i) chưa được chọn then Đưa i vào Danh sách còn lại; Chọn (NumberOfSent \u2013 count) câu trong Danh sách còn lại; 7"],[724,"Sắp xếp selection theo chiều tăng dần; 8"],[725,"return selection; Với ví dụ tệp input1.txt áp dụng thuật toán 4 các câu được chọn là: 11, 8, 10, 4, 1 Văn bản được tóm tắt: [1]Những người này khuyến cáo Quả táo cần nhanh chóng đưa ra biện pháp khắc phục hậu quả để lấy lại lòng tin từ khách hàng, cho dù chi phí bỏ ra sẽ rất lớn"],[726,""],[727,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[728,"32 [4]Không những vậy, tạp chí tiêu dùng uy tín Consumer Reports của Mỹ còn lên tiếng chê bai iPhone 4 và khuyến cáo người dùng không nên mua sản phẩm này"],[729,"[8]Tuy nhiên, ít lâu sau, \"Quả táo\" lại khẳng định lỗi sóng yếu là do phần cứng và sẽ mất rất nhiều thời gian để khắc phục khi mà hãng đã bán ra một số lượng lớn sản phẩm"],[730,"[10]Không những thế, họ còn buộc Quả táo phải bồi thường chi phí mua điện thoại, kể cả những tổn thất phát sinh khác mà khách hàng phải gánh chịu"],[731,"[11]Từ khi xảy ra lỗi mất sóng trên iPhone 4, các chuyên gia quốc tế cùng nhiều trang công nghệ lớn như Engadget, Cnet\u2026 đã vào cuộc nhằm tìm ra nguyện nhân sự việc"],[732,"c) Phương pháp 3"],[733,"Phân đoạn văn bản Bước 1: Tách văn bản thành những phân đoạn, căn cứ vào độ dài của văn bản và tỉ lệ nén p%"],[734,"Bước 2: Áp dụng phương pháp 1 đối với từng phân đoạn, ở mỗi phân đoạn chọn ít nhất một câu"],[735,"Các câu còn lại được chọn là các nút có bậc cao trong các phân đoạn"],[736,"Quá trình chọn sẽ dừng lại khi đạt đủ số câu cần thiết"],[737,"Thuật toán 5 Input: Đồ thị liên kết D(i,j), tỉ lệ nén p%, số câu n"],[738,"Output: Tập các câu được chọn Selection"],[739,"1"],[740,"Tính số câu cần chọn; 2"],[741,"Tính bậc của các nút; 3"],[742,"{Tính toán số đoạn, số câu chọn mỗi đoạn} Số_câu = 1; Số_đoạn = n/ Số_câu; while NumberOfSeg > số_đoạn begin Số_câu = Số_câu + 1 Số_câu = n/ Số_câu end;"],[743,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[744,"33 số_câu_mỗi_đoạn = số_đoạn / Số_câu 4"],[745,"{Chọn ra các câu trong từng đoạn} First = 1; Last = Số_câu; while last < n begin Sắp xếp bậc của các nút trong đoạn [First, Last]; for i = 1 to SelectSentPerSeg chọn câu có bậc lớn nhất; First = Last + 1; Last = Last + Số_câu; end; 5"],[746,"Sắp xếp selection theo chiều tăng dần; 6"],[747,"return selection; Với văn bản input1.txt có 25 câu, với tỷ lệ nén là 20% số câu cần trích xuất ra là 5"],[748,"Vì vậy văn bản sẽ được chia làm 5 đoạn nhỏ"],[749,"Ta chọn trong mỗi đoạn 1 câu có số bậc lớn nhất"],[750,"Đoạn 1 Đoạn 2 Đoạn 3 Đoạn 4 Đoạn 5 Đỉnh Bậc Đỉnh Bậc Đỉnh Bậc Đỉnh Bậc Đỉnh Bậc 0 6 5 5 10 13 15 2 20 7 1 12 6 3 11 14 16 3 21 4 2 10 7 2 12 8 17 9 22 8 3 10 8 13 13 3 18 4 23 9 4 12 9 4 14 2 19 3 24 1 Bảng 3.2: Phân chia đoạn của văn bản input1.txt Thứ tự các câu sau khi phân đoạn là: 1, 8, 11, 17, 23 [1]Những người này khuyến cáo Quả táo cần nhanh chóng đưa ra biện pháp khắc phục hậu quả để lấy lại lòng tin từ khách hàng, cho dù chi phí bỏ ra sẽ rất lớn"],[751,"[8]Tuy nhiên, ít lâu sau, \"Quả táo\" lại khẳng định lỗi sóng yếu là do phần cứng và sẽ mất rất nhiều thời gian để khắc phục khi mà hãng đã bán ra một số lượng lớn sản phẩm"],[752,"[11]Từ khi xảy ra lỗi mất sóng trên iPhone 4, các chuyên gia quốc tế cùng nhiều"],[753,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[754,"34 trang công nghệ lớn như Engadget, Cnet\u2026 đã vào cuộc nhằm tìm ra nguyện nhân sự việc"],[755,"[17]Tuy nhiên chính điều đó mới thể hiện Quả táo là một tập đoàn đẳng cấp và luôn đặt chất lượng sản phẩm lên hàng đầu"],[756,"[23]Trên thực tế, nếu giải pháp này được thực hiện, Apple sẽ chỉ thiệt hại 1 USD/chiếc"],[757,"3.6"],[758,"Kết luận"],[759,"Trong chương này, chúng tôi đã giới thiệu mô hình tóm tắt văn bản sử dụng phương pháp cấu trúc và trình bày chi tiết về việc xây dựng chương trình tóm tắt văn bản"],[760,"Nhằm mục đích kiểm nghiệm tác dụng của bộ tách từ tiếng Việt, từ điển đồng nghĩa, chúng tôi đã cài đặt 3 phiên bản cho ứng dụng này"],[761,""],[762,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[763,"35 CHƯƠNG 4: XÂY DỰNG ỨNG DỤNG MINH HỌA 4.1"],[764,"Một số giao diện chính của hệ thống"],[765,"4.1.1"],[766,"Giao diện chính của chương trình"],[767,"Hình 4.1: Giao diện chính của chương trình"],[768,"4.1.2"],[769,"Giao diện form quản lý từ điển từ dừng, từ đồng nghĩa"],[770,"Hình 4.2: Giao diện quản lý từ dừng"],[771,""],[772,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[773,"36 4.1.3"],[774,"Giao diện form tách từ, tách câu"],[775,"Hình 4.3: Giao diện tách từ tách câu 4.1.4"],[776,"Giao diện form loại từ dừng, từ đồng nghĩa"],[777,"Hình 4.4: Loại bỏ từ dừng, từ đồng nghĩa trong văn bản"],[778,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[779,"37 4.1.5"],[780,"Giao diện form xây dựng đồ thị liên kết"],[781,"Hình 4.5: Giao diện form xây dựng đồ thị liên kết cho văn bản"],[782,"4.1.6"],[783,"Giao diện form tóm tắt văn bản"],[784,"Hình 4.6: Giao diện tóm tắt văn bản"],[785,""],[786,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[787,"38 4.1.7"],[788,"Giao diện form đánh giá độ chính xác"],[789,"Hình 4.7: Đánh giá độ chính xác của văn bản tóm tắt 4.2"],[790,"Một số module chính của chương trình"],[791,"4.2.1"],[792,"Module tóm tắt văn bản"],[793,"Đầu vào: đầu vào của module là một văn bản dạng tệp text được công cụ JvnTextPro tách thành 2 file một file chứa các câu được ngăn cách bởi dấu chấm (.) và một file lưu tập các từ với các từ ghép được ghép lại với nhau bởi dấu gạch dưới"],[794,"Đầu ra: một đoạn văn ngắn gọn được tóm tắt từ tệp văn bản đầu vào với một tỷ lệ nén nhất định"],[795,"Quá trình xử lý: - Đối với phiên bản 1: không sử dụng bộ tách từ tách câu, không sử dụng từ điển từ dừng, từ đồng nghĩa"],[796,"Từ tệp văn bản gốc tách ra các từ dựa vào khoảng trắng"],[797,"Tách tập các câu dựa vào dấu chấm"],[798,"Sau đó tính tần số xuất hiện của các từ trong văn bản, tính độ tương tự của các câu và cho vào đồ thị liên kết"],[799,"Tính bậc của các câu để tìm ra câu quan trọng, tùy vào tỷ lệ nén là bao nhiêu phần trăm để lấy ra số câu tương ứng"],[800,"- Đối với phiên bản 2: sử dụng bộ tách từ tách câu"],[801,"Chọn đầu vào là tệp văn bản .txt dùng công cụ JvnTextPro để tách ra tập các từ và các câu"],[802,"Tính tần số của các từ, vector từ của mỗi câu, tính độ tương tự của mỗi câu trong văn bản để cho vào đồ thị liên kết"],[803,"Căn cứ vào số câu lấy ra ta chọn trong CSDL những câu có bậc lớp nhất"],[804,""],[805,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[806,"39 - Đối với phiên bản 3: sử dụng bộ tách từ, tách câu, sử dụng từ điển từ dừng, từ đồng nghĩa"],[807,"Từ tệp văn bản đầu vào tiến hành tách từ, tách câu dựa vào công cụ JVnTextPro, loại bỏ từ dừng, từ đồng nghĩa của văn bản"],[808,"Tính tần số xuất hiện của mỗi từ trong câu, tính vector từ của văn bản"],[809,"Tính toán độ tương tự của các câu, so sánh với ngưỡng để đưa câu vào đồ thị liên kết"],[810,"Dựa vào số câu lấy ra để chọn ra những câu có bậc lớn trong CSDL"],[811,"4.2.2"],[812,"Module quản lý từ dừng, từ đồng nghĩa Đầu vào: Dữ liệu đầu vào là các từ dừng, từ đồng nghĩa"],[813,"Đầu ra: Từ được lưu vào trong CSDL hoặc được sửa đổi, xóa bỏ khỏi CSDL Quá trình xử lý: Kết nối đến cơ sở dữ liệu nhập đầy đủ dữ liệu vào các ô Textbox sau đó ấn Thêm để thể thêm vào CSDL, sửa để cập nhật các từ hoặc ấn Xóa để loại bỏ các từ dừng, từ đồng nghĩa"],[814,"Cập nhật các thay đổi vào trong CSDL, báo cho người dùng biết kết quả"],[815,"4.2.3"],[816,"Module đánh giá hệ thống tóm tắt"],[817,"Đầu vào: Nhập các câu mà phần mềm tóm tắt ra vào ô textbox thứ nhất"],[818,"Nhập số câu của ghệ thống tóm tắt đối sánh vào ô textbox thứ 2 sau đó nhấn nút để kiểm tra để thực hiện đánh giá"],[819,"Đầu ra: Đầu ra của module là các thong số độ chính xác, độ bao phủ, hàm điều hòa của hệ thống tóm tắt so với hệ thống tóm tắt đối sánh"],[820,"Quá trình xử lý: Nhập các câu mà hệ thống tóm tắt sinh ra và ô textbox thứ nhất"],[821,"Nhập các câu mà hệ thống đối sánh sinh ra và nhấp nút đánh giá"],[822,"Hệ thống sẽ tiến hành lựa chọn các câu giống nhau của 2 hệ thống, tính toán kết quả và trả ra các thong số tương ứng"],[823,"4.3"],[824,"Kết luận"],[825,"Trong chương này nhóm đồ án đã trình bày một số giao diện chính của hệ thống và mô tả một số module của chương trình"],[826,""],[827,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[828,"40 CHƯƠNG 5: THỰC NGHIỆM VÀ ĐÁNH GIÁ 5.1"],[829,"Môi trường thử nghiệm"],[830,"Chương trình được xây dựng và thử nghiệm trên máy tính cá nhân có cấu hình và các phần mềm cần thiết như sau: - Vi xử lý: Intel Dual Core T2390 1.86GHz - Bộ nhớ: 2GB - Hệ điều hành: Windows 7"],[831,"- Phần mềm phát triển: Microsoft Visual Studio 2008 - Bộ công cụ JVnTextPro-v.2.0 của tác giả Nguyễn Cẩm Tú \u2013 Phan Xuân Hiếu nhằm thực hiện tách từ, tách câu của văn bản đầu vào"],[832,"5.2"],[833,"Dữ liệu thử nghiệm a) Tập văn bản thử nghiệm Gồm 20 văn bản có nội dung với nhiều lĩnh vực khác nhau, phần lớn được lấy từ website vnexpress, dantri.com và một số bài báo khoa học khác"],[834,"Mỗi văn bản được lưu trong một tập tin được đặt tên theo thứ tự từ input1.txt đến Text20.txt"],[835,"Văn bản có kích thước lớn nhất là 27KB với 179 câu, văn bản có kích thước nhỏ nhất là 1,45KB với 9 câu"],[836,"b) Từ điển - Từ điển từ dừng gồm 235 từ"],[837,"- Từ điển đồng nghĩa gồm 1000 mục từ"],[838,"5.3"],[839,"Phương pháp đánh giá"],[840,"Như trên đã trình bày, có nhiều phương pháp khác nhau để đánh giá kết quả của một hệ thống tóm tắt"],[841,"Trong đó, phương pháp so sánh văn bản của hệ thống tóm tắt với văn bản do con người thực hiện được sử dụng nhiều"],[842,"Trong thử nghiệm của chúng tôi, phương pháp này cũng được sử dụng để đánh giá độ chính xác của hệ thống tóm tắt"],[843,"Gọi hệ thống tóm tắt cần đánh giá là S, hệ thống tóm tắt đối sánh là CS thì ta có bảng đánh giá mức độ liên quan của S và CS như sau:"],[844,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[845,"41 Hệ thống S Hệ thống CS Hệ thống S chọn Hệ thống S không chọn Hệ thống CS chọn A B Hệ thống CS không chọn C D Bảng 5.1: Đánh giá sự liên quan của văn bản tóm tắt và văn bản đối sánh"],[846,"Trong đó: A là tổng số câu được cả 2 hệ thống tóm tắt chọn"],[847,"B là tổng số câu S không chọn nhưng CS chọn"],[848,"C là tổng số câu S chọn nhưng CS không chọn"],[849,"D là tổng số câu mà cả 2 hệ thống đều không chọn"],[850,"Khi đó, độ chính xác Precision (P) được tính bằng: Độ chính xác P cho biết tỉ lệ giữa các câu S chọn ra chính xác so với tổng số những câu có trong văn bản tóm tắt do S thực hiện"],[851,"Độ bao phủ Recall (R) được tính bằng: Độ bao phủ R cho biết tỉ lệ giữa các S chọn ra chính xác so với tổng số câu trong văn bản do CS thực hiện"],[852,"Độ đo F: là tiêu chí đánh giá chung cho kết quả tóm tắt của hệ thống, độ đo này là hàm điều hoà của độ chính xác và độ hồi quy và được tính bằng: Như trên đã trình bày, tỉ lệ nén của văn bản tóm tắt là tỉ lệ giữa tổng số câu do hệ thống tóm tắt lựa chọn so với tổng số câu của văn bản ban đầu"],[853,"Chúng tôi thử nghiệm hệ thống tóm tắt với 3 mức độ nén: 10%, 20% và 30%"],[854,""],[855,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[856,"42 Tập văn bản thử nghiệm trên được tóm tắt bởi con người, mỗi văn bản được tóm tắt thành 3 văn bản với mức độ nén lần lượt là 10%, 20% và 30%"],[857,"Các văn bản được chuyển cho người tóm tắt để chọn ra các câu có ý nghĩa quan trọng"],[858,"Việc lựa chọn các câu sẽ là chọn ra số thứ tự của câu đó trong văn bản gốc"],[859,"Mỗi câu được chọn sẽ được ghi trên một dòng"],[860,"Chẳng hạn, với văn bản input1.txt trong tập văn bản thử nghiệm, văn bản này có 25 câu"],[861,"Giả sử, với tỉ lệ nén là 10% thì người tóm tắt sẽ thực hiện chọn ra 3 câu, các câu được chọn được ghi trong một tập tin văn bản viết theo dạng: Hình 5.1: Tóm tắt văn bản input1.txt bởi con người"],[862,"Văn bản tóm tắt của input1.txt [8]Tuy nhiên, ít lâu sau, \"Quả táo\" lại khẳng định lỗi sóng yếu là do phần cứng và sẽ mất rất nhiều thời gian để khắc phục khi mà hãng đã bán ra một số lượng lớn sản phẩm"],[863,"[10]Không những thế, họ còn buộc Quả táo phải bồi thường chi phí mua điện thoại, kể cả những tổn thất phát sinh khác mà khách hàng phải gánh chịu"],[864,"[11]Từ khi xảy ra lỗi mất sóng trên iPhone 4, các chuyên gia quốc tế cùng nhiều trang công nghệ lớn như Engadget, Cnet\u2026 đã vào cuộc nhằm tìm ra nguyện nhân sự việc"],[865,"Đồng thời, để so sánh kết quả tóm tắt của hệ thống với các hệ thống khác, nhóm đồ án lựa chọn Microsoft Office Word 2007 làm hệ tóm tắt đối sánh"],[866,"Sử dụng công cụ Auto Summarize trong Microsoft Office để tóm tắt văn bản, Auto Summarize tóm"],[867,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[868,"43 tắt theo nguyên tắc tính điểm cho các câu chứa từ được lặp lại nhiều lần"],[869,"Những câu được nhiều điểm nhất sẽ được đưa vào văn bản tóm tắt"],[870,"5.4"],[871,"Kết quả thực nghiệm"],[872,"5.4.1"],[873,"Thử nghiệm xác định ngưỡng"],[874,"Ngưỡng là giá trị dùng để quyết định xem 2 câu của văn bản có được đưa vào đồ thị liên kết hay không"],[875,"Nếu độ tương tự giữa hai câu đạt đến ngưỡng thì 2 câu đó được đưa vào đồ thị"],[876,"Nhóm đồ án đã tiến hành thử nghiệm các phiên bản với những ngưỡng khác nhau để chọn ra một ngưỡng phù hợp"],[877,"Đơn vị: % Ngưỡng Phiên bản 1 Phiên bản 2 Phiên bản 3 Độ chính xác Độ bao phủ Hàm điều hòa Độ chính xác Độ bao phủ Hàm điều hòa Độ chính xác Độ bao phủ Hàm điều hòa 0.1 36.94 47.61 41.48 30.27 37.61 33.33 34.44 44.04 38.33 0.2 30.27 41.66 34.95 34.44 42.38 37.72 41.11 43.44 42.22 0.3 39.06 50 43.69 36.94 40.27 38.42 41.11 43.49 42.22 0.4 38.61 43.25 40.73 41.11 43.44 42.22 44.44 46.82 45.55 0.5 30.27 32.06 31.11 41.11 41.11 41.11 41.11 41.11 41.11 Bảng 5.2: Kết quả đánh giá thử nghiệm với các ngưỡng khác nhau"],[878,"Đồ thị dưới đây mô tả giá trị hàm điều hoà trong việc thử nghiệm các ngưỡng đối với từng phiên bản"],[879,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[880,"44 0 5 10 15 20 25 30 35 40 45 50 0.1 0.2 0.3 0.4 0.5 Phiên b n 1 Phiên b n 2 Phiên b n 3 Hình 5.2: Đồ thị hàm điều hòa với các ngưỡng"],[881,"Qua kết quả này, ta có thể nhận thấy, với ngưỡng 0.2, 0.3, 0.4 thì chương trình tóm tắt cho kết quả khả quan nhất"],[882,"Khi ngưỡng tăng dần thì giá trị hàm điều hoà lại giảm rất nhanh do khi độ tương tự giữa hai câu không đạt đến ngưỡng đó thì hai câu đó không thể được đưa vào đồ thị liên kết, từ đó hai câu này sẽ không được chọn vào văn bản tóm tắt (mà rất có thể hai câu này chứa nội dung chính và sẽ được chọn)"],[883,"Việc xác định ngưỡng có một vị trí quan trọng trong chương trình tóm tắt"],[884,"Bởi lẽ ngưỡng còn phụ thuộc vào từng loại văn bản, một ngưỡng này có thể là tốt với loại văn bản nhưng có thể lại không tốt với loại văn bản khác"],[885,"Trong thử nghiệm kết quả tóm tắt đối với từng văn bản dưới đây chúng tôi sử dụng ngưỡng 0,4 để đánh giá"],[886,"5.4.2"],[887,"Đánh giá kết quả thử nghiệm đối với từng phiên bản"],[888,"a) Đánh giá chất lượng tóm tắt của Microsoft Word"],[889,"Bảng dưới đây là kết quả đối sánh của các bản tóm tắt do Microsoft Word thực hiện"],[890,"T ỷ lệ p h ần t ră m"],[891,"Tóm tắt văn bản dựa vào trích xuất câu và xây dựng ứng dụng minh họa"],[892,"45 Đơn vị: % Tỷ lệ nén Độ chính xác Độ bao phủ Hàm điều hòa 10% 33.33 25 28.57 20% 40 33.33 36.36 30% 50 44.44 47.05 Trung bình 41.11 34.25 37.32 Bảng 5.3: Đánh giá kết quả tóm tắt của Microsoft office 2007 b) Phiên bản 1 Trong phiên bản này, chúng tôi không sử dụng bộ tách từ mà chỉ sử dụng dấu trắng làm dấu hiệu phân tách từ"],[893,"Ngưỡng threshold được chọn đối với cả 3 phiên bản để đưa 2 câu vào đồ thị liên kết được chọn là 0,4"],[894,"Dưới đây là kết quả đánh giá độ chính xác và độ bao phủ trun"]],"downloaded":true,"m":[-1,-1],"n":"baocaodatn_8451.txt","o":"https://tailieu.vn/docview/tailieu/2014/20140421/nguyenthuan9191/baocaodatn_8451.pdf"},{"saved_path":"temp/20131848_Duong_Viet_Hung_1514557567432.txt","r":0.3352988660335541,"s":[[55,29,0.930232584476471,40,0,42,0,42,"Ngược lại, tóm tắt đa văn bản là từ nhiều văn bản nguồn cũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng thời cho nhiều văn bản khác nhau","Ngược lại tóm tắt đa văn bản là từ một văn bản nguồn cũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng thời cho nhiều văn bản khác nhau"],[54,28,0.800000011920929,18,5,24,0,19,"Theo đầu vào hệ thống Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn gọn của văn bản đó","Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn ngọn của văn bản đó"]],"t":"\n \r\n \r\n1.1 Giới thiệu \r\n \r\n\r\nTrong kỉ nguyên công nghệ số như hiện nay, lượng kiến thức của nhân loại \r\nlà vô cùng lớn, hơn nữa sự gia tăng của lượng thông tin đó theo thời gian là vô cùng \r\nnhanh, và đa phần trong đó được biểu diễn dưới dạng các văn bản. Với sự tăng \r\ntrưởng đó tầm quan trọng của việc tóm lược thông tin ngày càng quan trọng. Làm \r\nsao ta có thể biết được điều gì là quan trọng trong một khoảng thời gian ngắn ? Việc \r\ntóm lược thông tin giúp ta có thể quyết định xem tiếp tục tập trung vào phần nào, \r\nnhất là trong các văn bản phức tạp như bài báo khoa học hay toàn bộ nội dung một \r\ncuốn sách. Ngoài ra nó còn có thể ứng dụng trong rất nhiều các lĩnh vực khác mà \r\ncon người cần phải tóm lược một lượng rất lớn các dữ liệu như tài chính, dữ liệu \r\nthuốc của bệnh nhân trong y học. \r\n\r\nBài toán tóm tắt văn bản là một trong những bài toán kinh điển trong lĩnh \r\nvực xử lý dữ liệu văn bản. Xử lý dữ liệu văn bản bao gồm: \r\n\r\n Kiểm tra lỗi chính tả (spelling-checker) \r\n Kiểm tra lỗi văn phạm (grammar-checker) \r\n Từ điển đồng nghĩa (thesaurus) \r\n Phân tích văn bản (text analyzer) \r\n Phân loại văn bản (text classification) \r\n Tóm tắt văn bản (text summarization) \r\n Tổng hợp tiếng  nói (speech synthesis) \r\n Nhận dạng giọng nói (speech recognization) \r\n Dịch tự động (automatic translation) \r\n . \r\n\r\nTóm tắt văn bản là công việc phân tích nội dung của văn bản và sau đó sinh \r\nra một văn bản tóm tắt có kích thước nhỏ hơn văn bản ban đầu, loại bỏ đi những \r\nthông tin không quan trọng nhưng vẫn đảm bảo giữ được những nội dung cốt lõi \r\ncủa văn bản. Do đó để công việc tóm tắt văn bản chính xác cần phải đáp ứng được \r\ncác yêu cầu sau: \r\n\r\n Các văn bản khi phân tích thì phải hiểu được nội dung để xác định \r\nđược các tiêu chuẩn trong văn bản. \r\n\r\n Các văn bản tóm tắt cần được kiểm tra bằng một thang đo tiêu chuẩn.  \r\n \r\n\r\n Rõ ràng việc tóm tắt văn bản chính là công việc khai phá dữ liệu văn bản \r\n(text data mining).  \r\n \r\n\r\n\r\n\r\n\r\n1.2 Lịch sử phát triển của tóm tắt văn bản \r\n \r\n Tóm tắt văn bản bắt đầu từ những năm cuối thập kỉ 1950 với nghiên cứu của \r\nLuhn(1958) dựa trên tần số từ. Ý tưởng cơ bản của phương pháp tần số từ dựa trên \r\nkiến thức cho rằng tần số của từng từ trong văn bản là một độ đo hữu dụng để đánh \r\ngiá tầm quan trọng của chúng. \r\n Tiếp theo đó là phương pháp tóm tắt dựa trên vị trí của các câu trong văn bản \r\ncủa Baxendale (1958) và những nghiên cứu của Edmundson(1969) về vị trí của các \r\ncâu trong văn bản và các từ/cụm từ mang ý nghĩa tổng quát. Theo đó, những câu bắt \r\nđầu và kết thúc của đoạn văn bài viết hay những câu chưa những từ như important \r\n(đặc biệt), result are (kết qủa là) . là những câu có ý nghĩa quan trọng. \r\n Đầu những năm 1970, tiếp tục có những nghiên cứu với hướng tiếp cận \r\nngoài (sử dụng các cụm từ dấu hiệu) và được ứng dụng trong các phần mềm thương \r\nmại \r\n Những năm 1980, phát triển nhiều nghiên cứu với nhiều hướng khác nhau, \r\nđặc biệt là hướng tiếp cận mức thực thể dựa trên trí tuệ nhân tạo  như sử dụng script \r\n(Lehnert 1981), các luật sản xuất mạng và logic (Fum 1985), mạng ngữ nghĩa \r\n(Reimer và Hahn 1988) cũng như các hướng tiếp cận kết hợp (Rau 1989) hay \r\n(Aretoulaki 1994). \r\n Willam B. Cavnar (1994) : biểu diễn văn bản dựa trên n-gram thay cho cách \r\nbiểu diễn truyền thống bằng từ khoá. \r\n Jaine Carbonell (1998) đã tóm tắt văn bản bằng cách xếp hạng các câu trội \r\n(câu chưa các ý chính của văn bản) và rút ra các câu trội. \r\n Jade Goldstein (1999) : phân loại tóm tắt dựa trên độ đo liên quan, phương \r\nphpas sử dụng kết hợp giữa ngữ học, thống kê. Một câu được đặc trưng bằng các \r\nđặc tính ngữ học và độ đo thống kê. \r\n J.Larocca Neto (2000) đã tạo tóm tắt văn bản dựa trên các dãy từ trong câu \r\nđược chọn theo hệ số tf, sau đó dùng kỹ thuật gom cụm (clustering) để tạo tóm tắt. \r\n Yoshio (2001) đã tạo tóm tắt văn bản tiếng Nhật. Có 2 phương pháp là rút \r\ncâu dựa trên từ khoá và rút câu dựa trên kiến trúc ngữ nghĩa trong đó có xây dựng \r\nđộ đo mối liên kiết giữa hai từ. \r\n Hiện nay, một số nghiên cứu về xử lý ngôn ngữ tự nhiên cũng bước đầu \r\nđược áp dụng trong tóm tắt văn bản. Mặt khác, các nghiên cứu về tóm tắt đa văn \r\nbản, đa ngôn ngữ và tóm tắt đa phương tiện cũng bắt đầu phát triển. \r\n \r\n1.3 Phân loại các phương pháp tóm tắt văn bản \r\n \r\n\r\nMột trong những cách phân chia của bài toán tóm tắt là: Tóm tắt đơn văn bản \r\nvà Tóm tắt đa văn bản. Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản \r\n\r\n\r\n\r\n\r\nngắn ngọn của văn bản đó. Ngược lại tóm tắt đa văn bản là từ một văn bản nguồn \r\ncũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm \r\ntắt một văn bản đồng thời cho nhiều văn bản khác nhau. \r\n\r\nTrong phạm vi đồ án, em sẽ tập trung nghiên cứu và áp dụng các kĩ thuật \r\ntóm tắt văn bản tự động vào bài toán tóm tắt đơn văn bản vì tính đặc trưng của các \r\nkĩ thuật áp dụng. Thuật toán cho bài toán tóm tắt đa văn bản được điều chỉnh cho \r\nphù hợp từ cơ sở bài toán tóm tắt đơn văn bản. \r\n\r\n \r\n1.3.1 Phân loại theo dạng tóm tắt \r\n\r\n1.3.1.1 Phương pháp tóm tắt trích xuất  Extractive text summarization \r\n \r\n\r\nPhương pháp trích xuất bao gồm việc lựa chọn đơn vị của văn bản (câu hay \r\nđoạn văn), được coi là có chứa lượng thông tin cốt tử của văn bản (informative \r\ncontent, informativity), và kết nối các đơn vị này theo một trình tự thích hợp. Một \r\ntrích xuất là sự lắp ghép các đoạn được trích rút ra từ văn bản nguồn. Mục tiêu của \r\ntrích xuất là cung cấp một cái nhìn tổng quan về nội dung của văn bản gốc. Độ dài \r\ncủa văn bản tóm tắt bằng trích xuất có thể được xác định bởi tỉ lệ nén, hay nói cách \r\nkhác Văn bản tóm tắt ngắn hơn bao nhiêu so với văn bản gốc. \r\n Thuật toán tóm tắt tự động bằng trích xuất có thể chia ra làm 3 mức: surface-\r\nlevel (mức bề mặt), intermediate-level (mức trung bình) và deep parsing techniques \r\n(các kĩ thuật phân tích sâu).  \r\n \r\n Tóm tắt trích rút xuất phát từ ý tưởng: Một tài liệu được chia nhỏ thành các \r\nđơn vị ngữ pháp (các câu văn), sau đó được đánh trọng số theo kinh nghiệm \r\n(heuristic); Các đơn vị ngữ pháp có điểm cao nhất sẽ được trích rút và liên kết với \r\nnhau để tạo nên văn bản tóm tắt.  \r\n \r\n\r\n Thuật toán tiếp cận ở mức bề mặt: Không đào sâu vào chiều sâu ngôn ngữ \r\ncủa văn bản, thay vào đó là sử dụng các phần tử ngôn ngữ nhất định để xác \r\nđịnh các đoạn có liên hệ với nhau trong văn bản. Kĩ thuật của mức bề mặt \r\ndựa vào sự xuất hiện của từ để đánh trọng số cho các câu. Một kĩ thuật khác \r\ndựa trên ý tưởng: Những từ được sử dụng trong tiêu đề của văn bản là quan \r\ntrọng. Trong khi đó, một số kĩ thuật dựa vào vị trí của các đoạn trong văn \r\nbản. Kĩ thuật này được áp dụng với nhưng văn bản có cấu trúc cố định, như \r\ntiêu đề, các mục và các đoạn,... Một số nghiên cứu còn chỉ ra rằng: Dòng đầu \r\ntiên luôn là dòng quan trọng nhất trong văn bản đối với các thể loại báo chí. \r\n\r\n Thuật toán tiếp cận mức trung bình: Sử dụng thông tin về ngôn ngữ học \r\nphức tạp hơn thuật toán tiếp cận mức bề mặt nhưng lại ít phức tạp hơn mức \r\n\r\n\r\n\r\n\r\nphân tích sâu. Một kĩ thuật của dạng này là phát hiện các chuỗi từ vựng. \r\nChuỗi từ vựng là một dãy các từ kết nối với nhau theo quan hệ về ngữ nghĩa. \r\nMột cách tổng quát, quá trình tóm tắt bao gồm 4 giai đoạn. \r\nBốn giai đoạn đó bao gồm:  \r\n\r\n Chia văn bản gốc thành các đoạn (segments). Xây dựng các chuỗi từ \r\nvựng  lexical chain. \r\n\r\n Xác định các strong chain  chuỗi từ mạnh \r\n Trích rút các câu chứa các strong chain \r\n Lắp ghép các câu được trích rút thành văn bản tóm tắt \r\n\r\n Thuật toán phân tích sâu: Dựa trên ý tưởng rằng sử dụng các kĩ thuật \r\nchuyên sâu về ngôn ngữ để phát hiện ra các cấu trúc rời rạc của văn bản.  \r\nNhững hệ thống tóm tắt văn bản tự động dựa trên phân tích diễn ngôn bắt \r\nnguồn từ ý tưởng: Văn bản được định nghĩa bởi cấu trúc trong của nó và các \r\nmối quan hệ diễn ngôn - phụ thuộc vào ngôn ngữ mà văn bản sử dụng. \r\nNhững hệ thống này cung cấp độ quan trọng nhiều hơn cho các thành phần \r\ncốt  tử của các quan hệ rời rạc.  \r\nSử dụng lý thuyết cấu trúc diễn ngôn (Rhetorical structure theory) chia văn \r\nbản thành các đơn vị rời rạc sử dụng tập các quan hệ tối thiểu (minimal set of \r\nrelations). Một khi các cấu trúc rời rạc được xác định, một thuật toán sẽ được \r\náp dụng để đánh trọng số và thứ tự cho mỗi phần tử trong cấu trúc tựa cây \r\nmột cách rời rạc. Và cuối cùng, các câu với trọng số cao nhất sẽ được lựa \r\nchọn để tạo nên văn bản tóm tắt. \r\n\r\n1.3.1.2 Phương pháp tóm tắt tóm lược  Abstractive summarization \r\n \r\n\r\nTuy tóm tắt bằng trích rút đã thành công trong việc xác định câu nào trong \r\nvăn bản đầu vào mang nội dung quan trọng nhưng dường như những phương pháp \r\nnày rất xa với việc tạo ra một bản tóm tắt tối ưu theo nghĩa cả về nội dung và chất \r\nlượng trong ngôn ngữ học. Trong khi đó, hệ thống tạo ra văn bản tóm tắt bằng tóm \r\nlược dựa trên việc hiểu văn bản gốc và đạt tới việc sinh ra một văn bản mới một \r\ncách chính xác về ngữ pháp, súc tích và mạch lạc về nội dung, bằng cách sinh ra \r\nvăn bản tóm tắt bằng những từ vựng không xuất hiện trong văn bản gốc. \r\n Trong tóm lược, việc diễn giải, viết lại các câu phức tạp sẽ nhằm mục đích \r\ntạo ra phiên bản súc tích của nội dung ban đầu. Mặc dù con người có thể tái sử dụng \r\nmột phần văn bản gốc nhưng không phải sử dụng toàn bộ nó; sử dụng các đoạn hay \r\nmột phần của câu thay vì sử dụng toàn bộ câu. \r\n \r\n1.3.2 Phân loại theo mức độ xử lý: \r\n\r\n \r\n\r\n\r\n\r\n\r\n Tiếp cận mức ngoài : thông tin được miêu tả dứoi dạng khái niệm về các \r\nđặc trưng nông (shallow feature). Các đặc trưng nông bao gồm các thuật \r\nngữ quan trọn gqua thống kê ( dựa vào tần số của các thuật ngữ trong văn \r\nbản), các thuật ngữ quan trọng dựa vào vị trí, các cụm từ dấu hiệu hay \r\ncác thuật ngữu trong câu truy vấn của ngừoi dùng. Kết quả là một bàn \r\ntóm tắt dạng trích xuất (extract). \r\n\r\n Tiếp cận mức sâu (deeper-level) : ở mức này bản tóm tắt có thể là dạng \r\ntrích xuất hoặc dạng tóm tắt (abstract) và cần phải sửu dụng đên sinh \r\ntổng hợp ngôn ngữu tự nhiên. Với dạng tiếp cận này phải cần đến những \r\nphân tích về mặt ngữ nghĩa, chẳng hạn sử dụng hướng tiếp cận thực thể \r\nđẻ xây dựng dạng biểu diễn của cấc thực thể văn bản và mối quan hệ \r\ngiữa các thực thể rồi từ đố tìm ra phần trái nghĩa, nghĩa hẹp, nghĩa \r\nrộng., quan hệ cú pháp dựa trên cây phân tích cú pháp và các mối quan \r\nhệ khác. \r\n \r\n\r\n1.3.3 Phân loại theo mục đích của bản tóm tắt: \r\n\r\n \r\n Trình bày sơ lược : Đưa ra những thông tin ngắn gọn về chủ đề chính của \r\n\r\nvăn bản. Dạng tóm tắt này thường được sử dụng trong các hệ thống tìm \r\nkiếm thông tin. Thông thường, độ dài của văn bản tóm tắt loại này chỉ \r\ntừu 5 đến 10% độ dài của toàn bộ văn bản \r\n\r\n Tóm tắt cung cấp tin tức: Cung cấp các chủ đề con của toàn bộ văn bản, \r\nkiểu tóm tắt này có độ dài từ 20-30% văn bản gốc. \r\n\r\n Phê bình và đánh giá: Văn bản tóm tắt đưa ra những quan điểm của \r\nngười tóm tắt về chủ đề được đưa ra. Tuy nhiên, kiểu tóm tắt này dường \r\nnhư vượt qua tầm của các hệ thống tóm tắt tự động hiện này. \r\n \r\n\r\n1.4 Những vấn đề trong bài toán tóm tắt văn bản \r\n \r\n\r\nTóm tắt văn bản có 2 dạng cơ bản là Extractive và Abtractive. Hầu hết các \r\ncông cụ tóm tắt hiện này đều là extractive. Đó là phương pháp tóm tắt giữa vào trích \r\nxuất các từ các câu tồn tại trong văn bản đầu vào sau đó dùng các giải thuật để đánh \r\ngiá xếp hạng chúng rồi sắp xếp lại thành văn bản tóm tắt. Nhưng con người chúng \r\nta thì suy nghĩ phức tạp hơn như vậy. Khi con người chúng ta tóm tắt não chúng ta \r\nkhởi tạo những đặc trưng ngữ nghĩa mà chúng ta đọc từ văn bản và từ đó tóm lược \r\nnội dung văn bản. Đó cũng chính là các phương thức abtractive hoạt động. Với \r\nnhững bước tiến về mặt sức mạnh phần cứng deeplearning có thể giúp ta thực hiện \r\nđiều này.  \r\n \r\n\r\n\r\n\r\n\r\n1.5 Giải pháp định hướng \r\nVới sự tiến bộ trong lĩnh vực Học máy (Machine learning) nói chung và học \r\n\r\nsâu (Deep learning) nói riêng có rất nhiều phương pháp đã chứng minh được tính \r\nhiệu quả trong việc giải quyết những bài toán phức tạp mà các cách tiếp cận truyền \r\nthống chưa thể giải quyết triệt để được. \r\n\r\nĐể giải quyết vấn đề khai phá, trích xuất những nội dung ngữ nghĩa được ẩn \r\nđi trong tài liệu(extractive), em đề xuất một thuật toán kết hợp các kĩ thuật phân tích \r\nvăn bản truyền thống. Từ đó, em sẽ thiết kế, xây dựng và đánh giá hệ thống tóm tắt \r\nvăn bản tự động dựa trên cách tiếp cận này. Cụ thể, nội dung đồ án sẽ tập trung \r\nnghiên cứu, tìm hiểu kĩ thuật phân tích ma trận NMF và trích suất đặc trưng.  \r\n Để giải quyết bài toàn tóm tắt văn bản bằng phương pháp abtractive, trích \r\nxuất nội dung ngữ nghĩa trong tài liệu em đề xuất sử dụng một mô hình được sử \r\ndụng phổ biết trong các bài toán dịch máy đó là mô hình sequence to sequence kết \r\nhợp cũng kĩ thuật attention, một kĩ thuật đang được áp dụng rất phổ biến gần đây \r\ncho các mô hình sequence to sequence nhằm tăng độ chính xác và giảm số lượng dữ \r\nliệu cần phải xử lý. Sau đó sẽ so sánh kết quả đạt được với phương pháp extractive \r\nsử dụng mà trận không âm NMF kết hợp với trích suất đặc trưng. \r\n \r\n \r\n\r\n\r\n\r\n\r\n \r\nCHƯƠNG 2 PHƯƠNG PHÁP PHÂN TÍCH MA TRẬN TRONG BÀI \r\n\r\nTOÁN TÓM TẮT  \r\n2.1 Cơ sở lý thuyết \r\n \r\n2.1.1 Kĩ thuật phân tích ma trận không âm \r\n\r\nPhân tích ma trận không âm - Non-negative matrix factorization là một nhóm \r\ncác thuật toán phân tích đa biến trong đại số tuyến tính. Ma trận A được phân tích \r\nthành 2 ma trận W và H với điều kiện là cả 3 ma trận này đều chỉ mang các thuộc \r\ntính không âm,  \r\n\r\n \r\n\r\n \r\nMa trận A được phân tích thành 2 ma trận W và H: \r\n\r\n ! = #$   \r\n \r\n\r\n Với A là một ma trận mxn, W là một ma trận mxk, và H là một ma trận kxn, \r\nk luôn được chọn nhỏ hơn m và n, do đó cả 2 ma trận W và H đều có size nhỏ hơn \r\nma trận A. \r\n Chúng ta sử dụng Frobenius norm như là hàm mục tiêu (objective function) \r\nđể thỏa mãn điều kiện xấp xỉ A  WH . Frobenius norm được chỉ ra trong công \r\nthức (Lee & Seung, 1999, 2001): \r\n \r\n\r\n! \",$  &-\"$ ()  *+,- \"+-$-,\r\n.\r\n\r\n-/0\r\n\r\n1\r\n\r\n,/0\r\n\r\n2\r\n\r\n+/0\r\n\r\n)\r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n \r\n Công thức này có cận dưới bằng 0, và rõ ràng tiến tới 0 khi và chỉ khi A = \r\nWH. W và H liên tục được cập nhật tới khi E(W,H) hội tụ dưới ngưỡng được \r\nđịnh nghĩa hoặc vượt quá số lần lặp. Luật cập nhật được chỉ ra dưới đây: \r\n !\"# \t \t!\"#\r\n\r\n%&' \"#\r\n%&%! \"#\r\n\r\n \r\n \r\n\r\n \r\n\r\n \r\n\r\n\r\n\r\n\r\n !\"# \t \t!\"#\r\n%&' \"#\r\n!&&' \"#\r\n\r\n \r\n \r\n\r\n \r\n\r\n \r\n Vec-tơ cột A tương ứng với câu thứ j, Aj, có thể được biểu diễn như là một \r\nsự kết hợp tuyến tính của vec-tơ đặc trưng ngữ nghĩa W*l và biến ngữ nghĩa Hlj như \r\ndưới đây: \r\n \r\n\r\n!*# = H&'(*)\r\n*\r\n\r\n)+,\r\n \r\n \r\n\r\n \r\n\r\n \r\n Ví dụ 1: Chúng ta sẽ lấy một ví dụ để minh họa cho thuật toán NMF: Cho  \r\nk = 2, số bước lặp là 50, và dung sai = 0.001 (tolerance). Các phần tử tại thời điểm \r\nban đầu của W và H băng 0.5, ma trận không âm A được phân tích thành 2 ma trận \r\nkhông âm W và H, được chỉ ra trong câu sử dụng NMF. Vec-tơ cột A*3 tương ứng với câu thứ 3 được biểu diễn như là sự \r\nkết hợp tuyến tính của vec-tơ đặc trưng ngữ nghĩa W*l và vec-tơ cột biến ngữ nghĩa \r\n(semantic variable column vector) H*3.  \r\n NMF phân tích một ma trận thưa thành hai ma trận thưa. Ở đây tỉ lệ phần tử \r\nbằng 0 (non-zero ratio) của ma trận có nghĩa là giá trị các phần tử khác 0 chia cho \r\ntổng số phần tử của ma trận. Ma trận không âm A là 1 ma trận vuông nxn, và giá trị \r\ncủa n được đặt bằng 100, 200, 300 và 400. Non-zero entries được chọn một cách \r\nngẫu nhiên. Số lượng đặc trưng nghĩa nghĩa, r, được chọn là 10% cuả n. Tỉ lệ non-\r\nzero cuả A được chọn lần lượt là 0.5%, 1%, 2%, 3%, 5%, 7%, 10%, 30%, 60% và \r\n99%. Hai ma trận W và H thu được bằng NMF. \r\n \r\n        A                            W                                       H                                              A \r\n\r\n1 2 3\r\n4 5 6\r\n7 8 9\r\n10 11 12\r\n\r\n\t\r\n0.1487 1.5998\r\n0.6610 0.9676\r\n1.1481 0.5727\r\n1.6129 0.4066\r\n\r\n 6.1136 6.6784 7.17840.0854 0.5923 1.2245 =\r\n1.0457 1.9420 3.0263\r\n4.1237 4.9813 5.9297\r\n7.0679 8.0071 8.9470\r\n9.8953 11.0127 12.0759\r\n\r\n \r\n\r\n \r\n               A*3      W*1       W*2                                  H*3                                                                        \r\n\r\n \r\n            A*3        H13         W*1             H23           W*2 \r\n\r\n3\r\n6\r\n9\r\n12\r\n\r\n 7.1784\r\n\r\n0.1487\r\n0.6610\r\n1.1481\r\n1.6129\r\n\r\n+ 1.2245\r\n1.5998\r\n0.9676\r\n0.5727\r\n0.4066\r\n\r\n \r\n\r\n \r\n \r\n\r\n \r\n\r\n\r\n\r\n\r\n2.1.2 Kĩ thuật tiếp cận dựa trên cấu trúc \r\n\r\nTrong các nghiên cứu gần đây có rất nhiều các đặc trưng hiệu quả của câu văn \r\nđược đề xuất để dùng cho tóm tắt trích rút, ví dụ như signature word, event hay \r\nsentence relevance. Mặc dù có nhiều kết quả đáng khích lệ nhưng hầu hết các đặc \r\ntrưng này được khảo sát một cách độc lập. Tuy nhiên, thực tế mỗi đặc trưng này lại \r\ncó đóng góp riêng của nó và sự kết hợp các đặc trưng đó lại với nhau có thể thu \r\nđược một kết quả tốt hơn trong các trường hợp riêng lẻ. Trong phần 2.5 của đồ án \r\nsẽ trình bày các kết quả thực nghiệm để đánh giá và chọn ra những bộ đặc trưng cho \r\nkết quả tốt nhất đáp ứng với bài toán tóm tắt văn bản. Trong mục này sẽ trình bày \r\nchi tiết các đặc trưng được xem xét. \r\n\r\n Surface Features  Đặc trưng bề mặt: Nhóm đặc trưng này xem xét đến \r\nđặc điểm cấu trúc của câu. Bao gồm: vị trí của câu trong văn bản - thông \r\nthường các câu đầu văn bản thường là các câu chứa đựng chủ đề khái quát \r\ncủa cả bài văn; số lượng từ trong câu - căn cứ vào các kiểu văn bản khác \r\nnhau, văn bản báo chí, xã luận, hay bài báo khoa học thì câu văn thường có \r\nmột độ dài trung bình nhất định, những câu văn có số lượng từ nhỏ hơn \r\nngưỡng đó sẽ là các câu không quan trọng; số lượng trích dẫn trong câu - \r\nmột câu chứa quá nhiều trích dẫn là câu không quan trọng. \r\n\r\n Relevance Features  Đặc trưng độ liên quan: Đặc trưng này được sử \r\ndụng để tìm ra mối liên hệ giữa các câu. Để làm được điều đó, ta đặt quy ước \r\nrằng: Giữa các câu luôn tồn tại mối liên hệ với nhau, sẽ có một số câu mang \r\nnội dung quan trọng hơn các câu khác và khi những câu khác liên quan đến \r\nnhững câu đó thì mức độ quan trọng cũng tăng lên. Tại thời điểm ban đầu, ta \r\ncó những câu đầu tiên của tài liệu và những câu đầu tiên của đoạn văn là \r\nquan trọng. Thước đo độ liên quan trong trường hợp này là độ tương đồng \r\ncosine. \r\n\r\n Content Features  Đặc trưng nội dung: Trong nhóm đặc trưng này, chọn \r\nđặc trưng Centroid, dựa vào đặc trưng centroid để xác định câu nào tập trung \r\nvào chủ đề của văn bản. \r\n \r\n\r\n2.2 Áp dụng phân tích ma trận không âm vào phân tích văn bản \r\n \r\n\r\nTourism in Greate Britain (Hoa 2005). \r\n\r\n \r\n \r\n \r\n \r\n\r\n\r\n\r\n\r\nMột số câu Câu văn \r\nS1 TOURIST arrivals to the UK in 1991 are forecast to recover \r\n\r\nsharply after the steep decline earlier this year cause by the Gufl \r\nwar. The British Tourist Authority said incoming tourist \r\nnumbers had already increased significantly after falling 18 \r\npercent in the first two months of this year from the levels of the \r\ncorresponding period of 1990 \r\n\r\nS2 The increases were achived in spite of a fall in the number of \r\nvisitors from western Europe rose 12 percent to 23 m  higher \r\nthan in any previous first quarter. A RECORD 185 m tourists \r\nvisited Britain in the 12 months to March, 8 percent more than \r\nthe previous year and the British Tourist Authority said \r\nyesterday that it was expecting even higher numbers this year \r\n\r\n. . \r\nS20 The increase were achieved in spite of a fall in the number of \r\n\r\nNorth American visitors Visits by North Americans fell 6 \r\npercent to 600,000 in the first quarter. However, the number of \r\nvisitors from western Europe rose 12 percent to 23 m  higher \r\nthan in any previous first quarter. A RECORD 185 m tourists \r\nvisited Britain in the 12 months to March, 8% more than the \r\nprevious year  and the British Tourist Authority said yesterday \r\nthat it was expecting even higher numbers this year \r\n\r\n. . \r\n \r\n\r\n \r\nThuật \r\n\r\nngữ \r\n S\r\n\r\n1 \r\nS\r\n2 \r\n\r\nS\r\n3 \r\n\r\nS\r\n4 \r\n\r\nS\r\n5 \r\n\r\nS\r\n6 \r\n\r\nS\r\n7 \r\n\r\nS\r\n8 \r\n\r\nS\r\n9 \r\n\r\nS \r\n10 \r\n\r\n. S \r\n20 \r\n\r\n. S \r\n57 \r\n\r\n1 Tourist 3 2 0 2 1 0 0 0 0 0 . 2 . 1 \r\n2 Arrival 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n3 UK 1 1 0 0 1 0 0 0 0 0 . 0 . 1 \r\n4 Forecast 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n5 Recover 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n6 Sharply 1 0 0 0 0 0 0 0 0 0  0 . 0 \r\n7 Steep 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n8 Decline 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n9 Earlier 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n\r\n10 Year 2 2 1 0 0 1 0 0 0 0 . 2 . 0 \r\n\r\n\r\n\r\n\r\n11 Cause 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n12 Gulf 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n13 War 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n14 British 1 2 0 1 1 0 0 0 0 0 . 1 . 0 \r\n15 Authority 1 1 0 1 1 0 0 0 0 0 . 1 . 1 \r\n16 Income 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n17 Increase 1 1 0 0 0 0 0 0 0 0 . 1 . 0 \r\n18 Significantly 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n. . . . . . . . . . . . . . . . \r\n\r\n396 Return 0 0 0 0 0 0 0 0 1 0 . 0  0 \r\n \r\n\r\n \r\n\r\nbộ tập các câu trong sentences. Dễ dàng nhận thấy trong là một ma trận rất thưa. \r\n\r\nThuật ngữ Đặc trưng ngữ nghĩa Câu S20 \r\nW*1 W*2 W*3 . W*10 Original !\"#$%*\"\r\n\r\n'$\r\n\r\n\"('\r\n \r\n \r\n\r\n. . . . . . . . .  \r\n13 War 0 0 0 . 0.04 0  0.11 \r\n14 British 0 0.68 0.44 . 0.13 1  0.89 \r\n15 authority 0 0.60 0 . 0 1  1.05 \r\n16 income 0 0 0.35 . 0.03 0  0.11 \r\n17 increase 0.07 0 0 . 0.76 1  1.01 \r\n. . . . . . . . .  \r\n\r\n396 Return 0 0 0 . 0.08 0  0.07 \r\nTrọng số Hj20  0 0.07 0 . 0    \r\n\r\n \r\n\r\n \r\n\r\nphân tích NMF đối với ma trận A, giá trị trọng số H1,20, ..., H10,20 của vec-tơ đặc \r\ntrưng ngữ nghĩa tương ứng với câu S20, vec-tơ câu ban đầu. Vec-tơ câu được tính \r\ntừ các giá trị trọng số và các vec-tơ ngữ nghĩa. Phương pháp NMF trích xuất câu có \r\ntrọng số lớn nhất theo nghĩa: câu đó phản ánh nhiều nhất tới chủ đề chính của tài \r\nliệu, điều đó được biểu diễn bởi các đặc trưng ngữ nghĩa. Do đó, phương pháp NMF \r\n\r\n\r\n\r\n\r\ncó likelihood tốt hơn trong việc trích xuất các câu quan trọng về mặt ngữ nghĩa so \r\nvới phương pháp LSA. \r\n\r\n \r\n2.3 Các vấn đề của NMF \r\n2.3.1 Ưu điểm \r\n\r\n Đối với việc số hóa một tài liệu sang dạng dữ liệu để máy tính  phiên bản số \r\ncủa tài liệu có thể thực hiện các phép toán cộng, trừ, nhân, chia,..., từ đó có thể thực \r\nhiện các công việc khai phá dữ liệu như phân loại văn bản (bài toán topic \r\nmodelling), tóm tắt văn bản (text summarizing),. thì việc sử dụng mô hình không \r\ngian vec-tơ mà cụ thể là phương pháp phân tích ma trận theo mô hình tần suất \r\ndường như là một cách làm mang tính tự nhiên nhất. Trong chương 2, đồ án đã đề \r\nxuất sử dụng một phương pháp không giám sát mới để sinh ra văn bản tóm tắt của \r\ntài liệu tương ứng sử dụng kĩ thuật phân tích ma trận không âm NMF. Phương pháp \r\nđược đề xuất có những ưu điểm sau đây: \r\n\r\n Thứ nhất, đây là phương pháp không giám sát (unsupervised) và \r\nkhông yêu cầu các tóm tắt mẫu cho bước tập huấn và cho bộ tóm tắt. \r\n\r\n Thứ hai, các vec-tơ đặc trưng ngữ nghĩa được trích rút từ NMF có thể \r\nđược thể hiện trực quan hơn là sử dụng các phương pháp liên quan \r\nđến LSA, bởi vì các thành phần trong phân tích NMF chỉ gồm các giá \r\ntrị không âm và chúng rất thưa trong khi cũng là các thành phần đó \r\nnhưng trong phương pháp LSA thì gồm cả giá trị âm và giá trị dương, \r\nngoài ra, còn có chứa một vài giá trị bằng 0.  \r\n\r\n Hơn nữa, một câu được có thể được biểu diễn như là sự kết hợp tuyến \r\ntính của những đặc trưng ngữ nghĩa một cách trực quan. \r\n\r\n Cuối cùng, phạm vi ngữ nghĩa của đặc trưng ngữ nghĩa là hẹp, bởi vì \r\nchúng rất thưa, theo đó, các chủ đề nhỏ (sub-topics) của tài liệu được \r\nxác định một cách dễ dàng và chính xác hơn. Do đó, khả năng trích \r\nrút được các câu quan trọng sẽ tốt hơn các phương pháp khác. \r\n \r\n\r\n2.3.2 Nhược điểm \r\n\r\n Tuy nhiên, nhược điểm của phương pháp nằm ở việc không thể phát hiện ra \r\ncác liên kết ẩn giữa các từ, các phần trong văn bản. Các liên kết này có thể tồn tại \r\ndưới nhiều dạng, đó có thể là quan hệ nguyên nhân  kết quả giữa các luận điểm, có \r\nthể là những phần được nhấn mạnh, quan trọng hơn những phần khác hay là sự thay \r\nđổi cách sử dụng ngôn từ diễn đạt, và có một số thuật ngữ, tuy khác nhau về hình \r\nthức nhưng lại mang những nét nghĩa giống nhau.  \r\n\r\n\r\n\r\n\r\n2.4 Mô hình đề xuất \r\n \r\n\r\nTrong phần này ta sẽ đi vào thiết kế hệ thống thực tế để giải quyết bài toán \r\ntóm tắt văn bản trong ngôn ngữ tiếng Anh và tiếng Việt sử dụng NMF và phân tích \r\nđặc trưng.  \r\n\r\n \r\n\r\n \r\n \r\n \r\n2.4.1 Khối tiền xử lý văn bản \r\n\r\n2.4.1.1 Khối tiền xử lý văn bản tiếng Việt \r\n \r\n\r\nQuá trình tiền xử lý văn bản đầu vào tiếp theo gồm các bước sau:  \r\n Chia văn bản thành các câu. \r\n Chia nhỏ từng câu thành các từ. \r\n Chuyển toàn bộ văn bản về dạng chữ thường \r\n Loại bỏ các kí tự đặc biệt, không có ý nghĩa \r\n\r\nPhần tách câu và tách từ sử dụng công cụ Vitk (Vietnamese Text Progressing \r\nToolkit)  của tác giả Lê Hồng Phương. Ví dụ câu Mỹ: hai tai nạn trên đường cao \r\ntốc, 11 người thiệt mạng sau khi qua tool sẽ được tách thành Mỹ : hai tai_nạn trên \r\nđường_cao_tốc , 11 người thiệt_mạng . \r\n\r\nCác kí tự đặc biệt như \"\\-;%()|+&=*%.,!?:#$@\\/ cũng sẽ bị loại bỏ khỏi văn \r\nbản. \r\n\r\n2.4.1.2 Khối tiền xử lý văn bản tiếng Anh \r\n \r\n Bước tiền xử lý gồm 2 hoạt động chính là Chuẩn hoá từ và Loại bỏ các cấu \r\ntrúc ngữ pháp của từ, đău về dạng nguyên thể trong tiếng Anh.  \r\n\r\n\r\n\r\n\r\nCả hai hoạt động này đều đóng vai trò quan trọng trong việc vec-tơ hóa tài liệu bởi \r\nvì nó sẽ làm giảm không gian biểu diễn của văn bản xuống, do đó làm giảm khối \r\nlượng cần tính toán. \r\n  \r\n\r\nCụ thể, quá trình tiền xử lí văn bản đầu vào bao gồm các công việc sau: \r\n Chia văn bản đầu vào thành tập các câu. \r\n Chia nhỏ câu thành các từ. \r\n Lọc stopwords \r\n Chuẩn hóa từ \r\n\r\n Lemmatizing \r\n Stemming \r\n \r\n\r\n Stemming  \r\n\r\n Là kĩ thuật hình thái từ dành cho khai phá thông tin (Information retrieval) \r\nđược ứng dụng rộng rãi nhất. Stemming là kĩ thuật dùng để biến đổi một từ về dạng \r\ngốc (được gọi là stem hoặc root form) bằng cách cực kì đơn giản là loại bỏ một số \r\nkí tự nằm ở cuối từ mà nó nghĩ rằng là biến thể của từ. Người ta gọi các bộ xử lí \r\nstemming là stemmer. Bởi vì nguyên tắc hoạt động của stemmer rất đơn giản nên \r\ntốc độ xử lí của nó rất nhanh nhưng đôi khi lại cho ra kết quả không như ý muốn. \r\n\r\n Ví dụ 4: Cách thực hiện của bộ stemmer \r\n\r\n Các từ walks, walked, walkingsau khi stemming, bỏ đi các hậu \r\ntố -s, -ed, -ing sẽ trở thành walk \r\n\r\n Từ gosesau stemming thành gos \r\n Không thể đưa các từ như spoke, went về dạng speak hay go \r\n\r\n Lemmatization   \r\n\r\n Lemmatization là một kĩ thuật chuẩn hóa từ khác: Không giống với \r\nStemming là xử lí bằng cách loại bỏ các kí tự cuối từ một cách kinh nghiệm \r\n(heuristic), Lemmatization sẽ xử lí thông minh hơn bằng một bộ từ điển hoặc \r\nontology (hệ thống nhãn ngữ nghĩa) nào đó. Điều này đảm bảo đưa chính xác các \r\ndạng biến thể của từ về nguyên gốc trong từ điển. Người ta gọi bộ xử lí \r\nlemmatization là lemmatizer \r\n\r\n Nhược điểm của lemmatization là tốc độ xử lí khá chậm vì phải thực hiện tra \r\ncứu từ trong cơ sở dữ liệu. Trong các ứng dụng xử lí ngôn ngữ tự nhiên mà cần độ \r\n\r\n\r\n\r\n\r\nchính xác cao hơn và thời gian không quan trọng, người ta có thể sử dụng \r\nLemmatization. \r\n\r\n Ví dụ 5: Cách thực hiện của Lemmatizer \r\n\r\n Các từ như gose, wentsẽ được đưa chính xác về go. \r\n Các danh từ như mouse, micecũng được đưa về cùng một dạng \r\n\r\nnhư nhau. \r\n\r\n Loại bỏ stopwords \r\n\r\n Trong quá trình tính toán, stopwords là những từ được lọc trước hoặc sau quá \r\ntrình xử lý dữ liệu ngôn ngữ tự nhiên (văn bản). Stopwords thường là những từ xuất \r\nhiện với tần suất lớn trong một ngôn ngữ, do đó không có một danh sách các \r\nstopwords thống nhất và được sử dụng bởi tất cả các công cụ xử lý ngôn ngữ tự \r\nnhiên. \r\n\r\n Một nhóm bất kì các từ có thể được chọn là một stopwords để thực hiện một \r\nmục đích nhất định. Đối với một search engine, có một số từ được xếp vào loại stop \r\nwords do sự xuất hiện thường xuyên trong các trường hợp tìm kiếm như: the, is, at, \r\nwhich và on. Trong trường hợp này, stopwords có thể là nguyên nhân gây ra vấn đề \r\nkhi tìm kiếm theo phrases mà bao gồm những function word này, đặc biệt là khi tìm \r\nkiếm một số tên như: The Who, The The, hoặc Take That. Ngoài ra, một số \r\nsearch engine loại bỏ các từ common words, bao gồm cả lexical words như want \r\nkhỏi câu truy vấn nhằm mục đích cải thiện hiệu suất của search engine. \r\n\r\n Sự phân biệt giữa function words và lexical words được đề xuất bởi C. Fries \r\nvào năm 1952 và có một tầm ảnh hưởng lớn đến việc dạy tiếng Anh. \r\n\r\n Function words: Còn gọi là functors là những từ có một chút lexical \r\nmeaning hoặc có sự nhập nhằng về nghĩa và chúng nhấn mạnh mối \r\nquan hệ ngữ pháp với các từ khác trong cùng một câu, một quan điểm \r\ncụ thể hay tâm trạng của người nói. Một số trường hợp của function \r\nwords: Pronouns  đại từ (he  him, she-her,.); conjunction  liên từ \r\nhoặc auxiliary verb - trợ động từ \r\n\r\n Lexical words: Từ thực, những từ mà không phải là function word. \r\nlexical word bao gôm: danh từ, động từ, tính từ và hầu hết trạng từ vì \r\ncó một số trạng từ là function word như: then, why. \r\n\r\n Từ điển có thể định nghĩa một cách cụ thể một lexical word, nhưng \r\nchỉ có thể miêu tả một cách sử dụng tổng quát của function word. \r\n\r\n\r\n\r\n\r\n Ngược lại, ngữ pháp có thể miêu tả cách sử dụng của function words \r\nmột cách chi tiết, nhưng lại chỉ có thể xem lexical words trong các \r\nthuật ngữ chung (general term). \r\n\r\n \r\n2.4.2 Độ tương đồng Cosine trong Không gian Vec-tơ \r\n\r\nTrong mục này, em sẽ trình bày những kiến thức cơ bản về thước đo cosine \r\nđược sử dụng để xác định độ tương đồng giữa 2 từ trong mô hình Word2Vec và ứng \r\ndụng trong phạm vi đồ án. \r\n\r\n \r\nTích vô hướng \r\n\r\n \r\n Chúng ta bắt đầu với định nghĩa về số học của tích vô hướng giữa hai vec-tơ: \r\n ! = !#, !%, !&, .    và ! = !#, !%, !&, .    với an và bn lần lượt là các thành phần \r\ncủa vec-tơ !   ,  !   và n là số chiều của các vec-tơ: \r\n \r\n !. # = !%#% = !&#& + !(#( + + !*#*\r\n\r\n*\r\n\r\n%+&\r\n \r\n \r\n\r\n \r\n\r\n \r\n Tuy nhiên, để thấy được hết ý nghĩa của phép nhân vô hướng giữa 2 vec-tơ, \r\nchúng ta phải xem xét đến định nghĩa hình học của nó: \r\n \r\n !\" = !\" cos (   \r\n\r\n \r\n Sử dụng tính chất giao hoán để sắp xếp lại vế phải của công thức trên ta có: \r\n \r\n !\" = \"! cos (   \r\n\r\n \r\n Trong lý thuyết hình học, phép nhân \" cos &   chính là phép chiếu của vect-\r\ntơ !   lên vec-tơ !   , \r\n \r\n\r\n\r\n\r\n\r\n \r\n\r\n \r\n Khi vec-tơ !   vuông góc với vec-tơ !   tích này trở thành: \r\n\r\n \r\n\r\n \r\n Khi 2 vec-tơ vuông góc, tích vô hướng của chúng bằng 0. Đây cũng là một \r\ncách để chúng ta kiểm tra 2 vec-tơ có quan hệ vuông góc hay không. Tuy nhiên, ví \r\ndụ trên mới chỉ dừng lại ở  không gian vec-tơ hai chiều, nhưng có một điều thú vị \r\nrằng, chúng ta cũng có thể tính toán góc và độ tương đồng giữa các vec-tơ trong \r\nkhông gian nhiều chiều, mà trong bài toán của chúng ta là Không gian vec-tơ 300 \r\nchiều. \r\n \r\n Độ tương đồng Cosine \r\n \r\n Độ tương đồng cosine giữa hai vec-tơ (hoặc 2 từ trong Không gian vec-tơ) là \r\nmột thước đo tính giá trị cosine của góc giữa chúng. Thước đo này là thước đo về \r\nhướng của 2 vec-tơ, không phải thước đo về độ lớn. \r\n Ta có: \r\n \r\n\r\ncos $ = &'\r\n&'\r\n\r\n \r\n \r\n\r\n \r\n\r\n Đây chính là công thức về độ tương đồng cosine. Độ tương đồng cosine sẽ \r\nsinh ra một số, số này sẽ cho chúng ta biết 2 từ liên quan đến nhau như thế nào \r\ntrong không gian bằng cách xem xét góc giữa chúng, thay vì so sánh về độ lớn. \r\n \r\n\r\n \r\n\r\n\r\n\r\n\r\n       a)  Cùng hướng                      b) Vuông góc                         c) Đối diện \r\n \r\n\r\n2.4.3 Khối tính điểm cho câu sử dụng NMF \r\n\r\nKhối tính điểm cho câu trong tài liệu là tổng hợp điểm đầu ra của 3 khối nhỏ \r\nhơn, trong đó: \r\n\r\n Sử dụng khối Word2Vec như một đặc trưng thứ nhất để xác định các \r\nngữ nghĩa ẩn trong bài toán tóm tắt. \r\n\r\n Sử dụng khối đặc trưng thứ hai để phân tích các đặc trưng cấu trúc \r\ncủa tài liệu. \r\n\r\n Sử dụng kết quả của kĩ thuật phân tích ma trận NMF.  \r\nỞ đây ta sẽ sử dụng một phương pháp mới để chọn câu dựa trên phân tích \r\n\r\nNMF và định nghĩa đại lượng Generic Relevance of a Sentence (GRS)  như sau: \r\n \t   \r\n\r\n\t\t\t\t\t\t\t\t\t\"#$#%&'\t(#)#*+$'#\t,-\t+\t./\t1#$/#$'# = \t 3457#&8/ 34*\r\n:\r\n\r\n4;<\r\n \r\n\r\n \r\n  \r\n !\"#$& '(* =\r\n\r\n'(+,+-.\r\n'/+,+-.0/-.\r\n\r\n \r\n \r\n\r\n \r\n\r\n \r\n Trong đó, trọng số weight(Hi*) là sự liên quan về quan hệ (relative \r\nrelevance) của đặc trưng ngữ nghĩa thứ i (W*i) với tất cả các đặc trưng ngữ nghĩa \r\ncòn lại. Một cách tổng quát, đại lượng thể hiện mức độ liên quan của một câu chính \r\nlà mức độ phản ánh của câu đó đối với chủ đề chính của tài liệu, và được biểu diễn \r\ndưới hình thức các đặc trưng ngữ nghĩa. \r\n2.4.4 Khối tính điểm đặc trưng cấu trúc \r\n\r\na. Đặc trưng bề mặt \r\n \r\n\r\nCác câu đầu đứng đầu hầu như mang nhiều nội dung tóm tắt hơn các câu \r\nphía sau. Do đó ta sẽ ưu tiên cho các câu này. Công thức tính điểm như sau: \r\n\r\n position = \r\n!\r\n\"#!    (  i là hệ số vị trí câu)  \r\n\r\nTrong đó:  \r\n i: là hệ số vị trí câu \r\n position: là kí hiệu điểm đặc trưng vị trí \r\n \r\n\r\n\r\n\r\n\r\nCác câu quá ngắn cũng không mang nhiều giá trị. Do vậy những câu độ dài \r\nnhỏ hơn 10 từ sẽ bị điểm trừ: \r\n\r\nlengthSent = !\"#$%&\t(\t)*)*     (  i là hệ số vị trí câu, !\"#$%&   là số từ xuất                    \r\nhiện trong câu thứ i) \r\n\r\n Trong đó: \r\n  i: là hệ số vị trí câu \r\n  !\"#$%&  : là số từ xuất hiện trong câu thứ i \r\n  lengthSent: là kí hiệu điểm đặc trưng đồ dài \r\n\r\nb. Đặc trưng nội dung \r\n \r\n\r\nChúng ta sẽ sử dụng 2 phương pháp centroid base và frequence word để tính \r\nđiểm đặc trưng nội dung. \r\nCentroid dựa trên độ tương đồng giữa các câu trong văn bản. Ở đây em sử \r\ndụng hàm cosin để tính độ tương đồng giữa câu với đầu vào là vectơ biểu \r\ndiễn từ sử dụng word2vec. \r\n !\" = $%&%'()%*+($\", $.)0.12     \r\nTrong đó: \r\n n: là tổng số câu trong văn bản \r\n i: là vị trí câu hiện tại \r\n !\"  : là kí hiệu điểm centroid của câu thứ i \r\n \r\nFrequence word lại tính điểm câu dựa trên tần suất xuất hiện các từ quan \r\ntrọng trong câu. Ở đây qua quá trình thực nghiệm em chọn ngưỡng 20% từ \r\nxuất hiện nhiều nhất trong văn bản đầu vào.  \r\n \r\n\r\n  Fi = !(#$)&(')\r\n(\r\n)            \r\n\r\n \r\n Trong đó:  \r\n\r\nf(!\"  ): tổng số lần xuất hiện của từ k trong cả văn bản \r\n  s(d): tổng số lần xuất hiện của tất cả các từ trong văn bản \r\n  Fi : là điểm Frequence của câu thứ i \r\n\r\nc. Đặc trưng độ liên quan \r\nỞ phương pháp tính theo đặc trưng độ liên quan em đề suất sử dụng 2 \r\nphương pháp đó là tính theo độ liên quan với câu đầu tiên FirstRel và \r\nphương pháp PageRank. PageRank là phương pháp khai thác liên quan giữa \r\n\r\n\r\n\r\n\r\ncác câu bằng việc xây dựng một bản đồ câu. Dựa trên bản đồ này thuật toán \r\nPageRank được áp dụng để đánh giá tầm quan trọng của một câu. \r\n !\" = $%&%'()%*+($\", $.)    ( độ tương đồng từng câu so với câu đầu tiên) \r\nTrong đó: \r\n !\"  : là vecto biểu diễn câu thứ i \r\n !\"  : là điểm FirstRel của câu thứ i \r\n \r\n\r\n2.4.5 Khối trích rút câu \r\n\r\n Kết hợp các phương pháp trên ta có công thức cuối cùng để tính điểm \r\ncho từng câu: \r\n \r\n! \" = \t!%&' +\t!)  \r\n \r\nTrong đó: \r\n\r\n ! \" \t  : Trọng số cuối cùng của câu s \r\n !\"#$   : Trọng số thu được từ phân tích ma trận NMF \r\n !\"  :  Trọng số thu được từ phân tích các đặc trưng cấu trúc của câu. \r\n\r\n \r\n!\" # = \t&'( # +\t&*+ # +\t&,-(#)  \r\n \r\nTrong đó: \r\n\r\n !\" # \t  : Trọng số đặc trưng cho câu s \r\n ! \" \t  Điểm đặc trưng nội dung (Content) \r\n ! \"   : Điểm đặc trưng bề mặt (Surface) \r\n !(#)  : Điểm đặc trưng độ liên quan (Relevance) \r\n !\", !$, !%\t  :  lần lượt là các trọng ứng với các đặc trưng về nội dung, bề \r\n\r\nmặt và liên quan được tính toán và điều chỉnh dựa trên kết quả thực \r\nnghiệm.  \r\n \r\n \r\n\r\n2.5 Thực nghiệm \r\n \r\n2.5.1 Môi trường thử nghiệm \r\n\r\n Chương trình được xây dựng và thử nghiệm trên máy tính cá nhân có cấu \r\nhình và các phần mềm cần thiết như sau:  \r\n\r\n- Vi xử lý: 2.2 GHz Quad-Core Intel Core i7 Crystalwell \r\n\r\n\r\n\r\n\r\n- Ram: 16Gb  \r\n- Hệ điều hành: MacOs Sierra \r\n- Phần mềm phát triển: PyCharm \r\n- Ngôn ngữ sử dụng: Python \r\n- Thư viện tách từ, xử lý từ tiếng Anh: nltk \r\n- Thư viện tách từ, tách câu tiếng Việt: vnTokenizer \r\n\r\n \r\n2.5.2 Phương pháp đánh giá \r\n\r\nĐánh giá kết quả tóm tắt văn bản là một việc làm khó khăn trong thời điểm \r\nhiện tại. Việc sử dụng ý kiến đánh giá của các chuyên gia ngôn ngữ được xem là \r\ncách đánh giá tốt nhất, tuy nhiên, cách làm này lại tốn rất nhiều chi phí. Bên cạnh \r\ncác phương pháp đánh giá thủ công do các chuyên gia thực hiện, vấn đề đánh giá tự \r\nđộng kết quả tóm tắt cũng nhận được nhiều sự chú ý hiện nay. NIST kể từ năm \r\n2000 đã tổ chức hội nghị DUC mỗi năm một lần để thực hiện việc đánh giá với quy \r\nmô lớn các hệ thống tóm tắt văn bản. Việc đánh giá tựu động này nhằm mục đích là \r\ntìm ra được một độ đo đánh giá tóm tắt gần với những đánh giá của con người \r\nnhất.Trong bài toán này em lựa chọn phương pháp Rouge để làm thước đo đánh giá \r\nđộ chính xác cho cả bài toán tóm tắt văn bản tiếng Anh lẫn tóm tắt văn bản tiếng \r\nViệt. \r\n\r\nRecall Oriented Understudy (ROUGE) là một phương pháp do Lin và Hovy \r\nđưa ra vào năm 2003 cũng dựa trên các khái niệm tương tự. Phương pháp này sử \r\ndụng n-gram để đánh giá sự tương quan giữa các kết qủa của mô hình tóm tắt và tập \r\ndữ liệu đánh giá. Phương pháp này đã cho ra kết quả khả quan và được sự đánh giá \r\ncao của cộng đồng nghiên cứu tóm tắt văn bản. \r\n\r\nROUGE-N là một thu hồi n-gram (n-gram recall) giữa một bản tóm tắt tự \r\nđộng và một tập các tài liệu tóm tắt tham chiếu (ReferenceSummaries). ROUGE-N \r\nđược tính như sau: \r\n   \r\n \r\n\r\n\t\t\t\t\t\t\"#$%&-( = \t *+,-./0123 456789:0/;=={?@A@:@82@=B//0:C@D} *+,-.(45678)9:0/;=={?@A@:@82@=B//0:C@D}\r\n \r\n \r\n\r\n \r\nTrong đó: \r\n\r\n n là chiều dài của n-gram \r\n Countmatch(gramn) là số lượng tối đa n-gram có thể xảy ra đồng thời \r\n\r\ntrong bản tóm tắt tự động và bản tóm tắt tham chiếu. \r\n\r\n\r\n\r\n\r\n Rõ ràng ROUGE-N là một độ đo liên quan đến độ recall bởi vì mẫu số của \r\nvế phải trong công thức trên là tổng số n-gram xảy ra ở phía bản tóm tắt tham \r\nchiếu. \r\n Cũng có một lưu ý rằng, số lượng n-gram ở mẫu số trong công thức tính \r\nROUGE-N sẽ tăng lên khi chúng ta cho thêm nhiều tham chiếu. Điều này hoàn toàn \r\ntrực quan và hợp lí bởi vì có thể tồn tại nhiều bản tóm tắt tốt. \r\n Mỗi khi chúng ta thêm một tham chiếu vào tập các văn bản tham chiếu, \r\nchúng ta đã mở rộng không gian các văn bản tóm tắt thay thế (alternative \r\nsummaries). Bằng cách điều khiển các kiểu tham chiếu mà ta thêm vào tập văn bản \r\ntham chiếu, chúng ta có thể thiết kế các đánh giá tập trung vào các khía cạnh khác \r\nnhau của việc tóm tắt. Ngoài ra, tổng tử số lớn hơn tổng số số bản tóm tắt tham \r\nchiếu. Điều này hiệu quả vì cung cấp thêm nhiều trọng số để matching các n-grams \r\nxảy ra trong đa tham chiếu. Do đó, một bản tóm tắt tự động càng chứa nhiều những \r\ntừ được xuất hiện trong nhiều bản tóm tắt tham chiếu thì sẽ dành được điểm \r\nROUGE-N càng cao. Điều này một lần nữa lại rất trực quan và hợp lí bởi vì chúng \r\nta thường ưu tiên các bản tóm tắt tự động càng có nhiều nét giống với các điểm \r\ngiống nhau giữa các bản tóm tắt tham chiếu càng tốt. \r\n Khi sử dụng đa tham chiếu, chúng ta tính ROUGE-N theo từng cặp, giữa bản \r\ntóm tắt tự động s và từng bản tóm tắt tham chiếu ri trong tập các văn bản tóm tắt \r\ntham chiếu. Sau đó, kết quả điểm ROUGE-N cuối cùng trong đa tham chiếu sẽ là \r\nđiểm ROUGE-N cao nhất trong tất cả các cặp được tính. Điều này có thể được thể \r\nhiện theo công thức sau: \r\n \r\n !\"#$%-' = )*+,)-.!\"#$%-' *., 0    \r\n\r\n \r\n Trong quá trình khởi tạo, thuật toán đánh giá sử dụng thủ tục Jackknifing. \r\nCho M tham chiếu, chúng ta tính điểm tốt nhất khi duyệt qua M tập tham chiếu M-\r\n1; điểm ROUGE-N cuối cùng là trung bình cộng của M điểm ROUGE-N đối với \r\ncác tham chiếu M-1. Thủ tục Jackknifing được chọn bởi chúng ta thường cần so \r\nsánh hiệu suất giữa con người và hệ thống và bản tóm tắt tham chiếu thường chỉ do \r\ncon người tóm tạo ra. \r\n Bằng cách áp dụng thủ tục này, chúng ta có thể ước lượng hiệu suất trung \r\nbình của con người bằng việc lấy trung bình cộng M điểm ROUGE-N của một bản \r\ntham chiếu với toàn bộ M-1 tham chiếu. \r\n\r\n \r\n \r\n\r\n\r\n\r\n\r\n2.5.3 Thực nghiệm trên dữ liệu văn bản tiếng Anh \r\n\r\n2.5.3.1  Dữ liệu thực nghiệm \r\nDữ liệu được sử dụng trong chương trình là bộ dữ liệu DUC2007. Đây là các \r\n\r\nbài báo tin cậy phủ rộng trong nhiều lĩnh vực. Bộ dữ liệu gồm 43 bản ghi, mỗi bản \r\nghi gồm khoảng 10 văn bản, ứng với mỗi bản ghi lại có 3 bản tóm tắt. \r\n\r\nĐồ án sử dụng tập dữ liẹu DUC2007 như là một tập dữ liệu để kiểm tra. \r\nDocument Understanding Conference (DUC) là một hội nghị quốc tế để đánh giá \r\nhiệu suất của hệ thống tóm tắt bằng cách so sánh bản tóm tắt bằng tay của các \r\nchuyên gia với bản tóm tắt tự động của máy tính. DUC2007 là bộ dữ liệu dùng cho \r\ntác vụ tóm tắt đa văn bản, gồm 50 bản ghi, mỗi bản ghi gồm nhiều văn bản có cùng \r\nchủ đề. Để phù hợp với bài toán đặt ra ta coi mỗi bản ghi đó là một đơn văn bản. \r\nBản tóm tắt cũng gồm 50 bản ghi, mỗi bản có độ dài 250 từ.  \r\n Trong quá trình tiền xử lý dữ liệu em sử dụng thư viện ntlk cho quá trình \r\ntách từ, loại bỏ stopword, lemmatized. Phần tách câu được bỏ qua do bộ dữ liêu đã \r\nchia câu sẵn trong các thẻ xml.  \r\n\r\n2.5.3.2 Kết quả thực nghiệm \r\n Đồ án tập trung vào việc nghiện cứu kết hợp phương pháp tóm tắt không \r\ngiám sát  đại diện là phương pháp phân tích ma trận NMF với phương pháp tóm \r\ntắt dựa trên các đặc trưng cấu trúc.  \r\n  \r\n\r\nRouge  \r\nFeature\t\r\n\r\nRouge-1 \r\n(%) \r\n\r\nRouge-2 \r\n(%) \r\n\r\nRelevance 41.92         10.48 \r\n\r\nSurface 39.04           9.29 \r\n\r\nContent 42.37 10.69 \r\n \r\n\r\n \r\n Từ bảng kết qủa trên cho chúng ta nhận xét trong 3 đặc trưng thì đặc trưng \r\nContent cho chất lượng văn bản tóm tắt tốt nhất, 42.37% với Rouge-1 và 10.69% \r\nvới Rogue-2. Đặc trưng Relevance có độ quan trọng thứ 2 với điểm số gần như \r\ntương tự 41.92% với Rouge-1 và 10.48% với Rouge-2 \r\n \r\n \r\n\r\n\r\n\r\n\r\nRouge  \r\nFeature\t\r\n\r\nRouge-1 \r\n(%) \r\n\r\nRouge-2 \r\n(%) \r\n\r\nNMF 41.67           9.99 \r\n\r\n3 features 41.56 10.42 \r\n\r\nNMF + 3 features 42.34 10.77 \r\n \r\n\r\n \r\nKhi kết hợp cả 2 phương pháp với nhau hệ thống cho kết qủa tốt nhất với điểm \r\nRouge-2 là 10.77% và Rouge-1 là 42.34%. Từ bản trên ta cũng có thể thấy phương \r\npháp NMF đơn thuần cho kết quả cao hơn với phương pháp đặc trưng cấu trúc \r\n41.67% với 41.56% \r\n Qua kết quả trên chúng ta có thể rút ra được nhận xét: \r\n\r\n Trong phạm vi nghiên cứu, đồ án đã chứng minh được phương pháp \r\nkết hợp cả 2 hướng tiếp cận NMF và cấu trúc mang kết qủa tốt hơn \r\nkhi sử dụng đơn lẻ từng phương pháp \r\n\r\n Do tính đặc trưng của ngôn ngữ học, sự kết hợp các đặc trưng cấu trúc \r\nkhông phải luôn tuân theo quy luật tỉ lệ thuận giữa điểm ROUGE-1 và \r\nROUGE-2. \r\n\r\n Việc kết hơp cả 3 phương pháp đặc trưng cấu trúc không hẳn là một \r\nlựa chọn tốt do làm giảm hiệu năng khi so sách với trường hợp sử \r\ndụng từng đặc trưng một. \r\n\r\n    \r\n2.5.4 Thực nghiệm trên dữ liệu văn bản tiếng Việt \r\n\r\n2.5.4.1  Dữ liệu thực nghiệm \r\n \r\n\r\nDữ liệu trong bài toán sử dụng là hơn một triệu văn bản từ Báo Mới. Sau đó \r\nchọn ra 100 văn bản để tóm tắt. Tách riêng phần lead + head của bài báo và coi đó \r\nlà văn bản tóm tắt đúng. Phần giữ lại chính là đầu vào của bài toán. \r\n\r\nĐồ án sử dụng tập dữ liệu được chọn ra từ hơn một triệu văn bản từ Báo \r\nMới. Bộ dữ liệu Báo Mới có dung lượng 3.64GB được chia thành 1000 bản ghi, \r\nmỗi bản ghi gồm hơn 1000 văn bản được chia cắt bởi kí tự #. Bản thân bộ dữ liệu \r\ncũng đã được tiền xử lý qua trước, 2 câu đầu tiên của mỗi văn bản là tiêu \r\nđề(heading) và phần miêu tả (description), từ câu thứ 3 trờ đi là phần nội dung của \r\nvăn bản. \r\n\r\n\r\n\r\n\r\n Bước đầu tiên của quá trình tiền xử lý là phải tách riêng từng văn bản từ tập \r\n1000 bản ghi, sau đó loại bỏ những văn bản trùng lặp. Chọn trong tập văn bản \r\nnhững văn bản thoả mãn điều kiện có số từ tổng cộng ở phần headline + description \r\ntrong khoảng 240-260 từ, phần này sau đó sẽ được tách ra để làm dữ liệu đánh giá \r\nkết qảu của chương trình. Phần nội dung văn bản cũng phải thoả mãn có độ dài \r\ntrung bình từ 1300 đến 1400 từ. Sau quá trình này thu được 140 văn bản từ tập hơn \r\n1 triệu văn bản thoả mãn yêu cầu. \r\n Trước khi đưa vào NMF 140 văn bản trên được tiền xử lý tiếp qua các bước \r\ntách câu, tách từ, lowercase, loại bỏ kí tự đặc biệt. Phần tách câu và tách từ em sử \r\ndụng công cụ vnTokenizer phiên bản 4.1.1 của Tiến sĩ Lê Hồng Phương. Bộ cung \r\ncụ được viết bằng java có các chức năng chính như tách từ, tách câu, gán nhãn từ \r\nloại với độ chính xác khoảng 98%.  Phần lowercase và loại bỏ kí tự đặc biệt được \r\nthực hiện qua phương thức clean_text \r\n \r\ndef clean_text(text):  \r\n    text = text.lower() \r\n    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE) \r\n    text = re.sub(r'\\<a href', ' ', text) \r\n    text = re.sub(r'&amp;', '', text) \r\n    text = re.sub(r'[\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text) \r\n    text = re.sub(r'<br />', ' ', text) \r\n    text = re.sub(r'\\'', ' ', text) \r\n \r\n    return text \r\n\r\n2.5.4.2 Kết quả thực nghiệm \r\n  \r\n\r\nRouge  \r\nFeature\t\r\n\r\nRouge-1 \r\n(%) \r\n\r\nRouge-2 \r\n(%) \r\n\r\nRelevance 53.33         10.35 \r\n\r\nSurface 53.98         10.58 \r\n\r\nContent 54.87 11.25 \r\n \r\n\r\n \r\n Đặc trưng Content vẫn cho kết quả tốt nhất như với bài toán tóm tắt văn bản \r\ncho tiếng Anh 54.87% với Rouge 1 và 11.25% đối với Rouge 2. Đặc trưng Surface \r\nvới bài toán tóm tắt tiếng Việt lại cho kết quả cao hơn so với đặc trưng Relevance \r\n0.65% cho Rouge 1 và 0.23% cho Rouge 2 trong khi bài toán tóm tắt với tiếng Anh \r\nđặc trưng Relevance lại cho kết qủa cao hơn so với Surface. Nguyên nhân có thể \r\nđược giải thích do tập dữ liệu đầu vào của 2 bài toán có cấu trúc khác nhau. Đối với \r\n\r\n\r\n\r\n\r\nbài toán tóm tắt văn bản cho tiếng Anh dữ liệu đầu vào là các văn bản có chung chủ \r\nđề được ghép lại với nhau còn dữ liệu cho bài toán tóm tắt bằng tiếng Việt chỉ có \r\nmột văn bản duy nhất.  \r\n  \r\n\r\nRouge  \r\nFeature\t\r\n\r\nRouge-1 \r\n(%) \r\n\r\nRouge-2 \r\n(%) \r\n\r\nNMF 53.23         10.33 \r\n\r\n3 features 54.07         10.31 \r\n\r\nNMF + 3 features 54.57 11.53 \r\n \r\n\r\n \r\n\r\nKhi kết hợp cả 2 phương pháp với nhau hệ thống cho kết qủa tốt nhất với điểm \r\nRouge-2 là 11.53% và Rouge-1 là 54.57%. Việc kết hợp 2 cách tiếp cận vẫn đem lại \r\nkết quả tốt hơn khi áp dụng đơn lẻ với từng phương pháp khi áp dụng cho ngôn ngữ \r\ntiếng Việt. Và việc kết hợp cả 3 phương pháp đặc trưng vẫn cho kết quả thấp hơn \r\nmột số đặc trưng đơn lẻ, việc này là do các trọng số từng đặc trưng vẫn chưa được \r\ntối ưu một cách tốt nhất. \r\n \r\n2.6 Tóm tắt chương \r\n \r\n Chương này đã đưa ra một cái nhìn tổng quan về các kĩ thuật: Phân tích ma \r\ntrận, các đặc trưng cấu trúc của văn bản trong vấn đề khai phá dữ liệu văn bản mà \r\ncụ thể là bài toán Tóm tắt văn bản tự động. Ứng dụng phương pháp này cho cả 2 \r\nngôn ngữ tiếng Anh và tiếng Việt. \r\n Đồ án đã đề suất một cách tiếp với bài toán tóm tắt văn bản dựa vào trích \r\nxuất bằng cách sử dụng ma trận không âm NMF kết hợp với trích suất đặc trưng và \r\nchứng minh được tính hiệu quả của phương pháp khi áp dụng trên cả 2 ngôn ngữ \r\ntiếng Việt và tiếng Anh. Các thí nghiệm của em được thực hiện với các kịch bản \r\nkhác nhau bằng bộ dữ liệu DUC2007 cho tiếng Anh và bộ dữ liệu Báo Mới cho \r\ntiếng Việt. Kết quả thí nghiệm cho thấy khi NMF được kết hợp với ba loại đặc \r\ntrưng câu (đặc trưng bề mặt, đặc trưng độ liên quan, đặc trưng nội dung). Các phép \r\nđo Rouge-1 và Rouge-2 của hệ thống tăng 0.67% và 0.78% so với NMF cơ bản khi \r\nthử nghiệm trên bộ dữ liệu tiếng Anh và 1.34% và 1.2% khi thử nghiệm trên bộ dữ \r\nliệu tiếng Anh. \r\n\r\n\r\n\r\n\r\n Kết quả của chương này đã được viết thành bài báo Enhancing extractive \r\nsummarization using non-negative matrix factorization with semantic aspects and \r\nsentence features và đã được accept ở hội nghị SoIct 2017[1] \r\n \r\n \r\n\r\n\r\n\r\n\r\nCHƯƠNG 3 PHƯƠNG PHÁP TÓM TẮT VĂN BẢN SỬ DỤNG DEEP \r\nLEARNING \r\n\r\n \r\n3.1 Giới thiệu công nghệ học sâu \r\n \r\n\r\nTrong những năm qua, thuật ngữ \"deep learning\" (học sâu) đã dần len lỏi trong \r\ncác cuộc hội thảo khi bàn về trí tuệ nhân tạo (AI), dữ liệu lớn (Big Data) và phân \r\ntích (Analytics). Đây là một cách tiếp cận đầy hứa hẹn tới AI khi phát triển các hệ \r\nthống tự trị, tự học, những thứ đang cách mạng hóa nhiều ngành công nghiệp. \r\n\r\n \r\n\r\n \r\nNếu coi ta học máy (machine learning) là công nghệ tiên tiến nhất, thì học sâu \r\n\r\nlà \"tiên tiến của tiên tiến\". Học máy lấy một vài ý tưởng cốt lõi của trí tuệ nhân tạo \r\nvà tập trung vào việc giải quyết các vấn đề thế giới thực với các mạng thần kinh \r\nđược thiết kế để bắt chước khả năng đưa ra quyết định của chúng ta. Học sâu, đúng \r\nnhư tên gọi của nó, đi sâu hơn nữa vào một tập hợp các công cụ và kỹ thuật học \r\nmáy, từ đó áp dụng chúng để giải quyết bất kỳ vấn đề nào đòi hỏi \"khả năng tư duy\" \r\n con người hay nhân tạo. \r\n\r\nVề cơ bản, học sâu là cho một hệ thống máy tính \"ăn\" rất nhiều dữ liệu, để \r\nchúng có thể sử dụng và đưa ra các quyết định về những dữ liệu khác. Dữ liệu này \r\nđược nạp thông qua các mạng thần kinh, tương tự như học máy. Những mạng lưới \r\nnày  các cấu trúc logic yêu cầu một loạt các câu hỏi đúng/sai, hoặc trích xuất một \r\ngiá trị số, của mỗi bit dữ liệu đi qua chúng và phân loại theo các câu trả lời nhận \r\nđược. \r\n\r\nVì công việc của học sâu là tập trung phát triển những mạng lưới này, chúng \r\nđã trở thành \"mạng thần kinh sâu\" (Deep Neural Network)  những mạng logic \r\n\r\n\r\n\r\n\r\nphức tạp cần thiết để xử lý các bộ dữ liệu lớn, như thư viện hình ảnh của Google \r\nhay Instagram. \r\n\r\nVới các bộ dữ liệu toàn diện như vậy, và các mạng logic phức tạp để xử lý \r\nphân loại chúng, việc một chiếc máy tính lấy một hình ảnh và nhận dạng với độ \r\nchính xác cao trở nên \"quá đỗi bình thường\". \r\n\r\nCác hình ảnh là ví dụ tuyệt vời nhất về cách thức hoạt động của học sâu, vì \r\nchúng có chứa nhiều yếu tố khác nhau và để hiểu rõ được làm thế nào để máy tính, \r\nvới não bộ một chiều chủ yếu dựa trên sự tính toán, có thể học cách giải thích chúng \r\ngiống như con người. Tuy vậy, học sâu có thể được áp dụng cho bất kỳ hình thức \r\ndữ liệu nào  âm thanh, video, lời nói, chữ viết,...  để đưa ra những kết luận như \r\nthể do con người thực hiện với tốc độ rất nhanh. Chúng ta hãy thử xem xét một số \r\nví dụ thực tiễn. \r\n\r\nGiả sử một hệ thống được thiết kế để tự động ghi nhận và báo cáo có bao nhiêu \r\nchiếc xe của một mẫu xe nhất định đã đi ngang qua một con đường. Trước tiên, nó \r\nsẽ được quyền truy cập vào một cơ sở dữ liệu khổng lồ về các loại xe, bao gồm hình \r\ndáng, kích thước và thậm chí là tiếng của động cơ. Điều này có thể được biên soạn \r\ntheo cách thủ công hoặc, trong các điều kiện tiên tiến hơn, được thu thập tự động \r\nbởi hệ thống nếu như nó được lập trình để tìm kiếm trên internet và lấy dữ liệu mà \r\nnó tìm thấy ở đó. Tiếp theo, nó sẽ lấy dữ liệu cần được xử lý  dữ liệu trong thế giới \r\nthực có chứa thông tin chi tiết cần nắm bắt, trong trường hợp này là bởi các camera \r\nvà microphone bên đường. Bằng cách so sánh dữ liệu từ cảm biến với những dữ liệu \r\nmà nó đã \"học được\", nó có thể phân loại, với một độ chính xác nhất định, từng loại \r\nxe đã đi qua con đường đó. \r\n\r\nTrên đây là một ví dụ cụ thể, ngoài ra học sâu còn có thể ứng dụng ở trong rất \r\nnhiều các lĩnh vực khác như:  \r\n\r\n Cung cấp khả năng điều hướng cho xe tự lái: Với hệ thống cảm biến và phần \r\nmềm phân tích trên buồng lái, các xe tự lái có thể học cách nhận dạng những \r\nchướng ngại vật có trên đường và có giải pháp xử lý thích hợp bằng cách sử \r\ndụng học sâu. \r\n\r\n Phục chế màu cho ảnh đen trắng: thông qua việc dạy cho máy tính cách nhận \r\nbiết các vật thể và cách mà mắt người nhìn chúng, các hình ảnh và video đen \r\ntrắng sẽ có thể được tái hiện lại với đầy đủ các màu sắc phù hợp. \r\n\r\n Dự đoán kết quả của các thủ tục pháp lý: Một nhóm các nhà nghiên cứu \r\nngười Anh và Mỹ đã có thể dự đoán chính xác kết quả của một phiên tòa, sau \r\nkhi hệ thống máy tính của họ được nạp sẵn những thông tin cơ bản của vụ \r\nán. \r\n\r\n Thuốc đặc trị: Các kỹ thuật học sâu hiện đang được dùng để phát triển các \r\nloại thuốc đã được chỉnh sửa sao cho phù hợp với bộ gen của bệnh nhân. \r\n\r\n\r\n\r\n\r\n Phân tích và báo cáo tự động: Các hệ thống có thể phân tích dữ liệu và báo \r\ncáo những thông tin chi tiết của chúng dưới dạng âm thanh tự nhiên hoặc \r\nngôn ngữ của con người. \r\n\r\n Chơi trò chơi: Các hệ thống học sâu đã và đang được dạy cách chơi (và \r\ngiành chiến thắng) các trò chơi như cờ vây, Breakout của Atari hay Starcraft. \r\n\r\n \r\n3.2  Cơ sở lý thuyết \r\n \r\n3.2.1 Mạng neural nhân tạo (Artificial neural network) \r\n\r\n Mạng Nơron nhân tạo (Artificial Neural Network- ANN) là mô hình xử lý \r\nthông tin được mô phỏng dựa trên hoạt động của hệ thống thần kinh của sinh vật, \r\nbao gồm số lượng lớn các Nơron được gắn kết để xử lý thông tin. ANN giống như \r\nbộ não con người, được học bởi kinh nghiệm (thông qua huấn luyện), có khả năng \r\nlưu giữ những kinh nghiệm hiểu biết (tri thức) và sử dụng những tri thức đó trong \r\nviệc dự đoán các dữ liệu chưa biết (unseen data). \r\n Kiến trúc chung của một mạng nơron nhân tạo (ANN) gồm 3 thành phần đó \r\nlà: Input Layer, Hidden Layer và Output Layer (Xem Trong đó, lớp ẩn (Hidden Layer) gồm các Nơron nhận dữ liệu input từ các Nơron ở \r\nlớp (Layer) trước đó và chuyển đổi các input này cho các lớp xử lý tiếp theo. Trong \r\nmột ANN có thể có nhiều lớp ẩn. \r\n \r\n\r\n \r\n\r\n \r\n\r\n\r\n\r\n\r\nTrong đó các Processing Elements (PE) của ANN gọi là Nơron, mỗi \r\nNơron nhận các dữ liệu vào (Inputs) xử lý chúng và cho ra một kết quả (Output) \r\nduy nhất. Kết quả xử lý của một Nơron có thể làm Input cho các Nơron khác. \r\n- Quá trình xử lý thông tin của một ANN: \r\n\r\n \r\n\r\n \r\n+ Inputs (dữ liệu vào): Mỗi Input tương ứng với 1 thuộc tính (attribute) của dữ liệu \r\n(patterns). Trong các mô hình mạng neural hiện tại x thường là một vecto được \r\nembedding từ dữ liệu đầu vào. \r\n+ Output (kết quả): Kết quả của một ANN là một giải pháp cho một vấn đề. \r\n+ Connection Weights (Trọng số liên kết): Đây là thành phần rất quan trọng của \r\nmột ANN, nó thể hiện mức độ quan trọng (độ mạnh) của dữ liệu đầu vào đối với \r\nquá trình xử lý thông tin (quá trình chuyển đổi dữ liệu từ Layer này sang layer \r\nkhác). Quá trình học (Learning Processing) của ANN thực ra là quá trình điều chỉnh \r\ncác trọng số (Weight) của các input data để có được kết quả mong muốn.  \r\n+ Summation Function (Hàm tổng): Tính tổng trọng số của tất cả các input được \r\nđưa vào mỗi Nơron (phần tử xử lý PE). Hàm tổng của một Nơron đối với n input \r\nđược tính theo công thức sau: \r\n\r\n! = \t $%&%\r\n'\r\n\r\n%()\r\n \r\n \r\n\r\n  \r\n+ Transfer Function (Hàm chuyển đổi): Hàm tổng (Summation Function) hay còn \r\ngọi là Activate Function của một Nơron cho biết khả năng kích hoạt (Activation) \r\ncủa Nơron đó còn gọi là kích hoạt bên trong (internal activation). Các Nơron này có \r\nthể sinh ra một output hoặc không trong ANN (nói cách khác rằng có thể output của \r\n1 Nơron có thể được chuyển đến layer tiếp trong mạng Nơron hoặc không). Mối \r\nquan hệ giữa Internal Activation và kết quả (output) được thể hiện bằng hàm \r\nchuyển đổi (Transfer Function).  \r\n\r\n\r\n\r\n\r\n \r\n+ Việc lựa chọn Transfer Function có tác động lớn đến kết quả của ANN. Một số \r\nhàm chuyển đổi phi tuyến hay được sử dụng trong ANN:  \r\n\r\n Linear g(a) = a \r\n\r\n Sigmoid g(a) = sigm(a) = \r\n!\r\n\r\n!\"\t$%&(-))   \r\n\r\n Tanh g(a) = tanh(a) = \r\n!\"# $ -\t'()\t(-$)\r\n!\"# $ ,\t!\"#(-$)    \r\n\r\n Rectified Linear g(a) = recline(a) = max (0, a)  \r\n Step \r\n Gaussian \r\n Softmax (hàm này rất hay được sử dụng ở layer cuối cùng) \r\n\r\n \r\nKết quả xử lý tại các Nơron (Output) đôi khi rất lớn, vì vậy transfer function \r\n\r\nđược sử dụng để xử lý output này trước khi chuyển đến layer tiếp theo. Đôi khi thay \r\nvì sử dụng Transfer Function người ta sử dụng giá trị ngưỡng (Threshold value) để \r\nkiểm soát các output của các Nơron tại một layer nào đó trước khi chuyển các \r\noutput này đến các Layer tiếp theo. Nếu output của một nơron nào đó nhỏ hơn giá \r\ntrị ngưỡng thì nó sẽ không được chuyển đến Layer tiếp theo. \r\n\r\nTrên kia là kiến trúc mạng ANN cơ bản. Để phục vụ những bài toán phức tạp ta \r\ncũng cần những kiến trúc mạng phức tạp hơn. Một số kiến trức mạng phổ biến hiện \r\nnay như:  \r\n\r\n Deep Neural Network (DNN) \r\n Deep Belief Network (DBN) \r\n Deep Boltzmann Machine (DBM) \r\n Recurrent Neural Network (RNN) \r\n Convolution Neural Network (CNN) \r\n Multi-modal/multi-tasking \r\n Deep Stacking Network (DSN)  \r\n\r\nTrong các kiến trúc trên em lựa chọn RNN cho bài toán tóm tắt văn bản, do các đặc \r\ntrưng đặc thù về chuỗi RNN phù hợp với các bài toán về xử lý ngôn ngữ tự nhiên sẽ \r\nđược nói rõ hơn ở phần 3.2.2 \r\n \r\n3.2.2 Giới thiệu mạng neural hồi quy RNN \r\n\r\nMô hình mạng neural hồi quy RNN là mô hình được áp dụng rất rộng rãi \r\ntrong các bài toán xử lý ngôn ngữ tự nhiên (NLP). Do mô hình RNN mô hình hoá \r\nđược bản chất dữ liệu trong NLP. Dữ liệu trong NLP có đặc tính chuỗi và có sự phụ \r\nthuộc lẫn nhau giữa các thành phần (trạng thái) trong dữ liệu. Năng lực tính toán \r\n\r\n\r\n\r\n\r\ncủa máy tính ngày càng mạnh nên đã thực hiện thực hoá được việc huấn luyện \r\nmạng neural hồi quy vốn yêu cầu nhiều bước tính toán hơn mạng neural thông \r\nthường. Việc áp dụng RNN có thể được coi là một bước đột phá trong NLP. \r\n\r\nÝ tưởng đằng sau RNN là sử dụng thông tin dạng chuỗi. Trong một mạng \r\nneural truyền thống chúng ta giả định rằng tất cả các đầu vào đều độc lập với nhau, \r\nnhưng mô hình này không phù hợp trong nhiều bài toán. Ví dụ nếu muốn đoán từ \r\ntiếp theo có thể xuất hiện trong một câu thì ta cũng cần biết các từ trước đố xuất \r\nhiện lần lượt thế nào? RNN được gọi là hồi quy bởi lẽ chúng thực hiện cùng một tác \r\nvụ cho tất cả các phần tửu của một chuỗi với đầu ra phụ thuộc vào cả các phép tính \r\ntrước đó. Nói các khác, RNN có khả năng nhớ các thông tin được tính toán trước \r\nđó. Trên lý thuyết RNN có thể sử dụng được thông tin của một văn bản rất dài, tuy \r\nnhiên thực tế thì nó chỉ có thể nhớ được một vài bước trước đó mà thôi. Về cơ bản \r\nmột mạng RNN sau khi phân tích ra sẽ có dạng như sau:  \r\n\r\n         \r\n\r\n \r\n Mô hình trên mô tả phép triển khai nội dung của một RNN. Triển khai ở đây \r\ncó thể hiểu đơn gỉản là ta vẽ ra một mạng nơ-ron chuỗi tuần tự. Ví dụ ta có một câu \r\ngồm 5 chữ Tôi yêu quê hương tôi, thì mạng nơ-ron được triển khai sẽ gồm 5 tầng \r\nnơ-ron tương ứng với mỗi chữ một tầng. Lúc đó việc tính toán bên trong RNN được \r\nthực hiện như sau: \r\n\r\n !\"   là đầu vào tại bước t. Ví dụ !\"   là một vec-tơ one-hot tương ứng với \r\ntừ thứ 2 của câu (yêu). \r\n\r\n !\"   là trạng thái ẩn tại bước t. Nó chính là bộ nhớ của mạng. !\"   được \r\ntính toán dựa trên cả các trạng thái ẩn phía trước và đầu vào tại bước \r\nđó: !\" = \t%('(\"   + !\"#$%  ) . Hàm f  thường là một hàm phi tuyến như \r\ntang, sigmoid hay ReLu. Để làm phép toán cho phần tử ẩn đầu tiên ta \r\ncần khởi tạo them !\"#  , thường giá trị khởi tạo được gắn bằng 0. \r\n\r\n\r\n\r\n\r\n !\"   là đầu ra tại bước t, Ví dụ, ta muốn dự đoán từ tiếp theo có thể xuất \r\nhiện trong câu thì !\"   chính là một vec-tơ xác xuất các từ trong danh \r\nsách từ vựng của ta: !\" = \t%!&'()*(,%\")    \r\n\r\n Vector đầu ra !\"   sẽ được sử dụng cho những dự đoán tiếp theo như dự \r\nđoán sentiment của một câu hay dự đáon từ loại của từng từ vựng \r\ntrong câu (PoS Tagging) \r\n\r\nViệc huấn luyện mạng neural hồi quy được thực hiện qua 2 bước:  \r\n Duỗi thẳng mạng neural hồi quy \r\n Sử dụng thuật toán backpropagation để tính đạo hàm một phần \r\n\r\n(gradient) của hàm mất mát ( giống như mạng neural thông thường ).  \r\n \r\n\r\nMột điểm nổi bật của RNN chính là ý tưởng kết nối các thông tin phía trước \r\nđể dự đoán cho hiện tại. Việc này tương tự như ta sử dụng các cảnh trước của bộ \r\nphim để hiểu được cảnh hiện thời. Đôi lúc ta chỉ cần xem lại thông tin vừa có thôi là \r\nđủ để biết được tình huống hiện tại. Ví dụ, ta có câu: Các đám mây trên bầu trời \r\nthì ta chỉ cần đọc tới các đám mây trên bầu là đủ biết được chữ tiếp theo là trời \r\nrồi. Trong tình huống này, khoảng cách tới thông tin có được cần để dự đoán là nhỏ, \r\nnên RNN hoàn toàn có thể học được. Nhưng trong nhiều tình huống ta buộc phải sử \r\ndụng nhiều ngữ cảnh hơn để suy luận. Ví dụ dự đoán chữ cuối cùng trong đoạn : I \r\ngrew up in France. I speak fluent French.. Rõ ràng là các thông tin gần (I speak \r\nfluent) chỉ có phép ta biết được đằng sau nó sẽ là tên của một ngôn ngữ nào đó, \r\ncòn không thể nào biết được đó là tiếng gì. Muốn biết là tiếng gì, thì ta cần phải có \r\nthêm ngữ cảnh I grew up in France nữa mới có thể suy luận được. Rõ ràng là \r\nkhoảng cách thông tin lúc này có thể đã khá xa rồi. \r\n\r\n \r\n    \r\nVề mặt lý thuyết, rõ ràng là RNN có khả năng xử lý các phụ thuộc xa (long-\r\nterm dependencies). Chúng ta có thể xem xét và cài đặt các tham số sao cho khéo là \r\ncó thể giải quyết được vấn đề này. Tuy nhiên, đáng tiếc trong thực tế RNN có vẻ \r\nkhông thể học được các tham số đó. Vấn đề này đã được khám phá khá sâu bởi \r\n\r\n\r\n\r\n\r\nHochreiter (1991) và Bengio, et al.(1994) trong các bài báo của mình, họ đã tìm \r\nđược nhưng lý do căn bản để giải thích tại sao RNN không thể học được. \r\n \r\n3.2.3 Mạng LSTM \r\n\r\nMạng bộ nhớ dài-ngắn (Long Short Term Memory networks), thường được \r\ngọi là LSTM - là một dạng đặc biệt của RNN, nó có khả năng học được các phụ \r\nthuộc xa. LSTM được giới thiệu bởi Hochreiter và Schmidhuber (1997), và sau đó \r\nđã được cải tiến và phổ biến bởi rất nhiều người trong ngành. Chúng hoạt động cực \r\nkì hiệu quả trên nhiều bài toán khác nhau nên dần đã trở nên phổ biến như hiện nay. \r\nLSTM được thiết kế để tránh được vấn đề phụ thuộc xa (long-term dependency). \r\nViệc nhớ thông tin trong suốt thời gian dài là đặc tính mặc định của chúng, chứ ta \r\nkhông cần phải huấn luyện nó để có thể nhớ được. Tức là ngay nội tại của nó đã có \r\nthể ghi nhớ được mà không cần bất kì can thiệp nào. \r\nMọi mạng hồi quy đều có dạng là một chuỗi các mô-đun lặp đi lặp lại của mạng nơ-\r\nron. Với mạng RNN chuẩn, các mô-dun này có cấu trúc rất đơn giản, thường là một \r\ntầng tanh. \r\n \r\n\r\n \r\n \r\nLSTM cũng có kiến trúc dạng chuỗi như vậy, nhưng các mô-đun trong nó có \r\ncấu trúc khác với mạng RNN chuẩn. Thay vì chỉ có một tầng mạng nơ-ron, chúng \r\ncó tới 4 tầng tương tác với nhau một cách rất đặc biệt. \r\n \r\n\r\n\r\n\r\n\r\n \r\n\r\n \r\nBước đầu tiên của LSTM là quyết định xem thông tin nào cần bỏ đi từ trạng \r\n\r\nthái tế bào. Quyết định này được đưa ra bởi tầng sigmoid - gọi là tầng cổng quên \r\n(forget gate layer). Nó sẽ lấy đầu vào là \"#$   và !\"   rồi đưa ra kết quả là một số \r\ntrong khoảng [0,1] cho mỗi số trong trạng thái tế bào !\"#$  . Đẩu ra là 1 thể hiện \r\nrằng nó giữ toàn bộ thông tin lại, còn 0 chỉ rằng toàn bộ thông tin sẽ bị bỏ đi. \r\n\r\nQuay trở lại với ví dụ mô hình ngôn ngữ dự đoán từ tiếp theo dựa trên tất cả \r\ncác từ trước đó, với những bài toán như vậy, thì trạng thái tế bào có thể sẽ mang \r\nthông tin về giới tính của một nhân vật nào đó giúp ta sử dụng được đại từ nhân \r\nxưng chuẩn xác. Tuy nhiên, khi đề cập tới một người khác thì ta sẽ không muốn \r\nnhớ tới giới tính của nhân vật nữa, vì nó không còn tác dụng gì với chủ thế mới này. \r\n\r\n \r\n\r\n \r\n\r\n \r\nBước tiếp theo là quyết định xem thông tin mới nào ta sẽ lưu vào trạng thái \r\n\r\ntế bào. Việc này gồm 2 phần. Đầu tiên là sử dụng một tầng sigmoid được gọi là \r\ntầng cổng vào (input gate layer) để quyết định giá trị nào ta sẽ cập nhập. Tiếp \r\ntheo là một tầng tanh tạo ra một véc-tơ cho giá trị mới !\"   nhằm thêm vào cho trạng \r\nthái. Trong bước tiếp theo, ta sẽ kết hợp 2 giá trị đó lại để tạo ra một cập nhập cho \r\ntrạng thái. \r\n\r\n\r\n\r\n\r\nChẳng hạn với ví dụ mô hình ngôn ngữ của ta, ta sẽ muốn thêm giới tính của nhân \r\nvật mới này vào trạng thái tế bào và thay thế giới tính của nhân vật trước đó. \r\n \r\n\r\n \r\n\r\nGiờ là lúc cập nhập trạng thái tế bào cũ !\"#$  thành trạng thái mới !\"   . Ở các \r\nbước trước đó đã quyết định những việc cần làm, nên giờ ta chỉ cần thực hiện là \r\nxong. \r\nTa sẽ nhân trạng thái cũ với !\"\t  để bỏ đi những thông tin ta quyết định quên lúc \r\ntrước. Sau đó cộng thêm !\"*$\"\t.\t  Trạng thái mơi thu được này phụ thuộc vào việc ta \r\nquyết định cập nhập mỗi giá trị trạng thái ra sao. \r\n\r\nVới bài toàn mô hình ngôn ngữ, chính là việc ta bỏ đi thông tin về giới tính \r\ncủa nhân vật cũ, và thêm thông tin về giới tính của nhân vật mới như ta đã quyết \r\nđịnh ở các bước trước đó. \r\n\r\n \r\n\r\n \r\nCuối cùng, ta cần quyết định xem ta muốn đầu ra là gì. Giá trị đầu ra sẽ dựa \r\n\r\nvào trạng thái tế bào, nhưng sẽ được tiếp tục sàng lọc. Đầu tiên, ta chạy một tầng \r\nsigmoid để quyết định phần nào của trạng thái tế bào ta muốn xuất ra. Sau đó, ta \r\nđưa nó trạng thái tế bảo qua một hàm tanh để co giá trị nó về khoảng [1,1], và \r\nnhân nó với đầu ra của cổng sigmoid để được giá trị đầu ra ta mong muốn. \r\n\r\nVới ví dụ về mô hình ngôn ngữ, chỉ cần xem chủ thể mà ta có thể đưa ra \r\nthông tin về một trạng từ đi sau đó. Ví dụ, nếu đầu ra của chủ thể là số ít hoặc số \r\nnhiều thì ta có thể biết được dạng của trạng từ đi theo sau nó phải như thế nào. \r\n\r\n\r\n\r\n\r\n \r\n\r\n \r\n \r\n\r\n3.2.4 Mô hình sequence to sequence \r\n\r\nMạng RNN được sử dụng như một mô hình ngôn ngữ để dự đoán các phần \r\ntử trong tương lai của chuỗi được cho trước. Tuy nhiên chúng ta vẫn thiếu các thành \r\nphần cần thiết để xây dựng các mô hình dịch bởi vì chúng ta mới chỉ xử lý trên một \r\nchuỗi duy nhất trong khi bản dịch cần phải xử lý trên cả 2 dãy chuỗi nhập và chuỗi \r\ndịch. \r\n Mô hình sequence to sequence được xây dựng bằng việc thêm một bước mã \r\nhoá (encoder) và một bước giải mã (decoder). Ở bước encoder mô hình sẽ chuyển \r\nđổi chuỗi đầu vào thành một biểu diễn cố định. Trong bước decoder, một mô hình \r\nngôn ngữ sẽ học từ cả chuỗi đầu ra (ví dụ như câu văn đã được dịch) và chuỗi biểu \r\ndiễn cố định sinh ra từ bước mã hoá. Do mô hình decoder nhìn thấy cả chuỗi biểu \r\ndiễn cố định sinh ra từ chuỗi đầu lẫn chuỗi dịch, nên nó có thể sinh ra những dự \r\nđoán thông minh hơn về các từ tương lai dựa trên từ hiện tại. Ví dụ, trong mô hình \r\nngôn ngữ cơ bản, chúng ta gặp từ đi nhưng không thể chắc rằng từ đó đang nói về \r\nmột hành động của con người là đi lại hay đang ám chỉ một người đã ra đi (đã chết). \r\nTuy nhiên nếu chúng được cho qua một ngữ cảnh mã hoá, lớp giải mã có nhận ra \r\nrằng chuỗi đầu vào đang ám chỉ việc người đã mất chứ không phải ám chỉ hành \r\nđộng đi lại. Với ngữ cảnh, bộ decoder có thể chọn từ kế tiếp thích hợp và cung cấp \r\nbản dịch chính xác hơn.  \r\n Bây giờ chúng ta cần phải hiểu cách thức hoạt động cơ bản của mô hình \r\nsequence to sequence, chúng ta sẽ nhắc lại về cách xây dựng một mô hình mạng \r\nneural cơ bản. Ở bước mã hoá (encoder) chúng ta sẽ sử dụng một mạng RNN. Mạng \r\nRNN này sẽ xử lý chuỗi đầu vào, sau đó sẽ chuyền đầu ra cho lớp giải mã (decoder) \r\nnhư là một biến ngữ cảnh. Lớp giải mã cũng là một mạng RNN. Nó có nhiệm vụ \r\nxem chuỗi đầu vào đã được dịch và từ đứng trước đó sau đó cố gắng dự đoán từ tiếp \r\ntheo trong chuỗi giải mã. Sau khi huấn luyện chúng ta có thể tạo ra bản dịch bằng \r\ncách mã hoá chuỗi đầu vào chúng ta muốn dịch và sau đó chạy mạng sinh chuỗi. \r\nMô hình mạng sequence to sequence được miêu tả như hình dưới:  \r\n\r\n\r\n\r\n\r\n \r\n\r\n \r\n\r\n  \r\n3.2.5 Kĩ thuật attention \r\n\r\nHãy bắt đầu với khái niệm chú ý (attention) trong thế giới thực. Mỗi ngày, \r\ncon người tiếp nhận rất nhiều dữ kiện đầu vào. Thật ngạc nhiên bộ não của chúng ta \r\ncó thể làm giảm lượng lớn dữ kiện đó đó thành những thông tin hữu dụng từ đó \r\nchúng ta có đưa ra các quyết định. Những nghiên cứu gần đây chỉ ra rằng các quy \r\ntrình tương tự được áp dụng trong mô hình mạng neural cho phép chúng ta tập trung \r\nvào những thông tin quan trọng trong khi có thể lọc được những dữ liệu không cần \r\nthiết. Kĩ thuật này được gọi là attention, nó giúp chúng ta xây dựng các mạng \r\nneural có thể giải quyết hiệu quả các thách thức trước đây với bài toán xử lý chuỗi \r\nnhư là dịch máy hay tóm tắt văn bản điều mà mô hình sequence to sequence bình \r\nthường không thực hiện được. \r\n\r\nMô hình sequence to sequence cho chúng ta khả năng xử lý các chuỗi đầu \r\nvào và đầu ra. Nhưng việc nén toàn bộ chuỗi đầu vào vào một vecto cố định duy \r\nnhất là khá khó khăn. Hơn nữa trạng thái cuối cùng của bộ mã hoá chưa phần lớn \r\nthông tin từ những phần tử cuối cùng của chuỗi mã hoá. Do đó nó có phần thiện vị \r\nvề phía cuối của chuỗi mã hoá và có thể bỏ lỡ mất những thông tin quan trọng ở \r\nphần đầu của chuỗi. \r\n\r\nThay vì nén toàn bộ chuỗi đầu vào thành một vectơ ngữ cảnh cố định chúng \r\nta có thể sử dụng kĩ thuật attention. Kĩ thuật này sẽ lưu giữ toàn bộ các trạng thái từ \r\nphần mã hoá và đưa cho từng phần tử của bộ giải mã giá trị trọng số trung bình của \r\ncác trạng thái mã hoá.  Ban đầu tất cả các trạng cuối cùng của chuỗi mã hoá đầu vào \r\nđều được giữ lại. Trong suốt quá trình giải mã chúng ta sẽ lấy trạng thái của mạng \r\n\r\n\r\n\r\n\r\ngiải mã kết hợp với trạng thái của bộ mã hoá và chuyền vào mạng feedforward. \r\nMạng này sẽ trả về danh sách các trọng số cho từng trạng thái encoder. Chúng ta sẽ \r\nnhân encoder input với các trọng số sau đó tính trung bình có trọng số của các \r\nencoder states. Kết quả ngữ cảnh này sau đó sẽ được chuyền đến lớp giải mã. Mạng \r\ndecoder của chúng ta bây giờ có thể sử dụng các phần khác nhau của chuỗi giải mã \r\ntrong quá trình sinh chuỗi decoder thay vì chỉ sử dụng một vecto ngữ cảnh cố định. \r\nĐiều này cho phép mạng tập trung vào những phần quan trọng nhất của chuỗi đầu \r\nvào thay vì toàn bộ chuỗi đầu vào, do đó tạo ra các dự đoán thông minh hơn cho từ \r\ntiếp theo trong chuỗi giải mã. Hình dưới sẽ mô tả cụ thể kĩ thuật này:  \r\n\r\n \r\n\r\n \r\n3.2.6 WordEmbedding \r\n\r\nWordEmbedding là một trong những phương diện nghiên cứu thú vị nhất của \r\nphương pháp học sâu trong xử lý ngôn ngữ tự nhiên. Một WordEmbedding là một \r\nhàm ánh xạ từ thành các vec-tơ nhiều chiều (200 đến 500 chiều). Ví dụ như: \r\n\r\nW(cat) = (0.2, -0.4, 0.7,.) \r\nW(mat) = (0.0, 0.6, -0.1,.) \r\n\r\n Thường thì hàm này sẽ là một bảng tra cứu, lưu trữ dưới dạng một ma trận , \r\nvới W(wn) = n . Các vec-tơ trong Word Embedding có các tính chất sau: \r\n\r\n Số lượng chiều không lớn (so với tập từ vựng) \r\n Các từ có chung nét ngữ nghĩa sẽ được về gần nhau trong không gian \r\n Mối quan hệ tương đồng ngữ nghĩa được chuyển thành mối quan hệ \r\n\r\ngiống nhau giữa các vec-tơ. \r\n \r\n\r\n\r\n\r\n\r\n \r\nTrong bài toán này em lựa Word2Vec là phương pháp cho bài khối \r\n\r\nWordEmbedding.Word2Vec là một phương pháp cụ thể của bài toán \r\nWordEmbedding. Không sử dụng một tác vụ để kiểm tra một cụm \"5-gram\" có hợp \r\nlệ hay không. Word2vec lựa chọn việc huấn luyện ra một mạng nơ-ron cho phép dự \r\nđoán từ (hoặc các từ) từ các từ lân cận cho trước (có thể gồm nhiều hoặc một từ) và \r\nngược lại. \r\n Về khối kết cấu, Word2Vec là 1 mạng nơ-ron cạn gồm 1 lớp ẩn. Có 2 kiến \r\ntrúc là hội tụ và phân kì từ xung quanh để tạo ra mô hình Word2vec là CBOW và \r\nSkip-gram. Ngoài ra, thực tế còn có các phương pháp cải tiến nhằm tối ưu hóa hiệu \r\nquả tính toán \r\n Một cách tổng quát về Word2Vec: \r\n\r\n Biểu diễn phân tán cho từ \r\n Học ra một vec-tơ giá trị thực (real-valued vector) cho  từng từ \r\n Đưa những từ có ý nghĩa giống nhau về gần nhau \r\n Một ứng dụng đơn giản của của mạng nơ-ron 2 lớp \r\n\r\n \r\n3.3 Các vấn đề của mô hình sequence to sequence và kĩ thuật attention \r\n\r\n Mạng RNN cơ bản chỉ đi theo một chiều duy nhất là từ đầu chuối đến cuối \r\nchuỗi. Ví dụ để dự đoán từ còn thiếu trong câu thì việc không thể chỉ xem xét \r\nphần trước mà phải xem xét cả các phần tử đứng đằng sau.  \r\n\r\n Kích thước tập từ điển rất lớn, nhất là khi dữ liệu train ngày càng tăng lên \r\nđến vài triệu bản. Việc chọn kích thước tập từ điển ảnh hưởng rất nhiều đến \r\nhiệu năng của mạng hơn nữa. Chọn kích thước quá lớn thì làm tăng thời gian \r\nhuấn luyện mạng lên rất nhiều, quá nhỏ thì lại không đủ độ chính xác cho bài \r\ntoán. Việc chọn những từ nào xuất hiện trong từ điển cũng là một bài toán \r\nnan giải. Số lượng trọng số trong mạng gần như tăng tuyến tính theo kích \r\nthước của tập từ điển (và \r\n Trong quá trình huấn luyện những từ nằm ngoài từ điển sẽ bị dán nhãn \r\n<unk> và nếu chỉ dùng mạng RNN đơn thuần thì chuỗi đầu ra sau khi sinh sẽ \r\nbị mất mát thông tin. Đôi khi những từ xuất hiện ít trong tập dữ liệu nhưng \r\nlại mang nhiều thông tin quan trọng như tên riêng, thời gian,.  \r\n\r\n Khác biệt lớn nhất giữa quá trình huấn luyện và dự đoán là việc dự đoán kí \r\ntự !\"   . Trong quá trình huấn luyện !\"\t  sẽ được sinh ra từ việc kết hợp với kí tự \r\n\r\nđứng trước nó là !\"#$   còn trong quá trình suy luận là từ kí tự !\"#$   được suy \r\n\r\nra từ mô hình. Mạng RNN (hay các biến thể như LSTM) thường được huấn \r\n\r\n\r\n\r\n\r\nluyện để tối đa hoá khả năng tạo ra các chuỗi đích từ chuỗi đầu vào, vì thế \r\nmô hình có thể sinh ra những dự đoán tồi do gặp phải những không gian mà \r\nnó chưa bao giờ nhìn thấy. \r\n\r\n Một vấn đề nữa ở kĩ thuật attention cơ bản đó là việc tính toán ngữ cảnh \r\ncũng như tính toán trọng số đều dùng chung một lớp ẩn đầu vào. Việc này sẽ \r\nlàm cho các trọng số không thể hiện được hoàn toàn vai trò của từng kí tự \r\ntrong chuỗi đầu vào. \r\n\r\n \r\n\r\n\r\n\r\n\r\n \r\n\r\n \r\n \r\n3.4 Mô hình đề xuất \r\n Lấy cảm hứng từ mô hình rất thành công trong mô hình dịch máy, em đã kết \r\nhợp mô hình mạng ngôn ngữ với một mô hình mã hoá ngữ cảnh. Hơn nữa bản chất \r\nmô hình sequence to sequence được cấu thành từ mạng RNN, mô hình mạng này rất \r\nphù hợp cho các bài toán về xử lý chuỗi tuần tự, có khả năng lưu trữ thông tin của \r\ntoàn bộ chuỗi đầu vào. Bộ mã hoá được áp dụng thêm kĩ thuật attention, kĩ thuật \r\nnày sẽ giúp tìm kiếm những sự liên kết tiềm ẩn trong văn bản đầu vào, giúp hệ \r\nthống có thể tập trung vào những dữ kiện quan trọng như tên riêng, số, .. qua đó \r\ngiúp giảm lượng thông tin cần ghi nhớ. Và để giải quyết một số vấn đề của mô hình \r\nattention encoder decoder như đã đề cập ở phần trên trong phần này cũng đề xuất \r\nmột số giải pháp để cải tiến chất lượng mô hình. \r\n\r\n\r\n\r\n\r\n \r\n\r\n \r\n\r\n3.4.1 Khối tiền xử lí dữ liệu \r\nDo muốn máy có thể học cách sử dụng ngôn ngữ như con người nên phần \r\n\r\nlowercase và loại bỏ các dấu câu như : ! ? , được bỏ qua. Chỉ sử dụng tách từ và \r\ntách câu sử dụng 2 công cụ giống như đã nêu ở phần 0  \r\n Từ điển được sử dụng trong mô hình có kích thước 40000 từ. Lớp mã hoá từ \r\ntoken từ sang vecto embedding có số chiều là 400. Để phục vụ cho các tác vụ phía \r\nsau từ điển cũng như các từ ngoài từ điển được sắp xếp theo thứ tự về số lần xuất \r\nhiện của chúng trong văn bản. Sau khi xử lý xong thì ta thu được tập từ có số lượng \r\nrất lớn lên đến 350 nghìn từ. 40000 từ có số lần xuất hiện nhiều nhất sẽ được chọn \r\nvào trong tập từ điển và được thay đổi theo từng batch-size. Ta cũng quy ước 2 kí tự \r\nđặc biệt empty và eos (kí tự báo hiệu kết thúc câu) là 2 kí tự đầu tiên trong từ điển. \r\n\r\n\r\n\r\n\r\n    \r\n\r\n \r\n  Vấn đề tiếp theo cần phải giải quyết đó là xử lý những từ nằm trong tập từ \r\nđiển của embedding nhưng lại không có trong tập từ điển của dữ liệu chúng ta. Đối \r\nvới những từ này ta sẽ tính giá trị trung bình của toàn bộ trọng số ebedding hiện tại \r\ngọi là scale, sau đó sinh vecto 400 chiều ngẫu nhiên tương ứng trong khoảng từ -\r\nscale đến scale. \r\n Ở bước tiền xử lý này chúng ta cũng lưu trữ tập các từ nằm ngoài từ điển \r\nnhưng có độ tương đồng cao với các từ có trong tập từ điển. Trong mô hình này em \r\nđề xuất ngưỡng tương đồng là 0.5 \r\n\r\n \r\n\r\n \r\n\r\n\r\n\r\n\r\n \r\n\r\n \r\n\r\n  \r\n\r\n3.4.2 Khối huấn luyện mô hình encoder-decoder \r\n \r\n Chúng ta sử dụng kiến trúc encoder-decoder như đã miêu tả ở phần 3.2.4. \r\nKiến trúc này gồm 2 phần bộ mã hoá (encoder) và bộ giải mã (decoder) . Cả 2 phần \r\nđều là các mạng RNN. \r\n \r\n\r\n  \r\n \r\n\r\n  \r\n Bộ mã hoá sẽ truyền vào từng từ một trong văn bản đầu vào. Mỗi từ sau đó \r\nsẽ được đi qua một lớp embedding để biểu diễn từ đó về dạng vecto số, trong bài \r\ntoán này em sử dụng embedding là w2v 400 chiều trên tập dữ liệu Báo Mới). Vecto \r\nnày sau đó sẽ được đi qua các lớp ẩn, ở mỗi lớp nó lại được kết hợp với những lớp \r\nẩn được sinh ra từ token phía trước, đối với từ đầu tiên thì tất cả các giá trị này đều \r\nbằng 0.  \r\n\r\n\r\n\r\n\r\n Bộ giải mã sẽ nhận layer ẩn cuối cùng của bộ mã hoá kết hợp với token \r\n<eos> (kí tự kết thúc câu) là đầu vào. Sau đó bộ giải mã sẽ sinh từng từ một sử dụng \r\nlớp softmax và kĩ thuật attention. Bộ giải mã sẽ dừng lại khi sinh đến kí tự <eos>.  \r\n Hàm mất mát em sử dụng trong bài toán là hàm log loss: \r\n \r\n\r\n-\"#$\t& '(, . . . , ',' .(, .. . . , ., = \t -\t \"#$\t& '0 '(, .. . . , '0-(, .(, . . .,\r\n,'\r\n\r\n01(\r\n \r\n \r\n\r\n \r\nTrong đó: \r\n\r\n x là chuỗi đầu vào  \r\n y là chuỗi đầu ra \r\nỞ đây xảy ra vấn đề mất kết nối giữa quá trình huấn luyện và kiểm thử khi \r\n\r\nmà trong quá trình giải mã ở huấn luyện từ tiếp theo được sinh ra sau khi truyền \r\nvào từ đứng trước nó trong headline gốc còn ở quá trình kiểm thử là từ được \r\nsinh ra từ mô hình. Để giải quyết vấn đề này em sử dụng kĩ thuật flip. Ta sẽ úp \r\nngẫu nhiên một số từ ở phần headline và thay nó bằng từ được dự đoán từ mô \r\nhình hiện tại. Tuy nhiên ở giai đoạn đầu huấn luyện mô hình chưa được tốt nên \r\nviệc này có thể làm chậm lại quá trình huấn luyện, nên kĩ thuật này sẽ được sử \r\ndụng sau khi mô hình đã tương đối tốt. Trong suốt quá trình kiểm thử chúng ta \r\nsử dụng giải thuật beam-search khi sinh từ một, ở mỗi bước sẽ sinh ra 10 chuỗi \r\ncó xác suất cao nhất. \r\n\r\n \r\nTrong quá trình xử lý dữ liệu đầu vào, có những từ ít xuất hiện nằm ngoài \r\n\r\nvocab sẽ bị dán nhãn <unk>, điều này làm có thể dẫn đến làm mất mát nhiều \r\nthông tin quan trọng. Trong mô hình này em xử lý vấn đề này bằng 2 cách. Nếu \r\ngặp phải một từ nằm ngoài tập từ điển đầu tiên sẽ kiểm tra xem nó có nằm trong \r\ntập các từ có độ tương đồng cao (đã được nêu trong phần 3.4.1) với các từ có \r\ntrong từ điển hay không, nếu có ta sẽ chọn từ có độ tương đồng cao nhất. Nếu \r\nkhông nằm trong tập này sẽ kiểm tra phân loại và gán nhãn cho từ này vào các \r\nthẻ <time> nếu token đó là định dạng thời gian, <url> nếu token là các đường \r\ndẫn, các trường hợp còn lại (hầu hết là tên riêng) được gán vào nhãn <oov>. Sau \r\nquá trình giải mã nếu trong mã giải có những token kia ta sẽ truy ngược lại văn \r\nbản đầu vào để khôi phục chúng theo nhãn được gán từ quá trình tiền xử lý. \r\n\r\n \r\nChúng ta sử dụng mạng 4 lớp LSTM ẩn. Mỗi lớp ẩn có kích thước là 512 \r\n\r\nunits. Các trọng số trong mô hình được khởi tạo giá trị trong khoảng [-0.1;0.1]. \r\nLearning rate là 0.01 và hàm optimize là giải thuật Adam  \r\n\r\n\r\n\r\n\r\n3.4.3 Kĩ thuật attention \r\nKĩ thuật attention giúp cho mạng neural có thể ghi nhớ chính xác những nội \r\n\r\ndung quan trọng một cách chính xác hơn. Khi sinh mỗi từ output kĩ thuât này sẽ tính \r\ntrọng số cho mỗi từ trong input phụ thuộc vào sự chú ý của từ đó đến từng từ trong \r\nchuỗi đầu vào. Cơ chế cụ thể đã được miêu tả trong phần 3.4.3. Trọng số attention \r\ncho input word ở bước thứ t được tính như sau:  \r\n   \r\n\r\n !\"#' % = \t\r\n()*(,-#. ,/#' )\r\n()*(,-#\r\n\r\n. ,/#' )\r\n.\r\n#\r\n\r\n   \r\n\r\nTrong đó \"#    đại diện cho layer cuối cùng được sinh ra sau khi truyền vào t từ , \"#'    \r\nđại diện cho layer cuối cùng của bước hiện tại của modul giải mã \r\n\r\nLưu ý rằng ở cách thông thường việc tính toán trọng số attention và tính \r\nvecto ngữ cảnh đều dùng chung các lớp ẩn (hidden units). Vì vậy em đề suất biến \r\nđổi kĩ thuật này một chút được gọi là simple attention. Với kĩ thuật này ta sẽ tách \r\nlayer cuối cùng ở mỗi input thành 2 phần. Phần đầu có kích thước 40 được sử dụng \r\nđể tính toán trọng số attention, phần còn lại được sử dụng để tính vecto ngữ cảnh. \r\nTương tự cho layer cuối cùng ở modul decoder. Ngoài những thay đổi công thức \r\ntính toán trọng số vẫn được giữ nguyên. \r\n\r\n  \r\n\r\n\r\n\r\n\r\n  \r\n \r\n\r\n  \r\n3.5 Thực nghiệm \r\n3.5.1 Môi trường thực nghiệm \r\n\r\n Chương trình được xây dựng và thử nghiệm trên máy tính cá nhân có cấu \r\nhình và các phần mềm cần thiết như sau:  \r\n\r\n- Vi xử lý: 2.2 GHz Quad-Core Intel Core i7 Crystalwell \r\n- Ram: 16Gb  \r\n- Hệ điều hành: MacOs Sierra \r\n- Phần mềm phát triển: PyCharm \r\n- Ngôn ngữ sử dụng: Python \r\n-    Card đồ hoạ: GeForce GTX 1060 6Gb Ram \r\n-    Bộ thư viện dùng cho quá trình huấn luyện model: Keras chạy trên nền \r\nthư viện TensorFlow \r\n-    Bộ công cụ tách từ tiếng Việt: pyvi của tác giả Trần Việt Trung \r\n\r\n \r\n3.5.2 Thư viện TensorFlow \r\n\r\n Tensorflow là một thư viện mã nguồn mở cung cấp khả năng xử lý tính toán \r\nsố học dựa trên biểu đồ mô tả sự thay đổi của dữ liệu. Tensor được sử dụng khi ta \r\ncần giải quyết các bài toán supervised learning. Tensorflow được Google phát triển \r\n\r\n\r\n\r\n\r\nvà phát hành tháng 10 năm 2015. Các mô hình deeplearning phát triển trên \r\nTensorFlow có thể được sử dụng trên nhiều các loại platform khác nhau (từ \r\nsmartphone tới distributed servers) và trên CPUs lẫn GPUs. \r\n \r\n\r\n                    \r\n\r\n \r\n Trong TensorFlow mọi kiểu dữ liệu đều được quy về một mối được gọi là \r\nTensor. Vậy nên có thể hiểu được phần nào tên gọi của thư viện TensorFlow là một \r\nthư viện mô tả, điều chỉnh dòng chảy của các Tensor. Tensor là một kiểu dữ liệu \r\ndạng mảng có nhiều chiều. Ví dụ Tensor = [[[1,1,1] ,[178,62,74]] ,[[45,2,2] \r\n,[19,0,17]] ,[[7,5,2],[0,11,4]],[[8,13,5],[1,6,7]]] . Mảng nhiều chiều này được đính \r\nkèm them một vài thuộc tính tham chiếu khác. Các thuộc tính của Tensor được mô \r\ntả trong tài liệu gồm:  \r\n\r\n device: Tên của thiết bị mà Tensor hiện tại sẽ được xuất bản. Có thể None. \r\n graph: Đồ thị chứa Tensor hiện tại. \r\n name: Tên của Tensor hiện tại. \r\n shape: Trả về TensorShape mô tả lại Shape của Tensor hiện tại. \r\n op: Operation được sử dụng để xuất bản Tensor hiện tại. \r\n dtype: Kiểu của các phần tử trong Tensor hiện tại. \r\n\r\n \r\n\r\n\r\n\r\n\r\n3.5.3 Thư viện Keras \r\n\r\n Keras là một API cấp cao được viết trên Python và có khả năng trên nền của \r\ncác thư viện khác như TensorFlow,CNTK hay Theano. Thư viện này giúp những ai \r\nmới nghiên cứu về mạng neural tiếp cận một cách dễ hơn và trực quan hơn. Keras \r\ncho phép chúng ta dễ dàng khởi tạo, cấu hình hay mở rộng các model, nó cũng hỗ \r\ntrợ rất tốt cho cả 2 mô hình CNN ( convolutional network ) và RNN (recurrent \r\nnetworks). \r\n \r\n3.5.4 Dữ liệu thực nghiệm \r\n\r\nMô hình sử dụng bộ dữ liệu gồm một triệu văn bản từ Báo Mới. Bộ \r\nword2vec đã được huận luyện cũng từ tập dữ liệu Báo Mới. Mỗi văn bản được tách \r\nthành 3 phần: Headline, Description và Content. Vì mô hình chưa có khả năng lưu \r\ntrữ một lượng thông tin đầu vào lớn nên sẽ chỉ tập trung vào việc sinh tiêu \r\nđề(headline) từ phần miêu tả(description). Do đó phần Headline và Description sẽ \r\nđược tách ra để phục vụ cho mục đích của bài toán. \r\n\r\nBộ dữ liệu Báo Mới có dung lượng 3.64GB được chia thành 1000 bản ghi, \r\nmỗi bản ghi gồm hơn 1000 văn bản được chia cắt bởi kí tự #. Bản thân bộ dữ liệu \r\ncũng đã được tiền xử lý qua trước, 2 câu đầu tiên của mỗi văn bản là tiêu \r\nđề(heading) và phần miêu tả (description), từ câu thứ 3 trờ đi là phần nội dung của \r\nvăn bản. \r\n\r\nPhần heading và description sẽ được giữ lại để làm dữ liệu huấn luyện và \r\ntest. Bước đầu tiên của quá trình tiền xử lý là phải tách riêng từng văn bản từ tập \r\n1000 bản ghi, sau đó loại bỏ những văn bản trùng lặp. Bộ dữ liệu ban đầu có tất cả \r\n1175154 văn bản, sau khi loại bỏ các văn bản trùng lặp dữ liệu còn lại 980204 văn \r\nbản. Sau đó lấy ngẫu nhiên 3000 văn bản ra để làm tập dữ liệu test validation Sau \r\nquá trình tiền xử lý như đã đề cập ở mục 3.3.2 dữ liệu sẽ được đóng gọi dưới đinh \r\ndạng .pkl.  \r\n\r\n \r\n3.5.5 Phương pháp đánh giá \r\n\r\nĐối với bài toán này em vẫn lựa chọn Rouge làm phương pháp đo độ chính \r\nxác. Phương pháp này đã được nêu chi tiết ở phần 2.5.2.2 \r\n \r\n3.5.6 Kết quả thực nghiệm  \r\n\r\n Đồ án sẽ tập trung vào việc so sánh 2 model: model attention encoder-\r\ndecoder gốc được tạo bởi Rush và đồng nghiệp với model đó sau khi đã được cải \r\ntiến bằng một số kĩ thuật đã được nêu ra ở mục 3.3.3 \r\n\r\n\r\n\r\n\r\nRouge  \r\nFeature\t\r\n\r\nRouge-1 \r\n(%) \r\n\r\nRouge-2 \r\n(%) \r\n\r\nModel gốc 28.32           6.66 \r\n\r\nModel cải tiến 33.60          12.21 \r\n\r\n \r\n Từ kết quả bảng trên ta có thể thấy việc áp dụng một số cải tiến vào mô hình \r\nhuấn luyện đã đem lại hiệu quả. Sau khi cải tiến model tăng 5.28% với Rouge1 và \r\n5.55% với Rouge2. Tuy nhiên điểm độ đo Rouge vẫn chưa thực cao, nguyên nhân \r\nlà do phép đo Rouge so khớp kí tự của bản do người tóm tắt với máy tóm tắt, mà \r\nđặc trưng của phương pháp tóm tăt abtract là không phải trích rút từ những câu \r\nnhững từ có sẵn trong văn bản đầu vào. \r\n Dưới đây là một số kết quả của model cuối cùng sau thời gian huấn luyện 1 \r\ntuần \r\n  \r\n\r\nVăn bản đầu vào Tiêu đề gốc Tiêu đề do máy dự \r\nđoán \r\n\r\nNgày 20/5 , Phái_đoàn thường_trực \r\nViệt_Nam bên cạnh Liên_hiệp quốc , \r\nTổ_chức Thương_mại Thế_giới ( \r\nWTO ) và các tổ_chức quốc_tế khác \r\ntại Geneva , Thụy_Sĩ , đã ra \r\nthông_cáo về những diễn_biến gần \r\nđây ở biển Đông và gửi đến \r\nVăn_phòng Liên_hiệp_quốc tại \r\nGeneva , các tổ_chức quốc_tế cùng \r\ncác cơ_quan báo_chí có trụ_sở tại \r\nGeneva . \r\n \r\n\r\nViệt_Nam gửi \r\nthông_cáo về biển \r\nĐông lên LHQ \r\n \r\n\r\nViệt_Nam gửi \r\nthông_cáo về \r\ntình_hình \r\nBiển_Đông \r\n \r\n\r\nNghị_quyết về mức giá các loại đất \r\nnăm 2011 vừa được HĐND TP \r\nthông_qua , áp_dụng từ ngày \r\n1.1.2011^ . Theo đó , giá đất nhiều \r\nkhu_vực trung_tâm thành_phố ( quận \r\nNinh_Kiều^ ) tăng gần gấp đôi so với \r\nnăm 2010 . \r\n \r\n\r\nGiá đất nhiều \r\nkhu_vực nội ô tăng \r\ngần gấp đôi \r\n \r\n\r\nGiá đất tại \r\nCần_Thơ tăng \r\n \r\n\r\n\r\n\r\n\r\nTrong lúc đang đánh_bắt hải_sản ở \r\nvùng đảo Hoàng_Sa , tàu \r\nTrung_Quốc bất_ngờ xuất_hiện và \r\ntấn_công tàu cá của ngư_dân \r\nQuảng_Ngãi . \r\n \r\n\r\nTàu cá \r\nQuảng_Ngãi \r\ntiếp_tục bị tàu \r\nTrung_Quốc \r\ntấn_công \r\n \r\n\r\nTàu cá ngư_dân \r\nTrung_Quốc \r\ntấn_công trên biển \r\n \r\n\r\nMột máy_bay của Hãng hàng không \r\nMalaysia mất_tích khi bay vào \r\nkhông_phận Việt_Nam  \r\n \r\n\r\nMáy_bay chở 227 \r\nhành_khách đã rơi \r\ncách đảo Thổ_Chu \r\n300 km \r\n \r\n\r\nMáy_bay Malaysia \r\nmất_tích : \r\nMáy_bay đã gặp \r\nnạn \r\n \r\n \r\n\r\nBáo Telegraph ( Anh ) rút ra năm \r\nbài_học từ trận Bayern_Munich ( B.M \r\n) hạ Manchester United ( M.U ) 3-1 ở \r\ntứ_kết lượt về Champions_League . \r\n \r\n\r\n5 bài_học từ trận \r\nM.U thua Bayern \r\n \r\n\r\nDavid_Moyes vẫn \r\nkhông được \r\nthất_bại \r\n \r\n\r\nNguyên_nhân của clip phụ_huynh \r\nhọc_sinh đánh nhau tại Hà_Nội khiến \r\nnhiều người bất_ngờ . Đó là từ câu \r\nnói \" xấu lại còn thích thể_hiện \" . \r\n \r\n\r\nNữ_sinh và \r\nphụ_huynh xô_xát \r\n: Từ lời chê xấu gái \r\ntrên mạng \r\n \r\n \r\n\r\nHọc_sinh \r\nphụ_huynh đánh \r\nnhau \r\n \r\n\r\nHai bảo_mẫu hành_hạ trẻ_em sẽ được \r\nxét_xử lưu_động ngày 20/1 tại \r\nHội_trường Nhà thiếu_nhi quận \r\nThủ_Đức . \r\n \r\n\r\nXét_xử lưu_động 2 \r\nbảo_mẫu hành_hạ \r\ntrẻ_em \r\n \r\n\r\nVụ bảo_mẫu \r\nhành_hạ trẻ trẻ \r\n \r\n\r\n\r\n\r\n\r\nThị_trường chứng_khoán Việt_Nam \r\nđã có một tuần giao_dịch khá \r\ntích_cực , chỉ_số VN-Index tăng 4,75 \r\n% , HNX-Index tăng 2,87^ % . \r\nĐồng_hành với nhà đầu_tư trong \r\nnước , tuần qua , thị_trường đã \r\nchứng_kiến những phiên giao_dịch \r\nghi đậm dấu_ấn của khối ngoại . \r\n  \r\n\r\nTuần từ 13 - 17/1 : \r\nKhối ngoại mua \r\nròng 738,27^ tỷ \r\nđồng trên HOSE \r\n \r\n\r\nVN-Index tiếp_tục \r\nhồi_phục \r\n \r\n\r\nNgày 31/3 , Cục Đăng_kiểm \r\nViệt_Nam cho biết , đã sửa_đổi \r\nThông_tư 56/2012^ nhằm","u":"http://202.191.57.85:8000/InternetData/Data/DATN/20131848_Duong_Viet_Hung_1514557567432.txt","sentences":[[1,"Với sự tăng trưởng đó tầm quan trọng của việc tóm lược thông tin ngày càng quan trọng"],[2,"Làm sao ta có thể biết được điều gì là quan trọng trong một khoảng thời gian ngắn"],[3,"Việc tóm lược thông tin giúp ta có thể quyết định xem tiếp tục tập trung vào phần nào, nhất là trong các văn bản phức tạp như bài báo khoa học hay toàn bộ nội dung một cuốn sách"],[4,"Ngoài ra nó còn có thể ứng dụng trong rất nhiều các lĩnh vực khác mà con người cần phải tóm lược một lượng rất lớn các dữ liệu như tài chính, dữ liệu thuốc của bệnh nhân trong y học"],[5,"Bài toán tóm tắt văn bản là một trong những bài toán kinh điển trong lĩnh vực xử lý dữ liệu văn bản"],[6,"Xử lý dữ liệu văn bản bao gồm: Kiểm tra lỗi chính tả (spelling-checker) Kiểm tra lỗi văn phạm (grammar-checker) Từ điển đồng nghĩa (thesaurus) Phân tích văn bản (text analyzer) Phân loại văn bản (text classification) Tóm tắt văn bản (text summarization) Tổng hợp tiếng nói (speech synthesis) Nhận dạng giọng nói (speech recognization) Dịch tự động (automatic translation)"],[7,"Tóm tắt văn bản là công việc phân tích nội dung của văn bản và sau đó sinh ra một văn bản tóm tắt có kích thước nhỏ hơn văn bản ban đầu, loại bỏ đi những thông tin không quan trọng nhưng vẫn đảm bảo giữ được những nội dung cốt lõi của văn bản"],[8,"Do đó để công việc tóm tắt văn bản chính xác cần phải đáp ứng được các yêu cầu sau: Các văn bản khi phân tích thì phải hiểu được nội dung để xác định được các tiêu chuẩn trong văn bản"],[9,"Các văn bản tóm tắt cần được kiểm tra bằng một thang đo tiêu chuẩn"],[10,"Rõ ràng việc tóm tắt văn bản chính là công việc khai phá dữ liệu văn bản (text data mining)"],[11,"1.2 Lịch sử phát triển của tóm tắt văn bản Tóm tắt văn bản bắt đầu từ những năm cuối thập kỉ 1950 với nghiên cứu của Luhn(1958) dựa trên tần số từ"],[12,"Ý tưởng cơ bản của phương pháp tần số từ dựa trên kiến thức cho rằng tần số của từng từ trong văn bản là một độ đo hữu dụng để đánh giá tầm quan trọng của chúng"],[13,"Tiếp theo đó là phương pháp tóm tắt dựa trên vị trí của các câu trong văn bản của Baxendale (1958) và những nghiên cứu của Edmundson(1969) về vị trí của các câu trong văn bản và các từ/cụm từ mang ý nghĩa tổng quát"],[14,"Theo đó, những câu bắt đầu và kết thúc của đoạn văn bài viết hay những câu chưa những từ như important (đặc biệt), result are (kết qủa là)"],[15,"là những câu có ý nghĩa quan trọng"],[16,"Đầu những năm 1970, tiếp tục có những nghiên cứu với hướng tiếp cận ngoài (sử dụng các cụm từ dấu hiệu) và được ứng dụng trong các phần mềm thương mại Những năm 1980, phát triển nhiều nghiên cứu với nhiều hướng khác nhau, đặc biệt là hướng tiếp cận mức thực thể dựa trên trí tuệ nhân tạo như sử dụng script (Lehnert 1981), các luật sản xuất mạng và logic (Fum 1985), mạng ngữ nghĩa (Reimer và Hahn 1988) cũng như các hướng tiếp cận kết hợp (Rau 1989) hay (Aretoulaki 1994)"],[17,"Willam B"],[18,"Cavnar (1994) : biểu diễn văn bản dựa trên n-gram thay cho cách biểu diễn truyền thống bằng từ khoá"],[19,"Jaine Carbonell (1998) đã tóm tắt văn bản bằng cách xếp hạng các câu trội (câu chưa các ý chính của văn bản) và rút ra các câu trội"],[20,"Jade Goldstein (1999) : phân loại tóm tắt dựa trên độ đo liên quan, phương phpas sử dụng kết hợp giữa ngữ học, thống kê"],[21,"Một câu được đặc trưng bằng các đặc tính ngữ học và độ đo thống kê"],[22,"J.Larocca Neto (2000) đã tạo tóm tắt văn bản dựa trên các dãy từ trong câu được chọn theo hệ số tf, sau đó dùng kỹ thuật gom cụm (clustering) để tạo tóm tắt"],[23,"Yoshio (2001) đã tạo tóm tắt văn bản tiếng Nhật"],[24,"Có 2 phương pháp là rút câu dựa trên từ khoá và rút câu dựa trên kiến trúc ngữ nghĩa trong đó có xây dựng độ đo mối liên kiết giữa hai từ"],[25,"Hiện nay, một số nghiên cứu về xử lý ngôn ngữ tự nhiên cũng bước đầu được áp dụng trong tóm tắt văn bản"],[26,"Mặt khác, các nghiên cứu về tóm tắt đa văn bản, đa ngôn ngữ và tóm tắt đa phương tiện cũng bắt đầu phát triển"],[27,"1.3 Phân loại các phương pháp tóm tắt văn bản Một trong những cách phân chia của bài toán tóm tắt là: Tóm tắt đơn văn bản và Tóm tắt đa văn bản"],[28,"Tóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn ngọn của văn bản đó"],[29,"Ngược lại tóm tắt đa văn bản là từ một văn bản nguồn cũng chỉ cho ra một đoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng thời cho nhiều văn bản khác nhau"],[30,"Trong phạm vi đồ án, em sẽ tập trung nghiên cứu và áp dụng các kĩ thuật tóm tắt văn bản tự động vào bài toán tóm tắt đơn văn bản vì tính đặc trưng của các kĩ thuật áp dụng"],[31,"Thuật toán cho bài toán tóm tắt đa văn bản được điều chỉnh cho phù hợp từ cơ sở bài toán tóm tắt đơn văn bản"],[32,"1.3.1 Phân loại theo dạng tóm tắt 1.3.1.1 Phương pháp tóm tắt trích xuất Extractive text summarization Phương pháp trích xuất bao gồm việc lựa chọn đơn vị của văn bản (câu hay đoạn văn), được coi là có chứa lượng thông tin cốt tử của văn bản (informative content, informativity), và kết nối các đơn vị này theo một trình tự thích hợp"],[33,"Một trích xuất là sự lắp ghép các đoạn được trích rút ra từ văn bản nguồn"],[34,"Mục tiêu của trích xuất là cung cấp một cái nhìn tổng quan về nội dung của văn bản gốc"],[35,"Độ dài của văn bản tóm tắt bằng trích xuất có thể được xác định bởi tỉ lệ nén, hay nói cách khác Văn bản tóm tắt ngắn hơn bao nhiêu so với văn bản gốc"],[36,"Thuật toán tóm tắt tự động bằng trích xuất có thể chia ra làm 3 mức: surface- level (mức bề mặt), intermediate-level (mức trung bình) và deep parsing techniques (các kĩ thuật phân tích sâu)"],[37,"Tóm tắt trích rút xuất phát từ ý tưởng: Một tài liệu được chia nhỏ thành các đơn vị ngữ pháp (các câu văn), sau đó được đánh trọng số theo kinh nghiệm (heuristic); Các đơn vị ngữ pháp có điểm cao nhất sẽ được trích rút và liên kết với nhau để tạo nên văn bản tóm tắt"],[38,"Thuật toán tiếp cận ở mức bề mặt: Không đào sâu vào chiều sâu ngôn ngữ của văn bản, thay vào đó là sử dụng các phần tử ngôn ngữ nhất định để xác định các đoạn có liên hệ với nhau trong văn bản"],[39,"Kĩ thuật của mức bề mặt dựa vào sự xuất hiện của từ để đánh trọng số cho các câu"],[40,"Một kĩ thuật khác dựa trên ý tưởng: Những từ được sử dụng trong tiêu đề của văn bản là quan trọng"],[41,"Trong khi đó, một số kĩ thuật dựa vào vị trí của các đoạn trong văn bản"],[42,"Kĩ thuật này được áp dụng với nhưng văn bản có cấu trúc cố định, như tiêu đề, các mục và các đoạn,.."],[43,"Một số nghiên cứu còn chỉ ra rằng: Dòng đầu tiên luôn là dòng quan trọng nhất trong văn bản đối với các thể loại báo chí"],[44,"Thuật toán tiếp cận mức trung bình: Sử dụng thông tin về ngôn ngữ học phức tạp hơn thuật toán tiếp cận mức bề mặt nhưng lại ít phức tạp hơn mức phân tích sâu"],[45,"Một kĩ thuật của dạng này là phát hiện các chuỗi từ vựng"],[46,"Chuỗi từ vựng là một dãy các từ kết nối với nhau theo quan hệ về ngữ nghĩa"],[47,"Một cách tổng quát, quá trình tóm tắt bao gồm 4 giai đoạn"],[48,"Bốn giai đoạn đó bao gồm: Chia văn bản gốc thành các đoạn (segments)"],[49,"Xây dựng các chuỗi từ vựng lexical chain"],[50,"Xác định các strong chain chuỗi từ mạnh Trích rút các câu chứa các strong chain Lắp ghép các câu được trích rút thành văn bản tóm tắt Thuật toán phân tích sâu: Dựa trên ý tưởng rằng sử dụng các kĩ thuật chuyên sâu về ngôn ngữ để phát hiện ra các cấu trúc rời rạc của văn bản"],[51,"Những hệ thống tóm tắt văn bản tự động dựa trên phân tích diễn ngôn bắt nguồn từ ý tưởng: Văn bản được định nghĩa bởi cấu trúc trong của nó và các mối quan hệ diễn ngôn - phụ thuộc vào ngôn ngữ mà văn bản sử dụng"],[52,"Những hệ thống này cung cấp độ quan trọng nhiều hơn cho các thành phần cốt tử của các quan hệ rời rạc"],[53,"Sử dụng lý thuyết cấu trúc diễn ngôn (Rhetorical structure theory) chia văn bản thành các đơn vị rời rạc sử dụng tập các quan hệ tối thiểu (minimal set of relations)"],[54,"Một khi các cấu trúc rời rạc được xác định, một thuật toán sẽ được áp dụng để đánh trọng số và thứ tự cho mỗi phần tử trong cấu trúc tựa cây một cách rời rạc"],[55,"Và cuối cùng, các câu với trọng số cao nhất sẽ được lựa chọn để tạo nên văn bản tóm tắt"],[56,"1.3.1.2 Phương pháp tóm tắt tóm lược Abstractive summarization Tuy tóm tắt bằng trích rút đã thành công trong việc xác định câu nào trong văn bản đầu vào mang nội dung quan trọng nhưng dường như những phương pháp này rất xa với việc tạo ra một bản tóm tắt tối ưu theo nghĩa cả về nội dung và chất lượng trong ngôn ngữ học"],[57,"Trong khi đó, hệ thống tạo ra văn bản tóm tắt bằng tóm lược dựa trên việc hiểu văn bản gốc và đạt tới việc sinh ra một văn bản mới một cách chính xác về ngữ pháp, súc tích và mạch lạc về nội dung, bằng cách sinh ra văn bản tóm tắt bằng những từ vựng không xuất hiện trong văn bản gốc"],[58,"Trong tóm lược, việc diễn giải, viết lại các câu phức tạp sẽ nhằm mục đích tạo ra phiên bản súc tích của nội dung ban đầu"],[59,"Mặc dù con người có thể tái sử dụng một phần văn bản gốc nhưng không phải sử dụng toàn bộ nó; sử dụng các đoạn hay một phần của câu thay vì sử dụng toàn bộ câu"],[60,"1.3.2 Phân loại theo mức độ xử lý: Tiếp cận mức ngoài : thông tin được miêu tả dứoi dạng khái niệm về các đặc trưng nông (shallow feature)"],[61,"Các đặc trưng nông bao gồm các thuật ngữ quan trọn gqua thống kê ( dựa vào tần số của các thuật ngữ trong văn bản), các thuật ngữ quan trọng dựa vào vị trí, các cụm từ dấu hiệu hay các thuật ngữu trong câu truy vấn của ngừoi dùng"],[62,"Kết quả là một bàn tóm tắt dạng trích xuất (extract)"],[63,"Tiếp cận mức sâu (deeper-level) : ở mức này bản tóm tắt có thể là dạng trích xuất hoặc dạng tóm tắt (abstract) và cần phải sửu dụng đên sinh tổng hợp ngôn ngữu tự nhiên"],[64,"Với dạng tiếp cận này phải cần đến những phân tích về mặt ngữ nghĩa, chẳng hạn sử dụng hướng tiếp cận thực thể đẻ xây dựng dạng biểu diễn của cấc thực thể văn bản và mối quan hệ giữa các thực thể rồi từ đố tìm ra phần trái nghĩa, nghĩa hẹp, nghĩa rộng., quan hệ cú pháp dựa trên cây phân tích cú pháp và các mối quan hệ khác"],[65,"1.3.3 Phân loại theo mục đích của bản tóm tắt: Trình bày sơ lược : Đưa ra những thông tin ngắn gọn về chủ đề chính của văn bản"],[66,"Dạng tóm tắt này thường được sử dụng trong các hệ thống tìm kiếm thông tin"],[67,"Thông thường, độ dài của văn bản tóm tắt loại này chỉ từu 5 đến 10% độ dài của toàn bộ văn bản Tóm tắt cung cấp tin tức: Cung cấp các chủ đề con của toàn bộ văn bản, kiểu tóm tắt này có độ dài từ 20-30% văn bản gốc"],[68,"Phê bình và đánh giá: Văn bản tóm tắt đưa ra những quan điểm của người tóm tắt về chủ đề được đưa ra"],[69,"Tuy nhiên, kiểu tóm tắt này dường như vượt qua tầm của các hệ thống tóm tắt tự động hiện này"],[70,"1.4 Những vấn đề trong bài toán tóm tắt văn bản Tóm tắt văn bản có 2 dạng cơ bản là Extractive và Abtractive"],[71,"Hầu hết các công cụ tóm tắt hiện này đều là extractive"],[72,"Đó là phương pháp tóm tắt giữa vào trích xuất các từ các câu tồn tại trong văn bản đầu vào sau đó dùng các giải thuật để đánh giá xếp hạng chúng rồi sắp xếp lại thành văn bản tóm tắt"],[73,"Nhưng con người chúng ta thì suy nghĩ phức tạp hơn như vậy"],[74,"Khi con người chúng ta tóm tắt não chúng ta khởi tạo những đặc trưng ngữ nghĩa mà chúng ta đọc từ văn bản và từ đó tóm lược nội dung văn bản"],[75,"Đó cũng chính là các phương thức abtractive hoạt động"],[76,"Với những bước tiến về mặt sức mạnh phần cứng deeplearning có thể giúp ta thực hiện điều này"],[77,"1.5 Giải pháp định hướng Với sự tiến bộ trong lĩnh vực Học máy (Machine learning) nói chung và học sâu (Deep learning) nói riêng có rất nhiều phương pháp đã chứng minh được tính hiệu quả trong việc giải quyết những bài toán phức tạp mà các cách tiếp cận truyền thống chưa thể giải quyết triệt để được"],[78,"Để giải quyết vấn đề khai phá, trích xuất những nội dung ngữ nghĩa được ẩn đi trong tài liệu(extractive), em đề xuất một thuật toán kết hợp các kĩ thuật phân tích văn bản truyền thống"],[79,"Từ đó, em sẽ thiết kế, xây dựng và đánh giá hệ thống tóm tắt văn bản tự động dựa trên cách tiếp cận này"],[80,"Cụ thể, nội dung đồ án sẽ tập trung nghiên cứu, tìm hiểu kĩ thuật phân tích ma trận NMF và trích suất đặc trưng"],[81,"Để giải quyết bài toàn tóm tắt văn bản bằng phương pháp abtractive, trích xuất nội dung ngữ nghĩa trong tài liệu em đề xuất sử dụng một mô hình được sử dụng phổ biết trong các bài toán dịch máy đó là mô hình sequence to sequence kết hợp cũng kĩ thuật attention, một kĩ thuật đang được áp dụng rất phổ biến gần đây cho các mô hình sequence to sequence nhằm tăng độ chính xác và giảm số lượng dữ liệu cần phải xử lý"],[82,"Sau đó sẽ so sánh kết quả đạt được với phương pháp extractive sử dụng mà trận không âm NMF kết hợp với trích suất đặc trưng"],[83,"CHƯƠNG 2 PHƯƠNG PHÁP PHÂN TÍCH MA TRẬN TRONG BÀI TOÁN TÓM TẮT 2.1 Cơ sở lý thuyết 2.1.1 Kĩ thuật phân tích ma trận không âm Phân tích ma trận không âm - Non-negative matrix factorization là một nhóm các thuật toán phân tích đa biến trong đại số tuyến tính"],[84,"Ma trận A được phân tích thành 2 ma trận W và H với điều kiện là cả 3 ma trận này đều chỉ mang các thuộc tính không âm, Ma trận A được phân tích thành 2 ma trận W và H:"],[85,"= #$ Với A là một ma trận mxn, W là một ma trận mxk, và H là một ma trận kxn, k luôn được chọn nhỏ hơn m và n, do đó cả 2 ma trận W và H đều có size nhỏ hơn ma trận A"],[86,"Chúng ta sử dụng Frobenius norm như là hàm mục tiêu (objective function) để thỏa mãn điều kiện xấp xỉ A WH"],[87,"Frobenius norm được chỉ ra trong công thức (Lee & Seung, 1999, 2001):"],[88,"\",$ &-\"$ () *+,- \"+-$-,"],[89,"-/0 1 ,/0 2 +/0 ) Công thức này có cận dưới bằng 0, và rõ ràng tiến tới 0 khi và chỉ khi A = WH"],[90,"W và H liên tục được cập nhật tới khi E(W,H) hội tụ dưới ngưỡng được định nghĩa hoặc vượt quá số lần lặp"],[91,"Luật cập nhật được chỉ ra dưới đây: !\"# !\"# %&' \"# %&%"],[92,"\"# !\"# !\"# %&' \"# !&&' \"# Vec-tơ cột A tương ứng với câu thứ j, Aj, có thể được biểu diễn như là một sự kết hợp tuyến tính của vec-tơ đặc trưng ngữ nghĩa W*l và biến ngữ nghĩa Hlj như dưới đây: !*# = H&'(*) * )+, Ví dụ 1: Chúng ta sẽ lấy một ví dụ để minh họa cho thuật toán NMF: Cho k = 2, số bước lặp là 50, và dung sai = 0.001 (tolerance)"],[93,"Các phần tử tại thời điểm ban đầu của W và H băng 0.5, ma trận không âm A được phân tích thành 2 ma trận không âm W và H, được chỉ ra trong câu sử dụng NMF"],[94,"Vec-tơ cột A*3 tương ứng với câu thứ 3 được biểu diễn như là sự kết hợp tuyến tính của vec-tơ đặc trưng ngữ nghĩa W*l và vec-tơ cột biến ngữ nghĩa (semantic variable column vector) H*3"],[95,"NMF phân tích một ma trận thưa thành hai ma trận thưa"],[96,"Ở đây tỉ lệ phần tử bằng 0 (non-zero ratio) của ma trận có nghĩa là giá trị các phần tử khác 0 chia cho tổng số phần tử của ma trận"],[97,"Ma trận không âm A là 1 ma trận vuông nxn, và giá trị của n được đặt bằng 100, 200, 300 và 400"],[98,"Non-zero entries được chọn một cách ngẫu nhiên"],[99,"Số lượng đặc trưng nghĩa nghĩa, r, được chọn là 10% cuả n"],[100,"Tỉ lệ non- zero cuả A được chọn lần lượt là 0.5%, 1%, 2%, 3%, 5%, 7%, 10%, 30%, 60% và 99%"],[101,"Hai ma trận W và H thu được bằng NMF"],[102,"A W H A 1 2 3 4 5 6 7 8 9 10 11 12 0.1487 1.5998 0.6610 0.9676 1.1481 0.5727 1.6129 0.4066 6.1136 6.6784 7.17840.0854 0.5923 1.2245 = 1.0457 1.9420 3.0263 4.1237 4.9813 5.9297 7.0679 8.0071 8.9470 9.8953 11.0127 12.0759 A*3 W*1 W*2 H*3 A*3 H13 W*1 H23 W*2 3 6 9 12 7.1784 0.1487 0.6610 1.1481 1.6129 + 1.2245 1.5998 0.9676 0.5727 0.4066 2.1.2 Kĩ thuật tiếp cận dựa trên cấu trúc Trong các nghiên cứu gần đây có rất nhiều các đặc trưng hiệu quả của câu văn được đề xuất để dùng cho tóm tắt trích rút, ví dụ như signature word, event hay sentence relevance"],[103,"Mặc dù có nhiều kết quả đáng khích lệ nhưng hầu hết các đặc trưng này được khảo sát một cách độc lập"],[104,"Tuy nhiên, thực tế mỗi đặc trưng này lại có đóng góp riêng của nó và sự kết hợp các đặc trưng đó lại với nhau có thể thu được một kết quả tốt hơn trong các trường hợp riêng lẻ"],[105,"Trong phần 2.5 của đồ án sẽ trình bày các kết quả thực nghiệm để đánh giá và chọn ra những bộ đặc trưng cho kết quả tốt nhất đáp ứng với bài toán tóm tắt văn bản"],[106,"Trong mục này sẽ trình bày chi tiết các đặc trưng được xem xét"],[107,"Surface Features Đặc trưng bề mặt: Nhóm đặc trưng này xem xét đến đặc điểm cấu trúc của câu"],[108,"Bao gồm: vị trí của câu trong văn bản - thông thường các câu đầu văn bản thường là các câu chứa đựng chủ đề khái quát của cả bài văn; số lượng từ trong câu - căn cứ vào các kiểu văn bản khác nhau, văn bản báo chí, xã luận, hay bài báo khoa học thì câu văn thường có một độ dài trung bình nhất định, những câu văn có số lượng từ nhỏ hơn ngưỡng đó sẽ là các câu không quan trọng; số lượng trích dẫn trong câu - một câu chứa quá nhiều trích dẫn là câu không quan trọng"],[109,"Relevance Features Đặc trưng độ liên quan: Đặc trưng này được sử dụng để tìm ra mối liên hệ giữa các câu"],[110,"Để làm được điều đó, ta đặt quy ước rằng: Giữa các câu luôn tồn tại mối liên hệ với nhau, sẽ có một số câu mang nội dung quan trọng hơn các câu khác và khi những câu khác liên quan đến những câu đó thì mức độ quan trọng cũng tăng lên"],[111,"Tại thời điểm ban đầu, ta có những câu đầu tiên của tài liệu và những câu đầu tiên của đoạn văn là quan trọng"],[112,"Thước đo độ liên quan trong trường hợp này là độ tương đồng cosine"],[113,"Content Features Đặc trưng nội dung: Trong nhóm đặc trưng này, chọn đặc trưng Centroid, dựa vào đặc trưng centroid để xác định câu nào tập trung vào chủ đề của văn bản"],[114,"2.2 Áp dụng phân tích ma trận không âm vào phân tích văn bản Tourism in Greate Britain (Hoa 2005)"],[115,"Một số câu Câu văn S1 TOURIST arrivals to the UK in 1991 are forecast to recover sharply after the steep decline earlier this year cause by the Gufl war"],[116,"The British Tourist Authority said incoming tourist numbers had already increased significantly after falling 18 percent in the first two months of this year from the levels of the corresponding period of 1990 S2 The increases were achived in spite of a fall in the number of visitors from western Europe rose 12 percent to 23 m higher than in any previous first quarter"],[117,"A RECORD 185 m tourists visited Britain in the 12 months to March, 8 percent more than the previous year and the British Tourist Authority said yesterday that it was expecting even higher numbers this year"],[118,""],[119,"S20 The increase were achieved in spite of a fall in the number of North American visitors Visits by North Americans fell 6 percent to 600,000 in the first quarter"],[120,"However, the number of visitors from western Europe rose 12 percent to 23 m higher than in any previous first quarter"],[121,"A RECORD 185 m tourists visited Britain in the 12 months to March, 8% more than the previous year and the British Tourist Authority said yesterday that it was expecting even higher numbers this year"],[122,""],[123,"Thuật ngữ S 1 S 2 S 3 S 4 S 5 S 6 S 7 S 8 S 9 S 10"],[124,"S 20"],[125,"S 57 1 Tourist 3 2 0 2 1 0 0 0 0 0"],[126,"2"],[127,"1 2 Arrival 1 0 0 0 0 0 0 0 0 0"],[128,"0"],[129,"0 3 UK 1 1 0 0 1 0 0 0 0 0"],[130,"0"],[131,"1 4 Forecast 1 0 0 0 0 0 0 0 0 0"],[132,"0"],[133,"0 5 Recover 1 0 0 0 0 0 0 0 0 0"],[134,"0"],[135,"0 6 Sharply 1 0 0 0 0 0 0 0 0 0 0"],[136,"0 7 Steep 1 0 0 0 0 0 0 0 0 0"],[137,"0"],[138,"0 8 Decline 1 0 0 0 0 0 0 0 0 0"],[139,"0"],[140,"0 9 Earlier 1 0 0 0 0 0 0 0 0 0"],[141,"0"],[142,"0 10 Year 2 2 1 0 0 1 0 0 0 0"],[143,"2"],[144,"0 11 Cause 1 0 0 0 0 0 0 0 0 0"],[145,"0"],[146,"0 12 Gulf 1 0 0 0 0 0 0 0 0 0"],[147,"0"],[148,"0 13 War 1 0 0 0 0 0 0 0 0 0"],[149,"0"],[150,"0 14 British 1 2 0 1 1 0 0 0 0 0"],[151,"1"],[152,"0 15 Authority 1 1 0 1 1 0 0 0 0 0"],[153,"1"],[154,"1 16 Income 1 0 0 0 0 0 0 0 0 0"],[155,"0"],[156,"0 17 Increase 1 1 0 0 0 0 0 0 0 0"],[157,"1"],[158,"0 18 Significantly 1 0 0 0 0 0 0 0 0 0"],[159,"0"],[160,"0"],[161,""],[162,""],[163,""],[164,""],[165,""],[166,""],[167,""],[168,""],[169,""],[170,""],[171,""],[172,""],[173,""],[174,""],[175,""],[176,"396 Return 0 0 0 0 0 0 0 0 1 0"],[177,"0 0 bộ tập các câu trong sentences"],[178,"Dễ dàng nhận thấy trong là một ma trận rất thưa"],[179,"Thuật ngữ Đặc trưng ngữ nghĩa Câu S20 W*1 W*2 W*3"],[180,"W*10 Original !\"#$%*\" '$ \"('"],[181,""],[182,""],[183,""],[184,""],[185,""],[186,""],[187,""],[188,""],[189,"13 War 0 0 0"],[190,"0.04 0 0.11 14 British 0 0.68 0.44"],[191,"0.13 1 0.89 15 authority 0 0.60 0"],[192,"0 1 1.05 16 income 0 0 0.35"],[193,"0.03 0 0.11 17 increase 0.07 0 0"],[194,"0.76 1 1.01"],[195,""],[196,""],[197,""],[198,""],[199,""],[200,""],[201,""],[202,""],[203,"396 Return 0 0 0"],[204,"0.08 0 0.07 Trọng số Hj20 0 0.07 0"],[205,"0 phân tích NMF đối với ma trận A, giá trị trọng số H1,20, ..., H10,20 của vec-tơ đặc trưng ngữ nghĩa tương ứng với câu S20, vec-tơ câu ban đầu"],[206,"Vec-tơ câu được tính từ các giá trị trọng số và các vec-tơ ngữ nghĩa"],[207,"Phương pháp NMF trích xuất câu có trọng số lớn nhất theo nghĩa: câu đó phản ánh nhiều nhất tới chủ đề chính của tài liệu, điều đó được biểu diễn bởi các đặc trưng ngữ nghĩa"],[208,"Do đó, phương pháp NMF có likelihood tốt hơn trong việc trích xuất các câu quan trọng về mặt ngữ nghĩa so với phương pháp LSA"],[209,"2.3 Các vấn đề của NMF 2.3.1 Ưu điểm Đối với việc số hóa một tài liệu sang dạng dữ liệu để máy tính phiên bản số của tài liệu có thể thực hiện các phép toán cộng, trừ, nhân, chia,..., từ đó có thể thực hiện các công việc khai phá dữ liệu như phân loại văn bản (bài toán topic modelling), tóm tắt văn bản (text summarizing),"],[210,"thì việc sử dụng mô hình không gian vec-tơ mà cụ thể là phương pháp phân tích ma trận theo mô hình tần suất dường như là một cách làm mang tính tự nhiên nhất"],[211,"Trong chương 2, đồ án đã đề xuất sử dụng một phương pháp không giám sát mới để sinh ra văn bản tóm tắt của tài liệu tương ứng sử dụng kĩ thuật phân tích ma trận không âm NMF"],[212,"Phương pháp được đề xuất có những ưu điểm sau đây: Thứ nhất, đây là phương pháp không giám sát (unsupervised) và không yêu cầu các tóm tắt mẫu cho bước tập huấn và cho bộ tóm tắt"],[213,"Thứ hai, các vec-tơ đặc trưng ngữ nghĩa được trích rút từ NMF có thể được thể hiện trực quan hơn là sử dụng các phương pháp liên quan đến LSA, bởi vì các thành phần trong phân tích NMF chỉ gồm các giá trị không âm và chúng rất thưa trong khi cũng là các thành phần đó nhưng trong phương pháp LSA thì gồm cả giá trị âm và giá trị dương, ngoài ra, còn có chứa một vài giá trị bằng 0"],[214,"Hơn nữa, một câu được có thể được biểu diễn như là sự kết hợp tuyến tính của những đặc trưng ngữ nghĩa một cách trực quan"],[215,"Cuối cùng, phạm vi ngữ nghĩa của đặc trưng ngữ nghĩa là hẹp, bởi vì chúng rất thưa, theo đó, các chủ đề nhỏ (sub-topics) của tài liệu được xác định một cách dễ dàng và chính xác hơn"],[216,"Do đó, khả năng trích rút được các câu quan trọng sẽ tốt hơn các phương pháp khác"],[217,"2.3.2 Nhược điểm Tuy nhiên, nhược điểm của phương pháp nằm ở việc không thể phát hiện ra các liên kết ẩn giữa các từ, các phần trong văn bản"],[218,"Các liên kết này có thể tồn tại dưới nhiều dạng, đó có thể là quan hệ nguyên nhân kết quả giữa các luận điểm, có thể là những phần được nhấn mạnh, quan trọng hơn những phần khác hay là sự thay đổi cách sử dụng ngôn từ diễn đạt, và có một số thuật ngữ, tuy khác nhau về hình thức nhưng lại mang những nét nghĩa giống nhau"],[219,"2.4 Mô hình đề xuất Trong phần này ta sẽ đi vào thiết kế hệ thống thực tế để giải quyết bài toán tóm tắt văn bản trong ngôn ngữ tiếng Anh và tiếng Việt sử dụng NMF và phân tích đặc trưng"],[220,"2.4.1 Khối tiền xử lý văn bản 2.4.1.1 Khối tiền xử lý văn bản tiếng Việt Quá trình tiền xử lý văn bản đầu vào tiếp theo gồm các bước sau: Chia văn bản thành các câu"],[221,"Chia nhỏ từng câu thành các từ"],[222,"Chuyển toàn bộ văn bản về dạng chữ thường Loại bỏ các kí tự đặc biệt, không có ý nghĩa Phần tách câu và tách từ sử dụng công cụ Vitk (Vietnamese Text Progressing Toolkit) của tác giả Lê Hồng Phương"],[223,"Ví dụ câu Mỹ: hai tai nạn trên đường cao tốc, 11 người thiệt mạng sau khi qua tool sẽ được tách thành Mỹ : hai tai_nạn trên đường_cao_tốc , 11 người thiệt_mạng"],[224,"Các kí tự đặc biệt như \"\\-;%()|+&=*%.,!?:#$@\\/ cũng sẽ bị loại bỏ khỏi văn bản"],[225,"2.4.1.2 Khối tiền xử lý văn bản tiếng Anh Bước tiền xử lý gồm 2 hoạt động chính là Chuẩn hoá từ và Loại bỏ các cấu trúc ngữ pháp của từ, đău về dạng nguyên thể trong tiếng Anh"],[226,"Cả hai hoạt động này đều đóng vai trò quan trọng trong việc vec-tơ hóa tài liệu bởi vì nó sẽ làm giảm không gian biểu diễn của văn bản xuống, do đó làm giảm khối lượng cần tính toán"],[227,"Cụ thể, quá trình tiền xử lí văn bản đầu vào bao gồm các công việc sau: Chia văn bản đầu vào thành tập các câu"],[228,"Chia nhỏ câu thành các từ"],[229,"Lọc stopwords Chuẩn hóa từ Lemmatizing Stemming Stemming Là kĩ thuật hình thái từ dành cho khai phá thông tin (Information retrieval) được ứng dụng rộng rãi nhất"],[230,"Stemming là kĩ thuật dùng để biến đổi một từ về dạng gốc (được gọi là stem hoặc root form) bằng cách cực kì đơn giản là loại bỏ một số kí tự nằm ở cuối từ mà nó nghĩ rằng là biến thể của từ"],[231,"Người ta gọi các bộ xử lí stemming là stemmer"],[232,"Bởi vì nguyên tắc hoạt động của stemmer rất đơn giản nên tốc độ xử lí của nó rất nhanh nhưng đôi khi lại cho ra kết quả không như ý muốn"],[233,"Ví dụ 4: Cách thực hiện của bộ stemmer Các từ walks, walked, walkingsau khi stemming, bỏ đi các hậu tố -s, -ed, -ing sẽ trở thành walk Từ gosesau stemming thành gos Không thể đưa các từ như spoke, went về dạng speak hay go Lemmatization Lemmatization là một kĩ thuật chuẩn hóa từ khác: Không giống với Stemming là xử lí bằng cách loại bỏ các kí tự cuối từ một cách kinh nghiệm (heuristic), Lemmatization sẽ xử lí thông minh hơn bằng một bộ từ điển hoặc ontology (hệ thống nhãn ngữ nghĩa) nào đó"],[234,"Điều này đảm bảo đưa chính xác các dạng biến thể của từ về nguyên gốc trong từ điển"],[235,"Người ta gọi bộ xử lí lemmatization là lemmatizer Nhược điểm của lemmatization là tốc độ xử lí khá chậm vì phải thực hiện tra cứu từ trong cơ sở dữ liệu"],[236,"Trong các ứng dụng xử lí ngôn ngữ tự nhiên mà cần độ chính xác cao hơn và thời gian không quan trọng, người ta có thể sử dụng Lemmatization"],[237,"Ví dụ 5: Cách thực hiện của Lemmatizer Các từ như gose, wentsẽ được đưa chính xác về go"],[238,"Các danh từ như mouse, micecũng được đưa về cùng một dạng như nhau"],[239,"Loại bỏ stopwords Trong quá trình tính toán, stopwords là những từ được lọc trước hoặc sau quá trình xử lý dữ liệu ngôn ngữ tự nhiên (văn bản)"],[240,"Stopwords thường là những từ xuất hiện với tần suất lớn trong một ngôn ngữ, do đó không có một danh sách các stopwords thống nhất và được sử dụng bởi tất cả các công cụ xử lý ngôn ngữ tự nhiên"],[241,"Một nhóm bất kì các từ có thể được chọn là một stopwords để thực hiện một mục đích nhất định"],[242,"Đối với một search engine, có một số từ được xếp vào loại stop words do sự xuất hiện thường xuyên trong các trường hợp tìm kiếm như: the, is, at, which và on"],[243,"Trong trường hợp này, stopwords có thể là nguyên nhân gây ra vấn đề khi tìm kiếm theo phrases mà bao gồm những function word này, đặc biệt là khi tìm kiếm một số tên như: The Who, The The, hoặc Take That"],[244,"Ngoài ra, một số search engine loại bỏ các từ common words, bao gồm cả lexical words như want khỏi câu truy vấn nhằm mục đích cải thiện hiệu suất của search engine"],[245,"Sự phân biệt giữa function words và lexical words được đề xuất bởi C"],[246,"Fries vào năm 1952 và có một tầm ảnh hưởng lớn đến việc dạy tiếng Anh"],[247,"Function words: Còn gọi là functors là những từ có một chút lexical meaning hoặc có sự nhập nhằng về nghĩa và chúng nhấn mạnh mối quan hệ ngữ pháp với các từ khác trong cùng một câu, một quan điểm cụ thể hay tâm trạng của người nói"],[248,"Một số trường hợp của function words: Pronouns đại từ (he him, she-her,.); conjunction liên từ hoặc auxiliary verb - trợ động từ Lexical words: Từ thực, những từ mà không phải là function word"],[249,"lexical word bao gôm: danh từ, động từ, tính từ và hầu hết trạng từ vì có một số trạng từ là function word như: then, why"],[250,"Từ điển có thể định nghĩa một cách cụ thể một lexical word, nhưng chỉ có thể miêu tả một cách sử dụng tổng quát của function word"],[251,"Ngược lại, ngữ pháp có thể miêu tả cách sử dụng của function words một cách chi tiết, nhưng lại chỉ có thể xem lexical words trong các thuật ngữ chung (general term)"],[252,"2.4.2 Độ tương đồng Cosine trong Không gian Vec-tơ Trong mục này, em sẽ trình bày những kiến thức cơ bản về thước đo cosine được sử dụng để xác định độ tương đồng giữa 2 từ trong mô hình Word2Vec và ứng dụng trong phạm vi đồ án"],[253,"Tích vô hướng Chúng ta bắt đầu với định nghĩa về số học của tích vô hướng giữa hai vec-tơ:"],[254,"= !#, !%, !&,"],[255,"và"],[256,"= !#, !%, !&,"],[257,"với an và bn lần lượt là các thành phần của vec-tơ"],[258,","],[259,"và n là số chiều của các vec-tơ: !"],[260,"# = !%#% = !&#& + !(#( + + !*#* * %+& Tuy nhiên, để thấy được hết ý nghĩa của phép nhân vô hướng giữa 2 vec-tơ, chúng ta phải xem xét đến định nghĩa hình học của nó: !\" = !\" cos ( Sử dụng tính chất giao hoán để sắp xếp lại vế phải của công thức trên ta có: !\" = \""],[261,"cos ( Trong lý thuyết hình học, phép nhân \" cos & chính là phép chiếu của vect- tơ"],[262,"lên vec-tơ"],[263,", Khi vec-tơ"],[264,"vuông góc với vec-tơ"],[265,"tích này trở thành: Khi 2 vec-tơ vuông góc, tích vô hướng của chúng bằng 0"],[266,"Đây cũng là một cách để chúng ta kiểm tra 2 vec-tơ có quan hệ vuông góc hay không"],[267,"Tuy nhiên, ví dụ trên mới chỉ dừng lại ở không gian vec-tơ hai chiều, nhưng có một điều thú vị rằng, chúng ta cũng có thể tính toán góc và độ tương đồng giữa các vec-tơ trong không gian nhiều chiều, mà trong bài toán của chúng ta là Không gian vec-tơ 300 chiều"],[268,"Độ tương đồng Cosine Độ tương đồng cosine giữa hai vec-tơ (hoặc 2 từ trong Không gian vec-tơ) là một thước đo tính giá trị cosine của góc giữa chúng"],[269,"Thước đo này là thước đo về hướng của 2 vec-tơ, không phải thước đo về độ lớn"],[270,"Ta có: cos $ = &' &' Đây chính là công thức về độ tương đồng cosine"],[271,"Độ tương đồng cosine sẽ sinh ra một số, số này sẽ cho chúng ta biết 2 từ liên quan đến nhau như thế nào trong không gian bằng cách xem xét góc giữa chúng, thay vì so sánh về độ lớn"],[272,"a) Cùng hướng b) Vuông góc c) Đối diện 2.4.3 Khối tính điểm cho câu sử dụng NMF Khối tính điểm cho câu trong tài liệu là tổng hợp điểm đầu ra của 3 khối nhỏ hơn, trong đó: Sử dụng khối Word2Vec như một đặc trưng thứ nhất để xác định các ngữ nghĩa ẩn trong bài toán tóm tắt"],[273,"Sử dụng khối đặc trưng thứ hai để phân tích các đặc trưng cấu trúc của tài liệu"],[274,"Sử dụng kết quả của kĩ thuật phân tích ma trận NMF"],[275,"Ở đây ta sẽ sử dụng một phương pháp mới để chọn câu dựa trên phân tích NMF và định nghĩa đại lượng Generic Relevance of a Sentence (GRS) như sau: \"#$#%&' (#)#*+$'# ,- + ./ 1#$/#$'# = 3457#&8/ 34* : 4;< !\"#$& '(* = '(+,+-"],[276,"'/+,+-.0/-"],[277,"Trong đó, trọng số weight(Hi*) là sự liên quan về quan hệ (relative relevance) của đặc trưng ngữ nghĩa thứ i (W*i) với tất cả các đặc trưng ngữ nghĩa còn lại"],[278,"Một cách tổng quát, đại lượng thể hiện mức độ liên quan của một câu chính là mức độ phản ánh của câu đó đối với chủ đề chính của tài liệu, và được biểu diễn dưới hình thức các đặc trưng ngữ nghĩa"],[279,"2.4.4 Khối tính điểm đặc trưng cấu trúc a"],[280,"Đặc trưng bề mặt Các câu đầu đứng đầu hầu như mang nhiều nội dung tóm tắt hơn các câu phía sau"],[281,"Do đó ta sẽ ưu tiên cho các câu này"],[282,"Công thức tính điểm như sau: position ="],[283,"\"#"],[284,"( i là hệ số vị trí câu) Trong đó: i: là hệ số vị trí câu position: là kí hiệu điểm đặc trưng vị trí Các câu quá ngắn cũng không mang nhiều giá trị"],[285,"Do vậy những câu độ dài nhỏ hơn 10 từ sẽ bị điểm trừ: lengthSent = !\"#$%& ( )*)* ( i là hệ số vị trí câu, !\"#$%& là số từ xuất hiện trong câu thứ i) Trong đó: i: là hệ số vị trí câu !\"#$%& : là số từ xuất hiện trong câu thứ i lengthSent: là kí hiệu điểm đặc trưng đồ dài b"],[286,"Đặc trưng nội dung Chúng ta sẽ sử dụng 2 phương pháp centroid base và frequence word để tính điểm đặc trưng nội dung"],[287,"Centroid dựa trên độ tương đồng giữa các câu trong văn bản"],[288,"Ở đây em sử dụng hàm cosin để tính độ tương đồng giữa câu với đầu vào là vectơ biểu diễn từ sử dụng word2vec"],[289,"!\" = $%&%'()%*+($\", $.)0.12 Trong đó: n: là tổng số câu trong văn bản i: là vị trí câu hiện tại !\" : là kí hiệu điểm centroid của câu thứ i Frequence word lại tính điểm câu dựa trên tần suất xuất hiện các từ quan trọng trong câu"],[290,"Ở đây qua quá trình thực nghiệm em chọn ngưỡng 20% từ xuất hiện nhiều nhất trong văn bản đầu vào"],[291,"Fi = !(#$)&(') ( ) Trong đó: f(!\" ): tổng số lần xuất hiện của từ k trong cả văn bản s(d): tổng số lần xuất hiện của tất cả các từ trong văn bản Fi : là điểm Frequence của câu thứ i c"],[292,"Đặc trưng độ liên quan Ở phương pháp tính theo đặc trưng độ liên quan em đề suất sử dụng 2 phương pháp đó là tính theo độ liên quan với câu đầu tiên FirstRel và phương pháp PageRank"],[293,"PageRank là phương pháp khai thác liên quan giữa các câu bằng việc xây dựng một bản đồ câu"],[294,"Dựa trên bản đồ này thuật toán PageRank được áp dụng để đánh giá tầm quan trọng của một câu"],[295,"!\" = $%&%'()%*+($\", $.) ( độ tương đồng từng câu so với câu đầu tiên) Trong đó: !\" : là vecto biểu diễn câu thứ i !\" : là điểm FirstRel của câu thứ i 2.4.5 Khối trích rút câu Kết hợp các phương pháp trên ta có công thức cuối cùng để tính điểm cho từng câu:"],[296,"\" = !%&' + !) Trong đó:"],[297,"\" : Trọng số cuối cùng của câu s !\"#$ : Trọng số thu được từ phân tích ma trận NMF !\" : Trọng số thu được từ phân tích các đặc trưng cấu trúc của câu"],[298,"!\" # = &'( # + &*+ # + &,-(#) Trong đó: !\" # : Trọng số đặc trưng cho câu s"],[299,"\" Điểm đặc trưng nội dung (Content)"],[300,"\" : Điểm đặc trưng bề mặt (Surface) !(#) : Điểm đặc trưng độ liên quan (Relevance) !\", !$, !% : lần lượt là các trọng ứng với các đặc trưng về nội dung, bề mặt và liên quan được tính toán và điều chỉnh dựa trên kết quả thực nghiệm"],[301,"2.5 Thực nghiệm 2.5.1 Môi trường thử nghiệm Chương trình được xây dựng và thử nghiệm trên máy tính cá nhân có cấu hình và các phần mềm cần thiết như sau: - Vi xử lý: 2.2 GHz Quad-Core Intel Core i7 Crystalwell - Ram: 16Gb - Hệ điều hành: MacOs Sierra - Phần mềm phát triển: PyCharm - Ngôn ngữ sử dụng: Python - Thư viện tách từ, xử lý từ tiếng Anh: nltk - Thư viện tách từ, tách câu tiếng Việt: vnTokenizer 2.5.2 Phương pháp đánh giá Đánh giá kết quả tóm tắt văn bản là một việc làm khó khăn trong thời điểm hiện tại"],[302,"Việc sử dụng ý kiến đánh giá của các chuyên gia ngôn ngữ được xem là cách đánh giá tốt nhất, tuy nhiên, cách làm này lại tốn rất nhiều chi phí"],[303,"Bên cạnh các phương pháp đánh giá thủ công do các chuyên gia thực hiện, vấn đề đánh giá tự động kết quả tóm tắt cũng nhận được nhiều sự chú ý hiện nay"],[304,"NIST kể từ năm 2000 đã tổ chức hội nghị DUC mỗi năm một lần để thực hiện việc đánh giá với quy mô lớn các hệ thống tóm tắt văn bản"],[305,"Việc đánh giá tựu động này nhằm mục đích là tìm ra được một độ đo đánh giá tóm tắt gần với những đánh giá của con người nhất.Trong bài toán này em lựa chọn phương pháp Rouge để làm thước đo đánh giá độ chính xác cho cả bài toán tóm tắt văn bản tiếng Anh lẫn tóm tắt văn bản tiếng Việt"],[306,"Recall Oriented Understudy (ROUGE) là một phương pháp do Lin và Hovy đưa ra vào năm 2003 cũng dựa trên các khái niệm tương tự"],[307,"Phương pháp này sử dụng n-gram để đánh giá sự tương quan giữa các kết qủa của mô hình tóm tắt và tập dữ liệu đánh giá"],[308,"Phương pháp này đã cho ra kết quả khả quan và được sự đánh giá cao của cộng đồng nghiên cứu tóm tắt văn bản"],[309,"ROUGE-N là một thu hồi n-gram (n-gram recall) giữa một bản tóm tắt tự động và một tập các tài liệu tóm tắt tham chiếu (ReferenceSummaries)"],[310,"ROUGE-N được tính như sau: \"#$%&-( = *+,-./0123 456789:0/;=={?@A@:@82@=B//0:C@D} *+,-.(45678)9:0/;=={?@A@:@82@=B//0:C@D} Trong đó: n là chiều dài của n-gram Countmatch(gramn) là số lượng tối đa n-gram có thể xảy ra đồng thời trong bản tóm tắt tự động và bản tóm tắt tham chiếu"],[311,"Rõ ràng ROUGE-N là một độ đo liên quan đến độ recall bởi vì mẫu số của vế phải trong công thức trên là tổng số n-gram xảy ra ở phía bản tóm tắt tham chiếu"],[312,"Cũng có một lưu ý rằng, số lượng n-gram ở mẫu số trong công thức tính ROUGE-N sẽ tăng lên khi chúng ta cho thêm nhiều tham chiếu"],[313,"Điều này hoàn toàn trực quan và hợp lí bởi vì có thể tồn tại nhiều bản tóm tắt tốt"],[314,"Mỗi khi chúng ta thêm một tham chiếu vào tập các văn bản tham chiếu, chúng ta đã mở rộng không gian các văn bản tóm tắt thay thế (alternative summaries)"],[315,"Bằng cách điều khiển các kiểu tham chiếu mà ta thêm vào tập văn bản tham chiếu, chúng ta có thể thiết kế các đánh giá tập trung vào các khía cạnh khác nhau của việc tóm tắt"],[316,"Ngoài ra, tổng tử số lớn hơn tổng số số bản tóm tắt tham chiếu"],[317,"Điều này hiệu quả vì cung cấp thêm nhiều trọng số để matching các n-grams xảy ra trong đa tham chiếu"],[318,"Do đó, một bản tóm tắt tự động càng chứa nhiều những từ được xuất hiện trong nhiều bản tóm tắt tham chiếu thì sẽ dành được điểm ROUGE-N càng cao"],[319,"Điều này một lần nữa lại rất trực quan và hợp lí bởi vì chúng ta thường ưu tiên các bản tóm tắt tự động càng có nhiều nét giống với các điểm giống nhau giữa các bản tóm tắt tham chiếu càng tốt"],[320,"Khi sử dụng đa tham chiếu, chúng ta tính ROUGE-N theo từng cặp, giữa bản tóm tắt tự động s và từng bản tóm tắt tham chiếu ri trong tập các văn bản tóm tắt tham chiếu"],[321,"Sau đó, kết quả điểm ROUGE-N cuối cùng trong đa tham chiếu sẽ là điểm ROUGE-N cao nhất trong tất cả các cặp được tính"],[322,"Điều này có thể được thể hiện theo công thức sau: !\"#$%-' = )*+,)-.!\"#$%-' *., 0 Trong quá trình khởi tạo, thuật toán đánh giá sử dụng thủ tục Jackknifing"],[323,"Cho M tham chiếu, chúng ta tính điểm tốt nhất khi duyệt qua M tập tham chiếu M- 1; điểm ROUGE-N cuối cùng là trung bình cộng của M điểm ROUGE-N đối với các tham chiếu M-1"],[324,"Thủ tục Jackknifing được chọn bởi chúng ta thường cần so sánh hiệu suất giữa con người và hệ thống và bản tóm tắt tham chiếu thường chỉ do con người tóm tạo ra"],[325,"Bằng cách áp dụng thủ tục này, chúng ta có thể ước lượng hiệu suất trung bình của con người bằng việc lấy trung bình cộng M điểm ROUGE-N của một bản tham chiếu với toàn bộ M-1 tham chiếu"],[326,"2.5.3 Thực nghiệm trên dữ liệu văn bản tiếng Anh 2.5.3.1 Dữ liệu thực nghiệm Dữ liệu được sử dụng trong chương trình là bộ dữ liệu DUC2007"],[327,"Đây là các bài báo tin cậy phủ rộng trong nhiều lĩnh vực"],[328,"Bộ dữ liệu gồm 43 bản ghi, mỗi bản ghi gồm khoảng 10 văn bản, ứng với mỗi bản ghi lại có 3 bản tóm tắt"],[329,"Đồ án sử dụng tập dữ liẹu DUC2007 như là một tập dữ liệu để kiểm tra"],[330,"Document Understanding Conference (DUC) là một hội nghị quốc tế để đánh giá hiệu suất của hệ thống tóm tắt bằng cách so sánh bản tóm tắt bằng tay của các chuyên gia với bản tóm tắt tự động của máy tính"],[331,"DUC2007 là bộ dữ liệu dùng cho tác vụ tóm tắt đa văn bản, gồm 50 bản ghi, mỗi bản ghi gồm nhiều văn bản có cùng chủ đề"],[332,"Để phù hợp với bài toán đặt ra ta coi mỗi bản ghi đó là một đơn văn bản"],[333,"Bản tóm tắt cũng gồm 50 bản ghi, mỗi bản có độ dài 250 từ"],[334,"Trong quá trình tiền xử lý dữ liệu em sử dụng thư viện ntlk cho quá trình tách từ, loại bỏ stopword, lemmatized"],[335,"Phần tách câu được bỏ qua do bộ dữ liêu đã chia câu sẵn trong các thẻ xml"],[336,"2.5.3.2 Kết quả thực nghiệm Đồ án tập trung vào việc nghiện cứu kết hợp phương pháp tóm tắt không giám sát đại diện là phương pháp phân tích ma trận NMF với phương pháp tóm tắt dựa trên các đặc trưng cấu trúc"],[337,"Rouge Feature Rouge-1 (%) Rouge-2 (%) Relevance 41.92 10.48 Surface 39.04 9.29 Content 42.37 10.69 Từ bảng kết qủa trên cho chúng ta nhận xét trong 3 đặc trưng thì đặc trưng Content cho chất lượng văn bản tóm tắt tốt nhất, 42.37% với Rouge-1 và 10.69% với Rogue-2"],[338,"Đặc trưng Relevance có độ quan trọng thứ 2 với điểm số gần như tương tự 41.92% với Rouge-1 và 10.48% với Rouge-2 Rouge Feature Rouge-1 (%) Rouge-2 (%) NMF 41.67 9.99 3 features 41.56 10.42 NMF + 3 features 42.34 10.77 Khi kết hợp cả 2 phương pháp với nhau hệ thống cho kết qủa tốt nhất với điểm Rouge-2 là 10.77% và Rouge-1 là 42.34%"],[339,"Từ bản trên ta cũng có thể thấy phương pháp NMF đơn thuần cho kết quả cao hơn với phương pháp đặc trưng cấu trúc 41.67% với 41.56% Qua kết quả trên chúng ta có thể rút ra được nhận xét: Trong phạm vi nghiên cứu, đồ án đã chứng minh được phương pháp kết hợp cả 2 hướng tiếp cận NMF và cấu trúc mang kết qủa tốt hơn khi sử dụng đơn lẻ từng phương pháp Do tính đặc trưng của ngôn ngữ học, sự kết hợp các đặc trưng cấu trúc không phải luôn tuân theo quy luật tỉ lệ thuận giữa điểm ROUGE-1 và ROUGE-2"],[340,"Việc kết hơp cả 3 phương pháp đặc trưng cấu trúc không hẳn là một lựa chọn tốt do làm giảm hiệu năng khi so sách với trường hợp sử dụng từng đặc trưng một"],[341,"2.5.4 Thực nghiệm trên dữ liệu văn bản tiếng Việt 2.5.4.1 Dữ liệu thực nghiệm Dữ liệu trong bài toán sử dụng là hơn một triệu văn bản từ Báo Mới"],[342,"Sau đó chọn ra 100 văn bản để tóm tắt"],[343,"Tách riêng phần lead + head của bài báo và coi đó là văn bản tóm tắt đúng"],[344,"Phần giữ lại chính là đầu vào của bài toán"],[345,"Đồ án sử dụng tập dữ liệu được chọn ra từ hơn một triệu văn bản từ Báo Mới"],[346,"Bộ dữ liệu Báo Mới có dung lượng 3.64GB được chia thành 1000 bản ghi, mỗi bản ghi gồm hơn 1000 văn bản được chia cắt bởi kí tự #"],[347,"Bản thân bộ dữ liệu cũng đã được tiền xử lý qua trước, 2 câu đầu tiên của mỗi văn bản là tiêu đề(heading) và phần miêu tả (description), từ câu thứ 3 trờ đi là phần nội dung của văn bản"],[348,"Bước đầu tiên của quá trình tiền xử lý là phải tách riêng từng văn bản từ tập 1000 bản ghi, sau đó loại bỏ những văn bản trùng lặp"],[349,"Chọn trong tập văn bản những văn bản thoả mãn điều kiện có số từ tổng cộng ở phần headline + description trong khoảng 240-260 từ, phần này sau đó sẽ được tách ra để làm dữ liệu đánh giá kết qảu của chương trình"],[350,"Phần nội dung văn bản cũng phải thoả mãn có độ dài trung bình từ 1300 đến 1400 từ"],[351,"Sau quá trình này thu được 140 văn bản từ tập hơn 1 triệu văn bản thoả mãn yêu cầu"],[352,"Trước khi đưa vào NMF 140 văn bản trên được tiền xử lý tiếp qua các bước tách câu, tách từ, lowercase, loại bỏ kí tự đặc biệt"],[353,"Phần tách câu và tách từ em sử dụng công cụ vnTokenizer phiên bản 4.1.1 của Tiến sĩ Lê Hồng Phương"],[354,"Bộ cung cụ được viết bằng java có các chức năng chính như tách từ, tách câu, gán nhãn từ loại với độ chính xác khoảng 98%"],[355,"Phần lowercase và loại bỏ kí tự đặc biệt được thực hiện qua phương thức clean_text def clean_text(text): text = text.lower() text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE) text = re.sub(r'\\<a href', ' ', text) text = re.sub(r'&amp;', '', text) text = re.sub(r'[\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text) text = re.sub(r'<br />', ' ', text) text = re.sub(r'\\'', ' ', text) return text 2.5.4.2 Kết quả thực nghiệm Rouge Feature Rouge-1 (%) Rouge-2 (%) Relevance 53.33 10.35 Surface 53.98 10.58 Content 54.87 11.25 Đặc trưng Content vẫn cho kết quả tốt nhất như với bài toán tóm tắt văn bản cho tiếng Anh 54.87% với Rouge 1 và 11.25% đối với Rouge 2"],[356,"Đặc trưng Surface với bài toán tóm tắt tiếng Việt lại cho kết quả cao hơn so với đặc trưng Relevance 0.65% cho Rouge 1 và 0.23% cho Rouge 2 trong khi bài toán tóm tắt với tiếng Anh đặc trưng Relevance lại cho kết qủa cao hơn so với Surface"],[357,"Nguyên nhân có thể được giải thích do tập dữ liệu đầu vào của 2 bài toán có cấu trúc khác nhau"],[358,"Đối với bài toán tóm tắt văn bản cho tiếng Anh dữ liệu đầu vào là các văn bản có chung chủ đề được ghép lại với nhau còn dữ liệu cho bài toán tóm tắt bằng tiếng Việt chỉ có một văn bản duy nhất"],[359,"Rouge Feature Rouge-1 (%) Rouge-2 (%) NMF 53.23 10.33 3 features 54.07 10.31 NMF + 3 features 54.57 11.53 Khi kết hợp cả 2 phương pháp với nhau hệ thống cho kết qủa tốt nhất với điểm Rouge-2 là 11.53% và Rouge-1 là 54.57%"],[360,"Việc kết hợp 2 cách tiếp cận vẫn đem lại kết quả tốt hơn khi áp dụng đơn lẻ với từng phương pháp khi áp dụng cho ngôn ngữ tiếng Việt"],[361,"Và việc kết hợp cả 3 phương pháp đặc trưng vẫn cho kết quả thấp hơn một số đặc trưng đơn lẻ, việc này là do các trọng số từng đặc trưng vẫn chưa được tối ưu một cách tốt nhất"],[362,"2.6 Tóm tắt chương Chương này đã đưa ra một cái nhìn tổng quan về các kĩ thuật: Phân tích ma trận, các đặc trưng cấu trúc của văn bản trong vấn đề khai phá dữ liệu văn bản mà cụ thể là bài toán Tóm tắt văn bản tự động"],[363,"Ứng dụng phương pháp này cho cả 2 ngôn ngữ tiếng Anh và tiếng Việt"],[364,"Đồ án đã đề suất một cách tiếp với bài toán tóm tắt văn bản dựa vào trích xuất bằng cách sử dụng ma trận không âm NMF kết hợp với trích suất đặc trưng và chứng minh được tính hiệu quả của phương pháp khi áp dụng trên cả 2 ngôn ngữ tiếng Việt và tiếng Anh"],[365,"Các thí nghiệm của em được thực hiện với các kịch bản khác nhau bằng bộ dữ liệu DUC2007 cho tiếng Anh và bộ dữ liệu Báo Mới cho tiếng Việt"],[366,"Kết quả thí nghiệm cho thấy khi NMF được kết hợp với ba loại đặc trưng câu (đặc trưng bề mặt, đặc trưng độ liên quan, đặc trưng nội dung)"],[367,"Các phép đo Rouge-1 và Rouge-2 của hệ thống tăng 0.67% và 0.78% so với NMF cơ bản khi thử nghiệm trên bộ dữ liệu tiếng Anh và 1.34% và 1.2% khi thử nghiệm trên bộ dữ liệu tiếng Anh"],[368,"Kết quả của chương này đã được viết thành bài báo Enhancing extractive summarization using non-negative matrix factorization with semantic aspects and sentence features và đã được accept ở hội nghị SoIct 2017[1] CHƯƠNG 3 PHƯƠNG PHÁP TÓM TẮT VĂN BẢN SỬ DỤNG DEEP LEARNING 3.1 Giới thiệu công nghệ học sâu Trong những năm qua, thuật ngữ \"deep learning\" (học sâu) đã dần len lỏi trong các cuộc hội thảo khi bàn về trí tuệ nhân tạo (AI), dữ liệu lớn (Big Data) và phân tích (Analytics)"],[369,"Đây là một cách tiếp cận đầy hứa hẹn tới AI khi phát triển các hệ thống tự trị, tự học, những thứ đang cách mạng hóa nhiều ngành công nghiệp"],[370,"Nếu coi ta học máy (machine learning) là công nghệ tiên tiến nhất, thì học sâu là \"tiên tiến của tiên tiến\""],[371,"Học máy lấy một vài ý tưởng cốt lõi của trí tuệ nhân tạo và tập trung vào việc giải quyết các vấn đề thế giới thực với các mạng thần kinh được thiết kế để bắt chước khả năng đưa ra quyết định của chúng ta"],[372,"Học sâu, đúng như tên gọi của nó, đi sâu hơn nữa vào một tập hợp các công cụ và kỹ thuật học máy, từ đó áp dụng chúng để giải quyết bất kỳ vấn đề nào đòi hỏi \"khả năng tư duy\" con người hay nhân tạo"],[373,"Về cơ bản, học sâu là cho một hệ thống máy tính \"ăn\" rất nhiều dữ liệu, để chúng có thể sử dụng và đưa ra các quyết định về những dữ liệu khác"],[374,"Dữ liệu này được nạp thông qua các mạng thần kinh, tương tự như học máy"],[375,"Những mạng lưới này các cấu trúc logic yêu cầu một loạt các câu hỏi đúng/sai, hoặc trích xuất một giá trị số, của mỗi bit dữ liệu đi qua chúng và phân loại theo các câu trả lời nhận được"],[376,"Vì công việc của học sâu là tập trung phát triển những mạng lưới này, chúng đã trở thành \"mạng thần kinh sâu\" (Deep Neural Network) những mạng logic phức tạp cần thiết để xử lý các bộ dữ liệu lớn, như thư viện hình ảnh của Google hay Instagram"],[377,"Với các bộ dữ liệu toàn diện như vậy, và các mạng logic phức tạp để xử lý phân loại chúng, việc một chiếc máy tính lấy một hình ảnh và nhận dạng với độ chính xác cao trở nên \"quá đỗi bình thường\""],[378,"Các hình ảnh là ví dụ tuyệt vời nhất về cách thức hoạt động của học sâu, vì chúng có chứa nhiều yếu tố khác nhau và để hiểu rõ được làm thế nào để máy tính, với não bộ một chiều chủ yếu dựa trên sự tính toán, có thể học cách giải thích chúng giống như con người"],[379,"Tuy vậy, học sâu có thể được áp dụng cho bất kỳ hình thức dữ liệu nào âm thanh, video, lời nói, chữ viết,.."],[380,"để đưa ra những kết luận như thể do con người thực hiện với tốc độ rất nhanh"],[381,"Chúng ta hãy thử xem xét một số ví dụ thực tiễn"],[382,"Giả sử một hệ thống được thiết kế để tự động ghi nhận và báo cáo có bao nhiêu chiếc xe của một mẫu xe nhất định đã đi ngang qua một con đường"],[383,"Trước tiên, nó sẽ được quyền truy cập vào một cơ sở dữ liệu khổng lồ về các loại xe, bao gồm hình dáng, kích thước và thậm chí là tiếng của động cơ"],[384,"Điều này có thể được biên soạn theo cách thủ công hoặc, trong các điều kiện tiên tiến hơn, được thu thập tự động bởi hệ thống nếu như nó được lập trình để tìm kiếm trên internet và lấy dữ liệu mà nó tìm thấy ở đó"],[385,"Tiếp theo, nó sẽ lấy dữ liệu cần được xử lý dữ liệu trong thế giới thực có chứa thông tin chi tiết cần nắm bắt, trong trường hợp này là bởi các camera và microphone bên đường"],[386,"Bằng cách so sánh dữ liệu từ cảm biến với những dữ liệu mà nó đã \"học được\", nó có thể phân loại, với một độ chính xác nhất định, từng loại xe đã đi qua con đường đó"],[387,"Trên đây là một ví dụ cụ thể, ngoài ra học sâu còn có thể ứng dụng ở trong rất nhiều các lĩnh vực khác như: Cung cấp khả năng điều hướng cho xe tự lái: Với hệ thống cảm biến và phần mềm phân tích trên buồng lái, các xe tự lái có thể học cách nhận dạng những chướng ngại vật có trên đường và có giải pháp xử lý thích hợp bằng cách sử dụng học sâu"],[388,"Phục chế màu cho ảnh đen trắng: thông qua việc dạy cho máy tính cách nhận biết các vật thể và cách mà mắt người nhìn chúng, các hình ảnh và video đen trắng sẽ có thể được tái hiện lại với đầy đủ các màu sắc phù hợp"],[389,"Dự đoán kết quả của các thủ tục pháp lý: Một nhóm các nhà nghiên cứu người Anh và Mỹ đã có thể dự đoán chính xác kết quả của một phiên tòa, sau khi hệ thống máy tính của họ được nạp sẵn những thông tin cơ bản của vụ án"],[390,"Thuốc đặc trị: Các kỹ thuật học sâu hiện đang được dùng để phát triển các loại thuốc đã được chỉnh sửa sao cho phù hợp với bộ gen của bệnh nhân"],[391,"Phân tích và báo cáo tự động: Các hệ thống có thể phân tích dữ liệu và báo cáo những thông tin chi tiết của chúng dưới dạng âm thanh tự nhiên hoặc ngôn ngữ của con người"],[392,"Chơi trò chơi: Các hệ thống học sâu đã và đang được dạy cách chơi (và giành chiến thắng) các trò chơi như cờ vây, Breakout của Atari hay Starcraft"],[393,"3.2 Cơ sở lý thuyết 3.2.1 Mạng neural nhân tạo (Artificial neural network) Mạng Nơron nhân tạo (Artificial Neural Network- ANN) là mô hình xử lý thông tin được mô phỏng dựa trên hoạt động của hệ thống thần kinh của sinh vật, bao gồm số lượng lớn các Nơron được gắn kết để xử lý thông tin"],[394,"ANN giống như bộ não con người, được học bởi kinh nghiệm (thông qua huấn luyện), có khả năng lưu giữ những kinh nghiệm hiểu biết (tri thức) và sử dụng những tri thức đó trong việc dự đoán các dữ liệu chưa biết (unseen data)"],[395,"Kiến trúc chung của một mạng nơron nhân tạo (ANN) gồm 3 thành phần đó là: Input Layer, Hidden Layer và Output Layer (Xem Trong đó, lớp ẩn (Hidden Layer) gồm các Nơron nhận dữ liệu input từ các Nơron ở lớp (Layer) trước đó và chuyển đổi các input này cho các lớp xử lý tiếp theo"],[396,"Trong một ANN có thể có nhiều lớp ẩn"],[397,"Trong đó các Processing Elements (PE) của ANN gọi là Nơron, mỗi Nơron nhận các dữ liệu vào (Inputs) xử lý chúng và cho ra một kết quả (Output) duy nhất"],[398,"Kết quả xử lý của một Nơron có thể làm Input cho các Nơron khác"],[399,"- Quá trình xử lý thông tin của một ANN: + Inputs (dữ liệu vào): Mỗi Input tương ứng với 1 thuộc tính (attribute) của dữ liệu (patterns)"],[400,"Trong các mô hình mạng neural hiện tại x thường là một vecto được embedding từ dữ liệu đầu vào"],[401,"+ Output (kết quả): Kết quả của một ANN là một giải pháp cho một vấn đề"],[402,"+ Connection Weights (Trọng số liên kết): Đây là thành phần rất quan trọng của một ANN, nó thể hiện mức độ quan trọng (độ mạnh) của dữ liệu đầu vào đối với quá trình xử lý thông tin (quá trình chuyển đổi dữ liệu từ Layer này sang layer khác)"],[403,"Quá trình học (Learning Processing) của ANN thực ra là quá trình điều chỉnh các trọng số (Weight) của các input data để có được kết quả mong muốn"],[404,"+ Summation Function (Hàm tổng): Tính tổng trọng số của tất cả các input được đưa vào mỗi Nơron (phần tử xử lý PE)"],[405,"Hàm tổng của một Nơron đối với n input được tính theo công thức sau:"],[406,"= $%&% ' %() + Transfer Function (Hàm chuyển đổi): Hàm tổng (Summation Function) hay còn gọi là Activate Function của một Nơron cho biết khả năng kích hoạt (Activation) của Nơron đó còn gọi là kích hoạt bên trong (internal activation)"],[407,"Các Nơron này có thể sinh ra một output hoặc không trong ANN (nói cách khác rằng có thể output của 1 Nơron có thể được chuyển đến layer tiếp trong mạng Nơron hoặc không)"],[408,"Mối quan hệ giữa Internal Activation và kết quả (output) được thể hiện bằng hàm chuyển đổi (Transfer Function)"],[409,"+ Việc lựa chọn Transfer Function có tác động lớn đến kết quả của ANN"],[410,"Một số hàm chuyển đổi phi tuyến hay được sử dụng trong ANN: Linear g(a) = a Sigmoid g(a) = sigm(a) ="],[411,"!\" $%&(-)) Tanh g(a) = tanh(a) = !\"# $ - '() (-$) !\"# $ , !\"#(-$) Rectified Linear g(a) = recline(a) = max (0, a) Step Gaussian Softmax (hàm này rất hay được sử dụng ở layer cuối cùng) Kết quả xử lý tại các Nơron (Output) đôi khi rất lớn, vì vậy transfer function được sử dụng để xử lý output này trước khi chuyển đến layer tiếp theo"],[412,"Đôi khi thay vì sử dụng Transfer Function người ta sử dụng giá trị ngưỡng (Threshold value) để kiểm soát các output của các Nơron tại một layer nào đó trước khi chuyển các output này đến các Layer tiếp theo"],[413,"Nếu output của một nơron nào đó nhỏ hơn giá trị ngưỡng thì nó sẽ không được chuyển đến Layer tiếp theo"],[414,"Trên kia là kiến trúc mạng ANN cơ bản"],[415,"Để phục vụ những bài toán phức tạp ta cũng cần những kiến trúc mạng phức tạp hơn"],[416,"Một số kiến trức mạng phổ biến hiện nay như: Deep Neural Network (DNN) Deep Belief Network (DBN) Deep Boltzmann Machine (DBM) Recurrent Neural Network (RNN) Convolution Neural Network (CNN) Multi-modal/multi-tasking Deep Stacking Network (DSN) Trong các kiến trúc trên em lựa chọn RNN cho bài toán tóm tắt văn bản, do các đặc trưng đặc thù về chuỗi RNN phù hợp với các bài toán về xử lý ngôn ngữ tự nhiên sẽ được nói rõ hơn ở phần 3.2.2 3.2.2 Giới thiệu mạng neural hồi quy RNN Mô hình mạng neural hồi quy RNN là mô hình được áp dụng rất rộng rãi trong các bài toán xử lý ngôn ngữ tự nhiên (NLP)"],[417,"Do mô hình RNN mô hình hoá được bản chất dữ liệu trong NLP"],[418,"Dữ liệu trong NLP có đặc tính chuỗi và có sự phụ thuộc lẫn nhau giữa các thành phần (trạng thái) trong dữ liệu"],[419,"Năng lực tính toán của máy tính ngày càng mạnh nên đã thực hiện thực hoá được việc huấn luyện mạng neural hồi quy vốn yêu cầu nhiều bước tính toán hơn mạng neural thông thường"],[420,"Việc áp dụng RNN có thể được coi là một bước đột phá trong NLP"],[421,"Ý tưởng đằng sau RNN là sử dụng thông tin dạng chuỗi"],[422,"Trong một mạng neural truyền thống chúng ta giả định rằng tất cả các đầu vào đều độc lập với nhau, nhưng mô hình này không phù hợp trong nhiều bài toán"],[423,"Ví dụ nếu muốn đoán từ tiếp theo có thể xuất hiện trong một câu thì ta cũng cần biết các từ trước đố xuất hiện lần lượt thế nào"],[424,"RNN được gọi là hồi quy bởi lẽ chúng thực hiện cùng một tác vụ cho tất cả các phần tửu của một chuỗi với đầu ra phụ thuộc vào cả các phép tính trước đó"],[425,"Nói các khác, RNN có khả năng nhớ các thông tin được tính toán trước đó"],[426,"Trên lý thuyết RNN có thể sử dụng được thông tin của một văn bản rất dài, tuy nhiên thực tế thì nó chỉ có thể nhớ được một vài bước trước đó mà thôi"],[427,"Về cơ bản một mạng RNN sau khi phân tích ra sẽ có dạng như sau: Mô hình trên mô tả phép triển khai nội dung của một RNN"],[428,"Triển khai ở đây có thể hiểu đơn gỉản là ta vẽ ra một mạng nơ-ron chuỗi tuần tự"],[429,"Ví dụ ta có một câu gồm 5 chữ Tôi yêu quê hương tôi, thì mạng nơ-ron được triển khai sẽ gồm 5 tầng nơ-ron tương ứng với mỗi chữ một tầng"],[430,"Lúc đó việc tính toán bên trong RNN được thực hiện như sau: !\" là đầu vào tại bước t"],[431,"Ví dụ !\" là một vec-tơ one-hot tương ứng với từ thứ 2 của câu (yêu)"],[432,"!\" là trạng thái ẩn tại bước t"],[433,"Nó chính là bộ nhớ của mạng"],[434,"!\" được tính toán dựa trên cả các trạng thái ẩn phía trước và đầu vào tại bước đó: !\" = %('(\" + !\"#$% )"],[435,"Hàm f thường là một hàm phi tuyến như tang, sigmoid hay ReLu"],[436,"Để làm phép toán cho phần tử ẩn đầu tiên ta cần khởi tạo them !\"# , thường giá trị khởi tạo được gắn bằng 0"],[437,"!\" là đầu ra tại bước t, Ví dụ, ta muốn dự đoán từ tiếp theo có thể xuất hiện trong câu thì !\" chính là một vec-tơ xác xuất các từ trong danh sách từ vựng của ta: !\" = %!&'()*(,%\") Vector đầu ra !\" sẽ được sử dụng cho những dự đoán tiếp theo như dự đoán sentiment của một câu hay dự đáon từ loại của từng từ vựng trong câu (PoS Tagging) Việc huấn luyện mạng neural hồi quy được thực hiện qua 2 bước: Duỗi thẳng mạng neural hồi quy Sử dụng thuật toán backpropagation để tính đạo hàm một phần (gradient) của hàm mất mát ( giống như mạng neural thông thường )"],[438,"Một điểm nổi bật của RNN chính là ý tưởng kết nối các thông tin phía trước để dự đoán cho hiện tại"],[439,"Việc này tương tự như ta sử dụng các cảnh trước của bộ phim để hiểu được cảnh hiện thời"],[440,"Đôi lúc ta chỉ cần xem lại thông tin vừa có thôi là đủ để biết được tình huống hiện tại"],[441,"Ví dụ, ta có câu: Các đám mây trên bầu trời thì ta chỉ cần đọc tới các đám mây trên bầu là đủ biết được chữ tiếp theo là trời rồi"],[442,"Trong tình huống này, khoảng cách tới thông tin có được cần để dự đoán là nhỏ, nên RNN hoàn toàn có thể học được"],[443,"Nhưng trong nhiều tình huống ta buộc phải sử dụng nhiều ngữ cảnh hơn để suy luận"],[444,"Ví dụ dự đoán chữ cuối cùng trong đoạn : I grew up in France"],[445,"I speak fluent French."],[446,"Rõ ràng là các thông tin gần (I speak fluent) chỉ có phép ta biết được đằng sau nó sẽ là tên của một ngôn ngữ nào đó, còn không thể nào biết được đó là tiếng gì"],[447,"Muốn biết là tiếng gì, thì ta cần phải có thêm ngữ cảnh I grew up in France nữa mới có thể suy luận được"],[448,"Rõ ràng là khoảng cách thông tin lúc này có thể đã khá xa rồi"],[449,"Về mặt lý thuyết, rõ ràng là RNN có khả năng xử lý các phụ thuộc xa (long- term dependencies)"],[450,"Chúng ta có thể xem xét và cài đặt các tham số sao cho khéo là có thể giải quyết được vấn đề này"],[451,"Tuy nhiên, đáng tiếc trong thực tế RNN có vẻ không thể học được các tham số đó"],[452,"Vấn đề này đã được khám phá khá sâu bởi Hochreiter (1991) và Bengio, et al.(1994) trong các bài báo của mình, họ đã tìm được nhưng lý do căn bản để giải thích tại sao RNN không thể học được"],[453,"3.2.3 Mạng LSTM Mạng bộ nhớ dài-ngắn (Long Short Term Memory networks), thường được gọi là LSTM - là một dạng đặc biệt của RNN, nó có khả năng học được các phụ thuộc xa"],[454,"LSTM được giới thiệu bởi Hochreiter và Schmidhuber (1997), và sau đó đã được cải tiến và phổ biến bởi rất nhiều người trong ngành"],[455,"Chúng hoạt động cực kì hiệu quả trên nhiều bài toán khác nhau nên dần đã trở nên phổ biến như hiện nay"],[456,"LSTM được thiết kế để tránh được vấn đề phụ thuộc xa (long-term dependency)"],[457,"Việc nhớ thông tin trong suốt thời gian dài là đặc tính mặc định của chúng, chứ ta không cần phải huấn luyện nó để có thể nhớ được"],[458,"Tức là ngay nội tại của nó đã có thể ghi nhớ được mà không cần bất kì can thiệp nào"],[459,"Mọi mạng hồi quy đều có dạng là một chuỗi các mô-đun lặp đi lặp lại của mạng nơ- ron"],[460,"Với mạng RNN chuẩn, các mô-dun này có cấu trúc rất đơn giản, thường là một tầng tanh"],[461,"LSTM cũng có kiến trúc dạng chuỗi như vậy, nhưng các mô-đun trong nó có cấu trúc khác với mạng RNN chuẩn"],[462,"Thay vì chỉ có một tầng mạng nơ-ron, chúng có tới 4 tầng tương tác với nhau một cách rất đặc biệt"],[463,"Bước đầu tiên của LSTM là quyết định xem thông tin nào cần bỏ đi từ trạng thái tế bào"],[464,"Quyết định này được đưa ra bởi tầng sigmoid - gọi là tầng cổng quên (forget gate layer)"],[465,"Nó sẽ lấy đầu vào là \"#$ và !\" rồi đưa ra kết quả là một số trong khoảng [0,1] cho mỗi số trong trạng thái tế bào !\"#$"],[466,"Đẩu ra là 1 thể hiện rằng nó giữ toàn bộ thông tin lại, còn 0 chỉ rằng toàn bộ thông tin sẽ bị bỏ đi"],[467,"Quay trở lại với ví dụ mô hình ngôn ngữ dự đoán từ tiếp theo dựa trên tất cả các từ trước đó, với những bài toán như vậy, thì trạng thái tế bào có thể sẽ mang thông tin về giới tính của một nhân vật nào đó giúp ta sử dụng được đại từ nhân xưng chuẩn xác"],[468,"Tuy nhiên, khi đề cập tới một người khác thì ta sẽ không muốn nhớ tới giới tính của nhân vật nữa, vì nó không còn tác dụng gì với chủ thế mới này"],[469,"Bước tiếp theo là quyết định xem thông tin mới nào ta sẽ lưu vào trạng thái tế bào"],[470,"Việc này gồm 2 phần"],[471,"Đầu tiên là sử dụng một tầng sigmoid được gọi là tầng cổng vào (input gate layer) để quyết định giá trị nào ta sẽ cập nhập"],[472,"Tiếp theo là một tầng tanh tạo ra một véc-tơ cho giá trị mới !\" nhằm thêm vào cho trạng thái"],[473,"Trong bước tiếp theo, ta sẽ kết hợp 2 giá trị đó lại để tạo ra một cập nhập cho trạng thái"],[474,"Chẳng hạn với ví dụ mô hình ngôn ngữ của ta, ta sẽ muốn thêm giới tính của nhân vật mới này vào trạng thái tế bào và thay thế giới tính của nhân vật trước đó"],[475,"Giờ là lúc cập nhập trạng thái tế bào cũ !\"#$ thành trạng thái mới !\""],[476,"Ở các bước trước đó đã quyết định những việc cần làm, nên giờ ta chỉ cần thực hiện là xong"],[477,"Ta sẽ nhân trạng thái cũ với !\" để bỏ đi những thông tin ta quyết định quên lúc trước"],[478,"Sau đó cộng thêm !\"*$\""],[479,"Trạng thái mơi thu được này phụ thuộc vào việc ta quyết định cập nhập mỗi giá trị trạng thái ra sao"],[480,"Với bài toàn mô hình ngôn ngữ, chính là việc ta bỏ đi thông tin về giới tính của nhân vật cũ, và thêm thông tin về giới tính của nhân vật mới như ta đã quyết định ở các bước trước đó"],[481,"Cuối cùng, ta cần quyết định xem ta muốn đầu ra là gì"],[482,"Giá trị đầu ra sẽ dựa vào trạng thái tế bào, nhưng sẽ được tiếp tục sàng lọc"],[483,"Đầu tiên, ta chạy một tầng sigmoid để quyết định phần nào của trạng thái tế bào ta muốn xuất ra"],[484,"Sau đó, ta đưa nó trạng thái tế bảo qua một hàm tanh để co giá trị nó về khoảng [1,1], và nhân nó với đầu ra của cổng sigmoid để được giá trị đầu ra ta mong muốn"],[485,"Với ví dụ về mô hình ngôn ngữ, chỉ cần xem chủ thể mà ta có thể đưa ra thông tin về một trạng từ đi sau đó"],[486,"Ví dụ, nếu đầu ra của chủ thể là số ít hoặc số nhiều thì ta có thể biết được dạng của trạng từ đi theo sau nó phải như thế nào"],[487,"3.2.4 Mô hình sequence to sequence Mạng RNN được sử dụng như một mô hình ngôn ngữ để dự đoán các phần tử trong tương lai của chuỗi được cho trước"],[488,"Tuy nhiên chúng ta vẫn thiếu các thành phần cần thiết để xây dựng các mô hình dịch bởi vì chúng ta mới chỉ xử lý trên một chuỗi duy nhất trong khi bản dịch cần phải xử lý trên cả 2 dãy chuỗi nhập và chuỗi dịch"],[489,"Mô hình sequence to sequence được xây dựng bằng việc thêm một bước mã hoá (encoder) và một bước giải mã (decoder)"],[490,"Ở bước encoder mô hình sẽ chuyển đổi chuỗi đầu vào thành một biểu diễn cố định"],[491,"Trong bước decoder, một mô hình ngôn ngữ sẽ học từ cả chuỗi đầu ra (ví dụ như câu văn đã được dịch) và chuỗi biểu diễn cố định sinh ra từ bước mã hoá"],[492,"Do mô hình decoder nhìn thấy cả chuỗi biểu diễn cố định sinh ra từ chuỗi đầu lẫn chuỗi dịch, nên nó có thể sinh ra những dự đoán thông minh hơn về các từ tương lai dựa trên từ hiện tại"],[493,"Ví dụ, trong mô hình ngôn ngữ cơ bản, chúng ta gặp từ đi nhưng không thể chắc rằng từ đó đang nói về một hành động của con người là đi lại hay đang ám chỉ một người đã ra đi (đã chết)"],[494,"Tuy nhiên nếu chúng được cho qua một ngữ cảnh mã hoá, lớp giải mã có nhận ra rằng chuỗi đầu vào đang ám chỉ việc người đã mất chứ không phải ám chỉ hành động đi lại"],[495,"Với ngữ cảnh, bộ decoder có thể chọn từ kế tiếp thích hợp và cung cấp bản dịch chính xác hơn"],[496,"Bây giờ chúng ta cần phải hiểu cách thức hoạt động cơ bản của mô hình sequence to sequence, chúng ta sẽ nhắc lại về cách xây dựng một mô hình mạng neural cơ bản"],[497,"Ở bước mã hoá (encoder) chúng ta sẽ sử dụng một mạng RNN"],[498,"Mạng RNN này sẽ xử lý chuỗi đầu vào, sau đó sẽ chuyền đầu ra cho lớp giải mã (decoder) như là một biến ngữ cảnh"],[499,"Lớp giải mã cũng là một mạng RNN"],[500,"Nó có nhiệm vụ xem chuỗi đầu vào đã được dịch và từ đứng trước đó sau đó cố gắng dự đoán từ tiếp theo trong chuỗi giải mã"],[501,"Sau khi huấn luyện chúng ta có thể tạo ra bản dịch bằng cách mã hoá chuỗi đầu vào chúng ta muốn dịch và sau đó chạy mạng sinh chuỗi"],[502,"Mô hình mạng sequence to sequence được miêu tả như hình dưới: 3.2.5 Kĩ thuật attention Hãy bắt đầu với khái niệm chú ý (attention) trong thế giới thực"],[503,"Mỗi ngày, con người tiếp nhận rất nhiều dữ kiện đầu vào"],[504,"Thật ngạc nhiên bộ não của chúng ta có thể làm giảm lượng lớn dữ kiện đó đó thành những thông tin hữu dụng từ đó chúng ta có đưa ra các quyết định"],[505,"Những nghiên cứu gần đây chỉ ra rằng các quy trình tương tự được áp dụng trong mô hình mạng neural cho phép chúng ta tập trung vào những thông tin quan trọng trong khi có thể lọc được những dữ liệu không cần thiết"],[506,"Kĩ thuật này được gọi là attention, nó giúp chúng ta xây dựng các mạng neural có thể giải quyết hiệu quả các thách thức trước đây với bài toán xử lý chuỗi như là dịch máy hay tóm tắt văn bản điều mà mô hình sequence to sequence bình thường không thực hiện được"],[507,"Mô hình sequence to sequence cho chúng ta khả năng xử lý các chuỗi đầu vào và đầu ra"],[508,"Nhưng việc nén toàn bộ chuỗi đầu vào vào một vecto cố định duy nhất là khá khó khăn"],[509,"Hơn nữa trạng thái cuối cùng của bộ mã hoá chưa phần lớn thông tin từ những phần tử cuối cùng của chuỗi mã hoá"],[510,"Do đó nó có phần thiện vị về phía cuối của chuỗi mã hoá và có thể bỏ lỡ mất những thông tin quan trọng ở phần đầu của chuỗi"],[511,"Thay vì nén toàn bộ chuỗi đầu vào thành một vectơ ngữ cảnh cố định chúng ta có thể sử dụng kĩ thuật attention"],[512,"Kĩ thuật này sẽ lưu giữ toàn bộ các trạng thái từ phần mã hoá và đưa cho từng phần tử của bộ giải mã giá trị trọng số trung bình của các trạng thái mã hoá"],[513,"Ban đầu tất cả các trạng cuối cùng của chuỗi mã hoá đầu vào đều được giữ lại"],[514,"Trong suốt quá trình giải mã chúng ta sẽ lấy trạng thái của mạng giải mã kết hợp với trạng thái của bộ mã hoá và chuyền vào mạng feedforward"],[515,"Mạng này sẽ trả về danh sách các trọng số cho từng trạng thái encoder"],[516,"Chúng ta sẽ nhân encoder input với các trọng số sau đó tính trung bình có trọng số của các encoder states"],[517,"Kết quả ngữ cảnh này sau đó sẽ được chuyền đến lớp giải mã"],[518,"Mạng decoder của chúng ta bây giờ có thể sử dụng các phần khác nhau của chuỗi giải mã trong quá trình sinh chuỗi decoder thay vì chỉ sử dụng một vecto ngữ cảnh cố định"],[519,"Điều này cho phép mạng tập trung vào những phần quan trọng nhất của chuỗi đầu vào thay vì toàn bộ chuỗi đầu vào, do đó tạo ra các dự đoán thông minh hơn cho từ tiếp theo trong chuỗi giải mã"],[520,"Hình dưới sẽ mô tả cụ thể kĩ thuật này: 3.2.6 WordEmbedding WordEmbedding là một trong những phương diện nghiên cứu thú vị nhất của phương pháp học sâu trong xử lý ngôn ngữ tự nhiên"],[521,"Một WordEmbedding là một hàm ánh xạ từ thành các vec-tơ nhiều chiều (200 đến 500 chiều)"],[522,"Ví dụ như: W(cat) = (0.2, -0.4, 0.7,.) W(mat) = (0.0, 0.6, -0.1,.) Thường thì hàm này sẽ là một bảng tra cứu, lưu trữ dưới dạng một ma trận , với W(wn) = n"],[523,"Các vec-tơ trong Word Embedding có các tính chất sau: Số lượng chiều không lớn (so với tập từ vựng) Các từ có chung nét ngữ nghĩa sẽ được về gần nhau trong không gian Mối quan hệ tương đồng ngữ nghĩa được chuyển thành mối quan hệ giống nhau giữa các vec-tơ"],[524,"Trong bài toán này em lựa Word2Vec là phương pháp cho bài khối WordEmbedding.Word2Vec là một phương pháp cụ thể của bài toán WordEmbedding"],[525,"Không sử dụng một tác vụ để kiểm tra một cụm \"5-gram\" có hợp lệ hay không"],[526,"Word2vec lựa chọn việc huấn luyện ra một mạng nơ-ron cho phép dự đoán từ (hoặc các từ) từ các từ lân cận cho trước (có thể gồm nhiều hoặc một từ) và ngược lại"],[527,"Về khối kết cấu, Word2Vec là 1 mạng nơ-ron cạn gồm 1 lớp ẩn"],[528,"Có 2 kiến trúc là hội tụ và phân kì từ xung quanh để tạo ra mô hình Word2vec là CBOW và Skip-gram"],[529,"Ngoài ra, thực tế còn có các phương pháp cải tiến nhằm tối ưu hóa hiệu quả tính toán Một cách tổng quát về Word2Vec: Biểu diễn phân tán cho từ Học ra một vec-tơ giá trị thực (real-valued vector) cho từng từ Đưa những từ có ý nghĩa giống nhau về gần nhau Một ứng dụng đơn giản của của mạng nơ-ron 2 lớp 3.3 Các vấn đề của mô hình sequence to sequence và kĩ thuật attention Mạng RNN cơ bản chỉ đi theo một chiều duy nhất là từ đầu chuối đến cuối chuỗi"],[530,"Ví dụ để dự đoán từ còn thiếu trong câu thì việc không thể chỉ xem xét phần trước mà phải xem xét cả các phần tử đứng đằng sau"],[531,"Kích thước tập từ điển rất lớn, nhất là khi dữ liệu train ngày càng tăng lên đến vài triệu bản"],[532,"Việc chọn kích thước tập từ điển ảnh hưởng rất nhiều đến hiệu năng của mạng hơn nữa"],[533,"Chọn kích thước quá lớn thì làm tăng thời gian huấn luyện mạng lên rất nhiều, quá nhỏ thì lại không đủ độ chính xác cho bài toán"],[534,"Việc chọn những từ nào xuất hiện trong từ điển cũng là một bài toán nan giải"],[535,"Số lượng trọng số trong mạng gần như tăng tuyến tính theo kích thước của tập từ điển (và Trong quá trình huấn luyện những từ nằm ngoài từ điển sẽ bị dán nhãn <unk> và nếu chỉ dùng mạng RNN đơn thuần thì chuỗi đầu ra sau khi sinh sẽ bị mất mát thông tin"],[536,"Đôi khi những từ xuất hiện ít trong tập dữ liệu nhưng lại mang nhiều thông tin quan trọng như tên riêng, thời gian,"],[537,"Khác biệt lớn nhất giữa quá trình huấn luyện và dự đoán là việc dự đoán kí tự !\""],[538,"Trong quá trình huấn luyện !\" sẽ được sinh ra từ việc kết hợp với kí tự đứng trước nó là !\"#$ còn trong quá trình suy luận là từ kí tự !\"#$ được suy ra từ mô hình"],[539,"Mạng RNN (hay các biến thể như LSTM) thường được huấn luyện để tối đa hoá khả năng tạo ra các chuỗi đích từ chuỗi đầu vào, vì thế mô hình có thể sinh ra những dự đoán tồi do gặp phải những không gian mà nó chưa bao giờ nhìn thấy"],[540,"Một vấn đề nữa ở kĩ thuật attention cơ bản đó là việc tính toán ngữ cảnh cũng như tính toán trọng số đều dùng chung một lớp ẩn đầu vào"],[541,"Việc này sẽ làm cho các trọng số không thể hiện được hoàn toàn vai trò của từng kí tự trong chuỗi đầu vào"],[542,"3.4 Mô hình đề xuất Lấy cảm hứng từ mô hình rất thành công trong mô hình dịch máy, em đã kết hợp mô hình mạng ngôn ngữ với một mô hình mã hoá ngữ cảnh"],[543,"Hơn nữa bản chất mô hình sequence to sequence được cấu thành từ mạng RNN, mô hình mạng này rất phù hợp cho các bài toán về xử lý chuỗi tuần tự, có khả năng lưu trữ thông tin của toàn bộ chuỗi đầu vào"],[544,"Bộ mã hoá được áp dụng thêm kĩ thuật attention, kĩ thuật này sẽ giúp tìm kiếm những sự liên kết tiềm ẩn trong văn bản đầu vào, giúp hệ thống có thể tập trung vào những dữ kiện quan trọng như tên riêng, số, ."],[545,"qua đó giúp giảm lượng thông tin cần ghi nhớ"],[546,"Và để giải quyết một số vấn đề của mô hình attention encoder decoder như đã đề cập ở phần trên trong phần này cũng đề xuất một số giải pháp để cải tiến chất lượng mô hình"],[547,"3.4.1 Khối tiền xử lí dữ liệu Do muốn máy có thể học cách sử dụng ngôn ngữ như con người nên phần lowercase và loại bỏ các dấu câu như :"],[548,""],[549,", được bỏ qua"],[550,"Chỉ sử dụng tách từ và tách câu sử dụng 2 công cụ giống như đã nêu ở phần 0 Từ điển được sử dụng trong mô hình có kích thước 40000 từ"],[551,"Lớp mã hoá từ token từ sang vecto embedding có số chiều là 400"],[552,"Để phục vụ cho các tác vụ phía sau từ điển cũng như các từ ngoài từ điển được sắp xếp theo thứ tự về số lần xuất hiện của chúng trong văn bản"],[553,"Sau khi xử lý xong thì ta thu được tập từ có số lượng rất lớn lên đến 350 nghìn từ"],[554,"40000 từ có số lần xuất hiện nhiều nhất sẽ được chọn vào trong tập từ điển và được thay đổi theo từng batch-size"],[555,"Ta cũng quy ước 2 kí tự đặc biệt empty và eos (kí tự báo hiệu kết thúc câu) là 2 kí tự đầu tiên trong từ điển"],[556,"Vấn đề tiếp theo cần phải giải quyết đó là xử lý những từ nằm trong tập từ điển của embedding nhưng lại không có trong tập từ điển của dữ liệu chúng ta"],[557,"Đối với những từ này ta sẽ tính giá trị trung bình của toàn bộ trọng số ebedding hiện tại gọi là scale, sau đó sinh vecto 400 chiều ngẫu nhiên tương ứng trong khoảng từ - scale đến scale"],[558,"Ở bước tiền xử lý này chúng ta cũng lưu trữ tập các từ nằm ngoài từ điển nhưng có độ tương đồng cao với các từ có trong tập từ điển"],[559,"Trong mô hình này em đề xuất ngưỡng tương đồng là 0.5 3.4.2 Khối huấn luyện mô hình encoder-decoder Chúng ta sử dụng kiến trúc encoder-decoder như đã miêu tả ở phần 3.2.4"],[560,"Kiến trúc này gồm 2 phần bộ mã hoá (encoder) và bộ giải mã (decoder)"],[561,"Cả 2 phần đều là các mạng RNN"],[562,"Bộ mã hoá sẽ truyền vào từng từ một trong văn bản đầu vào"],[563,"Mỗi từ sau đó sẽ được đi qua một lớp embedding để biểu diễn từ đó về dạng vecto số, trong bài toán này em sử dụng embedding là w2v 400 chiều trên tập dữ liệu Báo Mới)"],[564,"Vecto này sau đó sẽ được đi qua các lớp ẩn, ở mỗi lớp nó lại được kết hợp với những lớp ẩn được sinh ra từ token phía trước, đối với từ đầu tiên thì tất cả các giá trị này đều bằng 0"],[565,"Bộ giải mã sẽ nhận layer ẩn cuối cùng của bộ mã hoá kết hợp với token <eos> (kí tự kết thúc câu) là đầu vào"],[566,"Sau đó bộ giải mã sẽ sinh từng từ một sử dụng lớp softmax và kĩ thuật attention"],[567,"Bộ giải mã sẽ dừng lại khi sinh đến kí tự <eos>"],[568,"Hàm mất mát em sử dụng trong bài toán là hàm log loss: -\"#$ & '(,"],[569,""],[570,""],[571,", ',' .(, ."],[572,""],[573,""],[574,", ., = - \"#$ & '0 '(, ."],[575,""],[576,""],[577,", '0-(, .(,"],[578,""],[579,"., ,' 01( Trong đó: x là chuỗi đầu vào y là chuỗi đầu ra Ở đây xảy ra vấn đề mất kết nối giữa quá trình huấn luyện và kiểm thử khi mà trong quá trình giải mã ở huấn luyện từ tiếp theo được sinh ra sau khi truyền vào từ đứng trước nó trong headline gốc còn ở quá trình kiểm thử là từ được sinh ra từ mô hình"],[580,"Để giải quyết vấn đề này em sử dụng kĩ thuật flip"],[581,"Ta sẽ úp ngẫu nhiên một số từ ở phần headline và thay nó bằng từ được dự đoán từ mô hình hiện tại"],[582,"Tuy nhiên ở giai đoạn đầu huấn luyện mô hình chưa được tốt nên việc này có thể làm chậm lại quá trình huấn luyện, nên kĩ thuật này sẽ được sử dụng sau khi mô hình đã tương đối tốt"],[583,"Trong suốt quá trình kiểm thử chúng ta sử dụng giải thuật beam-search khi sinh từ một, ở mỗi bước sẽ sinh ra 10 chuỗi có xác suất cao nhất"],[584,"Trong quá trình xử lý dữ liệu đầu vào, có những từ ít xuất hiện nằm ngoài vocab sẽ bị dán nhãn <unk>, điều này làm có thể dẫn đến làm mất mát nhiều thông tin quan trọng"],[585,"Trong mô hình này em xử lý vấn đề này bằng 2 cách"],[586,"Nếu gặp phải một từ nằm ngoài tập từ điển đầu tiên sẽ kiểm tra xem nó có nằm trong tập các từ có độ tương đồng cao (đã được nêu trong phần 3.4.1) với các từ có trong từ điển hay không, nếu có ta sẽ chọn từ có độ tương đồng cao nhất"],[587,"Nếu không nằm trong tập này sẽ kiểm tra phân loại và gán nhãn cho từ này vào các thẻ <time> nếu token đó là định dạng thời gian, <url> nếu token là các đường dẫn, các trường hợp còn lại (hầu hết là tên riêng) được gán vào nhãn <oov>"],[588,"Sau quá trình giải mã nếu trong mã giải có những token kia ta sẽ truy ngược lại văn bản đầu vào để khôi phục chúng theo nhãn được gán từ quá trình tiền xử lý"],[589,"Chúng ta sử dụng mạng 4 lớp LSTM ẩn"],[590,"Mỗi lớp ẩn có kích thước là 512 units"],[591,"Các trọng số trong mô hình được khởi tạo giá trị trong khoảng [-0.1;0.1]"],[592,"Learning rate là 0.01 và hàm optimize là giải thuật Adam 3.4.3 Kĩ thuật attention Kĩ thuật attention giúp cho mạng neural có thể ghi nhớ chính xác những nội dung quan trọng một cách chính xác hơn"],[593,"Khi sinh mỗi từ output kĩ thuât này sẽ tính trọng số cho mỗi từ trong input phụ thuộc vào sự chú ý của từ đó đến từng từ trong chuỗi đầu vào"],[594,"Cơ chế cụ thể đã được miêu tả trong phần 3.4.3"],[595,"Trọng số attention cho input word ở bước thứ t được tính như sau: !\"#' % = ()*(,-#"],[596,",/#' ) ()*(,-#"],[597,",/#' )"],[598,"# Trong đó \"# đại diện cho layer cuối cùng được sinh ra sau khi truyền vào t từ , \"#' đại diện cho layer cuối cùng của bước hiện tại của modul giải mã Lưu ý rằng ở cách thông thường việc tính toán trọng số attention và tính vecto ngữ cảnh đều dùng chung các lớp ẩn (hidden units)"],[599,"Vì vậy em đề suất biến đổi kĩ thuật này một chút được gọi là simple attention"],[600,"Với kĩ thuật này ta sẽ tách layer cuối cùng ở mỗi input thành 2 phần"],[601,"Phần đầu có kích thước 40 được sử dụng để tính toán trọng số attention, phần còn lại được sử dụng để tính vecto ngữ cảnh"],[602,"Tương tự cho layer cuối cùng ở modul decoder"],[603,"Ngoài những thay đổi công thức tính toán trọng số vẫn được giữ nguyên"],[604,"3.5 Thực nghiệm 3.5.1 Môi trường thực nghiệm Chương trình được xây dựng và thử nghiệm trên máy tính cá nhân có cấu hình và các phần mềm cần thiết như sau: - Vi xử lý: 2.2 GHz Quad-Core Intel Core i7 Crystalwell - Ram: 16Gb - Hệ điều hành: MacOs Sierra - Phần mềm phát triển: PyCharm - Ngôn ngữ sử dụng: Python - Card đồ hoạ: GeForce GTX 1060 6Gb Ram - Bộ thư viện dùng cho quá trình huấn luyện model: Keras chạy trên nền thư viện TensorFlow - Bộ công cụ tách từ tiếng Việt: pyvi của tác giả Trần Việt Trung 3.5.2 Thư viện TensorFlow Tensorflow là một thư viện mã nguồn mở cung cấp khả năng xử lý tính toán số học dựa trên biểu đồ mô tả sự thay đổi của dữ liệu"],[605,"Tensor được sử dụng khi ta cần giải quyết các bài toán supervised learning"],[606,"Tensorflow được Google phát triển và phát hành tháng 10 năm 2015"],[607,"Các mô hình deeplearning phát triển trên TensorFlow có thể được sử dụng trên nhiều các loại platform khác nhau (từ smartphone tới distributed servers) và trên CPUs lẫn GPUs"],[608,"Trong TensorFlow mọi kiểu dữ liệu đều được quy về một mối được gọi là Tensor"],[609,"Vậy nên có thể hiểu được phần nào tên gọi của thư viện TensorFlow là một thư viện mô tả, điều chỉnh dòng chảy của các Tensor"],[610,"Tensor là một kiểu dữ liệu dạng mảng có nhiều chiều"],[611,"Ví dụ Tensor = [[[1,1,1] ,[178,62,74]] ,[[45,2,2] ,[19,0,17]] ,[[7,5,2],[0,11,4]],[[8,13,5],[1,6,7]]]"],[612,"Mảng nhiều chiều này được đính kèm them một vài thuộc tính tham chiếu khác"],[613,"Các thuộc tính của Tensor được mô tả trong tài liệu gồm: device: Tên của thiết bị mà Tensor hiện tại sẽ được xuất bản"],[614,"Có thể None"],[615,"graph: Đồ thị chứa Tensor hiện tại"],[616,"name: Tên của Tensor hiện tại"],[617,"shape: Trả về TensorShape mô tả lại Shape của Tensor hiện tại"],[618,"op: Operation được sử dụng để xuất bản Tensor hiện tại"],[619,"dtype: Kiểu của các phần tử trong Tensor hiện tại"],[620,"3.5.3 Thư viện Keras Keras là một API cấp cao được viết trên Python và có khả năng trên nền của các thư viện khác như TensorFlow,CNTK hay Theano"],[621,"Thư viện này giúp những ai mới nghiên cứu về mạng neural tiếp cận một cách dễ hơn và trực quan hơn"],[622,"Keras cho phép chúng ta dễ dàng khởi tạo, cấu hình hay mở rộng các model, nó cũng hỗ trợ rất tốt cho cả 2 mô hình CNN ( convolutional network ) và RNN (recurrent networks)"],[623,"3.5.4 Dữ liệu thực nghiệm Mô hình sử dụng bộ dữ liệu gồm một triệu văn bản từ Báo Mới"],[624,"Bộ word2vec đã được huận luyện cũng từ tập dữ liệu Báo Mới"],[625,"Mỗi văn bản được tách thành 3 phần: Headline, Description và Content"],[626,"Vì mô hình chưa có khả năng lưu trữ một lượng thông tin đầu vào lớn nên sẽ chỉ tập trung vào việc sinh tiêu đề(headline) từ phần miêu tả(description)"],[627,"Do đó phần Headline và Description sẽ được tách ra để phục vụ cho mục đích của bài toán"],[628,"Bộ dữ liệu Báo Mới có dung lượng 3.64GB được chia thành 1000 bản ghi, mỗi bản ghi gồm hơn 1000 văn bản được chia cắt bởi kí tự #"],[629,"Bản thân bộ dữ liệu cũng đã được tiền xử lý qua trước, 2 câu đầu tiên của mỗi văn bản là tiêu đề(heading) và phần miêu tả (description), từ câu thứ 3 trờ đi là phần nội dung của văn bản"],[630,"Phần heading và description sẽ được giữ lại để làm dữ liệu huấn luyện và test"],[631,"Bước đầu tiên của quá trình tiền xử lý là phải tách riêng từng văn bản từ tập 1000 bản ghi, sau đó loại bỏ những văn bản trùng lặp"],[632,"Bộ dữ liệu ban đầu có tất cả 1175154 văn bản, sau khi loại bỏ các văn bản trùng lặp dữ liệu còn lại 980204 văn bản"],[633,"Sau đó lấy ngẫu nhiên 3000 văn bản ra để làm tập dữ liệu test validation Sau quá trình tiền xử lý như đã đề cập ở mục 3.3.2 dữ liệu sẽ được đóng gọi dưới đinh dạng .pkl"],[634,"3.5.5 Phương pháp đánh giá Đối với bài toán này em vẫn lựa chọn Rouge làm phương pháp đo độ chính xác"],[635,"Phương pháp này đã được nêu chi tiết ở phần 2.5.2.2 3.5.6 Kết quả thực nghiệm Đồ án sẽ tập trung vào việc so sánh 2 model: model attention encoder- decoder gốc được tạo bởi Rush và đồng nghiệp với model đó sau khi đã được cải tiến bằng một số kĩ thuật đã được nêu ra ở mục 3.3.3 Rouge Feature Rouge-1 (%) Rouge-2 (%) Model gốc 28.32 6.66 Model cải tiến 33.60 12.21 Từ kết quả bảng trên ta có thể thấy việc áp dụng một số cải tiến vào mô hình huấn luyện đã đem lại hiệu quả"],[636,"Sau khi cải tiến model tăng 5.28% với Rouge1 và 5.55% với Rouge2"],[637,"Tuy nhiên điểm độ đo Rouge vẫn chưa thực cao, nguyên nhân là do phép đo Rouge so khớp kí tự của bản do người tóm tắt với máy tóm tắt, mà đặc trưng của phương pháp tóm tăt abtract là không phải trích rút từ những câu những từ có sẵn trong văn bản đầu vào"],[638,"Dưới đây là một số kết quả của model cuối cùng sau thời gian huấn luyện 1 tuần Văn bản đầu vào Tiêu đề gốc Tiêu đề do máy dự đoán Ngày 20/5 , Phái_đoàn thường_trực Việt_Nam bên cạnh Liên_hiệp quốc , Tổ_chức Thương_mại Thế_giới ( WTO ) và các tổ_chức quốc_tế khác tại Geneva , Thụy_Sĩ , đã ra thông_cáo về những diễn_biến gần đây ở biển Đông và gửi đến Văn_phòng Liên_hiệp_quốc tại Geneva , các tổ_chức quốc_tế cùng các cơ_quan báo_chí có trụ_sở tại Geneva"],[639,"Việt_Nam gửi thông_cáo về biển Đông lên LHQ Việt_Nam gửi thông_cáo về tình_hình Biển_Đông Nghị_quyết về mức giá các loại đất năm 2011 vừa được HĐND TP thông_qua , áp_dụng từ ngày 1.1.2011^"],[640,"Theo đó , giá đất nhiều khu_vực trung_tâm thành_phố ( quận Ninh_Kiều^ ) tăng gần gấp đôi so với năm 2010"],[641,"Giá đất nhiều khu_vực nội ô tăng gần gấp đôi Giá đất tại Cần_Thơ tăng Trong lúc đang đánh_bắt hải_sản ở vùng đảo Hoàng_Sa , tàu Trung_Quốc bất_ngờ xuất_hiện và tấn_công tàu cá của ngư_dân Quảng_Ngãi"],[642,"Tàu cá Quảng_Ngãi tiếp_tục bị tàu Trung_Quốc tấn_công Tàu cá ngư_dân Trung_Quốc tấn_công trên biển Một máy_bay của Hãng hàng không Malaysia mất_tích khi bay vào không_phận Việt_Nam Máy_bay chở 227 hành_khách đã rơi cách đảo Thổ_Chu 300 km Máy_bay Malaysia mất_tích : Máy_bay đã gặp nạn Báo Telegraph ( Anh ) rút ra năm bài_học từ trận Bayern_Munich ( B.M ) hạ Manchester United ( M.U ) 3-1 ở tứ_kết lượt về Champions_League"],[643,"5 bài_học từ trận M.U thua Bayern David_Moyes vẫn không được thất_bại Nguyên_nhân của clip phụ_huynh học_sinh đánh nhau tại Hà_Nội khiến nhiều người bất_ngờ"],[644,"Đó là từ câu nói \" xấu lại còn thích thể_hiện \""],[645,"Nữ_sinh và phụ_huynh xô_xát : Từ lời chê xấu gái trên mạng Học_sinh phụ_huynh đánh nhau Hai bảo_mẫu hành_hạ trẻ_em sẽ được xét_xử lưu_động ngày 20/1 tại Hội_trường Nhà thiếu_nhi quận Thủ_Đức"],[646,"Xét_xử lưu_động 2 bảo_mẫu hành_hạ trẻ_em Vụ bảo_mẫu hành_hạ trẻ trẻ Thị_trường chứng_khoán Việt_Nam đã có một tuần giao_dịch khá tích_cực , chỉ_số VN-Index tăng 4,75 % , HNX-Index tăng 2,87^ %"],[647,"Đồng_hành với nhà đầu_tư trong nước , tuần qua , thị_trường đã chứng_kiến những phiên giao_dịch ghi đậm dấu_ấn của khối ngoại"],[648,"Tuần từ 13 - 17/1 : Khối ngoại mua ròng 738,27^ tỷ đồng trên HOSE VN-Index tiếp_tục hồi_phục Ngày 31/3 , Cục Đăng_kiểm Việt_Nam cho biết , đã sửa_đổi Thông_tư 56/2012^ nhằm"]],"downloaded":true,"m":[-1,-1],"n":"20131848_Duong_Viet_Hung_1514557567432.txt","o":"http://storage.googleapis.com/soict20171/cnpm/dhcq/20131848_Duong_Viet_Hung_1514557567432.pdf\r"},{"saved_path":"temp/20122230_Quan_Van_Phu_1496365507040.txt","r":0,"s":[],"t":"\n \r\n\r\n \r\n\r\n1.1 Giới thiệu \r\n\r\n \r\n\r\n Có một mệnh đề phát biểu rằng: Việc có quá nhiều thông tin sẽ làm che lấp \r\n\r\nđi thông tin. So sánh với tình hình hiện nay, thì mệnh đề này có vẻ liên quan và thể \r\n\r\nhiện đúng hơn bao giờ hết. Thực tế, việc có nhiều ngôn ngữ được sử dụng trên Internet \r\n\r\nkhông gây nên vấn đề nhưng lại làm tăng khó khăn của việc phân tích tài liệu. Chính \r\n\r\nvì vậy, tóm tắt văn bản tự động giúp chúng ta xử lý hiệu quả sự tăng lên không ngừng \r\n\r\nvề số lượng thông tin mà con người không đủ năng lực để xử lý. Trong khi đó, các \r\n\r\nbản tóm tắt của các tài liệu online được viết bởi tác giả không phải luôn có sẵn. Trong \r\n\r\nthực tế, các bản tóm tắt có thể được viết bởi chính tác giả của tài liệu hoặc các chuyên \r\n\r\ngia về tóm tắt. Tuy nhiên, việc nhờ các chuyên gia về tóm tắt thực hiện công việc này \r\n\r\nvẫn chưa phải là lựa chọn tốt nhất. Có rất nhiều nguyên nhân giải thích cho điều này, \r\n\r\nnhưng có hai nguyên nhân chính được đề cập đến, đó là: Chi phí trả cho một chuyên \r\n\r\ngia tóm tắt văn bản là rất cao và mức độ tin tưởng của văn bản tóm tắt kiểu này vẫn \r\n\r\ncòn là một chủ đề đang được tranh luận. Bởi vì, việc biết được cách viết một tài liệu \r\n\r\nkhông phải lúc nào cũng tương đương với việc viết được một bản tóm tắt chính xác \r\n\r\nvà súc tích về nội dung. Điều này đặc biệt đúng trong trường hợp tài liệu cần tóm tắt \r\n\r\nliên quan đến những nội dung có tính đặc thù. \r\n\r\n Và dưới đây là những ưu điểm của việc tóm tắt văn bản tự động: \r\n\r\n Tóm tắt làm giảm thời gian đọc \r\n\r\n Các thuật toán tóm tắt có chất lượng đều hơn các bản tóm tắt của con \r\n\r\nngười \r\n\r\n Các bản tóm tắt có thể là hữu ích trong các hệ thống Hỏi - Đáp \r\n\r\n Việc sử dụng các hệ thống tự động hoặc bán tự động có thể tạo nên các \r\n\r\ndịch vụ tóm lược thương mại (enables commercial abstract services) \r\n\r\nlàm tăng số lượng văn bản mà con người có thể xử lý. \r\n\r\n . \r\n\r\n    Bổ sung cho nhận định trên, Viện Tiêu Chuẩn Quốc Gia Hoa Kì (ANSI) chỉ ra \r\n\r\nrằng một tóm lược được chuẩn bị tốt giúp người đọc xác định được nội dung  cơ bản \r\n\r\ncủa tài liệu một cách nhanh hơn và chính xác hơn, cũng như dễ dàng xác định nội \r\n\r\ndung đó có liên quan đến vấn đề mà họ đang quan tâm hay không, do đó quyết định \r\n\r\nnên hay không nên đọc toàn bộ tài liệu này. Thực vậy, báo cáo tại hội nghị \r\n\r\nSUMMAC 2002 đã xác nhận điều này bằng cách chứng minh được rằng: Các bản \r\n\r\ntóm tắt chỉ cần ngắn bằng khoảng 17% độ dài của văn bản gốc thì sẽ làm tăng tốc độ \r\n\r\nra quyết định lên 2 lần mà không có sự suy giảm về độ chính xác trong tỉ lệ xác suất \r\n\r\ncó nghĩa. \r\n\r\n\r\n\r\n2 \r\n\r\n\r\n1.2 Những vấn đề trong bài toán tóm tắt văn bản \r\n\r\n \r\n\r\n Hiện tại, có rất nhiều các hướng tiếp cận, thuật toán được đề xuất để thực hiện \r\n\r\nbài toán tóm tắt văn bản tự động. Xét riêng với tóm tắt đơn văn bản ta đã có các \r\n\r\nphương pháp như: Tóm tắt dựa trên cấu trúc tài liệu, tóm tắt dựa trên mô hình không \r\n\r\ngian vec-tơ. Tuy nhiên, những phương pháp này vẫn còn tồn tại những hạn chế đặc \r\n\r\ntrưng nhất định, ví dụ tóm tắt dựa trên cấu trúc tài liệu chỉ phù hợp cho những tài liệu \r\n\r\ncó cấu trúc rõ ràng như Báo chí, luận văn hay tạp chí khoa học,. Trong khi đó, \r\n\r\nphương pháp tóm tắt dựa trên mô hình không gian vec-tơ lại chưa khai thác được \r\n\r\nnhững nội dung ngữ nghĩa được ẩn đi trong các tình huống tác giả tài liệu thay cách \r\n\r\nsử dụng từ ngữ để nói về cùng một vấn đề. Đây là một trường hợp rất hay được áp \r\n\r\ndụng trong quy tắc hành văn nói chung. Chính vấn đề này đã dẫn đến yêu cầu tìm \r\n\r\nkiếm một giải pháp mới cho cách tiếp cận bài toán tóm tắt văn bản để có thể giải \r\n\r\nquyết những hạn chế này. \r\n\r\n  \r\n\r\n1.3 Giải pháp định hướng \r\n\r\n \r\n\r\n Với sự tiến bộ trong lĩnh vực học máy (Machine Learning) nói chung và học \r\n\r\nsâu (Deep Learning) nói riêng, có rất nhiều phương pháp đã chứng minh được tính \r\n\r\nhiệu quả trong việc giải quyết những bài toán phức tạp mà các cách tiếp cận truyền \r\n\r\nthống chưa thể giải quyết triệt để được. \r\n\r\n Để giải quyết vấn đề khai phá, trích xuất những nội dung ngữ nghĩa được ẩn \r\n\r\nđi trong tài liệu, tôi đề xuất một phương pháp kết hợp các kĩ thuật phân tích văn bản \r\n\r\ntruyền thống với các kĩ thuật của phương pháp học sâu. Từ đó, tôi sẽ thiết kế, xây \r\n\r\ndựng và đánh giá hệ thống tóm tắt văn bản tự động dựa trên cách tiếp cận này. Cụ \r\n\r\nthể, nội dung đồ án sẽ tập trung nghiên cứu, tìm hiểu kĩ thuật Biểu diễn Phân tán  \r\n\r\nDistributed Representation trong phương pháp học sâu và ứng dụng của nó - \r\n\r\nWord2Vec trong việc vec-tơ hóa từ và biểu diễn văn bản. Cuối cùng là kết hợp kĩ \r\n\r\nthuật này với các kĩ thuật phân tích văn bản truyền thống để nâng cao chất lượng bài \r\n\r\ntoán tóm tắt văn bản tự động. \r\n\r\n \r\n\r\n  \r\n\r\n  \r\n\r\n\r\n\r\n3 \r\n\r\n\r\nCHƯƠNG 2 CƠ SỞ LÝ THUYẾT \r\n\r\n \r\n\r\n Trong nội dung của chương này, đồ án sẽ trình bày về các kiến thức cơ bản \r\n\r\nnhất về bài toán tóm tắt văn bản cũng như các thuật toán tóm tắt văn bản thường được \r\n\r\nsử dụng. Chương này cũng trình bày những kiến thức cơ bản về mô hình biểu diễn \r\n\r\nphân tán, và một ứng dụng của nó trong lĩnh vực xử lý ngôn ngữ tự nhiên  Word2Vec \r\n\r\n \r\n\r\n2.1 Bài toán tóm tắt văn bản \r\n\r\n \r\n\r\n2.1.1 Tổng quan \r\n\r\n \r\n\r\n Bài toán tóm tắt văn bản là một trong những bài toán kinh điển trong lĩnh vực \r\n\r\nxử lý dữ liệu văn bản. Xử lý dữ liệu văn bản bao gồm: \r\n\r\n Kiểm tra lỗi chính tả (spelling-checker) \r\n\r\n Kiểm tra lỗi văn phạm (grammar-checker) \r\n\r\n Từ điển đồng nghĩa (thesaurus) \r\n\r\n Phân tích văn bản (text analyzer) \r\n\r\n Phân loại văn bản (text classification) \r\n\r\n Tóm tắt văn bản (text summarization) \r\n\r\n Tổng hợp tiếng  nói (speech synthesis) \r\n\r\n Nhận dạng giọng nói (speech recognization) \r\n\r\n Dịch tự động (automatic translation) \r\n\r\n . \r\n\r\n \r\n\r\n Tóm tắt văn bản là công việc phân tích nội dung của văn bản và sau đó sinh ra \r\n\r\nmột văn bản tóm tắt có kích thước nhỏ hơn văn bản ban đầu, loại bỏ đi những thông \r\n\r\ntin không quan trọng nhưng vẫn đảm bảo giữ được những nội dung cốt lõi của văn \r\n\r\nbản [5]. Do đó để công việc tóm tắt văn bản chính xác cần phải đáp ứng được các yêu \r\n\r\ncầu sau: \r\n\r\n Các văn bản khi phân tích thì phải hiểu được nội dung để xác định \r\n\r\nđược các tiêu chuẩn trong văn bản. \r\n\r\n Các văn bản tóm tắt cần được kiểm tra bằng một thang đo tiêu chuẩn.  \r\n\r\n \r\n\r\n Rõ ràng việc tóm tắt văn bản chính là công việc khai phá dữ liệu văn bản (text \r\n\r\ndata mining).  \r\n\r\n \r\n\r\n\r\n\r\n4 \r\n\r\n\r\n2.1.2 Phân loại các phương pháp tóm tắt văn bản \r\n\r\n \r\n\r\n Một trong những cách phân chia của bài toán tóm tắt là: Tóm tắt đơn văn bản \r\n\r\nvà Tóm tắt đa văn bản. Trong phạm vi đồ án, tôi sẽ tập trung nghiên cứu và áp dụng \r\n\r\ncác kĩ thuật tóm tắt văn bản tự động vào bài toán tóm tắt đơn văn bản vì tính đặc trưng \r\n\r\ncủa các kĩ thuật áp dụng. Thuật toán cho bài toán tóm tắt đa văn bản được điều chỉnh \r\n\r\ncho phù hợp từ cơ sở bài toán tóm tắt đơn văn bản. \r\n\r\n2.1.2.1 Phương pháp tóm tắt trích xuất  Extract summarization \r\n\r\n \r\n\r\n Phương pháp trích xuất bao gồm việc lựa chọn đơn vị của văn bản (câu hay \r\n\r\nđoạn văn), được coi là có chứa lượng thông tin cốt tử của văn bản (informative \r\n\r\ncontent, informativity), và kết nối các đơn vị này theo một trình tự thích hợp. Một \r\n\r\ntrích xuất là sự lắp ghép các đoạn được trích rút ra từ văn bản nguồn. Mục tiêu của \r\n\r\ntrích xuất là cung cấp một cái nhìn tổng quan về nội dung của văn bản gốc. Độ dài \r\n\r\ncủa văn bản tóm tắt bằng trích xuất có thể được xác định bởi tỉ lệ nén, hay nói cách \r\n\r\nkhác Văn bản tóm tắt ngắn hơn bao nhiêu so với văn bản gốc. \r\n\r\n Thuật toán tóm tắt tự động bằng trích xuất có thể chia ra làm 3 mức: surface-\r\n\r\nlevel (mức bề mặt), intermediate-level (mức trung bình) và deep parsing techniques \r\n\r\n(các kĩ thuật phân tích sâu).  \r\n\r\n Tóm tắt trích rút xuất phát từ ý tưởng: Một tài liệu được chia nhỏ thành các \r\n\r\nđơn vị ngữ pháp (các câu văn), sau đó được đánh trọng số theo kinh nghiệm \r\n\r\n(heuristic); Các đơn vị ngữ pháp có điểm cao nhất sẽ được trích rút và liên kết với \r\n\r\nnhau để tạo nên văn bản tóm tắt.  \r\n\r\n Thuật toán tiếp cận ở mức bề mặt: Không đào sâu vào chiều sâu ngôn ngữ \r\n\r\ncủa văn bản, thay vào đó là sử dụng các phần tử ngôn ngữ nhất định để xác \r\n\r\nđịnh các đoạn có liên hệ với nhau trong văn bản. Kĩ thuật của mức bề mặt dựa \r\n\r\nvào sự xuất hiện của từ để đánh trọng số cho các câu. Một kĩ thuật khác dựa \r\n\r\ntrên ý tưởng: Những từ được sử dụng trong tiêu đề của văn bản là quan trọng. \r\n\r\nTrong khi đó, một số kĩ thuật dựa vào vị trí của các đoạn trong văn bản. Kĩ \r\n\r\nthuật này được áp dụng với nhưng văn bản có cấu trúc cố định, như tiêu đề, \r\n\r\ncác mục và các đoạn,... Một số nghiên cứu còn chỉ ra rằng: Dòng đầu tiên luôn \r\n\r\nlà dòng quan trọng nhất trong văn bản đối với các thể loại báo chí. \r\n\r\n Thuật toán tiếp cận mức trung bình: Sử dụng thông tin về ngôn ngữ học \r\n\r\nphức tạp hơn thuật toán tiếp cận mức bề mặt nhưng lại ít phức tạp hơn mức \r\n\r\nphân tích sâu. Một kĩ thuật của dạng này là phát hiện các chuỗi từ vựng. Chuỗi \r\n\r\ntừ vựng là một dãy các từ kết nối với nhau theo quan hệ về ngữ nghĩa. Một \r\n\r\ncách tổng quát, quá trình tóm tắt bao gồm 4 giai đoạn. \r\n\r\n\r\n\r\n5 \r\n\r\n\r\nBốn giai đoạn đó bao gồm:  \r\n\r\n Chia văn bản gốc thành các đoạn (segments). Xây dựng các chuỗi từ \r\n\r\nvựng  lexical chain. \r\n\r\n Xác định các strong chain  chuỗi từ mạnh \r\n\r\n Trích rút các câu chứa các strong chain \r\n\r\n Lắp ghép các câu được trích rút thành văn bản tóm tắt \r\n\r\n Thuật toán phân tích sâu: Dựa trên ý tưởng rằng sử dụng các kĩ thuật chuyên \r\n\r\nsâu về ngôn ngữ để phát hiện ra các cấu trúc rời rạc của văn bản.  \r\n\r\nNhững hệ thống tóm tắt văn bản tự động dựa trên phân tích diễn ngôn bắt \r\n\r\nnguồn từ ý tưởng: Văn bản được định nghĩa bởi cấu trúc trong của nó và các \r\n\r\nmối quan hệ diễn ngôn - phụ thuộc vào ngôn ngữ mà văn bản sử dụng. Những \r\n\r\nhệ thống này cung cấp độ quan trọng nhiều hơn cho các thành phần cốt  tử của \r\n\r\ncác quan hệ rời rạc.  \r\n\r\nSử dụng lý thuyết cấu trúc diễn ngôn (Rhetorical structure theory) chia văn \r\n\r\nbản thành các đơn vị rời rạc sử dụng tập các quan hệ tối thiểu (minimal set of \r\n\r\nrelations). Một khi các cấu trúc rời rạc được xác định, một thuật toán sẽ được \r\n\r\náp dụng để đánh trọng số và thứ tự cho mỗi phần tử trong cấu trúc tựa cây một \r\n\r\ncách rời rạc. Và cuối cùng, các câu với trọng số cao nhất sẽ được lựa chọn để \r\n\r\ntạo nên văn bản tóm tắt. \r\n\r\n2.1.2.2 Phương pháp tóm tắt tóm lược  Abstract summarization \r\n\r\n \r\n\r\n Tuy tóm tắt bằng trích rút đã thành công trong việc xác định câu nào trong văn \r\n\r\nbản đầu vào mang nội dung quan trọng nhưng dường như những phương pháp này \r\n\r\nrất xa với việc tạo ra một bản tóm tắt tối ưu theo nghĩa cả về nội dung và chất lượng \r\n\r\ntrong ngôn ngữ học. Trong khi đó, hệ thống tạo ra văn bản tóm tắt bằng tóm lược dựa \r\n\r\ntrên việc hiểu văn bản gốc và đạt tới việc sinh ra một văn bản mới một cách chính \r\n\r\nxác về ngữ pháp, súc tích và mạch lạc về nội dung, bằng cách sinh ra văn bản tóm tắt \r\n\r\nbằng những từ vựng không xuất hiện trong văn bản gốc. \r\n\r\n Trong tóm lược, việc diễn giải, viết lại các câu phức tạp sẽ nhằm mục đích tạo \r\n\r\nra phiên bản súc tích của nội dung ban đầu. Mặc dù con người có thể tái sử dụng một \r\n\r\nphần văn bản gốc nhưng không phải sử dụng toàn bộ nó; sử dụng các đoạn hay một \r\n\r\nphần của câu thay vì sử dụng toàn bộ câu. \r\n\r\n \r\n\r\n  \r\n\r\n\r\n\r\n6 \r\n\r\n\r\n2.1.3 Phân loại các hướng tiếp cận tóm tắt văn bản \r\n\r\n2.1.3.1 Tiếp cận dựa trên cấu trúc \r\n\r\n \r\n\r\n Hướng tiếp cận này tương ứng với các thuật toán tiếp cận ở mức bề mặt được \r\n\r\nđề cập ở mục 2.1.2.1. Trong mục này sẽ đề cập chi tiết hơn đến những đặc trưng được \r\n\r\nsử dụng trong thuật toán. \r\n\r\n Trong các nghiên cứu gần đây có rất nhiều các đặc trưng hiệu quả của câu văn \r\n\r\nđược đề xuất để dùng cho tóm tắt trích rút, ví dụ như signature word, event hay \r\n\r\nsentence relevance [6]. Mặc dù có nhiều kết quả đáng khích lệ nhưng hầu hết các đặc \r\n\r\ntrưng này được khảo sát một cách độc lập. Tuy nhiên, thực tế mỗi đặc trưng này lại \r\n\r\ncó đóng góp riêng của nó và sự kết hợp các đặc trưng đó lại với nhau có thể thu được \r\n\r\nmột kết quả tốt hơn trong các trường hợp riêng lẻ. Trong Chương 4 của đồ án sẽ trình \r\n\r\nbày các kết quả thực nghiệm để đánh giá và chọn ra những bộ đặc trưng cho kết quả \r\n\r\ntốt nhất đáp ứng với bài toán tóm tắt văn bản. Trong mục này sẽ trình bày chi tiết các \r\n\r\nđặc trưng được xem xét. \r\n\r\n Surface Features  Đặc trưng bề mặt: Nhóm đặc trưng này xem xét đến đặc \r\n\r\nđiểm cấu trúc của câu. Bao gồm: vị trí của câu trong văn bản - thông thường \r\n\r\ncác câu đầu văn bản thường là các câu chứa đựng chủ đề khái quát của cả bài \r\n\r\nvăn; số lượng từ trong câu - căn cứ vào các kiểu văn bản khác nhau, văn bản \r\n\r\nbáo chí, xã luận, hay bài báo khoa học thì câu văn thường có một độ dài trung \r\n\r\nbình nhất định, những câu văn có số lượng từ nhỏ hơn ngưỡng đó sẽ là các câu \r\n\r\nkhông quan trọng; số lượng trích dẫn trong câu - một câu chứa quá nhiều trích \r\n\r\ndẫn là câu không quan trọng. \r\n\r\n Relevance Features  Đặc trưng độ liên quan: Đặc trưng này được sử dụng \r\n\r\nđể tìm ra mối liên hệ giữa các câu. Để làm được điều đó, ta đặt quy ước rằng: \r\n\r\nGiữa các câu luôn tồn tại mối liên hệ với nhau, sẽ có một số câu mang nội \r\n\r\ndung quan trọng hơn các câu khác và khi những câu khác liên quan đến những \r\n\r\ncâu đó thì mức độ quan trọng cũng tăng lên. Tại thời điểm ban đầu, ta có những \r\n\r\ncâu đầu tiên của tài liệu và những câu đầu tiên của đoạn văn là quan trọng. \r\n\r\nThước đo độ liên quan trong trường hợp này là độ tương đồng cosine. \r\n\r\n Content Features  Đặc trưng nội dung: Trong nhóm đặc trưng này, chọn \r\n\r\nđặc trưng Centroid, dựa vào đặc trưng centroid để xác định câu nào tập trung \r\n\r\nvào chủ đề của văn bản. \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n\r\n\r\n7 \r\n\r\n\r\n2.1.3.2 Tiếp cận dựa trên mô hình không gian vec-tơ  VSM \r\n\r\n  \r\n\r\n Khi quá trình tiền xử lí kết thúc và một phương pháp tóm tắt văn bản được lựa \r\n\r\nchọn thì văn bản cần được biểu diễn dưới một dạng nào đó. Trong đó, không gian \r\n\r\nvectơ (Vector Space Model) được sử dụng rộng rãi trong lĩnh vực khai thác thông tin \r\n\r\n(Information retrieval - IR) để biểu diễn tài liệu và các thuật ngữ trong không gian \r\n\r\nvec-tơ tương ứng. \r\n\r\n Mô hình không gian vec-tơ văn bản - Vector space model - là một phương \r\n\r\npháp được đề ra bởi G.Salton, A.Wong và C.S.Yang dùng để biểu diễn văn bản - gồm \r\n\r\ntập hợp các thuật ngữ (term) - dưới dạng một vec-tơ, trong đó các đặc trưng hay chiều \r\n\r\ncủa vec-tơ tương ứng với các thuật ngữ trong văn bản, còn độ lớn hay trọng số của \r\n\r\ncác đặc trưng này được xác định tùy thuộc vào yêu cầu cụ thể của thuật toán sử dụng \r\n\r\nmô hình này. \r\n\r\n Trong cách biểu diễn này, chúng ta sẽ mô phỏng theo mô hình hướng IR, khi \r\n\r\nđó thứ tự các từ là không quan trọng. Mô hình được biết đến một cái tên khác chính \r\n\r\nlà mô hình Bag-of-words. Mỗi word (term) được cung cấp một trọng số , để đo độ \r\n\r\nquan trọng của nó trong tài liệu.  \r\n\r\n Xét một văn bản bất kì di  trong không gian dữ liệu văn bản D. Ta giả thiết \r\n\r\nrằng văn bản di bao gồm ni  thuật ngữ khác nhau ti1, ti2, ...tini. Các thuật ngữ ở đây có \r\n\r\nthể được lấy một cách đơn giản là một tiếng riêng biệt, hay một cụm các tiếng để cấu \r\n\r\ntạo nên một từ đầy đủ ngữ nghĩa. \r\n\r\n Sau khi đã xác định được các thuật ngữ khác nhau của từng văn bản trong bộ \r\n\r\ndữ liệu, ta gọi T là tập hợp các thuật ngữ khác nhau có trong toàn bộ các văn bản cần \r\n\r\nđược xử lí. Giả sử số lượng thuật ngữ có trong tập hợp T là n, do mô hình VSM lấy \r\n\r\nđặc trưng hay chiều của các vec-tơ văn bản tương ứng với các thuật ngữ khác nhau \r\n\r\ncó trong bộ dữ liệu, do đó số chiều của các vec-tơ được biểu diễn từ bộ văn bản trên \r\n\r\nlà n. Mô hình không gian vec-tơ được minh họa trong \r\n Xét văn bản di, đối với mỗi thuật ngữ tj có trong tập hợp các thuật ngữ của bộ \r\n\r\ndữ liệu T, ta xây dựng một hệ số hay trọng số wij tương ứng. Khi đó vec-tơ biểu diễn \r\n\r\ntương ứng của văn bản di là vi = (wi1, wi2, ..., win). Ta gọi V là tập hợp các vec-tơ \r\n\r\nđược biểu diễn từ bộ dữ liệu văn bản cần xử lí. Giả sử bộ dữ liệu bao gồm m văn bản \r\n\r\nkhác nhau, khi đó tập hợp các vec-tơ văn bản V có m vec-tơ n chiều, hay tương đương \r\n\r\nvới một ma trận mxn. \r\n\r\n\r\n\r\n8 \r\n\r\n\r\n \r\n\r\n\r\n \r\n\r\n Sử dụng không gian vec-tơ biểu diễn văn bản: Một số mô hình không gian \r\n\r\nvec-tơ thường được áp dụng trong bài toán xử lý văn bản như: mô hình Boolean, TF, \r\n\r\nIDF, TFxIDF. Để biểu diễn tập văn bản theo các mô hình trên, ta giả sử tập gồm m \r\n\r\nvăn bản: D = {d1, d2,., dm}; mỗi văn bản được biểu diễn dưới dạng một vec-tơ gồm \r\n\r\nn thuật ngữ T = {t1, t2,., tn}; gọi W =  {wij} là ma trận trọng số, trong đó wij là giá trị \r\n\r\ncủa thuật ngữ ti  trong văn bản dj. Khi đó giá trị trọng số được xác định theo từng mô \r\n\r\nhình biểu diễn cụ thể như sau: \r\n\r\n \r\n\r\n Mô hình Boolean: là mô hình biểu diễn vectơ với hàm f cho giá trị rời \r\n\r\nrạc với duy nhất 1 và 0 (đúng/sai). Hàm f(t) tương ứng với thuật ngữ ti \r\n\r\nsẽ cho giá trị đúng nếu và chỉ nếu thuật ngữ ti xuất hiện trong văn bản \r\n\r\nđó. \r\n\r\n \r\n = {\r\n\r\n      1,   \r\n0,   \r\n\r\n \r\n(1) \r\n\r\n \r\n\r\n Mô hình tần suất (Term Frequency - TF): là mô hình mà giá trị wij \r\n\r\nđược tính dựa trên tần số xuất hiện của thuật ngữ trong văn bản. Gọi fij \r\n\r\nlà số lần xuất hiện của thuật ngữ ti trong văn bản dj, khi đó wij được \r\n\r\ntính bởi một trong các công thức: \r\n\r\n  =  . (2) \r\n\r\n \r\n\r\n  = 1 + log (). (3) \r\n\r\n \r\n =  \r\n\r\n(4) \r\n\r\n \r\n\r\n\r\n\r\n9 \r\n\r\n\r\nTrong phương pháp này, trọng số wij tỉ lệ với số lần xuất hiện của thuật \r\n\r\nngữ ti trong văn bản dj. Khi số lần xuất hiện thuật ngữ ti trong văn bản \r\n\r\ndj càng lớn thì điều này có nghĩa là văn bản dj càng phụ thuộc vào thuật \r\n\r\nngữ ti, hay nói cách khác ti mang nhiều thông tin trong văn bản dj. \r\n\r\n \r\n\r\n Mô hình nghịch đảo tần số văn bản (Inverse Document Frequency \r\n\r\n- IDF): Trọng số wij được xác định theo phương pháp này sẽ dựa trên \r\n\r\nđộ quan trọng của thuật ngữ ti trong văn bản dj. Nếu ti xuất hiện trong \r\n\r\ncàng ít văn bản, có nghĩa là nếu nó xuất hiện trong văn bản dj thì trọng \r\n\r\nsố của nó đối với văn bản dj càng lớn hay hàm lượng thông tin trong nó \r\n\r\ncàng lớn.  \r\n\r\n   \r\n\r\n \r\n\r\n = {      \r\nlog\r\n\r\n\r\n\r\n\r\n ,   \r\n\r\n0 ,   \r\n\r\n \r\n\r\n(5) \r\n\r\n   \r\n\r\n  Với m là tổng số văn bản, hi là số lượng văn bản chứa thuật ngữ ti \r\n\r\n \r\n\r\n Mô hình kết hợp IFxIDF: là sự kết hợp hai phương pháp TF và IDF, \r\n\r\ndo đó nó có những ưu điểm của cả hai phương pháp này. Giá trị thành \r\n\r\nphần ma trận trọng số được tính như sau: \r\n\r\n \r\n\r\n = {      \r\n(1 + log())  log\r\n\r\n\r\n\r\n\r\n ,   \r\n\r\n0 ,   \r\n\r\n \r\n\r\n(6) \r\n\r\n \r\n\r\n2.2 Kĩ thuật phân tích ma trận không âm  Non-negative Matrix Factorization \r\n\r\n  \r\n\r\n2.2.1 Cơ sở lý thuyết \r\n\r\n \r\n\r\n Phân tích ma trận không âm - Non-negative matrix factorization là một nhóm \r\n\r\ncác thuật toán phân tích đa biến trong đại số tuyến tính [4]. Ma trận A được phân tích \r\n\r\nthành 2 ma trận W và H với điều kiện là cả 3 ma trận này đều chỉ mang các thuộc \r\n\r\ntính không âm, \r\n\r\n\r\n10 \r\n\r\n\r\n \r\n\r\n\r\n \r\n\r\n Ma trận A được phân tích thành 2 ma trận W và H: \r\n\r\n  =  (7) \r\n\r\n \r\n\r\n Với A là một ma trận mxn, W là một ma trận mxk, và H là một ma trận kxn, \r\n\r\nk luôn được chọn nhỏ hơn m và n, do đó cả 2 ma trận W và H đều có cỡ nhỏ hơn ma \r\n\r\ntrận A. \r\n\r\n Chúng ta sử dụng Frobenius norm như là hàm mục tiêu (objective function) \r\n\r\nđể thỏa mãn điều kiện xấp xỉ A  WH . Frobenius norm được chỉ ra trong công thức \r\n\r\n(Lee & Seung, 1999, 2001): \r\n\r\n \r\n\r\n(, )    \r\n2    (   \r\n\r\n\r\n\r\n=1\r\n\r\n)\r\n\r\n\r\n\r\n=1\r\n\r\n\r\n\r\n=1\r\n\r\n2\r\n\r\n \r\n\r\n(8) \r\n\r\n \r\n\r\n Công thức này có cận dưới bằng 0, và rõ ràng tiến tới 0 khi và chỉ khi A = \r\n\r\nWH. W và H liên tục được cập nhật tới khi E(W,H) hội tụ dưới ngưỡng được định \r\n\r\nnghĩa hoặc vượt quá số lần lặp. Luật cập nhật được chỉ ra dưới đây: \r\n\r\n \r\n\r\n\r\n \r\n  \r\n\r\n()\r\n()\r\n\r\n \r\n(9) \r\n\r\n \r\n\r\n \r\n\r\n\r\n \r\n  \r\n\r\n()\r\n()\r\n\r\n \r\n(10) \r\n\r\n \r\n\r\n Vec-tơ cột A tương ứng với câu thứ j, Aj, có thể được biểu diễn như là một sự \r\n\r\nkết hợp tuyến tính của vec-tơ đặc trưng ngữ nghĩa W*l và biến ngữ nghĩa Hlj như dưới \r\n\r\nđây: \r\n\r\n \r\n =  Hlj\r\n\r\n\r\n\r\n=1\r\n\r\n \r\n(11) \r\n\r\n \r\n\r\n  \r\n\r\n\r\n\r\n11 \r\n\r\n\r\n Ví dụ 1:  \r\n\r\n Chúng ta sẽ lấy một ví dụ để minh họa cho thuật toán NMF: Cho k = 2, số \r\n\r\nbước lặp là 50, và dung sai = 0.001 (tolerance). Các phần tử tại thời điểm ban đầu \r\n\r\ncủa W và H bằng 0.5, ma trận không âm A được phân tích thành 2 ma trận không âm \r\n\r\nW và H, được chỉ ra trong \r\nNMF. Vec-tơ cột A*3 tương ứng với câu thứ 3 được biểu diễn như là sự kết hợp tuyến \r\n\r\ntính của vec-tơ đặc trưng ngữ nghĩa W*l và vec-tơ cột biến ngữ nghĩa (semantic \r\n\r\nvariable column vector) H*3.  \r\n\r\n \r\n\r\n NMF phân tích một ma trận thưa thành hai ma trận thưa. Ở đây tỉ lệ phần tử \r\n\r\nkhác 0 (non-zero ratio) của ma trận có nghĩa là giá trị các phần tử khác 0 chia cho \r\n\r\ntổng số phần tử của ma trận. Ma trận không âm A là 1 ma trận vuông nxn, và giá trị \r\n\r\ncủa n được đặt bằng 100, 200, 300 và 400. Các phần từ khác 0 được chọn một cách \r\n\r\nngẫu nhiên. Số lượng đặc trưng nghĩa nghĩa, r, được chọn là 10% cuả n. Tỉ lệ khác 0 \r\n\r\ncuả A được chọn lần lượt là 0.5%, 1%, 2%, 3%, 5%, 7%, 10%, 30%, 60% và 99%. \r\n\r\nHai ma trận W và H thu được bằng NMF. \r\n\r\n \r\n\r\n        A                            W                                       H                                              A \r\n\r\n[\r\n\r\n1 2 3\r\n4 5 6\r\n7 8 9\r\n\r\n10 11 12\r\n\r\n]   [\r\n\r\n0.1487 1.5998\r\n0.6610 0.9676\r\n1.1481 0.5727\r\n1.6129 0.4066\r\n\r\n]  [\r\n6.1136 6.6784 7.1784\r\n0.0854 0.5923 1.2245\r\n\r\n] = [\r\n\r\n1.0457 1.9420 3.0263\r\n4.1237 4.9813 5.9297\r\n7.0679 8.0071 8.9470\r\n9.8953 11.0127 12.0759\r\n\r\n] \r\n\r\n               A*3      W*1       W*2                                  H*3                                                                        \r\n\r\n \r\n\r\n\r\n \r\n\r\n            A*3        H13         W*1             H23           W*2 \r\n\r\n[\r\n\r\n3\r\n6\r\n9\r\n\r\n12\r\n\r\n]  7.1784  [\r\n\r\n0.1487\r\n\r\n0.6610\r\n\r\n1.1481\r\n\r\n1.6129\r\n\r\n] + 1.2245  [\r\n\r\n1.5998\r\n0.9676\r\n0.5727\r\n0.4066\r\n\r\n] \r\n\r\n \r\n\r\n\r\n \r\n\r\n  \r\n\r\n  \r\n\r\n\r\n\r\n12 \r\n\r\n\r\n2.2.2 Áp dụng phân tích ma trận không âm vào phân tích văn bản \r\n\r\n \r\n\r\n \r\nđề Tourism in Greate Britain (Hoa 2005). \r\n\r\n \r\n\r\n \r\n\r\nMột số câu Câu văn \r\n\r\nS1 \r\n\r\nTOURIST arrivals to the UK in 1991 are forecast to recover \r\n\r\nsharply after the steep decline earlier this year cause by the Gufl \r\n\r\nwar. The British Tourist Authority said incoming tourist numbers \r\n\r\nhad already increased significantly after falling 18 percent in the \r\n\r\nfirst two months of this year from the levels of the corresponding \r\n\r\nperiod of 1990 \r\n\r\nS2 \r\n\r\nThe increases were achived in spite of a fall in the number of \r\n\r\nvisitors from western Europe rose 12 percent to 23 m  higher \r\n\r\nthan in any previous first quarter. A RECORD 185 m tourists \r\n\r\nvisited Britain in the 12 months to March, 8 percent more than \r\n\r\nthe previous year and the British Tourist Authority said yesterday \r\n\r\nthat it was expecting even higher numbers this year \r\n\r\n. . \r\n\r\nS20 \r\n\r\nThe increase were achieved in spite of a fall in the number of \r\n\r\nNorth American visitors Visits by North Americans fell 6 percent \r\n\r\nto 600,000 in the first quarter. However, the number of visitors \r\n\r\nfrom western Europe rose 12 percent to 23 m  higher than in any \r\n\r\nprevious first quarter. A RECORD 185 m tourists visited Britain \r\n\r\nin the 12 months to March, 8% more than the previous year  and \r\n\r\nthe British Tourist Authority said yesterday that it was expecting \r\n\r\neven higher numbers this year \r\n\r\n. . \r\n\r\n \r\n\r\n\r\n  \r\n\r\n\r\n\r\n13 \r\n\r\n\r\n \r\n\r\nSTT Thuật ngữ \r\nS\r\n\r\n1 \r\n\r\nS\r\n\r\n2 \r\n\r\nS\r\n\r\n3 \r\n\r\nS\r\n\r\n4 \r\n\r\nS\r\n\r\n5 \r\n\r\nS\r\n\r\n6 \r\n\r\nS\r\n\r\n7 \r\n\r\nS\r\n\r\n8 \r\n\r\nS\r\n\r\n9 \r\n\r\nS \r\n\r\n10 \r\n. \r\n\r\nS \r\n\r\n20 \r\n. \r\n\r\nS \r\n\r\n57 \r\n\r\n1 Tourist 3 2 0 2 1 0 0 0 0 0 . 2 . 1 \r\n\r\n2 Arrival 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n\r\n3 UK 1 1 0 0 1 0 0 0 0 0 . 0 . 1 \r\n\r\n4 Forecast 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n\r\n5 Recover 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n\r\n6 Sharply 1 0 0 0 0 0 0 0 0 0  0 . 0 \r\n\r\n7 Steep 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n\r\n8 Decline 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n\r\n9 Earlier 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n\r\n10 Year 2 2 1 0 0 1 0 0 0 0 . 2 . 0 \r\n\r\n11 Cause 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n\r\n12 Gulf 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n\r\n13 War 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n\r\n14 British 1 2 0 1 1 0 0 0 0 0 . 1 . 0 \r\n\r\n15 Authority 1 1 0 1 1 0 0 0 0 0 . 1 . 1 \r\n\r\n16 Income 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n\r\n17 Increase 1 1 0 0 0 0 0 0 0 0 . 1 . 0 \r\n\r\n18 Significantly 1 0 0 0 0 0 0 0 0 0 . 0 . 0 \r\n\r\n. . . . . . . . . . . . . . . . \r\n\r\n396 Return 0 0 0 0 0 0 0 0 1 0 . 0  0 \r\n\r\n \r\n\r\n\r\n \r\n\r\n \r\nbộ tập các câu trong \r\nDễ dàng nhận thấy trong \r\ntrận rất thưa. \r\n\r\n  \r\n\r\n\r\n\r\n14 \r\n\r\n\r\nThuật ngữ \r\n\r\nĐặc trưng ngữ nghĩa Câu S20 \r\n\r\nW*1 W*2 W*3 . W*10 Original  20\r\n10\r\n\r\n=1\r\n \r\n\r\n. . . . . . . . .  \r\n\r\n13 War 0 0 0 . 0.04 0  0.11 \r\n\r\n14 British 0 0.68 0.44 . 0.13 1  0.89 \r\n\r\n15 authority 0 0.60 0 . 0 1  1.05 \r\n\r\n16 income 0 0 0.35 . 0.03 0  0.11 \r\n\r\n17 increase 0.07 0 0 . 0.76 1  1.01 \r\n\r\n. . . . . . . . .  \r\n\r\n396 Return 0 0 0 . 0.08 0  0.07 \r\n\r\nTrọng số Hj20  0 0.07 0 . 0    \r\n\r\n \r\n\r\n\r\n \r\n\r\n \r\nphân tích NMF đối với ma trận A, giá trị trọng số H1,20, ..., H10,20 của vec-tơ đặc trưng \r\n\r\nngữ nghĩa tương ứng với câu S20, vec-tơ câu ban đầu. Vec-tơ câu được tính từ các \r\n\r\ngiá trị trọng số và các vec-tơ ngữ nghĩa. Phương pháp NMF trích xuất câu có trọng \r\n\r\nsố lớn nhất theo nghĩa: câu đó phản ánh nhiều nhất tới chủ đề chính của tài liệu, điều \r\n\r\nđó được biểu diễn bởi các đặc trưng ngữ nghĩa. Do đó, phương pháp NMF có \r\n\r\nlikelihood tốt hơn trong việc trích xuất các câu quan trọng về mặt ngữ nghĩa so với \r\n\r\nphương pháp LSA. \r\n\r\n   \r\n\r\n2.3 Phương pháp học sâu với Word2Vec \r\n\r\n \r\n\r\nYou shall know a word by the company it keeps \r\n\r\n \r\n\r\n      J.R. Firth 1957 \r\n\r\n \r\n\r\n Như đã trình bày ở Chương 1, ta thấy các vấn đề còn vướng mắc của các \r\n\r\nphương án vec-tơ hóa văn bản hiện tại. Trong mục này, đồ án sẽ trình bày về việc \r\n\r\nứng dụng phương pháp học sâu vào bài toán xử lý ngôn ngữ tự nhiên, mà cụ thể là \r\n\r\nbiểu diễn phân tán từ trong quá trình vec-tơ hóa từ và văn bản, đóng vai trò như đặc \r\n\r\ntrưng đầu vào cho các thuật toán tóm tắt. Ngoài ra, chương này cũng trình bày nội \r\n\r\ndung cơ bản về thước đo cosine, thước đo đánh giá độ tương đồng trong Word2Vec. \r\n\r\n  \r\n\r\n  \r\n\r\n\r\n\r\n15 \r\n\r\n\r\n2.3.1 Phương pháp học sâu và bài toán biểu diễn phân tán từ \r\n\r\n  \r\n\r\n Học sâu  Deep Learning: là những thuật toán học máy dựa trên việc học các \r\n\r\ntầng biểu diễn khác nhau của dữ liệu.  \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n\r\n \r\n\r\n Học sâu là một lĩnh vực mà: \r\n\r\n Có sự phát triển nhanh và bao phủ một miền rộng lớn. \r\n\r\n Là cơ sở của học máy và lý thuyết nhận dạng mô hình (Pattern \r\n\r\nrecognition theory). \r\n\r\n Nâng cao công nghệ xây dựng các hệ thống trí tuệ nhân tạo. \r\n\r\n \r\n\r\n Trong đó, có thể nói bài toán biểu diễn phân tán từ - Word distributed \r\n\r\nrepresentation hay còn gọi là WordEmbedding là một trong những phương diện \r\n\r\nnghiên cứu thú vị nhất của phương pháp học sâu trong xử lí ngôn ngữ tự nhiên. \r\n\r\n Ý tưởng của bài toán này bắt đầu từ một nhận xét (hay định nghĩa) kinh điển \r\n\r\ncủa J.R. Firth vào năm 1957, tạm dịch là:  \r\n\r\n \r\n\r\nChúng ta có thể suy diễn nghĩa của một từ nếu biết những từ vựng khác hay dùng \r\n\r\nkèm với nó. \r\n\r\n \r\n\r\n Một WordEmbedding là một hàm ánh xạ từ thành các vec-tơ nhiều chiều (200 \r\n\r\nđến 500 chiều). Ví dụ như: \r\n\r\nW(cat) = (0.2, -0.4, 0.7,.) \r\n\r\nW(mat) = (0.0, 0.6, -0.1,.) \r\n\r\n Thường thì hàm này sẽ là một bảng tra cứu, lưu trữ dưới dạng một ma trận , \r\n\r\nvới W(wn) = n .  \r\n\r\n Ban đầu W được khởi tạo một vec-tơ ngẫu nhiên cho mỗi từ. Sau đó nó sẽ học \r\n\r\nra các vec-tơ có nghĩa để thực hiện một số tác vụ (task). Ví dụ, ta cần huấn luyện \r\n\r\nra một mạng (network) nhằm kiểm tra xem một chuỗi 5 từ (5-gram) là hợp lệ hay \r\n\r\nkhông.  \r\n\r\nĐặc trưng \r\n\r\nmức thấp \r\n\r\nĐặc trưng \r\n\r\nmức trung \r\n\r\nĐặc trưng \r\n\r\nmức cao \r\n\r\nLớp \r\n\r\nphân \r\n\r\nloại \r\n\r\n\r\n\r\n16 \r\n\r\n\r\n Mô hình được huấn luyện ra sẽ chạy mỗi từ trong cụm 5-gram từ ma trận W \r\n\r\nđể lấy ra vec-tơ đại diện của nó. Sau đó đưa những vec-tơ này vào trong một mô-\r\n\r\nđun khác gọi là R để thử dự đoán xem 5-gram này là hợp lệ hay không. Ví dụ như: \r\n\r\n R( W(cat), W(sat), W(on), W(the), W(mat) ) = 1 \r\n\r\n R( W(cat), W(sat), W(song), W(the), W(mat) ) = 0 \r\n\r\n \r\n\r\n\r\n \r\n\r\n Để dự đoán chính xác các giá trị này, mạng cần phải học được các tham số tốt \r\n\r\ntừ cả W và R. Đến đây thì kết quả tác vụ này đã không còn nhiều ý nghĩa. \r\n\r\n Thực tế, điều chúng ta hướng đến là việc học ra W. Có thể thực hiện các tác \r\n\r\nvụ khác nhau để thu được kết quả này chứ không nhất thiết phải là tác vụ đã được ví \r\n\r\ndụ ở trên.  \r\n\r\n Để có thể thu được một chút nhận xét về không gian WordEmbedding, ta có \r\n\r\nthể sử dụng t-SNE để biểu diễn không gian WordEmbedding lên không gian 2 chiều, \r\n\r\nHình  2.7. \r\n\r\n \r\n\r\n\r\n\r\n17 \r\n\r\n\r\n \r\n\r\nHình  2.7: Sử dụng t-SNE trên không gian WordEmbedding \r\n\r\n \r\n\r\n \r\n\r\n\r\n \r\n\r\n Biểu diễn này cho thấy, những từ gần giống nhau sẽ gần với nhau. Kết quả này \r\n\r\ncòn có thể được nhìn thấy thông qua việc liệt kê các từ gần nhất với một từ cho trước \r\n\r\ntrong không gian WordEmbedding. Một lần nữa các từ cùng một nhóm cũng khá \r\n\r\ntương đồng với nhau. \r\n\r\n Rất tự nhiên mà các từ có nghĩa tương đồng được đưa về các vec-tơ gần nhau. \r\n\r\nNếu ta thay thế một từ thành một từ có nghĩa tương đồng với nó, sự hợp lệ của câu \r\n\r\nkhông hề thay đổi [9]. Trong khi xét trên sự thay đổi về mặt chuỗi, rõ ràng câu đầu \r\n\r\nvào đã có sự thay đổi lớn. Nếu như W ánh xạ được các từ có nghĩa tương đồng về \r\n\r\ngần với nhau thì R chỉ có một chút sự thay đổi. \r\n\r\n\r\n\r\n18 \r\n\r\n\r\n Kết quả này thực sự tốt khi mà số lượng các 5-gram thì rất lớn nhưng ta chỉ \r\n\r\ncó một số lượng nhỏ để làm dữ liệu học. Các từ có nghĩa tương đồng được đưa về \r\n\r\ngần nhau, cho phép ta sinh ra một tập các câu tương tự nhau từ một câu cho trước. \r\n\r\nNó không chỉ là việc thay một từ bởi một từ đồng nghĩa mà còn là thay một từ bởi \r\n\r\nmột từ trong cùng tập các từ gần nhau. Ngoài ra, ta cũng có thể thay thế nhiều từ cùng \r\n\r\nmột lúc. \r\n\r\n Bên cạnh đó, WordEmbedding còn một tính chất đáng giá hơn: Khi sự tương \r\n\r\ntự giữa các từ dường như được mã hóa thành sự tương đồng giữa các vec-tơ biểu diễn \r\n\r\ntừ. Ví dụ như có một hằng số giữa sự khác biệt của các vec-tơ male-female: \r\n\r\nW(woman)  W(man) = W(aunt)  W(uncle) \r\n\r\nW(woman)  W(man) = W(aunt)  W(uncle) \r\n\r\n Thực tế việc thay đổi các từ trong câu có thể tạo ra các câu sai về mặt ngữ \r\n\r\nnghĩa. Ví dụ, khi nói: She is not a Queen, He is a King nhưng He is a Queen \r\n\r\ncoi là câu sai ngữ nghĩa. Như vậy theo một cách tự nhiên khi học các 5-gram đúng, \r\n\r\nthì WordEmbedding đã học cả các mặt ngữ nghĩa của từ. \r\n\r\n Tổng hợp lại, kết quả của bài toán WordEmbedding sẽ cho ta một ánh xạ từ \r\n\r\nthành vec-tơ với các tính chất sau: \r\n\r\n Số lượng chiều không lớn (so với tập từ vựng) \r\n\r\n Các từ có chung nét ngữ nghĩa sẽ được về gần nhau trong không gian \r\n\r\n Mối quan hệ tương đồng ngữ nghĩa được chuyển thành mối quan hệ \r\n\r\ngiống nhau giữa các vec-tơ. \r\n\r\n \r\n\r\n2.3.2 Word2Vec \r\n\r\n \r\n\r\n Word2Vec là một phương pháp cụ thể của bài toán WordEmbedding. Không \r\n\r\nsử dụng một tác vụ để kiểm tra một cụm \"5-gram\" có hợp lệ hay không như ví dụ ở  \r\n\r\nmục 2.3.1 , Word2vec lựa chọn việc huấn luyện ra một mạng nơ-ron cho phép dự \r\n\r\nđoán từ (hoặc các từ) bởi các từ lân cận cho trước (có thể gồm nhiều hoặc một từ) và \r\n\r\nngược lại. \r\n\r\n Về khối kết cấu, Word2Vec là 1 mạng nơ-ron cạn gồm 1 lớp ẩn. Có 2 kiến \r\n\r\ntrúc là hội tụ và phân kì từ xung quanh để tạo ra mô hình Word2vec là CBOW và \r\n\r\nSkip-gram. Ngoài ra, thực tế còn có các phương pháp cải tiến nhằm tối ưu hóa hiệu \r\n\r\nquả tính toán. \r\n\r\n Một cách tổng quát về Word2Vec: \r\n\r\n Biểu diễn phân tán cho từ \r\n\r\n Học ra một vec-tơ giá trị thực (real-valued vector) cho  từng từ \r\n\r\n Đưa những từ có ý nghĩa giống nhau về gần nhau \r\n\r\n Một ứng dụng đơn giản của của mạng nơ-ron 2 lớp \r\n\r\n\r\n\r\n19 \r\n\r\n\r\n2.3.2.1 Mô hình CBOW \r\n\r\n \r\n\r\n  \r\n\r\n\r\n \r\n\r\n Nguyên tắc của CBOW là sử dụng mạng nơ-ron để xây dựng một mô hình trên \r\n\r\ndữ liệu học, sao cho có thể tìm ra được một từ thông qua các từ lân cận nó (gọi là \r\n\r\ncontext - ngữ cảnh) [7]. \r\n\r\n \r\n\r\n Ngữ cảnh chỉ gồm một từ - Single word context \r\n\r\n \r\n\r\n Trước tiên ta bắt đầu từ ví dụ đơn giản nhất của CBOW rằng một ngữ cảnh chỉ \r\n\r\ngồm một từ. Nói một cách khác là mô hình sẽ dự đoán từ cần tìm thông qua một từ \r\n\r\ncho trước. \r\nchỉ gồm một từ. Giả sử kích thước của tập từ điển là V, kích thước của lớp ẩn là N. \r\n\r\nNode trên lớp bên cạnh được kết nối đầy đủ. Vec-tơ đầu vào là một vec-tơ one-hot \r\n\r\nencoded [ Phụ lục 2]. \r\n\r\n \r\n\r\n\r\n\r\n\r\n20 \r\n\r\n\r\n Trọng số giữa lớp vào và lớp ra được biểu diễn dưới dạng ma trận W kích \r\n\r\nthước VxN. Mỗi hàng của W là 1 vec-tơ N chiều đại diện vw ứng với từ liên kết của \r\n\r\nvec-tơ đầu vào. Truyền vào một ngữ cảnh, giả sử xk = 1 và xk = 0 với mọi k  k, \r\n\r\nkhi đó: \r\n\r\n  =  =  = \r\n (12) \r\n\r\n \r\n\r\n Từ lớp ẩn đến lớp đầu ra, còn có một ma trận trọng số NxV khác  \r\n\r\nW = { wij }. Sử dụng các trọng số này ta có thể tính toán điểm uj cho từng từ trong \r\n\r\ntập từ vựng: \r\n\r\n  = \r\n  (13) \r\n\r\n \r\n\r\n Với vwj là cột thứ j của ma trận W. Sau đó chúng ta có thể sử dụng soft-max, \r\n\r\nmột model phân loại log-linear để có được sự phân bố của các từ (the posterior \r\n\r\ndistribution of words) dưới dạng 1 đa thức phân phối. \r\n\r\n \r\n\r\n \r\n(|) =  =\r\n\r\nexp ()\r\n\r\n ( )\r\n\r\n=1\r\n\r\n \r\n(14) \r\n\r\n \r\n\r\n Với yj là đầu ra của node j trong lớp đầu ra. Thế (12), (13) vào (14)  ta có: \r\n\r\n \r\n(|) =  =\r\n\r\nexp (\r\n )\r\n\r\n ( )\r\n\r\n=1\r\n\r\n \r\n(15) \r\n\r\n \r\n\r\n Chú ý rằng vw, vw là hai đặc trưng của từ.  vw đến từ hàng của W, tức là từ \r\n\r\nđầu vào đến ma trận trọng số ẩn, và vw đến từ W, tức là từ lớp ẩn đến ma trận đầu \r\n\r\nra. Trong các phần tiếp theo ta sẽ gọi vw là vec-tơ đầu vào và vw là vec-tơ đầu ra \r\n\r\ncủa w. \r\n\r\n Một đối tượng tập huấn (training object) được tối đa hóa từ (15), xác suất có \r\n\r\nđiều kiện của việc quan sát thực tế của từ đầu ra wO (chỉ số của từ này được biểu thị \r\n\r\ntrong lớp đầu ra là j*) khi đưa vào ngữ cảnh đầu vào wI với mối liên quan đến trọng \r\n\r\nsố: \r\n\r\n max (|) = max  (16) \r\n\r\n                                   = max log  (17) \r\n\r\n \r\n                            =   log   ( \r\n\r\n) = \r\n\r\n\r\n=1\r\n \r\n\r\n(18) \r\n\r\n                 \r\n\r\n\r\n\r\n21 \r\n\r\n\r\n Với E = log p (wO | wI) là hàm lỗi (ta muốn cực tiểu hóa giá trị này) và j* là \r\n\r\nvị trí của từ đầu ra thực tế trong lớp đầu ra. Chú ý rằng E có thể coi như là một trường \r\n\r\nhợp đặc biệt của cross-entropy giữa hai phân bố xác suất. \r\n\r\n \r\n\r\nPhương trình cập nhật cho W \r\n\r\n \r\n\r\n Xét phương trình cập nhật trọng số của lớp ẩn (hidden layer) và lớp đầu ra, ta \r\n\r\ntính đạo hàm E với uj: \r\n\r\n \r\n\r\n\r\n=      \r\n\r\n(19) \r\n\r\n \r\n\r\n Với tj = 1 khi node thứ j là từ đầu ra thực tế, tj bằng 0 trong các trường hợp \r\n\r\ncòn lại. Chú ý rằng các tính toán trên chỉ là một đơn giản hóa cho dự đoán lỗi ej của \r\n\r\nlớp đầu ra. \r\n\r\n Tiếp theo ta tính đạo hàm trên wij để tìm ra gradient của trọng số trên W: \r\n\r\n \r\n\r\n\r\n=\r\n\r\n\r\n\r\n\r\n   \r\n\r\n\r\n\r\n\r\n=    \r\n\r\n(20) \r\n\r\n \r\n\r\n Sử dụng Stochastic Gradient Descent, ta có phương trình cập nhật trọng số \r\n\r\ntrên W: \r\n\r\n \r\n() = \r\n\r\n()       (21) \r\n\r\n  hoặc \r\n\r\n \r\n() = \r\n\r\n()       (22) \r\n\r\n \r\n\r\n Với  > 0 là độ học ( learning rate ), ej = yj  tj , và hi là node thứ i trong lớp \r\n\r\nẩn, vwj là vec-tơ đầu ra của wj. Chú ý là phương trình cập nhật này bắt buộc là ta \r\n\r\nphải đi toàn bộ các từ trong bộ từ, kiểm tra xác suất đầu ra yj và so sánh nó với kì \r\n\r\nvọng đầu ra tj (là 0 hoặc 1). Nếu yj > tj, ta trừ vwO đi 1 tỉ lệ của vec-tơ ẩn h (ví dụ: \r\n\r\nvwI), nó khiến cho vwO xa khỏi vwI. Nếu yj < tj, ta cộng vwO đi 1 tỉ lệ của vec-tơ \r\n\r\nẩn h, nó khiến cho vwO gần lại vwI. \r\n\r\n \r\n\r\n Ở đây xa hay gần là khoảng cách cosine, không phải là khoảng cách \r\n\r\nEuclidean. \r\n\r\n \r\n\r\n  \r\n\r\n\r\n\r\n22 \r\n\r\n\r\nPhương trình cập nhật cho W: \r\n\r\n \r\n\r\n Đã tìm được W, ta tiếp tục tính toán đến W. Ta tính toán đạo hàm của E trên \r\n\r\nđầu ra của lớp ẩn thu được kết quả: \r\n\r\n \r\n\r\n\r\n= \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n=1\r\n\r\n\r\n\r\n\r\n\r\n=      = \r\n\r\n\r\n\r\n=1\r\n\r\n \r\n\r\n(23) \r\n\r\n với hi là đầu ra của nút thứ i trong lớp ẩn, uj đã được định nghĩa trong công \r\n\r\nthức (13) là mạng đầu vào của nút thứ j trong lớp đầu ra và ej = yj - tj là giá trị lỗi dự \r\n\r\nđoán của từ thứ j trong lớp đầu ra. EH là một vec-tơ N chiều là tổng của các vec-tơ \r\n\r\nđầu ra của toàn bộ các từ trong tập từ, được trọng số bởi giá trị lỗi dự đoán của chúng. \r\n\r\n Tiếp theo, ta tính đạo hàm của E trên W. Đầu tiên phải nhớ rằng lớp ẩn chuyển \r\n\r\nhóa thực hiện tính toán tuyến tính trên các giá trị từ lớp đầu vào. Diễn giải công thức \r\n\r\n(12) ta có: \r\n\r\n \r\n\r\n =    \r\n\r\n\r\n\r\n=1\r\n\r\n \r\n\r\n(24) \r\n\r\n \r\n\r\n Tính đạo hàm của E với W ta được: \r\n\r\n \r\n\r\n\r\n=\r\n\r\n\r\n\r\n\r\n   \r\n\r\n\r\n\r\n\r\n=    \r\n\r\n(25) \r\n\r\n \r\n\r\n \r\n\r\n\r\n=     \r\n\r\n(26) \r\n\r\n \r\n\r\n Từ đó ta tìm được một ma trận VxN. Chỉ có một thành phần của x là khác 0 \r\n\r\nđồng nghĩa với việc một hàng của \r\n\r\n\r\n\r\n là khác 0, và giá trị của hàng đó là EH, một \r\n\r\nvec-tơ N chiều. Ta tính được phương trình cập nhật của W là: \r\n\r\n \r\n\r\n\r\n\r\n\r\n()\r\n= \r\n\r\n\r\n\r\n\r\n()\r\n    (27) \r\n\r\n \r\n\r\n với vwI là một hàng của W, vec-tơ đầu vào của từ trong ngữ cảnh, hàng duy \r\n\r\nnhất của W có đạo hàm khác 0. Ta không cần quan tâm đến các hàng khác của W vì \r\n\r\nđạo hàm của chúng đều là 0.  \r\n\r\n Dễ thấy, có thể hiểu () thêm vào một phần của mọi vec-tơ đầu ra trong tập \r\n\r\ntừ vào vec-tơ đầu vào của từ trong ngữ cảnh. Nếu trong lớp đầu ra, yj > tj thì vec-\r\n\r\ntơ đầu vào wI sẽ được dịch xa khỏi vec-tơ đầu ra wj và ngược lại. Độ dịch chuyển \r\n\r\nnày được xác định bởi tỉ lệ dự đoán lỗi (prediction error) của tất cả các vec-tơ trong \r\n\r\ntập từ. Tỉ lệ dự đoán lỗi càng lớn thì càng ảnh hưởng đến độ dịch chuyển. \r\n\r\n\r\n\r\n23 \r\n\r\n\r\n Ngữ cảnh gồm nhiều từ - Multi-word context \r\n\r\n \r\n\r\n \r\n\r\n\r\n \r\n\r\n \r\nKhi tính toán đầu ra của lớp ẩn, thay  vì trực tiếp sao chép vec-tơ đầu vào của từ từ \r\n\r\nđầu vào trong ngữ cảnh (như trường hợp ngữ cảnh chỉ có một từ đã trình bày ở trên), \r\n\r\nCBOW lấy trung bình các vec-tơ của các từ đầu vào trong ngữ cảnh, và sử dụng kết \r\n\r\nquả của quá trình từ đầu vào đến trọng số ẩn và vec-tơ trung bình làm đầu ra. \r\n\r\n \r\n =\r\n\r\n1\r\n\r\n\r\n   (1 + 2 + 3 +  + ) \r\n\r\n(28) \r\n\r\n \r\n    =\r\n\r\n1\r\n\r\n\r\n (1 + 2 + 3 +  + ) \r\n\r\n(29) \r\n\r\n \r\n\r\n Với C là số từ trong ngữ cảnh, w1, ..., wc là các từ trong ngữ cảnh, và vw là \r\n\r\nvec-tơ đầu vào của từ w. Hàm lỗi lúc này được xác định bởi công thức: \r\n\r\n \r\n\r\n  =  log ( | ,1, ,2, ,3, . , ,) (30) \r\n\r\n \r\n\r\n                       =   log  exp ()\r\n\r\n\r\n\r\n=1\r\n\r\n \r\n\r\n(31) \r\n\r\n \r\n\r\n= \r\n    + log  exp (\r\n\r\n   )\r\n\r\n\r\n\r\n=1\r\n\r\n \r\n\r\n(32) \r\n\r\n                      \r\n\r\n\r\n\r\n24 \r\n\r\n\r\n Công thức này hoàn toàn giống với công thức (18) trừ việc thay h bằng công \r\n\r\nthức (29) thay vì công thức (12). Phương trình cập nhật cho trọng số ẩn đến trọng số \r\n\r\nđầu ra hoàn toàn giống như phương trình (22): \r\n\r\n \r\n\r\n\r\n() = \r\n\r\n\r\n()    ej   (33) \r\n\r\n     for j = 1, 2,., V \r\n\r\n \r\n\r\n Chú ý rằng ta cần phải sử dụng phương trình này cho từng thành phần trong \r\n\r\nma trận trọng số W với từng đối tượng tập huấn. \r\n\r\n Phương trình cập nhật trọng số cho W  cũng tương tự như ()  trừ việc giờ ta \r\n\r\nphải áp dụng phương trình ở dưới cho toàn bộ các từ trong ngữ cảnh: \r\n\r\n \r\n\r\n\r\n\r\n,\r\n\r\n() = \r\n\r\n\r\n,\r\n\r\n()   \r\n1\r\n\r\n\r\n   \r\n\r\n(34) \r\n\r\n   for c = 1, 2, .,C \r\n\r\n \r\n\r\n  vwI,c là vec-tơ đầu vào của từ thứ c trong ngữ cảnh,  là độ học chủ động \r\n\r\n(positive learning-rate), và EH đã được cho bởi công thức. Theo một cách tương đối \r\n\r\nmà nói thì (34) giống với (). \r\n\r\n \r\n\r\n2.3.2.2 Mô hình Skip-gram \r\n\r\n \r\n\r\n\r\n \r\n\r\n Skip-gram là mô hình ngược lại với CBOW hay chi tiết hơn là lớp đầu vào sẽ \r\n\r\nlà từ, và lớp đầu ra sẽ là ngữ cảnh [1]. Ta vẫn kí hiệu vwI là vec-tơ đầu vào của từ duy \r\n\r\n\r\n\r\n25 \r\n\r\n\r\nnhất trên lớp đầu vào, đồng thời định nghĩa đầu ra lớp ẩn h giống như trong công thức \r\n\r\n(12) nghĩa là h là việc sao chép một hàng của ma trận trọng số W \r\n\r\n \r\n\r\n  =  =   (35) \r\n\r\n \r\n\r\n Trên lớp đầu ra, thay cho việc chỉ có một đa thức phân phối ta sẽ cho ra C đa \r\n\r\nthức phân phối. Mỗi một đầu được tính toán trên cùng ma trận W: \r\n\r\n \r\n\r\n \r\n(, = ,|) = , =\r\n\r\nexp (,)\r\n\r\n ( )\r\n\r\n=1\r\n\r\n \r\n(36) \r\n\r\n \r\n\r\n \r\n\r\n\r\n \r\n\r\n Với wc,j là từ thứ j trong panel thứ c của lớp đầu ra; wO,c là từ thứ c thực tế \r\n\r\nxuất hiện trong ngữ cảnh đầu ra; wI là từ đầu vào (duy nhất); yc,j là đầu ra của node \r\n\r\nthứ j trên panel thứ c của lớp đầu ra; uc,j là mạng đầu vào của nút thứ j của panel thứ \r\n\r\nc của lớp đầu ra. Bởi vì các panel của lớp đầu ra có cùng trọng số nên: \r\n\r\n \r\n\r\n , =  =  \r\n  (37) \r\n\r\n   for    c  = 1, 2, ., C \r\n\r\n \r\n\r\n  với vwj \r\nlà vec-tơ đầu ra của từ thứ j trong tập từ vựng  (wj), được lấy \r\n\r\nra từ một hàng của ma trận trọng số W. \r\n\r\n\r\n\r\n26 \r\n\r\n\r\n Đạo hàm của phương trình cập nhật trọng số cũng không có nhiều điểm khác \r\n\r\nbiệt so với mô hình ngữ cảnh một từ đã trình bày ở mục. Tuy nhiên hàm lỗi E được \r\n\r\nchuyển thành: \r\n\r\n \r\n\r\n  =  log ( ,1, ,2, ,3, . , ,  |) (38) \r\n\r\n \r\n\r\n                      = log \r\n(,)\r\n\r\n ()\r\n\r\n=1\r\n\r\n\r\n\r\n=1\r\n\r\n \r\n\r\n(39) \r\n\r\n \r\n\r\n                     =   , +   log  ()\r\n\r\n\r\n\r\n=1\r\n\r\n\r\n\r\n=1\r\n\r\n \r\n\r\n(40) \r\n\r\n \r\n\r\n với jc* là vị trí của từ thứ c xuất hiện thực tế trong ngữ cảnh đầu ra. Ta tính đạo \r\n\r\nhàm của E với mạng đầu vào của từng nút trên từng panel của lớp đầu ra, uc,j và có \r\n\r\n \r\n\r\n \r\n\r\n,\r\n= ,  ,  , \r\n\r\n(41) \r\n\r\n \r\n\r\n là giá trị dự đoán lỗi trên node, giống với (19). Để đơn giản, ta định nghĩa một \r\n\r\nvec-tơ N chiều EI = {EI1, EI2,.,  EIV} là tổng của tất cả các giá trị dự đoán lỗi trên \r\n\r\ntoàn bộ các từ của ngữ cảnh: \r\n\r\n \r\n\r\n \r\n\r\n =  ,\r\n\r\n\r\n\r\n=1\r\n\r\n \r\n\r\n(42) \r\n\r\n \r\n\r\n Ta tiếp tục tính đạo hàm của E trên W thu được: \r\n\r\n \r\n\r\n \r\n\r\n\r\n=  \r\n\r\n\r\n\r\n,\r\n\r\n\r\n\r\n=1\r\n\r\n\r\n,\r\n\r\n\r\n=    \r\n\r\n(43) \r\n\r\n \r\n\r\n Vì thế ta tìm được phương trình cập nhật ma trận trọng số W: \r\n\r\n \r\n\r\n \r\n\r\n\r\n()\r\n= \r\n\r\n\r\n\r\n()\r\n      (44) \r\n\r\n  hay: \r\n\r\n \r\n\r\n\r\n() = \r\n\r\n\r\n()       (45) \r\n\r\nfor j = 1, 2,., V \r\n\r\n \r\n\r\n\r\n\r\n27 \r\n\r\n\r\n Cảm tính mà nói hàm cập nhật này giống với công thức (22) trừ việc hệ số dự \r\n\r\nđoán lỗi được tính tổng trên toàn bộ các từ trong ngữ cảnh của lớp đầu ra. Chú ý rằng \r\n\r\nta cần áp dụng hàm cập nhật này với mọi thành phần của ma trận W cho từng đối \r\n\r\ntượng trong tập huấn. \r\n\r\n Đạo hàm của phương trình cập nhật cho ma trận W hoàn toàn giống từ (23) \r\n\r\nđến (27) trừ việc thay đổi giá trị dự đoán lỗi ej thành EHj. Phương trình cập nhật trọng \r\n\r\nsố trong trường hợp này sẽ là: \r\n\r\n \r\n\r\n \r\n\r\n\r\n()\r\n= \r\n\r\n\r\n\r\n()\r\n    (46) \r\n\r\n \r\n\r\n \r\n\r\n với EH là một vec-tơ N chiều, mỗi thành phần được tính theo công thức: \r\n\r\n \r\n\r\n =    ,\r\n\r\n\r\n\r\n=1\r\n\r\n \r\n\r\n(47) \r\n\r\n \r\n\r\n \r\n\r\n2.3.3 Độ tương đồng Cosine trong không gian Vec-tơ \r\n\r\n Trong mục này, tôi sẽ trình bày những kiến thức cơ bản về thước đo cosine \r\n\r\nđược sử dụng để xác định độ tương đồng giữa 2 từ trong mô hình Word2Vec và ứng \r\n\r\ndụng trong phạm vi đồ án. \r\n\r\n \r\n\r\n Tích vô hướng \r\n\r\n Chúng ta bắt đầu với định nghĩa về số học của tích vô hướng giữa hai vec-tơ: \r\n\r\n  = (1, 2, 3, . ) và  = (1, 2, 3, . ) với an và bn lần lượt là các thành phần của \r\n\r\nvec-tơ  ,   và n là số chiều của các vec-tơ: \r\n\r\n \r\n\r\n \r\n.  =   = 11 + 22 +  + \r\n\r\n\r\n\r\n=1\r\n \r\n\r\n(48) \r\n\r\n \r\n\r\n Tuy nhiên, để thấy được hết ý nghĩa của phép nhân vô hướng giữa 2 vec-tơ, \r\n\r\nchúng ta phải xem xét đến định nghĩa hình học của nó: \r\n\r\n \r\n\r\n  =  cos  (49) \r\n\r\n \r\n\r\n Sử dụng tính chất giao hoán để sắp xếp lại vế phải của công thức trên ta có: \r\n\r\n \r\n\r\n\r\n\r\n28 \r\n\r\n\r\n  =  cos  (50) \r\n\r\n \r\n\r\n Trong lý thuyết hình học, phép nhân    cos  chính là phép chiếu của vect-\r\n\r\ntơ  lên vec-tơ  ,Hình \r\n \r\n\r\n \r\n\r\n\r\n \r\n\r\n Khi vec-tơ  vuông góc với vec-tơ  tích này trở thành: \r\n\r\n \r\n\r\n\r\n \r\n\r\n Khi 2 vec-tơ vuông góc, tích vô hướng của chúng bằng 0. Đây cũng là một \r\n\r\ncách để chúng ta kiểm tra 2 vec-tơ có quan hệ vuông góc hay không. Tuy nhiên, ví \r\n\r\ndụ trên mới chỉ dừng lại ở  không gian vec-tơ hai chiều, nhưng có một điều thú vị \r\n\r\nrằng, chúng ta cũng có thể tính toán góc và độ tương đồng giữa các vec-tơ trong \r\n\r\nkhông gian nhiều chiều, mà trong bài toán của chúng ta là không gian vec-tơ 300 \r\n\r\nchiều. \r\n\r\n \r\n\r\n Độ tương đồng Cosine \r\n\r\n Độ tương đồng cosine giữa hai vec-tơ (hoặc 2 từ trong không gian vec-tơ) là \r\n\r\nmột thước đo tính giá trị cosine của góc giữa chúng. Thước đo này là thước đo về \r\n\r\nhướng của 2 vec-tơ, không phải thước đo về độ lớn. \r\n\r\n  \r\n\r\n\r\n\r\n29 \r\n\r\n\r\n Từ công thức (49) ta có: \r\n\r\n \r\ncos  =\r\n\r\n\r\n\r\n\r\n \r\n\r\n(51) \r\n\r\n Đây chính là công thức về độ tương đồng cosine. Độ tương đồng cosine sẽ \r\n\r\nsinh ra một số, số này sẽ cho chúng ta biết 2 từ liên quan đến nhau như thế nào trong \r\n\r\nkhông gian bằng cách xem xét góc giữa chúng, thay vì so sánh về độ lớn. \r\n\r\n \r\n\r\n \r\n\r\n       a)  Cùng hướng                      b) Vuông góc                         c) Đối diện \r\n\r\n \r\n\r\n\r\n \r\n\r\n \r\n\r\n2.3.4 Ứng dụng phương pháp học sâu Word2Vec với xử lí ngôn ngữ tự nhiên \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n- Mô hình n-gram            - Giảm khối lượng tính toán                - Sử dụng biểu diễn \r\n\r\n                                                                                                        phân phối cho từ                                                                                                                             \r\n\r\n- Sử dụng chuỗi các         - Phân cụm các từ vào trong                - Các từ tương đồng \r\n\r\nluật xác suất                      các chỉ mục                                           ở gần nhau \r\n\r\n- Ước lượng bằng cách    - Với 1 biểu diễn one-hot, khoảng         \r\n\r\nthống kê số n-gram           cách giữa hai từ luôn bằng 2  \r\n\r\n \r\n\r\n\r\n \r\n\r\n Mô hình ngôn ngữ - Language model: Cốt lõi nhất của phương pháp xử lí \r\n\r\nngôn ngữ tự nhiên dựa trên thống kê chính là việc xây dựng mô hình ngôn ngữ. \r\n\r\n Mô hình ngôn ngữ là một phân bố xác suất trên các tập văn bản. Cụ thể thì mô \r\n\r\nhình ngôn ngữ cho biết xác suất của một câu (một cụm từ hoặc một từ) trong bộ dữ \r\n\r\nLanguage \r\n\r\nModel \r\n\r\nClass-based \r\n\r\nLanguage \r\n\r\nModel \r\n\r\nNeural \r\n\r\nNetworks \r\n\r\nLanguage \r\n\r\nModels \r\n\r\n\r\n\r\n30 \r\n\r\n\r\nliệu mẫu là bao nhiêu. Mô hình ngôn ngữ có nhiều hướng tiếp cận nhưng chủ yếu là \r\n\r\nmô hình N-gram. \r\n\r\n  \r\n(1, . , ) = (1, . , 1)  (|1, . , +1)\r\n\r\n\r\n\r\n=\r\n\r\n  \r\n(52) \r\n\r\n  \r\n\r\n \r\n\r\n(53) \r\n\r\nP (\"ầ ờ à \") = 3(\"Bầu trời màu\")3(\"ờ à \")/2(ờ à) \r\n\r\n \r\n\r\n Theo công thức (52), mô hình ngôn ngữ cần phải có một lượng bộ nhớ vô cùng \r\n\r\nlớn để có thể lưu hết xác suất của tất cả các chuỗi có độ dài nhỏ hơn n. Giả sử rằng \r\n\r\nchỉ có k từ được đưa và trong bộ tiền ngữ (history), áp dụng chuỗi Markov bậc k \r\n\r\n(các từ cũ hơn có khả năng ít liên quan) [8], ta có: \r\n\r\n \r\n\r\n (|1, . , 1)  (|4, 3, 2, 1) (54) \r\n\r\n \r\n\r\n Tuy nhiên, mỗi (|4, 3, 2, 1) có thể không đủ thống kê để ước \r\n\r\nlượng, do khi tính xác suất có nhiều trường hợp sẽ gặp các cụm n-gram chưa xuất \r\n\r\nhiện hoặc do sự phân bố không đều trong tập huấn luyện sẽ dẫn tới việc tính toán \r\n\r\nkhông chính xác. Do đó, chúng ta phải sử dụng một phương pháp làm mịn, ví dụ như \r\n\r\nKneser-Ney [11] với mô hình truy hồi để khắc phục vấn đề này. Đến đây thì việc \r\n\r\ntính toán trở nên vô cùng phức tạp: Truy hồi  (|4, 3, 2, 1) , \r\n\r\n(|2, 1), . về (). \r\n\r\n \r\n\r\n Mô hình ngôn ngữ dựa trên lớp  Class-based Language Model: Sử dụng \r\n\r\nphương pháp one-hot coding [Phụ lục 2] để biểu diễn một từ trong tập từ vựng. Tuy \r\n\r\nnhiên phương pháp này có nhược điểm lớn: là kích thước của vec-tơ biểu diễn quá \r\n\r\nlớn vì kích thước của văn bản có thể tiến tới vô cùng. \r\n\r\n \r\n\r\n Từ những phân tích trên, chúng ta có một cái nhìn tổng quát về sự phát triển \r\n\r\ncủa các mô hình ngôn ngữ trong lĩnh vực xử lí ngôn ngữ tự nhiên. Qua đó, thấy được \r\n\r\nmột lần nữa những điểm hạn chế đối với những mô hình truyền thống như mô hình \r\n\r\nngôn ngữ hay mô hình ngôn ngữ dựa trên lớp, cũng như những cải tiến trong mô hình \r\n\r\nngôn ngữ mạng nơ-ron. \r\n\r\n Đối với một số vấn đề mà với các phương pháp khai phá dữ liệu truyền thống \r\n\r\nnhư Cây quyết định (Decision tree), Nave Bayes,.chưa thể làm được thì nay, với \r\n\r\nsự hỗ trợ của công nghệ Deep Learning, điều đó hoàn toàn có khả năng thực hiện.  \r\n\r\n Ta xét một số ví dụ để có thể hiểu hơn về điều này: \r\n\r\n\r\n\r\n31 \r\n\r\n\r\n  \r\n\r\n \r\n  \r\n\r\n Cơ sở của phép suy diễn tương tự trong Word2Vec: \r\n\r\n đà ô  ụ ữ + à đế  \r\n2\r\n (55) \r\n\r\n \r\n\r\n Ví dụ 2: \r\n\r\n Tí đi vào bếp     Dưa hấu thì tròn \r\n\r\n Tí lượm một trái khế    Quả mướp thì dài \r\n\r\n Sau đó Tí chạy ra vườn   Mướp xanh mươn mướt \r\n\r\n Tí làm rơi trái khế    Mướp và dưa hấu cùng màu \r\n\r\n Hỏi: Trái khế ở đâu?   Hỏi: Quả dưa hấu màu gì? \r\n\r\n Máy tính: ở ngoài vườn   Máy tính: màu xanh \r\n\r\n \r\n\r\n Ví dụ 3: Sử dụng Word2Vec trong bài toán topic modelling, ta có thể huấn \r\n\r\nluyện ra những model cho mục đích phân loại, sử dụng model đó để tìm các từ mang \r\n\r\nnét nghĩa giống nhau, ta có thể thu được những kết quả như sau: \r\n\r\n Các từ liên quan đến chủ đề Trường học: Nhà trường, học sinh, lớp \r\n\r\nhọc,. \r\n\r\n Các từ liên quan đến chủ đề Đảng: Nghị quyết, kinh nghiệm, quán \r\n\r\ntriệt, chủ chương, quyết liệt, to lớn,. \r\n\r\n \r\n\r\n2.4 Kết luận \r\n\r\n \r\n\r\n Trong nội dung chương này, tôi đã trình bày cơ sở lý thuyết cơ bản của bài \r\n\r\ntoán tóm tắt văn bản tự động cũng như những phương pháp kĩ thuật sử dụng trong \r\n\r\nphạm vi đồ án, bao gồm: Kĩ thuật phân tích ma trận không âm, biểu diễn phân tán và \r\n\r\nWord2Vec. \r\n\r\n  \r\n\r\n\r\n\r\n32 \r\n\r\n\r\nCHƯƠNG 3 GIẢI PHÁP ĐỀ XUẤT \r\n\r\n \r\n\r\n3.1 Nhận xét về kĩ thuật phân tích ma trận không âm \r\n\r\n \r\n\r\n3.1.1 Ưu điểm \r\n\r\n Đối với việc số hóa một tài liệu sang dạng dữ liệu để máy tính có thể thực hiện \r\n\r\ncác phép toán cộng, trừ, nhân, chia,... (phiên bản số của tài liệu), từ đó có thể thực \r\n\r\nhiện các công việc khai phá dữ liệu như phân loại văn bản (bài toán topic modelling), \r\n\r\ntóm tắt văn bản (text summarizing),. thì việc sử dụng mô hình không gian vec-tơ \r\n\r\nmà cụ thể là phương pháp phân tích ma trận theo mô hình tần suất dường như là một \r\n\r\ncách làm mang tính tự nhiên nhất. Trong chương 2, đồ án đã đề cập sử dụng một \r\n\r\nphương pháp không giám sát mới để sinh ra văn bản tóm tắt của tài liệu tương ứng \r\n\r\nsử dụng kĩ thuật phân tích ma trận không âm-NMF. Phương pháp được đề xuất có \r\n\r\nnhững ưu điểm sau đây: \r\n\r\n Thứ nhất, đây là phương pháp không giám sát (unsupervised) và không \r\n\r\nyêu cầu các tóm tắt mẫu cho bước tập huấn và cho bộ tóm tắt. \r\n\r\n Thứ hai, các vec-tơ đặc trưng ngữ nghĩa được trích rút từ NMF có thể \r\n\r\nđược thể hiện trực quan hơn là sử dụng các phương pháp liên quan đến \r\n\r\nLSA, bởi vì các thành phần trong phân tích NMF chỉ gồm các giá trị \r\n\r\nkhông âm và chúng rất thưa trong khi cũng là các thành phần đó nhưng \r\n\r\ntrong phương pháp LSA thì gồm cả giá trị âm và giá trị dương, ngoài \r\n\r\nra, còn có chứa một vài giá trị bằng 0.  \r\n\r\n Hơn nữa, một câu được có thể được biểu diễn như là sự kết hợp tuyến \r\n\r\ntính của những đặc trưng ngữ nghĩa một cách trực quan. \r\n\r\n Cuối cùng, phạm vi ngữ nghĩa của đặc trưng ngữ nghĩa là hẹp, bởi vì \r\n\r\nchúng rất thưa, theo đó, các chủ đề nhỏ (sub-topics) của tài liệu được \r\n\r\nxác định một cách dễ dàng và chính xác hơn. Do đó, khả năng trích rút \r\n\r\nđược các câu quan trọng sẽ tốt hơn các phương pháp khác. \r\n\r\n \r\n\r\n3.1.2 Nhược điểm \r\n\r\n Tuy nhiên, nhược điểm của phương pháp nằm ở việc không thể phát hiện ra \r\n\r\ncác liên kết ẩn giữa các từ, các phần trong văn bản. Các liên kết này có thể tồn tại \r\n\r\ndưới nhiều dạng, đó có thể là quan hệ nguyên nhân  kết quả giữa các luận điểm, có \r\n\r\nthể là những phần được nhấn mạnh, quan trọng hơn những phần khác hay là sự thay \r\n\r\nđổi cách sử dụng ngôn từ diễn đạt, và có một số thuật ngữ, tuy khác nhau về hình \r\n\r\nthức nhưng lại mang những nét nghĩa giống nhau.  \r\n\r\n  \r\n\r\n\r\n\r\n33 \r\n\r\n\r\n3.2 Mô hình đề xuất \r\n\r\n Sau những kiến thức lý thuyết đã trình bày, trong phần này ta đi vào thiết kế \r\n\r\nhệ thống thực tế để giải quyết bài toán tóm tắt văn bản báo chí bằng ngôn ngữ tiếng \r\n\r\nAnh ứng dụng Word2Vec.  \r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n\r\n  \r\n\r\n Mô hình hệ thống tổng quát sẽ gồm hai mô-đun chính:  \r\n\r\n Mô-đun huấn luyện Word2Vec \r\n\r\n Mô-đun tóm tắt văn bản. \r\n\r\n \r\n\r\n Với các vấn đề về khai thác ngữ nghĩa ẩn, hệ thống khắc phục nhược điểm của \r\n\r\nphương pháp phân tích ma trận không âm bằng cách: Sử dụng mô hình Word2Vec \r\n\r\nđã được huấn luyện để tìm ra tập các từ tương đồng với nhau trong văn bản nguồn. \r\n\r\nTừ đó, thay đổi cách xây dựng ma trận tần suất đầu vào của phân tích ma trận không \r\n\r\nâm. \r\n\r\n  \r\n\r\n\r\n\r\n34 \r\n\r\n\r\n Bên cạnh đó, kế thừa những ưu điểm của các phương pháp tóm tắt văn bản \r\n\r\ntruyền thống, trong mô-đun tóm tắt văn bản, các nhóm đặc trưng phù hợp được lựa \r\n\r\nchọn qua quá trình thực nghiệm (Chương 4 ) được tích hợp vào khối tính điểm cho \r\n\r\ncâu. Các đặc trưng được đề xuất trong mô hình dựa theo gợi ý từ nghiên cứu của một \r\n\r\nsố chuyên gia về tóm tắt văn bản [6]. Các đặc trưng đó bao gồm: đặc trưng bề mặt, \r\n\r\nđặc trưng nội dung và đặc trưng về độ liên quan. \r\n\r\n Trong mục tiếp theo tôi sẽ trình bày chi tiết về các mô-đun, khối chức năng \r\n\r\ntrong hệ thống tóm tắt đề xuất.  \r\n\r\n \r\n\r\n3.3 Mô-đun huấn luyện mô hình Word2Vec \r\n\r\n \r\n\r\n Mô-đun thực hiện việc huấn luyện mô hình Word2Vec đóng vai trò như một \r\n\r\nđặc trưng đầu vào trong khối phân tích ma trận NMF. \r\n\r\n  \r\n\r\n3.3.1 Ngữ liệu huấn luyện \r\n\r\n Ngữ liệu dùng đế huấn luyện mô hình Word2Vec, bao gồm các bài báo, tin \r\n\r\ntức từ Wikipedia và bộ dữ liệu DUC 2004. Đây là các bài báo tin cậy, phủ rộng trên \r\n\r\nnhiều lĩnh vực. Việc lấy dữ liệu từ nguồn này cho phép ta xây dựng được một mô \r\n\r\nhình vec-tơ hóa đặc thù cho dữ liệu văn bản báo chí nhưng vẫn đầy đủ các lĩnh vực. \r\n\r\nNhững dữ liệu này sẽ được tiền xử lí trước khi đưa vào huấn luyện mô hình. \r\n\r\n \r\n\r\n3.3.2 Khối tiền xử lí Word2Vec \r\n\r\n Với dữ liệu là các văn bản, trước khi đưa vào huấn luyện đều cần phải được \r\n\r\ntiền xử lý. Quá trình xử lí sơ bộ sẽ tạo ra một chuỗi các phần nhỏ; ví dụ một tài liệu \r\n\r\nvăn bản (plain text document) được chuyển thành một đối tượng với số đặc trưng \r\n\r\nngôn ngữ học tối thiểu như các từ và các câu.  \r\n\r\n \r\n\r\n3.3.3 Khối huấn luyện mô hình Word2Vec \r\n\r\n Với những dữ liệu đã được tiền xử lí, thực hiện việc huấn luyện mô hình \r\n\r\nWord2Vec trên nguồn dữ liệu đầu vào. Mô hình kiến trúc sử dụng Continuous Skip-\r\n\r\ngram, số chiều của vec-tơ bằng 300. Độ dài cửa sổ ngữ cảnh gồm 5 từ phía trước và \r\n\r\n5 từ phía sau. \r\n\r\n \r\n\r\n3.3.4 Mô hình Word2Vec \r\n\r\n Mô hình Word2Vec sau huấn luyện, được lưu trữ tại bộ nhớ ngoài để có thể \r\n\r\nsử dụng độc lập trong các bước sau. \r\n\r\n  \r\n\r\n\r\n\r\n35 \r\n\r\n\r\n3.4 Mô-đun tóm tắt văn bản \r\n\r\n \r\n\r\n Mô-đun thực hiện các tác vụ liên quan tới quá trình phân tích, hiểu, và tóm tắt \r\n\r\nvăn bản. \r\n\r\n \r\n\r\n3.4.1 Khối tiền xử lí văn bản  \r\n\r\n Khác với khối tiền xử lí Word2Vec, quá trình tiền xử lí văn bản đầu vào bao \r\n\r\ngồm nhiều hơn 2 hoạt động: Chuẩn hóa từ và Loại bỏ các cấu trúc ngữ pháp của từ, \r\n\r\nđưa về dạng nguyên thể trong tiếng Anh.  \r\n\r\n Cả hai hoạt động này đều đóng vai trò quan trọng trong việc vec-tơ hóa tài liệu \r\n\r\nbởi vì nó sẽ làm giảm không gian biểu diễn của văn bản xuống, do đó làm giảm khối \r\n\r\nlượng cần tính toán. \r\n\r\n Cụ thể, quá trình tiền xử lí văn bản đầu vào bao gồm các công việc sau: \r\n\r\n Chia văn bản đầu vào thành tập các câu. \r\n\r\n Chia nhỏ câu thành các từ. \r\n\r\n Lọc từ dừng (stopwords) \r\n\r\n Chuẩn hóa từ \r\n Lemmatizing \r\n Stemming \r\n\r\n Gắn PoS (Part of Speech) \r\n\r\n Stemming \r\n\r\n Là kĩ thuật hình thái từ dành cho khai phá thông tin (Information retrieval) \r\n\r\nđược ứng dụng rộng rãi nhất. Stemming là kĩ thuật dùng để biến đổi một từ về dạng \r\n\r\ngốc (được gọi là stem hoặc root form) bằng cách cực kì đơn giản là loại bỏ một số kí \r\n\r\ntự nằm ở cuối từ mà nó nghĩ rằng là biến thể của từ. Người ta gọi các bộ xử lí \r\n\r\nstemming là stemmer. Bởi vì nguyên tắc hoạt động của stemmer rất đơn giản nên tốc \r\n\r\nđộ xử lí của nó rất nhanh nhưng đôi khi lại cho ra kết quả không như ý muốn [10]. \r\n\r\n Ví dụ 4: Cách thực hiện của bộ stemmer \r\n\r\n Các từ walks, walked, walkingsau khi stemming, bỏ đi các hậu \r\ntố -s, -ed, -ing sẽ trở thành walk \r\n\r\n Từ gosesau stemming thành gos \r\n\r\n Không thể đưa các từ như spoke, went về dạng speak hay go \r\n\r\n Lemmatization \r\n\r\n Lemmatization là một kĩ thuật chuẩn hóa từ khác: Không giống với Stemming \r\n\r\nlà xử lí bằng cách loại bỏ các kí tự cuối từ một cách kinh nghiệm (heuristic), \r\n\r\nLemmatization sẽ xử lí thông minh hơn bằng một bộ từ điển hoặc ontology (hệ thống \r\n\r\n\r\n\r\n36 \r\n\r\n\r\nnhãn ngữ nghĩa). Điều này đảm bảo đưa chính xác các dạng biến thể của từ về nguyên \r\n\r\ngốc trong từ điển. Người ta gọi bộ xử lí lemmatization là lemmatizer \r\n\r\n Nhược điểm của lemmatization là tốc độ xử lí khá chậm vì phải thực hiện tra \r\n\r\ncứu từ trong cơ sở dữ liệu. Trong các ứng dụng xử lí ngôn ngữ tự nhiên mà cần độ \r\n\r\nchính xác cao hơn và thời gian không quan trọng, người ta có thể sử dụng \r\n\r\nLemmatization. \r\n\r\n Ví dụ 5: Cách thực hiện của Lemmatizer \r\n\r\n Các từ như gose, wentsẽ được đưa chính xác về go. \r\n\r\n Các danh từ như mouse, micecũng được đưa về cùng một dạng như \r\nnhau. \r\n\r\n Loại bỏ từ dừng \r\n\r\n Trong quá trình tính toán, từ dừng là những từ được lọc trước hoặc sau quá \r\n\r\ntrình xử lý dữ liệu ngôn ngữ tự nhiên (văn bản). Từ dừng thường là những từ xuất \r\n\r\nhiện với tần suất lớn trong một ngôn ngữ, do đó không có một danh sách các từ dừng \r\n\r\nthống nhất và được sử dụng bởi tất cả các công cụ xử lý ngôn ngữ tự nhiên. \r\n\r\n Một nhóm bất kì các từ có thể được chọn là một từ dừng để thực hiện một mục \r\n\r\nđích nhất định. Đối với một máy tìm kiếm (search engine), có một số từ được xếp vào \r\n\r\nloại từ dừng do sự xuất hiện thường xuyên trong các trường hợp tìm kiếm như: the, \r\n\r\nis, at, which và on. Trong trường hợp này, từ dừng có thể là nguyên nhân gây ra vấn \r\n\r\nđề khi tìm kiếm theo cụm từ mà bao gồm những function word này, đặc biệt là khi \r\n\r\ntìm kiếm một số tên như: The Who, The The, hoặc Take That. Ngoài ra, một \r\n\r\nsố máy tìm kiếm loại bỏ các từ common words, bao gồm cả lexical words như want \r\n\r\nkhỏi câu truy vấn nhằm mục đích cải thiện hiệu suất. \r\n\r\n Sự phân biệt giữa function words và lexical words được đề xuất bởi C. Fries \r\n\r\nvào năm 1952 và có một tầm ảnh hưởng lớn đến việc dạy tiếng Anh. \r\n\r\n Function words: Còn gọi là functors là những có một chút sự nhập \r\nnhằng về nghĩa và chúng nhấn mạnh mối quan hệ ngữ pháp với các từ \r\n\r\nkhác trong cùng một câu, một quan điểm cụ thể hay tâm trạng của người \r\n\r\nnói. Một số trường hợp của function words: Pronouns  đại từ (he  \r\n\r\nhim, she-her,.); conjunction  liên từ hoặc auxiliary verb - trợ động \r\n\r\ntừ \r\n\r\n Lexical words: Từ thực, những từ mà không phải là function word. \r\nlexical word bao gôm: danh từ, động từ, tính từ và hầu hết trạng từ vì \r\n\r\ncó một số trạng từ là function word như: then, why. \r\n\r\n  \r\n\r\n\r\n\r\n37 \r\n\r\n\r\n Từ điển có thể định nghĩa một cách cụ thể một lexical word, nhưng chỉ \r\ncó thể miêu tả một cách sử dụng tổng quát của function word. \r\n\r\n Ngược lại, ngữ pháp có thể miêu tả cách sử dụng của function words \r\nmột cách chi tiết, nhưng lại chỉ có thể xem lexical words trong các thuật \r\n\r\nngữ chung (general term). \r\n\r\n Gán nhãn từ loại \r\n\r\n \r\n\r\n PoS: Part of Speech  Gán nhãn từ loại, là cơ sở phục vụ cho các bài toán về \r\n\r\nngữ nghĩa cao hơn. Đồ án sử dụng bộ PoS Tagging trong bộ công cụ xử lý ngôn ngữ \r\n\r\ntự nhiên Stanford Core NLP. Trong bộ Tagger này, các tên viết tắt cho các nhãn từ \r\n\r\nloại trong tiếng Anh sử dụng hệ thống nhãn Penn Treebank gồm 36 nhãn. \r\n\r\n Sau khi gán nhãn từ loại bằng Stanford PoS Tagger, những nhãn này sẽ được \r\n\r\nchuyển sang định dạng Universal PoS Tags. Hai bảng dưới đây trình bày hệ thống \r\n\r\nnhãn trong Universal PoS và Peen treebank. \r\n\r\n \r\n\r\nOpen class word Closed class word Other \r\n\r\nADJ ADP PUNCT \r\n\r\nADV AUX SYM \r\n\r\nINTJ CCONJ X \r\n\r\nNOUN DET  \r\n\r\nPROPN NUM  \r\n\r\nVERB PART  \r\n\r\n PRON  \r\n\r\n SCONJ  \r\n\r\n \r\n\r\n\r\n  \r\n\r\n\r\n\r\n38 \r\n\r\n\r\nSTT Nhãn Mô tả \r\n\r\n1 CC Coordinating conjunction \r\n\r\n2 CD Cardinal number \r\n\r\n3 DT Determiner \r\n\r\n4 EX Existential there \r\n\r\n5 FW Foreign word \r\n\r\n6 IN Preposition/ subordinating conjunction \r\n\r\n7 JJ Adjective \r\n\r\n8 JJR Adjective, comparative \r\n\r\n9 JJS Adjective, superlative \r\n\r\n10 LS List item marker \r\n\r\n11 MD Modal \r\n\r\n12 NN Noun, singular or mass \r\n\r\n13 NNS Noun, plural \r\n\r\n14 NNP Proper noun, singular \r\n\r\n15 NNPS Proper noun, plural \r\n\r\n16 PDT Predeterminer \r\n\r\n17 POS Possessive ending \r\n\r\n18 PRP Personal pronoun \r\n\r\n19 PRP$ Possessive pronoun \r\n\r\n20 RB Adverb \r\n\r\n21 RBR Adverb, comparative \r\n\r\n22 RBS Adverb, superlative \r\n\r\n23 RP Particle \r\n\r\n24 SYM Symbol \r\n\r\n25 TO to \r\n\r\n26 UH Interjection \r\n\r\n27 VB Verb, base form \r\n\r\n28 VBD Verb, past tense \r\n\r\n29 VBG Verb, gerund or present participle \r\n\r\n30 VBN Verb, past participle \r\n\r\n31 VBP Verb, non-3rd person singular present \r\n\r\n32 VBZ Ver, 3rd persion singular present \r\n\r\n33 WDT Wh-determiner \r\n\r\n34 WP Wh-pronoun \r\n\r\n35 WP$ Possessive wh-pronoun \r\n\r\n36 WRB Wh-adverb \r\n\r\n  \r\n\r\n\r\n\r\n\r\n39 \r\n\r\n\r\n3.4.2 Khối phân tích ma trận NMF \r\n\r\n Sử dụng thuật toán trình bày tại mục 2.2 , chúng ta thu được ma trận tần suất \r\n\r\ntừ văn bản đầu vào lần một. Tiếp theo, sử dụng mô hình Word2Vec đã được huấn \r\n\r\nluyện để điều chỉnh ma trận tần suất này. Quá trình tính toán sử dụng bước trung gian \r\n\r\nlà xây dựng từ điển tương đồng cho tập từ vựng trong văn bản nguồn với độ tương \r\n\r\nđồng được xác định qua thực nghiệm. \r\n\r\n Cuối cùng, sử dụng phép phân tích ma trận không âm để phân tích ma trận tần \r\n\r\nsuất thành ma trận đặc trưng ngữ nghĩa không âm và ma trận biến ngữ nghĩa không \r\n\r\nâm. \r\n\r\n \r\n\r\n Xây dựng từ điển tương đồng (Thesaurus): Dựa vào mô hình Word2Vec đã \r\n\r\nđược huấn luyện, ta sẽ xây dựng một từ điển tương đồng để phục vụ cho bài toán tóm \r\n\r\ntắt văn bản tự động. \r\n\r\n Từ điển tương đồng được xây dựng bằng cách tính khoảng cách giữa các từ \r\n\r\nbằng độ tương đồng cosine và được xây dựng đối với tập từ vựng thu được từ văn \r\n\r\nbản tóm tắt. Bằng cách thực hiện nhiều thực nghiệm để xác định khoảng tương đồng \r\n\r\nhợp lí, từ điển sẽ bao gồm 1 từ gốc và tập các từ vựng có nét nghĩa gần với nó nhất, \r\n\r\nđạt độ tương đồng cosine  0.60 \r\n\r\n \r\n\r\n Ví dụ 6: Xác định từ đồng nghĩa khi độ tương đồng  0.60: \r\n\r\n Girl: \r\n\r\n Boy 0.88 \r\n\r\n Schoolgirl 0.73 \r\n\r\n Woman 0.64 \r\n\r\n 12-year-old 0.64 \r\n\r\n 14-year-old 0.63 \r\n\r\n 13-year-old 0.63 \r\n\r\n Kid 0.62 \r\n\r\n Teenage 0.60 \r\n\r\n 11-year-old 0.60 \r\n\r\n Mỗi từ trong văn bản tóm tắt sẽ được ánh xạ thành một vec-tơ 300 chiều (bằng \r\n\r\nvới số chiều của các vec-tơ trong mô hình Word2Vec được huấn luyện). \r\n\r\n Khoảng cách giữa các từ chính là khoảng cách giữa hai vec-tơ trong không \r\n\r\ngian. \r\n\r\n  \r\n\r\n\r\n\r\n40 \r\n\r\n\r\n Điều chỉnh trọng số ma trận sử dụng Word2Vec: Mô hình Word2Vec sau \r\n\r\nhuấn luyện được sử dụng như đầu vào của khối phân tích ma trận không âm trong \r\n\r\nviệc xác định trọng số cho từ trong tài liệu. Bằng cách sử dụng từ điển tương đồng đã \r\n\r\nxây dựng từ bước trước, chúng ta tính tần suất xuất hiện của một từ trong tài liệu bằng \r\n\r\ntần suất xuất hiện của từ gốc và các từ tương đồng với từ gốc. Công thức cập \r\n\r\nnhật giá trị cho ma trận tần suất được thể hiện như sau: \r\n\r\n \r\n\r\n () = () + ( ) (56) \r\n\r\n \r\n\r\n Trong đó: \r\n\r\n value(Aij) là giá trị của ô (i, j) trong ma trận tần suất A trong phân tích \r\n\r\nNMF \r\n\r\n count(Termij) là số lần xuất hiện của termi của câu j trong tài liệu \r\n\r\n count(Similar Termij) là số lần xuất hiện của những term có nét nghĩa \r\n\r\ntương đồng với termij trong tài liệu thỏa mãn ngưỡng tương đồng về \r\n\r\nngữ nghĩa nhất định  độ đo cosine. \r\n\r\n \r\n\r\n Áp dụng kĩ thuật phân tích ma trận không âm đối với ma trận tần suất A, ta \r\n\r\nthu được đầu ra của phép phân tích ma trận NMF là hai ma trận: ma trận đặc trưng \r\n\r\nngữ nghĩa không âm (non-negative semantic feature matrix) W và ma trận biến ngữ \r\n\r\nnghĩa không âm H (non-negative semantic variable matrix).  \r\n\r\n  \r\n\r\n Đầu ra của khối phân tích NMF: Sử dụng một phương pháp mới để chọn \r\n\r\ncâu dựa trên phân tích NMF và định nghĩa đại lượng Generic Relevance of a \r\n\r\nSentence[4] (GRS  độ liên quan của câu)  như sau: \r\n\r\n   (57) \r\n\r\n               =   (  ())\r\n\r\n\r\n\r\n=1\r\n\r\n \r\n\r\n  \r\n\r\n \r\n() =\r\n\r\n \r\n\r\n=1\r\n\r\n  \r\n\r\n=1\r\n\r\n\r\n=1\r\n\r\n \r\n(58) \r\n\r\n \r\n\r\n Trong đó, trọng số weight(Hi*) là sự liên quan về quan hệ (relative relevance) \r\n\r\ncủa đặc trưng ngữ nghĩa thứ i (W*i) với tất cả các đặc trưng ngữ nghĩa còn lại. Một \r\n\r\ncách tổng quát, đại lượng thể hiện mức độ liên quan của một câu chính là mức độ \r\n\r\nphản ánh của câu đó đối với chủ đề chính của tài liệu, và được biểu diễn dưới hình \r\n\r\nthức các đặc trưng ngữ nghĩa. \r\n\r\n\r\n\r\n41 \r\n\r\n\r\n3.4.3 Khối tính điểm cho câu \r\n\r\n Khối tính điểm cho câu trong tài liệu là tổng hợp điểm đầu ra của 3 khối nhỏ \r\n\r\nhơn, trong đó: \r\n\r\n Sử dụng khối Word2Vec như một đặc trưng thứ nhất để xác định các \r\n\r\nngữ nghĩa ẩn trong bài toán tóm tắt. \r\n\r\n Sử dụng khối đặc trưng thứ hai để phân tích các đặc trưng cấu trúc của \r\n\r\ntài liệu. \r\n\r\n Sử dụng kết quả của kĩ thuật phân tích ma trận NMF.  \r\n\r\n \r\n\r\n Đầu ra của khối các đặc trưng cấu trúc: Bằng các kết quả thực nghiệm tại \r\n\r\nmục 4.4.2 , ta chọn được tập các đặc trưng mang lại kết quả tốt nhất để áp dụng cho \r\n\r\nbài toán tóm tắt văn bản. Các đặc trưng đó bao gồm: \r\n\r\n Đặc trưng bề mặt \r\n\r\n Đặc trưng nội dung \r\n\r\n Đặc trưng độ liên quan \r\n\r\n \r\n\r\n Trong đó, trọng số cho từng nhóm đặc trưng được xác định như sau: \r\n\r\n Đặc trưng bề mặt:  \r\n\r\n Câu văn đứng ở vị trí đầu tài liệu nhận trọng số bằng 1. Các câu \r\n\r\nphía sau sẽ có trọng số giảm dần. \r\n\r\n Trọng số cho Vị trí thuộc đoạn [0, 1] \r\n\r\n Ngưỡng độ dài trung bình (giá trị cutoff) được quy định cho câu \r\n\r\nvăn thuộc chủ đề báo chí là 12. \r\n\r\n Đặc trưng nội dung \r\n\r\n Dựa vào đặc trưng Centroid để xác định câu nào tập trung vào \r\n\r\nchủ đề văn bản. \r\n\r\n Trọng số cho Centroid thuộc đoạn [0, 1] \r\n\r\n Đặc trưng độ liên quan: \r\n\r\n Đặc trưng này được sử dụng để tìm ra mối liên hệ giữa các câu \r\n\r\ntrong tài liệu. \r\n\r\n Để làm được điều đó, ta đặt ra quy ước rằng, giữa các câu luôn \r\n\r\ntồn tại mối liên hệ với nhau. Có một số câu quan trọng, những \r\n\r\ncâu khác liên quan đến những câu đó cũng là câu quan trọng. \r\n\r\n Tại thời điểm ban đầu, câu đầu tiên của tài liệu và câu đầu tiên \r\n\r\ncủa đoạn văn là quan trọng. \r\n\r\n Sử dụng độ tương đồng cosine để xác định độ liên quan giữa các \r\n\r\ncâu. \r\n\r\n\r\n\r\n42 \r\n\r\n\r\n Công thức tính điểm cuối cùng \r\n\r\n \r\n\r\n Để  â =  + Để ấ ú (59) \r\n\r\n \r\n\r\n Trong đó: \r\n\r\n Điểm cho câu: Giá trị trọng số cuối cùng cho câu văn. Các câu quan \r\n\r\ntrọng được trích rút theo thứ tự giảm dần của giá trị Điểm cho câu \r\n\r\n GRS: Generic Relevance of a jth sentence, giá trị đầu ra của phân tích \r\n\r\nNMF \r\n\r\n Điểm cấu trúc: Giá trị trọng số của câu dựa vào các đặc trưng cấu trúc. \r\n\r\n    (60) \r\n\r\nĐể ấ ú = {\r\n2  () + 0.5  ()   > 12\r\n                                           0                        < 12\r\n\r\n \r\n\r\n \r\n\r\n Trong đó: \r\n\r\n Centroid: Điểm cho đặc trưng Centroid \r\n\r\n Position: Điểm cho đặc trưng Vị trí \r\n\r\n Length: Độ dài của câu, lớn hơn hay nhỏ hơn 12 từ. \r\n\r\n \r\n\r\n3.4.4 Khối trích rút câu \r\n\r\n Từ văn bản tóm tắt tại đầu vào, các câu được phân chia và nhận một trọng số \r\n\r\ntương ứng với mức độ quan trọng trong tài liệu. Tập hợp các câu này được sắp xếp \r\n\r\ntrong một danh sách theo thự giảm dần của giá trị Điểm cho câu. Lần lượt chọn ra \r\n\r\ncác câu quan trong nhất cho đến khi văn bản đạt ngưỡng độ dài yêu cầu (mục 4.2.2 ), \r\n\r\nsau đó sắp xếp các câu được trích rút theo thứ tự xuất hiện trong văn bản đầu vào, \r\n\r\nchúng ta thu được văn bản tóm tắt cuối cùng. \r\n\r\n \r\n\r\n3.5 Kết luận \r\n\r\n \r\n\r\n Như vậy, trong chương 3, đồ án đã tập trung vào việc phân tích ưu-nhược điểm \r\n\r\ncủa các mô hình tính toán truyền thống trong bài toán tóm tắt văn bản tự động, từ đó \r\n\r\nđề xuất thiết kế, xây dựng các mô hình tính toán mới có chất lượng tốt hơn, bao gồm \r\n\r\ncác công việc: Xây dựng công thức tính trọng số cho các đặc trưng cấu trúc, xây dựng \r\n\r\nmô hình Word2Vec, ứng dụng Word2Vec và các đặc trưng cấu trúc để nâng cao độ \r\n\r\nchính xác cho kĩ thuật phân tích ma trận NMF. Chương tiếp theo tôi sẽ trình bày chi \r\n\r\ntiết việc xây dựng hệ thống theo mô hình đã thiết kế tại các bước trên. \r\n\r\n  \r\n\r\n\r\n\r\n43 \r\n\r\n\r\nCHƯƠNG 4 XÂY DỰNG VÀ THỰC NGHIỆM \r\n\r\n \r\n\r\n Với mô hình tính toán được đưa ra từ những chương trước, chương này tôi sẽ \r\n\r\ntrình bày chi tiết việc phát triển hệ thống tóm tắt dựa trên mô hình đề xuất để giải \r\n\r\nquyết bài toán tóm tắt văn bản báo chí tiếng Anh. Từ đó, tiến hành các thực nghiệm \r\n\r\nkiểm tra việc áp dụng hệ thống được xây dựng. \r\n\r\n \r\n\r\n4.1 Xây dựng hệ thống tóm tắt văn bản \r\n\r\n  \r\n\r\n Từ kết quả thu được từ các bước trước, tôi đã tìm hiểu và lựa chọn các công \r\n\r\ncụ để xây dựng hệ thống theo chức năng của từng mô-đun trong mô hình. \r\n\r\n \r\n\r\n4.1.1 Khối tiền xử lý \r\n\r\n  \r\n\r\n Trong khối tiền xử lý tổng quát, có hai công việc : Tiền xử lý cho ngữ liệu đầu \r\n\r\nvào để huấn luyện mô hình Word2Vec và Tiền xử lý đối với văn bản tóm tắt. Trong \r\n\r\nđó, tiền xử lý cho ngữ liệu dùng cho huấn luyện sử dụng bộ công cụ NLTK (Natural \r\n\r\nLanguage Toolkit) chuyên dùng để xử lý các vấn đề liên quan đến ngôn ngữ tự nhiên. \r\n\r\nĐối với quá trình tiền xử lý cho văn bản tóm tắt, sử dụng hai công cụ liên quan đến \r\n\r\nChuẩn hóa từ (mô-đun của NLTK) và gắn nhãn từ loại (PoS) (sử dụng bộ Stanford \r\n\r\nCore NLP). \r\n\r\n \r\n\r\n4.1.1.1 Bộ công cụ NLTK \r\n\r\n \r\n\r\n NLTK là một bộ công cụ dành riêng cho NLP và được tích hợp vào Python. \r\n\r\nNó đang ngày càng hoàn thiện và tích hợp các công cụ mới bởi hàng nghìn lập trình \r\n\r\nviên và cộng tác viên trên khắp thế giới. NLTK bao gồm những thư viện hàm, các \r\n\r\ncông cụ phân tích, nguồn ngữ liệu, wordnet,. giúp đơn giản hóa, tiết kiệm thời gian \r\n\r\nvà công sức cho các lập trình viên.  \r\n\r\n NLTK cung cấp một giao diện dễ sử dụng với hơn 50 bộ ngữ liệu và lexical \r\n\r\nresources với các thư viện hỗ trợ tiền xử lý văn bản dành cho các tác vụ phân loại, \r\n\r\ntokenization, stemming, gán nhãn từ loại, phân tích cú pháp và suy diễn ngữ nghĩa  \r\n\r\nsematic reasoning.  \r\n\r\n  \r\n\r\n  \r\n\r\n\r\n\r\n44 \r\n\r\n\r\n Một số ví dụ về chức năng trong bộ công cụ NLTK: \r\n\r\n \r\n>>> import nltk \r\n\r\n>>> sentence = \"\"\"At eight o'clock on Thursday morning \r\n\r\n... Arthur didn't feel very good.\"\"\" \r\n\r\n>>> tokens = nltk.word_tokenize(sentence) \r\n\r\n>>> tokens \r\n\r\n['At', 'eight', \"o'clock\", 'on', 'Thursday', 'morning', \r\n\r\n'Arthur', 'did', \"n't\", 'feel', 'very', 'good', '.'] \r\n\r\n>>> tagged = nltk.pos_tag(tokens) \r\n\r\n>>> tagged[0:6] \r\n\r\n[('At', 'IN'), ('eight', 'CD'), (\"o'clock\", 'JJ'), ('on', 'IN'), \r\n\r\n('Thursday', 'NNP'), ('morning', 'NN')] \r\n\r\n \r\n\r\n\r\n \r\n>>> entities = nltk.chunk.ne_chunk(tagged) \r\n\r\n>>> entities \r\n\r\nTree('S', [('At', 'IN'), ('eight', 'CD'), (\"o'clock\", 'JJ'), \r\n\r\n           ('on', 'IN'), ('Thursday', 'NNP'), ('morning', 'NN'), \r\n\r\n       Tree('PERSON', [('Arthur', 'NNP')]), \r\n\r\n           ('did', 'VBD'), (\"n't\", 'RB'), ('feel', 'VB'), \r\n\r\n           ('very', 'RB'), ('good', 'JJ'), ('.', '.')]) \r\n\r\n \r\n\r\n \r\n\r\n\r\n \r\n\r\n \r\n\r\n \r\n\r\n\r\n \r\n\r\n4.1.1.2 Bộ công cụ Stanford Core NLP \r\n\r\n \r\n\r\n Stanford CoreNLP cung cấp một tập các công cụ phân tích ngôn ngữ tự nhiên. \r\n\r\nCông cụ này cho phép xác định các dạng nguyên thể của từ vựng, gán nhãn từ loại \r\n\r\n(PoS tagging), gán nhãn tên thực thể (Named-Entity recognition). Chuẩn hóa ngày, \r\n\r\ngiờ,.  \r\n\r\n \r\n\r\n \r\n\r\n\r\n\r\n45 \r\n\r\n\r\n4.1.2 Khối huấn luyện mô hình \r\n\r\n \r\n\r\n Với dữ liệu đã được tiền xử lý, tôi sử dụng mã nguồn mở gensim[3]  một \r\n\r\ntrong những mã nguồn mở tốt nhất về Word2Vec-Doc2Vec trên ngôn ngữ PYTHON. \r\n\r\nVới các tùy chỉnh về việc lựa chọn kiến trúc, số lượng chiều vec-tơ,.ta thu được mô \r\n\r\nhình Word2Vec. \r\n\r\n Mô hình sau khi huấn luyện thành công sẽ được lưu trữ và có thể sử dụng độc \r\n\r\nlập trên một máy đơn chứ không nhất thiết phải cùng hệ thống huấn luyện. \r\n\r\n \r\n\r\n4.1.3 Khối phân tích ma trận \r\n\r\n \r\n\r\n Sử dụng mô hình Word2Vec sau khi huấn luyện thành công với các dữ liệu là \r\n\r\nvăn bản cần tóm tắt đã được xử lý, tôi sử dụng mã nguồn mở Scikit-learn để khởi tạo \r\n\r\ncác thuật toán phân tích ma trận. \r\n\r\n Có thể nói, thư viện Scikit-learn chính là một trong số những nền tảng phổ \r\n\r\nbiến nhất hiện nay dành cho lĩnh vực học máy và khoa học dữ liệu [2]. Scikit-learn \r\n\r\nđược xây dựng trên nền Python, một ngôn ngữ lập trình với sự hỗ trợ đầy đủ và mạnh \r\n\r\nmẽ. Được cung cấp một số lượng lớn các thuật toán hiệu quả, bao phủ trọn lĩnh vực \r\n\r\nhọc máy và khoa học dữ liệu : Phân lớp, phân cụm, tiền xử lý dữ liệu, giảm số chiều, \r\n\r\nlựa chọn mô hình,... Scikit-learn còn được biết đến với sự rõ ràng, nhất quán và hợp \r\n\r\nlý trong API của mình. Điểm lợi của tính nhất quán trong trường hợp này là : Một khi \r\n\r\nngười đọc hiểu được ký pháp và cách sử dụng căn bản của Scikit-learn cho một mô \r\n\r\nhình thì việc chuyển đổi sang một mô hình mới hoặc thuật toán mới là vô cùng dễ \r\n\r\ndàng. Ngoài ra, song song với đó là nguồn tài liệu online luôn đầy đủ và thuận tiện. \r\n\r\n  \r\n\r\n\r\n\r\n46 \r\n\r\n\r\n4.2 Dữ liệu thực nghiệm \r\n\r\n \r\n\r\n4.2.1 Ngữ liệu huấn luyện Word2Vec \r\n\r\nĐặc điểm Chi tiết \r\n\r\nSố lượng Tokens 2.3 tỉ \r\n\r\nSố lượng từ khác nhau 296,630 từ \r\n\r\n \r\n\r\nTiền xử lí \r\n\r\n \r\n\r\n \r\n\r\nChia thành các câu \r\n\r\nLemmatized \r\n\r\nGắn nhãn từ loại \r\n\r\nLoại bỏ từ dừng \r\n\r\nĐộ dài cửa sổ ngữ cảnh \r\n5 từ bên trái & \r\n\r\n5 từ bên phải \r\n\r\nThuật toán Continuous Skip-Gram \r\n\r\nHiệu năng của mô hình \r\n\r\n \r\n\r\nSimLex999 0.40 \r\n\r\nGoogle \r\n\r\nAnalogy \r\n0.81 \r\n\r\n \r\n\r\n\r\n \r\n\r\n Ngữ liệu dùng để xây dựng mô hình Word2Vec là nguồn dữ liệu từ Wikipedia. \r\n\r\nCác chủ đề bao gồm : Báo chí, tin tức. Thông tin chi tiết của bộ ngữ được trình bày \r\n\r\ntrong hình vẽ trên. Đây là những trang báo chí và tin tức đáng tin cậy, phủ rộng trên \r\n\r\nnhiều lĩnh vực. Việc lấy dữ liệu từ nguồn Wikipedia cho phép ta xây dựng một mô \r\n\r\nhình vec-tơ hóa đặc thù cho dữ liệu văn bản báo chí nhưng vẫn đầy đủ các lĩnh vực. \r\n\r\nNguồn ngữ liệu này sẽ được tiền xử lý trước khi được đưa vào mô hình, bao gồm: \r\n\r\nchia dữ liệu theo đơn vị câu, tách câu thành các token, thực hiện chuẩn hóa từ, gắn \r\n\r\nnhãn từ loại, gắn nhãn tên thực thể và loại bỏ từ dừng.  \r\n\r\n Độ dài của cửa sổ ngữ cảnh dùng để huấn luyện mô hình Word2Vec gồm 5 từ \r\n\r\nphía trước và 5 từ phía sau. \r\n\r\n Mô hình Word2Vec sau huấn luyện thu được có kích thước 340 MB. Các độ \r\n\r\nđo được sử dụng để đánh giá chất lượng của model bao gồm : SimLex999 và Google \r\n\r\nAnalogy lần lượt là : \r\n\r\n SimLex999: 0.4 \r\n\r\n Google Analogy: 0.81  \r\n\r\n\r\n\r\n47 \r\n\r\n\r\n4.2.2 Bộ dữ liệu đánh giá tóm tắt văn bản \r\n\r\n \r\n\r\n Đồ án sử dụng tập dữ liệu DUC 2004 như là một tập dữ liệu để kiểm tra. \r\n\r\nDocument Understanding Conference (DUC) là một hội nghị quốc tế để đánh giá \r\n\r\nhiệu suất của hệ thống tóm tắt bằng cách so sánh bản tóm tắt bằng tay của các chuyên \r\n\r\ngia với bản tóm tắt tự động của máy tính. \r\n\r\n \r\n\r\nTác vụ #Cụm #Nguồn \r\n\r\nTác vụ 1 \r\n50 TDT  \r\n\r\nTiếng Anh \r\nThời báo AP, \r\n\r\nTác vụ 2 \r\n50 TDT \r\n\r\nTiếng Anh  \r\n\r\nThời báo \r\n\r\nNewYorkTimes  \r\n\r\nTác vụ 3 \r\n25 TDT \r\n\r\nTiếng Ả-rập  \r\n\r\nThời báo Agence \r\n\r\nFrance, \r\n\r\nTác vụ 4 \r\n25 TDT \r\n\r\nTiếng Ả-rập \r\n\r\nThời báo \r\n\r\nẢ-rập \r\n\r\nTác vụ 5 \r\n50TREC \r\n\r\nTiếng Anh \r\n\r\nThời báo AP, \r\n\r\nThời báo \r\n\r\nNewYorkTimes, \r\n\r\nThời báo \r\n\r\nTân Hoa Xã \r\n\r\n \r\n\r\n\r\n(TDT: Topic detection and tracking) \r\n\r\n \r\n\r\n DUC 2004 là bộ dữ liệu dùng cả cho tóm tắt đơn văn bản và đa văn bản, trong \r\n\r\nkhi DUC 2003 trở về trước chỉ áp dụng cho đơn văn bản và DUC 2005 trở về sau chỉ \r\n\r\náp dụng cho tóm tắt đa văn bản. \r\n\r\n DUC 2004 bao gồm các văn bản thể loại báo chí. \r\n\r\n Tác vụ 1 : Tóm tắt văn bản rất ngắn (văn bản tóm tắt 10 từ) \r\n\r\n Tác vụ 2 : Tóm tắt văn bản ngắn tập trung vào các sự kiện ( văn bản \r\n\r\ntóm tắt 100 từ) \r\n\r\n\r\n\r\n48 \r\n\r\n\r\n Tác vụ 3 và Tác vụ 4 : Chứa các bản tóm tắt từ một nguồn nhiễu, được \r\n\r\nsinh ra từ quá trình dịch máy (machine translation) từ tiếng Ả-rập sang \r\n\r\ntiếng Anh (văn bản tóm tắt 100 từ) \r\n\r\n Tác vụ 5 : Bao gồm các tóm tắt tập trung vào dạng truy vấn. \r\n\r\n \r\n\r\n4.3 Đánh giá chất lượng tóm tắt \r\n\r\n \r\n\r\n Đồ án sử dụng độ đánh giá ROUGE cho sự so sánh giữa các bản tóm tắt tự \r\n\r\nđộng và bản tóm tắt tham chiếu bởi các chuyên gia có trong tập dữ liệu thử nghiệm.  \r\n\r\nROUGE  viết tắt của Recall-Oriented Understudy for Gisting Evaluation. ROUGE \r\n\r\nbao gồm bộ các độ đo để đánh giá tự động chất lượng của văn bản tóm tắt bằng cách \r\n\r\nso sánh bản tóm tắt sinh ra bởi hệ thống với những bản tóm tắt được tạo ra bởi con \r\n\r\nngười. Các độ đo cơ bản ROUGE bao gồm : ROUGE-N, ROUGE-L, ROUGE-W và \r\n\r\nROUGE-S. Trong đó 3 trong số các độ đo trên được sử dụng trong DUC 2004. \r\n\r\n \r\n\r\n4.3.1 ROUGE-N: Thống kê số lần xuất hiện đồng thời của các N-gram (N-gram \r\n\r\nCo-Occurrence Statistics) \r\n\r\n \r\n\r\n ROUGE-N là một thu hồi n-gram (n-gram recall) giữa một bản tóm tắt tự \r\n\r\nđộng và một tập các tài liệu tóm tắt tham chiếu (ReferenceSummaries). ROUGE-N \r\n\r\nđược tính như sau: \r\n\r\n    (61) \r\n\r\n \r\n\r\n         =  \r\n  (){}\r\n\r\n  (){}\r\n \r\n\r\n \r\n\r\n Trong đó: \r\n\r\n n là chiều dài của n-gram \r\n\r\n Countmatch(gramn) là số lượng tối đa n-gram có thể xảy ra đồng thời \r\n\r\ntrong bản tóm tắt tự động và bản tóm tắt tham chiếu. \r\n\r\n Rõ ràng ROUGE-N là một độ đo liên quan đến độ recall bởi vì mẫu số của vế \r\n\r\nphải trong công thức trên là tổng số n-gram xảy ra ở phía bản tóm tắt tham chiếu. \r\n\r\n Cũng có một lưu ý rằng, số lượng n-gram ở mẫu số trong công thức tính \r\n\r\nROUGE-N sẽ tăng lên khi chúng ta cho thêm nhiều tham chiếu. Điều này hoàn toàn \r\n\r\ntrực quan và hợp lí bởi vì có thể tồn tại nhiều bản tóm tắt tốt. \r\n\r\n Mỗi khi chúng ta thêm một tham chiếu vào tập các văn bản tham chiếu, chúng \r\n\r\nta đã mở rộng không gian các văn bản tóm tắt thay thế (alternative summaries). Bằng \r\n\r\n\r\n\r\n49 \r\n\r\n\r\ncách điều khiển các kiểu tham chiếu mà ta thêm vào tập văn bản tham chiếu, chúng \r\n\r\nta có thể thiết kế các đánh giá tập trung vào các khía cạnh khác nhau của việc tóm tắt. \r\n\r\nNgoài ra, tổng tử số lớn hơn tổng số số bản tóm tắt tham chiếu. Điều này hiệu quả vì \r\n\r\ncung cấp thêm nhiều trọng số để so khớp các n-grams xảy ra trong đa tham chiếu. \r\n\r\nDo đó, một bản tóm tắt tự động càng chứa nhiều những từ được xuất hiện trong nhiều \r\n\r\nbản tóm tắt tham chiếu thì sẽ dành được điểm ROUGE-N càng cao. Điều này một lần \r\n\r\nnữa lại rất trực quan và hợp lí bởi vì chúng ta thường ưu tiên các bản tóm tắt tự động \r\n\r\ncàng có nhiều nét giống với các điểm giống nhau giữa các bản tóm tắt tham chiếu \r\n\r\ncàng tốt. \r\n\r\n Khi sử dụng đa tham chiếu, chúng ta tính ROUGE-N theo từng cặp, giữa bản \r\n\r\ntóm tắt tự động s và từng bản tóm tắt tham chiếu ri trong tập các văn bản tóm tắt tham \r\n\r\nchiếu. Sau đó, kết quả điểm ROUGE-N cuối cùng trong đa tham chiếu sẽ là điểm \r\n\r\nROUGE-N cao nhất trong tất cả các cặp được tính. Điều này được thể hiện theo công \r\n\r\nthức sau: \r\n\r\n    =   ( , ) (62) \r\n\r\n \r\n\r\n Trong quá trình khởi tạo, thuật toán đánh giá sử dụng thủ tục Jackknifing. \r\n\r\nCho M tham chiếu, chúng ta tính điểm tốt nhất khi duyệt qua M tập tham chiếu M-\r\n\r\n1; điểm ROUGE-N cuối cùng là trung bình cộng của M điểm ROUGE-N đối với các \r\n\r\ntham chiếu M-1. Thủ tục Jackknifing được chọn bởi chúng ta thường cần so sánh \r\n\r\nhiệu suất giữa con người và hệ thống và bản tóm tắt tham chiếu thường chỉ do con \r\n\r\nngười tạo ra. \r\n\r\n Bằng cách áp dụng thủ tục này, chúng ta có thể ước lượng hiệu suất trung bình \r\n\r\ncủa con người bằng việc lấy trung bình cộng M điểm ROUGE-N của một bản tham \r\n\r\nchiếu với toàn bộ M-1 tham chiếu. \r\n\r\n \r\n\r\n4.3.2 Độ đo sử dụng để đánh giá chất lượng tóm tắt \r\n\r\n \r\n\r\n Trong phạm vi nghiên cứu, tôi đề xuất sử dụng 2 độ đo ROUGE-1 và ROUGE-\r\n\r\n2 tương ứng với n = 1 và n = 2 trong ROUGE-N để đánh giá chất lượng của văn bản \r\n\r\ncần tóm tắt. \r\n\r\n  \r\n\r\n\r\n\r\n50 \r\n\r\n\r\n4.4 Kết quả thực nghiệm \r\n\r\n \r\n\r\n Đồ án tập trung vào việc nghiên cứu kết hợp phương pháp tóm tắt không giám \r\n\r\nsát  đại diện là phương pháp phân tích ma trận NMF và ứng dụng của phương pháp \r\n\r\nhọc sâu  đại diện là biểu diễn phân tán của từ nên việc thiết kế các trường hợp thực \r\n\r\nnghiệm sẽ lấy trường hợp NMF và Word2Vec làm cơ sở. \r\n\r\n Các thí nghiệm được thiết kế bao gồm 2 mục tiêu chính: \r\n\r\n Đánh giá và lựa chọn hướng tiếp cận tóm tắt \r\n\r\n Đánh giá và lựa chọn đặc trưng  \r\n\r\n Đánh giá và lựa chọn phương pháp tóm tắt \r\n\r\n \r\n\r\n4.4.1 Kết quả lựa chọn hướng tiếp cận \r\n\r\n  \r\n\r\n                           Rouge Rouge-1 Rouge-2 \r\n\r\nNMF 37.488 7.858 \r\n\r\n Surface + Relevance + \r\n\r\nContent \r\n38.351 8.856 \r\n\r\nNMF + \r\n\r\nWord2Vec \r\n39.979 8.921 \r\n\r\n \r\n\r\n\r\n \r\n\r\n Từ kết quả thí nghiệm 1 ta có nhận xét : \r\n\r\n Phương pháp tiếp cận theo hướng cấu trúc sử dụng 3 đặc trưng cấu trúc: \r\n\r\nđặc trưng bề mặt, độ liên quan và nội dung có kết quả tốt hơn hướng \r\n\r\nphân tích ma trận không âm NMF \r\n\r\n Phương pháp kết hợp phân tích ma trận không âm và Word2Vec cho \r\n\r\nkết quả tốt hơn phương pháp tiếp cận theo hướng cấu trúc \r\n\r\n \r\n\r\n Như vậy, trong 3 hướng tiếp cận thì trường hợp kết hợp phương pháp biểu \r\n\r\ndiễn trong không gian vec-tơ và biểu diễn phân tán của từ là có kết quả tốt hơn cả. \r\n\r\nTuy nhiên, chúng ta sẽ thực hiện thí nghiệm tiếp theo để nghiên cứu việc kết hợp cả \r\n\r\n3 hướng tiếp cận này vào trong cùng phương pháp. \r\n\r\n Tại thí nghiệm này, sẽ thực hiện việc lựa chọn theo từng đặc trưng để kết hợp \r\n\r\nvới 2 kĩ thuật phân tích ma trận không âm và Word2Vec. \r\n\r\n \r\n\r\n  \r\n\r\n\r\n\r\n51 \r\n\r\n\r\n4.4.2 Kết quả lựa chọn đặc trưng \r\n\r\n \r\n\r\n               Rouge Rouge-1 Rouge-2 \r\n\r\nNMF+ Word2Vec + \r\n\r\nRelevance \r\n43.555 11.233 \r\n\r\nNMF+ Word2Vec + \r\n\r\nSurface \r\n45.982 15.011 \r\n\r\nNMF+ Word2Vec + \r\n\r\nContent \r\n46.013 15.231 \r\n\r\n \r\n\r\n\r\n \r\n\r\n Thí nghiệm 2 cho chúng ta các nhận xét : \r\n\r\n Trong 3 đặc trưng, thì đặc trưng Content cho chất lượng văn bản tóm \r\n\r\ntắt tốt nhất \r\n\r\n Đặc trưng Surface khi kết hợp với NMF và Word2Vec thì cho kết quả \r\n\r\ncao hơn Relevance nhưng thấp hơn đặc trưng Content \r\n\r\n Dựa vào kết quả thí nghiệm 2, ta thiết kế thí nghiệm 3 để kiểm tra và so sánh \r\n\r\ngiữa các kết quả khi kết hợp nhiều đặc trưng lại với nhau; theo từng cặp một, hoặc \r\n\r\nkết hợp cả 3 đặc trưng. Vì như đã trình bày tại Chương 2 mục 2.1.3.1 : Mỗi đặc trưng \r\n\r\ncấu trúc đóng góp một vai trò riêng của mình và có thể sự kết hợp các đặc trưng với \r\n\r\nnhau sẽ cho chúng ta một kết quả có ý nghĩa. \r\n\r\n \r\n\r\n4.4.3 Kết quả cuối cùng \r\n\r\n \r\n\r\nRouge \r\n\r\n \r\nRouge-1 Rouge-2 \r\n\r\nNMF+ Word2Vec + \r\n\r\nSurface + Relevance \r\n42.501 11.112 \r\n\r\nNMF+ Word2Vec + \r\n\r\nRelevance + Content \r\n45.175 15.210 \r\n\r\nNMF+ Word2Vec + \r\n\r\nSurface + Content \r\n45.817 14.101 \r\n\r\nNMF+ Word2Vec + \r\n\r\n3 Features \r\n49.979 12.911 \r\n\r\n \r\n\r\n\r\n\r\n\r\n52 \r\n\r\n\r\n \r\n\r\n \r\n\r\n\r\n \r\n\r\n Có thể coi thí nghiệm 3 cũng là thí nghiệm kiểm tra cuối cùng để so sánh giữa \r\n\r\ncác phương pháp tóm tắt văn bản được trong đồ án. \r\n\r\n Trong đó : \r\n\r\n Trường hợp kết hợp phân tích ma trận không âm, Word2Vec và 3 đặc \r\n\r\ntrưng cấu trúc cho kết quả tốt nhất. ROUGE-1 đạt 49.979% và \r\n\r\nROUGE-2 đạt 12.911%. \r\n\r\n Trường hợp kết hợp kết hợp NMF, Word2Vec và 2 đặc trưng Surface, \r\n\r\nContent cho điểm ROUGE-1 là 45.817%, cao hơn cả 2 tổ hợp đặc trưng \r\n\r\ncòn lại, lần lượt là : Surface + Relevance  42.501% và Relevance + \r\n\r\nContent  45.175%. \r\n\r\n Tuy nhiên, ROUGE-2 khi kết hợp với 2 đặc trưng Surface, Content là \r\n\r\n14.101 lại nhỏ hơn trường hợp Relevance + Content ( bằng 15.210%) \r\n\r\nnhưng lớn hơn Surface + Relevance (11.112%) \r\n\r\n \r\n\r\n4.5 Kết luận \r\n\r\n \r\n\r\n Qua kết quả của cả 3 thí nghiệm, chúng ta rút ra được nhận xét : \r\n\r\n Trong phạm vi nghiên cứu, Đồ án đã chứng minh được phương pháp \r\n\r\nkết hợp 3 hướng tiếp cận : cấu trúc, không gian vec-tơ và biểu diễn phân \r\n\r\ntán là mang lại kết quả tốt tất cả các trường hợp còn lại. \r\n\r\n Kết quả này chứng minh cho ta một hướng đi mới, có ý nghĩa trong \r\n\r\nviệc khai phá dữ liệu bằng cách ứng dụng Word2Vec để đưa những từ \r\n\r\ncó nét nghĩa giống nhau về gần nhau trong không gian. \r\n\r\n  Do tính đặc trưng của ngôn ngữ học, sự kết hợp các đặc trưng cấu trúc \r\n\r\nkhông phải luôn tuân theo quy luật tỉ lệ thuận giữa điểm ROUGE-1 và \r\n\r\nROUGE-2. \r\n\r\n  \r\n\r\n\r\n\r\n53 \r\n\r\n\r\nCHƯƠNG 5 KẾT LUẬN VÀ HƯỚNG PHÁT TRIỂN \r\n\r\n \r\n\r\n5.1 Ưu điểm của áp dụng biểu diễn phân tán trong bài toán tóm tắt \r\n\r\n \r\n\r\n Với những kết quả đã trình bày các chương trên, có thể thấy việc sử dụng \r\n\r\nWord2Vec trong việc vec-tơ hóa từ cho ta một kết quả tốt với không gian bộ nhớ sử \r\n\r\ndụng là ít trên các thuật toán tóm tắt văn bản. \r\n\r\n Tuy nhiên, không có nghĩa là các phương pháp khai phá dữ liệu cũ đã lỗi thời \r\n\r\nhay lạc hậu. Trong thực tế, theo các kết quả thu được từ thực nghiệm trong đồ án, \r\n\r\nviệc sử dụng kết hợp các phương pháp một cách khéo léo sẽ làm tăng hiệu quả lên \r\n\r\nmột cách đáng ghi nhận. \r\n\r\n \r\n\r\n5.2 Đóng góp của đồ án \r\n\r\n \r\n\r\n Đồ án đưa ra một cái nhìn tổng quan về các kĩ thuật: Phân tích ma trận, các \r\n\r\nđặc trưng cấu trúc của văn bản. Từ đó đề xuất xây dựng mô hình ứng dụng biểu diễn \r\n\r\nphân tán từ Word2Vec kết hợp các phương pháp phân tích truyền thống trong vấn đề \r\n\r\nkhai phá dữ liệu văn bản mà cụ thể là bài toán tóm tắt văn bản tự động. \r\n\r\n \r\n\r\n5.3 Hướng nghiên cứu tiếp \r\n\r\n \r\n\r\n Tóm tắt theo truy vấn (Query base) dựa trên các kĩ thuật ma trận. Một truy vấn \r\n\r\ncũng như một câu hỏi về một vấn đề nào đó dựa trên một tập tài liệu có trước. Việc \r\n\r\ntrích xuất thông tin cần thiết nhất với một câu hỏi cũng là một đề tài nghiên cứu tốt \r\n\r\nvà có nhiều ứng dụng thực tiễn về việc tra cứu thông tin. \r\n\r\n Xây dựng một hệ thống tóm tắt văn bản cho tiếng Việt. Việc tổng hợp và tóm \r\n\r\ntắt các văn bản là một vấn đề khá hữu ích cho việc tìm kiếm và tra cứu thông tin. \r\n\r\n Loại bỏ dư thừa và xung đột dữ liệu. Việc loại bỏ dư thừ","u":"http://202.191.57.85:8000/InternetData/Data/DATN/20122230_Quan_Van_Phu_1496365507040.txt","sentences":[[1,"So sánh với tình hình hiện nay, thì mệnh đề này có vẻ liên quan và thể hiện đúng hơn bao giờ hết"],[2,"Thực tế, việc có nhiều ngôn ngữ được sử dụng trên Internet không gây nên vấn đề nhưng lại làm tăng khó khăn của việc phân tích tài liệu"],[3,"Chính vì vậy, tóm tắt văn bản tự động giúp chúng ta xử lý hiệu quả sự tăng lên không ngừng về số lượng thông tin mà con người không đủ năng lực để xử lý"],[4,"Trong khi đó, các bản tóm tắt của các tài liệu online được viết bởi tác giả không phải luôn có sẵn"],[5,"Trong thực tế, các bản tóm tắt có thể được viết bởi chính tác giả của tài liệu hoặc các chuyên gia về tóm tắt"],[6,"Tuy nhiên, việc nhờ các chuyên gia về tóm tắt thực hiện công việc này vẫn chưa phải là lựa chọn tốt nhất"],[7,"Có rất nhiều nguyên nhân giải thích cho điều này, nhưng có hai nguyên nhân chính được đề cập đến, đó là: Chi phí trả cho một chuyên gia tóm tắt văn bản là rất cao và mức độ tin tưởng của văn bản tóm tắt kiểu này vẫn còn là một chủ đề đang được tranh luận"],[8,"Bởi vì, việc biết được cách viết một tài liệu không phải lúc nào cũng tương đương với việc viết được một bản tóm tắt chính xác và súc tích về nội dung"],[9,"Điều này đặc biệt đúng trong trường hợp tài liệu cần tóm tắt liên quan đến những nội dung có tính đặc thù"],[10,"Và dưới đây là những ưu điểm của việc tóm tắt văn bản tự động: Tóm tắt làm giảm thời gian đọc Các thuật toán tóm tắt có chất lượng đều hơn các bản tóm tắt của con người Các bản tóm tắt có thể là hữu ích trong các hệ thống Hỏi - Đáp Việc sử dụng các hệ thống tự động hoặc bán tự động có thể tạo nên các dịch vụ tóm lược thương mại (enables commercial abstract services) làm tăng số lượng văn bản mà con người có thể xử lý"],[11,""],[12,"Bổ sung cho nhận định trên, Viện Tiêu Chuẩn Quốc Gia Hoa Kì (ANSI) chỉ ra rằng một tóm lược được chuẩn bị tốt giúp người đọc xác định được nội dung cơ bản của tài liệu một cách nhanh hơn và chính xác hơn, cũng như dễ dàng xác định nội dung đó có liên quan đến vấn đề mà họ đang quan tâm hay không, do đó quyết định nên hay không nên đọc toàn bộ tài liệu này"],[13,"Thực vậy, báo cáo tại hội nghị SUMMAC 2002 đã xác nhận điều này bằng cách chứng minh được rằng: Các bản tóm tắt chỉ cần ngắn bằng khoảng 17% độ dài của văn bản gốc thì sẽ làm tăng tốc độ ra quyết định lên 2 lần mà không có sự suy giảm về độ chính xác trong tỉ lệ xác suất có nghĩa"],[14,"2 1.2 Những vấn đề trong bài toán tóm tắt văn bản Hiện tại, có rất nhiều các hướng tiếp cận, thuật toán được đề xuất để thực hiện bài toán tóm tắt văn bản tự động"],[15,"Xét riêng với tóm tắt đơn văn bản ta đã có các phương pháp như: Tóm tắt dựa trên cấu trúc tài liệu, tóm tắt dựa trên mô hình không gian vec-tơ"],[16,"Tuy nhiên, những phương pháp này vẫn còn tồn tại những hạn chế đặc trưng nhất định, ví dụ tóm tắt dựa trên cấu trúc tài liệu chỉ phù hợp cho những tài liệu có cấu trúc rõ ràng như Báo chí, luận văn hay tạp chí khoa học,"],[17,"Trong khi đó, phương pháp tóm tắt dựa trên mô hình không gian vec-tơ lại chưa khai thác được những nội dung ngữ nghĩa được ẩn đi trong các tình huống tác giả tài liệu thay cách sử dụng từ ngữ để nói về cùng một vấn đề"],[18,"Đây là một trường hợp rất hay được áp dụng trong quy tắc hành văn nói chung"],[19,"Chính vấn đề này đã dẫn đến yêu cầu tìm kiếm một giải pháp mới cho cách tiếp cận bài toán tóm tắt văn bản để có thể giải quyết những hạn chế này"],[20,"1.3 Giải pháp định hướng Với sự tiến bộ trong lĩnh vực học máy (Machine Learning) nói chung và học sâu (Deep Learning) nói riêng, có rất nhiều phương pháp đã chứng minh được tính hiệu quả trong việc giải quyết những bài toán phức tạp mà các cách tiếp cận truyền thống chưa thể giải quyết triệt để được"],[21,"Để giải quyết vấn đề khai phá, trích xuất những nội dung ngữ nghĩa được ẩn đi trong tài liệu, tôi đề xuất một phương pháp kết hợp các kĩ thuật phân tích văn bản truyền thống với các kĩ thuật của phương pháp học sâu"],[22,"Từ đó, tôi sẽ thiết kế, xây dựng và đánh giá hệ thống tóm tắt văn bản tự động dựa trên cách tiếp cận này"],[23,"Cụ thể, nội dung đồ án sẽ tập trung nghiên cứu, tìm hiểu kĩ thuật Biểu diễn Phân tán Distributed Representation trong phương pháp học sâu và ứng dụng của nó - Word2Vec trong việc vec-tơ hóa từ và biểu diễn văn bản"],[24,"Cuối cùng là kết hợp kĩ thuật này với các kĩ thuật phân tích văn bản truyền thống để nâng cao chất lượng bài toán tóm tắt văn bản tự động"],[25,"3 CHƯƠNG 2 CƠ SỞ LÝ THUYẾT Trong nội dung của chương này, đồ án sẽ trình bày về các kiến thức cơ bản nhất về bài toán tóm tắt văn bản cũng như các thuật toán tóm tắt văn bản thường được sử dụng"],[26,"Chương này cũng trình bày những kiến thức cơ bản về mô hình biểu diễn phân tán, và một ứng dụng của nó trong lĩnh vực xử lý ngôn ngữ tự nhiên Word2Vec 2.1 Bài toán tóm tắt văn bản 2.1.1 Tổng quan Bài toán tóm tắt văn bản là một trong những bài toán kinh điển trong lĩnh vực xử lý dữ liệu văn bản"],[27,"Xử lý dữ liệu văn bản bao gồm: Kiểm tra lỗi chính tả (spelling-checker) Kiểm tra lỗi văn phạm (grammar-checker) Từ điển đồng nghĩa (thesaurus) Phân tích văn bản (text analyzer) Phân loại văn bản (text classification) Tóm tắt văn bản (text summarization) Tổng hợp tiếng nói (speech synthesis) Nhận dạng giọng nói (speech recognization) Dịch tự động (automatic translation)"],[28,"Tóm tắt văn bản là công việc phân tích nội dung của văn bản và sau đó sinh ra một văn bản tóm tắt có kích thước nhỏ hơn văn bản ban đầu, loại bỏ đi những thông tin không quan trọng nhưng vẫn đảm bảo giữ được những nội dung cốt lõi của văn bản [5]"],[29,"Do đó để công việc tóm tắt văn bản chính xác cần phải đáp ứng được các yêu cầu sau: Các văn bản khi phân tích thì phải hiểu được nội dung để xác định được các tiêu chuẩn trong văn bản"],[30,"Các văn bản tóm tắt cần được kiểm tra bằng một thang đo tiêu chuẩn"],[31,"Rõ ràng việc tóm tắt văn bản chính là công việc khai phá dữ liệu văn bản (text data mining)"],[32,"4 2.1.2 Phân loại các phương pháp tóm tắt văn bản Một trong những cách phân chia của bài toán tóm tắt là: Tóm tắt đơn văn bản và Tóm tắt đa văn bản"],[33,"Trong phạm vi đồ án, tôi sẽ tập trung nghiên cứu và áp dụng các kĩ thuật tóm tắt văn bản tự động vào bài toán tóm tắt đơn văn bản vì tính đặc trưng của các kĩ thuật áp dụng"],[34,"Thuật toán cho bài toán tóm tắt đa văn bản được điều chỉnh cho phù hợp từ cơ sở bài toán tóm tắt đơn văn bản"],[35,"2.1.2.1 Phương pháp tóm tắt trích xuất Extract summarization Phương pháp trích xuất bao gồm việc lựa chọn đơn vị của văn bản (câu hay đoạn văn), được coi là có chứa lượng thông tin cốt tử của văn bản (informative content, informativity), và kết nối các đơn vị này theo một trình tự thích hợp"],[36,"Một trích xuất là sự lắp ghép các đoạn được trích rút ra từ văn bản nguồn"],[37,"Mục tiêu của trích xuất là cung cấp một cái nhìn tổng quan về nội dung của văn bản gốc"],[38,"Độ dài của văn bản tóm tắt bằng trích xuất có thể được xác định bởi tỉ lệ nén, hay nói cách khác Văn bản tóm tắt ngắn hơn bao nhiêu so với văn bản gốc"],[39,"Thuật toán tóm tắt tự động bằng trích xuất có thể chia ra làm 3 mức: surface- level (mức bề mặt), intermediate-level (mức trung bình) và deep parsing techniques (các kĩ thuật phân tích sâu)"],[40,"Tóm tắt trích rút xuất phát từ ý tưởng: Một tài liệu được chia nhỏ thành các đơn vị ngữ pháp (các câu văn), sau đó được đánh trọng số theo kinh nghiệm (heuristic); Các đơn vị ngữ pháp có điểm cao nhất sẽ được trích rút và liên kết với nhau để tạo nên văn bản tóm tắt"],[41,"Thuật toán tiếp cận ở mức bề mặt: Không đào sâu vào chiều sâu ngôn ngữ của văn bản, thay vào đó là sử dụng các phần tử ngôn ngữ nhất định để xác định các đoạn có liên hệ với nhau trong văn bản"],[42,"Kĩ thuật của mức bề mặt dựa vào sự xuất hiện của từ để đánh trọng số cho các câu"],[43,"Một kĩ thuật khác dựa trên ý tưởng: Những từ được sử dụng trong tiêu đề của văn bản là quan trọng"],[44,"Trong khi đó, một số kĩ thuật dựa vào vị trí của các đoạn trong văn bản"],[45,"Kĩ thuật này được áp dụng với nhưng văn bản có cấu trúc cố định, như tiêu đề, các mục và các đoạn,.."],[46,"Một số nghiên cứu còn chỉ ra rằng: Dòng đầu tiên luôn là dòng quan trọng nhất trong văn bản đối với các thể loại báo chí"],[47,"Thuật toán tiếp cận mức trung bình: Sử dụng thông tin về ngôn ngữ học phức tạp hơn thuật toán tiếp cận mức bề mặt nhưng lại ít phức tạp hơn mức phân tích sâu"],[48,"Một kĩ thuật của dạng này là phát hiện các chuỗi từ vựng"],[49,"Chuỗi từ vựng là một dãy các từ kết nối với nhau theo quan hệ về ngữ nghĩa"],[50,"Một cách tổng quát, quá trình tóm tắt bao gồm 4 giai đoạn"],[51,"5 Bốn giai đoạn đó bao gồm: Chia văn bản gốc thành các đoạn (segments)"],[52,"Xây dựng các chuỗi từ vựng lexical chain"],[53,"Xác định các strong chain chuỗi từ mạnh Trích rút các câu chứa các strong chain Lắp ghép các câu được trích rút thành văn bản tóm tắt Thuật toán phân tích sâu: Dựa trên ý tưởng rằng sử dụng các kĩ thuật chuyên sâu về ngôn ngữ để phát hiện ra các cấu trúc rời rạc của văn bản"],[54,"Những hệ thống tóm tắt văn bản tự động dựa trên phân tích diễn ngôn bắt nguồn từ ý tưởng: Văn bản được định nghĩa bởi cấu trúc trong của nó và các mối quan hệ diễn ngôn - phụ thuộc vào ngôn ngữ mà văn bản sử dụng"],[55,"Những hệ thống này cung cấp độ quan trọng nhiều hơn cho các thành phần cốt tử của các quan hệ rời rạc"],[56,"Sử dụng lý thuyết cấu trúc diễn ngôn (Rhetorical structure theory) chia văn bản thành các đơn vị rời rạc sử dụng tập các quan hệ tối thiểu (minimal set of relations)"],[57,"Một khi các cấu trúc rời rạc được xác định, một thuật toán sẽ được áp dụng để đánh trọng số và thứ tự cho mỗi phần tử trong cấu trúc tựa cây một cách rời rạc"],[58,"Và cuối cùng, các câu với trọng số cao nhất sẽ được lựa chọn để tạo nên văn bản tóm tắt"],[59,"2.1.2.2 Phương pháp tóm tắt tóm lược Abstract summarization Tuy tóm tắt bằng trích rút đã thành công trong việc xác định câu nào trong văn bản đầu vào mang nội dung quan trọng nhưng dường như những phương pháp này rất xa với việc tạo ra một bản tóm tắt tối ưu theo nghĩa cả về nội dung và chất lượng trong ngôn ngữ học"],[60,"Trong khi đó, hệ thống tạo ra văn bản tóm tắt bằng tóm lược dựa trên việc hiểu văn bản gốc và đạt tới việc sinh ra một văn bản mới một cách chính xác về ngữ pháp, súc tích và mạch lạc về nội dung, bằng cách sinh ra văn bản tóm tắt bằng những từ vựng không xuất hiện trong văn bản gốc"],[61,"Trong tóm lược, việc diễn giải, viết lại các câu phức tạp sẽ nhằm mục đích tạo ra phiên bản súc tích của nội dung ban đầu"],[62,"Mặc dù con người có thể tái sử dụng một phần văn bản gốc nhưng không phải sử dụng toàn bộ nó; sử dụng các đoạn hay một phần của câu thay vì sử dụng toàn bộ câu"],[63,"6 2.1.3 Phân loại các hướng tiếp cận tóm tắt văn bản 2.1.3.1 Tiếp cận dựa trên cấu trúc Hướng tiếp cận này tương ứng với các thuật toán tiếp cận ở mức bề mặt được đề cập ở mục 2.1.2.1"],[64,"Trong mục này sẽ đề cập chi tiết hơn đến những đặc trưng được sử dụng trong thuật toán"],[65,"Trong các nghiên cứu gần đây có rất nhiều các đặc trưng hiệu quả của câu văn được đề xuất để dùng cho tóm tắt trích rút, ví dụ như signature word, event hay sentence relevance [6]"],[66,"Mặc dù có nhiều kết quả đáng khích lệ nhưng hầu hết các đặc trưng này được khảo sát một cách độc lập"],[67,"Tuy nhiên, thực tế mỗi đặc trưng này lại có đóng góp riêng của nó và sự kết hợp các đặc trưng đó lại với nhau có thể thu được một kết quả tốt hơn trong các trường hợp riêng lẻ"],[68,"Trong Chương 4 của đồ án sẽ trình bày các kết quả thực nghiệm để đánh giá và chọn ra những bộ đặc trưng cho kết quả tốt nhất đáp ứng với bài toán tóm tắt văn bản"],[69,"Trong mục này sẽ trình bày chi tiết các đặc trưng được xem xét"],[70,"Surface Features Đặc trưng bề mặt: Nhóm đặc trưng này xem xét đến đặc điểm cấu trúc của câu"],[71,"Bao gồm: vị trí của câu trong văn bản - thông thường các câu đầu văn bản thường là các câu chứa đựng chủ đề khái quát của cả bài văn; số lượng từ trong câu - căn cứ vào các kiểu văn bản khác nhau, văn bản báo chí, xã luận, hay bài báo khoa học thì câu văn thường có một độ dài trung bình nhất định, những câu văn có số lượng từ nhỏ hơn ngưỡng đó sẽ là các câu không quan trọng; số lượng trích dẫn trong câu - một câu chứa quá nhiều trích dẫn là câu không quan trọng"],[72,"Relevance Features Đặc trưng độ liên quan: Đặc trưng này được sử dụng để tìm ra mối liên hệ giữa các câu"],[73,"Để làm được điều đó, ta đặt quy ước rằng: Giữa các câu luôn tồn tại mối liên hệ với nhau, sẽ có một số câu mang nội dung quan trọng hơn các câu khác và khi những câu khác liên quan đến những câu đó thì mức độ quan trọng cũng tăng lên"],[74,"Tại thời điểm ban đầu, ta có những câu đầu tiên của tài liệu và những câu đầu tiên của đoạn văn là quan trọng"],[75,"Thước đo độ liên quan trong trường hợp này là độ tương đồng cosine"],[76,"Content Features Đặc trưng nội dung: Trong nhóm đặc trưng này, chọn đặc trưng Centroid, dựa vào đặc trưng centroid để xác định câu nào tập trung vào chủ đề của văn bản"],[77,"7 2.1.3.2 Tiếp cận dựa trên mô hình không gian vec-tơ VSM Khi quá trình tiền xử lí kết thúc và một phương pháp tóm tắt văn bản được lựa chọn thì văn bản cần được biểu diễn dưới một dạng nào đó"],[78,"Trong đó, không gian vectơ (Vector Space Model) được sử dụng rộng rãi trong lĩnh vực khai thác thông tin (Information retrieval - IR) để biểu diễn tài liệu và các thuật ngữ trong không gian vec-tơ tương ứng"],[79,"Mô hình không gian vec-tơ văn bản - Vector space model - là một phương pháp được đề ra bởi G.Salton, A.Wong và C.S.Yang dùng để biểu diễn văn bản - gồm tập hợp các thuật ngữ (term) - dưới dạng một vec-tơ, trong đó các đặc trưng hay chiều của vec-tơ tương ứng với các thuật ngữ trong văn bản, còn độ lớn hay trọng số của các đặc trưng này được xác định tùy thuộc vào yêu cầu cụ thể của thuật toán sử dụng mô hình này"],[80,"Trong cách biểu diễn này, chúng ta sẽ mô phỏng theo mô hình hướng IR, khi đó thứ tự các từ là không quan trọng"],[81,"Mô hình được biết đến một cái tên khác chính là mô hình Bag-of-words"],[82,"Mỗi word (term) được cung cấp một trọng số , để đo độ quan trọng của nó trong tài liệu"],[83,"Xét một văn bản bất kì di trong không gian dữ liệu văn bản D"],[84,"Ta giả thiết rằng văn bản di bao gồm ni thuật ngữ khác nhau ti1, ti2, ...tini"],[85,"Các thuật ngữ ở đây có thể được lấy một cách đơn giản là một tiếng riêng biệt, hay một cụm các tiếng để cấu tạo nên một từ đầy đủ ngữ nghĩa"],[86,"Sau khi đã xác định được các thuật ngữ khác nhau của từng văn bản trong bộ dữ liệu, ta gọi T là tập hợp các thuật ngữ khác nhau có trong toàn bộ các văn bản cần được xử lí"],[87,"Giả sử số lượng thuật ngữ có trong tập hợp T là n, do mô hình VSM lấy đặc trưng hay chiều của các vec-tơ văn bản tương ứng với các thuật ngữ khác nhau có trong bộ dữ liệu, do đó số chiều của các vec-tơ được biểu diễn từ bộ văn bản trên là n"],[88,"Mô hình không gian vec-tơ được minh họa trong Xét văn bản di, đối với mỗi thuật ngữ tj có trong tập hợp các thuật ngữ của bộ dữ liệu T, ta xây dựng một hệ số hay trọng số wij tương ứng"],[89,"Khi đó vec-tơ biểu diễn tương ứng của văn bản di là vi = (wi1, wi2, ..., win)"],[90,"Ta gọi V là tập hợp các vec-tơ được biểu diễn từ bộ dữ liệu văn bản cần xử lí"],[91,"Giả sử bộ dữ liệu bao gồm m văn bản khác nhau, khi đó tập hợp các vec-tơ văn bản V có m vec-tơ n chiều, hay tương đương với một ma trận mxn"],[92,"8 Sử dụng không gian vec-tơ biểu diễn văn bản: Một số mô hình không gian vec-tơ thường được áp dụng trong bài toán xử lý văn bản như: mô hình Boolean, TF, IDF, TFxIDF"],[93,"Để biểu diễn tập văn bản theo các mô hình trên, ta giả sử tập gồm m văn bản: D = {d1, d2,., dm}; mỗi văn bản được biểu diễn dưới dạng một vec-tơ gồm n thuật ngữ T = {t1, t2,., tn}; gọi W = {wij} là ma trận trọng số, trong đó wij là giá trị của thuật ngữ ti trong văn bản dj"],[94,"Khi đó giá trị trọng số được xác định theo từng mô hình biểu diễn cụ thể như sau: Mô hình Boolean: là mô hình biểu diễn vectơ với hàm f cho giá trị rời rạc với duy nhất 1 và 0 (đúng/sai)"],[95,"Hàm f(t) tương ứng với thuật ngữ ti sẽ cho giá trị đúng nếu và chỉ nếu thuật ngữ ti xuất hiện trong văn bản đó"],[96,"= { 1, 0, (1) Mô hình tần suất (Term Frequency - TF): là mô hình mà giá trị wij được tính dựa trên tần số xuất hiện của thuật ngữ trong văn bản"],[97,"Gọi fij là số lần xuất hiện của thuật ngữ ti trong văn bản dj, khi đó wij được tính bởi một trong các công thức: ="],[98,"(2) = 1 + log ()"],[99,"(3) = (4) 9 Trong phương pháp này, trọng số wij tỉ lệ với số lần xuất hiện của thuật ngữ ti trong văn bản dj"],[100,"Khi số lần xuất hiện thuật ngữ ti trong văn bản dj càng lớn thì điều này có nghĩa là văn bản dj càng phụ thuộc vào thuật ngữ ti, hay nói cách khác ti mang nhiều thông tin trong văn bản dj"],[101,"Mô hình nghịch đảo tần số văn bản (Inverse Document Frequency - IDF): Trọng số wij được xác định theo phương pháp này sẽ dựa trên độ quan trọng của thuật ngữ ti trong văn bản dj"],[102,"Nếu ti xuất hiện trong càng ít văn bản, có nghĩa là nếu nó xuất hiện trong văn bản dj thì trọng số của nó đối với văn bản dj càng lớn hay hàm lượng thông tin trong nó càng lớn"],[103,"= { log , 0 , (5) Với m là tổng số văn bản, hi là số lượng văn bản chứa thuật ngữ ti Mô hình kết hợp IFxIDF: là sự kết hợp hai phương pháp TF và IDF, do đó nó có những ưu điểm của cả hai phương pháp này"],[104,"Giá trị thành phần ma trận trọng số được tính như sau: = { (1 + log()) log , 0 , (6) 2.2 Kĩ thuật phân tích ma trận không âm Non-negative Matrix Factorization 2.2.1 Cơ sở lý thuyết Phân tích ma trận không âm - Non-negative matrix factorization là một nhóm các thuật toán phân tích đa biến trong đại số tuyến tính [4]"],[105,"Ma trận A được phân tích thành 2 ma trận W và H với điều kiện là cả 3 ma trận này đều chỉ mang các thuộc tính không âm, 10 Ma trận A được phân tích thành 2 ma trận W và H: = (7) Với A là một ma trận mxn, W là một ma trận mxk, và H là một ma trận kxn, k luôn được chọn nhỏ hơn m và n, do đó cả 2 ma trận W và H đều có cỡ nhỏ hơn ma trận A"],[106,"Chúng ta sử dụng Frobenius norm như là hàm mục tiêu (objective function) để thỏa mãn điều kiện xấp xỉ A WH"],[107,"Frobenius norm được chỉ ra trong công thức (Lee & Seung, 1999, 2001): (, ) 2 ( =1 ) =1 =1 2 (8) Công thức này có cận dưới bằng 0, và rõ ràng tiến tới 0 khi và chỉ khi A = WH"],[108,"W và H liên tục được cập nhật tới khi E(W,H) hội tụ dưới ngưỡng được định nghĩa hoặc vượt quá số lần lặp"],[109,"Luật cập nhật được chỉ ra dưới đây: () () (9) () () (10) Vec-tơ cột A tương ứng với câu thứ j, Aj, có thể được biểu diễn như là một sự kết hợp tuyến tính của vec-tơ đặc trưng ngữ nghĩa W*l và biến ngữ nghĩa Hlj như dưới đây: = Hlj =1 (11) 11 Ví dụ 1: Chúng ta sẽ lấy một ví dụ để minh họa cho thuật toán NMF: Cho k = 2, số bước lặp là 50, và dung sai = 0.001 (tolerance)"],[110,"Các phần tử tại thời điểm ban đầu của W và H bằng 0.5, ma trận không âm A được phân tích thành 2 ma trận không âm W và H, được chỉ ra trong NMF"],[111,"Vec-tơ cột A*3 tương ứng với câu thứ 3 được biểu diễn như là sự kết hợp tuyến tính của vec-tơ đặc trưng ngữ nghĩa W*l và vec-tơ cột biến ngữ nghĩa (semantic variable column vector) H*3"],[112,"NMF phân tích một ma trận thưa thành hai ma trận thưa"],[113,"Ở đây tỉ lệ phần tử khác 0 (non-zero ratio) của ma trận có nghĩa là giá trị các phần tử khác 0 chia cho tổng số phần tử của ma trận"],[114,"Ma trận không âm A là 1 ma trận vuông nxn, và giá trị của n được đặt bằng 100, 200, 300 và 400"],[115,"Các phần từ khác 0 được chọn một cách ngẫu nhiên"],[116,"Số lượng đặc trưng nghĩa nghĩa, r, được chọn là 10% cuả n"],[117,"Tỉ lệ khác 0 cuả A được chọn lần lượt là 0.5%, 1%, 2%, 3%, 5%, 7%, 10%, 30%, 60% và 99%"],[118,"Hai ma trận W và H thu được bằng NMF"],[119,"A W H A [ 1 2 3 4 5 6 7 8 9 10 11 12 ] [ 0.1487 1.5998 0.6610 0.9676 1.1481 0.5727 1.6129 0.4066 ] [ 6.1136 6.6784 7.1784 0.0854 0.5923 1.2245 ] = [ 1.0457 1.9420 3.0263 4.1237 4.9813 5.9297 7.0679 8.0071 8.9470 9.8953 11.0127 12.0759 ] A*3 W*1 W*2 H*3 A*3 H13 W*1 H23 W*2 [ 3 6 9 12 ] 7.1784 [ 0.1487 0.6610 1.1481 1.6129 ] + 1.2245 [ 1.5998 0.9676 0.5727 0.4066 ] 12 2.2.2 Áp dụng phân tích ma trận không âm vào phân tích văn bản đề Tourism in Greate Britain (Hoa 2005)"],[120,"Một số câu Câu văn S1 TOURIST arrivals to the UK in 1991 are forecast to recover sharply after the steep decline earlier this year cause by the Gufl war"],[121,"The British Tourist Authority said incoming tourist numbers had already increased significantly after falling 18 percent in the first two months of this year from the levels of the corresponding period of 1990 S2 The increases were achived in spite of a fall in the number of visitors from western Europe rose 12 percent to 23 m higher than in any previous first quarter"],[122,"A RECORD 185 m tourists visited Britain in the 12 months to March, 8 percent more than the previous year and the British Tourist Authority said yesterday that it was expecting even higher numbers this year"],[123,""],[124,"S20 The increase were achieved in spite of a fall in the number of North American visitors Visits by North Americans fell 6 percent to 600,000 in the first quarter"],[125,"However, the number of visitors from western Europe rose 12 percent to 23 m higher than in any previous first quarter"],[126,"A RECORD 185 m tourists visited Britain in the 12 months to March, 8% more than the previous year and the British Tourist Authority said yesterday that it was expecting even higher numbers this year"],[127,""],[128,"13 STT Thuật ngữ S 1 S 2 S 3 S 4 S 5 S 6 S 7 S 8 S 9 S 10"],[129,"S 20"],[130,"S 57 1 Tourist 3 2 0 2 1 0 0 0 0 0"],[131,"2"],[132,"1 2 Arrival 1 0 0 0 0 0 0 0 0 0"],[133,"0"],[134,"0 3 UK 1 1 0 0 1 0 0 0 0 0"],[135,"0"],[136,"1 4 Forecast 1 0 0 0 0 0 0 0 0 0"],[137,"0"],[138,"0 5 Recover 1 0 0 0 0 0 0 0 0 0"],[139,"0"],[140,"0 6 Sharply 1 0 0 0 0 0 0 0 0 0 0"],[141,"0 7 Steep 1 0 0 0 0 0 0 0 0 0"],[142,"0"],[143,"0 8 Decline 1 0 0 0 0 0 0 0 0 0"],[144,"0"],[145,"0 9 Earlier 1 0 0 0 0 0 0 0 0 0"],[146,"0"],[147,"0 10 Year 2 2 1 0 0 1 0 0 0 0"],[148,"2"],[149,"0 11 Cause 1 0 0 0 0 0 0 0 0 0"],[150,"0"],[151,"0 12 Gulf 1 0 0 0 0 0 0 0 0 0"],[152,"0"],[153,"0 13 War 1 0 0 0 0 0 0 0 0 0"],[154,"0"],[155,"0 14 British 1 2 0 1 1 0 0 0 0 0"],[156,"1"],[157,"0 15 Authority 1 1 0 1 1 0 0 0 0 0"],[158,"1"],[159,"1 16 Income 1 0 0 0 0 0 0 0 0 0"],[160,"0"],[161,"0 17 Increase 1 1 0 0 0 0 0 0 0 0"],[162,"1"],[163,"0 18 Significantly 1 0 0 0 0 0 0 0 0 0"],[164,"0"],[165,"0"],[166,""],[167,""],[168,""],[169,""],[170,""],[171,""],[172,""],[173,""],[174,""],[175,""],[176,""],[177,""],[178,""],[179,""],[180,""],[181,"396 Return 0 0 0 0 0 0 0 0 1 0"],[182,"0 0 bộ tập các câu trong Dễ dàng nhận thấy trong trận rất thưa"],[183,"14 Thuật ngữ Đặc trưng ngữ nghĩa Câu S20 W*1 W*2 W*3"],[184,"W*10 Original 20 10 =1"],[185,""],[186,""],[187,""],[188,""],[189,""],[190,""],[191,""],[192,""],[193,"13 War 0 0 0"],[194,"0.04 0 0.11 14 British 0 0.68 0.44"],[195,"0.13 1 0.89 15 authority 0 0.60 0"],[196,"0 1 1.05 16 income 0 0 0.35"],[197,"0.03 0 0.11 17 increase 0.07 0 0"],[198,"0.76 1 1.01"],[199,""],[200,""],[201,""],[202,""],[203,""],[204,""],[205,""],[206,""],[207,"396 Return 0 0 0"],[208,"0.08 0 0.07 Trọng số Hj20 0 0.07 0"],[209,"0 phân tích NMF đối với ma trận A, giá trị trọng số H1,20, ..., H10,20 của vec-tơ đặc trưng ngữ nghĩa tương ứng với câu S20, vec-tơ câu ban đầu"],[210,"Vec-tơ câu được tính từ các giá trị trọng số và các vec-tơ ngữ nghĩa"],[211,"Phương pháp NMF trích xuất câu có trọng số lớn nhất theo nghĩa: câu đó phản ánh nhiều nhất tới chủ đề chính của tài liệu, điều đó được biểu diễn bởi các đặc trưng ngữ nghĩa"],[212,"Do đó, phương pháp NMF có likelihood tốt hơn trong việc trích xuất các câu quan trọng về mặt ngữ nghĩa so với phương pháp LSA"],[213,"2.3 Phương pháp học sâu với Word2Vec You shall know a word by the company it keeps J.R"],[214,"Firth 1957 Như đã trình bày ở Chương 1, ta thấy các vấn đề còn vướng mắc của các phương án vec-tơ hóa văn bản hiện tại"],[215,"Trong mục này, đồ án sẽ trình bày về việc ứng dụng phương pháp học sâu vào bài toán xử lý ngôn ngữ tự nhiên, mà cụ thể là biểu diễn phân tán từ trong quá trình vec-tơ hóa từ và văn bản, đóng vai trò như đặc trưng đầu vào cho các thuật toán tóm tắt"],[216,"Ngoài ra, chương này cũng trình bày nội dung cơ bản về thước đo cosine, thước đo đánh giá độ tương đồng trong Word2Vec"],[217,"15 2.3.1 Phương pháp học sâu và bài toán biểu diễn phân tán từ Học sâu Deep Learning: là những thuật toán học máy dựa trên việc học các tầng biểu diễn khác nhau của dữ liệu"],[218,"Học sâu là một lĩnh vực mà: Có sự phát triển nhanh và bao phủ một miền rộng lớn"],[219,"Là cơ sở của học máy và lý thuyết nhận dạng mô hình (Pattern recognition theory)"],[220,"Nâng cao công nghệ xây dựng các hệ thống trí tuệ nhân tạo"],[221,"Trong đó, có thể nói bài toán biểu diễn phân tán từ - Word distributed representation hay còn gọi là WordEmbedding là một trong những phương diện nghiên cứu thú vị nhất của phương pháp học sâu trong xử lí ngôn ngữ tự nhiên"],[222,"Ý tưởng của bài toán này bắt đầu từ một nhận xét (hay định nghĩa) kinh điển của J.R"],[223,"Firth vào năm 1957, tạm dịch là: Chúng ta có thể suy diễn nghĩa của một từ nếu biết những từ vựng khác hay dùng kèm với nó"],[224,"Một WordEmbedding là một hàm ánh xạ từ thành các vec-tơ nhiều chiều (200 đến 500 chiều)"],[225,"Ví dụ như: W(cat) = (0.2, -0.4, 0.7,.) W(mat) = (0.0, 0.6, -0.1,.) Thường thì hàm này sẽ là một bảng tra cứu, lưu trữ dưới dạng một ma trận , với W(wn) = n"],[226,"Ban đầu W được khởi tạo một vec-tơ ngẫu nhiên cho mỗi từ"],[227,"Sau đó nó sẽ học ra các vec-tơ có nghĩa để thực hiện một số tác vụ (task)"],[228,"Ví dụ, ta cần huấn luyện ra một mạng (network) nhằm kiểm tra xem một chuỗi 5 từ (5-gram) là hợp lệ hay không"],[229,"Đặc trưng mức thấp Đặc trưng mức trung Đặc trưng mức cao Lớp phân loại 16 Mô hình được huấn luyện ra sẽ chạy mỗi từ trong cụm 5-gram từ ma trận W để lấy ra vec-tơ đại diện của nó"],[230,"Sau đó đưa những vec-tơ này vào trong một mô- đun khác gọi là R để thử dự đoán xem 5-gram này là hợp lệ hay không"],[231,"Ví dụ như: R( W(cat), W(sat), W(on), W(the), W(mat) ) = 1 R( W(cat), W(sat), W(song), W(the), W(mat) ) = 0 Để dự đoán chính xác các giá trị này, mạng cần phải học được các tham số tốt từ cả W và R"],[232,"Đến đây thì kết quả tác vụ này đã không còn nhiều ý nghĩa"],[233,"Thực tế, điều chúng ta hướng đến là việc học ra W"],[234,"Có thể thực hiện các tác vụ khác nhau để thu được kết quả này chứ không nhất thiết phải là tác vụ đã được ví dụ ở trên"],[235,"Để có thể thu được một chút nhận xét về không gian WordEmbedding, ta có thể sử dụng t-SNE để biểu diễn không gian WordEmbedding lên không gian 2 chiều, Hình 2.7"],[236,"17 Hình 2.7: Sử dụng t-SNE trên không gian WordEmbedding Biểu diễn này cho thấy, những từ gần giống nhau sẽ gần với nhau"],[237,"Kết quả này còn có thể được nhìn thấy thông qua việc liệt kê các từ gần nhất với một từ cho trước trong không gian WordEmbedding"],[238,"Một lần nữa các từ cùng một nhóm cũng khá tương đồng với nhau"],[239,"Rất tự nhiên mà các từ có nghĩa tương đồng được đưa về các vec-tơ gần nhau"],[240,"Nếu ta thay thế một từ thành một từ có nghĩa tương đồng với nó, sự hợp lệ của câu không hề thay đổi [9]"],[241,"Trong khi xét trên sự thay đổi về mặt chuỗi, rõ ràng câu đầu vào đã có sự thay đổi lớn"],[242,"Nếu như W ánh xạ được các từ có nghĩa tương đồng về gần với nhau thì R chỉ có một chút sự thay đổi"],[243,"18 Kết quả này thực sự tốt khi mà số lượng các 5-gram thì rất lớn nhưng ta chỉ có một số lượng nhỏ để làm dữ liệu học"],[244,"Các từ có nghĩa tương đồng được đưa về gần nhau, cho phép ta sinh ra một tập các câu tương tự nhau từ một câu cho trước"],[245,"Nó không chỉ là việc thay một từ bởi một từ đồng nghĩa mà còn là thay một từ bởi một từ trong cùng tập các từ gần nhau"],[246,"Ngoài ra, ta cũng có thể thay thế nhiều từ cùng một lúc"],[247,"Bên cạnh đó, WordEmbedding còn một tính chất đáng giá hơn: Khi sự tương tự giữa các từ dường như được mã hóa thành sự tương đồng giữa các vec-tơ biểu diễn từ"],[248,"Ví dụ như có một hằng số giữa sự khác biệt của các vec-tơ male-female: W(woman) W(man) = W(aunt) W(uncle) W(woman) W(man) = W(aunt) W(uncle) Thực tế việc thay đổi các từ trong câu có thể tạo ra các câu sai về mặt ngữ nghĩa"],[249,"Ví dụ, khi nói: She is not a Queen, He is a King nhưng He is a Queen coi là câu sai ngữ nghĩa"],[250,"Như vậy theo một cách tự nhiên khi học các 5-gram đúng, thì WordEmbedding đã học cả các mặt ngữ nghĩa của từ"],[251,"Tổng hợp lại, kết quả của bài toán WordEmbedding sẽ cho ta một ánh xạ từ thành vec-tơ với các tính chất sau: Số lượng chiều không lớn (so với tập từ vựng) Các từ có chung nét ngữ nghĩa sẽ được về gần nhau trong không gian Mối quan hệ tương đồng ngữ nghĩa được chuyển thành mối quan hệ giống nhau giữa các vec-tơ"],[252,"2.3.2 Word2Vec Word2Vec là một phương pháp cụ thể của bài toán WordEmbedding"],[253,"Không sử dụng một tác vụ để kiểm tra một cụm \"5-gram\" có hợp lệ hay không như ví dụ ở mục 2.3.1 , Word2vec lựa chọn việc huấn luyện ra một mạng nơ-ron cho phép dự đoán từ (hoặc các từ) bởi các từ lân cận cho trước (có thể gồm nhiều hoặc một từ) và ngược lại"],[254,"Về khối kết cấu, Word2Vec là 1 mạng nơ-ron cạn gồm 1 lớp ẩn"],[255,"Có 2 kiến trúc là hội tụ và phân kì từ xung quanh để tạo ra mô hình Word2vec là CBOW và Skip-gram"],[256,"Ngoài ra, thực tế còn có các phương pháp cải tiến nhằm tối ưu hóa hiệu quả tính toán"],[257,"Một cách tổng quát về Word2Vec: Biểu diễn phân tán cho từ Học ra một vec-tơ giá trị thực (real-valued vector) cho từng từ Đưa những từ có ý nghĩa giống nhau về gần nhau Một ứng dụng đơn giản của của mạng nơ-ron 2 lớp 19 2.3.2.1 Mô hình CBOW Nguyên tắc của CBOW là sử dụng mạng nơ-ron để xây dựng một mô hình trên dữ liệu học, sao cho có thể tìm ra được một từ thông qua các từ lân cận nó (gọi là context - ngữ cảnh) [7]"],[258,"Ngữ cảnh chỉ gồm một từ - Single word context Trước tiên ta bắt đầu từ ví dụ đơn giản nhất của CBOW rằng một ngữ cảnh chỉ gồm một từ"],[259,"Nói một cách khác là mô hình sẽ dự đoán từ cần tìm thông qua một từ cho trước"],[260,"chỉ gồm một từ"],[261,"Giả sử kích thước của tập từ điển là V, kích thước của lớp ẩn là N"],[262,"Node trên lớp bên cạnh được kết nối đầy đủ"],[263,"Vec-tơ đầu vào là một vec-tơ one-hot encoded [ Phụ lục 2]"],[264,"20 Trọng số giữa lớp vào và lớp ra được biểu diễn dưới dạng ma trận W kích thước VxN"],[265,"Mỗi hàng của W là 1 vec-tơ N chiều đại diện vw ứng với từ liên kết của vec-tơ đầu vào"],[266,"Truyền vào một ngữ cảnh, giả sử xk = 1 và xk = 0 với mọi k k, khi đó: = = = (12) Từ lớp ẩn đến lớp đầu ra, còn có một ma trận trọng số NxV khác W = { wij }"],[267,"Sử dụng các trọng số này ta có thể tính toán điểm uj cho từng từ trong tập từ vựng: = (13) Với vwj là cột thứ j của ma trận W"],[268,"Sau đó chúng ta có thể sử dụng soft-max, một model phân loại log-linear để có được sự phân bố của các từ (the posterior distribution of words) dưới dạng 1 đa thức phân phối"],[269,"(|) = = exp () ( ) =1 (14) Với yj là đầu ra của node j trong lớp đầu ra"],[270,"Thế (12), (13) vào (14) ta có: (|) = = exp ( ) ( ) =1 (15) Chú ý rằng vw, vw là hai đặc trưng của từ"],[271,"vw đến từ hàng của W, tức là từ đầu vào đến ma trận trọng số ẩn, và vw đến từ W, tức là từ lớp ẩn đến ma trận đầu ra"],[272,"Trong các phần tiếp theo ta sẽ gọi vw là vec-tơ đầu vào và vw là vec-tơ đầu ra của w"],[273,"Một đối tượng tập huấn (training object) được tối đa hóa từ (15), xác suất có điều kiện của việc quan sát thực tế của từ đầu ra wO (chỉ số của từ này được biểu thị trong lớp đầu ra là j*) khi đưa vào ngữ cảnh đầu vào wI với mối liên quan đến trọng số: max (|) = max (16) = max log (17) = log ( ) = =1 (18) 21 Với E = log p (wO | wI) là hàm lỗi (ta muốn cực tiểu hóa giá trị này) và j* là vị trí của từ đầu ra thực tế trong lớp đầu ra"],[274,"Chú ý rằng E có thể coi như là một trường hợp đặc biệt của cross-entropy giữa hai phân bố xác suất"],[275,"Phương trình cập nhật cho W Xét phương trình cập nhật trọng số của lớp ẩn (hidden layer) và lớp đầu ra, ta tính đạo hàm E với uj: = (19) Với tj = 1 khi node thứ j là từ đầu ra thực tế, tj bằng 0 trong các trường hợp còn lại"],[276,"Chú ý rằng các tính toán trên chỉ là một đơn giản hóa cho dự đoán lỗi ej của lớp đầu ra"],[277,"Tiếp theo ta tính đạo hàm trên wij để tìm ra gradient của trọng số trên W: = = (20) Sử dụng Stochastic Gradient Descent, ta có phương trình cập nhật trọng số trên W: () = () (21) hoặc () = () (22) Với > 0 là độ học ( learning rate ), ej = yj tj , và hi là node thứ i trong lớp ẩn, vwj là vec-tơ đầu ra của wj"],[278,"Chú ý là phương trình cập nhật này bắt buộc là ta phải đi toàn bộ các từ trong bộ từ, kiểm tra xác suất đầu ra yj và so sánh nó với kì vọng đầu ra tj (là 0 hoặc 1)"],[279,"Nếu yj > tj, ta trừ vwO đi 1 tỉ lệ của vec-tơ ẩn h (ví dụ: vwI), nó khiến cho vwO xa khỏi vwI"],[280,"Nếu yj < tj, ta cộng vwO đi 1 tỉ lệ của vec-tơ ẩn h, nó khiến cho vwO gần lại vwI"],[281,"Ở đây xa hay gần là khoảng cách cosine, không phải là khoảng cách Euclidean"],[282,"22 Phương trình cập nhật cho W: Đã tìm được W, ta tiếp tục tính toán đến W"],[283,"Ta tính toán đạo hàm của E trên đầu ra của lớp ẩn thu được kết quả: = =1 = = =1 (23) với hi là đầu ra của nút thứ i trong lớp ẩn, uj đã được định nghĩa trong công thức (13) là mạng đầu vào của nút thứ j trong lớp đầu ra và ej = yj - tj là giá trị lỗi dự đoán của từ thứ j trong lớp đầu ra"],[284,"EH là một vec-tơ N chiều là tổng của các vec-tơ đầu ra của toàn bộ các từ trong tập từ, được trọng số bởi giá trị lỗi dự đoán của chúng"],[285,"Tiếp theo, ta tính đạo hàm của E trên W"],[286,"Đầu tiên phải nhớ rằng lớp ẩn chuyển hóa thực hiện tính toán tuyến tính trên các giá trị từ lớp đầu vào"],[287,"Diễn giải công thức (12) ta có: = =1 (24) Tính đạo hàm của E với W ta được: = = (25) = (26) Từ đó ta tìm được một ma trận VxN"],[288,"Chỉ có một thành phần của x là khác 0 đồng nghĩa với việc một hàng của là khác 0, và giá trị của hàng đó là EH, một vec-tơ N chiều"],[289,"Ta tính được phương trình cập nhật của W là: () = () (27) với vwI là một hàng của W, vec-tơ đầu vào của từ trong ngữ cảnh, hàng duy nhất của W có đạo hàm khác 0"],[290,"Ta không cần quan tâm đến các hàng khác của W vì đạo hàm của chúng đều là 0"],[291,"Dễ thấy, có thể hiểu () thêm vào một phần của mọi vec-tơ đầu ra trong tập từ vào vec-tơ đầu vào của từ trong ngữ cảnh"],[292,"Nếu trong lớp đầu ra, yj > tj thì vec- tơ đầu vào wI sẽ được dịch xa khỏi vec-tơ đầu ra wj và ngược lại"],[293,"Độ dịch chuyển này được xác định bởi tỉ lệ dự đoán lỗi (prediction error) của tất cả các vec-tơ trong tập từ"],[294,"Tỉ lệ dự đoán lỗi càng lớn thì càng ảnh hưởng đến độ dịch chuyển"],[295,"23 Ngữ cảnh gồm nhiều từ - Multi-word context Khi tính toán đầu ra của lớp ẩn, thay vì trực tiếp sao chép vec-tơ đầu vào của từ từ đầu vào trong ngữ cảnh (như trường hợp ngữ cảnh chỉ có một từ đã trình bày ở trên), CBOW lấy trung bình các vec-tơ của các từ đầu vào trong ngữ cảnh, và sử dụng kết quả của quá trình từ đầu vào đến trọng số ẩn và vec-tơ trung bình làm đầu ra"],[296,"= 1 (1 + 2 + 3 + + ) (28) = 1 (1 + 2 + 3 + + ) (29) Với C là số từ trong ngữ cảnh, w1, ..., wc là các từ trong ngữ cảnh, và vw là vec-tơ đầu vào của từ w"],[297,"Hàm lỗi lúc này được xác định bởi công thức: = log ( | ,1, ,2, ,3,"],[298,", ,) (30) = log exp () =1 (31) = + log exp ( ) =1 (32) 24 Công thức này hoàn toàn giống với công thức (18) trừ việc thay h bằng công thức (29) thay vì công thức (12)"],[299,"Phương trình cập nhật cho trọng số ẩn đến trọng số đầu ra hoàn toàn giống như phương trình (22): () = () ej (33) for j = 1, 2,., V Chú ý rằng ta cần phải sử dụng phương trình này cho từng thành phần trong ma trận trọng số W với từng đối tượng tập huấn"],[300,"Phương trình cập nhật trọng số cho W cũng tương tự như () trừ việc giờ ta phải áp dụng phương trình ở dưới cho toàn bộ các từ trong ngữ cảnh: , () = , () 1 (34) for c = 1, 2, .,C vwI,c là vec-tơ đầu vào của từ thứ c trong ngữ cảnh, là độ học chủ động (positive learning-rate), và EH đã được cho bởi công thức"],[301,"Theo một cách tương đối mà nói thì (34) giống với ()"],[302,"2.3.2.2 Mô hình Skip-gram Skip-gram là mô hình ngược lại với CBOW hay chi tiết hơn là lớp đầu vào sẽ là từ, và lớp đầu ra sẽ là ngữ cảnh [1]"],[303,"Ta vẫn kí hiệu vwI là vec-tơ đầu vào của từ duy 25 nhất trên lớp đầu vào, đồng thời định nghĩa đầu ra lớp ẩn h giống như trong công thức (12) nghĩa là h là việc sao chép một hàng của ma trận trọng số W = = (35) Trên lớp đầu ra, thay cho việc chỉ có một đa thức phân phối ta sẽ cho ra C đa thức phân phối"],[304,"Mỗi một đầu được tính toán trên cùng ma trận W: (, = ,|) = , = exp (,) ( ) =1 (36) Với wc,j là từ thứ j trong panel thứ c của lớp đầu ra; wO,c là từ thứ c thực tế xuất hiện trong ngữ cảnh đầu ra; wI là từ đầu vào (duy nhất); yc,j là đầu ra của node thứ j trên panel thứ c của lớp đầu ra; uc,j là mạng đầu vào của nút thứ j của panel thứ c của lớp đầu ra"],[305,"Bởi vì các panel của lớp đầu ra có cùng trọng số nên: , = = (37) for c = 1, 2, ., C với vwj là vec-tơ đầu ra của từ thứ j trong tập từ vựng (wj), được lấy ra từ một hàng của ma trận trọng số W"],[306,"26 Đạo hàm của phương trình cập nhật trọng số cũng không có nhiều điểm khác biệt so với mô hình ngữ cảnh một từ đã trình bày ở mục"],[307,"Tuy nhiên hàm lỗi E được chuyển thành: = log ( ,1, ,2, ,3,"],[308,", , |) (38) = log (,) () =1 =1 (39) = , + log () =1 =1 (40) với jc* là vị trí của từ thứ c xuất hiện thực tế trong ngữ cảnh đầu ra"],[309,"Ta tính đạo hàm của E với mạng đầu vào của từng nút trên từng panel của lớp đầu ra, uc,j và có , = , , , (41) là giá trị dự đoán lỗi trên node, giống với (19)"],[310,"Để đơn giản, ta định nghĩa một vec-tơ N chiều EI = {EI1, EI2,., EIV} là tổng của tất cả các giá trị dự đoán lỗi trên toàn bộ các từ của ngữ cảnh: = , =1 (42) Ta tiếp tục tính đạo hàm của E trên W thu được: = , =1 , = (43) Vì thế ta tìm được phương trình cập nhật ma trận trọng số W: () = () (44) hay: () = () (45) for j = 1, 2,., V 27 Cảm tính mà nói hàm cập nhật này giống với công thức (22) trừ việc hệ số dự đoán lỗi được tính tổng trên toàn bộ các từ trong ngữ cảnh của lớp đầu ra"],[311,"Chú ý rằng ta cần áp dụng hàm cập nhật này với mọi thành phần của ma trận W cho từng đối tượng trong tập huấn"],[312,"Đạo hàm của phương trình cập nhật cho ma trận W hoàn toàn giống từ (23) đến (27) trừ việc thay đổi giá trị dự đoán lỗi ej thành EHj"],[313,"Phương trình cập nhật trọng số trong trường hợp này sẽ là: () = () (46) với EH là một vec-tơ N chiều, mỗi thành phần được tính theo công thức: = , =1 (47) 2.3.3 Độ tương đồng Cosine trong không gian Vec-tơ Trong mục này, tôi sẽ trình bày những kiến thức cơ bản về thước đo cosine được sử dụng để xác định độ tương đồng giữa 2 từ trong mô hình Word2Vec và ứng dụng trong phạm vi đồ án"],[314,"Tích vô hướng Chúng ta bắt đầu với định nghĩa về số học của tích vô hướng giữa hai vec-tơ: = (1, 2, 3,"],[315,") và = (1, 2, 3,"],[316,") với an và bn lần lượt là các thành phần của vec-tơ , và n là số chiều của các vec-tơ:"],[317,"= = 11 + 22 + + =1 (48) Tuy nhiên, để thấy được hết ý nghĩa của phép nhân vô hướng giữa 2 vec-tơ, chúng ta phải xem xét đến định nghĩa hình học của nó: = cos (49) Sử dụng tính chất giao hoán để sắp xếp lại vế phải của công thức trên ta có: 28 = cos (50) Trong lý thuyết hình học, phép nhân cos chính là phép chiếu của vect- tơ lên vec-tơ ,Hình Khi vec-tơ vuông góc với vec-tơ tích này trở thành: Khi 2 vec-tơ vuông góc, tích vô hướng của chúng bằng 0"],[318,"Đây cũng là một cách để chúng ta kiểm tra 2 vec-tơ có quan hệ vuông góc hay không"],[319,"Tuy nhiên, ví dụ trên mới chỉ dừng lại ở không gian vec-tơ hai chiều, nhưng có một điều thú vị rằng, chúng ta cũng có thể tính toán góc và độ tương đồng giữa các vec-tơ trong không gian nhiều chiều, mà trong bài toán của chúng ta là không gian vec-tơ 300 chiều"],[320,"Độ tương đồng Cosine Độ tương đồng cosine giữa hai vec-tơ (hoặc 2 từ trong không gian vec-tơ) là một thước đo tính giá trị cosine của góc giữa chúng"],[321,"Thước đo này là thước đo về hướng của 2 vec-tơ, không phải thước đo về độ lớn"],[322,"29 Từ công thức (49) ta có: cos = (51) Đây chính là công thức về độ tương đồng cosine"],[323,"Độ tương đồng cosine sẽ sinh ra một số, số này sẽ cho chúng ta biết 2 từ liên quan đến nhau như thế nào trong không gian bằng cách xem xét góc giữa chúng, thay vì so sánh về độ lớn"],[324,"a) Cùng hướng b) Vuông góc c) Đối diện 2.3.4 Ứng dụng phương pháp học sâu Word2Vec với xử lí ngôn ngữ tự nhiên - Mô hình n-gram - Giảm khối lượng tính toán - Sử dụng biểu diễn phân phối cho từ - Sử dụng chuỗi các - Phân cụm các từ vào trong - Các từ tương đồng luật xác suất các chỉ mục ở gần nhau - Ước lượng bằng cách - Với 1 biểu diễn one-hot, khoảng thống kê số n-gram cách giữa hai từ luôn bằng 2 Mô hình ngôn ngữ - Language model: Cốt lõi nhất của phương pháp xử lí ngôn ngữ tự nhiên dựa trên thống kê chính là việc xây dựng mô hình ngôn ngữ"],[325,"Mô hình ngôn ngữ là một phân bố xác suất trên các tập văn bản"],[326,"Cụ thể thì mô hình ngôn ngữ cho biết xác suất của một câu (một cụm từ hoặc một từ) trong bộ dữ Language Model Class-based Language Model Neural Networks Language Models 30 liệu mẫu là bao nhiêu"],[327,"Mô hình ngôn ngữ có nhiều hướng tiếp cận nhưng chủ yếu là mô hình N-gram"],[328,"(1,"],[329,", ) = (1,"],[330,", 1) (|1,"],[331,", +1) = (52) (53) P (\"ầ ờ à \") = 3(\"Bầu trời màu\")3(\"ờ à \")/2(ờ à) Theo công thức (52), mô hình ngôn ngữ cần phải có một lượng bộ nhớ vô cùng lớn để có thể lưu hết xác suất của tất cả các chuỗi có độ dài nhỏ hơn n"],[332,"Giả sử rằng chỉ có k từ được đưa và trong bộ tiền ngữ (history), áp dụng chuỗi Markov bậc k (các từ cũ hơn có khả năng ít liên quan) [8], ta có: (|1,"],[333,", 1) (|4, 3, 2, 1) (54) Tuy nhiên, mỗi (|4, 3, 2, 1) có thể không đủ thống kê để ước lượng, do khi tính xác suất có nhiều trường hợp sẽ gặp các cụm n-gram chưa xuất hiện hoặc do sự phân bố không đều trong tập huấn luyện sẽ dẫn tới việc tính toán không chính xác"],[334,"Do đó, chúng ta phải sử dụng một phương pháp làm mịn, ví dụ như Kneser-Ney [11] với mô hình truy hồi để khắc phục vấn đề này"],[335,"Đến đây thì việc tính toán trở nên vô cùng phức tạp: Truy hồi (|4, 3, 2, 1) , (|2, 1),"],[336,"về ()"],[337,"Mô hình ngôn ngữ dựa trên lớp Class-based Language Model: Sử dụng phương pháp one-hot coding [Phụ lục 2] để biểu diễn một từ trong tập từ vựng"],[338,"Tuy nhiên phương pháp này có nhược điểm lớn: là kích thước của vec-tơ biểu diễn quá lớn vì kích thước của văn bản có thể tiến tới vô cùng"],[339,"Từ những phân tích trên, chúng ta có một cái nhìn tổng quát về sự phát triển của các mô hình ngôn ngữ trong lĩnh vực xử lí ngôn ngữ tự nhiên"],[340,"Qua đó, thấy được một lần nữa những điểm hạn chế đối với những mô hình truyền thống như mô hình ngôn ngữ hay mô hình ngôn ngữ dựa trên lớp, cũng như những cải tiến trong mô hình ngôn ngữ mạng nơ-ron"],[341,"Đối với một số vấn đề mà với các phương pháp khai phá dữ liệu truyền thống như Cây quyết định (Decision tree), Nave Bayes,.chưa thể làm được thì nay, với sự hỗ trợ của công nghệ Deep Learning, điều đó hoàn toàn có khả năng thực hiện"],[342,"Ta xét một số ví dụ để có thể hiểu hơn về điều này: 31 Cơ sở của phép suy diễn tương tự trong Word2Vec: đà ô ụ ữ + à đế 2 (55) Ví dụ 2: Tí đi vào bếp Dưa hấu thì tròn Tí lượm một trái khế Quả mướp thì dài Sau đó Tí chạy ra vườn Mướp xanh mươn mướt Tí làm rơi trái khế Mướp và dưa hấu cùng màu Hỏi: Trái khế ở đâu"],[343,"Hỏi: Quả dưa hấu màu gì"],[344,"Máy tính: ở ngoài vườn Máy tính: màu xanh Ví dụ 3: Sử dụng Word2Vec trong bài toán topic modelling, ta có thể huấn luyện ra những model cho mục đích phân loại, sử dụng model đó để tìm các từ mang nét nghĩa giống nhau, ta có thể thu được những kết quả như sau: Các từ liên quan đến chủ đề Trường học: Nhà trường, học sinh, lớp học,"],[345,"Các từ liên quan đến chủ đề Đảng: Nghị quyết, kinh nghiệm, quán triệt, chủ chương, quyết liệt, to lớn,"],[346,"2.4 Kết luận Trong nội dung chương này, tôi đã trình bày cơ sở lý thuyết cơ bản của bài toán tóm tắt văn bản tự động cũng như những phương pháp kĩ thuật sử dụng trong phạm vi đồ án, bao gồm: Kĩ thuật phân tích ma trận không âm, biểu diễn phân tán và Word2Vec"],[347,"32 CHƯƠNG 3 GIẢI PHÁP ĐỀ XUẤT 3.1 Nhận xét về kĩ thuật phân tích ma trận không âm 3.1.1 Ưu điểm Đối với việc số hóa một tài liệu sang dạng dữ liệu để máy tính có thể thực hiện các phép toán cộng, trừ, nhân, chia,.."],[348,"(phiên bản số của tài liệu), từ đó có thể thực hiện các công việc khai phá dữ liệu như phân loại văn bản (bài toán topic modelling), tóm tắt văn bản (text summarizing),"],[349,"thì việc sử dụng mô hình không gian vec-tơ mà cụ thể là phương pháp phân tích ma trận theo mô hình tần suất dường như là một cách làm mang tính tự nhiên nhất"],[350,"Trong chương 2, đồ án đã đề cập sử dụng một phương pháp không giám sát mới để sinh ra văn bản tóm tắt của tài liệu tương ứng sử dụng kĩ thuật phân tích ma trận không âm-NMF"],[351,"Phương pháp được đề xuất có những ưu điểm sau đây: Thứ nhất, đây là phương pháp không giám sát (unsupervised) và không yêu cầu các tóm tắt mẫu cho bước tập huấn và cho bộ tóm tắt"],[352,"Thứ hai, các vec-tơ đặc trưng ngữ nghĩa được trích rút từ NMF có thể được thể hiện trực quan hơn là sử dụng các phương pháp liên quan đến LSA, bởi vì các thành phần trong phân tích NMF chỉ gồm các giá trị không âm và chúng rất thưa trong khi cũng là các thành phần đó nhưng trong phương pháp LSA thì gồm cả giá trị âm và giá trị dương, ngoài ra, còn có chứa một vài giá trị bằng 0"],[353,"Hơn nữa, một câu được có thể được biểu diễn như là sự kết hợp tuyến tính của những đặc trưng ngữ nghĩa một cách trực quan"],[354,"Cuối cùng, phạm vi ngữ nghĩa của đặc trưng ngữ nghĩa là hẹp, bởi vì chúng rất thưa, theo đó, các chủ đề nhỏ (sub-topics) của tài liệu được xác định một cách dễ dàng và chính xác hơn"],[355,"Do đó, khả năng trích rút được các câu quan trọng sẽ tốt hơn các phương pháp khác"],[356,"3.1.2 Nhược điểm Tuy nhiên, nhược điểm của phương pháp nằm ở việc không thể phát hiện ra các liên kết ẩn giữa các từ, các phần trong văn bản"],[357,"Các liên kết này có thể tồn tại dưới nhiều dạng, đó có thể là quan hệ nguyên nhân kết quả giữa các luận điểm, có thể là những phần được nhấn mạnh, quan trọng hơn những phần khác hay là sự thay đổi cách sử dụng ngôn từ diễn đạt, và có một số thuật ngữ, tuy khác nhau về hình thức nhưng lại mang những nét nghĩa giống nhau"],[358,"33 3.2 Mô hình đề xuất Sau những kiến thức lý thuyết đã trình bày, trong phần này ta đi vào thiết kế hệ thống thực tế để giải quyết bài toán tóm tắt văn bản báo chí bằng ngôn ngữ tiếng Anh ứng dụng Word2Vec"],[359,"Mô hình hệ thống tổng quát sẽ gồm hai mô-đun chính: Mô-đun huấn luyện Word2Vec Mô-đun tóm tắt văn bản"],[360,"Với các vấn đề về khai thác ngữ nghĩa ẩn, hệ thống khắc phục nhược điểm của phương pháp phân tích ma trận không âm bằng cách: Sử dụng mô hình Word2Vec đã được huấn luyện để tìm ra tập các từ tương đồng với nhau trong văn bản nguồn"],[361,"Từ đó, thay đổi cách xây dựng ma trận tần suất đầu vào của phân tích ma trận không âm"],[362,"34 Bên cạnh đó, kế thừa những ưu điểm của các phương pháp tóm tắt văn bản truyền thống, trong mô-đun tóm tắt văn bản, các nhóm đặc trưng phù hợp được lựa chọn qua quá trình thực nghiệm (Chương 4 ) được tích hợp vào khối tính điểm cho câu"],[363,"Các đặc trưng được đề xuất trong mô hình dựa theo gợi ý từ nghiên cứu của một số chuyên gia về tóm tắt văn bản [6]"],[364,"Các đặc trưng đó bao gồm: đặc trưng bề mặt, đặc trưng nội dung và đặc trưng về độ liên quan"],[365,"Trong mục tiếp theo tôi sẽ trình bày chi tiết về các mô-đun, khối chức năng trong hệ thống tóm tắt đề xuất"],[366,"3.3 Mô-đun huấn luyện mô hình Word2Vec Mô-đun thực hiện việc huấn luyện mô hình Word2Vec đóng vai trò như một đặc trưng đầu vào trong khối phân tích ma trận NMF"],[367,"3.3.1 Ngữ liệu huấn luyện Ngữ liệu dùng đế huấn luyện mô hình Word2Vec, bao gồm các bài báo, tin tức từ Wikipedia và bộ dữ liệu DUC 2004"],[368,"Đây là các bài báo tin cậy, phủ rộng trên nhiều lĩnh vực"],[369,"Việc lấy dữ liệu từ nguồn này cho phép ta xây dựng được một mô hình vec-tơ hóa đặc thù cho dữ liệu văn bản báo chí nhưng vẫn đầy đủ các lĩnh vực"],[370,"Những dữ liệu này sẽ được tiền xử lí trước khi đưa vào huấn luyện mô hình"],[371,"3.3.2 Khối tiền xử lí Word2Vec Với dữ liệu là các văn bản, trước khi đưa vào huấn luyện đều cần phải được tiền xử lý"],[372,"Quá trình xử lí sơ bộ sẽ tạo ra một chuỗi các phần nhỏ; ví dụ một tài liệu văn bản (plain text document) được chuyển thành một đối tượng với số đặc trưng ngôn ngữ học tối thiểu như các từ và các câu"],[373,"3.3.3 Khối huấn luyện mô hình Word2Vec Với những dữ liệu đã được tiền xử lí, thực hiện việc huấn luyện mô hình Word2Vec trên nguồn dữ liệu đầu vào"],[374,"Mô hình kiến trúc sử dụng Continuous Skip- gram, số chiều của vec-tơ bằng 300"],[375,"Độ dài cửa sổ ngữ cảnh gồm 5 từ phía trước và 5 từ phía sau"],[376,"3.3.4 Mô hình Word2Vec Mô hình Word2Vec sau huấn luyện, được lưu trữ tại bộ nhớ ngoài để có thể sử dụng độc lập trong các bước sau"],[377,"35 3.4 Mô-đun tóm tắt văn bản Mô-đun thực hiện các tác vụ liên quan tới quá trình phân tích, hiểu, và tóm tắt văn bản"],[378,"3.4.1 Khối tiền xử lí văn bản Khác với khối tiền xử lí Word2Vec, quá trình tiền xử lí văn bản đầu vào bao gồm nhiều hơn 2 hoạt động: Chuẩn hóa từ và Loại bỏ các cấu trúc ngữ pháp của từ, đưa về dạng nguyên thể trong tiếng Anh"],[379,"Cả hai hoạt động này đều đóng vai trò quan trọng trong việc vec-tơ hóa tài liệu bởi vì nó sẽ làm giảm không gian biểu diễn của văn bản xuống, do đó làm giảm khối lượng cần tính toán"],[380,"Cụ thể, quá trình tiền xử lí văn bản đầu vào bao gồm các công việc sau: Chia văn bản đầu vào thành tập các câu"],[381,"Chia nhỏ câu thành các từ"],[382,"Lọc từ dừng (stopwords) Chuẩn hóa từ Lemmatizing Stemming Gắn PoS (Part of Speech) Stemming Là kĩ thuật hình thái từ dành cho khai phá thông tin (Information retrieval) được ứng dụng rộng rãi nhất"],[383,"Stemming là kĩ thuật dùng để biến đổi một từ về dạng gốc (được gọi là stem hoặc root form) bằng cách cực kì đơn giản là loại bỏ một số kí tự nằm ở cuối từ mà nó nghĩ rằng là biến thể của từ"],[384,"Người ta gọi các bộ xử lí stemming là stemmer"],[385,"Bởi vì nguyên tắc hoạt động của stemmer rất đơn giản nên tốc độ xử lí của nó rất nhanh nhưng đôi khi lại cho ra kết quả không như ý muốn [10]"],[386,"Ví dụ 4: Cách thực hiện của bộ stemmer Các từ walks, walked, walkingsau khi stemming, bỏ đi các hậu tố -s, -ed, -ing sẽ trở thành walk Từ gosesau stemming thành gos Không thể đưa các từ như spoke, went về dạng speak hay go Lemmatization Lemmatization là một kĩ thuật chuẩn hóa từ khác: Không giống với Stemming là xử lí bằng cách loại bỏ các kí tự cuối từ một cách kinh nghiệm (heuristic), Lemmatization sẽ xử lí thông minh hơn bằng một bộ từ điển hoặc ontology (hệ thống 36 nhãn ngữ nghĩa)"],[387,"Điều này đảm bảo đưa chính xác các dạng biến thể của từ về nguyên gốc trong từ điển"],[388,"Người ta gọi bộ xử lí lemmatization là lemmatizer Nhược điểm của lemmatization là tốc độ xử lí khá chậm vì phải thực hiện tra cứu từ trong cơ sở dữ liệu"],[389,"Trong các ứng dụng xử lí ngôn ngữ tự nhiên mà cần độ chính xác cao hơn và thời gian không quan trọng, người ta có thể sử dụng Lemmatization"],[390,"Ví dụ 5: Cách thực hiện của Lemmatizer Các từ như gose, wentsẽ được đưa chính xác về go"],[391,"Các danh từ như mouse, micecũng được đưa về cùng một dạng như nhau"],[392,"Loại bỏ từ dừng Trong quá trình tính toán, từ dừng là những từ được lọc trước hoặc sau quá trình xử lý dữ liệu ngôn ngữ tự nhiên (văn bản)"],[393,"Từ dừng thường là những từ xuất hiện với tần suất lớn trong một ngôn ngữ, do đó không có một danh sách các từ dừng thống nhất và được sử dụng bởi tất cả các công cụ xử lý ngôn ngữ tự nhiên"],[394,"Một nhóm bất kì các từ có thể được chọn là một từ dừng để thực hiện một mục đích nhất định"],[395,"Đối với một máy tìm kiếm (search engine), có một số từ được xếp vào loại từ dừng do sự xuất hiện thường xuyên trong các trường hợp tìm kiếm như: the, is, at, which và on"],[396,"Trong trường hợp này, từ dừng có thể là nguyên nhân gây ra vấn đề khi tìm kiếm theo cụm từ mà bao gồm những function word này, đặc biệt là khi tìm kiếm một số tên như: The Who, The The, hoặc Take That"],[397,"Ngoài ra, một số máy tìm kiếm loại bỏ các từ common words, bao gồm cả lexical words như want khỏi câu truy vấn nhằm mục đích cải thiện hiệu suất"],[398,"Sự phân biệt giữa function words và lexical words được đề xuất bởi C"],[399,"Fries vào năm 1952 và có một tầm ảnh hưởng lớn đến việc dạy tiếng Anh"],[400,"Function words: Còn gọi là functors là những có một chút sự nhập nhằng về nghĩa và chúng nhấn mạnh mối quan hệ ngữ pháp với các từ khác trong cùng một câu, một quan điểm cụ thể hay tâm trạng của người nói"],[401,"Một số trường hợp của function words: Pronouns đại từ (he him, she-her,.); conjunction liên từ hoặc auxiliary verb - trợ động từ Lexical words: Từ thực, những từ mà không phải là function word"],[402,"lexical word bao gôm: danh từ, động từ, tính từ và hầu hết trạng từ vì có một số trạng từ là function word như: then, why"],[403,"37 Từ điển có thể định nghĩa một cách cụ thể một lexical word, nhưng chỉ có thể miêu tả một cách sử dụng tổng quát của function word"],[404,"Ngược lại, ngữ pháp có thể miêu tả cách sử dụng của function words một cách chi tiết, nhưng lại chỉ có thể xem lexical words trong các thuật ngữ chung (general term)"],[405,"Gán nhãn từ loại PoS: Part of Speech Gán nhãn từ loại, là cơ sở phục vụ cho các bài toán về ngữ nghĩa cao hơn"],[406,"Đồ án sử dụng bộ PoS Tagging trong bộ công cụ xử lý ngôn ngữ tự nhiên Stanford Core NLP"],[407,"Trong bộ Tagger này, các tên viết tắt cho các nhãn từ loại trong tiếng Anh sử dụng hệ thống nhãn Penn Treebank gồm 36 nhãn"],[408,"Sau khi gán nhãn từ loại bằng Stanford PoS Tagger, những nhãn này sẽ được chuyển sang định dạng Universal PoS Tags"],[409,"Hai bảng dưới đây trình bày hệ thống nhãn trong Universal PoS và Peen treebank"],[410,"Open class word Closed class word Other ADJ ADP PUNCT ADV AUX SYM INTJ CCONJ X NOUN DET PROPN NUM VERB PART PRON SCONJ 38 STT Nhãn Mô tả 1 CC Coordinating conjunction 2 CD Cardinal number 3 DT Determiner 4 EX Existential there 5 FW Foreign word 6 IN Preposition/ subordinating conjunction 7 JJ Adjective 8 JJR Adjective, comparative 9 JJS Adjective, superlative 10 LS List item marker 11 MD Modal 12 NN Noun, singular or mass 13 NNS Noun, plural 14 NNP Proper noun, singular 15 NNPS Proper noun, plural 16 PDT Predeterminer 17 POS Possessive ending 18 PRP Personal pronoun 19 PRP$ Possessive pronoun 20 RB Adverb 21 RBR Adverb, comparative 22 RBS Adverb, superlative 23 RP Particle 24 SYM Symbol 25 TO to 26 UH Interjection 27 VB Verb, base form 28 VBD Verb, past tense 29 VBG Verb, gerund or present participle 30 VBN Verb, past participle 31 VBP Verb, non-3rd person singular present 32 VBZ Ver, 3rd persion singular present 33 WDT Wh-determiner 34 WP Wh-pronoun 35 WP$ Possessive wh-pronoun 36 WRB Wh-adverb 39 3.4.2 Khối phân tích ma trận NMF Sử dụng thuật toán trình bày tại mục 2.2 , chúng ta thu được ma trận tần suất từ văn bản đầu vào lần một"],[411,"Tiếp theo, sử dụng mô hình Word2Vec đã được huấn luyện để điều chỉnh ma trận tần suất này"],[412,"Quá trình tính toán sử dụng bước trung gian là xây dựng từ điển tương đồng cho tập từ vựng trong văn bản nguồn với độ tương đồng được xác định qua thực nghiệm"],[413,"Cuối cùng, sử dụng phép phân tích ma trận không âm để phân tích ma trận tần suất thành ma trận đặc trưng ngữ nghĩa không âm và ma trận biến ngữ nghĩa không âm"],[414,"Xây dựng từ điển tương đồng (Thesaurus): Dựa vào mô hình Word2Vec đã được huấn luyện, ta sẽ xây dựng một từ điển tương đồng để phục vụ cho bài toán tóm tắt văn bản tự động"],[415,"Từ điển tương đồng được xây dựng bằng cách tính khoảng cách giữa các từ bằng độ tương đồng cosine và được xây dựng đối với tập từ vựng thu được từ văn bản tóm tắt"],[416,"Bằng cách thực hiện nhiều thực nghiệm để xác định khoảng tương đồng hợp lí, từ điển sẽ bao gồm 1 từ gốc và tập các từ vựng có nét nghĩa gần với nó nhất, đạt độ tương đồng cosine 0.60 Ví dụ 6: Xác định từ đồng nghĩa khi độ tương đồng 0.60: Girl: Boy 0.88 Schoolgirl 0.73 Woman 0.64 12-year-old 0.64 14-year-old 0.63 13-year-old 0.63 Kid 0.62 Teenage 0.60 11-year-old 0.60 Mỗi từ trong văn bản tóm tắt sẽ được ánh xạ thành một vec-tơ 300 chiều (bằng với số chiều của các vec-tơ trong mô hình Word2Vec được huấn luyện)"],[417,"Khoảng cách giữa các từ chính là khoảng cách giữa hai vec-tơ trong không gian"],[418,"40 Điều chỉnh trọng số ma trận sử dụng Word2Vec: Mô hình Word2Vec sau huấn luyện được sử dụng như đầu vào của khối phân tích ma trận không âm trong việc xác định trọng số cho từ trong tài liệu"],[419,"Bằng cách sử dụng từ điển tương đồng đã xây dựng từ bước trước, chúng ta tính tần suất xuất hiện của một từ trong tài liệu bằng tần suất xuất hiện của từ gốc và các từ tương đồng với từ gốc"],[420,"Công thức cập nhật giá trị cho ma trận tần suất được thể hiện như sau: () = () + ( ) (56) Trong đó: value(Aij) là giá trị của ô (i, j) trong ma trận tần suất A trong phân tích NMF count(Termij) là số lần xuất hiện của termi của câu j trong tài liệu count(Similar Termij) là số lần xuất hiện của những term có nét nghĩa tương đồng với termij trong tài liệu thỏa mãn ngưỡng tương đồng về ngữ nghĩa nhất định độ đo cosine"],[421,"Áp dụng kĩ thuật phân tích ma trận không âm đối với ma trận tần suất A, ta thu được đầu ra của phép phân tích ma trận NMF là hai ma trận: ma trận đặc trưng ngữ nghĩa không âm (non-negative semantic feature matrix) W và ma trận biến ngữ nghĩa không âm H (non-negative semantic variable matrix)"],[422,"Đầu ra của khối phân tích NMF: Sử dụng một phương pháp mới để chọn câu dựa trên phân tích NMF và định nghĩa đại lượng Generic Relevance of a Sentence[4] (GRS độ liên quan của câu) như sau: (57) = ( ()) =1 () = =1 =1 =1 (58) Trong đó, trọng số weight(Hi*) là sự liên quan về quan hệ (relative relevance) của đặc trưng ngữ nghĩa thứ i (W*i) với tất cả các đặc trưng ngữ nghĩa còn lại"],[423,"Một cách tổng quát, đại lượng thể hiện mức độ liên quan của một câu chính là mức độ phản ánh của câu đó đối với chủ đề chính của tài liệu, và được biểu diễn dưới hình thức các đặc trưng ngữ nghĩa"],[424,"41 3.4.3 Khối tính điểm cho câu Khối tính điểm cho câu trong tài liệu là tổng hợp điểm đầu ra của 3 khối nhỏ hơn, trong đó: Sử dụng khối Word2Vec như một đặc trưng thứ nhất để xác định các ngữ nghĩa ẩn trong bài toán tóm tắt"],[425,"Sử dụng khối đặc trưng thứ hai để phân tích các đặc trưng cấu trúc của tài liệu"],[426,"Sử dụng kết quả của kĩ thuật phân tích ma trận NMF"],[427,"Đầu ra của khối các đặc trưng cấu trúc: Bằng các kết quả thực nghiệm tại mục 4.4.2 , ta chọn được tập các đặc trưng mang lại kết quả tốt nhất để áp dụng cho bài toán tóm tắt văn bản"],[428,"Các đặc trưng đó bao gồm: Đặc trưng bề mặt Đặc trưng nội dung Đặc trưng độ liên quan Trong đó, trọng số cho từng nhóm đặc trưng được xác định như sau: Đặc trưng bề mặt: Câu văn đứng ở vị trí đầu tài liệu nhận trọng số bằng 1"],[429,"Các câu phía sau sẽ có trọng số giảm dần"],[430,"Trọng số cho Vị trí thuộc đoạn [0, 1] Ngưỡng độ dài trung bình (giá trị cutoff) được quy định cho câu văn thuộc chủ đề báo chí là 12"],[431,"Đặc trưng nội dung Dựa vào đặc trưng Centroid để xác định câu nào tập trung vào chủ đề văn bản"],[432,"Trọng số cho Centroid thuộc đoạn [0, 1] Đặc trưng độ liên quan: Đặc trưng này được sử dụng để tìm ra mối liên hệ giữa các câu trong tài liệu"],[433,"Để làm được điều đó, ta đặt ra quy ước rằng, giữa các câu luôn tồn tại mối liên hệ với nhau"],[434,"Có một số câu quan trọng, những câu khác liên quan đến những câu đó cũng là câu quan trọng"],[435,"Tại thời điểm ban đầu, câu đầu tiên của tài liệu và câu đầu tiên của đoạn văn là quan trọng"],[436,"Sử dụng độ tương đồng cosine để xác định độ liên quan giữa các câu"],[437,"42 Công thức tính điểm cuối cùng Để â = + Để ấ ú (59) Trong đó: Điểm cho câu: Giá trị trọng số cuối cùng cho câu văn"],[438,"Các câu quan trọng được trích rút theo thứ tự giảm dần của giá trị Điểm cho câu GRS: Generic Relevance of a jth sentence, giá trị đầu ra của phân tích NMF Điểm cấu trúc: Giá trị trọng số của câu dựa vào các đặc trưng cấu trúc"],[439,"(60) Để ấ ú = { 2 () + 0.5 () > 12 0 < 12 Trong đó: Centroid: Điểm cho đặc trưng Centroid Position: Điểm cho đặc trưng Vị trí Length: Độ dài của câu, lớn hơn hay nhỏ hơn 12 từ"],[440,"3.4.4 Khối trích rút câu Từ văn bản tóm tắt tại đầu vào, các câu được phân chia và nhận một trọng số tương ứng với mức độ quan trọng trong tài liệu"],[441,"Tập hợp các câu này được sắp xếp trong một danh sách theo thự giảm dần của giá trị Điểm cho câu"],[442,"Lần lượt chọn ra các câu quan trong nhất cho đến khi văn bản đạt ngưỡng độ dài yêu cầu (mục 4.2.2 ), sau đó sắp xếp các câu được trích rút theo thứ tự xuất hiện trong văn bản đầu vào, chúng ta thu được văn bản tóm tắt cuối cùng"],[443,"3.5 Kết luận Như vậy, trong chương 3, đồ án đã tập trung vào việc phân tích ưu-nhược điểm của các mô hình tính toán truyền thống trong bài toán tóm tắt văn bản tự động, từ đó đề xuất thiết kế, xây dựng các mô hình tính toán mới có chất lượng tốt hơn, bao gồm các công việc: Xây dựng công thức tính trọng số cho các đặc trưng cấu trúc, xây dựng mô hình Word2Vec, ứng dụng Word2Vec và các đặc trưng cấu trúc để nâng cao độ chính xác cho kĩ thuật phân tích ma trận NMF"],[444,"Chương tiếp theo tôi sẽ trình bày chi tiết việc xây dựng hệ thống theo mô hình đã thiết kế tại các bước trên"],[445,"43 CHƯƠNG 4 XÂY DỰNG VÀ THỰC NGHIỆM Với mô hình tính toán được đưa ra từ những chương trước, chương này tôi sẽ trình bày chi tiết việc phát triển hệ thống tóm tắt dựa trên mô hình đề xuất để giải quyết bài toán tóm tắt văn bản báo chí tiếng Anh"],[446,"Từ đó, tiến hành các thực nghiệm kiểm tra việc áp dụng hệ thống được xây dựng"],[447,"4.1 Xây dựng hệ thống tóm tắt văn bản Từ kết quả thu được từ các bước trước, tôi đã tìm hiểu và lựa chọn các công cụ để xây dựng hệ thống theo chức năng của từng mô-đun trong mô hình"],[448,"4.1.1 Khối tiền xử lý Trong khối tiền xử lý tổng quát, có hai công việc : Tiền xử lý cho ngữ liệu đầu vào để huấn luyện mô hình Word2Vec và Tiền xử lý đối với văn bản tóm tắt"],[449,"Trong đó, tiền xử lý cho ngữ liệu dùng cho huấn luyện sử dụng bộ công cụ NLTK (Natural Language Toolkit) chuyên dùng để xử lý các vấn đề liên quan đến ngôn ngữ tự nhiên"],[450,"Đối với quá trình tiền xử lý cho văn bản tóm tắt, sử dụng hai công cụ liên quan đến Chuẩn hóa từ (mô-đun của NLTK) và gắn nhãn từ loại (PoS) (sử dụng bộ Stanford Core NLP)"],[451,"4.1.1.1 Bộ công cụ NLTK NLTK là một bộ công cụ dành riêng cho NLP và được tích hợp vào Python"],[452,"Nó đang ngày càng hoàn thiện và tích hợp các công cụ mới bởi hàng nghìn lập trình viên và cộng tác viên trên khắp thế giới"],[453,"NLTK bao gồm những thư viện hàm, các công cụ phân tích, nguồn ngữ liệu, wordnet,"],[454,"giúp đơn giản hóa, tiết kiệm thời gian và công sức cho các lập trình viên"],[455,"NLTK cung cấp một giao diện dễ sử dụng với hơn 50 bộ ngữ liệu và lexical resources với các thư viện hỗ trợ tiền xử lý văn bản dành cho các tác vụ phân loại, tokenization, stemming, gán nhãn từ loại, phân tích cú pháp và suy diễn ngữ nghĩa sematic reasoning"],[456,"44 Một số ví dụ về chức năng trong bộ công cụ NLTK: >>> import nltk >>> sentence = \"\"\"At eight o'clock on Thursday morning .."],[457,"Arthur didn't feel very good.\"\"\" >>> tokens = nltk.word_tokenize(sentence) >>> tokens ['At', 'eight', \"o'clock\", 'on', 'Thursday', 'morning', 'Arthur', 'did', \"n't\", 'feel', 'very', 'good', '.'] >>> tagged = nltk.pos_tag(tokens) >>> tagged[0:6] [('At', 'IN'), ('eight', 'CD'), (\"o'clock\", 'JJ'), ('on', 'IN'), ('Thursday', 'NNP'), ('morning', 'NN')] >>> entities = nltk.chunk.ne_chunk(tagged) >>> entities Tree('S', [('At', 'IN'), ('eight', 'CD'), (\"o'clock\", 'JJ'), ('on', 'IN'), ('Thursday', 'NNP'), ('morning', 'NN'), Tree('PERSON', [('Arthur', 'NNP')]), ('did', 'VBD'), (\"n't\", 'RB'), ('feel', 'VB'), ('very', 'RB'), ('good', 'JJ'), ('.', '.')]) 4.1.1.2 Bộ công cụ Stanford Core NLP Stanford CoreNLP cung cấp một tập các công cụ phân tích ngôn ngữ tự nhiên"],[458,"Công cụ này cho phép xác định các dạng nguyên thể của từ vựng, gán nhãn từ loại (PoS tagging), gán nhãn tên thực thể (Named-Entity recognition)"],[459,"Chuẩn hóa ngày, giờ,"],[460,"45 4.1.2 Khối huấn luyện mô hình Với dữ liệu đã được tiền xử lý, tôi sử dụng mã nguồn mở gensim[3] một trong những mã nguồn mở tốt nhất về Word2Vec-Doc2Vec trên ngôn ngữ PYTHON"],[461,"Với các tùy chỉnh về việc lựa chọn kiến trúc, số lượng chiều vec-tơ,.ta thu được mô hình Word2Vec"],[462,"Mô hình sau khi huấn luyện thành công sẽ được lưu trữ và có thể sử dụng độc lập trên một máy đơn chứ không nhất thiết phải cùng hệ thống huấn luyện"],[463,"4.1.3 Khối phân tích ma trận Sử dụng mô hình Word2Vec sau khi huấn luyện thành công với các dữ liệu là văn bản cần tóm tắt đã được xử lý, tôi sử dụng mã nguồn mở Scikit-learn để khởi tạo các thuật toán phân tích ma trận"],[464,"Có thể nói, thư viện Scikit-learn chính là một trong số những nền tảng phổ biến nhất hiện nay dành cho lĩnh vực học máy và khoa học dữ liệu [2]"],[465,"Scikit-learn được xây dựng trên nền Python, một ngôn ngữ lập trình với sự hỗ trợ đầy đủ và mạnh mẽ"],[466,"Được cung cấp một số lượng lớn các thuật toán hiệu quả, bao phủ trọn lĩnh vực học máy và khoa học dữ liệu : Phân lớp, phân cụm, tiền xử lý dữ liệu, giảm số chiều, lựa chọn mô hình,.."],[467,"Scikit-learn còn được biết đến với sự rõ ràng, nhất quán và hợp lý trong API của mình"],[468,"Điểm lợi của tính nhất quán trong trường hợp này là : Một khi người đọc hiểu được ký pháp và cách sử dụng căn bản của Scikit-learn cho một mô hình thì việc chuyển đổi sang một mô hình mới hoặc thuật toán mới là vô cùng dễ dàng"],[469,"Ngoài ra, song song với đó là nguồn tài liệu online luôn đầy đủ và thuận tiện"],[470,"46 4.2 Dữ liệu thực nghiệm 4.2.1 Ngữ liệu huấn luyện Word2Vec Đặc điểm Chi tiết Số lượng Tokens 2.3 tỉ Số lượng từ khác nhau 296,630 từ Tiền xử lí Chia thành các câu Lemmatized Gắn nhãn từ loại Loại bỏ từ dừng Độ dài cửa sổ ngữ cảnh 5 từ bên trái & 5 từ bên phải Thuật toán Continuous Skip-Gram Hiệu năng của mô hình SimLex999 0.40 Google Analogy 0.81 Ngữ liệu dùng để xây dựng mô hình Word2Vec là nguồn dữ liệu từ Wikipedia"],[471,"Các chủ đề bao gồm : Báo chí, tin tức"],[472,"Thông tin chi tiết của bộ ngữ được trình bày trong hình vẽ trên"],[473,"Đây là những trang báo chí và tin tức đáng tin cậy, phủ rộng trên nhiều lĩnh vực"],[474,"Việc lấy dữ liệu từ nguồn Wikipedia cho phép ta xây dựng một mô hình vec-tơ hóa đặc thù cho dữ liệu văn bản báo chí nhưng vẫn đầy đủ các lĩnh vực"],[475,"Nguồn ngữ liệu này sẽ được tiền xử lý trước khi được đưa vào mô hình, bao gồm: chia dữ liệu theo đơn vị câu, tách câu thành các token, thực hiện chuẩn hóa từ, gắn nhãn từ loại, gắn nhãn tên thực thể và loại bỏ từ dừng"],[476,"Độ dài của cửa sổ ngữ cảnh dùng để huấn luyện mô hình Word2Vec gồm 5 từ phía trước và 5 từ phía sau"],[477,"Mô hình Word2Vec sau huấn luyện thu được có kích thước 340 MB"],[478,"Các độ đo được sử dụng để đánh giá chất lượng của model bao gồm : SimLex999 và Google Analogy lần lượt là : SimLex999: 0.4 Google Analogy: 0.81 47 4.2.2 Bộ dữ liệu đánh giá tóm tắt văn bản Đồ án sử dụng tập dữ liệu DUC 2004 như là một tập dữ liệu để kiểm tra"],[479,"Document Understanding Conference (DUC) là một hội nghị quốc tế để đánh giá hiệu suất của hệ thống tóm tắt bằng cách so sánh bản tóm tắt bằng tay của các chuyên gia với bản tóm tắt tự động của máy tính"],[480,"Tác vụ #Cụm #Nguồn Tác vụ 1 50 TDT Tiếng Anh Thời báo AP, Tác vụ 2 50 TDT Tiếng Anh Thời báo NewYorkTimes Tác vụ 3 25 TDT Tiếng Ả-rập Thời báo Agence France, Tác vụ 4 25 TDT Tiếng Ả-rập Thời báo Ả-rập Tác vụ 5 50TREC Tiếng Anh Thời báo AP, Thời báo NewYorkTimes, Thời báo Tân Hoa Xã (TDT: Topic detection and tracking) DUC 2004 là bộ dữ liệu dùng cả cho tóm tắt đơn văn bản và đa văn bản, trong khi DUC 2003 trở về trước chỉ áp dụng cho đơn văn bản và DUC 2005 trở về sau chỉ áp dụng cho tóm tắt đa văn bản"],[481,"DUC 2004 bao gồm các văn bản thể loại báo chí"],[482,"Tác vụ 1 : Tóm tắt văn bản rất ngắn (văn bản tóm tắt 10 từ) Tác vụ 2 : Tóm tắt văn bản ngắn tập trung vào các sự kiện ( văn bản tóm tắt 100 từ) 48 Tác vụ 3 và Tác vụ 4 : Chứa các bản tóm tắt từ một nguồn nhiễu, được sinh ra từ quá trình dịch máy (machine translation) từ tiếng Ả-rập sang tiếng Anh (văn bản tóm tắt 100 từ) Tác vụ 5 : Bao gồm các tóm tắt tập trung vào dạng truy vấn"],[483,"4.3 Đánh giá chất lượng tóm tắt Đồ án sử dụng độ đánh giá ROUGE cho sự so sánh giữa các bản tóm tắt tự động và bản tóm tắt tham chiếu bởi các chuyên gia có trong tập dữ liệu thử nghiệm"],[484,"ROUGE viết tắt của Recall-Oriented Understudy for Gisting Evaluation"],[485,"ROUGE bao gồm bộ các độ đo để đánh giá tự động chất lượng của văn bản tóm tắt bằng cách so sánh bản tóm tắt sinh ra bởi hệ thống với những bản tóm tắt được tạo ra bởi con người"],[486,"Các độ đo cơ bản ROUGE bao gồm : ROUGE-N, ROUGE-L, ROUGE-W và ROUGE-S"],[487,"Trong đó 3 trong số các độ đo trên được sử dụng trong DUC 2004"],[488,"4.3.1 ROUGE-N: Thống kê số lần xuất hiện đồng thời của các N-gram (N-gram Co-Occurrence Statistics) ROUGE-N là một thu hồi n-gram (n-gram recall) giữa một bản tóm tắt tự động và một tập các tài liệu tóm tắt tham chiếu (ReferenceSummaries)"],[489,"ROUGE-N được tính như sau: (61) = (){} (){} Trong đó: n là chiều dài của n-gram Countmatch(gramn) là số lượng tối đa n-gram có thể xảy ra đồng thời trong bản tóm tắt tự động và bản tóm tắt tham chiếu"],[490,"Rõ ràng ROUGE-N là một độ đo liên quan đến độ recall bởi vì mẫu số của vế phải trong công thức trên là tổng số n-gram xảy ra ở phía bản tóm tắt tham chiếu"],[491,"Cũng có một lưu ý rằng, số lượng n-gram ở mẫu số trong công thức tính ROUGE-N sẽ tăng lên khi chúng ta cho thêm nhiều tham chiếu"],[492,"Điều này hoàn toàn trực quan và hợp lí bởi vì có thể tồn tại nhiều bản tóm tắt tốt"],[493,"Mỗi khi chúng ta thêm một tham chiếu vào tập các văn bản tham chiếu, chúng ta đã mở rộng không gian các văn bản tóm tắt thay thế (alternative summaries)"],[494,"Bằng 49 cách điều khiển các kiểu tham chiếu mà ta thêm vào tập văn bản tham chiếu, chúng ta có thể thiết kế các đánh giá tập trung vào các khía cạnh khác nhau của việc tóm tắt"],[495,"Ngoài ra, tổng tử số lớn hơn tổng số số bản tóm tắt tham chiếu"],[496,"Điều này hiệu quả vì cung cấp thêm nhiều trọng số để so khớp các n-grams xảy ra trong đa tham chiếu"],[497,"Do đó, một bản tóm tắt tự động càng chứa nhiều những từ được xuất hiện trong nhiều bản tóm tắt tham chiếu thì sẽ dành được điểm ROUGE-N càng cao"],[498,"Điều này một lần nữa lại rất trực quan và hợp lí bởi vì chúng ta thường ưu tiên các bản tóm tắt tự động càng có nhiều nét giống với các điểm giống nhau giữa các bản tóm tắt tham chiếu càng tốt"],[499,"Khi sử dụng đa tham chiếu, chúng ta tính ROUGE-N theo từng cặp, giữa bản tóm tắt tự động s và từng bản tóm tắt tham chiếu ri trong tập các văn bản tóm tắt tham chiếu"],[500,"Sau đó, kết quả điểm ROUGE-N cuối cùng trong đa tham chiếu sẽ là điểm ROUGE-N cao nhất trong tất cả các cặp được tính"],[501,"Điều này được thể hiện theo công thức sau: = ( , ) (62) Trong quá trình khởi tạo, thuật toán đánh giá sử dụng thủ tục Jackknifing"],[502,"Cho M tham chiếu, chúng ta tính điểm tốt nhất khi duyệt qua M tập tham chiếu M- 1; điểm ROUGE-N cuối cùng là trung bình cộng của M điểm ROUGE-N đối với các tham chiếu M-1"],[503,"Thủ tục Jackknifing được chọn bởi chúng ta thường cần so sánh hiệu suất giữa con người và hệ thống và bản tóm tắt tham chiếu thường chỉ do con người tạo ra"],[504,"Bằng cách áp dụng thủ tục này, chúng ta có thể ước lượng hiệu suất trung bình của con người bằng việc lấy trung bình cộng M điểm ROUGE-N của một bản tham chiếu với toàn bộ M-1 tham chiếu"],[505,"4.3.2 Độ đo sử dụng để đánh giá chất lượng tóm tắt Trong phạm vi nghiên cứu, tôi đề xuất sử dụng 2 độ đo ROUGE-1 và ROUGE- 2 tương ứng với n = 1 và n = 2 trong ROUGE-N để đánh giá chất lượng của văn bản cần tóm tắt"],[506,"50 4.4 Kết quả thực nghiệm Đồ án tập trung vào việc nghiên cứu kết hợp phương pháp tóm tắt không giám sát đại diện là phương pháp phân tích ma trận NMF và ứng dụng của phương pháp học sâu đại diện là biểu diễn phân tán của từ nên việc thiết kế các trường hợp thực nghiệm sẽ lấy trường hợp NMF và Word2Vec làm cơ sở"],[507,"Các thí nghiệm được thiết kế bao gồm 2 mục tiêu chính: Đánh giá và lựa chọn hướng tiếp cận tóm tắt Đánh giá và lựa chọn đặc trưng Đánh giá và lựa chọn phương pháp tóm tắt 4.4.1 Kết quả lựa chọn hướng tiếp cận Rouge Rouge-1 Rouge-2 NMF 37.488 7.858 Surface + Relevance + Content 38.351 8.856 NMF + Word2Vec 39.979 8.921 Từ kết quả thí nghiệm 1 ta có nhận xét : Phương pháp tiếp cận theo hướng cấu trúc sử dụng 3 đặc trưng cấu trúc: đặc trưng bề mặt, độ liên quan và nội dung có kết quả tốt hơn hướng phân tích ma trận không âm NMF Phương pháp kết hợp phân tích ma trận không âm và Word2Vec cho kết quả tốt hơn phương pháp tiếp cận theo hướng cấu trúc Như vậy, trong 3 hướng tiếp cận thì trường hợp kết hợp phương pháp biểu diễn trong không gian vec-tơ và biểu diễn phân tán của từ là có kết quả tốt hơn cả"],[508,"Tuy nhiên, chúng ta sẽ thực hiện thí nghiệm tiếp theo để nghiên cứu việc kết hợp cả 3 hướng tiếp cận này vào trong cùng phương pháp"],[509,"Tại thí nghiệm này, sẽ thực hiện việc lựa chọn theo từng đặc trưng để kết hợp với 2 kĩ thuật phân tích ma trận không âm và Word2Vec"],[510,"51 4.4.2 Kết quả lựa chọn đặc trưng Rouge Rouge-1 Rouge-2 NMF+ Word2Vec + Relevance 43.555 11.233 NMF+ Word2Vec + Surface 45.982 15.011 NMF+ Word2Vec + Content 46.013 15.231 Thí nghiệm 2 cho chúng ta các nhận xét : Trong 3 đặc trưng, thì đặc trưng Content cho chất lượng văn bản tóm tắt tốt nhất Đặc trưng Surface khi kết hợp với NMF và Word2Vec thì cho kết quả cao hơn Relevance nhưng thấp hơn đặc trưng Content Dựa vào kết quả thí nghiệm 2, ta thiết kế thí nghiệm 3 để kiểm tra và so sánh giữa các kết quả khi kết hợp nhiều đặc trưng lại với nhau; theo từng cặp một, hoặc kết hợp cả 3 đặc trưng"],[511,"Vì như đã trình bày tại Chương 2 mục 2.1.3.1 : Mỗi đặc trưng cấu trúc đóng góp một vai trò riêng của mình và có thể sự kết hợp các đặc trưng với nhau sẽ cho chúng ta một kết quả có ý nghĩa"],[512,"4.4.3 Kết quả cuối cùng Rouge Rouge-1 Rouge-2 NMF+ Word2Vec + Surface + Relevance 42.501 11.112 NMF+ Word2Vec + Relevance + Content 45.175 15.210 NMF+ Word2Vec + Surface + Content 45.817 14.101 NMF+ Word2Vec + 3 Features 49.979 12.911 52 Có thể coi thí nghiệm 3 cũng là thí nghiệm kiểm tra cuối cùng để so sánh giữa các phương pháp tóm tắt văn bản được trong đồ án"],[513,"Trong đó : Trường hợp kết hợp phân tích ma trận không âm, Word2Vec và 3 đặc trưng cấu trúc cho kết quả tốt nhất"],[514,"ROUGE-1 đạt 49.979% và ROUGE-2 đạt 12.911%"],[515,"Trường hợp kết hợp kết hợp NMF, Word2Vec và 2 đặc trưng Surface, Content cho điểm ROUGE-1 là 45.817%, cao hơn cả 2 tổ hợp đặc trưng còn lại, lần lượt là : Surface + Relevance 42.501% và Relevance + Content 45.175%"],[516,"Tuy nhiên, ROUGE-2 khi kết hợp với 2 đặc trưng Surface, Content là 14.101 lại nhỏ hơn trường hợp Relevance + Content ( bằng 15.210%) nhưng lớn hơn Surface + Relevance (11.112%) 4.5 Kết luận Qua kết quả của cả 3 thí nghiệm, chúng ta rút ra được nhận xét : Trong phạm vi nghiên cứu, Đồ án đã chứng minh được phương pháp kết hợp 3 hướng tiếp cận : cấu trúc, không gian vec-tơ và biểu diễn phân tán là mang lại kết quả tốt tất cả các trường hợp còn lại"],[517,"Kết quả này chứng minh cho ta một hướng đi mới, có ý nghĩa trong việc khai phá dữ liệu bằng cách ứng dụng Word2Vec để đưa những từ có nét nghĩa giống nhau về gần nhau trong không gian"],[518,"Do tính đặc trưng của ngôn ngữ học, sự kết hợp các đặc trưng cấu trúc không phải luôn tuân theo quy luật tỉ lệ thuận giữa điểm ROUGE-1 và ROUGE-2"],[519,"53 CHƯƠNG 5 KẾT LUẬN VÀ HƯỚNG PHÁT TRIỂN 5.1 Ưu điểm của áp dụng biểu diễn phân tán trong bài toán tóm tắt Với những kết quả đã trình bày các chương trên, có thể thấy việc sử dụng Word2Vec trong việc vec-tơ hóa từ cho ta một kết quả tốt với không gian bộ nhớ sử dụng là ít trên các thuật toán tóm tắt văn bản"],[520,"Tuy nhiên, không có nghĩa là các phương pháp khai phá dữ liệu cũ đã lỗi thời hay lạc hậu"],[521,"Trong thực tế, theo các kết quả thu được từ thực nghiệm trong đồ án, việc sử dụng kết hợp các phương pháp một cách khéo léo sẽ làm tăng hiệu quả lên một cách đáng ghi nhận"],[522,"5.2 Đóng góp của đồ án Đồ án đưa ra một cái nhìn tổng quan về các kĩ thuật: Phân tích ma trận, các đặc trưng cấu trúc của văn bản"],[523,"Từ đó đề xuất xây dựng mô hình ứng dụng biểu diễn phân tán từ Word2Vec kết hợp các phương pháp phân tích truyền thống trong vấn đề khai phá dữ liệu văn bản mà cụ thể là bài toán tóm tắt văn bản tự động"],[524,"5.3 Hướng nghiên cứu tiếp Tóm tắt theo truy vấn (Query base) dựa trên các kĩ thuật ma trận"],[525,"Một truy vấn cũng như một câu hỏi về một vấn đề nào đó dựa trên một tập tài liệu có trước"],[526,"Việc trích xuất thông tin cần thiết nhất với một câu hỏi cũng là một đề tài nghiên cứu tốt và có nhiều ứng dụng thực tiễn về việc tra cứu thông tin"],[527,"Xây dựng một hệ thống tóm tắt văn bản cho tiếng Việt"],[528,"Việc tổng hợp và tóm tắt các văn bản là một vấn đề khá hữu ích cho việc tìm kiếm và tra cứu thông tin"],[529,"Loại bỏ dư thừa và xung đột dữ liệu"],[530,"Việc loại bỏ dư thừ"]],"downloaded":true,"m":[-1,-1],"n":"20122230_Quan_Van_Phu_1496365507040.txt","o":"http://storage.googleapis.com/soict-projects/cnpm/hedspi-a/20122230_Quan_Van_Phu_1496365507040.pdf\r"},{"saved_path":"temp/tim_hieu_cac_huong_tiep_can_bai_toan_phan_loai_van_ban_va_xa_6703.txt","r":0,"s":[],"t":"\n\n \n\nTRƯỜNG ĐẠI HỌC KHOA HỌC TỰ NHIÊN \nKHOA CÔNG NGHỆ THÔNG TIN \n\nBỘ MÔN HỆ THỐNG THÔNG TIN \n \n\n \n\nSINH VIÊN THỰC HIỆN \nNGUYỄN TRẦN THIÊN THANH  - TRẦN KHẢI HOÀNG             \n\n \n\n \n\nTÌM HIỂU CÁC HƯỚNG TIẾP CẬN \nBÀI TOÁN PHÂN LOẠI VĂN BẢN VÀ  \n\nXÂY DỰNG PHẦN MỀM  \nPHÂN LOẠI TIN TỨC BÁO ĐIỆN TỬ \n\n \n\n \nKHÓA LUẬN CỬ NHÂN TIN HỌC \n\n \n\n \n\n \n\n \n\n \nTp.HCM, 2005 \n\n\n\n \n  \n\n \n\nTRƯỜNG ĐẠI HỌC KHOA HỌC TỰ NHIÊN \nKHOA CÔNG NGHỆ THÔNG TIN \n\nBỘ MÔN HỆ THỐNG THÔNG TIN \n \n\n \n\nSINH VIÊN THỰC HIỆN \n NGUYỄN TRẦN THIÊN THANH  - 0112243 \n TRẦN KHẢI HOÀNG            - 0112305 \n\n \n\n \n\nTÌM HIỂU CÁC HƯỚNG TIẾP CẬN \nBÀI TOÁN PHÂN LOẠI VĂN BẢN VÀ  \n\nXÂY DỰNG PHẦN MỀM  \nPHÂN LOẠI TIN TỨC BÁO ĐIỆN TỬ \n\n \n\nKHÓA LUẬN CỬ NHÂN TIN HỌC \n\nGIÁO VIÊN HƯỚNG DẪN \nCử nhân : NGUYỄN VIỆT THÀNH \nThạc sĩ : NGUYỄN THANH HÙNG \n\n \n\n \nNiên khóa 2001-2005 \n\n\n\n \n \n\ni \n\nLỜI CẢM ƠN \n \n\nChúng em xin gửi lời cảm ơn chân thành và sâu sắc nhất đến thầy Nguyễn \n\nViệt Thành và thầy Nguyễn Thanh Hùng đã tận tụy hướng dẫn, động viên, \n\ngiúp đỡ chúng em trong suốt thời gian thực hiện đề tài. \n\nChúng em xin chân thành cảm ơn quý Thầy Cô trong Khoa Công Nghệ \n\nThông Tin truyền đạt kiến thức quý báu cho chúng em trong những năm học \n\nvừa qua. \n\nChúng con xin nói lên lòng biết ơn đối với Ông Bà, Cha Mẹ luôn là nguồn \n\nchăm sóc, động viên trên mỗi bước đường học vấn của chúng con. \n\nXin chân thành cám ơn các anh chị và bạn bè đã ủng hộ, giúp đỡ và động \n\nviên chúng em trong thời gian học tập và nghiên cứu. \n\nMặc dù chúng em đã cố gắng hoàn thành luận văn trong phạm vi và khả \n\nnăng cho phép nhưng chắc chắn sẽ không tránh khỏi những thiếu sót. Chúng \n\nem kính mong nhận được sự cảm thông và tận tình chỉ bảo của quý Thầy Cô \n\nvà các bạn. \n\n \n\n \n Nguyễn Trần Thiên Thanh & Trần Khải Hoàng \n\n 07/2005 \n \n\n \n\n \n\n \n\n \n\n\n\n \n  \n\n \n\n ii \n\nLỜI NÓI ĐẦU \nTrong những năm gần đây, sự phát triển vượt bậc của công nghệ thông tin đã \n\nlàm tăng số lượng giao dịch thông tin trên mạng Internet một cách đáng kể đặc biệt \n\nlà thư viện điện tử, tin tức điện tử.... Do đó mà số lượng văn bản xuất hiện trên \n\nmạng Internet cũng tăng theo với một tốc độ chóng mặt. Theo số lượng thống kê từ \n\nBroder et al (2003), lượng thông tin đó lại tăng gấp đôi sau từ 9 đến 12 tháng, và tốc \n\nđộ thay đổi thông tin là cực kỳ nhanh chóng.  \n\nVới lượng thông tin đồ sộ như vậy, một yêu cầu lớn đặt ra đối với chúng ta là \n\nlàm sao tổ chức và tìm kiếm thông tin có hiệu quả nhất. Phân loại thông tin là một \n\ntrong những giải pháp hợp lý cho yêu cầu trên. Nhưng một thực tế là khối lượng \n\nthông tin quá lớn, việc phân loại dữ liệu thủ công là điều không tưởng. Hướng giải \n\nquyết là một chương trình máy tính tự động phân loại các thông tin trên. \n\nChúng em đã tập trung thực hiện đề tài \u201cTìm hiểu các hướng tiếp cận cho bài \n\ntoán phân loại văn bản và xây dựng ứng dụng phân loại tin tức báo điện tử\u201d \n\nnhằm tìm hiểu và thử nghiệm các phương pháp phân loại văn bản áp dụng trên tiếng \n\nViệt. Để thực hiện việc phân loại, điều bắt buộc đối với tiếng Việt đó là việc tách từ. \n\nTrong luận văn này, chúng em cũng tìm hiểu một số cách tách từ tiếng Việt và thử \n\nnghiệm một phương pháp tách từ mới thích hợp cho việc phân loại mà không dùng \n\nbất kỳ từ điển hoặc tập ngữ liệu nào. Cuối cùng, chúng em xây dựng phần mềm \n\nphân loại văn bản tích hợp vào trang web \u201cToà soạn báo điện tử\u201d (Luận văn khoá \n\n2000 - Hoàng Minh Ngọc Hải (0012545), Nguyễn Duy Hiệp (0012038)) nhằm phục \n\nvụ cho việc phân loại tin tức báo điện tử.  \n\nHiện nay, trang web của khoa chúng ta vẫn chưa thực hiện được việc phân loại \n\ntự động các tin tức lấy về, do đó gây ra rất nhiều lãng phí về thời gian và công sức \n\ncủa nhà quản trị cũng như làm giới hạn việc thu thập tin tức từ nhiều nguồn khác \n\nnhau. Ứng dụng phân loại tin tức báo điện tử tích hợp với việc lấy tin tức tự động \n\ncủa chúng em hy vọng sẽ đem đến một cách quản trị mới, nhanh chóng và hiệu quả \n\nhơn cách lấy tin truyền thống. Ngoài ra, trong điều kiện cần cập nhật thông tin một \n\n\n\n \n  \n\n \n\n iii \n\ncách nhanh chóng như hiện nay, phần mềm phân loại văn bản tự động của chúng \n\nem còn có khả năng ứng dụng cho nhiều loại trang báo điện tử tiếng Việt khác. \n\nNội dung của luận văn được trình bày bao gồm 8 chương; trong đó, 3 chương \n\nđầu trình bày các hướng tiếp cận cho phân loại văn bản và tách từ tiếng Việt hiện \n\nnay; 2 chương tiếp theo trình bày hướng tiếp cận của luận văn đối với phân loại văn \n\nbản và tách từ tiếng Việt; 3 chương cuối trình bày hệ thống thử nghiệm văn bản, \n\nứng dụng vào phân loại tin tức bán tự động, và cuối cùng là đánh giá, kết luận quá \n\ntrình nghiên cứu của luận văn. \n\n Chương 1. Tổng quan: giới thiệu sơ lược về các phương pháp phân loại văn \n\nbản và các hướng tiếp cận cho việc tách từ tiếng Việt; đồng thời xác định \n\nmục tiêu của đề tài. \n\n Chương 2. Một số phương pháp phân loại văn bản: giới thiệu tóm tắt một \n\nsố phương pháp phân loại văn bản dành cho tiếng Anh. \n\n Chương 3. Phương pháp tách từ tiếng Việt hiện nay: trình bày tóm tắt \n\nmột số phương pháp tách từ tiếng Việt hiện nay, ưu điểm và hạn chế của các \n\nphương pháp đó. \n\n Chương 4. Phương Tách từ Tiếng Việt không dựa trên tập ngữ liệu \n\nđánh dấu (annotated corpus) hay từ điển (lexicon) \u2013 Một thách thức: \n\ntrình bày phương pháp tách từ tiếng Việt mới chỉ dựa vào việc thống kê từ \n\nInternet thông qua Google mà không cần bất kỳ từ điển hay tập ngữ liệu nào. \n\n Chương 5. Bài toán phân loại tin tức báo điện tử: trình bày hướng tiếp cận \n\ncho bài toán phân loại tin tức báo điện tử. \n\n Chương 6. Hệ thống thử nghiệm phân loại văn bản: giới thiệu về hệ thống \n\nthử nghiệm các phương pháp tách từ và phân loại văn bản do chúng em xây \n\ndựng. Ngoài ra, trong chương 6, chúng em trình bày về dữ liệu dùng để thử \n\nnghiệm và các kết quả thử nghiệm thu được. \n\n Chương 7. Ứng dụng phân loại tin tức báo điện tử bán tự động: giới \n\nthiệu ứng dụng phân loại tin tức báo điện tử do chúng em xây dựng tích hợp \n\n\n\n \n  \n\n \n\n iv \n\ntrên trang web do luận văn \u201cTòa soạn báo điện tử\u201d khóa 2000 xây dựng của \n\nsinh viên Hoàng Minh Ngọc Hải (0012545), Nguyễn Duy Hiệp (0012038) \n\n Chương 8. Tổng kết: là chương cuối cùng của đề tài, tóm lại các vấn đề đã \n\ngiải quyết và nêu một số hướng phát triển trong tương lai. \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n\n\n \n  \n\n \n\n v \n\nMỤC LỤC \nChương 1. TỔNG QUAN............................................................................................2 \n\n1.1. Đặt vấn đề ............................................................................................................2 \n\n1.2. Các  phương pháp phân loại văn bản...................................................................2 \n\n1.3. Tách từ Tiếng Việt \u2013 Một thách thức thú vị ........................................................3 \n\n1.4. Mục tiêu của luận văn..........................................................................................5 \n\n1.4.1. Phần tìm hiểu các thuật toán phân loại văn bản.........................................5 \n\n1.4.2. Phần tách từ tiếng Việt...............................................................................5 \n\n1.4.3. Phần mềm phân loại tin tức báo điện tử bán tự động ................................5 \n\n1.4.4. Đóng góp của luận văn ..............................................................................6 \n\nChương 2. CÁC PHƯƠNG PHÁP PHÂN LOẠI VĂN BẢN TIẾNG ANH..............8 \n\n2.1. Bối cảnh các phương pháp phân loại văn bản hiện nay.......................................8 \n\n2.2. Các phương pháp phân loại văn bản tiếng Anh hiện hành ..................................8 \n\n2.2.1. Biểu diễn văn bản ......................................................................................8 \n\n2.2.2. Support vector Machine(SVM) ...............................................................10 \n\n2.2.3. K\u2013Nearest Neighbor (kNN).....................................................................12 \n\n2.2.4. Naïve Bayes (NB)....................................................................................13 \n\n2.2.5. Neural Network (NNet) ...........................................................................15 \n\n2.2.6. Linear Least Square Fit (LLSF)...............................................................17 \n\n2.2.7. Centroid- based vector .............................................................................18 \n\n2.3. Kết luận..............................................................................................................19 \n\nChương 3. CÁC PHƯƠNG PHÁP TÁCH TỪ TIẾNG VIỆT HIỆN NAY ..............22 \n\n3.1. Tại sao tách từ tiếng Việt là một thách thức? ....................................................22 \n\n3.1.1. So sánh giữa tiếng Việt và tiếng Anh ......................................................22 \n\n3.1.2. Nhận xét ...................................................................................................23 \n\n3.2. Bối cảnh các phương pháp tách từ hiện nay ......................................................23 \n\n3.2.1. Bối cảnh chung ........................................................................................23 \n\n3.2.2. Các hướng tiếp cận dựa trên từ (Word-based approaches)......................24 \n\n3.2.3. Các hướng tiếp cận dựa trên ký tự (Character-based approaches) ..........26 \n\n3.3. Một số phương pháp tách từ tiếng Việt hiện nay...............................................28 \n\n3.3.1. Phương pháp Maximum Matching: forward/backward...........................28 \n\n\n\n \n  \n\n \n\n vi \n\n3.3.2. Phương pháp giải thuật học cải biến ( TBL)............................................30 \n\n3.3.3. Mô hình tách từ bằng WFST và mạng Neural.........................................31 \n\n3.3.4. Phương pháp quy hoạch động (dynamic programming) .........................34 \n\n3.3.5. Phương pháp tách từ tiếng Việt dựa trên thống kê từ Internet và thuật \n\ntoán di truyền (Internet and Genetics Algorithm-based Text Categorization for \n\nDocuments in Vietnamese - IGATEC)........................................................................34 \n\n3.4. So sánh các phương pháp tách từ Tiếng Việt hiện nay......................................37 \n\n3.5. Kết luận..............................................................................................................37 \n\nChương 4. TÁCH TỪ TIẾNG VIỆT KHÔNG DỰA TRÊN TẬP NGỮ LIỆU ĐÁNH \n\nDẤU (ANNOTATED CORPUS) HAY TỪ ĐIỂN (LEXICON) \u2013 MỘT THÁCH THỨC 40 \n\n4.1. Giới thiệu ...........................................................................................................40 \n\n4.2. Các nghiên cứu về thống kê dựa trên Internet ...................................................40 \n\n4.2.1. Giới thiệu .................................................................................................40 \n\n4.2.2. Một số công trình nghiên cứu về thống kê dựa trên Internet...................41 \n\n4.2.3. Nhận xét ...................................................................................................43 \n\n4.3. Các phương pháp tính độ liên quan giữa các từ dựa trên thống kê ...................43 \n\n4.3.1. Thông tin tương hỗ  và t-score dùng  trong tiếng Anh ............................44 \n\n4.3.2. Một số cải tiến trong cách tính độ liên quan ứng dụng trong tách từ tiếng \n\nHoa và tiếng Việt .........................................................................................................46 \n\n4.3.3. Nhận xét  về các cách tính độ liên quan khi áp dụng cho tiếng Việt .......48 \n\n4.4. Tiền xử lý (Pre-processing) ...............................................................................49 \n\n4.4.1. Xử lý văn bản đầu vào .............................................................................49 \n\n4.4.2. Tách ngữ & tách stopwords .....................................................................50 \n\n4.5. Hướng tiếp cận tách từ dựa trên thống kê từ Internet  và thuật toán di truyền \n\n(Internet and Genetic Algorithm - based ) .......................................................................51 \n\n4.5.1. Công cụ trích xuất thông tin từ Google ...................................................51 \n\n4.5.2. Công cụ tách từ dùng thuật toán di truyền (Genetic Algorithm \u2013 GA) ...53 \n\n4.6. Kết luận..............................................................................................................61 \n\nChương 5. BÀI TOÁN PHÂN LOẠI TIN TỨC ĐIỆN TỬ ......................................63 \n\n5.1. Lý do chọn phương pháp Naïve Bayes..............................................................63 \n\n5.2. Thuật toán Naïve Bayes.....................................................................................64 \n\n5.2.1. Công thức xác suất đầy đủ Bayes ............................................................64 \n\n\n\n \n  \n\n \n\n vii \n\n5.2.2. Tính độc lập có điều kiện (Conditional Independence) ...........................65 \n\n5.2.3. Nguồn gốc thuật toán Naïve Bayes..........................................................65 \n\n5.2.4. Phương pháp Naïve Bayes trong phân loại văn bản ................................66 \n\n5.2.5. Hai mô hình sự kiện trong phân loại văn bản bằng phương pháp Naïve \n\nBayes 68 \n\n5.3. Bài toán phân loại tin tức điện tử tiếng Việt ......................................................70 \n\n5.3.1. Quy ước ...................................................................................................70 \n\n5.3.2. Công thức phân loại văn bản trong IGATEC [H. Nguyen et al, 2005] ...71 \n\n5.3.3. Công thức Naïve Bayes trong bài toán phân loại tin tức điện tử tiếng Việt \n\nsử dụng thống kê từ Google.........................................................................................72 \n\n5.4. Kết luận..............................................................................................................74 \n\nChương 6. HỆ THỐNG THỬ NGHIỆM PHÂN LOẠI    VĂN BẢN ......................76 \n\n6.1. Giới thiệu hệ thống thử nghiệm Vikass .............................................................76 \n\n6.1.1. Chức năng hệ thống Vikass .....................................................................76 \n\n6.1.2. Tổ chức và xử lý dữ liệu ..........................................................................76 \n\n6.1.3. Một số màn hình của hệ thống Vikass.....................................................79 \n\n6.2. Thử nghiệm các cách trích xuất thông tin..........................................................82 \n\n6.2.1. Các phương pháp thử nghiệm..................................................................82 \n\n6.2.2. Nhận xét ...................................................................................................84 \n\n6.3. Dữ liệu thử nghiệm ............................................................................................84 \n\n6.3.1. Nguồn dữ liệu ..........................................................................................84 \n\n6.3.2. Số lượng dữ liệu thử nghiệm ...................................................................84 \n\n6.3.3. Nhận xét ...................................................................................................86 \n\n6.4. Thử nghiệm các công thức tính độ tương hỗ MI ...............................................87 \n\n6.4.1. Các phương pháp thử nghiệm..................................................................87 \n\n6.4.2. Kết quả .....................................................................................................87 \n\n6.4.3. Nhận xét ...................................................................................................88 \n\n6.5. Thử nghiệm phân loại tin tức điện tử.................................................................89 \n\n6.5.1. Thước đo kết quả phân loại văn bản........................................................89 \n\n6.5.2. Các phương pháp thử nghiệm..................................................................91 \n\n6.5.3. Kết quả .....................................................................................................91 \n\n6.5.4. Nhận xét ...................................................................................................96 \n\n\n\n \n  \n\n \n\n viii \n\nChương 7. ỨNG DỤNG PHÂN LOẠI TIN TỨC ĐIỆN TỬ TỰ ĐỘNG ................99 \n\n7.1. Giới thiệu tòa soạn báo điện tử ..........................................................................99 \n\n7.2. Tính cần thiết của phân loại tin tức tự động ......................................................99 \n\n7.3. Phân tích hiện trạng .........................................................................................100 \n\n7.3.1. Mô hình DFD quan niệm cấp 2 hiện hành cho ô xử lý Nhận bài và Trả bài\n\n 100 \n\n7.3.2. Phê phán hiện trạng................................................................................103 \n\n7.3.3. Mô hình DFD quan niệm cấp 2 mới cho ô xử lý Nhận bài và Trả bài ..104 \n\n7.4. Triển khai DLL ................................................................................................105 \n\n7.5. Chương trình cài đặt \u201cTòa soạn báo điện tử\u201d đã tích hợp module phân loại tin \n\ntức 106 \n\n7.6. Kết quả .............................................................................................................110 \n\nChương 8. TỔNG KẾT............................................................................................112 \n\n8.1. Kết quả đạt được ..............................................................................................112 \n\n8.1.1. Về mặt lý thuyết.....................................................................................112 \n\n8.1.2. Về mặt thực nghiệm...............................................................................113 \n\n8.2. Hạn chế và hướng phát triển............................................................................113 \n\n8.3. Kết luận............................................................................................................114 \n\n \n\n\n\n \n  \n\n \n\n ix \n\nDANH SÁCH HÌNH \nHình 2. 1. Biểu diễn văn bản .................................................................................................9 \n\nHình 2. 2. Siêu mặt phẳng h phân chia dữ liệu huấn huyện thành 2 lớp + và \u2013 với khoảng \n\ncách biên lớn nhất. Các điểm gần h nhất là các vector hỗ trợ ,Support Vector (được \n\nkhoanh tròn).............................................................................................................11 \n\nHình 2. 3. Hình Kiến trúc mô đun (Modular Architecture) . Các kết quả của từng mạng con \n\nsẽ là giá trị đầu vào cho mạng siêu chủ đề và được nhân lại với nhau để dự đoán \n\nchủ đề cuối cùng . ....................................................................................................16 \n\nHình 3.4. Các hướng tiếp cận cơ bản trong tách từ tiếng Hoa và các hướng tiếp cận hiện tại \n\nđược công bố trong tách từ tiếng Việt .....................................................................24 \n\nHình 3.5. Sơ đồ hệ thống WFST..........................................................................................31 \n\nHình 3.6. Toàn cảnh hệ thống IGATEC ..............................................................................35 \n\nHình 4. 1. Nội dung thông tin cần lấy..................................................................................50 \n\nHình 4. 2. Biểu diễn cá thể bằng các bit 0,1 ........................................................................55 \n\nHình 4. 3. Thang tỉ lệ phát sinh loại từ ................................................................................57 \n\nHình 4. 4.Quá trình lai ghép ................................................................................................58 \n\nHình 4. 5. Quá trình đột biến ...............................................................................................59 \n\nHình 4. 6. Quá trình sinh sản ...............................................................................................59 \n\nHình 4. 7. Quá trình chọn cá thể ..........................................................................................60 \n\nHình 5. 1. Minh họa quy ước cho văn bản...........................................................................70 \n\nHình 5. 2.Minh họa chủ đề \u201cXã hội\u201d ...................................................................................70 \n\nHình 6. 1. Tổ chức file dữ liệu.............................................................................................77 \n\nHình 6. 2. Chủ đề Thể thao..................................................................................................77 \n\nHình 6. 3. Màn hình tách từ .................................................................................................79 \n\nHình 6. 4.  Màn hình trích xuất từ Google...........................................................................80 \n\nHình 6. 5. Màn hình phân loại tin tức điện tử......................................................................81 \n\nHình 6. 6. Cây chủ đề ..........................................................................................................86 \n\nHình 6. 7. Biểu đồ so sánh kết quả các công thức tính độ tương hỗ MI..............................88 \n\nHình 6. 8. Các thông số dùng tính độ thu về, độ chính xác .................................................89 \n\nHình 6. 9. Biểu đồ F1 cho cấp 1 ..........................................................................................94 \n\nHình 6. 10. Biểu đồ F1 cho cấp 2 ........................................................................................96 \n\n\n\n \n  \n\n \n\n x \n\nHình 7. 1.Mô hình DFD hiện hành ....................................................................................100 \n\nHình 7. 2. Mô hình DFD cải tiến .......................................................................................104 \n\nHình 7. 3. Màn hình lấy tin tức cho phép phân loại tự động .............................................106 \n\nHình 7. 4. Màn hình bắt đầu. Click Next để bắt đầu cài đặt ..............................................107 \n\nHình 7. 5.Màn hình chọn chế độ cài đặt hoặc tháo gỡ chương trình. ................................107 \n\nHình 7. 6.Màn hình chọn đường dẫn để cài đặt chương trình. ..........................................108 \n\nHình 7. 7.Màn hình cài đặt chương trình...........................................................................108 \n\nHình 7. 8.Màn hình chọn chức năng gỡ chương trình. ......................................................109 \n\nHình 7. 9.Màn hình gỡ chương trình thành công...............................................................109 \n\n \n \n \n \n\n\n\n \n  \n\n \n\n xi \n\nDANH SÁCH BẢNG \nBảng 3. 1. So sánh giữa tiếng Việt và tiếng Anh.................................................................23 \n\nBảng 4. 1. Thống kê độ dài từ trong từ điển ........................................................................54 \n\nBảng 4. 2. Tham số thực hiện GA .......................................................................................56 \n\nBảng 6. 1. Mô tả một số control của màn hình tách từ ........................................................79 \n\nBảng 6.2. Mô tả một số control của màn hình trích từ Google ...........................................80 \n\nBảng 6.3. Bảng mô tả một số control của màn hình phân loại tin tức điện tử.....................81 \n\nBảng 6. 4. Tham số sử dụng dịch vụ Google.......................................................................82 \n\nBảng 6. 5. Một số câu truy vấn đặc biệt của Google ...........................................................83 \n\nBảng 6. 6. Kết quả thực nghiệm các công thức tính độ tương hỗ MI..................................87 \n\nBảng 6. 7. Bốn trường hợp của phân loại văn bản...............................................................90 \n\nBảng 6. 8. Kết quả phân loại văn bản cho từng chủ đề........................................................94 \n\nBảng 7. 1. Bảng kho dữ liệu những bài viết chưa được đăng............................................102 \n\nBảng 7. 2. Bảng mô tả các ô xử lý của mô hình DFD hiện hành.......................................103 \n\nBảng 7. 3. Bảng mô tả ô xử lý phân loại tin tức tự động...................................................105 \n\n \n \n \n\n\n\n \n \n\n1 \n\n \n\nCChhưươơnngg  11  \n\nTTỔỔNNGG  QQUUAANN  \n \n \n\nĐặt vấn đề \n\nCác phương pháp phân loại văn bản \n\nTách từ tiếng Việt \u2013 Một thách thức thú vị \n\nMục tiêu của luận văn \n\nPhần tìm hiểu các thuật toán phân loại văn bản \n\nPhần tách từ tiếng Việt  \n\nPhần mềm phân loại tin tức báo điện tử bán tự động \n\n\n\n \n  \n\n \n\n 2 \n\nChương 1. TỔNG QUAN \n\n1.1. Đặt vấn đề \nTrong thời đại bùng nổ công nghệ thông tin hiện nay, phương thức sử dụng giấy \n\ntờ trong giao dịch đã dần được số hoá chuyển sang các dạng văn bản lưu trữ trên \n\nmáy tính hoặc truyền tải trên mạng. Bởi nhiều tính năng ưu việt của tài liệu số như \n\ncách lưu trữ gọn nhẹ, thời gian lưu trữ lâu dài, tiện dụng trong trao đổi đặc biệt là \n\nqua Internet, dễ dàng sửa đổi\u2026 nên ngày nay, số lượng văn bản số tăng lên một \n\ncách chóng mặt đặc biệt là trên world-wide-web. Cùng với sự gia tăng về số lượng \n\nvăn bản, nhu cầu tìm kiếm văn bản cũng tăng theo. Với số lượng văn bản đồ sộ thì \n\nviệc phân loại văn bản tự động là một nhu cầu bức thiết. \n\nTại sao phải phân loại văn bản tự động? Việc phân loại văn bản sẽ giúp chúng ta \n\ntìm kiếm thông tin dễ dàng và nhanh chóng hơn rất nhiều so với việc phải bới tung \n\nmọi thứ trong ổ đĩa lưu trữ để tìm kiếm thông tin. Mặt khác, lượng thông tin ngày \n\nmột tăng lên đáng kể, việc phân loại văn bản tự động sẽ giúp con người tiết kiệm \n\nđược rất nhiều thời gian và công sức.  \n\nDo vậy, các phương pháp phân loại văn bản tự động đã ra đời để phục vụ cho \n\nnhu cầu chính đáng đó. \n\n1.2. Các  phương pháp phân loại văn bản \nTheo Yang & Xiu (1999),  \u201cviệc phân loại văn bản tự động là việc gán các nhãn \n\nphân loại lên một văn bản mới dựa trên mức độ tương tự của văn bản đó so với các \n\nvăn bản đã được gán nhãn trong tập huấn luyện\u201d.  \n\nTừ trước đến nay, phân loại văn bản tự động trong tiếng Anh đã có rất nhiều \n\ncông trình nghiên cứu và đạt được kết quả đáng khích lệ. Dựa trên các thống kê của \n\nYang & Xiu (1999) và nghiên cứu của chúng em, một số phương pháp phân loại \n\nthông dụng hiện nay là: Support Vector Machine [Joachims, 1998], k-Nearest \n\nNeighbor [Yang, 1994], Linear Least Squares Fit [Yang and Chute, 1994] Neural \n\nNetwork [Wiener et al, 1995], Naïve Bayes [Baker and Mccallum, 2000], Centroid-\n\nbased [Shankar and Karypis, 1998]. Các phương pháp trên đều dựa vào xác suất \n\n\n\n \n  \n\n \n\n 3 \n\nthống kê hoặc thông tin về trọng số của từ trong văn bản. Chi tiết về ý tưởng và \n\ncông thức tính toán của mỗi phương pháp sẽ được chúng em trình bày ở chương 3, \n\nmục 3.3. \n\nMỗi phương pháp phân loại văn bản đều có cách tính toán khác nhau, tuy nhiên, \n\nnhìn một cách tổng quan thì các phương pháp đó đều phải thực hiện một số bước \n\nchung như sau: đầu tiên, mỗi phương pháp sẽ dựa trên các thông tin về sự xuất hiện \n\ncủa từ trong văn bản (ví dụ tần số, số văn bản chứa từ\u2026) để biểu diễn văn bản thành \n\ndạng vector; sau đó, tuỳ từng phương pháp mà ta sẽ áp dụng công thức và phương \n\nthức tính toán khác nhau để thực hiện việc phân loại.  \n\nĐối với tiếng Anh, các kết quả trong lĩnh vực này rất khả quan, còn đối với tiếng \n\nViệt, các công trình nghiên cứu về phân loại văn bản gần đây đã có một số kết quả \n\nban đầu nhưng vẫn còn nhiều hạn chế. Nguyên nhân là ngay ở bước đầu tiên, chúng \n\nta đã gặp khó khăn trong việc xử lý văn bản để rút ra tần số xuất hiện của từ. Trong \n\nkhi đó, để phân loại văn bản thì có thể nói bước đầu tiên là quan trọng nhất bởi vì \n\nnếu ở bước tách từ đã sai thì việc phân loại hầu như không thể thành công được. \n\nPhần trình bày tiếp theo sẽ cho chúng ta biết những thách thức đặt ra trong việc tách \n\ntừ tiếng Việt, cũng như những ứng dụng thú vị của nó. \n\n1.3. Tách từ Tiếng Việt \u2013 Một thách thức thú vị \nĐối với tiếng Anh, \u201ctừ là một nhóm các ký tự có nghĩa được tách biệt với nhau \n\nbởi khoảng trắng trong câu\u201d (Webster Dictionary), do vậy việc tách từ trở nên rất \n\nđơn giản. Trong khi đối với tiếng Việt, ranh giới từ không được xác định mặc định \n\nlà khoảng trắng mà tùy thuộc vào ngữ cảnh dùng câu tiếng Việt. Ví dụ các từ trong \n\ntiếng Anh là \u201cbook\u201d , \u201ccat\u201d, \u201cstadium\u201d  thì trong tiếng Việt là \u201cquyển sách\u201d, \u201ccon \n\nmèo\u201d, \u201csân vận động\u201d \u2026 Vấn đề trên thực sự đưa ra một thách thức đối với chúng \n\nta - những người làm tin học. \n\nTuy nhiên, thách thức nào cũng có cái thú vị của nó. Nếu chúng ta giải quyết \n\nđược việc tách từ một cách thoả đáng, thì thành quả mà chúng ta đạt được là một \n\nnền tảng để phát triển cho các hướng nghiên cứu khác có liên quan đến việc xử lý \n\nngôn ngữ tự nhiên như: phân loại văn bản, dịch tự động, kiểm tra lỗi chính tả, kiểm \n\n\n\n \n  \n\n \n\n 4 \n\ntra ngữ pháp\u2026 Đó là các ứng dụng rất thiết thực với đời sống con người và là mục \n\ntiêu của con người đang chinh phục. \n\nMột số nước châu Á như Trung Quốc, Nhật Bản, Hàn Quốc, Việt Nam sử dụng \n\nloại hình ngôn ngữ gần như tương tự nhau về mặt hình thái và cú pháp. Do đó ta có \n\nthể áp dụng, cải tiến một số phương pháp tách từ của các nước bạn đặc biệt là Trung \n\nQuốc vào việc tách từ tiếng Việt.  \n\nTheo Đinh Điền (2004), các phương pháp tách từ sau có nguồn gốc từ tiếng Hoa \n\nđã được thử nghiệm trên tiếng Việt : Maximum Matching: forward/backward hay \n\ncòn gọi LRMM (Left Right Maximum Matching); giải thuật học cải biến TBL; \n\nmạng chuyển dịch trạng thái hữu hạn có trọng số WFST (Weighted finite-state \n\nTransducer); giải thuật dựa trên nén (compression);\u2026.Theo các cách tiếp cận trên, \n\nđiều kiện quan trọng cần có là một hệ thống từ điển (LRMM) và ngữ liệu đánh dấu \n\n(TBL, WFST) đầy đủ, chuẩn xác. Một từ điển hay một tập ngữ liệu không hoàn \n\nchỉnh sẽ làm giảm hiệu suất của thuật toán.  \n\nTuy nhiên, khó có thể tạo ra được một từ điển hoàn chỉnh nhất là trong thời đại \n\nngày nay, ngôn ngữ còn tiếp tục phát triển và thay đổi từng ngày. Xét về mặt phổ \n\nbiến, tiếng Anh là ngôn ngữ được dùng rộng rãi trong giao dịch trên thế giới. Do đó \n\nđể tạo ra một tập ngữ liệu tiếng Anh thỏa các tiêu chí chọn mẫu ngữ liệu là không \n\nquá phức tạp. Trong khi đó, Việt Nam chỉ mới cho phép truy cập Internet trong \n\nvòng chục năm trở lại đây, do đó số lượng trang web tiếng Việt là không nhiều. Cho \n\nđến nay, vẫn chưa có một tập ngữ liệu huấn luyện chuẩn nào dành cho việc tách từ \n\nvà phân loại trang web tiếng Việt được công bố. \n\nGần đây, một phương pháp tách từ mới được giới thiệu có ưu điểm là không cần \n\ndùng tập ngữ liệu hay từ điển để lấy thông tin thống kê hay trọng số của từ, đó là \n\nphương pháp Internet and Genetics Algorithm-based Text Categorization \n\n(IGATEC) của H. Nguyen et al (2005). Điểm sáng tạo của thuật toán là kết hợp \n\nthuật toán di truyền với việc trích xuất thông tin thống kê từ Internet thông qua một \n\ncông cụ tìm kiếm (như Google chẳng hạn) thay vì lấy từ tập ngữ liệu như các \n\nphương pháp trước. \n\n\n\n \n  \n\n \n\n 5 \n\nChúng em thực hiện bước tách từ trong luận văn này dựa trên ý tưởng của thuật \n\ntoán IGATEC nhưng có bổ sung nhiều cải tiến đáng kể để tăng độ chính xác đồng \n\nthời thực hiện các thí nghiệm chi tiết nhằm so sánh các cách áp dụng thuật toán để \n\ntìm ra cách tối ưu nhất. \n\n1.4. Mục tiêu của luận văn \n\n1.4.1. Phần tìm hiểu các thuật toán phân loại văn bản \nTrong khuôn khổ luận văn này, chúng em tìm hiểu ở mức cơ bản một số phương \n\npháp phân loại văn bản hiện có đang áp dụng cho tiếng Anh và đưa ra một số so \n\nsánh nhất định giữa các phương pháp: Support Vector Machine (Joachims, 1998), k-\n\nNearest Neighbor (Yang, 1994), Linear Least Squares Fit (Yang and Chute, 1994) \n\nNeural Network (Wiener et al, 1995), Naïve Bayes (Baker and Mccallum, 2000), \n\nCentroid-based (Shankar and Karypis, 1998).  \n\nSau đó, chúng em sẽ chọn và áp dụng một phương pháp cho bài toán phân loại \n\ntin tức báo điện tử tiếng Việt chấp nhận được, phù hợp với mức độ và thời gian cho \n\nphép của một luận văn đại học. \n\n1.4.2. Phần tách từ tiếng Việt \nHiện nay các phương pháp tách từ tiếng Việt được công bố vẫn chưa nhiều và \n\nhướng tiếp cận chủ yếu dựa vào tập huấn luyện và từ điển. Như chúng ta đã biết, \n\nviệc tạo ra hệ thống dữ liệu đó không phải là một sớm một chiều, mà yêu cầu đầu tư \n\nkhá nhiều công sức, thời gian và tiền bạc.  \n\nTrong luận văn này, chúng em cố gắng tìm hiểu, cải tiến, cài đặt, thử nghiệm \n\nmột phương pháp tách từ tiếng Việt theo hướng tiếp cận IGATEC, có độ chính xác \n\nchấp nhận được, và điều quan trọng là không cần dùng tập ngữ liệu (corpus) để \n\nphân định ranh giới từ. \n\nSau đó, chúng em sẽ cài đặt, thử nghiệm độ chính xác của phương pháp tách từ \n\nnày trong khía cạnh phân loại văn bản \n\n1.4.3. Phần mềm phân loại tin tức báo điện tử bán tự động \n\n\n\n \n  \n\n \n\n 6 \n\nĐể thử nghiệm hướng nghiên cứu tách từ tiếng Việt và phân loại văn bản của \n\nluận văn, chúng em tích hợp phần mềm phân loại tin tức vào trang web báo điện tử \n\ncó sẵn được xây dựng trên nền DotNetNuke Portal của luận văn khoá 2000 ( Hoàng \n\nMinh Ngọc Hải (0012545), Nguyễn Duy Hiệp (0012038) ) \n\nNhư chúng ta đều biết, điều kiện mạng cung cấp cho các trường đại học ở nước \n\nta hiện nay là khá hạn chế, khó đáp ứng được hoàn toàn việc cho phép các sinh viên \n\nlên mạng Internet để xem các tin tức mới hằng ngày. Để giải quyết phần nào vấn đề \n\ntrên, chúng ta có thể chọn lọc một số tin tức từ các nguồn khác, đăng tải trên trang \n\nweb nội bộ của trường. Trên cơ sở đó, chúng em tích hợp phần mềm phân loại tin \n\ntức báo điện tử tự động vào toà soạn báo điện tử cho phép lấy tin tự động từ các \n\ntrang web khác. Nhờ vậy, công việc lấy tin và phân loại tin tức giờ đây đã trở nên \n\nrất dễ dàng và nhanh chóng, tiết kiệm nhiều công sức và thời gian cho nhà quản trị. \n\nKhông chỉ ứng dụng cho các trường đại học, phần mềm phân loại tin tức của \n\nchúng em còn có thể ứng dụng, hỗ trợ cho nhiều công việc khác như : lưu trữ \n\n(clipping) báo chí, xây dựng bộ ngữ liệu cho các bài toán cần dữ liệu được phân \n\nloại, tiền đề cho các bài toán khác như phân loại website. \n\n1.4.4. Đóng góp của luận văn \nLuận văn đã thực hiện việc được nhiều cải tiến của hướng tiếp cận tách từ tiếng \n\nViệt dùng trong phân loại văn bản theo phương pháp dựa trên thống kê Internet.  \n\nĐối với tách từ tiếng Việt, chúng em đề nghị thêm một công thức tính toán độ \n\ntương hỗ mới, từ đó thực hiện thử nghiệm tính hiệu quả của cách tính này so với \n\ncách công thức ở những công trình khác.  \n\nTrong quá trình xây dựng thuật toán di truyền dùng trong tách từ, chúng em đã \n\ncải tiến hình thức đột biến mới phù hợp với hình thức cấu tạo từ trong câu. \n\nĐối với việc phân loại văn bản, chúng em cải tiến công thức tính trong hướng \n\ntiếp cận Naïve Bayes phù hợp với phương pháp tính dựa trên thống kê từ Google. \n\n  \n\n  \n\n\n\n \n  \n\n \n\n 7 \n\nCChhưươơnngg  22  \n\nCCÁÁCC  PPHHƯƯƠƠNNGG  PPHHÁÁPP  \n\nPPHHÂÂNN  LLOOẠẠII  VVĂĂNN  BBẢẢNN  \n\nTTIIẾẾNNGG  AANNHH    \n \n\n \n\nBối cảnh các phương pháp phân loại văn bản hiện nay \n\nCác phương pháp phân loại văn bản tiếng Anh hiện hành \n\nBiểu diễn văn bản \n\nSupport vector Machine (SVM) \n\nK\u2013Nearest Neighbor (kNN) \n\nNaïve Bayes (NB) \n\nNeural Network (NNet) \n\nLinear Least Square Fit (LLSF) \n\nCentroid- based vector \n\nKết luận  \n\n\n\n \n  \n\n \n\n 8 \n\nChương 2. CÁC PHƯƠNG PHÁP PHÂN LOẠI VĂN BẢN \nTIẾNG ANH \n\n2.1. Bối cảnh các phương pháp phân loại văn bản hiện nay \n Phân loại văn bản tự động là một lĩnh vực được chú ý nhất trong những năm \n\ngần đây. Để phân loại người ta sử dụng nhiều cách tiếp cận khác nhau như dựa trên \n\ntừ khóa,  dựa trên ngữ nghĩa các từ có tần số xuất hiện cao, mô hình Maximum \n\nEntropy, tập thô \u2026 Tiếng Anh là một trong những ngôn ngữ được nghiên cứu sớm \n\nvà rộng rãi nhất với kết quả đạt được rất khả quan. Một số lượng lớn các phương \n\npháp phân loại đã được áp dụng thành công trên ngôn ngữ này : mô hình hồi quy \n\n[Fuhr et al,1991], phân loại dựa trên láng giềng gần nhất (k-nearest neighbors) \n\n[Dasarathy, 1991], phương pháp dựa trên xác suất Naïve Bayes [Joachims, 1997], \n\ncây quyết định [Fuhr et al,1991], học luật quy nạp [William & Yoram, 1996], mạng \n\nnơron (neural network)[Wiener et al, 1995], học trực tuyến[William & Yoram, \n\n1996], và máy vector hỗ trợ (SVM-support vector machine) [Vapnik, 1995].  Hiệu \n\nquả của các phương pháp này rất khác nhau ngay cả khi áp dụng cho tiếng Anh. \n\nViệc đánh giá gặp nhiều khó khăn do việc thiếu các tập ngữ liệu huấn luyện chuẩn. \n\nThậm chí đối với tập dữ liệu được sử dụng rộng rãi nhất, Reuter cũng có nhiều \n\nphiên bản khác nhau. Hơn nữa, có rất nhiều độ đo được sử dụng như recall, \n\nprecision, accuracy hoặc error, break-even point, F-measure \u2026Chương này giới \n\nthiệu các thuật toán phân loại được sử dụng phổ biến nhất đồng thời so sánh giữa \n\ncác phương pháp sử dụng kết quả của [Yang, 1997]. \n\n2.2. Các phương pháp phân loại văn bản tiếng Anh hiện hành \n\n2.2.1. Biểu diễn văn bản \nBước đầu tiên của mọi phương pháp phân loại là chuyển việc mô tả văn bản \n\ndùng chuỗi ký tự thành một dạng mô tả khác, phù hợp với các thuật toán học theo \n\nmẫu và phân lớp. Hầu hết các thuật toán đều sử dụng cách biểu diễn văn bản sử \n\ndụng vector đặc trưng, sự khác nhau có chăng là việc chọn không gian đặc trưng \n\nkhác nhau. Vì vậy ở phần này chúng em sẽ trình bày sơ lược về vector đặc trưng. \n\n\n\n \n  \n\n \n\n 9 \n\nÝ tưởng chính là xem mỗi văn bản id  tương ứng là một vector đặc trưng \n\n( )1 2( ), ( ),..., ( )i nd TF w TF w TF w  trong không gian các từ nW ( iw là một từ, một đặc \n\ntrưng, tương ứng một chiều của không gian). Gía trị của ( )iTF w chính là số lần xuất \n\nhiện của từ iw  trong văn bản id  . Từ được chọn là một đặc trưng khi nó xuất hiện \n\ntrong ít nhất 3 văn bản [Joachims, 1997]. Để không bị phụ thuộc vào chiều dài văn \n\nbản vector đặc trưng sẽ được chuẩn hóa về chiều dài đơn vị : \n\n1 2\n2 2 2\n\n( )( ) ( )( , ,..., )\n( ) ( ) ( )\n\nn\n\ni i i\n\nTF wTF w TF wdi\nTF w TF w TF w∑ ∑ ∑\n\n \n\n \n\nHình 2. 1. Biểu diễn văn bản \n\nTrong thực tế để cải thiện tốc độ và kết quả người ta thường sử dụng )( iwIDF  \n\nhoặc i(w )TFIDF thay cho ( )iTF w :  \n\n( ) log( )\n( )i i\n\nmIDF w\nDF w\n\n=  \n\n( ) ( ). ( )i i iTFIDF w TF w IDF w=  \n\nVới  \n\n m chính là số văn bản huấn luyện \n\n\n\n \n  \n\n \n\n 10 \n\n DF(wi) là số văn bản có chứa từ iw . \n\nMột vấn đề nảy sinh khi biểu diễn văn bản theo hướng vector đặc trưng chính là \n\nviệc chọn đặc trưng và số chiều cho không gian. Cần phải chọn bao nhiêu từ và \n\nchọn những từ nào ? theo những cách nào ? Có nhiều hướng tiếp cận trong vấn đề \n\nnày mà tiêu biểu là sử dụng Information Gain [Yang & Petersen, 1997] ngoài ra còn \n\ncó các phương pháp như DF-Thresolding [Yang & Petersen, 1997], Test−2χ  \n\n[Schütze et al,1995] hoặc Term Strength [Yang & Wilbur,1997]. Phương pháp \n\nInformation Gain sử dụng độ đo Mutual Information(MI) [Yang & Petersen, 1997] \n\nđể chọn ra tập đặc trưng con f  gồm những từ có giá trị MI cao nhất. \n\nCác đặc trưng của văn bản khi biểu diễn dưới dạng vector : \n\n Số chiều không gian đặc trưng thường rất lớn (trên 10000) \n\n Có các đặc trưng độc lập nhau, sự kết hợp các đặc trưng này thường không \n\ncó ý nghĩa trong phân loại \n\n Đặc trưng rời rạc : vector id có rất nhiều giá trị 0 do có nhiều đặc trưng \n\nkhông xuất hiện trong văn bản id . \n\n Hầu hết các văn bản có thể được phân chia một cách tuyến tính bằng các \n\nhàm tuyến tính. \n\nViệc phân loại sẽ tốt hơn nếu các thuật toán tận dụng được những đặc trưng này. \n\nPhần tiếp theo sẽ nói rõ hơn về các thuật toán phân loại. \n\n2.2.2. Support vector Machine(SVM) \nSVM là phương pháp tiếp cận phân loại rất hiệu quả  được Vapnik giới thiệu \n\nnăm 1995 [Vapnik, 1995] để giải quyết vấn đề nhận dạng mẫu 2 lớp sử dụng \n\nnguyên lý Cực tiểu hóa Rủi ro có Cấu trúc (Structural Risk Minimization) [Vapnik, \n\nCortes, 1995].  \n\n\n\n \n  \n\n \n\n 11 \n\n2.2.2.1. Ý tưởng \nCho trước một tập huấn luyện được biểu diễn trong không gian vector trong đó \n\nmỗi tài liệu là một điểm, phương pháp này tìm ra một siêu mặt phẳng h quyết định \n\ntốt nhất có thể chia các điểm trên không gian này thành hai lớp riêng biệt tương ứng \n\nlớp + và lớp \u2013. Chất lượng của siêu mặt phẳng này được quyết định bởi khoảng \n\ncách (gọi là biên) của điểm dữ liệu gần nhất của mỗi lớp đến mặt phẳng này. \n\nKhoảng cách biên càng lớn thì mặt phẳng quyết định càng tốt đồng thời việc phân \n\nloại càng chính xác. Mục đích thuật toán SVM tìm được khoảng cách biên lớn nhất. \n\nHình sau minh họa cho thuật toán này : \n\n \n\nHình 2. 2. Siêu mặt phẳng h phân chia dữ liệu huấn huyện thành 2 lớp + và \u2013 \n\nvới khoảng cách biên lớn nhất. Các điểm gần h nhất là các vector hỗ trợ \n\n,Support Vector (được khoanh tròn) \n\n2.2.2.2. Công thức chính \nSVM thực chất là một bài toán tối ưu, mục tiêu của thuật toán này là tìm được \n\nmột không gian H và siêu mặt phẳng quyết định h trên H sao cho sai số phân loại là \n\nthấp nhất \n\nPhương trình siêu mặt phẳng chứa vector id  trong không gian như sau : \n\n0=+⋅ bwdi  \n\nĐặt \n⎪⎩\n\n⎪\n⎨\n⎧\n\n<+⋅−\n\n>+⋅+\n=+⋅=\n\n0,1\n\n0,1\n)()(\n\nbwd\n\nbwd\nbwdsigndh\n\ni\n\ni\nii  \n\n\n\n \n  \n\n \n\n 12 \n\nNhư thế )( idh biểu diễn sự phân lớp của id  vào hai lớp như đã nói. Gọi { }1±=iy , \n\niy  = + 1, văn bản id  ∈ lớp +; iy  = - 1, văn bản id  ∈ lớp -  Khi này để có siêu mặt \n\nphẳng h ta sẽ phải giải bài toán sau : \n\n \n\nTìm Min w  với w  và b  thõa điều kiên sau : \n\n( ) 1)(:,1 ≥+⋅∈∀ bwdsignyni ii  \nBài toán SVM có thể giải bằng kỹ thuật sử dụng toán tử Lagrange để biến đổi \n\nthành dạng đẳng thức. \n\nĐiểm thú vị ở SVM là mặt phẳng quyết định chỉ phụ thuộc vào các vector hỗ trợ \n\n(Support Vector) có khoảng cách đến mặt phẳng quyết định là \nw\n1 . Khi các điểm \n\nkhác bị xóa đi thì thuật toán vẫn cho kết quả giống như ban đầu. Chính đặc điểm \n\nnày làm cho SVM khác với các thuật toán khác như kNN,LLSF, NNet và NB vì tất \n\ncả dữ liệu trong tập huấn luyện đều được dùng để tối ưu hóa kết quả. Các phiên bản \n\nSVM tốt có thể kể đến là SVMLight [Joachims, 1998] và Sequential Minimal \n\nOptimization (SMO) [Platt, 1998] \n\n2.2.3.  K\u2013Nearest Neighbor (kNN) \nkNN là phương pháp truyền thống khá nổi tiếng về hướng tiếp cận dựa trên \n\nthống kê đã được nghiên cứu trong nhận dạng mẫu hơn bốn thập kỷ qua [Dasarathy, \n\n1991]. kNN được đánh giá là một trong những phương pháp tốt nhất (áp dụng trên \n\ntập dữ liệu Reuters phiên bản 21450), được sử dụng từ những thời kỳ đầu của việc \n\nphân loại văn bản [Marsand et al, 1992] [Yang, 1994] [Iwayama, Tokunaga, 1995]. \n\n2.2.3.1. Ý tưởng \nKhi cần phân loại một văn bản mới, thuật toán sẽ tính khoảng cách (khoảng cách \n\nEuclide, Cosine ...) của tất cả các văn bản trong tập huấn luyện đến văn bản này để \n\ntìm ra k văn bản gần nhất (gọi là k \u201cláng giềng\u201d), sau đó dùng các khoảng cách này \n\nđánh trọng số cho tất cả chủ đề. Trọng số của một chủ đề chính là tổng tất cả \n\nkhoảng cách ở trên của các văn bản trong k láng giềng có cùng chủ đề, chủ đề nào \n\n\n\n \n  \n\n \n\n 13 \n\nkhông xuất hiện trong k láng giềng sẽ có trọng số bằng 0. Sau đó các chủ đề sẽ được \n\nsắp xếp theo mức độ trọng số giảm dần và các chủ đề có trọng số cao sẽ được chọn \n\nlà chủ đề của văn bản cần phân loại.  \n\n2.2.3.2. Công thức chính \nTrọng số của chủ đề jc  đối với văn bản x  : \n\n{ }\n\nW( , ) ( , ). ( , )\ni\n\nj i i j j\nd kNN\n\nx c sim x d y d c b\n∈\n\n= −∑  \n\nTrong đó  \n\n ( ),i jy d c  ∈ {0,1}, với  \n y = 0 : văn bản id  không thuộc về chủ đề cj \n\n y = 1 : văn bản id  thuộc về chủ đề cj \n\n ( ), isim x d  : độ giống nhau giữa văn bản cần phân loại x  và văn bản id . Có \nthể sử dụng độ đo cosine để tính ( ), isim x d  \n\n( ) ii x.d, os(x,d )=\n.\n\nisim x d c\nx di\n\n=  \n\n jb  là ngưỡng phân loại của chủ đề cj được tự động học sử dụng một tập văn \n\nbản hợp lệ được chọn ra từ tập huấn luyện \n\nĐể chọn được tham số k tốt nhất cho việc phân loại, thuật toán phải được chạy \n\nthử nghiệm trên nhiều giá trị k khác nhau, giá trị k càng lớn thì thuật toán càng ổn \n\nđịnh và sai sót càng thấp [Yang, 1997]. Giá trị tốt nhất được sử dụng tương ứng trên \n\nhai bộ dữ liệu Reuter và Oshumed là k = 45 [Joachims, 1997].  \n\n2.2.4. Naïve Bayes (NB) \nNB là phương pháp phân loại dựa vào xác suất được sử dụng rộng rãi trong lĩnh \n\nvực máy học [Mitchell, 1996] [Joachims, 1997] [Jason, 2001] được sử dụng lần đầu \n\ntiên trong lĩnh vực phân loại bởi Maron vào năm 1961 [Maron, 1961] sau đó trở nên \n\nphổ biến dùng trong nhiều lĩnh vực như trong các công cụ tìm kiếm [Rijsbergen et \n\nal, 1970], các bộ lọc mail [Sahami et al, 1998]...  \n\n\n\n \n  \n\n \n\n 14 \n\n2.2.4.1. Ý tưởng \nÝ tưởng cơ bản của cách tiếp cận Naïve Bayes là sử dụng xác suất có điều kiện \n\ngiữa từ và chủ đề để dự đoán xác suất chủ đề của một văn bản cần phân loại. Điểm \n\nquan trọng của phương pháp này chính là ở chỗ giả định rằng sự xuất hiện của tất cả \n\ncác từ trong văn bản đều độc lập với nhau. Như thế NB không tận dụng được sự phụ \n\nthuộc của nhiều từ vào một chủ đề cụ thể \n\nGiả định đó làm cho việc tính toán NB hiệu quả và nhanh chóng hơn các \n\nphương pháp khác với độ phức tạp theo số mũ vì nó không sử dụng việc kếp hợp \n\ncác từ để đưa ra phán đoán chủ đề. \n\n2.2.4.2. Công thức chính \nMục đích chính là tính được xác suất Pr( , )Cj d \u2032 , xác suất để văn bản d \u2032  nằm \n\ntrong lớp Cj . Theo luật Bayes, văn bản d \u2032  sẽ được gán vào lớp Cj  nào có xác suất \n\nPr( , )Cj d \u2032 cao nhất. Công thức sau dùng để tính Pr( , )Cj d \u2032  [Joachims, 1997] \n\n1\n\n1\n\n( , )\n\n( , )\n\nPr( ). Pr( | )\n( ) arg max\n\nPr( ). Pr( | )\n\nPr( ). Pr( | )\narg max\n\nPr( ). Pr( | )\n\nd\n\nj i j\ni\n\nBAYES d\nCj C\n\ni\nC C i\n\nTF w d\nj\n\nw F\nTF w d\n\nCj C\nC C w F\n\nC w C\nH d\n\nC w C\n\nCj w C\n\nC w C\n\n\u2032\n\n=\n\u2032\n\n∈\n\n\u2032∈ =\n\n\u2032\n\n∈\n\u2032\n\n∈\n\n\u2032∈ ∈\n\n⎛ ⎞\n⎜ ⎟\n⎜ ⎟\u2032 =\n⎜ ⎟\n\n\u2032 \u2032⎜ ⎟\n⎝ ⎠\n\n⎛ ⎞\n⎜ ⎟= ⎜ ⎟\u2032 \u2032⎜ ⎟\n⎝ ⎠\n\n∏\n\n∑ ∏\n\n∏\n∑ ∏\n\n \n\n \n\nVới  \n\n ( , )iTF w d \u2032 là số lần xuất hiện của từ iw  trong văn bản d \u2032  \n\n d \u2032  là số lượng các từ trong văn bản d \u2032  \n\n iw  là một từ trong không gian đặc trưng F  với số chiều là F  \n\n Pr( )jC được tính dựa trên tỷ lệ phần trăm của số văn bản mỗi lớp tương ứng \n\ntrong tập dữ liệu luyện : Pr( ) j jj\nC C\n\nC C\nC\n\nC C\n\u2032∈\n\n= =\n\u2032∑\n\n \n\n\n\n \n  \n\n \n\n 15 \n\n Pr( | )i jw C  được tính sử dụng phép ước lượng Laplace [Napnik, 1982] : \n\n \n1 ( , )\n\nPr( | )\n( , )\n\ni j\ni j\n\nj\nw F\n\nTF w C\nw C\n\nF TF w C\n\u2032∈\n\n+\n=\n\n\u2032+ ∑\n \n\nNgoài ra còn có các phương pháp NB khác có thể kể ra như sau ML Naive \n\nBayes, MAP Naive Bayes, Expected Naive Bayes, Bayesian Naive Bayes [Jason, \n\n2001]. Naive Bayes là một công cụ rất hiệu quả trong một số trường hợp. Kết quả \n\ncó thể rất tồi nếu dữ liệu huấn luyện nghèo nàn và các tham số dự đoán (như không \n\ngian đặc trưng) có chất lượng kém. Nhìn chung đây là một thuật toán phân loại \n\ntuyến tính thích hợp trong phân loại văn bản nhiều chủ đề. NB có ưu điểm là cài đặt \n\nđơn giản, tốc độ nhanh, dễ dàng cập nhật dữ liệu huấn luyện mới và có tính độc lập \n\ncao với tập huấn luyện, có thể sử dụng kết hợp nhiều tập huấn luyện khác nhau. Tuy \n\nnhiên NB ngoài giả định tính độc lập giữa các từ còn phải cần đến một ngưỡng tối \n\nưu để cho kết quả khả quan. Nhằm mục đích cải thiện hiệu năng của NB, các \n\nphương pháp như multiclass-boosting, ECOC [Berger, 1999] [Ghani, 2000] có thể \n\nđược dùng kết hợp. \n\n2.2.5. Neural Network (NNet) \nNnet được nghiên cứu mạnh trong hướng trí tuệ nhân tạo. Wiener là người đã sử \n\ndụng Nnet để phân loại văn bản, sử dụng 2 hướng tiếp cận : kiến trúc phẳng (không \n\nsử dụng lớp ẩn) và mạng nơron 3 lớp (bao gồm một lớp ẩn)[Wiener et al, 1995] \n\nCả hai hệ thống trên đều sử dụng một mạng nơron riêng rẽ cho từng chủ đề, \n\nNNet học cách ánh xạ phi tuyến tính những yếu tố đầu vào như từ, hay mô hình \n\nvector của một văn bản vào một chủ đề cụ thể. \n\nKhuyết điểm của phương pháp NNet là tiêu tốn nhiều thời gian dành cho việc \n\nhuấn luyện mạng nơron. \n\n2.2.5.1. Ý tưởng \nMô hình mạng neural gồm có ba thành phần chính như sau: kiến trúc \n\n(architecture), hàm chi phí (cost function), và thuật toán tìm kiếm (search \n\n\n\n \n  \n\n \n\n 16 \n\nalgorithm). Kiến trúc định nghĩa dạng chức năng (functional form) liên quan giá trị \n\nnhập (inputs) đến giá trị xuất (outputs).  \n\nKiến trúc phẳng ( flat architecture ) : Mạng phân loại đơn giản nhất ( còn gọi là \n\nmạng logic) có một đơn vị xuất là kích hoạt kết quả (logistic activation) và không \n\ncó lớp ẩn, kết quả trả về ở dạng hàm (functional form) tương đương với mô hình hồi \n\nquy logic. Thuật toán tìm kiếm chia nhỏ mô hình mạng để thích hợp với việc điều \n\nchỉnh mô hình ứng với tập huấn luyện. Ví dụ, chúng ta có thể học trọng số trong \n\nmạng kết quả (logistic network) bằng cách sử dụng không gian trọng số giảm dần \n\n(gradient descent in weight space) hoặc sử dụng thuật toán interated-reweighted \n\nleast squares là thuật toán truyền thống trong hồi quy (logistic regression).  \n\nKiến trúc mô dun (modular architecture ):  Việc sử dụng một hay nhiều lớp ẩn \n\ncủa những hàm kích hoạt phi tuyến tính cho phép mạng thiết lập các mối quan hệ \n\ngiữa những biến nhập và biến xuất. Mỗi lớp ẩn học để biểu diễn lại dữ liệu đầu vào \n\nbằng cách khám phá ra những đặc trưng ở mức cao hơn từ sự kết hợp đặc trưng ở \n\nmức trước.  \n\n \n\nHình 2. 3. Hình Kiến trúc mô đun (Modular Architecture) . Các kết quả của \n\ntừng mạng con sẽ là giá trị đầu vào cho mạng siêu chủ đề và được nhân lại với \n\nnhau để dự đoán chủ đề cuối cùng . \n\n2.2.5.2. Công thức chính \nTrong công trình của Wiener et al (1995) dựa theo khung của mô hình hồi quy, \n\nliên quan từ đặc trưng đầu vào cho đến kết quả gán chủ đề tương ứng được học từ \n\n\n\n \n  \n\n \n\n 17 \n\ntập dữ liệu. Do vậy, để phân tích một cách tuyến tính, tác giả dùng hàm sigmoid sau \n\nlàm hàm truyền trong mạng neural: \n\n1\n1\n\np\ne η−\n\n=\n+\n\n \n\nTrong đó, T xη β=  là sự kết hợp của những đặc trưng đầu vào và p phải thỏa \n\nđiều kiện (0,1)p∈  \n\n2.2.6. Linear Least Square Fit (LLSF) \nLLSF là một cách tiếp cận ánh xạ được phát triển bởi Yang và Chute vào năm \n\n1992 [Yang & Chute, 1992]  Đầu tiên, LLSF được Yang và Chute  thử nghiệm \n\ntrong lĩnh vực xác định từ đồng nghĩa sau đó sử dụng trong phân loại vào năm 1994 \n\n[Yang & Chute, 1994]. Các thử nghiệm của Ỵang cho thấy hiệu suất phân loại của \n\nLLSF có thể ngang bằng với phương pháp kNN kinh điển. \n\n2.2.6.1. Ý tưởng \nLLSF sử dụng phương pháp hồi quy để học từ tập huấn luyện và các chủ đề có \n\nsẵn [Yang & Chute, 1994]. Tập huấn luyện được biểu diễn dưới dạng một cặp \n\nvector đầu vào và đầu ra như sau : \n\nVector đầu vào một văn bản bao gồm các từ và trọng số \n\nVector đầu ra gồm các chủ đề cùng với trọng số nhị phân của văn bản ứng với \n\nvector đầu vào \n\nGiải phương trình các cặp vector đầu vào/ đầu ra, ta sẽ được ma trận đồng hiện \n\ncủa hệ số hồi quy của từ và chủ đề(matrix of word-category regression coefficients) \n\n2.2.6.2. Công thức chính \n2arg minLS\n\nF\nF FA B= −  \n\nTrong đó  \n\n A, B là ma trận đại diện tập dữ liệu huấn luyện ( các cột trong ma trận tương \n\nứng là các vector đầu vào và đầu ra ) \n\n FLS là ma trận kết quả chỉ ra một ánh xạ từ một văn bản bất kỳ vào vector của \n\nchủ đề đã gán trọng số \n\n\n\n \n  \n\n \n\n 18 \n\nNhờ vào việc sắp xếp trọng số của các chủ đề, ta được một danh sách chủ đề có \n\nthể gán cho văn bản cần phân loại. Nhờ đặt ngưỡng lên trọng số của các chủ đề mà \n\nta tìm được chủ đề thích hợp cho văn bản đầu vào. Hệ thống tự động học các \n\nngưỡng tối ưu cho từng chủ đề, giống với kNN. Mặc dù LLSF và kNN khác nhau \n\nvề mặt thống kê, nhưng ta vẫn tìm thấy điểm chung ở hoạt động của hai phương \n\npháp là việc học ngưỡng tối ưu. \n\n2.2.7. Centroid- based vector \nLà một phương pháp phân loại đơn giản, dễ cài đặt và tốc độ nhanh do có độ \n\nphức tạp tuyến tính O(n) [Han, Karypis 2000] \n\n2.2.7.1. Ý tưởng \nMỗi lớp trong dữ liệu luyện sẽ được biểu diễn bởi một vector trọng tâm. Việc \n\nxác định lớp của một văn bản thử bất kì sẽ thông qua viêc tìm vector trọng tâm nào \n\ngần với vector biểu diễn văn bản thử nhất. Lớp của văn bản thử chính là lớp mà \n\nvector trọng tâm đại diện. Khoảng cách được tính theo độ đo cosine. \n\n2.2.7.2. Công thức chính \nCông thức tính vector trọng tâm của lớp i  \n\n{ }\n\n1\n{ }\n\nj\n\ni j\nd i\n\nC d\ni ∈\n\n= ∑  \n\nĐộ đo khoảng cách giữa vector x  và iC  \n\n( )cos ,\n*\n\ni\ni\n\ni\n\nx Cx C\nx C\n⋅\n\n=  \n\nTrong đó : \n\n x  là vector văn bản cần phân loại \n\n { }i là tập hợp các văn bản thuộc chủ đề Ci \n\nChủ đề của x  là Cx thõa cos( , ) arg max(cos( , ))x ix C x C=  \n\n\n\n \n  \n\n \n\n 19 \n\n2.3. Kết luận \nCác thuật toán phân loại trên từ thuật toán phân loại 2 lớp (SVM) đến các thuật \n\ntoán phân loại đa lớp (kNN) đều có điểm chung là yêu cầu văn bản phải được biểu \n\ndiễn dưới dạng vector đặc trưng. Ngoài ra các thuật toán như kNN,NB,LLSF đều \n\nphải sử dụng các ước lượng tham số và ngưỡng tối ưu trong khi đó thuật toán SVM \n\ncó thể tự tìm ra các tham số tối ưu này. Trong các phương pháp SVM là phương \n\npháp sử dụng không gian vector đặc trưng lớn nhất (hơn 10000 chiều) trong khi đó \n\nchỉ là 2000 đối với NB, 2415 cho kNN và LLSF, 1000 cho Nnet [Yang, 1997]. Thời \n\ngian huấn luyện cũng khác nhau đối với từng phương pháp, Nnet (sử dụng mỗi \n\nmạng tương ứng một chủ đề) và SVM là hai phương pháp có thời gian huấn luyện \n\nlâu nhất trong khi đó kNN,NB,LLSF và Centroid là các phương pháp có tốc độ \n\n(thời gian huấn luyện, phân loại) nhanh và cài đặt dễ dàng. \n\nVề hiệu suất, dựa vào thử nghiệm của Yang [Yang, Liu, 1997] trên tập dữ liệu \n\nReuter-21578 với hơn 90 chủ đề và trên 7769 văn bản, ta có thể sắp xếp các phương \n\npháp phân loại văn bản theo thứ tự như sau SVM > kNN >> {LLSF,NB,Nnet}. Tuy \n\nnhiên kết quả trên có thể không còn đúng khi áp dụng thử nghiệm phân loại trên \n\nTiếng Việt. Các lý do chính như sau : \n\nThứ nhất:  không có một tập dữ liệu chuẩn dành riêng cho việc phân loại.  \n\nThứ hai: hiện tại chưa có chuẩn thống nhất nào cho vấn đề font và dấu câu cho \n\nTiếng Việt.  \n\nThứ ba: viêc biểu diễn văn bản Tiếng Việt bằng vector đặc trưng gặp nhiều trở \n\nngại do bị phụ thuộc nhiều vào các phương pháp tách từ. Trong khi đó các phương \n\npháp này không đạt được hiệu quả cao như trong tiếng Anh.  \n\nĐể có thể áp dụng các phương pháp phân loại văn bản đã được sử dụng thành \n\ncông trên nhiều ngôn ngữ (Anh, Pháp,\u2026) như đã liệt kê trên, điều kiện tiên quyết là \n\nphải tìm ra một phương pháp tách từ tốt để thông qua đó cải thiện hiệu quả của các \n\nthuật toán phân loại. Trong tiếng Anh, đơn vị nhỏ nhất là \u201ctừ\u201d nên việc tách từ trở \n\nnên khá đơn giản, trong khi đối với một số ngôn ngữ như tiếng Hoa, Nhật, Hàn \n\nQuốc... và Tiếng Việt của chúng ta phải xử lý hoàn toàn khác do đơn vị nhỏ nhất lại \n\n\n\n \n  \n\n \n\n 20 \n\nlà \u201ctiếng\u201d. Do đó, trước khi thực hiện phân loại, chúng ta phải tìm hiểu về các \n\nhướng tiếp cận cho việc tách từ tiếng Việt, một vấn đề khá thú vị không kém các \n\nphương pháp phân loại. \n\n\n\n \n  \n\n \n\n 21 \n\n  \n\nCChhưươơnngg  33  \n\nCCÁÁCC  PPHHƯƯƠƠNNGG  PPHHÁÁPP  \n\nTTÁÁCCHH  TTỪỪ  TTIIẾẾNNGG  VVIIỆỆTT  \n\nHHIIỆỆNN  NNAAYY  \nTại sao tách từ tiếng Việt là một thách thức? \n\nSo sánh giữa tiếng Việt và tiếng Anh \n\nNhận xét \n\nBối cảnh các phương pháp tách từ hiện nay \n\nBối cảnh chung \n\nCác hướng tiếp cận dựa trên từ  \n\nCác hướng tiếp cận dựa trên ký tự \n\nMột số phương pháp tách từ tiếng Việt hiện nay \n\nPhương pháp Maximum Matching: forward/backward \n\nPhương pháp giải thuật học cải tiến \n\nMô hình tách từ bằng WFST và mạng Neural \n\nPhương pháp quy hoạch động \n\nPhương pháp tách từ tiếng Việt dựa trên thống kê từ Internet \n\nvà thuật toán di truyền \n\nKết luận \n\n\n\n \n  \n\n \n\n 22 \n\nChương 3. CÁC PHƯƠNG PHÁP TÁCH TỪ TIẾNG VIỆT \nHIỆN NAY \n\n3.1. Tại sao tách từ tiếng Việt là một thách thức? \n\n3.1.1. So sánh giữa tiếng Việt và tiếng Anh \nDựa vào các đặc điểm của tiếng Anh và tiếng Việt được trình bày trong [Đinh \n\nĐiền, 2004], chúng em lập bảng so sánh các đặc điểm chủ yếu giữa tiếng Anh và \n\ntiếng Việt như sau \n\nĐặc điểm của Tiếng Việt Đặc điểm của Tiếng Anh \n\n Được xếp là loại hình đơn lập \n\n(isolate) hay còn gọi là loại hình \n\nphi hình thái, không biến hình, \n\nđơn tiết \n\n Từ không biến đổi hình thái, ý \n\nnghĩa ngữ pháp nằm ở ngoài từ \n\nVí dụ : Chị ngã em nâng và Em ngã \n\n chị nâng \n\n Phương thức ngữ pháp chủ yếu: \n\ntrật tự từ và hư từ. \n\nVí dụ: Gạo xay và Xay gạo; đang \n\n học và học rồi ; \u201cnó bảo sao \n\n không tới\u201d, \u201csao không bảo nó \n\n tới\u201d, \u201csao không tới bảo nó\u201d.. \n\n Ranh giới từ không được xác \n\nđịnh mặc nhiên bằng khoảng \n\ntrắng \n\n \n\n Tồn tại loại từ đặc biệt \u201c từ chỉ \n\nloại\u201d (classifier) hay còn gọi là \n\n  Là loại hình biến cách (flexion) \n\nhay còn gọi là loại hình khuất \n\nchiết \n\n \n\n Từ có biến đổi hình thái, ý nghĩa \n\nngữ pháp nằm ở trong từ. \n\nVí dụ: I see him và He sees me. \n\n \n\n Phương thức ngữ pháp chủ yếu \n\nlà : phụ tố.  \n\nVí dụ: studying và studied \n\n \n\n \n\n \n\n Kết hợp giữa các hình vị là chặt \n\nchẽ, khó xác định, được nhận \n\ndiện bằng khoảng trắng hoặc dấu \n\ncâu. \n\n Hiện tượng cấu tạo bằng từ ghép \n\nthêm phụ tố (affix) vào gốc từ là \n\n\n\n \n  \n\n \n\n 23 \n\nphó danh từ chỉ loại kèm theo \n\nvới danh từ, như: cái bàn, cuốn \n\nsách, bức thư, con chó, con sông, \n\nvì sao\u2026 \n\n Có hiện tượng láy và nói lái \n\ntrong tiếng Việt  \n\nVí dụ: lấp lánh, lung linh \n\n Hiện đại -> hại điện, thầy giáo-> \n\n tháo giầy\u2026 \n\nrất phổ biến. \n\nVí dụ: anticomputerizational ( anti-\n\n compute-er-ize-ation-al) \n\n \n\n \n\nBảng 3. 1. So sánh giữa tiếng Việt và tiếng Anh \n\n3.1.2. Nhận xét \n Tiếng Việt là loại hình phi hình thái nên việc phân biệt loại từ (danh từ, động \n\ntừ, tính từ \u2026) và ý nghĩa từ là rất khó, cho dù có sử dụng từ điển. \n\n Việc tiền xử lý văn bản (tách từ, tách đoạn, tách câu\u2026) sẽ thêm phức tạp với \n\nphần xử lý các hư từ, phụ từ, từ láy\u2026 \n\n Phương thức ngữ pháp chủ yếu là trật tự từ nên nếu áp dụng phương pháp \n\ntính xác suất xuất hiện của từ có thể không chính xác như mong đợi \n\n Ranh giới từ không được xác định mặc nhiên bằng khoảng trắng. Điều này \n\nkhiến cho việc phân tích hình thái (tách từ) tiếng Việt trở nên khó khăn. Việc \n\nnhận diện ranh giới từ là quan trọng làm tiền đề cho các xử lý tiếp theo sau \n\nđó, như: kiểm lỗi chính tả, gán nhãn từ loại, thống kê tần suất từ,\u2026 \n\n Vì giữa tiếng Anh và tiếng Việt có nhiều điểm khác biệt nên chúng ta không \n\nthể  áp dụng y nguyên các thuật toán tiếng Anh cho tiếng Việt \n\n3.2. Bối cảnh các phương pháp tách từ hiện nay \n\n3.2.1. Bối cảnh chung \nDựa trên cơ sở thống kê các phương pháp tách từ trên tiếng Hoa của [Foo and \n\nLi, 2004], chúng em xin trình bày bối cảnh các phương pháp tách từ hiện nay cho \n\ntiếng Việt như sau: \n\n\n\n \n  \n\n \n\n 24 \n\n \n\nHình 3.4. Các hướng tiếp cận cơ bản trong tách từ tiếng Hoa và các hướng \n\ntiếp cận hiện tại được công bố trong tách từ tiếng Việt \n\n3.2.2. Các hướng tiếp cận dựa trên từ (Word-based approaches) \nHướng tiếp cận dựa trên từ với mục tiêu tách được các từ hoàn chỉnh trong câu. \n\nHướng tiếp cận này có thể chia ra là ba hướng: dựa trên thống kê (statistics-based), \n\ndựa trên từ điển (dictionary-based) và hydrid (kết hợp nhiều phương pháp với hy \n\nvọng đạt được những ưu điểm của các phương pháp này) \n\n \n\n3.2.2.1. Các công trình tách từ tiếng Hoa \nHướng tiếp cận dựa trên thống kê (statistics-based) dựa trên các thông tin như \n\ntần số xuất hiện của từ trong tập dữ liệu huấn luyện đầu. Hướng tiếp cận này đặc \n\nHybrid \n\nChinese segmentation \n\nCharacter-based Word-based \n\nUnigram N-gram Statistic Dictionary \n\nVietnamese segmentation \n\nLê An Hà (03) H. Nguyễn et al (05) \n\nFull word / Phrase Component \n\nShortest Match Longest Match Overlap Match \n\nĐinh Điền \n\net al (01) \n\nLuận văn này (05) \n\n\n\n \n  \n\n \n\n 25 \n\nbiệt dựa trên tập ngữ liệu huấn luyện, nhờ vậy nên hướng tiếp cận này tỏ ra rất linh \n\nhoạt và hữu dụng trong nhiều lãnh vực riêng biệt [Nie et al.,1996]. \n\nHướng tiếp cận dựa trên từ điển (dictionary-based) thường được sử dụng trong \n\ntách từ. Ý tưởng của hướng tiếp cận này là những cụm từ được tách ra từ văn bản \n\nphải khớp với các từ trong từ điển. Những hướng tiếp cận khác nhau sẽ sử dụng \n\nnhững loại từ điển khác nhau. Hướng tiếp cận \u201cfull word / phrase\u201d cần sử dụng một \n\ntừ điển hoàn chỉnh để có thể tách được đầy đủ các từ hoặc ngữ trong văn bản, trong \n\nkhi đó, hướng tiếp cận thành phần (component) lại sử dụng từ điển thành phần \n\n(component dictionary)[Wu & Tseng, 1993] . Từ điển hoàn chỉnh chứa tất cả các từ \n\nvà ngữ được dùng trong tiếng Hoa, trong khi từ điển thành phần (component \n\ndictionary) chỉ chứa các thành phần của từ và ngữ như hình vị và các từ đơn giản \n\ntrong tiếng Hoa. \n\nTùy theo cách chọn để khớp từ (match), hướng tiếp cận \u201cfull word/ phrase\u201d có \n\nthể được chia ra thành khớp dài nhất (longest match \u2013 bằng cách duyệt văn bản tuần \n\ntự  để tìm ra từ dài nhất có trong từ điển) và khớp ngắn nhất (shortest match \u2013 bằng \n\ncách duyệt văn bản tuần tự và chọn từ đầu tiên có trong từ điển ). Ngoài hai cách \n\nthông dụng nhất là khớp dài nhất và khớp ngắn nhất, He et. al. (1996)còn đề nghị \n\nmột cách thứ ba là cách kết hợp (overlap). Trong cách kết hợp này, mỗi chuỗi được \n\nphát sinh từ văn bản có thể chồng lấp lên chuỗi khác nếu chuỗi đó có trong từ điển  \n\n(ví dụ : học sinh học, ta sẽ có các token là \u201chọc sinh\u201d, \u201csinh học\u201d chứ không phải \n\nchỉ có một cách như khớp dài nhất hoặc khớp ngắn nhất). Tại thời điểm hiện tại, \n\nhướng tiếp cận khớp dài nhất được xem là phương pháp quan trọng và hiệu quả \n\nnhất trong hướng tiếp cận dựa trên từ điển [Foo & Li, 2002]. \n\nTuy nhiên, hướng tiếp cận dựa trên từ điển vẫn có một số hạn chế trong việc \n\ntách từ vì thực hiện hoàn toàn dựa trên một từ điển hoàn chỉnh. Trong thực tế, để \n\nxây dựng một bộ từ điển thật sự hoàn hảo chứa tất cả các từ tiếng Hoa là không thật \n\nsự cần thiết và khó thành hiện thực. Hướng tiếp cận dựa trên thành phần \n\n(component) phát triển cũng với mục đích làm nhẹ bớt mặt hạn chế này bằng cách \n\nnối các hình vị và từ thành những từ và ngữ hoàn chỉnh [Wu & Tseng,1993,1995].  \n\n\n\n \n  \n\n \n\n 26 \n\nHướng tiếp cận Hybrid với mục đích kết hợp các hướng tiếp cận khác nhau để \n\nthừa hưởng được ưu điểm của nhiều kỹ thuật khác nhau. Hướng tiếp cận này thường \n\nkết hợp giữa hướng dựa trên thống kê và dựa trên từ điển nhằm lấy được ưu thế \n\nchung và các mặt vượt trội riêng của mỗi phương pháp. Một số thành công của \n\nphương pháp này được trình bày trong [Nie et al, 1996]. Mặc dù hướng tiếp cận \n\nhibrid có được những ưu điểm của phương pháp khác nhưng lại gặp phải các phức \n\ntạp khác như thời gian xử lý, không gian đĩa và đòi hỏi nhiều chi phí. \n\n3.2.2.2. Các công trình tách từ tiếng Việt \nCông trình của Đinh Điền et al (2001) đã cố gắng xây dựng tập ngữ liệu huấn \n\nluyện riêng (khoảng 10M) dựa trên các thông tin có nguồn gốc từ Internet như tin \n\ntức, e-book\u2026 Tuy nhiên tập ngữ liệu vẫn còn khá nhỏ để đảm bảo dung lượng và \n\nđộ phong phú cho việc tách từ. Mặc khác, do tập ngữ liệu được xây dựng một cách \n\nthủ công, nên sẽ phần nào mang tính chủ quan. Và một hạn chế nữa là việc đánh giá \n\nlại được những thay đổi hằng ngày rất chậm, và có thể xảy ra hiện tượng flip-flop ( \n\nhiện tượng khi khắc phục lỗi này lại dẫn đến lỗi khác không ngờ tới) \n\nỞ hướng tiếp cận dựa trên từ điển, các từ được tách phải tương ứng với những từ \n\ncó trong từ điển. Hiện tại, ta vẫn chưa xây dựng được một bộ từ điển Việt Nam \n\nchứa toàn bộ các từ và ngữ. \n\n3.2.3. Các hướng tiếp cận dựa trên ký tự (Character-based approaches) \nCần phân biệt rằng hình vị nhỏ nhất của tiếng Việt là \u201ctiếng\u201d, được cấu tạo bởi \n\nnhiều ký tự trong bảng chữ cái, trong khi hình vị nhỏ nhất của tiếng Hoa là một ký \n\ntự. Vì chữ viết tiếng Hoa là chữ tượng hình, không dựa trên bảng chữ cái Latin như \n\ntiếng Việt nên trong trường hợp tiếng Hoa, người ta xét hình vị là \u201cký tự\u201d. Tuy \n\nnhiên, mỗi ký tự (character) trong tiếng Hoa được phát âm thành một \u201ctiếng\u201d, nên  \n\nxét về mặt âm vị, ta có thể xem \u201ctiếng\u201d trong tiếng Hoa và tiếng Việt là tương tự \n\nnhau. Vì vậy, để tránh sự hiểu nhằm ý nghĩa giữa ký tự trong tiếng Hoa và tiếng \n\ntrong tiếng Việt, chúng em xin phép dùng từ \u201ctiếng\u201d để chỉ cho ký tự tiếng Hoa và \n\ntiếng trong tiếng Việt ở một số trường hợp trình bày về cách tách từ. \n\n\n\n \n  \n\n \n\n 27 \n\nMặc dù có cách viết khác nhau, nhưng về cấu tạo từ và ngữ pháp của tiếng Hoa \n\nvà tiếng Việt có nhiều điểm tương đồng nhau. Xét về nguồn gốc, tiếng Việt là hình \n\nthức phiên âm của chữ Nôm do nhân dân ta sáng tạo nên, vốn có nguồn gốc từ tiếng \n\nTrung Hoa thời xưa. \n\n3.2.3.1.  Các công trình tách từ tiếng Hoa \nHướng tiếp cận này đơn thuần rút trích một số lượng nhất định các tiếng trong \n\nvăn bản như rút trích từ 1 ký tự (unigram) hay nhiều ký tự (n-gram). Mặc dù hướng \n\ntiếp cận này tương đối đơn giản hơn các hướng khác, nhưng nó cũng mang lại nhiều \n\nkết quả khả quan trong tiếng Hoa [Foo and Li, 2004]. \n\nHướng tiếp cận dựa trên một ký tự (unigram) chia văn bản ra các ký tự đơn lẻ để \n\nthực hiện việc tách từ. Ngày nay, hầu như người ta không sử dụng phương pháp này \n\nnhư hướng tiếp cận chính trong việc tách từ nữa. \n\nHướng tiếp cận dựa trên nhiều ký tự (n-gram) chia văn bản ra thành nhiều chuỗi, \n\nmỗi chuỗi gồm hai, ba ký tự trở lên. So với hướng tiếp cận dựa trên một ký tự, \n\nhướng tiếp cận này cho nhiều kết quả ổn định hơn [Kwok, 1997a;1997b]. Do hơn \n\n75% từ trong tiếng Hoa là từ gồm hai ký tự, nên các phương pháp phổ biến là dựa \n\ntrên việc tách từ gồm hai ký tự sẽ cho kết quả nhiều từ đúng hơn [Wu & Tseng, \n\n1993].Ví dụ, ta có một câu ABCDEF, hướng tiếp cận trên sẽ chia câu thành AB CD \n\nEF.  Một biến thể của phương pháp tách từ hai ký tự là hướng tiếp cận cách chia \n\nchồng lên nhau, ví dụ ta có ABCDEFG, hướng tiếp cận này sẽ chia thành AB BC \n\nCD DE DF FG. Nhóm nghiên cứu của Swiss Federal Institute of Technology (ETH) \n\náp dụng phương pháp biến thể và có thể cải tiến là sử dụng thêm danh sách  stoplist \n\n(tương tự như các hư từ trong tiếng Việt như à, ơi..) để tách các ngữ của câu trước \n\nkhi tách từ [Mateev et al, 1997]. Nhờ vậy, mà kích thước văn bản cần tách từ được \n\ngiảm xuống nhưng có khuyết điểm là nó có thể làm mất ý nghĩa của câu gốc. \n\nƯu điểm nổi bật của hướng tiếp cận dựa trên nhiều ký tự là tính đơn giản và dễ \n\nứng dụng, ngoài ra còn có thuận lợi là ít tốn chi phí cho việc tạo chỉ mục (index) và \n\nxử lý nhiều câu truy vấn (query processing). Qua nhiều công trình nghiên cứu, \n\n\n\n \n  \n\n \n\n 28 \n\nhướng tiếp cận tách từ dựa trên nhiều ký tự, đặc biệt là cách tách từ hai ký tự được \n\nxem là sự lựa chọn thích hợp[Foo & Li, 2002]. \n\n3.2.3.2.  Các công trình tách từ tiếng Việt \nTrong trường hợp tiếng Việt, hướng tiếp cận này được xem là hướng tiếp cận \n\ndựa trên tiếng, khác với tiếng Hoa là dựa trên ký tự. Ở Việt Nam, hướng tiếp cận \n\nnày cũng đã có một số công trình được phổ biến. [Lê An Hà, 2003] xây dựng tập \n\nngữ liệu thô 10M, sử dụng phương pháp quy hoạch động để cực đại hóa tổng xác \n\nsuất xuất hiện của các ngữ. Gần đây nhất có thể kể đến công trình của [H. Nguyen \n\net al, 2005], thay vì sử dụng ngữ liệu thô, công trình của họ có sáng tạo là lấy thông \n\ntin thống kê từ Internet và sử dụng thuật toán di truyền (Genetic Algorithm) để tìm \n\ncách tách từ tối ưu nhất. Mặc dù công trình của họ còn mang tính sơ bộ, và việc thử \n\nnghiệm chưa hoàn chỉnh, nhưng chúng em tin rằng ý tưởng mới lạ này đem lại \n\nnhiều hứa hẹn khả quan.  \n\nHướng tiếp cận cho việc tách từ của chúng em mở rộng trên ý tưởng này, ngoài \n\nra, chúng em thực hiện một số thay đổi quan trọng nhằm nâng cao tính chính xác \n\ncủa việc tách từ. Thêm nữa, chúng em đã thực hiện một số thử nghiệm trên số lượng \n\ndữ liệu đáng kể nhằm đưa ra các đánh giá một cách bao quát hơn, chính xác hơn. \n\n3.3. Một số phương pháp tách từ tiếng Việt hiện nay \n\n3.3.1. Phương pháp Maximum Matching: forward/backward \n\n3.3.1.1. Nội dung \nPhương pháp khớp tối đa (Maximum Matching) còn gọi là Left Right Maximum \n\nMatching (LRMM). Theo phương pháp này, ta sẽ duyệt một ngữ hoặc câu từ trái \n\nsang phải và chọn từ có nhiều âm tiết nhất có mặt trong từ điển, rồi cứ thể tiếp tục \n\ncho từ kế tiếp cho đến hết câu. Thuật toán được trình bày trong [Chih-Hao Tsai, \n\n2000] \n\nDạng đơn giản được dùng giải quyết nhập nhằng từ đơn. Giả sử có một chuỗi ký \n\ntự (tương đương với chuỗi tiếng trong tiếng Việt) C1, C2, ... , C2. Ta bắt đầu từ đầu \n\nchuỗi. Đầu tiên kiểm tra xem C1, có phải là từ hay không, sau đó kiểm tra xem C1C2 \n\n\n\n \n  \n\n \n\n 29 \n\ncó phải là từ hay không. Tiếp tục tìm cho đến khi tìm được từ dài nhất. Từ có vẻ \n\nhợp lý nhất sẽ là từ dài nhất. Chọn từ đó, sau đó tìm tiếp như trên cho những từ còn \n\nlại cho đến khi xác định được toàn bộ chuỗi từ. \n\nDạng phức tạp: Quy tắc của dạng này là phân đoạn có vẻ hợp lý nhất là đoạn ba \n\ntừ với chiều dài tối đa. Thuật toán bắt đầu như dạng đơn giản. Nếu phát hiện ra \n\nnhững cách tách từ gây nhập nhằng (ví dụ, C1 là từ và C1C2 cũng là từ), ta xem các \n\nchữ kế tiếp để tìm tất cả các đoạn ba từ có thể có bắt đầu với C1 hoặc C1C2. Ví dụ ta \n\nđược những đoạn sau: \n\n C1  C2   C3 C4 \n\n C1C2   C3 C4  C5 \n\n C1C2   C3 C4  C5 C6 \n\nChuỗi dài nhất sẽ là chuỗi thứ ba. Vậy từ đầu tiên của chuỗi thứ ba (C1C2) sẽ \n\nđược chọn. Thực hiện lại các bước cho đến khi được chuỗi từ hoàn chỉnh.  \n\n3.3.1.2. Ưu điểm \n Với cách này, ta dễ dàng tách được chính xác các ngữ/câu như \u201c hợp tác xã || \n\nmua bán\u201d, \u201cthành lập || nước || Việt Nam || dân chủ || cộng hòa\u201d  \n\n Cách tách từ đơn giản, nhanh, chỉ cần dựa vào từ điển \n\n Trong tiếng Hoa, cách này đạt được độ chính xác 98,41% [Chih-Hao Tsai, \n\n2000]. \n\n3.3.1.3. Hạn chế \n Độ chính xác của phương pháp phụ thuộc hoàn toàn vào tính đủ và tính \n\nchính xác của từ điển \n\n Phương pháp này sẽ tách từ sai trong các trường hợp \u201c học sinh || học sinh|| \n\nhọc\u201d, \u201cmột || ông || quan tài || giỏi\u201d, \u201ctrước || bàn là || một || ly || nước\u201d\u2026  \n\n\n\n \n  \n\n \n\n 30 \n\n3.3.2. Phương pháp giải thuật học cải biến (Transformation-based \nLearning, TBL) \n\n3.3.2.1. Nội dung \nĐây là cách tiếp cận dựa trên ngữ liệu đã đánh dấu. Theo cách tiếp cận này, để \n\nhuấn luyện cho máy tính biết cách nhận diện ranh giới từ tiếng Việt, ta có thể cho \n\nmáy \u201chọc\u201d trên ngữ liệu hàng vạn câu tiếng Việt đã được đánh dấu ranh giới từ \n\nđúng.  \n\n Sau khi học xong, máy sẽ xác định được các tham số (các xác suất) cần thiết \n\ncho mô hình nhận diện từ. \n\n3.3.2.2. Ưu điểm \n Đặc điểm của phương pháp này là khả năng tự rút ra quy luật của ngôn ngữ \n\n Nó có những ưu điểm của cách tiếp cận dựa trên luật  vì cuối cùng nó cũng \n\ndựa trên luật được rút ra) nhưng nó khắc phục được khuyết điểm của việc \n\nxây dựng các luật một cách thủ công bởi các chuyên gia. \n\n Các luật được thử nghiệm tại chỗ để đánh giá độ chính xác và hiệu quả của \n\nluật (dựa trên ngữ liệu huấn luyện) \n\n Có khả năng khử được một số nhập nhằng như \u201cThe singer sang a lot of \n\na??as\u201d, thì hệ có thể xác định được \u201ca??as\u201d là \u201carias\u201d (dân ca) thay vì \u201careas\u201d \n\n(khu vực) của các mô hình ngôn ngữ theo kiểu thống kê.  \n\n3.3.2.3. Hạn chế \n Phương pháp này \u201cdùng ngữ liệu có gán nhãn ngôn ngữ để học tự động các \n\nqui luật đó\u201d[Đinh Điền, 2004]. Như đã nói ở chương 1, việc xây dựng một \n\ntập ngữ liệu đạt được đầy đủ các tiêu chí của tập ngữ liệu trong tiếng Việt là \n\nmột điều rất khó, tốn kém nhiều về mặt thời gian và công sức. \n\n Hệ phải trải qua một thời gian huấn luyện khá lâu để có thể rút ra các luật \n\ntương đối đầy đủ \n\n Cài đặt phức tạp \n\n\n\n \n  \n\n \n\n 31 \n\n3.3.3. Mô hình tách từ bằng WFST và mạng Neural  \n\n3.3.3.1. Nội dung \nMô hình mạng chuyển dịch trạng thái hữu hạn có trọng số WFST (Weighted  \n\nfinit\u2013state Transducer) đã được [Richard et al, 1996]  áp dụng để tách từ tiếng \n\nTrung Quốc. Ý tưởng cơ bản là áp dụng WFST kết hợp với trọng số là xác suất xuất \n\nhiện của mỗi từ trong ngữ liệu. Dùng WFST để duyệt qua câu cần xét. Cách duyệt \n\ncó trọng số lớn nhất sẽ là cách tách từ được chọn. Giải pháp này cũng đã đượng áp \n\ndụng trong [Đinh Điền et al, 2001] kèm với mạng neutral để khử nhập nhằng. Hệ \n\nthống tách từ tiếng Việt của [Đinh Điền, 2001] gồm hai tầng: tầng WFST ngoài việc \n\ntách từ còn xử lý thêm các vấn đề liên quan đến đặc thù của tiếng Việt như từ láy, \n\ntên riêng\u2026 và tầng mạng neural dùng để khử nhập nhằng nếu có. \n\n \n\nHình 3.5. Sơ đồ hệ thống WFST \n\nBắt đầu\n\nTiền xử lý \n\nBắt đầu\n\nTiền xử lý \n\nTiền xử lý \n\nt <  T0 \nY\n\n\n\n \n  \n\n \n\n 32 \n\n Tầng WFST :gồm có ba bước \n\n Xây dựng từ điển trọng số : theo mô hình WFST, việc phân đoạn từ \n\nđược xem như là một sự chuyển dịch trạng thái có xác suất \n\n(Stochastic Transduction). Chúng ta miêu tả từ điển D là một đồ thị \n\nbiến đổi trạng thái hữu hạn có trọng số.  Giả sử: \n\n H: là tập các từ chính tả tiếng Việt (còn gọi là \u201ctiếng\u201d) \n\n P: là từ loại của từ (POS: Part \u2013 Of \u2013 Speech). \n\nMỗi cung của D có thể là: \n\n Từ một phần tử của H tới một phần tử của H, hoặc \n\n Từ ε (ký hiệu kết thúc từ) tối một phần tử của P \n\nCác nhãn trong D biểu thị một chi phí ước lượng (estimated cost) \n\nbằng công thức :    \n\nCost = - log(f/N) \n\n Với f: tần số của từ, N: kích thước tập mẫu. \n\nĐối với các trường hợp từ mới chưa gặp, tác giả áp dụng xác suất \n\ncó điều kiện Goog-Turning (Baayen) để tính toán trọng số. \n\n Xây dựng các khả năng phân đoạn từ : Để giảm sự bùng nổ tổ hợp khi \n\nsinh ra các dãy các từ có thể từ một dãy các tiếng trong câu, tác giả đề \n\nxuất một phương pháp mới là kết hợp dùng từ điển để hạn chế sinh ra \n\ncác bùng nổ tổ hợp. Khi phát hiện thấy một cách phân đoạn từ nào đó \n\nkhông phù hợp (không có trong từ điển, không phải là từ láy, không \n\nphải là danh từ riêng\u2026) thì tác giả loại bỏ các nhánh xuất phát từ cách \n\nphân đoạn từ đó. \n\n Lựa chọn khả năng phân đoạn từ tối ưu : Sau khi được một danh sách \n\ncác cách phân đoạn từ có thể có của câu, tác giả chọn trường hợp phân \n\nđoạn từ có trọng số bé nhất như sau: \n\n Ví dụ: input  = \u201cTốc độ truyền thông tin sẽ tăng cao\u201d \n\no Dictionary    \u201ctốc độ\u201d 8.68 \n\n \u201ctruyền\u201d 12.31 \n\n\n\n \n  \n\n \n\n 33 \n\n \u201ctruyền thông\u201d  1231 \n\n \u201cthông tin\u201d 7.24 \n\n \u201ctin\u201d 7.33 \n\n \u201csẽ\u201d 6.09 \n\n \u201ctăng\u201d 7.43 \n\n \u201ccao\u201d 6.95 \n\nId(D)*D* = \u201cTốc độ # truyền thông # tin # sẽ # tăng # cao.\u201d    48.79 \n\n(8.68 +12.31 + 7.33 + 6.09 + 7.43 +6.95 = 48.79 ) \n\nId(D)*D* = \u201cTốc độ # truyền # thông  tin # sẽ # tăng # cao.\u201d  48.70 \n\n(8.68 +12.31 + 7.24 + 6.09 + 7.43 +6.95 = 48.79 ) \n\nDo đó, ta có được phân đoạn tối ưu là \u201cTốc độ # truyền # thông  tin # sẽ # tăng # \n\ncao.\u201d \n\n Tầng mạng neural : Mô hình mạng neural mà tác giả đề xuất được dùng để \n\nlượng giá 3 dãy từ loại: NNV,NVN, VNN (N: Noun, V: Verb). Mô hình này \n\nđược học bằng chính các câu mà cách phân đoạn từ vẫn còn nhập nhằng sau \n\nkhi qua mô hình thứ nhất. \n\n3.3.3.2. Ưu điểm \n Độ chính xác trên 97% [Đinh Điền et al, 2001] \n\n Mô hình cho kết quả phân đoạn từ với độ tin cậy (xác suất) kèm theo. \n\n Nhờ có tầng mạng neural nên mô hình có thể khử nhập nhằng các trường hợp \n\ntầng WFST cho ra nhiều ứng viên có kết quả ngang nhau \n\n Phương pháp này cho kết quả với độ chính xác khá cao vì mục đích của tác \n\ngiả muốn nhắm đến việc tách từ thật chính xác để là nền tảng cho việc dịch \n\nmáy.  \n\n3.3.3.3. Hạn chế \n Cũng tương tự như phương pháp TBL, việc xây dựng tập ngữ liệu là rất công \n\nphu, nhưng thật sự rất cần thiết để phục vụ cho mục đích dịch máy sau này \n\ncủa tác giả. \n\n\n\n \n  \n\n \n\n 34 \n\n3.3.4. Phương pháp quy hoạch động (dynamic programming)  \n\n3.3.4.1. Nội dung \nPhương pháp quy hoạch động [Le An Ha, 2003] chỉ sử dụng tập ngữ liệu thô để \n\nlấy thông tin về tần số thống kê của từ , làm tăng độ tin cậy cho việc tính toán. Việc \n\ntính toán bắt đầu với những đơn vị chắc chắn như câu, các ngữ (chunk) được phân \n\ncách bởi dấu câu ( như dấu phẩy, gạch nối, chấm phẩy\u2026) vì những thành phần này \n\nkhông có tính nhập nhằng ngay cả trong văn viết cũng như nói. Sau đó, tác giả cố \n\ngắng tối đa hoá xác suất của ngữ bằng cách tìm ra nhiều cách tách ngữ đó. Cách \n\ntách cuối cùng là cách tách là cho ngữ đó có xác suất cao nhất. Ý tưởng của cách \n\ntách từ này cho một ngữ cần tách từ, ta phải tìm ra các tổ hợp từ tạo nên ngữ đó sao \n\ncho tổ hợp đó đạt được xác suất tối đa. Tuy nhiên trong phương pháp tính toán này, \n\ntác giả gặp phải vấn đề bùng nổ tổ hợp và phân tích ngữ liệu thô. Để giải quyết vấn \n\nđề trên, tác giả đã sử dụng phương pháp quy hoạch động (dynamic programming) vì \n\nlúc đó, xác suất cực đại của một ngữ nhỏ hơn chỉ phải tính toán một lần và sử dụng \n\nlại trong các lần sau. \n\n3.3.4.2. Ưu điểm \n Không cần sử dụng tập ngữ liệu đã đánh dấu chính xác \n\n3.3.4.3. Hạn chế \n Trong thí nghiệm, tác giả chỉ dừng lại ở việc tách các từ có ba tiếng bởi vì \n\ntập ngữ liệu đầu vào vẫn còn khá nhỏ. \n\n Xác suất từ đúng là 51%, xác suất từ chấp nhận được 65% [Le An Ha, 2003]. \n\nXác suất này tương đối thấp so với các phương pháp tách từ khác đã đề cập ở \n\ntrên. \n\n3.3.5. Phương pháp tách từ tiếng Việt dựa trên thống kê từ Internet và \nthuật toán di truyền (Internet and Genetics Algorithm-based Text \nCategorization for Documents in Vietnamese - IGATEC)  \n\n3.3.5.1. Nội dung \nPhương pháp IGATEC do H.Nguyễn et al (2005) giới thiệu là một hướng tiếp \n\ncận mới cho việc tách từ với mục đích phân loại văn bản mà không cần dùng đến \n\n\n\n \n  \n\n \n\n 35 \n\nmột từ điển hay tập huấn luyện nào. Trong hướng tiếp cận này, tác giả kết hợp giữa \n\nthuật toán di truyền (Genetics Algorithm - GA) với dữ liệu thống kê được trích xuất \n\ntừ Internet tiến hoá một quần thể gồm các cá thể là các khả năng tách từ trong câu. \n\nHệ thống gồm ba phần \n\n \n\nHình 3.6. Toàn cảnh hệ thống IGATEC \n\n Online Extractor : Phần này có tác dụng lấy thông tin về tần số xuất hiện của \n\ncác từ trong văn bản bằng cách sử dụng một search engine nổi tiếng như \n\nGoogle. Sau đó, tác giả sử dụng các công thức sau đây để tính toán mức độ \n\nphụ thuộc lẫn nhau (mutual information) để là cơ sở tính fitness cho GA \n\nengine. \n\n Tính xác suất các từ xuất hiện trên Internet \n\n ( )(w)= count wp\nMAX\n\n  \n\n 1 21 2\n( & )( & ) count w wp w w\n\nMAX\n=  \n\nTrong đó, MAX = 4 * 109 ;  \n\ncount(w) số lượng văn bản trên Internet được tìm thấy có chứa từ \n\nw hoặc cùng chứa w1 và w2 đối với count(w1 & w2) \n\n Tính xác suất độ phụ thuộc của một từ lên một từ khác \n\nOnline Extractor \n\nOnline Extractor Online Extractor \n\nOnline Extractor \n\nsegmentation\n\nsegmentation\n\nsegmentation\n\n\u2026\n\n\n\n \n  \n\n \n\n 36 \n\n 1 21 2\n1\n\n( & )( | )\n( )\n\np w wp w w\np w\n\n=   \n\n Thông tin phụ thuộc lẫn nhau (mutual information) của các từ ghép \n\nđược cấu tạo bởi n tiếng (cw = w1w2\u2026wn) \n\n 1 2\n\n1 2\n1\n\n(  &   &  ... &  ) ( ) = \n( ) -  (  &   &  ... &  )  \n\nn\nn\n\nj n\nj\n\np w w wMI cw\np w p w w w\n\n=\n∑\n\n \n\n GA Engine for Text Segmentation : mỗi cá thể trong quần thể được biểu diễn \n\nbởi chuỗi các bit 0,1, trong đó, mỗi bit đại diện cho một tiếng trong văn bản, \n\nmỗi nhóm bit cùng loại đại diện cho một segment.  \n\n Các cá thể được khởi tạo ngẫu nhiên, trong đó, mỗi segment được giới \n\nhạn trong khoảng 5. GA engine sau đó thực hiện các bước đột biến và \n\nlai ghép nhằm mục đích làm tăng giá trị fitness của các cá thể, để đạt \n\nđược cách tách từ tốt nhất có thể. \n\n Text Categorization  : tác giả dùng độ hỗ trợ (support degree) của văn bản \n\ncần phân loại cho các từ khoá để phân loại văn bản. \n\n3.3.5.2. Ưu điểm \n Không cần sử dụng bất cứ tập huấn luyện hoặc từ điển nào \n\n Phương pháp tương đối đơn giản. \n\n Không tốn thời gian huấn luyện \n\n3.3.5.3. Hạn chế \n So với các phương pháp trước, IGATEC có độ chính xác thấp hơn LRMM \n\nvà WFST nhưng vẫn chấp nhận được đối với mục đích tách từ dành cho phân \n\nloại văn bản. \n\n Thời gian chạy ban đầu khá chậm do phải lấy thông tin từ Internet mà đường \n\ntruyền ở Việt Nam còn hạn chế. \n\n Chưa có các thử nghiệm trên tập dữ liệu đủ lớn. \n\n\n\n \n  \n\n \n\n 37 \n\n3.4. So sánh các phương pháp tách từ Tiếng Việt hiện nay \nNhìn một cách tổng quan, phương pháp dựa trên từ (word-base) cho độ chính \n\nxác khá cao ( trên 95%) nhờ vào tập ngữ liệu huấn luyện lớn, được đánh dấu chính \n\nxác, tuy nhiên hiệu suất của thuật toán phụ thuộc hoàn toàn vào ngữ liệu huấn \n\nluyên. Bởi vì mục đích của các tác giả [Đinh Điền et al, 2001] là thực hiện tách từ \n\nthật chính xác để phục vụ cho việc dịch máy nên tác giả đã chọn phương pháp \n\nWFST. Với các phương pháp cần phải sử dụng từ điển hoặc tập huấn luyện, ngoài \n\nviệc tách từ thật chính xác, ta còn có thể nhờ vào các thông tin đánh dấu trong tập \n\nngữ liệu để thực hiện các mục đích khác cần đến việc xác định từ loại như dịch \n\nmáy, kiểm lỗi chính tả, từ điển đồng nghĩa... Do vậy, mặc dù thời gian huấn luyện \n\nkhá lâu, cài đặt khá phức tạp, chi phí tạo tập ngữ liệu huấn luyện rất tốn kém, nhưng \n\nkết quả mà hướng tiếp cận dựa trên từ mang lại cho mục đích dịch máy là rất xứng \n\nđáng cho công sức bỏ ra. \n\nHướng tiếp cận dựa trên ký tự (character-based) có ưu điểm là dễ thực hiện, thời \n\ngian thực thi tương đối nhanh, tuy nhiên lại có độ chính xác không cao bằng \n\nphương pháp dựa trên từ. Hướng tiếp cận này thích hợp cho các mục đích nghiên \n\ncứu không cần đến độ chính xác tuyệt đối cũng như các thông tin về từ loại như \n\nphân loại văn bản, lọc spam, firewall... Nhìn trên bình diện chung, hướng tiếp cận \n\ndựa trên từ có nhiều ưu điểm đáng kể, và đem lại nhiều hứa hẹn lạc quan cho các \n\nhướng nghiên cứu tiếp theo để nâng cao độ chính xác của phương pháp tách từ này. \n\n3.5. Kết luận \nDựa trên các phân tích về ưu khuyết điểm của các phương pháp, chúng em chọn \n\nhướng tiếp cận dựa trên \u201ctiếng\u201d (character-based) cho mục tiêu phân loại văn bản \n\ncủa mình.  \n\nBởi vì, mục tiêu của luận văn là phân loại tin tức báo điện tử, một loại hình cực \n\nkỳ phong phú về nội dung và ngôn ngữ, nên việc tạo ra một từ điển hoàn chỉnh và \n\ncó khả năng cập nhật các thay diễn ra liên tục của ngôn ngữ là khó thực hiện được. \n\nHệ thống xử lý cần phải có khả năng linh hoạt, tự động cập nhật những thay đổi \n\n\n\n \n  \n\n \n\n 38 \n\nhằng ngày, nên hướng tiếp cận không dựa trên từ điển hoặc tập ngữ liệu là cực kỳ \n\nthích hợp. \n\nHơn nữa, hệ thống phân loại tin tức cần có tốc độ xử lý chấp nhận được để có \n\nthể xử lý kịp thời các thông tin mới xuất bản hằng ngày. Do đó, với ưu điểm đơn \n\ngiản, tốc độ thực thi chấp nhận đươc, hướng tiếp cận IGATEC là một lựa chọn hoàn \n\ntoàn phù hợp. \n\nMặt khác, việc phân loại văn bản không yêu cầu việc tách từ phải có độ chính \n\nxác cao đến mức từng từ. Ta có hoàn toàn có thể thực hiện thêm việc loại bỏ các từ \n\nkhông cần thiết cho việc phân loại như các hư từ, thán từ... để tăng tốc độ và sự \n\nchính xác của bước tách từ, chuẩn bị cho việc phân loại văn bản. \n\n\n\n \n  \n\n \n\n 39 \n\n  \n\nCChhưươơnngg  44  \n\nTTÁÁCCHH  TTỪỪ  TTIIẾẾNNGG  VVIIỆỆTT  \n\nKKHHÔÔNNGG  DDỰỰAA  TTRRÊÊNN  TTẬẬPP  \n\nNNGGỮỮ  LLIIỆỆUU  HHAAYY  TTỪỪ  ĐĐIIỂỂNN    \n\n\u2013\u2013  MMỘỘTT  TTHHÁÁCCHH  TTHHỨỨCC    \n \n\nGiới thiệu \n\nCác nghiên cứu về thống kê dựa trên Internet \n\nCác phương pháp tính độ liên quan giữa các từ dựa trên thống kê \n\nTiền xử lý  \n\nHướng tiếp cận tách từ dựa trên thống kê từ Internet và thuật toán \n\ndi truyền \n\nCông cụ trích xuất thông tin từ Google \n\nCông cụ tách từ dùng thuật toán di truyền  \n\nKết quả thực nghiệm \n\nKết luận \n\n\n\n \n  \n\n \n\n 40 \n\nChương 4. TÁCH TỪ TIẾNG VIỆT KHÔNG DỰA TRÊN \nTẬP NGỮ LIỆU ĐÁNH DẤU (ANNOTATED CORPUS) \n\nHAY TỪ ĐIỂN (LEXICON) \u2013 MỘT THÁCH THỨC \n\n4.1. Giới thiệu \nNhư chúng ta đã tìm hiểu ở những phần trên, việc khó xác định ranh giới từ đã \n\nlàm cho việc xử lý tính nhập nhằng trong ngôn ngữ tiếng Việt càng thêm phức \n\ntạp.Ví dụ như: câu \u201công lão già đi rất nhanh\u201d, ta có thể phân chia từ theo nhiều cách \n\nmà câu vẫn có nghĩa \u201công ||già đi || rất || nhanh\u201d, \u201công già || đi || rất || nhanh\u201d, \u201công || \n\ngià || đi || rất || nhanh\u201d \u2026   \n\nNhìn chung, đối với tiếng Anh, về mặt lý thuyết tiếng Anh có nhiều thuận lợi vì \n\nlà loại ngôn ngữ hoà kết hay biến cách (flexion) [Đinh Điền, 2004] , hệ thống ngữ \n\npháp và từ loại đã được quy định rõ ràng, do đó việc phân định ranh giới từ cũng \n\nnhư xây dựng tập ngữ liệu đánh dấu là tương đối đễ dàng.  \n\nCòn đối với tiếng Việt, về mặt lý thuyết tiếng Việt là loại hình đơn lập [Đinh \n\nĐiền, 2004], phương thức ngữ pháp chủ yếu là trật tự từ và hư từ, vì vậy chỉ xét về \n\nmặt phân định ranh giới từ đã có thể có nhiều cách phân định cho cùng một câu mà \n\nvẫn đúng ngữ pháp Việt Nam. \n\nỞ phần này, chúng em xin trình bày hướng tiếp cận cho việc tách từ tiếng Việt \n\ntheo một hướng mới mà không cần sử dụng tập ngữ liệu huấn luyện hay từ điển. \n\nHướng tiếp cận của chúng em dựa trên ý tưởng của bài báo IGATEC, và có nhiều \n\ncải tiến đang kể hàm làm tăng chất lượng cho bước tách từ tiếng Việt phục vụ cho \n\nviệc phân loại tin tức báo điện tử. \n\n4.2. Các nghiên cứu về thống kê dựa trên Internet \n\n4.2.1. Giới thiệu \nVới sự phát triển nhanh chóng của Internet, world-wide-web đã trở thành nguồn \n\ndữ liệu lớn nhất trên thế giới, và là nguồn thông tin ngữ nghĩa tiềm tàng được hàng \n\ntriệu người dùng trên thế giới tạo ra. Đối với con người, việc xem xét mức độ liên \n\nquan giữa hai từ là rất dễ dàng bởi vì con người có thể dựa vào kiến thức  thông \n\n\n\n \n  \n\n \n\n 41 \n\nthường của mình để suy ra ngữ cảnh thích hợp, ví dụ giữa từ \u201ccái nón\u201d và \u201cmàu \n\nđỏ\u201d, con người dễ dàng nhận ra sự liên quan là \u201ccái nón có màu đỏ\u201d. Tuy nhiên, \n\nmáy tính của chúng ta không có khả năng như con người, vì vậy, chúng ta phải tìm \n\nra một cách biểu diễn ngữ nghĩa mà máy tính có thể \u201ctiêu hoá\u201d được. Có ý kiến cho \n\nrằng ta có thể tạo một mạng ngữ nghĩa đồ sộ như một hệ thống trí tuệ ban đầu, sau \n\nđó các kiến thức về cuộc sống thực sẽ tự động xuất hiện. Tuy nhiên hướng giải \n\nquyết này đòi hỏi lượng chi phí khổng lồ cho việc thiết kế cấu trúc có khả năng tính \n\ntoán tri thức và việc nhập các dữ liệu chuẩn xác do các chuyên gia thực hiện. Trong \n\nkhi nỗ lực này vẫn còn đang trong cuộc đua đường dài, chúng ta hãy sử dụng những \n\nthông tin hiện có trên world-wide-web để thực hiện việc biểu diễn ngữ nghĩa. \n\nChúng ta đều biết rằng Internet là kho dữ liệu vô tận, do vậy việc khai thác các \n\nthông tin trên đó không thể thực hiện thủ công mà chúng ta phải thông qua sự hỗ trợ \n\ncủa một công cụ tìm kiếm trên mạng. Nói đến công cụ tìm kiếm (search engine), có \n\nlẽ tên tuổi đầu tiên mà chúng ta nghĩ đến là Google, một công cụ tìm kiếm hàng đầu \n\nbởi tốc độ và chất lượng mà Google đem lại cho người dùng. Và điều đó càng được \n\nchứng minh cụ thể hơn khi có ngày càng nhiều các công trình nghiên cứu về thống \n\nkê trên Internet dựa vào công cụ tìm kiếm Google như trong phần trình bày tiếp \n\ntheo sau đây. \n\n4.2.2. Một số công trình nghiên cứu về thống kê dựa trên Internet \nTheo Rudi Cilibrasi & Paul Vitanyi (2005), công cụ tìm kiếm Google có thể \n\ndùng để tự động khám phá ý nghĩa của từ. Ví dụ : Google tìm thấy từ \u201cstudent\u201d và \n\n\u201cbook\u201d cùng xuất hiện với nhau trên Internet với tần số là 57.600.000, trong khi từ \n\n\u201cstudent\u201d và \u201capple\u201d lại chỉ xuất hiện 8.110.000. Rõ ràng, chúng ta có thể nhận thấy \n\n\u201cstudent\u201d và \u201cbook\u201d có liên quan với nhau mật thiết hơn là \u201cstudent\u201d và \u201capple\u201d.  \n\n  Tác giả đã sử dụng kết quả tìm kiếm của Google để huấn luyện ngữ nghĩa của \n\ncác từ (semantic meaning of words) cho phần mềm \u2013 một vấn đề trọng tâm trong \n\nngành trí tuệ nhân tạo. Giả sử muốn tính toán mức độ liên quan giữa từ x với từ y, \n\nRudi & Paul (2005) đã đưa ra công thức tính khoảng cách NGD (Normalise Google \n\nDistance) như sau: \n\n\n\n \n  \n\n \n\n 42 \n\nmax{log ( ), log ( )} log ( , )\nlog min{log ( ), log ( )}\n\nf x f y f x yNGD\nM f x f y\n\n−\n=\n\n−\n (1) \n\nTrong đó :  \n\n f(x) :số trang web chứa từ x mà Goole trả về \n\n  f(x,y) : số trang web chứa đồng thời từ x và từ y \n\n M = 8.058.044.651 là số trang web hiện tại mà Google đã đánh chỉ mục \n\nVới công thức trên, giá trị của NGD càng nhỏ thì mức độ liên quan giữa hai từ \n\ncàng cao. \n\nVí dụ: tần số xuất hiện của \u201cstudent\u201d= 401.000.000, \u201cbook\u201d = 387.000.000, \n\nđồng thời là 57.600.000, còn \u201capple\u201d là 144.000.000, \u201cstudent\u201d & \u201capple\u201d= \n\n8.110.000. Với M = 8.058.044.651, ta có  \n6 6\n\n6\n\nlog 401.10 log 57,6.10( , ) 0.64\nlog8058044651 log 387.10\n\nNGD student book −≈ ≈\n−\n\n \n\n6 6\n\n6\n\nlog 401.10 log8,11.10( , ) 0.97\nlog8058044651 log144.10\n\nNGD student apple −≈ ≈\n−\n\n \n\nTừ kết quả trên, ta có NGD(student,book) ≈0.64 < NGD(student,apple) ≈0.97, \n\nnên có thể kết luận là \u201cstudent\u201d liên quan với \u201cbook\u201d nhiều hơn là \u201capple\u201d. \n\nNếu NGD của hai từ lớn hơn 1 thì tác giả nhận xét rằng hai từ đó thường xuất \n\nhiện cùng với nhau trong trang web mà không vì một mối liên quan nào cả. \n\nVí dụ: tần số xuất hiện của \u201cby\u201d là 2.770.000.000, \u201cwith\u201d là 2.566.000.000, \n\nđồng thời \u201cby\u201d và \u201cwith\u201d là 49.700.000. Với M = 8.058.044.651, ta có \n\nNGD(by,with) ≈ 3.51 \n\nHơn nữa, NGD là số tỉ lệ bất biến (scale-invariant) nên có tính ổn định với sự \n\ntăng trưởng số lượng trang web trên Google. Đây là tính chất rất quan trọng bởi vì  \n\nM số lượng trang web do Google đánh chỉ mục tăng thường xuyên, do đó, số trang \n\nweb chứa các ngữ tìm kiếm cũng tăng lên ứng với tỉ lệ đó. Điều này có nghĩa là nếu \n\nM tăng gấp đôi thì tần số xuất hiện của các ngữ cũng tăng gấp đôi. Công trình của \n\nRudi & Paul (2005) đã mở ra một hướng tiếp cận mới cho các công trình nghiên \n\ncứu khác nhờ tính chất không giới hạn bởi dữ liệu, dễ dàng thực thi và là nền móng \n\ncho các phương pháp nghiên cứu khác [Rudi & Paul, 2005]. \n\n\n\n \n  \n\n \n\n 43 \n\nNgoài ra, theo James & Daniel (2005) còn có một số công trình nghiên cứu về \n\nphương pháp thống kê khác trên Internet như tính toán kết quả tìm kiếm bằng hàm \n\nluỹ thừa [Simkin & Roychowdhurry, 2003] [Bagrow et al, 2004] , hay phương pháp \n\nđược đánh giá tốt hơn là dựa vào giá trị tương tự cực đại (Maximum Likelihood) \n\n[James & Daniel, 2005]\u2026. Mục đích của việc sử dụng giá trị tương tự cực đại để \n\ntìm ra chỉ số gần giống nhau nhất giữa hai khái niệm. Tuy nhiên, theo kết luận của \n\nJames & Daniel(2005), các phương pháp tính toán dựa trên hàm mũ cho kết quả \n\nchưa khả quan lắm và còn mang tính chủ quan. \n\n4.2.3. Nhận xét \n Hướng thống kê dựa trên Internet hứa hẹn nhiều kết quả khả quan vì không \n\ncần phụ thuộc vào tập dữ liệu huấn luyện truyền thống mà chúng ta có thể \n\ntận dụng khả năng vô tận của Internet thông qua công cụ tìm kiếm.  \n\n Dựa trên nhận xét của Rudi & Paul (2005), tỉ lệ xuất hiện của từ trên Internet \n\nlà khá ổn định, điều này cho phép ta thực hiện các tính toán chính xác và ổn \n\nđịnh vì ít phụ thuộc vào số lượng trang web trên Internet tăng lên theo thời \n\ngian.  \n\n Hiện nay, các công trình nghiên cứu theo hướng tiếp cận mới này chủ yếu \n\nđược thực hiện trên tiếng Anh, còn đối với tiếng Việt thì có thể nói IGATEC \n\nlà công trình đầu tiên áp dụng phương pháp này nhưng đã đạt được kết quả \n\nrất đáng quan tâm. Chúng em hy vọng rằng rằng những nỗ lực nghiên cứu và \n\ncải tiến phương pháp IGATEC sẽ đạt được kết quả tốt hơn. \n\n4.3. Các phương pháp tính độ liên quan giữa các từ dựa trên \nthống kê \n\nTrong ngôn ngữ tự nhiên, nhất là loại ngôn ngữ phụ thuộc nhiều vào ngữ cảnh \n\nnhư tiếng Việt, đối với con người, chúng ta có thể dễ dàng xác định được ranh giới \n\ntừ trong câu. Tuy nhiên, do chưa có một quy định cụ thể nào về ranh giới từ tiếng \n\nViệt, nên có thể nhiều người Việt có nhiều cách tách từ khác nhau. Đối với người \n\nchúng ta vẫn chưa thống nhất được, nên khi dùng máy tính để xử lý ngôn ngữ ta vẫn \n\nchưa có một chuẩn nào để xác định đâu là ranh giới từ. Vì vậy, đã có rất nhiều công \n\n\n\n \n  \n\n \n\n 44 \n\ntrình nghiên cứu cách tính toán độ liên quan giữa các từ để khắc phục các công việc \n\nphức tạp do cách phân tích cấu trúc ngữ pháp trong câu đem lại.  \n\nTrong phần này, chúng em sẽ trình bày hai nội dung chính: \n\n Hai thước đo chuẩn dùng để tính toán độ liên quan giữa hai từ trong tiếng \n\nAnh là thông tin tương hỗ (Mutual Information ) và t-score. \n\n Một số ứng dụng và cải tiến của hai công cụ đo trên trong việc tách từ tiếng \n\nHoa và tiếng Việt. \n\n4.3.1. Thông tin tương hỗ (Mutual Information) và t-score dùng  trong \ntiếng Anh \n\nThông tin tương hỗ (Mutual Information) và t-score là hai khái niệm rất quan \n\ntrọng trong học thuyết về thông tin (Information Theory) và thống kê được trình bày \n\ntrong [Church et al, 1991] cho mục đích tính toán mức độ liên quan của hai từ trong \n\ntiếng Anh.   \n\n4.3.1.1. Thông tin tương hỗ MI (Mutual Information) \u2013 thước đo đặc điểm \ntương tự (A Measure of Similarity) \n\nTheo Church et al (1991), việc thống kê thông tin tương hỗ (Mutual \n\nInformation) dùng để nhận biết các trường hợp ngôn ngữ thú vị, bao gồm từ mối \n\nquan hệ ngữ nghĩa (semantic relations) như bác sĩ/y tá (dạng content word/content \n\nword) cho đến mối quan hệ từ vựng-cú pháp (lexico-syntactic) như sự xuất hiện \n\nđồng thời giữa động từ và giới từ (dạng content word/ funtion word). \n\nMI có nhiệm vụ so sánh xác suất xuất hiện đồng thời  (joint probability) của từ x \n\nvà từ y so với xác suất tìm thấy x và y xuất hiện độc lập. Công thức tính MI cho hai \n\ntừ tiếng Anh trong [Church et al, 1991] như sau: \n\n2\n( , )( ; ) log\n\n( ) ( )\nP x yI x y\n\nP x P y\n≡  \n\n\n\n \n  \n\n \n\n 45 \n\nTrong đó: \n\n x và y là hai từ tiếng Anh cần kiểm tra mức độ kết hợp lẫn nhau. \n\n I(x;y) là thông tin tương hỗ của hai từ.  \n\n P(x), P(y) là xác suất xuất hiện độc lập của x và của y. \n\n P(x,y) là xác suất xuất hiện đồng thời x và y. \n\nTheo Church et al (1991), giá trị I(x,y) càng lớn thì khả năng kết hợp của x và y \n\ncàng cao. \n\n4.3.1.2. t-score \u2013 thước đo sự khác biệt (A Measure of Dissimilarity) \nChúng ta dễ dàng nhận ra sự  giống nhau giữa strong và powerful, tuy nhiên làm \n\ncách nào để phân biệt sự khác nhau giữa chúng. Ví dụ, chúng ta đều biết rằng người \n\nta thường nói strong tea, powerful car hơn là nói powerful tea và strong car. Nhưng \n\nlàm sao cho máy tính nhận ra được sự khác biệt này? \n\nGiả sử , ta biết rằng strong support được dùng phổ biến hơn là powerful support, \n\nChurch et al (1991) đã đưa ra công thức tính t-score để đo sự khác biệt trên: \n\n1 2\n2 2\n\n1 2\n\n( | ) -  ( | )\n( ( | )  ( | ))\nP w w P w wt\nP w w w wσ σ\n\n= −\n+\n\n \n\nTrong đó:  \n\n w1,w2 là hai từ tương tự nhau cần phải phân biệt (ở ví dụ trên là strong và \n\npowerful) . \n\n w là từ dùng để phân biệt (ở ví dụ trên là support). \n\n P(w|w1), P(w|w2) là xác suất của từ w xuất hiện đi kèm với từ w1, w2  \n\nLúc đó:  \n\n2 2\n\n2 2\n\n(  ) -  (  )\n( (  )) ( (  ))\n\n(  ) f (  ) -  \n\n(  ) (  )\n\n2 175 13\n2 175\n\nP powerful support P strong supportt\nP powerful support P strong support\n\nf powerful support strong support\nN N\n\nf powerful support f strong support\nN N\n\nσ σ\n= −\n\n+\n\n≈ −\n+\n\n−\n≈ − ≈ −\n\n+\n\n \n\n\n\n \n  \n\n \n\n 46 \n\nTa nói rằng powerful support có độ lệch chuẩn (standard deviation) kém strong \n\nsupport 13 lần. Nhờ vậy, ta có thể phân biệt được sự khác nhau giữa powerful và \n\nstrong trong việc sử dụng hai từ này. \n\n4.3.2. Một số cải tiến trong cách tính độ liên quan ứng dụng trong tách \ntừ tiếng Hoa và tiếng Việt \n\n4.3.2.1. Thông tin tương hỗ (Mutual Information) \nKhi áp dụng thông tin tương hỗ MI trong tách từ tiếng Hoa, Su et al (1993)  cho \n\nrằng thông tin tương hỗ (Mutual Information) là thước đo mức độ kết hợp của một \n\ntừ. Nó có nhiệm vụ so sánh xác suất một nhóm các ký tự (tương tự như \u201ctiếng\u201d \n\ntrong tiếng Việt \u2013 xem giải thích ở mục 3.2.3.) xuất hiện đồng thời (joint \n\nprobability) so với xác suất tìm thấy từng ký tự  xuất hiện độc lập.  \n\nTheo Su et al (1993) cách tính MI cho từ có 2 ký tự có thể áp dụng công thức \n\ncủa Church et al (1991) với ý nghĩa của x và y lúc này không còn là \u201ctừ\u201d (word) như \n\ntrong tiếng Anh mà được hiểu là tiếng (xem giải thích ở mục 3.2.3.) trong tiếng \n\nHoa. \n\n2\n( , )( ; ) log\n\n( ) ( )\nP x yI x y\n\nP x P y\n≡      (1a) \n\nTrong đó: \n\n x và y là hai tiếng cần kiểm tra mức độ kết hợp lẫn nhau trong tiếng Hoa. \n\n I(x;y) là thông tin tương hỗ của hai tiếng.  \n\n P(x), P(y) là xác suất xuất hiện độc lập của tiếng x và của tiếng y. \n\n P(x,y) là xác suất xuất hiện đồng thời tiếng x và tiếng y. \n\n \n\nCách tính MI dành cho từ ghép 3 tiếng như sau [Su et al, 1991]: \n\n2\n( , , )( ; ; ) log\n( , , )\n\nD\n\nI\n\nP x y zI x y z\nP x y z\n\n≡      (1b) \n\nTrong đó:  \n\n PD(x,y,z) ≡ P(x,y,z) là xác suất xuất hiện đồng thời của x, y và x, \n\n(Dependently) \n\n\n\n \n  \n\n \n\n 47 \n\n PI(x,y,z) là xác suất xuất hiện độc lập của x,y, z (Independently) với   \n\nPI(x,y,z) ≡ P(x)P(y)P(z) + P(x)P(y,z) + P(x,y)P(z). \n\nNhìn chung I(.) >>0 sẽ cho biết từ ghép đó có mức độ liên quan giữa các tiếng là \n\nrất chặt chẽ. Ngược lại, các tiếng có xu hướng xuất hiện một cách độc lập. \n\n \n\nMột cách tính MI khác cũng được Ong & Chen (1999) đề nghị như sau:   \n\n1 2\n\n1 2\n\n( & &  ... & ) ( ) = \n( ) ( ) ( & &  ... & )\n\nn\n\nn\n\np w w wMI cw\np lw p rw p w w w+ −\n\n     (2) \n\nTrong đó \n\n cw = p( w1 & w2 ...& wn-1 )  \n\n lw = p( w1 & w2 ...&  wn-1 ) \n\n rw = p ( w2 & w3 ...& wn) \n\n \n\nTheo nghiên cứu của chúng em, hiện nay công trình nghiên cứu về cách tách từ \n\ndựa trên độ tương hỗ MI trên tiếng Việt chưa nhiều. Ở đây, chúng em xin giới thiệu  \n\ncách tính MI được đề nghị trong IGATEC trong [H. Nguyen et al, 2005] \n\n1 2\n\n1 2\n1\n\n(  &   &  ... &  ) ( ) = \n( ) -  (  &   &  ... &  )  \n\nn\nn\n\nj n\nj\n\np w w wMI cw\np w p w w w\n\n=\n∑\n\n   (3) \n\nNhìn vào các công thức tính MI, ta có thể dự đoán được mỗi công thức ưu tiên \n\ncho một loại từ khác nhau. Phần tiếp theo sau đây sẽ trình bày một số nhận xét về \n\ncác công thức trên để làm cơ sở đưa ra lựa chọn phù hợp nhất. \n\n4.3.2.2. Cách tính tần số tương đối (Relative Frequency Count) \nCách tính tần số tương đối cho từ ghép có i tiếng được định nghĩa như sau [Su et \n\nal, 1993]: \n\ni\ni\n\nfr\nK\n\n=  \n\nTrong đó, fi là số lần xuất hiện của từ ghép có i tiếng (ith n-gram) trong tập ngữ \n\nliệu, và K là số lần xuất hiện trung bình của một từ. Nói một cách khác, fi được bình \n\nthường hoá bằng cách chia cho K để lấy tỉ lệ liên quan. Một cách trực quan, ta sẽ \n\n\n\n \n  \n\n \n\n 48 \n\nnhận ra, cách tính RFC sẽ ưu tiên cho những từ xuất hiện với tần số rất cao mà nó sẽ \n\nbỏ mất những xuất hiện trong từ điển với tần số thấp. Vì vậy, RFC được dùng như \n\nmột thuộc tính hỗ trợ thêm cho việc tách từ. \n\n4.3.2.3. Nhận xét về cách sử dụng MI và RFC \nNếu ta sử dụng đồng thời MI và RFC cho việc tách từ sẽ đem lại kết quả như \n\nmong đợi bởi vì nếu chỉ sử dụng một công cụ tính toán, kết quả chúng ta đạt được \n\ncó thể chỉ ưu tiên cho một cách tách nào đó. Nếu chỉ sử dụng RFC, hệ thống của \n\nchúng ta có xu hướng chọn những từ xuất hiện nhiều lần nhưng lại có độ liên quan \n\nMI thấp. Ví dụ, nếu P(x) và P(y) rất lớn, nó có thể tạo ra P(x,y) cũng rất lớn mặc dù \n\nx và y không hề liên quan gì cả vì P(x,y)/ P(x) x P(y) rất nhỏ.  \n\nMặc khác, nếu chỉ sử dụng MI thôi, thì ở trường hợp P(x) và P(y) quá nhỏ sẽ \n\ndẫn đến kết quả không đáng tin cậy. Một từ n-gram có thể có MI cao không bởi vì \n\nchúng kết hợp chặt chẽ với nhau mà bởi vì khi chia hai số cùng nhỏ như nhau, ta sẽ \n\ncó số MI lớn. \n\nTóm lại, ta nên sử dụng cả hai thông tin MI và RFC vì thực tế, một nhóm các từ \n\nvừa có RFC và MI cao sẽ có xu hướng vừa kết hợp chặt chẽ với nhau, vừa được sử \n\ndụng rộng rãi. \n\n4.3.3. Nhận xét  về các cách tính độ liên quan khi áp dụng cho tiếng Việt \n Tiếng Hoa là loại ngôn ngữ đơn lập giống tiếng Việt, nên ta có thể áp dụng \n\nmột số công tình nghiên cứu trên tiếng Hoa lên tiếng Việt. \n\n Về mặt lý thuyết, ta hoàn toàn có thể sử dụng các công thức MI trên để áp \n\ndụng cho tiếng Việt, và quan thực nghiệm, chúng ta sẽ đề xuất thêm một số \n\ncải tiến để công thức tính MI phù hợp với việc tách tiếng Việt hơn nữa. \n\n Đối với công thức RFC, ta cần phân biệt khái niệm  f  trong công thức là tần \n\nsố xuất hiện của từ trong tập ngữ liệu, K là số lần xuất hiện trung bình của \n\nmột từ (real word) trong tập ngữ liệu. Khi sử dụng tập ngữ liệu, các số f và K \n\nlà hoàn toàn tính được. Tuy nhiên, phương pháp IGATEC mà chúng em sử \n\ndụng lại lấy kết quả số lượng trang web p chứa từ cần tìm nên chúng ta \n\nkhông thể tính được số K ( vì không thể dựa vào số lượng trang web trả về \n\n\n\n \n  \n\n \n\n 49 \n\nmà quyết định đó là từ hay không). Do vậy, hiện tại, chúng em vẫn chưa áp \n\ndụng cách tính RFC trên tiếng Việt. \n\n Bản chất của phương pháp tính t-score là tìm sự khác nhau trong việc sử \n\ndụng từ trong tiếng Anh, chúng em nhận thấy chưa thật sự cần thiết trong \n\nviệc tách từ  làm tăng tính phức tạp của việc tính toán. Do đó, chứng em \n\nchưa áp dụng t-score vào tách từ. \n\n4.4. Tiền xử lý (Pre-processing) \nBởi vì các bài báo điện tử được trình bày dưới dạng html, nên trước khi thực \n\nhiện tách từ để phân loại, chúng em phải xử lý văn bản để lấy ra những nội dung \n\nquan tâm.  \n\n4.4.1. Xử lý văn bản đầu vào \nNội dung tóm tắt của bài báo là rất quan trọng vì nó thể hiện nội dung bài báo \n\nmột cách cô đọng, súc tích, rõ ràng, giúp người xem dự đoán được đề tài của bài \n\nbáo muốn đề cập đến. Chính vì lý do đó, chúng em quyết định thực hiện việc phân \n\nloại tin tức dựa trên phần tóm tắt của bài báo để tiết kiệm thời gian xử lý và đạt \n\nđược kết quả chính xác cao. \n\nTrong mỗi văn bản, khối tiền xử lý sẽ nhận diện tiêu đề, tóm tắt\u2026 của bài báo \n\nbằng cách dựa vào thông tin định dang của các thẻ trong trang html. Theo khảo sát \n\ncủa chúng em về cấu trúc hiển thị nội dung trang báo điện tử ở các trang web tin tức \n\nở Việt Nam, tác giả luôn trình bày nội dung tóm tắt (abstract) của bài báo trước bài \n\nviết chi tiết, nên hướng phân loại dựa trên tóm tắt của bài báo là khả thi.  \n\n\n\n \n  \n\n \n\n 50 \n\n \n\nHình 4. 1. Nội dung thông tin cần lấy \n\nSau khi rút trích được nội dung cần thiết, chúng em tiếp tục thực hiện tách ngữ, \n\nphục vụ cho công việc tách từ. \n\n4.4.2. Tách ngữ & tách stopwords \nTách ngữ: Ứng với mỗi văn bản đã rút trích từ trang web, chúng em tiến hành \n\nloại bỏ các ký hiệu, các chữ số không cần thiết, sau đó, phân tích văn bản thành các \n\nngữ phân cách bởi dấu câu.  \n\nTách stopword: Nhằm làm tăng tốc độ tính toán của GA và lượt bớt các từ \n\nkhông có nghĩa phân loại trong câu, chúng em có thử nghiệm tách stopword trước \n\nkhi tiến hành tách từ. Bước tách stopword tỏ ra khá hiệu quả trong việc làm tăng tốc \n\nđộ GA nhờ chia nhỏ các ngữ ra thành những ngữ nhỏ hơn. Tuy nhiên, cách tách \n\nstopword không phải lúc nào cũng cho kết quả như mong đợi bởi vì tách stopword \n\ntrước khi tách từ sẽ có nhiều khả năng làm sai lạc ý nghĩa của câu, ảnh hưởng đến \n\nviệc phân loại sau đó. Do đó, chúng em đã thử nghiệm việc tách stopword sau khi \n\n\n\n \n  \n\n \n\n 51 \n\nđã tách từ,  kết quả phân loại sau khi đã loại bỏ stopword là khả quan hơn cách thực \n\nhiện ban đầu. (Xin xem chương 6 để biết kết quả thực nghiệm.) \n\n4.5. Hướng tiếp cận tách từ dựa trên thống kê từ Internet  và \nthuật toán di truyền (Internet and Genetic Algorithm-based ) \n\nChúng em xây dựng hai công cụ hỗ trợ cho việc tách từ gồm: công cụ trích xuất \n\nthông tin từ Google và công cụ tách từ dùng thuật toán di truyền. \n\n4.5.1. Công cụ trích xuất thông tin từ Google \n\n4.5.1.1. Mục đích \nNgày nay, cùng với sự phát triển nhanh chóng của các công nghệ thông tin hiện \n\nđại, Internet đã trở thành một thư viện tuyệt vời với một khối lượng văn bản đồ sộ. \n\nDo đó, việc khai thác thông tin từ world-wide-web như một tập ngữ liệu khổng lồ \n\ncho các công trình nghiên cứu sẽ rút ngắn được thời gian và công sức tự xây dựng \n\nmột tập ngữ liệu riêng. Với sự giúp sức của công cụ tìm kiếm miễn phí trên mạng, \n\nnhững thông tin cần thiết sẽ được lấy về một cách nhanh chóng và chính xác. Chúng \n\nem chọn Google là công cụ tìm kiếm chính bởi vì những ưu thế về tính nhanh \n\nchóng, chính xác, và phổ biến của nó so với các công cụ tìm kiếm khác.  \n\nTrong luận văn này, chúng em cần hai loại thông tin: \n\n Tần số xuất hiện của các văn bản chứa các từ (document frequency) trên các \n\ntrang web để làm tính công thức MI, dự đoán khả năng tồn tại của một từ là \n\nđúng hay không \n\n Tần số các văn bản chứa  từ với từ khóa đại diện cho chủ đề dùng để tính \n\nmức độ liên quan của từ với các chủ đề cần phân loại. \n\nDo vây, nhiệm vụ của công cụ trích xuất thông tin từ Google sẽ lấy kết quả tìm \n\nkiếm của Google, trả về cho chương trình khi chúng ta đưa yêu cầu tìm kiếm. \n\n\n\n \n  \n\n \n\n 52 \n\n4.5.1.2. Các công thức tính xác suất và độ tương hỗ \n\n4.5.1.2.1. Các công thức tính xác suất \nKhi nhận được kết quả trả về, dựa vào nền tảng của các công trình nghiên cứu về \n\nthống kê trên Internet của Rudi & Paul (2005), chúng em sẽ sử dụng các công thức \n\nsau đây để tính toán chỉ số MI. \n\nCác công thức tính xác suất các từ xuất hiện trên Internet :  \n\n Gọi count(w) là số lượng trang web chứa từ w \n\ncount(w1 & w2) là số trang web chứa đồng thời w1 và w2 \n\n ( )(w)= count wp\nMAX\n\n \n\n 1 21 2\n( & )( & ) count w wp w w\n\nMAX\n=    \n\n Trong đó, MAX = 4 * 109;  \n\n4.5.1.2.2. Các công thức tính độ tương hỗ (Mutual Information \u2013 MI) \nĐối với hướng tiếp cận N-Gram để tách từ, công thức MI để tính toán khả năng \n\ntồn tại một ngữ cần tách trong câu là rất quan trọng. Độ tương hỗ (Mutual \n\nInformation) cho biết thông tin phụ thuộc lẫn nhau của các từ ghép được cấu tạo bởi \n\nn tiếng (cw = w1 w2 \u2026 wn) . Đối với từ một tiếng, ta quy ước MI = p(w). Đối với từ \n\nghép từ 2 tiếng trở lên, chúng em thử nghiệm 3 cách tính MI  để tìm ra các tính hiệu \n\nquả nhất.  \n\n MI theo cách tính của IGATEC [H. Nguyen et al, 2005] ) (đã được trình bày \n\nở mục 4.3.2.1.) \n\n 1 2\n\n1 2\n1\n\n(  &   &  ... &  ) ( ) = \n( ) -  (  &   &  ... &  )  \n\nn\nn\n\nj n\nj\n\np w w wMI cw\np w p w w w\n\n=\n∑\n\n (2) \n\n MI theo cách tính của [Ong & Chen, 1999] (đã được trình bày ở mục \n\n4.3.2.1.) \n\n Giả sử ta có   \n\n cw = p( w1 & w2 ...& wn-1 )  \n\n lw = p( w1 & w2 ...&  wn-1 ) \n\n\n\n \n  \n\n \n\n 53 \n\n rw = p ( w2 & w3 ...& wn) \n\n 1 2\n1 2\n\n( & &  ... & ) ( ) = \n( ) ( ) ( & &  ... & )\n\nn\n\nn\n\np w w wMI cw\np lw p rw p w w w+ −\n\n (3) \n\n MI do chúng em đề nghị: \n\n Giả sử ta có   \n\n cw = p( w1 & w2 ...& wn-1 )   \n\n Với n chẵn : lw = p( w1 & w2 ...&  wn/2 ),  rw = p ( wn/2+1 & \n\nwn/2+2 ...& wn) \n\n Với n lẻ: lw = p( w1 & w2 ...&  wn-1 ) , rw = p ( w2 & w3 ...& wn) \n\n 1 2\n1 2\n\n( & &  ... & ) ( ) = \n( ) ( ) ( & &  ... & )\n\nn\n\nn\n\np w w wMI cw\np lw p rw p w w w+ −\n\n  (4) \n\nChúng ta sẽ sử dụng các công thức trên để tính độ thích nghi của các cá thể \n\ntrong thuật toán di truyền dưới đây. Kết quả của mỗi công thức tính MI sẽ ưu tiên \n\ncho những loại từ ghép khác nhau  mà ta sẽ hiểu rõ hơn trong kết quả thực nghiệm ở \n\nchương 6.  \n\n4.5.2. Công cụ tách từ dùng thuật toán di truyền (Genetic Algorithm \u2013 \nGA) \n\nMục đích của chúng ta là tìm ra các cách tách từ hợp lý nhất cho văn bản, tuy \n\nnhiên, chúng ta gặp phải trở ngại là không gian tìm kiếm (search space) quá lớn do \n\nsự bùng nổ tổ hợp khi sinh ra dãy các từ. Như chúng ta đều biết, thuật toán di truyền \n\n(Genetic Algorithm \u2013 GA) được biết đến với khả năng duyệt tắt qua những không \n\ngian tìm kiếm lớn một cách hiệu quả và đưa ra những giải pháp toàn cục tối ưu nhất. \n\nGA thực hiện tiến hoá một số thế hệ để tạo ra một quần thể gồm những cá thể tối ưu \n\nnhờ vào các bước lai ghép (cross-over), đột biến (mutation), sinh sản \n\n(reproduction), và cách chọn lựa cá thể. Chất lượng của mỗi cá thể được tính toán \n\ndựa trên chỉ số fitness cho mỗi cá thể và quần thể. Trong quá trình thử nghiệm, \n\nchúng em chọn top N cá thể chất lượng nhất sau khi thực hiện các bước lai ghép, \n\nđột biến, sinh sản. \n\n4.5.2.1. Khảo sát độ dài của \u201ctừ\u201d trên từ điển \n\n\n\n \n  \n\n \n\n 54 \n\nNhư chúng ta đều biết, thuật toán di truyền đòi hỏi phải có rất nhiều tham số cho \n\ncác bước thực hiện như số cá thể trong quần thể, số thế hệ tiến hoá, tỉ lệ lai ghép, tỉ \n\nlệ đột biến\u2026 Do vậy, chất lượng lựa chọn các tham số trên sẽ quyết định kết quả \n\ncủa thuật toán di truyền. Chính vì tính chất quan trọng của các tham số, chúng em \n\nthực hiện một khảo sát nhỏ về số lượng từ tương ứng với chiều dài từ trên từ điển \n\nthông dụng tại http://dict.vietfun.com để làm cơ sở cho các tham số sau này. \n\n \n\nĐộ dài từ (tiếng) Tần số xuất hiện Tỉ lệ \n\n1 8933 12.2 \n\n2 48995 67.1 \n\n3 5727 7.9 \n\n4 7040 9.7 \n\n≥ 5 2301 3.1 \n\nTổng cộng 72994 100 \n\nBảng 4. 1. Thống kê độ dài từ trong từ điển \n\nCó một điều cần lưu ý là tại thời điểm này, chúng ta vẫn chưa có một từ điển \n\nchuẩn nào được dùng cho việc xử lý ngôn ngữ, do đó, chúng em quyết định dùng \n\nloại từ điển phổ dụng để thống kê. Theo kết quả thống kê, trên 67% là từ ghép hai \n\ntiếng, còn lại khoảng 30% là các từ ghép một, ba, bốn tiếng. Các cụm từ dài hơn \n\nbốn tiếng chiếm khoảng 3%, tuy nhiên các cụm từ đó đa số là các câu thành ngữ của \n\nViệt Nam. \n\nKết quả thống kê trên có ý nghĩa rất quan trọng đối với công cụ tách từ bằng GA \n\ncủa chúng em. Dựa trên tỉ lệ của các loại từ,  chúng em thực hiện việc khởi tạo cá \n\nthể ngẫu nhiên có thêm thông tin về xác suất xuất hiện của từ và đó là cơ sở để \n\nchúng em quyết định cách tách từ phù hợp với thực tế của tiếng Việt. Chi tiết về các \n\nứng dụng của kết quả khảo sát sẽ được chúng em trình bày ở các phần sau.  \n\n4.5.2.2. Khởi tạo quần thể \n\n\n\n \n  \n\n \n\n 55 \n\n4.5.2.2.1. Biểu diễn cá thể \nGiả sử văn bản đầu vào t được tạo thành bởi n tiếng (syllables) như sau: \n\nt=s1s2...sn . Mục đích của quá trình chạy GA là tìm ra cách tách từ có độ chấp nhận \n\ncao nhất : t=w1w2\u2026wm , với wk= si\u2026 sj (1 ≤ k ≤ m, 1  ≤  i,j ≤ n) \n\nTương tự như IGATEC, chúng em cũng biểu diễn mỗi cá thể (id) trong quần thể \n\n(pop) bởi chuỗi các bit 0,1, trong đó, mỗi bit đại diện cho một tiếng trong văn bản, \n\nmỗi nhóm bit cùng loại đại diện cho một từ (word).  \n\nVí dụ: Với câu \u201cNhững || con || khủng long || trong || phim hoạt hình || rất || ngộ \n\nnghĩnh\u201d, chúng em sẽ biểu diễn dưới dạng các bit 0, 1 như sau: \n\n \n\n \n\nHình 4. 2. Biểu diễn cá thể bằng các bit 0,1  \n\n4.5.2.2.2. Khởi tạo các tham số \nỞ bước khởi tạo tham số, ta phải thiết lập một vài tham số cơ bản cho GA như \n\nsố thế hệ   tiến hoá (generations), kích thước quần thể (population size), tỉ lệ lai \n\nghép (reproduction fraction)\u2026 Ngoài ra, vì mỗi cá thể của chúng ta là một thể hiện \n\ncách tách từ trong câu, nên ta sẽ lợi dụng tính chất liên kết của các từ để thực hiện \n\nkhởi tạo cá thể ngẫu nhiên ban đầu. Tính chất liên kết của từ được thể hiện qua tỉ lệ \n\ncủa các từ trong từ điển, nên ta sẽ có thêm tham số về khả năng xuất hiện từ trong \n\ncâu ở bảng tham số dưới đây. \n\n\n\n \n  \n\n \n\n 56 \n\n \n\nTham số Giá trị \n\nSố thế hệ tiến hoá  100 \n\nKích thước quần thể  50 \n\nTỉ lệ lai ghép  95% \n\nTỉ lệ đột biến  5% \n\nTop N cá thể được chọn  100 \n\nTỉ lệ từ 1 tiếng (mono-gram) 10% \n\nTỉ lệ từ 2 tiếng (bigram) 70% \n\nTỉ lệ từ 3 tiếng (trigram) 10% \n\nTỉ lệ từ 4 tiếng (quadgram) 10% \n\nBảng 4. 2. Tham số thực hiện GA \n\n4.5.2.2.3. Khởi tạo cá thể \nNhư chúng ta đều biết, quy tắc của  thuật toán di truyền là thực hiện tiến hoá các \n\ncá thể qua các thế hệ nhằm đạt đến độ hội tụ của chỉ số thích nghi (sẽ được nói rõ ở \n\nmục 4.5.2.3). Nếu cá thể được khởi tạo ngẫu nhiên sẽ có độ thích nghi thấp, chúng \n\nta phải tiến hoá qua rất nhiều thế hệ để đạt đến độ hội tụ cần thiết. Và hậu quả là số \n\nthế hệ tiến hoá càng nhiều thì thời gian tiêu tốn và chi phí tính toán càng cao. Giải \n\npháp khắc phục nhược điểm trên là khởi tạo một số cá thể ban đầu gần với điểm hội \n\ntụ, nhờ vậy có thể rút ngắn được số thế hệ tiến hoá, tăng tốc độ. Ở bước khởi tạo \n\nquần thể, chúng em tạo ra cá các thể bằng hai cách: khởi tạo ngẫu nhiên và khởi tạo \n\ndựa trên phương pháp MM:forward/backward [Chih-Hao Tsai, 2000]. \n\n4.5.2.2.3.1. Khởi tạo cá thể ngẫu nhiên  \nTheo thống kê ở bảng 4.1, chúng em quyết định đặt ra một số giới hạn cho việc \n\ntạo cá thể ngẫu nhiên. Đầu tiên, tất cả các từ ghép wk tạo ra có độ dài không quá 4. \n\n\n\n \n  \n\n \n\n 57 \n\nThứ hai, chúng em khởi tạo ngẫu nhiên các cá thể có số lượng từ tương ứng với tỉ lệ \n\nvề độ dài từ ở trên, nhằm tạo ra điểm xuất phát tốt cho quá trình thực hiện GA. \n\nVí dụ: Giả sử ta có câu đầu vào \u201cNhững con khủng long trong phim hoạt hình \n\nrất đáng yêu\u201d gồm 11 tiếng. Theo các tham số khởi tạo của bảng 4.2., chúng em \n\nthiết lập giới hạn tạo từ ngẫu nhiên trong câu:  \n\n \n\n Hình 4. 3. Thang tỉ lệ phát sinh loại từ \n\nMột bộ phát sinh ngẫu nhiên sẽ phát sinh xác suất f  (0 ≤ f ≤ 1) để chọn loại từ: \n\n Nếu 0 ≤ f < 0.1 :  phát sinh loại từ 1 tiếng \n\n Nếu 0.1 ≤ f < 0.8 :  phát sinh loại từ 2 tiếng \n\n Nếu 0.8 ≤ f < 0.9 :  phát sinh loại từ 3 tiếng \n\n Nếu 0.9 ≤ f ≤ 1: phát sinh loại từ 4 tiếng \n\n4.5.2.2.3.2. Khởi tạo cá thể bằng Maximum Matching : \nforward/backward  \n\n(Phương pháp Maximum Matching : forward/backward [Chih-Hao Tsai, 2000] \n\nđã được trình bày ở mục 3.2.1.)  \n\nĐây là bước khởi tạo rất quan trọng và điểm cải tiến đáng kể so với IGATEC. \n\nChúng em chọn phương pháp MM: forward/backward để khởi tạo cá thể ban đầu vì \n\nđộ chính xác khá cao của phương pháp này sẽ tạo ra cá các thể gần đúng nhất, giúp \n\ntăng tốc quá trình tiến hoá. Ngoài ra, việc áp dụng phương pháp MM theo dạng đơn \n\ngiản chỉ cần duyệt tuyến tính, sẽ giảm thiểu được chi phí và thời gian tính toán so \n\nvới các phương pháp khác.  \n\nChúng em thực hiện tách từ theo hai hướng từ trái sang phải, và từ phải sang \n\ntrái. Nếu hai cách tách từ trên trùng nhau, chúng em sẽ chọn một và gộp vào các cá \n\nthể đã được phát sinh ngẫu nhiên ở trên. \n\n\n\n \n  \n\n \n\n 58 \n\nSau khi khởi tạo xong, quần thể sẽ được tiến hóa qua các quá trình lai ghép, đột \n\nbiến, sinh sản,    \n\n4.5.2.3. Thực hiện tiến hoá \n\n4.5.2.3.1. Quá trình lai ghép (cross-over) \nChúng em áp dụng phương pháp chuẩn của lai ghép là dựa trên một điểm ngẫu \n\nnhiên trong chuỗi bit của cá thể. Khi có một cặp cá thể bố mẹ , thế hệ con được tạo \n\nra dựa trên sự kết hợp từ phần đầu tiên của bố với phần cuối của mẹ và ngược lại. \n\nTuy nhiên, trong quá trình lai ghép, chúng em nhận thấy giới hạn từ ghép tối đa 4 \n\ntiếng có thể bị phá vỡ, do đó, đối với những phân đoạn wk nào có độ dài hơn chúng \n\nem sẽ thực hiện việc chuẩn hóa từ vị trí đó đến cuối sao cho không có một từ nào \n\nvượt quá 4 tiếng. \n\nVí dụ:  \n\n \n\nHình 4. 4.Quá trình lai ghép \n\n4.5.2.3.2. Quá trình đột biến (mutation) \nThay vì thực hiện phương pháp bật tắt bit (bit flip), chúng em thực hiện việc \n\nhoán chuyển vị trí của hai bit liền nhau tại một vị trí ngẫn nhiên. Ý tưởng thực hiện \n\n\n\n \n  \n\n \n\n 59 \n\nđột biến như thế này bởi vì, trong việc phân định ranh giới từ, ta dễ dàng nhận ra \n\nrằng một tiếng nếu kết hợp với tiếng trước không phù hợp thì có thể kết hợp với từ \n\nđứng sau sẽ phù hợp hơn, hoặc là đứng một mình. Tương tự như phần lai ghép, \n\nchúng em thực hiện chuẩn hoá các cá thể sau khi đột biến. \n\nVí dụ: \n\n \n\nHình 4. 5. Quá trình đột biến \n\n4.5.2.3.3. Quá trình sinh sản (reproduction) \nSau khi lai ghép và đột biến, chúng em kết hợp các cá thể bố mẹ với cá thể con \n\nvừa được tạo ra để phục vụ cho bước chọn cá thể. Sau khi kết hợp, chúng em lọc bỏ \n\ncác cá thể trong quần thể, để đạt được nhiều cách tách từ tốt. Ví dụ:  \n\n \n\nHình 4. 6. Quá trình sinh sản \n\n\n\n \n  \n\n \n\n 60 \n\n4.5.2.3.4. Quá trình chọn cá thể (selection) \nỞ mỗi thế hệ, chúng em chỉ chọn top N cá thể từ quá trình sinh sản ở trên. Trước \n\ntiên, các cá thể sẽ được tính độ thích nghi (fitness) chính là tổng giá trị MI của các \n\ntừ được tách trong câu. Sau đó, quần thể sẽ được sắp xếp theo giá trị của độ thích \n\nnghi giảm dần, quá trình chọn lọc cá thể sẽ chọn top N cá thể có độ thích nghi cao \n\nnhất để tạo nên quần thể tiếp tục tiến hoá ở các thế hệ sau. \n\nCách thức lựa chọn cá thể như sau: \n\n1 2 m k\n1\n\n( ) (w w ...w ) (w )\nm\n\nk\nfit id fit MI\n\n=\n\n= =∑  \n\n1\n( ) ( )\n\nN\n\ni\ni\n\nfit pop fit id\n=\n\n=∑  \n\nTrong đó, id = w1w1... w1 là một cá thể trong quần thể pop = {id1, id2} \n\nVí dụ:  \n\n \n\nHình 4. 7. Quá trình chọn cá thể \n\nCó thể nói đây là quá trình quan trọng nhất trong cả tiến trình tiến hoá vì sự lựa \n\nchọn cá thể ở bước này sẽ quyết định cá thể tiến hoá có tốt hay không. Ở quá trình \n\nchọn lọc cá thể này, chúng em đã thử nghiệm một số công thức tính độ tương hỗ \n\n(Mutual Information) như đã trình bày ở trên, và thu được các kết quả khác nhau \n\nkhi sử dụng các công thức khác nhau. Từ đó, chúng em rút ra một số kết luận và \n\nnhận xét quan trọng về ưu khuyết điểm của các công thức MI. \n\n Kết quả thực nghiệm và nhận xét về các công thức MI sẽ được chúng em trình \n\nbày ở chương 6. \n\n\n\n \n  \n\n \n\n 61 \n\n4.5.2.3.5. Độ hội tụ (convergence) \nQuá trình thực hiện GA cố gắng làm tăng độ thích nghi (fitness) của mỗi cá thể \n\ncũng đồng nghĩa với việc tăng chất lượng của từ được tách. Ở mỗi thế hệ tiến hoá, \n\nchỉ số thích nghi của quần thể sẽ tăng dần đến một ngưỡng gọi là độ hội tụ α. Khi \n\nđó, độ chênh lệnh chỉ số thích nghi của quần thể giữa hai thế hệ sẽ nhỏ dần và tiến \n\ndần đến 0. Vì vậy, chúng em thực hiện việc ngừng GA một cách tự động khi giá trị \n\nfitness của các thế hệ đạt đến độ hội tụ có chỉ số α = 10-7 hoặc số thế hệ đạt đến số \n\nlượng mặc định đã trình bày ở trên.  \n\nViệc ngừng GA tự động sẽ giúp chúng ta giảm thiểu thời gian và chi phí tính \n\ntoán không cần thiết, đồng thời là tăng tốc độ của việc tách từ. \n\n4.6. Kết luận \nPhương pháp tách từ dựa trên thống kê Internet và thuật toán di truyền tương đối \n\nđơn giản hơn các phương pháp khác và tỏ ra khá linh hoạt với sự biến động của \n\nngôn ngữ trong tin tức điện tử. Ngoài ra, đây là hướng tiếp cận khá mới mẻ, hạn chế \n\nđược khuyết điểm cơ bản của các phương pháp tách từ lâu nay là dựa trên tập ngữ \n\nliệu đã đánh dấu và từ điển chuyên biệt. Với ưu điểm là thuật toán đơn giản, dễ \n\nhiểu, dễ cài đặt, nhưng phương pháp IGATEC vẫn cho một kết quả tách từ chấp \n\nnhận được, có thể dùng trong phân loại văn bản.  \n\n\n\n \n  \n\n \n\n 62 \n\n  \n\nCChhưươơnngg  55  \n\nBBÀÀII  TTOOÁÁNN  PPHHÂÂNN  LLOOẠẠII  \n\nTTIINN  TTỨỨCC  ĐĐIIỆỆNN  TTỬỬ  \n \n\n \n\nLý do chọn phương pháp Naïve Bayes \n\nThuật toán Naïve Bayes \n\nCông thức xác suất đầy đủ Bayes \n\nTính độc lập có điều kiện (Conditional Independence) \n\nNguồn gốc Naïve Bayes \n\nNaïve Bayes trong phân loại văn bản \n\nHai mô hình sự kiện trong phân loại văn bản bằng Naïve \n\nBayes \n\nBài toán phân loại tin tức điện tử tiếng Việt \n\nKết quả \n\n \n\n\n\n \n  \n\n \n\n 63 \n\nChương 5. BÀI TOÁN PHÂN LOẠI TIN TỨC ĐIỆN TỬ \nNhằm tận dụng phương pháp tách từ  IGATEC đã được đề cập ở chương trên, \n\ntrong chương này chúng em sẽ giới thiệu cách phân loại tin tức điện tử tự động sử \n\ndụng phương pháp Naïve Bayes và giải thích sự phù hợp của Naïve Bayes với \n\nphương pháp tách từ IGATEC. \n\n5.1. Lý do chọn phương pháp Naïve Bayes \n Như đã được giới thiệu trong chương 2, Naïve Bayes là một phương pháp rất \n\nphổ biến sử dụng xác suất có điều kiện giữa từ và chủ đề để xác định chủ đề của văn \n\nbản. Các xác suất này dựa trên việc thống kê sự xuất hiện của từ và chủ đề trong tập \n\nhuấn luyện. Tập huấn luyện lớn có thể mang lại kết quả khả quan cho Naïve Bayes. \n\nInternet với hơn 10 tỷ trang web là một tập huấn luyện rất phong phú về mọi chủ đề \n\ntrong cuộc sống. Hơn nữa, với số lượng chủ đề tin tức điện tử không nhiều (khoảng \n\n20 chủ đề) thì việc sử dụng Internet như cơ sở dữ liệu  huấn luyện rất phù hợp. \n\nTrong báo chí, với mỗi chủ đề luôn có các từ chuyên môn với tần số xuất hiện rất \n\ncao, việc tận dụng tần số phụ thuộc của các từ này vào chủ đề có thể đem lại kết quả \n\nkhả quan cho phân loại.  \n\nVới dữ liệu được tạo ra nhờ công cụ tách từ GA và trích xuất thông tin từ \n\nGoogle, theo đánh giá của chúng em, thì phương pháp Naïve Bayes là khá phù hợp \n\nvì các dữ liệu đầu vào cho hướng phân loại này hoàn toàn phù hợp với dữ liệu hiện \n\ncó. Điều này sẽ giúp chúng em tiết kiệm được rất nhiều thời gian và công sức tạo \n\nthêm nhiều tập dữ liệu nếu chọn phương pháp phân loại khác. \n\nMặt khác, phương pháp Naïve Bayes là phương pháp khá cổ điển được sử dụng \n\nđầu tiên bởi Maron vào năm 1961 [Maron, 1961], và sau đó rất phổ biến trong các \n\nlãnh vực tìm kiếm, lọc mail, các bộ lọc mail\u2026 nên chúng ta có thể tin tưởng về xác \n\nsuất chính xác và các ưu khuyết điểm của phương pháp này để áp dụng phù hợp. \n\nMột lý do nữa mà chúng em chọn Naïve Bayes bởi phương pháp đơn giản, tốc \n\nđộ nhanh, cài đặt tương đối không quá phức tạp phù hợp với thời gian cho phép của \n\nluận văn. Chúng em không sử dụng kNN, do tập dữ liệu thử nghiệm hiện có là tập \n\n\n\n \n  \n\n \n\n 64 \n\ncác tin tức vắn tắt lấy ngẫu nhiên từ trang VnExpress.net còn khá nhỏ (dưới 1000). \n\nTrong khi đó để có thể sử dụng phương pháp kNN hiệu quả số lượng chủ đề và dữ \n\nliệu thử nghiệm phải lớn hơn nhiều. SVM tuy là một phương pháp được cho là có \n\nhiệu suất cao, nhưng thời gian huấn luyện lại rất lâu. Nnet lại cài đặt quá phức tạp. \n\nVới những lý do trên, chúng em đề xuất chọn phương pháp Naïve Bayes để phân \n\nloại văn bản. \n\n5.2. Thuật toán Naïve Bayes \nTheo tác giả Mitchell (2005), thuật toán phân loại Naïve Bayes có đặc điểm nổi \n\nbật là có khả năng giảm độ phức tạp tính toán từ 2(2n \u2013 1)  về còn 2n. Thế đặc điểm \n\nnào giúp Naïve Bayes có khả năng đó?  \n\n5.2.1. Công thức xác suất đầy đủ Bayes \nGiả sử ta muốn tính toán một hàm không biết giá trị đích :f X Y→  tương \n\nđương với P(Y|X). \n\nĐầu tiên, ta cho rằng Y là biến ngẫu nhiên có giá trị luận lý (boolean). \n\nX là vector gồm n thuộc tính luận lý (boolean), 1 2, ,..., nX X X X= 〈 〉  \n\nÁp dụng luật Bayes, P(Y=yi|X) được tính như sau: \n\n ( | ) ( )( | )\n( | ) ( )\n\nk i i\ni k\n\nk j i\nj\n\nP X x Y c P Y yP Y y X x\nP X x Y c P Y y\n\n= = =\n= = =\n\n= = =∑\n (2.1) \n\nTrong đó P(X|Y) và P(Y) được học từ tập huấn luyện. Tuy nhiên để tính toán \n\nchính xác P(X|Y) thường đòi hỏi rất nhiều dữ liệu huấn luyện. Để hiểu tại sao, \n\nchúng ta sẽ tính toán số lượng tham số cần thiết khi Y là biến boolean, X là vector \n\ngồm n thuộc tính boolean : \n\n( | )ij i jP X x Y yθ = = =  \n\nTrong i phải dựa trên 2n giá trị có thể cho những giá trị của vector X và j cần 2 \n\ngiá trị. Do đó, chúng ta cần tính toán khoảng 2n+1 tham số. Mặc khác, ta phải đảm \n\nbảo \n1\n\n1\nn\n\nij\ni\nθ\n\n=\n\n=∑ cho bất kỳ j cố định nào. Vì vậy, ứng với một giá trị đặc biệt yj, và 2n \n\n\n\n \n  \n\n \n\n 65 \n\ngiá trị có thể của xi, chúng ta chỉ cần tính toán 2n -1 tham số độc lập. Dựa trên giá trị \n\ncủa Y (Y là biến boolean), chúng ta cần tính tổng cộng là 2(2n -1) tham số θij . \n\n5.2.2. Tính độc lập có điều kiện (Conditional Independence) \nĐịnh nghĩa: cho các biến ngẫu nhiên X, Y và Z, chúng ta nói rằng X là độc lập có \n\nđiều kiện với Y gây ra Z, nếu và chỉ nếu xác suất phân phối chủ đạo X là độc lập với \n\ngiá trị của Y  gây ra Z. Lúc đó: \n\n( , , ) ( | , ) ( | )i j k i ki j k P X x Y y Z z P X x Z z∀ = = = = = =  \n\nVí dụ: ta xem ba biến luận lý (boolean) ngẫu nhiên trên đại diện cho các trạng \n\nthái của thời tiết là : Sấm , Mưa, và Sét. Chúng ta đều biết rằng sự kiện Sấm xảy ra \n\nhoàn toàn độc lập với sự kiện Mưa gây ra Sét. Bởi vì khi có Sét sẽ gây ra tiếng Sấm, \n\nnên một khi chúng ta biết rằng có Sét hay không thì ta có thể biết được giá trị của \n\nSấm mà không cần thêm thông tin nào từ Mưa. Trên thực tế, rõ ràng có sự phụ \n\nthuộc giữa Mưa và Sấm, tuy nhiên ta không cần thêm thông tin đó một khi ta đã có \n\nthông tin về Sét. \n\n5.2.3. Nguồn gốc thuật toán Naïve Bayes \nThuật toán phân loại Naïve Bayes dựa trên luật Bayes, với giả định tất cả các \n\nthuộc tính X1\u2026Xn đều độc lập có điều kiện với nhau do sự kiện Y gây ra. Chính giả \n\nthiết này đã đơn giản hóa cách tính của P(X|Y), và vấn đề ước lượng P(X|Y) từ tập \n\nngữ liệu huấn luyện. \n\nChúng ta hãy xét ví dụ sau, giả sử ta có 1 2,X X X= 〈 〉 , lúc đó \n\n1 2\n\n1 2 2\n\n1 2\n\n( | ) ( , | )\n( | , ) ( | )\n( | ) ( | )\n\nP X Y P X X Y\nP X X Y P X Y\nP X Y P X Y\n\n=\n=\n=\n\n \n\nKết quả của dòng thứ nhất là theo cách tính thông thường của xác suất, và dòng \n\nthứ ba là phân tích trực tiếp theo định nghĩa về độc lập có điều kiện. \n\nTừ đó, ta tổng quát hóa lên khi X chứa n thuộc tính đều độc lập với nhau do sự \n\nkiện Y gây ra được biểu diễn như sau: \n\n1\n1\n\n( ... | ) ( | )\nn\n\nn i\ni\n\nP X X Y P X Y\n=\n\n=∏  (2.2) \n\n\n\n \n  \n\n \n\n 66 \n\n Chú ý, khi Y và Xi là biến luận lý (boolean), chúng ta chỉ cần 2n tham số để định \n\nnghĩa P(Xi=xik|Y=yj).  \n\nBây giờ, chúng ta hãy xét đến nguồn gốc của thuật toán Naïve Bayes. Giả sử Y \n\nlà một biến bất kỳ mang giá trị riêng biệt, và các thuộc tính Xi\u2026Xn là thuộc tính rời \n\nrạc hoặc liên tục. Mục đích của chúng ta là huấn luyện để thuật toán phân loại trả ra \n\nsự phân phối xác suất trên các giá trị của Y  đối với mỗi thể hiện X mà ta cần phân \n\nloại. Biểu thức sau đây biểu diễn cho xác suất ứng với giá trị thứ k của Y: \n\n1\n1\n\n1\n\n( ) ( ... | )( | ... )\n( ) ( ... | )\n\nk n k\nk n\n\nj n jj\n\nP Y y P X X Y yP Y y X X\nP Y y P X X Y y\n= =\n\n= =\n= =∑\n\n \n\nTrong đó, tổng giá trị ở mẫu của biểu thức là tổng cho bởi tất cả các giá trị yj của \n\nY. Lúc này, sử dụng công thức (2.2), ta có thể viết lại công thức trên như sau: \n\n1\n\n( ) ( | )\n( | ... )\n\n( ) ( | )\nk i ki\n\nk n\nj i jj i\n\nP Y y P X Y y\nP Y y X X\n\nP Y y P X Y y\n= =\n\n= =\n= =\n∏\n\n∑ ∏\n  (2.3) \n\nCông thức (2.3) là công thức cơ bản của phương pháp phân loại Naïve Bayes. \n\nKhi cho một thể hiện  w 1= ...ne nX X X〈 〉 , theo công thức trên, ta sẽ tính toán được các \n\nxác suất của Y gây ra bởi Xnew bằng cách dựa vào P(Y) và p(Xi|Y) được ước lượng \n\ntừ tập ngữ liệu.Nếu chúng ta chỉ quan tâm đến giá trị lớn nhất của Y, thì sử dụng \n\ncông thức sau: \n\n( ) ( | )\nargmax\n\n( ) ( | )k\nk i ki\n\ny j i jj i\n\nP Y y P X Y y\nY\n\nP Y y P X Y y\n= =\n\n←\n= =\n∏\n\n∑ ∏\n  \n\n5.2.4. Phương pháp Naïve Bayes trong phân loại văn bản \n\n5.2.4.1. Công thức xác suất đầy đủ Bayes \nPhương pháp Naïve Bayes tìm chủ đề của văn bản d bằng các xác định chủ đề có \n\nxác suất P( | )iY c X d= = , xác suất để văn bản d nằm trong lớp ic , lớn nhất thông \n\nqua việc sử dụng công thức xác suất đầy đủ Bayes : \n\n ( | ) ( )( | )\n( | ) ( )\n\ni i\ni\n\nj j\nj\n\nP X d Y c P Y cP Y c X d\nP X d Y c P Y c\n\n= = =\n= = =\n\n= = =∑\n (2.7) \n\n\n\n \n  \n\n \n\n 67 \n\nTrong đó  \n\n jc  là chủ đề thứ j \n\n 1 2( , ,..., )nd w w w=  là văn bản cần phân loại.  \n\n P(Y=ci | X=d) gọi là xác suất xảy ra văn bản d thuộc về chủ đề ci . \n\n P(X=d | Y=ci) gọi là xác suất chủ đề ci có chứa văn bản d trong tập huấn \n\nluyện. \n\nMột cách để xác định ( | )P Y X là sử dụng tập huấn luyện để ước lượng ( | )P X Y  \n\nvà ( )P Y . Sau đó sử dụng công thức xác suất đầy đủ trên để xác định \n\n( | )iP Y c X d= =  với  d  bất kỳ. \n\n5.2.4.2. Uớc lượng P(X|Y) \nGiả sử với mỗi chủ đề, ta có biến cố các từ phụ thuộc vào chủ đề là độc lập có \n\nđiều kiện (conditional independence) với nhau. Ta có công thức của biểu diễn sự \n\nđộc lập có điều kiện của 2 biến cố X,Z vào Y  được trình bày ở 5.2.2 như sau : \n\n( | , ) ( | )P X Y Z P X Z=  \n\nSử dụng giả định trên ta tính được ( | )iP X d Y c= =  : \n\n1 2\n\n1 2\n\n1\n\n( | ) ( , ,.., | )\n( | ) ( | )... ( | )\n\n( | )\n\ni n i\n\ni i n i\nn\n\nj\nj\n\nP X d Y c P w w w Y c\nP w Y c P w Y c P w Y c\n\nP w Y ci\n=\n\n= = = =\n= = = =\n\n= =∏\n\n (2.8) \n\nTừ (2.8), (2.7) được viết lại như sau : \n\n  1 2\n( ) ( | )\n\n( | , ,..., )\n( ) ( | )\n\ni k ik\ni n\n\nj k jj k\n\nP Y c P w Y c\nP Y c w w w\n\nP Y c P w Y c\n= =\n\n= =\n= =\n∏\n\n∑ ∏\n (2.9) \n\nNhờ thống kê trên tập huấn luyện D, ( | )P X Y có thể được ước lượng theo : \n\n \n{ }\n\n{ }\n#\n\n( | )\n#\n\nj i\nj i\n\ni\n\nD X w Y c\nP X w Y c\n\nD Y c\n= ∧ =\n\n= =\n=\n\n (2.10) \n\n\n\n \n  \n\n \n\n 68 \n\nTrong đó \n\n { }# j iD X w Y c= ∧ = : số văn bản trong tập huấn luyện chứa đồng thời wj và ci \n { }# iD Y c= : số văn bản trong tập huấn luyện chứa ci \n\nCông thức ước lượng trên sẽ cho kết quả ( | ) 0j iP X w Y c= = =  khi không có văn \n\nbản chứa đồng thời cả hai (wj và ci). Nhằm tránh trường hợp này, ta nên sử dụng \n\nphép ước lượng đã được làm mịn sau : \n\n \n{ }\n\n{ }\n#\n\n( | )\n#\n\nj i\nj i\n\ni\n\nD X w Y c l\nP X w Y c\n\nD Y c lR\n= ∧ = +\n\n= =\n= +\n\n (2.11) \n\nVới  \n\n R : số lượng chủ đề \n\n l : quyết định độ mịn của phép ước lượng \n\n5.2.4.3. Ước lượng P(Y)  \nViệc ước lượng P(Y=ci) đơn giản là tính phần trăm số văn bản trong tập huấn \n\nluyện có chủ đề ci : \n\n { }#( ) ii\nD Y c\n\nP Y c\nD\n=\n\n= =  (2.12) \n\n5.2.5. Hai mô hình sự kiện trong phân loại văn bản bằng phương pháp \nNaïve Bayes \n\n5.2.5.1. Giới thiệu \nPhân loại văn bản là một lĩnh vực có phạm vi thuộc tính (attribute) rất nhiều bởi \n\nvì thuộc tính của những văn bản cần phân loại là từ (word), mà số lượng từ khác \n\nnhau thì vô cùng lớn. Và thuật toán Naïve Bayes đã thành công trong việc ứng dụng \n\nvào lĩnh vực phân loại với khả năng làm giảm độ phức tạp trên. Mặc dù đây là thuật \n\ntoán khá phổ biến, nhưng trong cộng đồng phân loại văn bản vẫn có một vài điều \n\nlẫn lộn về phương pháp phân loại Naïve Bayes bởi vì có hai mô hình phát sinh khác \n\nnhau vẫn thường được sử dụng. Cả hai mô hình đều sử dụng \u201cnaïve Bayes \n\nassumption\u201d và cả hai đều được giới phân loại gọi là \u201cnaïve Bayes\u201d. \n\n \n\n\n\n \n  \n\n \n\n 69 \n\n5.2.5.2. Mô hình đa biến trạng Bernoulli (Multi-variate Bernoulli Model) \nMột mô hình biểu diễn một văn bản là một vector có thuộc tính nhị phân cho \n\nbiết rằng từ nào có hay không xuất hiện trong văn bản. Số lần xuất hiện của một từ \n\ntrong văn bản là không cần thiết. Ở đây chúng ta có thể hiểu rằng văn bản là sự kiện \n\n(event) và sự có mặt hay vắng mặt của các từ trở thành thuộc tính của sợ kiện. Đấy \n\nchính là mô hình sự kiện đa biến trạng Bernoulli (multi-variate Bernoulli event \n\nmodel), một mô hình khá truyền thống, đã được nhiều người sử dụng trong phân \n\nloại văn bản. Theo McCallum & Nigam (1998), một số công trình tiêu biểu về \n\nhướng tiếp cận này là Robertson & Sparck-Jones (1976), Lewis(1992), Kalt & Croft \n\n(1996), Larkey & Croft (1996), Koller & Sahami (1997), Sahami (1996).  \n\n5.2.5.3. Mô hình đa thức (Multinomial Model) \nMô hình thứ hai cho rằng một văn bản đại diện tập hợp tần số xuất hiện của từ \n\ntrong văn bản. Do đó, thứ tự xuất hiện của từ được bỏ qua nhưng tần số xuất hiện \n\nđược giữ lại. Ở đây, chúng ta có thể hiểu rằng những tần số xuất hiện của các từ là \n\nnhững sự kiện (events) và văn bản trở thành tập hợp các sự kiện của từ (word \n\nevents). Chúng ta gọi đây là sự kiện mô hinh đa thức (Multinomial event model). \n\nĐây là hướng tiếp cận thông thường trong mô hình ngôn ngữ học thống kê. Hướng \n\ntiếp cận này cũng được rất nhiều người sử dụng mà theo McCallum & Nigam \n\n(1998) các công trình tiêu biểu như Lewis & Gale (1994), Kalt & Croft (1996), \n\nJoachims (1997), Mitchell (1997), McCallum et al (1998)\u2026 \n\n5.2.5.4. Nhận xét \nĐối với phương pháp multi-variate model, việc không nắm bắt thông tin tần số \n\nxuất hiện của từ có thể đưa đến khuyết điểm không phân biệt được văn bản ưu tiên \n\ncho chủ đề nào hơn nếu cả 2 văn bản đều xuất hiện cùng một từ nào đó nhưng tần \n\nsố lại khác nhau rất nhiều. Ví dụ, nếu từ \u201cthể thao\u201d sẽ xuất hiện nhiều trong các tin \n\ntức về thể thao, và sẽ ít xuất hiện trong các tin tức có nội dung khác, nhưng do \n\nphương pháp multi-variate không sử dụng thông tin tần số nên không phân biệt \n\nđược văn bản ưu tiên cho thể thao hơn.  Trong khi đó, hướng tiếp cận multinomial \n\nmodel rõ ràng đã sử dụng thông tin về xác suất phân phối từ trong văn bản. \n\n\n\n \n  \n\n \n\n 70 \n\nĐối với phương pháp mulnomial, do sử dụng tần số xuất hiện của từ nên sẽ phụ \n\nthuộc vào chiều dài văn bản, vì tài liệu càng dài, sự xuất hiện của các từ càng nhiều. \n\nTheo kết quả đạt được của thí nghiệm so sánh giữa hai phương pháp Naïve \n\nBayes trên, McCallum & Nigam (1998) đã đưa ra kết quả là hướng tiếp cận đa biến \n\ntrạng thực hiện tốt với kích thước từ vựng nhỏ (<500 từ), còn phương pháp mô hình \n\nđa thức thường cho kết quả tốt hơn đối với kích thước từ vựng lớn (>500 từ). \n\n5.3. Bài toán phân loại tin tức điện tử tiếng Việt \n\n5.3.1. Quy ước \n Với mỗi văn bản d , sau khi sử dụng GA để loại bỏ dấu câu và stopword, ta thu \n\nđược d được tách thành nhiều ngữ g dưới dạng sau d={g1,g2,\u2026, gm} , với gi là tập \n\nhợp gồm n cách tách của một ngữ, gi =  {ti1,ti2,\u2026,tin} trong đó tij là một cách tách \n\nngữ., tij = {w1,w2,\u2026,wp}.  \n\nVí dụ:  \n\n \n\nHình 5. 1. Minh họa quy ước cho văn bản \n\nViệc phân loại sẽ gán một chủ đề ch ∈ C={c1,c2,\u2026,cq} cho văn bản, mỗi chủ đề \n\nlại bao gồm nhiều từ khóa (keyword) K={k1,\u2026,kr}. Cây phân cấp chủ đề và từ khóa \n\nthể hiện như sau : \n\n \n\nHình 5. 2.Minh họa chủ đề \u201cXã hội\u201d \n\n\n\n \n  \n\n \n\n 71 \n\nTrong phần này chúng em sẽ trình bày các phương pháp tính toán được sử dụng \n\ntrong phân loại bao gồm: công thức được dùng trong IGATEC [H.Nguyen et al, \n\n2005]và công thức Naïve Bayes [Mitchell, 2005].  \n\n5.3.2. Công thức phân loại văn bản trong IGATEC [H. Nguyen et al, 2005] \nCông thức phân loại văn bản trong IGATEC [H.Nguyen et al, 2005] do chính \n\ntác giả đề nghị theo cách sử dụng độ phụ thuộc của văn bản vào chủ đề. Độ phụ \n\nthuộc này được tính dựa vào xác suất đồng xuất hiện của các từ trong văn bản với \n\nmột từ khóa nhất định. Chi tiết cách tính này như sau :  \n\nCho trước một từ khóa k , độ phụ thuộc của từ w vào k được tính như sau: \n\n( & )( | )  \n( )\n\np k wp k w\np w\n\n=  \n\nTrong đó  \n\n p(w) là xác suất xuất hiện của từ w trên Google được tính  theo công thức  \n\n( )( )= count wp w\nMAX\n\n (đã trình bày ở mục  4.5.1.2) \n\n p( k & w ) là xác suất xuất hiện đồng thời của chủ đề k và từ wi  trên Google \n\nvới:   ( & )( & ) count k wp k w\nMAX\n\n=   (đã trình bày ở mục 4.5.1.2.) \n\nTiếp theo, độ liên quan (relative) của một cách tách ngữ t với từ khóa k bằng \n\ntổng xác suất của tất cả các từ w xuất hiện đồng thời với từ khóa k như sau: \n\n1\n\n( , ) ( | )\np\n\ni\ni\n\nrel t k p k w\n=\n\n=∑  \n\nĐộ hỗ trợ (support) của cách tách ngữ t trên vào chủ đề c={k1,k2,\u2026,ks} là : \n\n1\n\n1( , ) ( , )\ns\n\ni\ni\n\nSP t c rel t k\ns =\n\n= ∑  \n\nTheo công thức trên, tác giả cho rằng văn bản có độ hỗ trợ vào một chủ đề càng \n\ncao thì khả năng văn bản đó thuộc về chủ đề này càng lớn. Dựa vào các công thức, \n\nđộ phụ thuộc của câu được xác định theo công thức: \n\n1 1 1\n\n1( , ) ( , ) ( , )\nm m n\n\ni ij\ni i j\n\nSP d c SP g c SP t c\nn= = =\n\n= =∑ ∑ ∑  \n\n\n\n \n  \n\n \n\n 72 \n\nTheo các công thức trên, văn bản d sẽ thuộc về chủ đề có SP(d,c) lớn nhất. \n\n5.3.3. Công thức Naïve Bayes trong bài toán phân loại tin tức điện tử \ntiếng Việt sử dụng thống kê từ Google \n\nỞ mục 5.2, chúng em đã trình bày các công thức Naïve Bayes cơ bản dùng \n\nthông tin xác suất học được từ tập dữ liệu huấn luyện. Tuy nhiên, hướng tiếp cận \n\ncủa chúng em không sử dụng tập ngữ liệu mà sử dụng thông tin thống kê từ Google \n\nnên các công thức trên được chúng em cải tiến cho phù hợp.  \n\n5.3.3.1. Ước lượng P(X|Y) \nVới công thức (2.11) được trình bày ở mục 5.2.  như sau:  \n\n{ }\n{ }\n\n#\n( | )\n\n#\nj i\n\nj i\ni\n\nD X w Y c\nP X w Y c\n\nD Y c\n= ∧ =\n\n= =\n=\n\n \n\nnếu sử dụng cho tập ngữ liệu có sẵn, công thức có ý nghĩa là xác suất chủ đề ci  \n\nchứa văn văn bản có wj  bằng số văn bản có chứa wj thuộc ci trên tổng số văn bản \n\nthuộc chủ đề ci. Tuy nhiên, trong hướng tiếp cận dựa trên Google, chúng ta không \n\nthể xác định được số lượng văn bản thực sự thuộc chủ đề ci . Do đó, chúng em đề \n\nxuất cách tính xác suất khác phù hợp với hướng tiếp cận dựa trên thống kê Google: \n\n \n{ }\n\n{ }\n# ( & ) 1\n\n( | )\n# ( & ) | |\n\nj i j i\nj i\n\ni j kk\n\nD X w Y c p w c\nP X w Y c\n\nD Y c p w c Y\n= ∧ = +\n\n= = =\n= +∑\n\n (4.1) \n\nTrong đó:  \n\n p(wj & ci ) là xác suất xuất hiện đồng thời wj và ci . \n\n k số thứ tự của các chủ đề, {1,...,| |}k Y∈  \n\nCông thức trên cho kết quả dựa trên xác suất xuất hiện đồng thời wj và ci trên \n\ntổng số lần xuất hiện số lần xuất hiện wj trong tất cả các chủ đề. \n\n5.3.3.2. Ước lượng P(Y) \nVới công thức (2.12) được trình bày ở mục 5.2 là: \n\n { }#( ) ii\nD Y c\n\nP Y c\nD\n=\n\n= =  (4.2)  \n\n\n\n \n  \n\n \n\n 73 \n\nỞ công thức này, ta giả sử các trang web chứa từ khóa ci đều thuộc chủ đề ci.  \n\nLúc đó, P(Y=ci) bằng xác suất xuất hiện ci trên tổng số trang web chứa tất cả các \n\nchủ đề: \n\n { }# ( )( )\n( )\n\ni i\ni\n\njj\n\nD Y c p cP Y c\nD p c\n=\n\n= = =\n∑\n\n \n\nTrong đó \n\n p(ci) : tần số xuất hiện của chủ đề ci  trên Google \n\n j : là chỉ số của các chủ đề cần phân loại \n\n5.3.3.3. Ước lượng P(Y|X) \nKhi đó công thức Naïve Bayes cho phân loại văn bản (2.9) sẽ có dạng : \n\n 1 2\n( ) ( & )\n\n( | , ,..., )\n( ) ( & )\ni k ik\n\ni n\nj k jj k\n\np c p w c\nP Y c w w w\n\np c p w c\n= = ∏\n\n∑ ∏\n (4.3) \n\nVì tần số xuất hiện p(w) (mục 4.5.1)  của từ trên Google rất nhỏ nên việc tính \n\nxác suất 1 2( | , ,..., )i nP Y c w w w=  theo công thức (4.3) có thể dẫn đến việc tràn số do \n\nnhân các số thực gần với 0. Chúng em khắc phục vấn đề này bằng cách chuyển \n\ncông thức (4.3) sang sử dụng log : \n\n( )\n( )\n( ) ( )\n( ) ( )( )\n\n1 2\n\nlog ( ) ( & )\n( | , ,..., )\n\nlog ( ) ( & )\n\nlog ( ) log ( & )\n\nlog ( ) log ( & )\n\ni k ik\ni n\n\nj k jj k\n\ni k ik\n\nj k jj k\n\np c p w c\nP Y c w w w\n\np c p w c\n\np c p w c\n\np c p w c\n\n\u2032 = = −\n\n+\n= −\n\n+\n\n∏\n∑ ∏\n\n∑\n∑ ∑\n\n \n\nVăn bản d sẽ được phân loại vào chủ đề ci có giá trị 1 2( | , ,..., )i nP Y c w w w\u2032 =  cao \n\nnhất. \n\n\n\n \n  \n\n \n\n 74 \n\n5.4. Kết luận \nCác phương pháp phân loại văn bản dựa trên công thức của IGATEC và phương \n\npháp Naïve đều tương đối đơn giản, không bị hạn chế về tập huấn luyện như khi sử \n\ndụng các phương pháp khác. Ngoài ra, các phương pháp trên cũng không gặp \n\ntrường hợp sai lạc do có sự thay đổi trong tập huấn luyện bởi tính linh hoạt đối với \n\nsự thay đổi nhờ dùng thông tin thống kê từ Google. \n\nCác kết quả trên thu nhận được thông qua việc chạy hệ thống thử nghiệm phân \n\nloại ViKass sẽ được mô tả chi tiết trong chương tiếp theo. \n\n \n\n\n\n \n  \n\n \n\n 75 \n\n  \n\nCChhưươơnngg  66  \n\nHHỆỆ  TTHHỐỐNNGG  TTHHỬỬ  \n\nNNGGHHIIỆỆMM  PPHHÂÂNN  LLOOẠẠII  VVĂĂNN  \n\nBBẢẢNN  \n \n\n \n\nGiới thiệu hệ thống thử nghiệm Vikass \n\nThử nghiệm các cách trích xuất thông tin \n\nDữ liệu thử nghiệm \n\nThử nghiệm các công thức tính độ tương hỗ MI  \n\nThử nghiệm phân loại tin tức điện tử \n\n \n\n\n\n \n  \n\n \n\n 76 \n\nChương 6. HỆ THỐNG THỬ NGHIỆM PHÂN LOẠI    \nVĂN BẢN \n\n6.1.  Giới thiệu hệ thống thử nghiệm Vikass \n\n6.1.1. Chức năng hệ thống Vikass \nHệ thống thử nghiệm phân loại văn bản Vikass được xây dựng nhằm mục đích \n\nkiểm nghiệm phương pháp tách từ IGATEC và các phương pháp phân loại đề cập ở \n\nchương trước nhằm tìm ra được các tham số tối ưu trước khi tích hợp vào toà soạn \n\nbáo điện tử. Các tham số này bao gồm các tham số chạy thuật toán di truyền như số \n\nlượng cá thể ban đầu, số thế hệ tối ưu,  tỉ lệ lai ghép, tỉ lệ đột biến; cách tính MI \n\nhiệu quả và phương pháp phân loại nào cho kết quả tốt hơn. Ngoài tích hợp mô-đun \n\ntrích tần số xuất hiện từ Google, hệ thống còn cung cấp các tính năng khác như trích \n\ntin tức, chỉnh sửa từ khóa. Chức năng của hệ thống sẽ được mô tả chi tiết trong các \n\nphần tiếp theo. \n\n6.1.2. Tổ chức và xử lý dữ liệu \n\n6.1.2.1. Giới thiệu chung \nHướng tiếp cận của luận văn dựa trên thống kê từ Google, điều đó có nghĩa là \n\nmỗi lần cần lấy tần số xuất hiện của một từ mới, hệ thống phải thực hiện lấy thông \n\ntin từ Internet. Điều này làm tiêu tốn rất nhiều thời gian chờ đợi, do vậy mỗi khi lấy \n\nđược thông tin từ Google, chúng em lưu lại vào một file dữ liệu đệm để có thể sử \n\ndụng lại mỗi khi cần đến.  \n\nVới mục đích làm tăng tốc độ xử lý của chương trình thử nghiệm, việc quản lý \n\ndữ liệu hoàn toàn được thực hiện trên file văn bản thông thường trên kiểu phông \n\nphổ biến của tiếng Việt là phông Unicode UTF8.  \n\nHệ thống thử nghiệm cần hai loại thông tin như sau: \n\n Đối với thử nghiệm tách từ tiếng Việt, hệ thống cần thông tin về xác suất \n\nxuất  hiện của các từ trên Google. \n\n Đối với việc thử nghiệm phân loại văn bản, hệ thống cần thông tin về xác \n\nsuất xuất hiện đồng thời của từ và từ khoá tương ứng với chủ đề. \n\n\n\n \n  \n\n \n\n 77 \n\n6.1.2.2. Tổ chức dữ liệu \nTừ những yêu cầu trên, hệ thống dữ liệu được thiết kế thành ba file có nội dung \n\nnhư sau: \n\n \n\nHình 6. 1. Tổ chức file dữ liệu \n\n File CACHE: là dạng file văn bản thông thường, chứa thông tin: \n\n Từ: từ đã tìm từ Google \n\n Xác suất: xác suất của từ đó trên Google \n\n Loại từ: mang một trong các giá trị W(là từ), NW (không là từ), WC ( \n\ncó thể là từ), NWC (không thể là từ), UD (chưa phân loại). \n\n File KEYWORD: File được viết dưới dạng xml bao gồm thông tin về tên chủ \n\nđề các cấp: \n\n Tên chủ đề: tên của chủ đề các cấp (cấp 1 và cấp 2) \n\n Chỉ số: chỉ số của mỗi chủ đề cho biết vị trí của chủ đề trong danh \n\nsách xác suất của từ với từng chủ đề trong file Relevant.  \n\n Chọn dạng xml để lưu tên chủ đề vì tính chất lồng nhau ở từng cấp \n\ncủa chủ đề rất thích hợp với cấu trúc dạng cây của tài liệu xml.  \n\n Ví dụ, ta có các chủ đề cấp 1 là \u201cthể thao\u201d và các chủ đề cấp 2 của nó \n\nlà \u201cBóng đá\u201d, \u201cQuần vợt\u201d như hình vẽ dưới đây\u201d \n\n \n\nHình 6. 2. Chủ đề Thể thao \n\nLúc đó, nội dung file chủ đề sẽ có nội dung như sau: \n\n\n\n \n  \n\n \n\n 78 \n\n \n File RELEVANT: chứa thông tin: \n\n Từ: từ đã tìm \n\n Danh sách xác suất của từ với từng chủ đề: xác suất xuất hiện đồng \n\nthời của từ ứng với từng chủ đề theo chỉ số được lưu trong file \n\nKEYWORD. \n\nSau khi thực hiện thử nghiệm, dung lượng file CACHE đã lên đến gần 10M và \n\nfile RELEVANT xấp xỉ 50M. Với khối lượng dữ liệu lớn như vậy, việc sử dụng \n\nmột hệ quản trị cơ sở dữ liệu là không cần thiết bởi vì việc xử lý thông tin trong hệ \n\nthống là đơn giản và yêu cầu tiên quyết của chương trình là tốc độ xử lý cao. Như \n\nvậy, chọn lựa lưu trữ thông tin dưới dạng văn bản bình thường là phù hợp với yêu \n\ncầu hệ thống. \n\n6.1.2.3. Xử lý dữ liệu \nKhi bắt đầu hoạt động, hệ thống tự động thực hiện đọc các file dữ liệu, phân tích \n\nchuỗi trong file để lấy thông tin và đưa vào bộ nhớ dưới dạng \u201cbảng băm\u201d \n\n(hashtable). Hệ thống thử nghiệm được phát triển nên ngôn ngữ C#, là một ngôn \n\nngữ khá mạnh hỗ trợ nhiều cấu trúc lưu trữ thông tin trong đó có hỗ trợ bảng băm. \n\nNhờ vậy mà việc tổ chức dữ liệu trở nên đơn giản hơn rất nhiều. Ngoài ra, cách xử \n\nlý như vậy sẽ làm tăng tốc độ tìm kiếm thông tin của từ nhờ các ưu điểm tổ chức dữ \n\nliệu của bảng băm.  \n\n<?xml version=\"1.0\" encoding=\"utf-8\" ?> \n\n<keyword> \n\n <topic name=\"thể thao\" value=\"1\"> \n\n  <topic name=\"bóng đá\" value=\"2\" /> \n\n  <topic name=\"quần vợt\" value=\"3\" /> \n\n <\/topic> \n\n<\/keyword> \n\n\n\n \n  \n\n \n\n 79 \n\n6.1.3. Một số màn hình của hệ thống Vikass \n\n \n\nHình 6. 3. Màn hình tách từ và phân loại \n\nSTT Mô tả \n1 Chọn thư mục chứa các tập tin cần tách từ và phân loại \n2 Chọn thư mục lưu kết quả \n3 Liệt kê tên các tập tin được chọn tách từ và phân loại \n4 Di chuyển các tập tin qua lại để chọn các tập tin thực hiện tách từ \n5 Liệt kê tên tất cả các tập tin có trong thư mục (1) \n6 Thực hiện tách từ và phân loại \n7 Dừng tách thực thi \n8 Xem tập tin kết quả phân loại \n9 Tab tùy chọn các thông số chạy GA \n10 Tab tùy chọn các thông số như loại MI sử dụng, có sử dụng stopword hay \n\nkhông ? \n11 Tab chọn các từ khóa sẽ sử dụng cho việc phân loại \n\nBảng 6. 1. Mô tả một số control của màn hình tách từ \n\n\n\n \n  \n\n \n\n 80 \n\nMàn hình môđun trích xuất từ Google: \n\n \n\nHình 6. 4.  Màn hình trích xuất từ Google \n\nSTT Mô tả \n1 Chọn thư mục chứa các tập tin như tập tin đệm, tập tin chứa độ liên quan \n\ncủa từ và từ khóa,\u2026 \n2 Các tùy chọn như chỉ tìm kiếm các từ có tần số 0, chỉ tìm các trang .vn, tìm \n\nkiếm độ liên quan của từ và từ khóa\u2026 \n3 Các phương pháp tải về sử dụng \n4 Thanh biểu thị tiến trình tìm kiếm và trích từ \n5 Thực hiện tìm kiếm và trích xuất \n6 Lưu lại tập tin đệm và tập tin chứa độ liên quan \n7 Dừng việc tìm kiếm \n8 Danh sách các từ đã được tìm kiếm \n\nBảng 6.2. Mô tả một số control của màn hình trích từ Google \n\n \n\n\n\n \n  \n\n \n\n 81 \n\nMàn hình phân loại tin tức điện tử hỗ trợ toà soạn báo điện tử : \n\n \n\nHình 6. 5. Màn hình phân loại tin tức điện tử \n\nSTT Mô tả \n1 Thiết lập các tham số kết nối đến SQL server \n2 Lấy các tin tức được toà soạn báo điện tử tải về \n3 Thực hiện phân loại \n4 Cập nhật các tin tức đã được phân loại vào SQL server \n5 Thực hiện tất cả các bước (2),(3),(4) \n6 Hiển thị các thông tin như : nội dung tin, tên của chủ đề được phân loại,\u2026 \n\nBảng 6.3. Bảng mô tả một số control của màn hình phân loại tin tức điện tử \n\n \n\n \n\n\n\n \n  \n\n \n\n 82 \n\n6.2. Thử nghiệm các cách trích xuất thông tin \nViệc trích xuất thông tin về tần số xuất hiện của từ, độ liên quan giữa từ và chủ \n\nđề được thực hiện thông qua module Google Extractor. Nhằm mục đích tăng tốc \n\ntrích thông tin từ Google, chúng em đã thử nghiệm trích thông tin bằng nhiều cách \n\nkhác nhau và thực hiện kết nối đến Google sử dụng nhiều luồng (>=15). Bên cạnh \n\nđó, để tránh việc phải thực hiện tìm kiếm nhiều lần, các tập tin đệm được sử dụng \n\nvới mục đích lưu lại hay cập nhất kết quả các lần tìm kiếm trước.  \n\n6.2.1. Các phương pháp thử nghiệm \nChúng em sử dụng 3 cách khác nhau để lấy kết quả tìm kiếm bao gồm sử dụng \n\ndịch vụ web do Google cung cấp, tải trang kết quả về máy cục bộ sau đó sử dụng \n\nXPath hay tìm kiếm chuỗi.  \n\n6.2.1.1. Google web service \nDịch vụ web là một ứng dụng cung cấp giao diện lập trình, hỗ trợ sự truyền  \n\nthông từ ứng dụng này đến ứng dụng khác qua mạng dùng XML. Dịch vụ web của \n\nGoogle tại địa chỉ http://api.google.com/GoogleSearch.wsdl là một phương pháp \n\ntiện lợi để khai thác công cụ tìm kiếm này. Tuy nhiên, ta phải đăng kí tài khoản \n\ntrước khi sử dụng. Với mỗi tài khoản Google giới hạn số lượng truy vấn là 1000 \n\ntruy vấn/ngày. Các tham số cần biết khi sử dụng dịch vụ : \n\n \n\nTham số tìm kiếm \n\nq Câu truy vấn  \n\nn Số kết quả trả về trên từng trang \n\nlr Giới hạn phạm vi ngôn ngữ tìm kiếm \n\nie Bảng mã câu truy vấn sử dụng \n\noe Bảng mã của kết quả trả về \n\nBảng 6. 4. Tham số sử dụng dịch vụ Google \n\nMột số câu truy vấn đặc biệt trên Google : \n\n \n\n\n\n \n  \n\n \n\n 83 \n\nTruy vấn đặc biệt Câu truy vấn Ý nghĩa \n\nLoại bỏ một từ bass \u2013music \u201c-\u201d để loại bỏ 1 từ ra khỏi kết \n\nquả tìm kiếm \n\nTừ khóa OR vacation london OR \nparis \n\nOR  \n\nGiới hạn site Admission \nsite:www.stanford.edu \n\nsite: chỉ tìm kiếm trong site \n\nđược chỉ định \n\nGiới hạn ngày Star Wars \ndaterange:2452122-\n\n2452234 \n\ndaterange: chỉ trả về các file có \n\nnhãn thời gian thõa điều kiện \n\nLọc file Google filetype:doc OR \nfiletype:pdf \n\nfiletype: chỉ tìm kiếm các file \n\ncó kiểu mở rộng được liệt kê \n\nLoại trừ file Google doc -filetype: \n-filetype:pdf \n\n-filetype: ngược lại với \n\nfiletype: \n\nTìm theo tiêu đề intitle:Google search intitle: chỉ tìm kiếm tiêu đề web\n\nBảng 6. 5. Một số câu truy vấn đặc biệt của Google \n\nTrong quá trình thử nghiệm sử dụng dịch vụ web của Google, chúng em nhận \n\nthấy thời gian đáp ứng không được nhanh (khoảng >5s cho một truy vấn-sử dụng \n\nmạng Internet của trường) hơn nữa còn tồn tại nhiều lỗi. Lý do có thể kể đến như \n\nphiên bản dịch vụ đang trong quá trình thử nghiệm (bản β), hạn chế do dung lượng \n\nmạng, chi phí chứng thực. Giới hạn 1000truy vấn/ngày cũng ảnh hưởng đến chương \n\ntrình khi phải thực hiện trích xuất trên lượng lớn các từ. Để khắc phục vấn đề này, \n\nchúng em sử dụng biện pháp tải trang kết quả về. \n\n6.2.1.2.  Xpath và tìm kiếm chuỗi \nTrang kết quả trả về sẽ được chuyển sang định dạng xHTML dùng cho việc trích \n\nxuất dùng Xpath (http://www.w3.org/TR/XPath20)  hay thực hiện tìm kiếm trên \n\nchuỗi. Cả hai phương pháp này đều cho hiệu suất tốt (khoảng 1-3s/truy vấn). \n\nXpath là định dạng được W3C đề nghị được sử dụng rộng rãi trong việc truy vấn \n\ntập tin XML. Sử dụng Xpath có thuận lợi hơn tìm kiếm chuỗi ở chỗ có thể sử dụng \n\ntrích xuất trên nhiều ngôn ngữ trả về từ Google và nếu cấu trúc của trang web thay \n\n\n\n \n  \n\n \n\n 84 \n\nđổi thì ta vẫn lấy được thông tin trả về của Google. Trong khi đó việc tìm kiếm \n\nchuỗi sẽ phụ thuộc vào các câu đặc biệt (như \u201ccác kết quả \u201d... ). Do đó, nếu các \n\ntrang trả về của Google trình bày khác đi, cách tìm kiếm chuỗi sẽ không cho kết quả \n\nmong muốn. Tuy nhiên, sử dụng cách tìm kiếm chuỗi sẽ cho kết quả nhanh hơn \n\ndùng Xpath vì hệ thống không phải tốn một thời gian phân tích dữ liệu thành dạng \n\ntài liệu XML. \n\n6.2.2. Nhận xét \nHiện tại, điều chúng ta quan tâm hàng đầu là tốc độ trích thông tin từ Google. \n\nMặt khác, trang web Google có cấu trúc khả ổn định, hầu như không thay đổi. Vì \n\nvậy khi thực hiện thử nghiệm, chúng em sử dụng cách thức tìm kiếm chuỗi để đạt \n\ntối độ cao nhất. Tuy nhiên, chúng em vẫn xây dựng các lựa chọn rút trích để tạo tính \n\nlinh hoạt trong thử nghiệm. \n\n6.3. Dữ liệu thử nghiệm \n\n6.3.1. Nguồn dữ liệu \nDữ liệu thử nghiệm được lấy từ trang tin tức VnExpress.net \n\n(www.vnexpress.net) tại thời điểm tháng 6/2005. Đây là một trong  những trang tin \n\ntức điện tử đầu tiên tại Việt Nam ra đời vào ngày 26/2/2001, đến nay đã hơn bốn \n\nnăm hoạt động với lượng độc giả đông đảo trong cả nước và quốc tế. Ngoài các \n\ntrang mục do phóng viên của tờ báo viết, VnExpress.net còn mở rộng đón nhận các \n\nbài viết do độc giả gửi về từ khắp nơi để làm phong phú thêm cho nội dung của tờ \n\nbáo và cập nhật tin tức thường xuyên nhanh chóng.  \n\n6.3.2. Số lượng dữ liệu thử nghiệm \nTừ các mục của VnExpress.net, đầu tiên chúng em chọn lọc ra một số mục  \n\nchính để lấy dữ liệu thử nghiệm.  \n\nVì chúng em quy định từ khóa cho chủ đề chính là tên chủ đề đó nên trong quá \n\ntrình thử nghiệm, chúng em phát hiện ra một số trường hợp nhập nhằng.  \n\n\n\n \n  \n\n \n\n 85 \n\nĐầu tiên, từ khóa Thế giới, Xã hội có ý nghĩa bao quát có thể về Kinh tế thế \n\ngiới, chính trị thế giới, văn hóa xã hội\u2026,  nên khả năng các tin tức được phân loại \n\nvào chủ đề này là rất cao do tần số xuất hiện của chủ đề này với các từ phổ biến lớn.  \n\nThứ hai, một số mục có tên không đồng nhất giữa các tờ báo điện tử như trang \n\nVnExpress.net dùng Vi tính trong khi đó TuoiTre.com.vn lại dùng Nhịp sống số, \n\nVnn.vn dùng Công nghệ thông tin và Viễn thông.... Việc này làm giảm kết quả khi \n\nsử dụng từ khóa khóa Vi tính cho chủ đề này vì từ khóa này không bao quát được \n\ncho các trang sử dụng tên chủ đề khác mặc dù cùng trình bày một nội dung.  \n\nDo vậy, chúng em chỉ sử dụng một số mục có từ khóa rõ ràng. Đối với mỗi tin \n\ntức, chúng em chỉ tách lấy phần tiêu đề, phần tóm lược và phần chú thích ảnh. Đây \n\nlà các phần có ý nghĩa phân loại cao do được người viết bài tóm lược và chọn lọc. \n\nỨng mỗi chủ đề, chúng em lấy ngẫu nhiên 100 tin. Còn cách giải quyết phần nhập \n\nnhằng trình bày ở trên sẽ là hướng mở rộng của luận văn. Tổng dữ liệu thử nghiệm \n\nlà 1500 tập tin bao gồm 15 chủ đề cấp 2, mỗi chủ đề 100 tập tin. \n\n \n\n\n\n \n  \n\n \n\n 86 \n\n \n\nHình 6. 6. Cây chủ đề \n\n6.3.3. Nhận xét \nMặc dù dữ liệu dùng thử nghiệm khá nhỏ do hạn chế về mặt thời gian, nhưng \n\ncách thức chọn dữ liệu và chủ đề thử nghiệm phân loại của chúng em đã mở rộng \n\nrất nhiều so với 35 văn bản thử nghiệm của [H. Nguyen et al, 2005] trên 5 chủ đề \n\nChính trị, Giáo dục, Kinh doanh, Sức khỏe, Thể thao. \n\n\n\n \n  \n\n \n\n 87 \n\n6.4. Thử nghiệm các công thức tính độ tương hỗ MI  \n\n6.4.1. Các phương pháp thử nghiệm \nNhằm xác định hiệu quả của các cách tính MI trong việc tách từ tiếng Việt, \n\nchúng em thực hiện thử nghiệm 3 công thức MI đã được trình bày ở mục 4.5: một \n\ncông thức tính MI của [H.Nguyen et al, 2005] (gọi là MI1) , một của [Ong & Chen, \n\n1999] (gọi là MI2), một do chúng em đề nghị (gọi là MI3) . Ứng với mỗi công thức \n\ntính MI trên, chúng em thử nghiệm thêm việc tách stopword và không tách \n\nstopword trước khi tách từ. Mục đích của việc tách stopword trước khi tách từ nhằm \n\ntạo ra nhiều ngữ nhỏ hơn khi đã bỏ các từ không có ý nghĩa, để làm tăng tốc độ tách \n\ntừ của hệ thống.  \n\nNhư vậy, tổng cộng có 6 thử nghiệm tách từ như sau:  \n\n MI1 tách stop word (MI1_NonSW) \n\n MI1 không tách stop word (MI1_SW)  \n\n MI2 tách stop word (MI2_NonSW) \n\n MI2 không tách stop word (MI2_NonSW) \n\n MI3 tách stop word (MI3_NonSW) \n\n MI3 không tách stop word (MI3_NonSW) \n\nChúng em thử nghiệm các công thức trên 1500 nội dung tóm tắt các tin tức của \n\nVnExpress.net \n\n6.4.2. Kết quả \nĐộ chính xác của các công thức tính độ tương hỗ như sau: \n\n \n\nCách tính MI Không tách stop word Có tách stopword \n\nMI 1 [H. Nguyen et al, 2005] 74% 72% \n\nMI 2 [Ong & Chen, 1999] 60% 55% \n\nMI 3 (chúng em đề nghị) 72% 69% \n\nBảng 6. 6. Kết quả thực nghiệm các công thức tính độ tương hỗ MI \n\n\n\n \n  \n\n \n\n 88 \n\n0%\n\n10%\n\n20%\n\n30%\n\n40%\n\n50%\n\n60%\n\n70%\n\n80%\n\nMI1 MI2 MI3\nLoại MI\n\nĐộ\n c\n\nhí\nnh\n\n x\nác\n\nNon SW\nSW\n\n \n\nHình 6. 7. Biểu đồ so sánh kết quả các công thức tính độ tương hỗ MI \n\n6.4.3. Nhận xét \nTrong 6 cách thử nghiệm, cách tách từ dùng công thức MI1. có độ chính xác cao \n\nnhất.  \n\nThời gian chạy tách từ lúc đầu khá lâu (trung bình khoảng 10 phút cho một mẫu \n\ntóm tắt dài khoảng 100 tiếng) đa phần là do thời gian lấy thông tin từ Google. \n\nNhưng khi thông tin về tần số xuất hiện của các từ đã được lưu lại tương đối lớn (độ \n\nlớn file cache khoảng 10M), thì tốc độ tách từ giảm xuống đáng kể (trung bình \n\n<1giây đối với các văn bản không cần lấy thông tin từ Internet) \n\nCách tiếp cận của công thức MI1 là ưu tiên dựa trên từ ghép có hai tiếng, mà \n\ntheo thống kê dựa trên từ điển của chúng em, số từ 2 tiếng chiếm đa số trong từ \n\nvựng tiếng Việt. Cách tính này cho kết quả khá tốt vì vừa thoả mãn được tính chất \n\ntự  nhiên dựa trên ưu thế áp đảo của từ 2 tiếng, vừa được chứng minh bằng thực \n\nnghiệm. \n\nTrong các trường hợp thử nghiệm có tách stopword, thời gian tách từ giảm đi rất \n\nnhiều (trung bình 5 phút cho văn bản mới). Tuy nhiên, trong quá trình thử nghiệm, \n\nchúng em nhận thấy việc tách stopword có thể làm sai lạc ý nghĩa của văn bản ban \n\n\n\n \n  \n\n \n\n 89 \n\nđầu do danh sách stopword đưa vào không hoàn chỉnh. Vì vậy kết quả tách từ có \n\ntách stopword không cao như  cách tách thuần tuý. \n\n6.5. Thử nghiệm phân loại tin tức điện tử \n\n6.5.1. Thước đo kết quả phân loại văn bản \nĐể đánh giá hiệu quả phân loại văn bản, thông thường người ta dùng các chỉ số \n\nvề độ thu về-recall và độ chính xác-precision [Yang, 2000]. Cho một phương pháp \n\nphân loại văn bản, đầu vào là một văn bản, và kết quả trả về là một danh sách các \n\nchủ đề được gán cho văn bản đó, chỉ số độ thu về, độ chính xác có thể được tính \n\nnhư sau: \n\n \n\n \n\nHình 6. 8. Các thông số dùng tính độ thu về, độ chính xác \n\nHình trên mô tả các thông số sau:  \n\n (A) là tất cả văn bản thực hiện phân loại văn bản cho chủ đề T  \n\n (B) là số văn bản được phân loại lấy về cho chủ đề T  \n\n (C) là số văn bản thực sự thuộc về chủ đề T  \n\n (D) là số văn bản lấy về chính xác.  \n\nCác tham số trên được dùng trong công thức tính độ thu về-recall, độ chính xác-\n\nprecision dưới đây:  \n\n \n\n\n\n \n  \n\n \n\n 90 \n\n \nViệc gán nhãn chủ đề của các phương pháp phân loại văn bản có thể được đánh \n\ngiá bằng cách dùng bảng trường hợp hai chiều ứng với từng loại chủ đề: \n\n \n\n Chủ đề đang xét ĐÚNG \nvới chủ đề văn bản \n\nChủ đề đang xét SAI \nvới chủ đề văn bản \n\nPhân loại ĐÚNG \n với chủ đề văn bản \n\na b \n\nPhân loại SAI  \nvới chủ đề văn bản \n\nc d \n\nBảng 6. 7. Bốn trường hợp của phân loại văn bản \n\nNhư vậy, với mỗi kết quả phân loại cho một văn bản, ta sẽ có được một trong 4 \n\ntrường hợp a,b,c hoặc d. Từ đó, ta tính được các chỉ số sau: \n\n arecall\na c\n\n=\n+\n\n nếu a + c >0, ngược lại là không xác định. \n\n aprecision\na b\n\n=\n+\n\n nếu a + b >0, ngược lại là không xác định. \n\n Tuy nhiên, cách tính với độ thu về, độ chính xác riêng rẽ sẽ cho kết quả \n\nkhông cân đối. Ví dụ nếu số văn bản lấy về đúng (D) gần bằng với số văn \n\nbản đúng thực sự (C) thì chỉ số độ thu về sẽ cao, tuy nhiên nếu số văn bản lấy \n\nvề (B) khá nhiều so với (D) sẽ cho chỉ số độ chính xác nhỏ. Do vậy, thông \n\nthường người ta thêm một chỉ số F1 [Yang , 1997] để phản ánh sự cân đối \n\ngiữa 2 độ đo trên: \n\n21 1 1F\n\nrecall precision\n\n=\n+\n\n \n\nNgoài ra, để tính toán hiệu quả thực thi trên toàn bộ chủ đề, thông thường người \n\nta còn sử dụng hai phương pháp macro-averaging và micro-averaging. \n\nMacro-averaging tính trung bình các chỉ số recall, precision, fallout, Acc,Err \n\ncủa tất cả các chủ đề. \n\n\n\n \n  \n\n \n\n 91 \n\nMicro-averaging tính toán các chỉ số dựa trên tổng giá trị a, b, c, d của từng chủ \n\nđề dựa theo các công thức áp dụng tính cho một chủ đề. \n\nSự khác nhau chủ yếu giữa hai cách tính macro-averaging và micro-averaging \n\nlà :  micro-averaging tính toán dựa trên trọng số của mỗi văn bản, nên cho kết quả \n\ntrung bình trên mỗi văn bản (per-document average); trong khi đó, macro-\n\naveraging tính toán trọng số trên mỗi chủ đề, do đó, kết quả cho sẽ đại diện cho giá \n\ntrị trung bình trên mỗi chủ đề (per-category average). \n\n6.5.2. Các phương pháp thử nghiệm \nỞ phần phân loại văn bản, chúng em thử nghiệm 2 công thức đã được trình bày \n\nở 5.3. là công thức phân loại được sử dụng trong [H. Nguyen et al, 2005] (gọi tắt là \n\ncông thức IClass) và công thức tính Naïve Bayes được cải tiến cho phù hợp với \n\nhướng tiếp cận dựa trên Google (gọi tắt là NBClass). \n\nỨng với công thức phân loại, chúng em thử nghiệm với 2 công thức tính MI: \n\nmột của [H. Nguyen et al, 2005] (gọi tắt là MI1) và một công thức MI do chúng em \n\nđề xuất (gọi tắt là MI3) cho hai trường hợp tách và không tách stopword.Ở phần này \n\nchúng em không thử nghiệm với MI2 của [Ong & Chen, 1999] vì kết quả tách từ \n\ncủa công thức này thấp hơn các công thức khác khá nhiều sẽ cho kết quả không tốt. \n\nNhư vậy tổng cộng chúng em thực hiện 8 lần thử nghiệm phân loại như sau: \n\n Công thức IClass + MI1 + tách stop word \n\n Công thức IClass + MI1 + không tách stop word \n\n Công thức IClass + MI3 + tách stop word \n\n Công thức IClass + MI3 + không tách stop word \n\n Công thức NBClass + MI1 + tách stop word \n\n Công thức NBClass + MI1 + không tách stop word \n\n Công thức NBClass + MI3 + tách stop word \n\n Công thức NBClass + MI3 + không tách stop word \n\n6.5.3. Kết quả \n\n\n\n \n  \n\n \n\n 92 \n\nSau khi thực hiện phân loại văn bản, chúng em sử dụng các độ đo đã được trình \n\nbày ở mục 6.5.1. để tính toán kết quả chính xác của các thử nghiệm phân loại. Kết \n\nquả tính toán được trình bày trong bảng thống kê sau: \n\n \n\nPhương \npháp Tên chủ đề R P F1 \n\nXã hội 0.62625 0.654047 0.639847\n\nKhoa học 0.72 0.975434 0.828475\n\nThể thao 0.765 0.968245 0.854706\n\nKinh doanh 0.795 0.293358 0.428571\n\nMacro 0.763437 0.892427 0.822908\n\nIClass  \n\n+ MI 1 \n\n+tách \n\nstopword \n\nMicro 0.663 0.682801 0.672755\n\nXã hội 0.764 0.636667 0.694545\n\nKhoa học 0.7216 0.942131 0.81725\n\nThể thao 0.65625 0.975 0.784483\n\nKinh doanh 0.816 0.348718 0.488623\n\nMacro 0.814333 0.951923 0.877769\n\nIClass  \n\n+ MI 1 \n\n+không \n\ntách \n\nstopword \n\nMicro 0.656 0.672131 0.663968\n\nXã hội 0.630 0.660 0.645\n\nKhoa học 0.857 0.873 0.865\n\nThể thao 0.861 0.915 0.887\n\nKinh doanh 0.630 0.740 0.681\n\nMacro 0.913 0.892 0.903\n\nIClass  \n\n+ MI 3 \n\n+tách \n\nstopword \n\nMicro 0.678 0.700 0.689\n\nXã hội 0.772 0.784 0.778IClass  \n\n+ MI 3 Khoa học 0.808 0.851 0.829\n\n\n\n \n  \n\n \n\n 93 \n\nThể thao 0.882 0.825 0.853\n\nKinh doanh 0.637 0.523 0.575\n\nMacro 0.858 0.830 0.844\n\n+không \n\ntách \n\nstopword \n\nMicro 0.553 0.566 0.559\n\nXã hội 0.680 0.738 0.708\n\nKhoa học 0.810 0.841 0.825\n\nThể thao 0.924 0.918 0.921\n\nKinh doanh 0.725 0.620 0.668\n\nMacro 0.785 0.779 0.782\n\nNBClass  \n\n+ MI 1 \n\n+tách \n\nstopword \n\nMicro 0.648 0.633 0.640\n\nXã hội 0.591 0.697 0.640\n\nKhoa học 0.704 0.897 0.789\n\nThể thao 0.886 0.918 0.902\n\nKinh doanh 0.675 0.581 0.625\n\nMacro 0.714 0.773 0.742\n\nNBClass  \n\n+ MI 1 \n\n+không \n\ntách \n\nstopword \n\nMicro 0.783 0.633 0.700\n\nXã hội 0.544 0.636 0.586\n\nKhoa học 0.680 0.855 0.757\n\nThể thao 0.708 1.142 0.874\n\nKinh doanh 1.404 0.332 0.537\n\nMacro 0.748 0.721 0.734\n\nNBClass  \n\n+ MI 3 \n\n+tách \n\nstopword \n\nMicro 0.725 0.648 0.684\n\nXã hội 0.611 0.590 0.600\n\nKhoa học 0.485 0.616 0.543\n\n \n\nNBClass  \n\n+ MI 3  \nThể thao 0.749 1.095 0.890\n\n\n\n \n  \n\n \n\n 94 \n\nKinh doanh 0.660 0.739 0.697\n\nMacro 0.626 0.760 0.687\n\n+không \n\ntách \n\nstopword \nMicro 0.647 0.647 0.647\n\nBảng 6. 8. Kết quả phân loại văn bản cho từng chủ đề ở cấp 1 \n\n0\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\n0.5\n\n0.6\n\n0.7\n\n0.8\n\n0.9\n\n1\n\nI M\nI1 \n\nSW\n\nI M\nI1 \n\nNo\nnS\n\nW\n\nI M\nI3 \n\nSW\n\nI M\nI3 \n\nNo\nnS\n\nW\n\nBa\nye\n\ns M\nI1 \n\nSW\n\nBa\nye\n\ns M\nI1 \n\nNo\nn S\n\nW\n\nBa\nye\n\ns M\nI3 \n\nSW\n\nBa\nye\n\ns M\nI3 \n\nNo\nnS\n\nW\n\nXã hội\nKhoa học\nThể thao\nKinh doanh\nMacro\nMicro\n\n \n\nHình 6. 9. Biểu đồ F1 cho cấp 1 \n\nVì kết quả của phần thử nghiệm phân loại ở cấp hai rất dài, nên chúng em chỉ \n\nxin trình bày biểu đồ kết quả phân loại mà không trình bày chi tiết bảng kết quả cho \n\ntừng chủ đề. \n\nSau đây là kết quả phân loại cho các chủ đề cấp 2. \n\n\n\n \n  \n\n \n\n 95 \n\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n\nI M\nI1 \n\nSW\n\nI M\nI1 \n\nNo\nnS\n\nW\n\nI M\nI3 \n\nSW\n\nI M\nI3 \n\nNo\nnS\n\nW\n\nBa\nye\n\ns M\nI1 \n\nSW\n\nBa\nye\n\ns M\nI1 \n\nNo\nn S\n\nW\n\nBa\nye\n\ns M\nI3 \n\nSW\n\nBa\nye\n\ns M\nI3 \n\nNo\nnS\n\nW\n\nGiáo dục\nDu học\nLối sống\nDu Lịch\nKhoa học\nBóng đá\n\n \n\n0\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\n0.5\n\n0.6\n\n0.7\n\n0.8\n\nI M\nI1 \n\nSW\n\nI M\nI1 \n\nNo\nnS\n\nW\n\nI M\nI3 \n\nSW\n\nI M\nI3 \n\nNo\nnS\n\nW\n\nBa\nye\n\ns M\nI1 \n\nSW\n\nBa\nye\n\ns M\nI1 \n\nNo\nn S\n\nW\n\nBa\nye\n\ns M\nI3 \n\nSW\n\nBa\nye\n\ns M\nI3 \n\nNo\nnS\n\nW\n\nQuần vợt\nBất động sản\nChứng khoán\nQuốc tế\nÂm nhạc\nThời trang\n\n \n\n\n\n \n  \n\n \n\n 96 \n\n0\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\n0.5\n\n0.6\n\nI M\nI1 \n\nSW\n\nI M\nI1 \n\nNo\nnS\n\nW\n\nI M\nI3 \n\nSW\n\nI M\nI3 \n\nNo\nnS\n\nW\n\nBa\nye\n\ns M\nI1 \n\nSW\n\nBa\nye\n\ns M\nI1 \n\nNo\nn S\n\nW\n\nBa\nye\n\ns M\nI3 \n\nSW\n\nBa\nye\n\ns M\nI3 \n\nNo\nnS\n\nW\n\nĐiện ảnh\nLàm đẹp\nGiới tính\nmacro\nmicro\n\n \n\nHình 6. 10. Biểu đồ F1 cho cấp 2 \n\n6.5.4. Nhận xét \nTrong hai mức phân loại chủ đề, ta nhận thấy kết quả phân loại ở mức 1 cho độ \n\nchính xác cao hơn mức 2. Lý do là vì số lượng chủ đề của cấp 2 nhiều hơn cấp 1 rất \n\nnhiều (15 so với 4 ở cấp 1) và một số chủ đề của cấp 2 chưa thực sự tốt như Bất \n\nđộng sản, Lối sống, Làm đẹp, Giới tính. Từ đó, ta thấy được việc xây dựng danh \n\nsách từ khoá cho mỗi chủ đề một yêu cầu cần thiết để nâng hiệu suất phân loại văn \n\nbản.  \n\nDựa vào kết quả thử  nghiệm ta nhận thấy rằng trong việc phân loại sử dụng \n\nBayes tốt hơn công thức phân loại của H. Nguyen et al (2005) trong nhiều trường \n\nhợp. Trong các thử  nghiệm công thức của H.Nguyen et al (2005), độ hỗ trợ của kết \n\nquả vào chủ đề đối có giá trị rất gần nhau, khi áp dụng cho các chủ đề hầu như \n\nkhông có sự khác biệt. Trong khi đó, với công thức Naïve Bayes, có một số chủ đề \n\n\n\n \n  \n\n \n\n 97 \n\nnổi trội hơn hẳn các chủ đề khác và kết quả thống kê cũng cho thấy Naïve Bayes \n\ncho kết quả chính xác hơn.  \n\nKết quả của thử nghiệm công thức trong [H.Nguyen et al, 2005] với độ chính \n\nxác chưa cao lắm bởi vì đấy là công thức do chính tác giả đề nghị chưa dựa trên cơ \n\nsở lý thuyết vững chắc. Trong khi đó, phương pháp Naïve Bayes đã xuất hiện khá \n\nlâu, được chứng minh trên lý thuyết và thực nghiệm nên độ tin cậy rất cao. Việc sử \n\ndụng hướng tiếp cận Naïve Bayes cho phân loại văn bản dựa trên Google có thể nói \n\nlà bước cải tiến đáng khíck lệ so với cách phân loại cũ. \n\nDựa vào biểu đồ, ta nhận thấy sự kết hợp giữa phương pháp phân loại Naïve \n\nBayes và công thức tính độ tương hỗ (MI) của [H. Nguyen et al, 2005] cho kết quả \n\nphân loại tốt nhất. Trong đó, tỉ lệ trung bình của phương pháp cho các chủ đề ở cấp \n\n1 là 75%, và cho các chủ đề ở cấp 2 là 67%. Kết quả này hợp lý vì thực nghiệm cho \n\nthấy công thức MI1 của H.Nguyen et al (2005) cho kết quả tách từ chính xác cao \n\nnhất nên đã góp phần làm cho kết quả phân loại tốt hơn.  \n\nKết quả phân loại văn bản trung bình giữa 8 cặp  là 75%, là kết quả chấp nhận \n\nđược đối với phân loại văn bản tiếng Việt. Kết quả không cao so với kết quả phân \n\nloại bằng tiếng Anh bởi vì như chúng ta đã biết phần tách từ tiếng Việt gặp rất nhiều \n\nphức tạp. \n\n \n\n\n\n \n  \n\n \n\n 98 \n\nCChhưươơnngg  77  \n\nỨỨNNGG  DDỤỤNNGG  PPHHÂÂNN  LLOOẠẠII  \n\nTTIINN  TTỨỨCC  ĐĐIIỆỆNN  TTỬỬ  TTỰỰ  \n\nĐĐỘỘNNGG  \n \n\nGiới thiệu tòa soạn báo điện tử \n\nTính cần thiết của phân loại tin tức tự động \n\nPhân tích hiện trạng \n\nMô hình DFD quan niệm cấp 2 hiện hành cho ô xử lý Nhận \n\nbài và Trả bài \n\nPhê phán hiện trạng \n\nMô hình DFD quan niệm cấp 2 mới cho ô xử lý Nhận bài và \n\nTrả bài \n\nTriển khai DLL \n\nChương trình cài đặt \u201cTòa soạn báo điện tử\u201d đã tích hợp module \n\nphân loại tin tức \n\nKết quả \n\n\n\n \n  \n\n \n\n 99 \n\nChương 7. ỨNG DỤNG PHÂN LOẠI TIN TỨC ĐIỆN TỬ \nTỰ ĐỘNG  \n\nNhằm đánh giá hiệu quả thực tế của việc phân loại sử dụng IGATEC và Naïve \n\nBayes, chúng em đã xây dựng công cụ phân loại thành một module đồng thời tích \n\nhọp vào trong tòa soạn báo điện tử. Trong chương này, chúng em sẽ giới thiệu sơ \n\nlược về tòa soạn báo điện tử và mô tả cách thức tích hợp module phân loại. \n\n7.1. Giới thiệu tòa soạn báo điện tử \nPhần mềm tòa soạn báo điện tử (Luận văn khóa 2000-Hoàng Minh Ngọc và \n\nNguyễn Duy Hiệp) xây dựng trên nền tảng DotNetNuke tuân thủ theo qui trình của \n\nmột tòa soạn thực tế đi từ soạn bài, duyệt bài và đăng bài. Mỗi biên tập viên sẽ phụ \n\ntrách một mảng chủ đề. Cộng tác viên hay người dùng sau khi viết bài phải được \n\nbiên tập viên duyệt. Nếu nội dung và hình thức chấp nhận được thì bài được chuyển \n\nlên vị trí có chức năng đưa bài lên website chính thức. Người quản trị sẽ phân công \n\nchuyên mục và chủ đề cho các biên tập viên. Nếu đã qua các cấp kiểm duyệt, bài \n\nviết được phép đưa lên website. Nếu tại một cấp nào đó, người quản lý thấy bài viết \n\ncần được chỉnh sửa thì bài viết sẽ được trả về đúng cấp có thẩm quyền. \n\nNgoài ra, tòa soạn báo điên tử còn hỗ trợ việc thu thập tin tức điện tử từ nhiều \n\nnguồn khác nhau. Tin tức được tải về sau đó phải được các biên tập viên xác định \n\nchủ đề và chuyên mục mà bài báo thuộc về để tiến hành thủ tục đăng bài. Việc phân \n\nloại tin tức ở giai đoạn thực hiện luận văn này là hoàn toàn thủ công. \n\n7.2. Tính cần thiết của phân loại tin tức tự động \nViệc thực hiện phân loại thủ công trên số lương lớn các tin tức được tải về có thể \n\nngốn rất nhiều thời gian và công sức. Nhằm làm tăng tính hiệu quả cũng như hỗ trợ \n\ntối đa cho các biên tập viên tập trung vào các công việc khác quan trọng hơn. \n\nModule phân loại tin tức tự động đã được xây dựng. Nhiệm vụ của module này là \n\nthực hiện phân loại tự động các tin tức tải về nhằm đề xuất sắp xếp tin tức này vào \n\nmột chuyên mục hợp lý. Module được viết dưới dạng một thư viện dll thực hiện các \n\n\n\n \n  \n\n \n\n 100 \n\ncông việc như sau: lấy các tin tức được tải về, tiến hành phân loại và cập nhật vào \n\ncơ sở dữ liệu. \n\n7.3.  Phân tích hiện trạng \nMục đích của luận văn chúng em là tích hợp phần xử lý phân loại trang web tự \n\nđộng vào phần duyệt bài viết và sửa bài viết nên chúng em chỉ trình bày mô hình  \n\nDFD cho ô xử lý \u201cNhận bài và Trả bài\u201d. Để tìm hiểu về toàn cảnh mô hình DFD \n\ncủa toà soạn báo điện tử, xin tham khảo luận văn \u201cToà soạn báo điện tử\u201d  của \n\nHoàng Minh Ngọc Hải (0012545), Nguyễn Duy Hiệp (0012038)) \n\n7.3.1. Mô hình DFD quan niệm cấp 2 hiện hành cho ô xử lý Nhận bài và \nTrả bài \n\n7.3.1.1. Mô hình \n \n\n \n\nHình 7. 1.Mô hình DFD hiện hành \n\n7.3.1.2. Mô tả mô hình \nThành viên có chức năng viết bài nhận bài viết mới được giao, sau khi hoàn \n\nthành thì lưu xuống kho dữ liệu những bài viết chưa đăng để chờ duyệt. Sau khi bài \n\nviết được duyệt, thành viên kiểm tra xem bài viết có cần chỉnh sửa không, nếu có thì \n\n\n\n \n  \n\n \n\n 101 \n\nthực hiện chỉnh sửa sau đó lưu phiên bản mới của bài viết chờ duyệt tiếp. Ngoài ra, \n\ncác bài báo được lấy tự động từ Internet xuống cũng được lưu trong kho dữ liệu các \n\nbài viết chưa đăng để chờ duyệt. \n\n7.3.1.2.1. Mô tả kho dữ liệu \n\n \nHệ thống thông \n\ntin: \n\nXây dựng toà \n\nsoạn báo điện tử \n\nMô hình quan niệm xử lý \n\nHiện tại [] \n\nTương lai[]  \n\nTrang :  \n\nỨng dụng :  \n\nXây dựng toà \n\nsoạn báo điện tử \n\n \n\nMô tả kho dữ liệu : \n\nNHỮNG BÀI VIẾT CHƯA \n\nĐƯỢC ĐĂNG \n\nTờ : \n\nNgày lập : 28/6/2004 \n\nNgười lập :  \n\n1. Hoàng Minh Ngọc Hải \n2. Nguyễn Duy Hiệp \n\n \n\nDòng dữ liệu vào : \n\nBài viết đã chỉnh sửa \n\nBài viết mới \n\n \n\nDòng dữ liệu ra : \n\nBài viết cần chỉnh sửa \n\n \n\nDiễn giải : \n\nKho này lưu trữ những bài viết đang nằm trong dây chuyền \n\n \n\nCấu trúc dữ liệu: \n\nMA_BAI_VIET \n\nMA_CHUYEN_MUC \n\nMA_TAC_GIA \n\n\n\n \n  \n\n \n\n 102 \n\nNGAY_VIET \n\nTIEU_DE \n\nNOI_DUNG \n\nDUONG_DAN_ANH \n\nKICH_THUOC_ANH \n\nCHIEU_DAI \n\nCHIEU_RONG \n\n \n\nKhối lượng : \n\n- Hiện tại : Không xác định \n- Tương lai : Không xác định \n\n \n\nThông tin thường truy xuất : \n\nMA_BAI_VIET \n\nMA_CHUYEN_MUC \n\nTIEU_DE \n\nNOI_DUNG \n\n \n\nBảng 7. 1. Bảng kho dữ liệu những bài viết chưa được đăng \n\n7.3.1.2.2. Mô tả ô xử lý \n\n \n\nÔ xử \nlý Tên \n\nDòng dữ \nliệu vào \n\nDòng dữ \nliệu ra Diễn giải \n\n(1.1) Nhận bài \nviết mới \n\nBài viết Bài viết mới Phóng viên sau khi viết một bài \nmới sẽ gửi vào hệ thống. \nNhững bài viết này được lưu \ndưới dạng những bài viết chưa \nđược xử lý. \n\n(1.2) Lưu bài \nviết mới \n\nBài viết mới Bài viết mới Lưu bài viết dưới tình trạng \n\u201cChưa xử lý\u201d \n\n\n\n \n  \n\n \n\n 103 \n\n(1.3) Kiểm tra \nnhững bài \nviết cần \nxử lý \n\nNhu cầu \nkiểm tra \n\nThông tin cá \nnhân \n\nBài viết cần \nchỉnh sửa \n\nKiểm tra các bài viết đã được \nduyệt xem có cần chỉnh sửa \nkhông \n\n(1.4) Nhận bài \nviết đã \nchỉnh sửa \n\nBài viết đã \nchỉnh sửa \n\nBài viết đã \nchỉnh sửa \n\nBài viết sau khi thành viên (có \nchức năng chỉnh sửa) duyệt, \nchỉnh sửa và trả lại cho thành \nviên phụ trách bài viết đó. \n\n(1.5) Lưu \nphiên bản \nmới của \nbài viết \n\nBài viết đã \nchỉnh sửa \n\nBài viết đã \nchỉnh sửa \n\nBài viết đã chỉnh sửa được lưu \nvào CSDL dưới tình trạng \u201cĐã \nxử lý\u201d tại cấp vừa chỉnh sửa và \ndưới tình trạng \u201cChưa xử lý\u201d \ntại cấp được chuyển bài về \n\n(1.6) Lấy tin tự \nđộng \n\nTin tức điện \ntử \n\nTin tức điện \ntử \n\nHệ thống tự động lấy tin tức từ \ncác trang báo khác và lưu \nxuống kho dữ liệu \n\n \n\nBảng 7. 2. Bảng mô tả các ô xử lý của mô hình DFD hiện hành \n\n7.3.2. Phê phán hiện trạng \nHiện tại, hệ thống tự động lấy tin tức từ các trang báo điện tử khác về và gán vào \n\ncác mục đã được chỉ định sẵn. Tuy nhiên, việc chỉ định chủ đề cho các tin tức lấy về \n\nmột cách cứng nhắc chỉ đúng trong trường hợp trang web lấy tin có cấu trúc chủ đề \n\ntương ứng với chủ đề trong  toà soạn báo điện tử của mình. Đối với những trang báo \n\ncó cấu trúc khác đi, việc gán nhãn mặc định cho các bài báo sẽ không còn đúng nữa.  \n\nVí dụ ở toà soạn báo điện tử của chúng ta có mục Kinh doanh\\Quốc tế, còn ở \n\nbáo www.vnexpress.net có mục Thế giới bao gồm nhiều nội dung, trong đó có một \n\nsố tin tức về Kinh doanh quốc tế, một số tin tức về chính trị thế giới, một số bài về \n\nvăn hoá chẳng hạn. Như vậy nếu ta chỉ định các bài báo lấy từ mục tin Thế giới ở \n\nwww.vnexpress.net  đều được xếp vào mục Kinh doanh\\Quốc tế thì kết quả không \n\ncòn đúng hoàn toàn nữa. Lúc đó, các thành viên duyệt bài lại phải đọc lần lượt các \n\n\n\n \n  \n\n \n\n 104 \n\nbài báo được lấy về một cách thủ công để phân loại chủ đề của tin tức cho phù hợp \n\nvới cấu trúc chủ đề của mình. \n\nĐể hạn chế trường hợp trên, chúng em đưa ra giải pháp là tích hợp module phân \n\nloại văn bản vào việc xử lý lấy tin tự động từ Internet. Các tin tức vừa được lấy về \n\nsẽ được module phân loại văn bản phân loại tự động vào các chủ đề có sẵn của toà \n\nsoạn báo. Như vậy, chúng ta sẽ tiết kiệm được nhiều công sức và thời gian duyệt bài \n\ncủa các thành viên một cách đáng kể. \n\n7.3.3. Mô hình DFD quan niệm cấp 2 mới cho ô xử lý Nhận bài và Trả bài \n\n7.3.3.1. Mô hình \n \n\n \n\nHình 7. 2. Mô hình DFD cải tiến \n\n7.3.3.2. Mô tả mô hình \nMô hình mới chỉ thêm một ô xử lý việc phân loại tin tức tự động sau khi hệ \n\nthống lấy tin tức từ trang web khác về.  \n\n\n\n \n  \n\n \n\n 105 \n\n7.3.3.2.1. Mô tả ô xử lý \n\nÔ xử \nlý Tên \n\nDòng dữ \nliệu vào \n\nDòng dữ \nliệu ra Diễn giải \n\n(1.7) Phân loại \ntin tức tự \nđộng \n\nTin tức điện \ntử \n\nTin tức điện \ntử đã phân \nloại \n\nModule phân loại văn bản mới \ntích hợp vào hệ thống thực hiện \nphân loại tự động các tin tức \nvừa lấy về. \n\nBảng 7. 3. Bảng mô tả ô xử lý phân loại tin tức tự động \n\n7.4. Triển khai DLL \nChương trình phân loại văn bản tự động được viết trên ngôn ngữ C#, trong khi \n\n\u201cTòa soạn báo điện tử\u201d của luận văn khóa 2000 được viết mã trên nền VB.Net. Do \n\nđó, để tích hợp hai hệ thống lại, chúng em đã xây dựng các thành phần chính dùng \n\ntrong phân loại văn bản thành DLL.  \n\nCó thể nói, việc đóng gói chương trình thành dạng DLL ngoài tính tiện lợi trong \n\nviệc tích hợp giữa các hệ thống xây dựng trên các ngôn ngữ khác nhau, goíi DLL \n\ncòn có ưu điểm là khả năng sử dụng đơn giản, dễ mang chuyển, là yếu tố quan trọng \n\ntrong việc xây dựng chương trình. \n\n\u201cTòa soạn báo điện tử\u201d của luận văn khóa 2000 được xây dựng khá công phu về \n\nmặt hình thức lẫn nội dung, cho nên khi tích hợp DLL mới vào,  chúng em nhận \n\nthấy không cần thiết phải thiết lập thêm giao diện nào nữa. Chúng em chỉ tạo thêm \n\nmột số lựa chọn cho người dụng có thể bật tắt chức năng phân loại. \n\n\n\n \n  \n\n \n\n 106 \n\n \n\nHình 7. 3. Màn hình lấy tin tức cho phép phân loại tự động \n\n7.5. Chương trình cài đặt \u201cTòa soạn báo điện tử\u201d đã tích hợp \nmodule phân loại tin tức \n\n\u201cTòa soạn báo điện tử\u201d của luận văn khóa 2000 hiện tại chưa xây dựng công cụ \n\ncài đặt vài gỡ chương trình tự động (Install và Uninstall), đòi hỏi người dùng phải \n\ncó nhiều kiến thức về SQL Server để có thể cài đặt cơ sở dữ liệu một cách thủ công. \n\nVì vậy, nhằm tăng thêm tính tiện dụng của \u201cTòa soạn báo điện tử\u201d, chúng em tự xây \n\ndựng công cụ cài đặt tự động \u201cTòa soạn báo điện tử\u201d vào máy chỉ với thao tác click \n\nchuột. Công cụ cài đặt thực hiện việc thiết lập cơ sở dữ liệu vào hệ quản trị SQL \n\nServer, thư mục ảo chứa nội dung trang web trong IIS, và tạo shorcut trên desktop.  \n\nMột số giao diện của công cụ cài đặt: \n\n\n\n \n  \n\n \n\n 107 \n\n \n\nHình 7. 4. Màn hình bắt đầu. Click Next để bắt đầu cài đặt \n\n \n\nHình 7. 5.Màn hình chọn chế độ cài đặt hoặc tháo gỡ chương trình.  \n\nChọn Install và click Next để sang bước tiếp theo \n\n\n\n \n  \n\n \n\n 108 \n\n \n\nHình 7. 6.Màn hình chọn đường dẫn để cài đặt chương trình.  \n\nSau khi chọn xong các đường dẫn phù hợp, nhấp vào Next để thực hiện cài đặt. \n\n \n\nHình 7. 7.Màn hình cài đặt chương trình \n\n\n\n \n  \n\n \n\n 109 \n\n \n\nHình 7. 8.Màn hình chọn chức năng gỡ chương trình. \n\nChọn Remove để gỡ chương trình đã cài đặt trên máy. \n\n \n\nHình 7. 9.Màn hình gỡ chương trình thành công \n\n\n\n \n  \n\n \n\n 110 \n\n7.6. Kết quả \nNhờ việc tích hợp module phân loại văn bản vào trong web \u201cTòa soạn báo điện \n\ntử\u201d mà giờ đây công việc phân loại tin tức điện tử đã trở nên nhanh chóng và tiện \n\nlợi hơn. Tuy xác suất phân loại đúng chưa đảm bảo cho hệ thống phân loại văn bản \n\nhoàn toàn tự động, mà cần có sự duyệt bài lại để đảm bào chính xác hoàn toàn, \n\nnhưng module phân loại văn bản bán tự động cũng đã cung cấp cho người dùng một \n\ntiện ích vô cùng hữu hiệu. \n\n\n\n \n  \n\n \n\n 111 \n\n  \n\nCChhưươơnngg  88  \n\nTTỔỔNNGG  KKẾẾTT  \n \n\n \n\n \n\nKết quả đạt được  \n\nVề mặt lý thuyết \n\nVề mặt thực hành \n\nHạn chế và hướng giải quyết \n\nKết luận \n\n\n\n \n  \n\n \n\n 112 \n\nChương 8. TỔNG KẾT \n\n8.1. Kết quả đạt được \n\n8.1.1. Về mặt lý thuyết \nPhân loại văn bản là một bài toán khó và rất thú vị. Khó bởi vì vấn đề phân loại \n\nvăn bản cần phải thực hiện xử lý ngôn ngữ, mà như chúng ta đều biết, ngôn ngữ tự \n\nnhiên là muôn hình vạn trạng, không chỉ phong phú về từ vựng, cú pháp mà còn \n\nphức tạp về ngữ nghĩa. Nhưng đây lại là bài toán rất thú vị vì với mỗi ngôn ngữ \n\nkhác nhau, chúng ta phải thực hiện những cách xử lý khác nhau đối với ngôn ngữ. \n\nTrong khuôn khổ luận văn này, những vấn đề liên quan đến đề tài như các \n\nphương pháp tách từ và phương pháp phân loại văn bản đã được chúng em tiến \n\nhành nghiên cứu khá công phu theo cả chiều rộng lẫn chiều sâu về. Trên cơ sở \n\nnghiên cứu đó, các hướng tiếp cận áp dụng cho tiếng Anh và tiếng Hoa phù hợp đã \n\nđược lựa chọn và thử nghiệm lên tiếng Việt.  \n\nĐặc biệt, ở giai đoạn tách từ chuẩn bị cho phân loại, chúng em đã tìm hiểu một \n\ncách sâu sắc về hướng thống kê dựa trên Internet. Dựa trên nền tảng đó, chúng em  \n\nmạnh dạn thực hiện cải tiến phương pháp tách từ dựa trên Internet và thuật toán di \n\ntruyền thay vì sử dụng lại các công cụ tách từ tiếng Việt đã được công bố trước đây. \n\nHướng tiếp cận mới này không những hạn chế được nhược điểm phụ thuộc vào tập \n\nngữ liệu của các phương pháp khác mà còn đem lại khả năng khai thác vô tận nguồn \n\ndữ liệu khổng lồ của nhân loại : word-wide-web. Kết quả đạt được của phương pháp \n\nnày là hoàn toàn khả quan và chấp nhận được đối với một hướng tiếp cận mới cho \n\ntách từ tiếng Việt dùng trong phân loại văn bản.  \n\nPhương pháp phân loại văn bản Naïve Bayes thường được dùng trong phân loại \n\nvăn bản tiếng Anh, nay được áp dụng trong tiếng Việt với hướng tiếp cận dựa trên \n\nthống kê từ Google tỏ ra khá hiệu bởi. Nhờ tính đơn giản, các thông số tính toán \n\nkhông cần quá lớn như các phương pháp khác, khả năng linh hoạt đối với sự thay \n\nđổi về thông tin huấn luyện, thời gian phân loại phù hợp yêu cầu, Naïve Bayes đã tở \n\nra rất phù hợp với các yêu cầu đề ra.  \n\n\n\n \n  \n\n \n\n 113 \n\n8.1.2. Về mặt thực nghiệm \nCông trình nghiên cứu của luận văn đã thực hiện được nhiều thử nghiệm đối với \n\ntừng hướng tiếp cận tách từ tiếng Việt dựa trên Google cũng như phân loại văn bản. \n\nNhờ vậy, kết quả thực nghiệm đã chứng minh được tính hiệu quả cho các công thức \n\ntrên lý thuyết. \n\nQua kết quả thực nghiệm, chúng em nhận thấy công thức tách từ của [H. \n\nNguyen et al, 2005] và công thức MI do chúng em đề nghị cho hiệu quả gần tương \n\nđương nhau, tuy cách tính của [H. Nguyen et al, 2005] có vẻ chính xác hơn cho các \n\ntừ có hai tiếng. \n\nKết quả thực nghiệm ở phần phân loại văn bản cho thấy công thức phân loại \n\ntrong [H. Nguyen et al, 2005] là mang tính chủ quan của tác giả, và dữ liệu thực \n\nnghiệm không đủ lớn để có thể kết luận. Nhưng khi áp dụng thử nghiệm trên số \n\nlượng văn bản và chủ đề nhiều hơn thì cách tính này cho ra kết quả thấp hơn nhiều \n\nso với kết quả mà tác giả trình bày. Kết quả sử dụng công thức Naïve Bayes đã cho \n\nkết quả khả quan hơn nhờ dựa vào lý thuyết đã được chứng minh từ các công trình \n\ntrước. \n\n8.2. Hạn chế và hướng phát triển \nVới những kết quả thử  nghiệm ban đầu, hệ thống phân loại văn bản đã bước đầu \n\nhoạt động hiệu quả , góp phần thực hiện phân loại văn bản bán tự động, giúp tiết \n\nkiệm được thời gian và công sức đọc văn bản một cách thủ công. Mặc dù những kết \n\nquả của hệ thống là chấp nhận được, tuy nhiên hệ thống có thể được cải thiện về độ \n\nchính xác và tốc độ nếu ta khắc phục một số hạn chế của hệ thống và thực hiện \n\nthêm các hướng mở rộng khác được trình bày sau đây. \n\nPhương pháp tách từ dựa trên Internet và thuật toán di truyền tỏ ra khá linh hoạt \n\ntrong việc xử lý ngôn ngữ. Tuy nhiên với mặt bằng chất lượng Internet hiện nay ở \n\nViệt Nam, bước đầu thực hiện việc tách từ sẽ khá lâu vì phải mất thời gian lấy \n\nthông tin từ  công cụ tìm kiếm trên mạng. Nhưng khi các thông tin trên được lưu lại \n\ntương đối lớn, tốc độ phân định ranh giới từ sẽ được cải thiện. \n\n\n\n \n  \n\n \n\n 114 \n\nTrong phần thử nghiệm phân loại văn bản, hiện tại chúng em quy định một chủ \n\nđề chỉ có một từ khóa chính là tên của chủ đề đó. Chính đây là một điểm hạn chế \n\ndẫn đến kết quả phân loại văn bản chưa cao như  trong các công trình phân loại văn \n\nbản tiếng Anh. Do vậy, nhu cầu xây dựng một công cụ chiết xuất từ khóa tự động từ \n\ntập dữ  liệu tin tức thô là rất cần thiết. Khi đã có tập từ khóa, độ chính xác của việc \n\nphân loại văn bản sẽ tăng lên đáng kể. \n\nHiện tại, luận văn thực hiện phân loại theo hướng tiếp cận Naïve Bayes với các \n\ntừ được tách trong câu mà không có sự chọn lựa những từ đặc trưng để thực hiện \n\nphân loại. Điều này dẫn đến một số từ  không có ý nghĩa phân loại vẫn xem như có \n\nvai trò tương tự như  những từ có ý nghĩa phân loại cao. Nếu chúng ta nghiên cứu \n\nthực hiện chọn lựa các đặc trưng của văn bản (feature selection)  rồi mới","u":"http://202.191.57.85:8000/InternetData/Data/tailieu.vn/docview/tailieu/2015/20151204/gaugau1905/tim_hieu_cac_huong_tiep_can_bai_toan_phan_loai_van_ban_va_xa_6703.txt","sentences":[[1,"TRƯỜNG ĐẠI HỌC KHOA HỌC TỰ NHIÊN KHOA CÔNG NGHỆ THÔNG TIN BỘ MÔN HỆ THỐNG THÔNG TIN SINH VIÊN THỰC HIỆN NGUYỄN TRẦN THIÊN THANH - 0112243 TRẦN KHẢI HOÀNG - 0112305 TÌM HIỂU CÁC HƯỚNG TIẾP CẬN BÀI TOÁN PHÂN LOẠI VĂN BẢN VÀ XÂY DỰNG PHẦN MỀM PHÂN LOẠI TIN TỨC BÁO ĐIỆN TỬ KHÓA LUẬN CỬ NHÂN TIN HỌC GIÁO VIÊN HƯỚNG DẪN Cử nhân : NGUYỄN VIỆT THÀNH Thạc sĩ : NGUYỄN THANH HÙNG Niên khóa 2001-2005"],[2,"i LỜI CẢM ƠN Chúng em xin gửi lời cảm ơn chân thành và sâu sắc nhất đến thầy Nguyễn Việt Thành và thầy Nguyễn Thanh Hùng đã tận tụy hướng dẫn, động viên, giúp đỡ chúng em trong suốt thời gian thực hiện đề tài"],[3,"Chúng em xin chân thành cảm ơn quý Thầy Cô trong Khoa Công Nghệ Thông Tin truyền đạt kiến thức quý báu cho chúng em trong những năm học vừa qua"],[4,"Chúng con xin nói lên lòng biết ơn đối với Ông Bà, Cha Mẹ luôn là nguồn chăm sóc, động viên trên mỗi bước đường học vấn của chúng con"],[5,"Xin chân thành cám ơn các anh chị và bạn bè đã ủng hộ, giúp đỡ và động viên chúng em trong thời gian học tập và nghiên cứu"],[6,"Mặc dù chúng em đã cố gắng hoàn thành luận văn trong phạm vi và khả năng cho phép nhưng chắc chắn sẽ không tránh khỏi những thiếu sót"],[7,"Chúng em kính mong nhận được sự cảm thông và tận tình chỉ bảo của quý Thầy Cô và các bạn"],[8,"Nguyễn Trần Thiên Thanh & Trần Khải Hoàng 07/2005"],[9,"ii LỜI NÓI ĐẦU Trong những năm gần đây, sự phát triển vượt bậc của công nghệ thông tin đã làm tăng số lượng giao dịch thông tin trên mạng Internet một cách đáng kể đặc biệt là thư viện điện tử, tin tức điện tử..."],[10,"Do đó mà số lượng văn bản xuất hiện trên mạng Internet cũng tăng theo với một tốc độ chóng mặt"],[11,"Theo số lượng thống kê từ Broder et al (2003), lượng thông tin đó lại tăng gấp đôi sau từ 9 đến 12 tháng, và tốc độ thay đổi thông tin là cực kỳ nhanh chóng"],[12,"Với lượng thông tin đồ sộ như vậy, một yêu cầu lớn đặt ra đối với chúng ta là làm sao tổ chức và tìm kiếm thông tin có hiệu quả nhất"],[13,"Phân loại thông tin là một trong những giải pháp hợp lý cho yêu cầu trên"],[14,"Nhưng một thực tế là khối lượng thông tin quá lớn, việc phân loại dữ liệu thủ công là điều không tưởng"],[15,"Hướng giải quyết là một chương trình máy tính tự động phân loại các thông tin trên"],[16,"Chúng em đã tập trung thực hiện đề tài \u201cTìm hiểu các hướng tiếp cận cho bài toán phân loại văn bản và xây dựng ứng dụng phân loại tin tức báo điện tử\u201d nhằm tìm hiểu và thử nghiệm các phương pháp phân loại văn bản áp dụng trên tiếng Việt"],[17,"Để thực hiện việc phân loại, điều bắt buộc đối với tiếng Việt đó là việc tách từ"],[18,"Trong luận văn này, chúng em cũng tìm hiểu một số cách tách từ tiếng Việt và thử nghiệm một phương pháp tách từ mới thích hợp cho việc phân loại mà không dùng bất kỳ từ điển hoặc tập ngữ liệu nào"],[19,"Cuối cùng, chúng em xây dựng phần mềm phân loại văn bản tích hợp vào trang web \u201cToà soạn báo điện tử\u201d (Luận văn khoá 2000 - Hoàng Minh Ngọc Hải (0012545), Nguyễn Duy Hiệp (0012038)) nhằm phục vụ cho việc phân loại tin tức báo điện tử"],[20,"Hiện nay, trang web của khoa chúng ta vẫn chưa thực hiện được việc phân loại tự động các tin tức lấy về, do đó gây ra rất nhiều lãng phí về thời gian và công sức của nhà quản trị cũng như làm giới hạn việc thu thập tin tức từ nhiều nguồn khác nhau"],[21,"Ứng dụng phân loại tin tức báo điện tử tích hợp với việc lấy tin tức tự động của chúng em hy vọng sẽ đem đến một cách quản trị mới, nhanh chóng và hiệu quả hơn cách lấy tin truyền thống"],[22,"Ngoài ra, trong điều kiện cần cập nhật thông tin một"],[23,"iii cách nhanh chóng như hiện nay, phần mềm phân loại văn bản tự động của chúng em còn có khả năng ứng dụng cho nhiều loại trang báo điện tử tiếng Việt khác"],[24,"Nội dung của luận văn được trình bày bao gồm 8 chương; trong đó, 3 chương đầu trình bày các hướng tiếp cận cho phân loại văn bản và tách từ tiếng Việt hiện nay; 2 chương tiếp theo trình bày hướng tiếp cận của luận văn đối với phân loại văn bản và tách từ tiếng Việt; 3 chương cuối trình bày hệ thống thử nghiệm văn bản, ứng dụng vào phân loại tin tức bán tự động, và cuối cùng là đánh giá, kết luận quá trình nghiên cứu của luận văn"],[25,"Chương 1"],[26,"Tổng quan: giới thiệu sơ lược về các phương pháp phân loại văn bản và các hướng tiếp cận cho việc tách từ tiếng Việt; đồng thời xác định mục tiêu của đề tài"],[27,"Chương 2"],[28,"Một số phương pháp phân loại văn bản: giới thiệu tóm tắt một số phương pháp phân loại văn bản dành cho tiếng Anh"],[29,"Chương 3"],[30,"Phương pháp tách từ tiếng Việt hiện nay: trình bày tóm tắt một số phương pháp tách từ tiếng Việt hiện nay, ưu điểm và hạn chế của các phương pháp đó"],[31,"Chương 4"],[32,"Phương Tách từ Tiếng Việt không dựa trên tập ngữ liệu đánh dấu (annotated corpus) hay từ điển (lexicon) \u2013 Một thách thức: trình bày phương pháp tách từ tiếng Việt mới chỉ dựa vào việc thống kê từ Internet thông qua Google mà không cần bất kỳ từ điển hay tập ngữ liệu nào"],[33,"Chương 5"],[34,"Bài toán phân loại tin tức báo điện tử: trình bày hướng tiếp cận cho bài toán phân loại tin tức báo điện tử"],[35,"Chương 6"],[36,"Hệ thống thử nghiệm phân loại văn bản: giới thiệu về hệ thống thử nghiệm các phương pháp tách từ và phân loại văn bản do chúng em xây dựng"],[37,"Ngoài ra, trong chương 6, chúng em trình bày về dữ liệu dùng để thử nghiệm và các kết quả thử nghiệm thu được"],[38,"Chương 7"],[39,"Ứng dụng phân loại tin tức báo điện tử bán tự động: giới thiệu ứng dụng phân loại tin tức báo điện tử do chúng em xây dựng tích hợp"],[40,"iv trên trang web do luận văn \u201cTòa soạn báo điện tử\u201d khóa 2000 xây dựng của sinh viên Hoàng Minh Ngọc Hải (0012545), Nguyễn Duy Hiệp (0012038) Chương 8"],[41,"Tổng kết: là chương cuối cùng của đề tài, tóm lại các vấn đề đã giải quyết và nêu một số hướng phát triển trong tương lai"],[42,""],[43,"v MỤC LỤC Chương 1"],[44,"TỔNG QUAN............................................................................................2 1.1"],[45,"Đặt vấn đề ............................................................................................................2 1.2"],[46,"Các phương pháp phân loại văn bản...................................................................2 1.3"],[47,"Tách từ Tiếng Việt \u2013 Một thách thức thú vị ........................................................3 1.4"],[48,"Mục tiêu của luận văn..........................................................................................5 1.4.1"],[49,"Phần tìm hiểu các thuật toán phân loại văn bản.........................................5 1.4.2"],[50,"Phần tách từ tiếng Việt...............................................................................5 1.4.3"],[51,"Phần mềm phân loại tin tức báo điện tử bán tự động ................................5 1.4.4"],[52,"Đóng góp của luận văn ..............................................................................6 Chương 2"],[53,"CÁC PHƯƠNG PHÁP PHÂN LOẠI VĂN BẢN TIẾNG ANH..............8 2.1"],[54,"Bối cảnh các phương pháp phân loại văn bản hiện nay.......................................8 2.2"],[55,"Các phương pháp phân loại văn bản tiếng Anh hiện hành ..................................8 2.2.1"],[56,"Biểu diễn văn bản ......................................................................................8 2.2.2"],[57,"Support vector Machine(SVM) ...............................................................10 2.2.3"],[58,"K\u2013Nearest Neighbor (kNN).....................................................................12 2.2.4"],[59,"Naïve Bayes (NB)....................................................................................13 2.2.5"],[60,"Neural Network (NNet) ...........................................................................15 2.2.6"],[61,"Linear Least Square Fit (LLSF)...............................................................17 2.2.7"],[62,"Centroid- based vector .............................................................................18 2.3"],[63,"Kết luận..............................................................................................................19 Chương 3"],[64,"CÁC PHƯƠNG PHÁP TÁCH TỪ TIẾNG VIỆT HIỆN NAY ..............22 3.1"],[65,"Tại sao tách từ tiếng Việt là một thách thức"],[66,"....................................................22 3.1.1"],[67,"So sánh giữa tiếng Việt và tiếng Anh ......................................................22 3.1.2"],[68,"Nhận xét ...................................................................................................23 3.2"],[69,"Bối cảnh các phương pháp tách từ hiện nay ......................................................23 3.2.1"],[70,"Bối cảnh chung ........................................................................................23 3.2.2"],[71,"Các hướng tiếp cận dựa trên từ (Word-based approaches)......................24 3.2.3"],[72,"Các hướng tiếp cận dựa trên ký tự (Character-based approaches) ..........26 3.3"],[73,"Một số phương pháp tách từ tiếng Việt hiện nay...............................................28 3.3.1"],[74,"Phương pháp Maximum Matching: forward/backward...........................28"],[75,"vi 3.3.2"],[76,"Phương pháp giải thuật học cải biến ( TBL)............................................30 3.3.3"],[77,"Mô hình tách từ bằng WFST và mạng Neural.........................................31 3.3.4"],[78,"Phương pháp quy hoạch động (dynamic programming) .........................34 3.3.5"],[79,"Phương pháp tách từ tiếng Việt dựa trên thống kê từ Internet và thuật toán di truyền (Internet and Genetics Algorithm-based Text Categorization for Documents in Vietnamese - IGATEC)........................................................................34 3.4"],[80,"So sánh các phương pháp tách từ Tiếng Việt hiện nay......................................37 3.5"],[81,"Kết luận..............................................................................................................37 Chương 4"],[82,"TÁCH TỪ TIẾNG VIỆT KHÔNG DỰA TRÊN TẬP NGỮ LIỆU ĐÁNH DẤU (ANNOTATED CORPUS) HAY TỪ ĐIỂN (LEXICON) \u2013 MỘT THÁCH THỨC 40 4.1"],[83,"Giới thiệu ...........................................................................................................40 4.2"],[84,"Các nghiên cứu về thống kê dựa trên Internet ...................................................40 4.2.1"],[85,"Giới thiệu .................................................................................................40 4.2.2"],[86,"Một số công trình nghiên cứu về thống kê dựa trên Internet...................41 4.2.3"],[87,"Nhận xét ...................................................................................................43 4.3"],[88,"Các phương pháp tính độ liên quan giữa các từ dựa trên thống kê ...................43 4.3.1"],[89,"Thông tin tương hỗ và t-score dùng trong tiếng Anh ............................44 4.3.2"],[90,"Một số cải tiến trong cách tính độ liên quan ứng dụng trong tách từ tiếng Hoa và tiếng Việt .........................................................................................................46 4.3.3"],[91,"Nhận xét về các cách tính độ liên quan khi áp dụng cho tiếng Việt .......48 4.4"],[92,"Tiền xử lý (Pre-processing) ...............................................................................49 4.4.1"],[93,"Xử lý văn bản đầu vào .............................................................................49 4.4.2"],[94,"Tách ngữ & tách stopwords .....................................................................50 4.5"],[95,"Hướng tiếp cận tách từ dựa trên thống kê từ Internet và thuật toán di truyền (Internet and Genetic Algorithm - based ) .......................................................................51 4.5.1"],[96,"Công cụ trích xuất thông tin từ Google ...................................................51 4.5.2"],[97,"Công cụ tách từ dùng thuật toán di truyền (Genetic Algorithm \u2013 GA) ...53 4.6"],[98,"Kết luận..............................................................................................................61 Chương 5"],[99,"BÀI TOÁN PHÂN LOẠI TIN TỨC ĐIỆN TỬ ......................................63 5.1"],[100,"Lý do chọn phương pháp Naïve Bayes..............................................................63 5.2"],[101,"Thuật toán Naïve Bayes.....................................................................................64 5.2.1"],[102,"Công thức xác suất đầy đủ Bayes ............................................................64"],[103,"vii 5.2.2"],[104,"Tính độc lập có điều kiện (Conditional Independence) ...........................65 5.2.3"],[105,"Nguồn gốc thuật toán Naïve Bayes..........................................................65 5.2.4"],[106,"Phương pháp Naïve Bayes trong phân loại văn bản ................................66 5.2.5"],[107,"Hai mô hình sự kiện trong phân loại văn bản bằng phương pháp Naïve Bayes 68 5.3"],[108,"Bài toán phân loại tin tức điện tử tiếng Việt ......................................................70 5.3.1"],[109,"Quy ước ...................................................................................................70 5.3.2"],[110,"Công thức phân loại văn bản trong IGATEC [H"],[111,"Nguyen et al, 2005] ...71 5.3.3"],[112,"Công thức Naïve Bayes trong bài toán phân loại tin tức điện tử tiếng Việt sử dụng thống kê từ Google.........................................................................................72 5.4"],[113,"Kết luận..............................................................................................................74 Chương 6"],[114,"HỆ THỐNG THỬ NGHIỆM PHÂN LOẠI VĂN BẢN ......................76 6.1"],[115,"Giới thiệu hệ thống thử nghiệm Vikass .............................................................76 6.1.1"],[116,"Chức năng hệ thống Vikass .....................................................................76 6.1.2"],[117,"Tổ chức và xử lý dữ liệu ..........................................................................76 6.1.3"],[118,"Một số màn hình của hệ thống Vikass.....................................................79 6.2"],[119,"Thử nghiệm các cách trích xuất thông tin..........................................................82 6.2.1"],[120,"Các phương pháp thử nghiệm..................................................................82 6.2.2"],[121,"Nhận xét ...................................................................................................84 6.3"],[122,"Dữ liệu thử nghiệm ............................................................................................84 6.3.1"],[123,"Nguồn dữ liệu ..........................................................................................84 6.3.2"],[124,"Số lượng dữ liệu thử nghiệm ...................................................................84 6.3.3"],[125,"Nhận xét ...................................................................................................86 6.4"],[126,"Thử nghiệm các công thức tính độ tương hỗ MI ...............................................87 6.4.1"],[127,"Các phương pháp thử nghiệm..................................................................87 6.4.2"],[128,"Kết quả .....................................................................................................87 6.4.3"],[129,"Nhận xét ...................................................................................................88 6.5"],[130,"Thử nghiệm phân loại tin tức điện tử.................................................................89 6.5.1"],[131,"Thước đo kết quả phân loại văn bản........................................................89 6.5.2"],[132,"Các phương pháp thử nghiệm..................................................................91 6.5.3"],[133,"Kết quả .....................................................................................................91 6.5.4"],[134,"Nhận xét ...................................................................................................96"],[135,"viii Chương 7"],[136,"ỨNG DỤNG PHÂN LOẠI TIN TỨC ĐIỆN TỬ TỰ ĐỘNG ................99 7.1"],[137,"Giới thiệu tòa soạn báo điện tử ..........................................................................99 7.2"],[138,"Tính cần thiết của phân loại tin tức tự động ......................................................99 7.3"],[139,"Phân tích hiện trạng .........................................................................................100 7.3.1"],[140,"Mô hình DFD quan niệm cấp 2 hiện hành cho ô xử lý Nhận bài và Trả bài 100 7.3.2"],[141,"Phê phán hiện trạng................................................................................103 7.3.3"],[142,"Mô hình DFD quan niệm cấp 2 mới cho ô xử lý Nhận bài và Trả bài ..104 7.4"],[143,"Triển khai DLL ................................................................................................105 7.5"],[144,"Chương trình cài đặt \u201cTòa soạn báo điện tử\u201d đã tích hợp module phân loại tin tức 106 7.6"],[145,"Kết quả .............................................................................................................110 Chương 8"],[146,"TỔNG KẾT............................................................................................112 8.1"],[147,"Kết quả đạt được ..............................................................................................112 8.1.1"],[148,"Về mặt lý thuyết.....................................................................................112 8.1.2"],[149,"Về mặt thực nghiệm...............................................................................113 8.2"],[150,"Hạn chế và hướng phát triển............................................................................113 8.3"],[151,"Kết luận............................................................................................................114"],[152,"ix DANH SÁCH HÌNH Hình 2"],[153,"1"],[154,"Biểu diễn văn bản .................................................................................................9 Hình 2"],[155,"2"],[156,"Siêu mặt phẳng h phân chia dữ liệu huấn huyện thành 2 lớp + và \u2013 với khoảng cách biên lớn nhất"],[157,"Các điểm gần h nhất là các vector hỗ trợ ,Support Vector (được khoanh tròn).............................................................................................................11 Hình 2"],[158,"3"],[159,"Hình Kiến trúc mô đun (Modular Architecture)"],[160,"Các kết quả của từng mạng con sẽ là giá trị đầu vào cho mạng siêu chủ đề và được nhân lại với nhau để dự đoán chủ đề cuối cùng"],[161,"....................................................................................................16 Hình 3.4"],[162,"Các hướng tiếp cận cơ bản trong tách từ tiếng Hoa và các hướng tiếp cận hiện tại được công bố trong tách từ tiếng Việt .....................................................................24 Hình 3.5"],[163,"Sơ đồ hệ thống WFST..........................................................................................31 Hình 3.6"],[164,"Toàn cảnh hệ thống IGATEC ..............................................................................35 Hình 4"],[165,"1"],[166,"Nội dung thông tin cần lấy..................................................................................50 Hình 4"],[167,"2"],[168,"Biểu diễn cá thể bằng các bit 0,1 ........................................................................55 Hình 4"],[169,"3"],[170,"Thang tỉ lệ phát sinh loại từ ................................................................................57 Hình 4"],[171,"4.Quá trình lai ghép ................................................................................................58 Hình 4"],[172,"5"],[173,"Quá trình đột biến ...............................................................................................59 Hình 4"],[174,"6"],[175,"Quá trình sinh sản ...............................................................................................59 Hình 4"],[176,"7"],[177,"Quá trình chọn cá thể ..........................................................................................60 Hình 5"],[178,"1"],[179,"Minh họa quy ước cho văn bản...........................................................................70 Hình 5"],[180,"2.Minh họa chủ đề \u201cXã hội\u201d ...................................................................................70 Hình 6"],[181,"1"],[182,"Tổ chức file dữ liệu.............................................................................................77 Hình 6"],[183,"2"],[184,"Chủ đề Thể thao..................................................................................................77 Hình 6"],[185,"3"],[186,"Màn hình tách từ .................................................................................................79 Hình 6"],[187,"4"],[188,"Màn hình trích xuất từ Google...........................................................................80 Hình 6"],[189,"5"],[190,"Màn hình phân loại tin tức điện tử......................................................................81 Hình 6"],[191,"6"],[192,"Cây chủ đề ..........................................................................................................86 Hình 6"],[193,"7"],[194,"Biểu đồ so sánh kết quả các công thức tính độ tương hỗ MI..............................88 Hình 6"],[195,"8"],[196,"Các thông số dùng tính độ thu về, độ chính xác .................................................89 Hình 6"],[197,"9"],[198,"Biểu đồ F1 cho cấp 1 ..........................................................................................94 Hình 6"],[199,"10"],[200,"Biểu đồ F1 cho cấp 2 ........................................................................................96"],[201,"x Hình 7"],[202,"1.Mô hình DFD hiện hành ....................................................................................100 Hình 7"],[203,"2"],[204,"Mô hình DFD cải tiến .......................................................................................104 Hình 7"],[205,"3"],[206,"Màn hình lấy tin tức cho phép phân loại tự động .............................................106 Hình 7"],[207,"4"],[208,"Màn hình bắt đầu"],[209,"Click Next để bắt đầu cài đặt ..............................................107 Hình 7"],[210,"5.Màn hình chọn chế độ cài đặt hoặc tháo gỡ chương trình"],[211,"................................107 Hình 7"],[212,"6.Màn hình chọn đường dẫn để cài đặt chương trình"],[213,"..........................................108 Hình 7"],[214,"7.Màn hình cài đặt chương trình...........................................................................108 Hình 7"],[215,"8.Màn hình chọn chức năng gỡ chương trình"],[216,"......................................................109 Hình 7"],[217,"9.Màn hình gỡ chương trình thành công...............................................................109"],[218,"xi DANH SÁCH BẢNG Bảng 3"],[219,"1"],[220,"So sánh giữa tiếng Việt và tiếng Anh.................................................................23 Bảng 4"],[221,"1"],[222,"Thống kê độ dài từ trong từ điển ........................................................................54 Bảng 4"],[223,"2"],[224,"Tham số thực hiện GA .......................................................................................56 Bảng 6"],[225,"1"],[226,"Mô tả một số control của màn hình tách từ ........................................................79 Bảng 6.2"],[227,"Mô tả một số control của màn hình trích từ Google ...........................................80 Bảng 6.3"],[228,"Bảng mô tả một số control của màn hình phân loại tin tức điện tử.....................81 Bảng 6"],[229,"4"],[230,"Tham số sử dụng dịch vụ Google.......................................................................82 Bảng 6"],[231,"5"],[232,"Một số câu truy vấn đặc biệt của Google ...........................................................83 Bảng 6"],[233,"6"],[234,"Kết quả thực nghiệm các công thức tính độ tương hỗ MI..................................87 Bảng 6"],[235,"7"],[236,"Bốn trường hợp của phân loại văn bản...............................................................90 Bảng 6"],[237,"8"],[238,"Kết quả phân loại văn bản cho từng chủ đề........................................................94 Bảng 7"],[239,"1"],[240,"Bảng kho dữ liệu những bài viết chưa được đăng............................................102 Bảng 7"],[241,"2"],[242,"Bảng mô tả các ô xử lý của mô hình DFD hiện hành.......................................103 Bảng 7"],[243,"3"],[244,"Bảng mô tả ô xử lý phân loại tin tức tự động...................................................105"],[245,"1 CChhưươơnngg 11 TTỔỔNNGG QQUUAANN Đặt vấn đề Các phương pháp phân loại văn bản Tách từ tiếng Việt \u2013 Một thách thức thú vị Mục tiêu của luận văn Phần tìm hiểu các thuật toán phân loại văn bản Phần tách từ tiếng Việt Phần mềm phân loại tin tức báo điện tử bán tự động"],[246,"2 Chương 1"],[247,"TỔNG QUAN 1.1"],[248,"Đặt vấn đề Trong thời đại bùng nổ công nghệ thông tin hiện nay, phương thức sử dụng giấy tờ trong giao dịch đã dần được số hoá chuyển sang các dạng văn bản lưu trữ trên máy tính hoặc truyền tải trên mạng"],[249,"Bởi nhiều tính năng ưu việt của tài liệu số như cách lưu trữ gọn nhẹ, thời gian lưu trữ lâu dài, tiện dụng trong trao đổi đặc biệt là qua Internet, dễ dàng sửa đổi\u2026 nên ngày nay, số lượng văn bản số tăng lên một cách chóng mặt đặc biệt là trên world-wide-web"],[250,"Cùng với sự gia tăng về số lượng văn bản, nhu cầu tìm kiếm văn bản cũng tăng theo"],[251,"Với số lượng văn bản đồ sộ thì việc phân loại văn bản tự động là một nhu cầu bức thiết"],[252,"Tại sao phải phân loại văn bản tự động"],[253,"Việc phân loại văn bản sẽ giúp chúng ta tìm kiếm thông tin dễ dàng và nhanh chóng hơn rất nhiều so với việc phải bới tung mọi thứ trong ổ đĩa lưu trữ để tìm kiếm thông tin"],[254,"Mặt khác, lượng thông tin ngày một tăng lên đáng kể, việc phân loại văn bản tự động sẽ giúp con người tiết kiệm được rất nhiều thời gian và công sức"],[255,"Do vậy, các phương pháp phân loại văn bản tự động đã ra đời để phục vụ cho nhu cầu chính đáng đó"],[256,"1.2"],[257,"Các phương pháp phân loại văn bản Theo Yang & Xiu (1999), \u201cviệc phân loại văn bản tự động là việc gán các nhãn phân loại lên một văn bản mới dựa trên mức độ tương tự của văn bản đó so với các văn bản đã được gán nhãn trong tập huấn luyện\u201d"],[258,"Từ trước đến nay, phân loại văn bản tự động trong tiếng Anh đã có rất nhiều công trình nghiên cứu và đạt được kết quả đáng khích lệ"],[259,"Dựa trên các thống kê của Yang & Xiu (1999) và nghiên cứu của chúng em, một số phương pháp phân loại thông dụng hiện nay là: Support Vector Machine [Joachims, 1998], k-Nearest Neighbor [Yang, 1994], Linear Least Squares Fit [Yang and Chute, 1994] Neural Network [Wiener et al, 1995], Naïve Bayes [Baker and Mccallum, 2000], Centroid- based [Shankar and Karypis, 1998]"],[260,"Các phương pháp trên đều dựa vào xác suất"],[261,"3 thống kê hoặc thông tin về trọng số của từ trong văn bản"],[262,"Chi tiết về ý tưởng và công thức tính toán của mỗi phương pháp sẽ được chúng em trình bày ở chương 3, mục 3.3"],[263,"Mỗi phương pháp phân loại văn bản đều có cách tính toán khác nhau, tuy nhiên, nhìn một cách tổng quan thì các phương pháp đó đều phải thực hiện một số bước chung như sau: đầu tiên, mỗi phương pháp sẽ dựa trên các thông tin về sự xuất hiện của từ trong văn bản (ví dụ tần số, số văn bản chứa từ\u2026) để biểu diễn văn bản thành dạng vector; sau đó, tuỳ từng phương pháp mà ta sẽ áp dụng công thức và phương thức tính toán khác nhau để thực hiện việc phân loại"],[264,"Đối với tiếng Anh, các kết quả trong lĩnh vực này rất khả quan, còn đối với tiếng Việt, các công trình nghiên cứu về phân loại văn bản gần đây đã có một số kết quả ban đầu nhưng vẫn còn nhiều hạn chế"],[265,"Nguyên nhân là ngay ở bước đầu tiên, chúng ta đã gặp khó khăn trong việc xử lý văn bản để rút ra tần số xuất hiện của từ"],[266,"Trong khi đó, để phân loại văn bản thì có thể nói bước đầu tiên là quan trọng nhất bởi vì nếu ở bước tách từ đã sai thì việc phân loại hầu như không thể thành công được"],[267,"Phần trình bày tiếp theo sẽ cho chúng ta biết những thách thức đặt ra trong việc tách từ tiếng Việt, cũng như những ứng dụng thú vị của nó"],[268,"1.3"],[269,"Tách từ Tiếng Việt \u2013 Một thách thức thú vị Đối với tiếng Anh, \u201ctừ là một nhóm các ký tự có nghĩa được tách biệt với nhau bởi khoảng trắng trong câu\u201d (Webster Dictionary), do vậy việc tách từ trở nên rất đơn giản"],[270,"Trong khi đối với tiếng Việt, ranh giới từ không được xác định mặc định là khoảng trắng mà tùy thuộc vào ngữ cảnh dùng câu tiếng Việt"],[271,"Ví dụ các từ trong tiếng Anh là \u201cbook\u201d , \u201ccat\u201d, \u201cstadium\u201d thì trong tiếng Việt là \u201cquyển sách\u201d, \u201ccon mèo\u201d, \u201csân vận động\u201d \u2026 Vấn đề trên thực sự đưa ra một thách thức đối với chúng ta - những người làm tin học"],[272,"Tuy nhiên, thách thức nào cũng có cái thú vị của nó"],[273,"Nếu chúng ta giải quyết được việc tách từ một cách thoả đáng, thì thành quả mà chúng ta đạt được là một nền tảng để phát triển cho các hướng nghiên cứu khác có liên quan đến việc xử lý ngôn ngữ tự nhiên như: phân loại văn bản, dịch tự động, kiểm tra lỗi chính tả, kiểm"],[274,"4 tra ngữ pháp\u2026 Đó là các ứng dụng rất thiết thực với đời sống con người và là mục tiêu của con người đang chinh phục"],[275,"Một số nước châu Á như Trung Quốc, Nhật Bản, Hàn Quốc, Việt Nam sử dụng loại hình ngôn ngữ gần như tương tự nhau về mặt hình thái và cú pháp"],[276,"Do đó ta có thể áp dụng, cải tiến một số phương pháp tách từ của các nước bạn đặc biệt là Trung Quốc vào việc tách từ tiếng Việt"],[277,"Theo Đinh Điền (2004), các phương pháp tách từ sau có nguồn gốc từ tiếng Hoa đã được thử nghiệm trên tiếng Việt : Maximum Matching: forward/backward hay còn gọi LRMM (Left Right Maximum Matching); giải thuật học cải biến TBL; mạng chuyển dịch trạng thái hữu hạn có trọng số WFST (Weighted finite-state Transducer); giải thuật dựa trên nén (compression);\u2026.Theo các cách tiếp cận trên, điều kiện quan trọng cần có là một hệ thống từ điển (LRMM) và ngữ liệu đánh dấu (TBL, WFST) đầy đủ, chuẩn xác"],[278,"Một từ điển hay một tập ngữ liệu không hoàn chỉnh sẽ làm giảm hiệu suất của thuật toán"],[279,"Tuy nhiên, khó có thể tạo ra được một từ điển hoàn chỉnh nhất là trong thời đại ngày nay, ngôn ngữ còn tiếp tục phát triển và thay đổi từng ngày"],[280,"Xét về mặt phổ biến, tiếng Anh là ngôn ngữ được dùng rộng rãi trong giao dịch trên thế giới"],[281,"Do đó để tạo ra một tập ngữ liệu tiếng Anh thỏa các tiêu chí chọn mẫu ngữ liệu là không quá phức tạp"],[282,"Trong khi đó, Việt Nam chỉ mới cho phép truy cập Internet trong vòng chục năm trở lại đây, do đó số lượng trang web tiếng Việt là không nhiều"],[283,"Cho đến nay, vẫn chưa có một tập ngữ liệu huấn luyện chuẩn nào dành cho việc tách từ và phân loại trang web tiếng Việt được công bố"],[284,"Gần đây, một phương pháp tách từ mới được giới thiệu có ưu điểm là không cần dùng tập ngữ liệu hay từ điển để lấy thông tin thống kê hay trọng số của từ, đó là phương pháp Internet and Genetics Algorithm-based Text Categorization (IGATEC) của H"],[285,"Nguyen et al (2005)"],[286,"Điểm sáng tạo của thuật toán là kết hợp thuật toán di truyền với việc trích xuất thông tin thống kê từ Internet thông qua một công cụ tìm kiếm (như Google chẳng hạn) thay vì lấy từ tập ngữ liệu như các phương pháp trước"],[287,""],[288,"5 Chúng em thực hiện bước tách từ trong luận văn này dựa trên ý tưởng của thuật toán IGATEC nhưng có bổ sung nhiều cải tiến đáng kể để tăng độ chính xác đồng thời thực hiện các thí nghiệm chi tiết nhằm so sánh các cách áp dụng thuật toán để tìm ra cách tối ưu nhất"],[289,"1.4"],[290,"Mục tiêu của luận văn 1.4.1"],[291,"Phần tìm hiểu các thuật toán phân loại văn bản Trong khuôn khổ luận văn này, chúng em tìm hiểu ở mức cơ bản một số phương pháp phân loại văn bản hiện có đang áp dụng cho tiếng Anh và đưa ra một số so sánh nhất định giữa các phương pháp: Support Vector Machine (Joachims, 1998), k- Nearest Neighbor (Yang, 1994), Linear Least Squares Fit (Yang and Chute, 1994) Neural Network (Wiener et al, 1995), Naïve Bayes (Baker and Mccallum, 2000), Centroid-based (Shankar and Karypis, 1998)"],[292,"Sau đó, chúng em sẽ chọn và áp dụng một phương pháp cho bài toán phân loại tin tức báo điện tử tiếng Việt chấp nhận được, phù hợp với mức độ và thời gian cho phép của một luận văn đại học"],[293,"1.4.2"],[294,"Phần tách từ tiếng Việt Hiện nay các phương pháp tách từ tiếng Việt được công bố vẫn chưa nhiều và hướng tiếp cận chủ yếu dựa vào tập huấn luyện và từ điển"],[295,"Như chúng ta đã biết, việc tạo ra hệ thống dữ liệu đó không phải là một sớm một chiều, mà yêu cầu đầu tư khá nhiều công sức, thời gian và tiền bạc"],[296,"Trong luận văn này, chúng em cố gắng tìm hiểu, cải tiến, cài đặt, thử nghiệm một phương pháp tách từ tiếng Việt theo hướng tiếp cận IGATEC, có độ chính xác chấp nhận được, và điều quan trọng là không cần dùng tập ngữ liệu (corpus) để phân định ranh giới từ"],[297,"Sau đó, chúng em sẽ cài đặt, thử nghiệm độ chính xác của phương pháp tách từ này trong khía cạnh phân loại văn bản 1.4.3"],[298,"Phần mềm phân loại tin tức báo điện tử bán tự động"],[299,"6 Để thử nghiệm hướng nghiên cứu tách từ tiếng Việt và phân loại văn bản của luận văn, chúng em tích hợp phần mềm phân loại tin tức vào trang web báo điện tử có sẵn được xây dựng trên nền DotNetNuke Portal của luận văn khoá 2000 ( Hoàng Minh Ngọc Hải (0012545), Nguyễn Duy Hiệp (0012038) ) Như chúng ta đều biết, điều kiện mạng cung cấp cho các trường đại học ở nước ta hiện nay là khá hạn chế, khó đáp ứng được hoàn toàn việc cho phép các sinh viên lên mạng Internet để xem các tin tức mới hằng ngày"],[300,"Để giải quyết phần nào vấn đề trên, chúng ta có thể chọn lọc một số tin tức từ các nguồn khác, đăng tải trên trang web nội bộ của trường"],[301,"Trên cơ sở đó, chúng em tích hợp phần mềm phân loại tin tức báo điện tử tự động vào toà soạn báo điện tử cho phép lấy tin tự động từ các trang web khác"],[302,"Nhờ vậy, công việc lấy tin và phân loại tin tức giờ đây đã trở nên rất dễ dàng và nhanh chóng, tiết kiệm nhiều công sức và thời gian cho nhà quản trị"],[303,"Không chỉ ứng dụng cho các trường đại học, phần mềm phân loại tin tức của chúng em còn có thể ứng dụng, hỗ trợ cho nhiều công việc khác như : lưu trữ (clipping) báo chí, xây dựng bộ ngữ liệu cho các bài toán cần dữ liệu được phân loại, tiền đề cho các bài toán khác như phân loại website"],[304,"1.4.4"],[305,"Đóng góp của luận văn Luận văn đã thực hiện việc được nhiều cải tiến của hướng tiếp cận tách từ tiếng Việt dùng trong phân loại văn bản theo phương pháp dựa trên thống kê Internet"],[306,"Đối với tách từ tiếng Việt, chúng em đề nghị thêm một công thức tính toán độ tương hỗ mới, từ đó thực hiện thử nghiệm tính hiệu quả của cách tính này so với cách công thức ở những công trình khác"],[307,"Trong quá trình xây dựng thuật toán di truyền dùng trong tách từ, chúng em đã cải tiến hình thức đột biến mới phù hợp với hình thức cấu tạo từ trong câu"],[308,"Đối với việc phân loại văn bản, chúng em cải tiến công thức tính trong hướng tiếp cận Naïve Bayes phù hợp với phương pháp tính dựa trên thống kê từ Google"],[309,""],[310,"7 CChhưươơnngg 22 CCÁÁCC PPHHƯƯƠƠNNGG PPHHÁÁPP PPHHÂÂNN LLOOẠẠII VVĂĂNN BBẢẢNN TTIIẾẾNNGG AANNHH Bối cảnh các phương pháp phân loại văn bản hiện nay Các phương pháp phân loại văn bản tiếng Anh hiện hành Biểu diễn văn bản Support vector Machine (SVM) K\u2013Nearest Neighbor (kNN) Naïve Bayes (NB) Neural Network (NNet) Linear Least Square Fit (LLSF) Centroid- based vector Kết luận"],[311,"8 Chương 2"],[312,"CÁC PHƯƠNG PHÁP PHÂN LOẠI VĂN BẢN TIẾNG ANH 2.1"],[313,"Bối cảnh các phương pháp phân loại văn bản hiện nay Phân loại văn bản tự động là một lĩnh vực được chú ý nhất trong những năm gần đây"],[314,"Để phân loại người ta sử dụng nhiều cách tiếp cận khác nhau như dựa trên từ khóa, dựa trên ngữ nghĩa các từ có tần số xuất hiện cao, mô hình Maximum Entropy, tập thô \u2026 Tiếng Anh là một trong những ngôn ngữ được nghiên cứu sớm và rộng rãi nhất với kết quả đạt được rất khả quan"],[315,"Một số lượng lớn các phương pháp phân loại đã được áp dụng thành công trên ngôn ngữ này : mô hình hồi quy [Fuhr et al,1991], phân loại dựa trên láng giềng gần nhất (k-nearest neighbors) [Dasarathy, 1991], phương pháp dựa trên xác suất Naïve Bayes [Joachims, 1997], cây quyết định [Fuhr et al,1991], học luật quy nạp [William & Yoram, 1996], mạng nơron (neural network)[Wiener et al, 1995], học trực tuyến[William & Yoram, 1996], và máy vector hỗ trợ (SVM-support vector machine) [Vapnik, 1995]"],[316,"Hiệu quả của các phương pháp này rất khác nhau ngay cả khi áp dụng cho tiếng Anh"],[317,"Việc đánh giá gặp nhiều khó khăn do việc thiếu các tập ngữ liệu huấn luyện chuẩn"],[318,"Thậm chí đối với tập dữ liệu được sử dụng rộng rãi nhất, Reuter cũng có nhiều phiên bản khác nhau"],[319,"Hơn nữa, có rất nhiều độ đo được sử dụng như recall, precision, accuracy hoặc error, break-even point, F-measure \u2026Chương này giới thiệu các thuật toán phân loại được sử dụng phổ biến nhất đồng thời so sánh giữa các phương pháp sử dụng kết quả của [Yang, 1997]"],[320,"2.2"],[321,"Các phương pháp phân loại văn bản tiếng Anh hiện hành 2.2.1"],[322,"Biểu diễn văn bản Bước đầu tiên của mọi phương pháp phân loại là chuyển việc mô tả văn bản dùng chuỗi ký tự thành một dạng mô tả khác, phù hợp với các thuật toán học theo mẫu và phân lớp"],[323,"Hầu hết các thuật toán đều sử dụng cách biểu diễn văn bản sử dụng vector đặc trưng, sự khác nhau có chăng là việc chọn không gian đặc trưng khác nhau"],[324,"Vì vậy ở phần này chúng em sẽ trình bày sơ lược về vector đặc trưng"],[325,""],[326,"9 Ý tưởng chính là xem mỗi văn bản id tương ứng là một vector đặc trưng ( )1 2( ), ( ),..., ( )i nd TF w TF w TF w trong không gian các từ nW ( iw là một từ, một đặc trưng, tương ứng một chiều của không gian)"],[327,"Gía trị của ( )iTF w chính là số lần xuất hiện của từ iw trong văn bản id"],[328,"Từ được chọn là một đặc trưng khi nó xuất hiện trong ít nhất 3 văn bản [Joachims, 1997]"],[329,"Để không bị phụ thuộc vào chiều dài văn bản vector đặc trưng sẽ được chuẩn hóa về chiều dài đơn vị : 1 2 2 2 2 ( )( ) ( )( , ,..., ) ( ) ( ) ( ) n i i i TF wTF w TF wdi TF w TF w TF w∑ ∑ ∑ Hình 2"],[330,"1"],[331,"Biểu diễn văn bản Trong thực tế để cải thiện tốc độ và kết quả người ta thường sử dụng )( iwIDF hoặc i(w )TFIDF thay cho ( )iTF w : ( ) log( ) ( )i i mIDF w DF w = ( ) ( )"],[332,"( )i i iTFIDF w TF w IDF w= Với m chính là số văn bản huấn luyện"],[333,"10 DF(wi) là số văn bản có chứa từ iw"],[334,"Một vấn đề nảy sinh khi biểu diễn văn bản theo hướng vector đặc trưng chính là việc chọn đặc trưng và số chiều cho không gian"],[335,"Cần phải chọn bao nhiêu từ và chọn những từ nào"],[336,"theo những cách nào"],[337,"Có nhiều hướng tiếp cận trong vấn đề này mà tiêu biểu là sử dụng Information Gain [Yang & Petersen, 1997] ngoài ra còn có các phương pháp như DF-Thresolding [Yang & Petersen, 1997], Test−2χ [Schütze et al,1995] hoặc Term Strength [Yang & Wilbur,1997]"],[338,"Phương pháp Information Gain sử dụng độ đo Mutual Information(MI) [Yang & Petersen, 1997] để chọn ra tập đặc trưng con f gồm những từ có giá trị MI cao nhất"],[339,"Các đặc trưng của văn bản khi biểu diễn dưới dạng vector : Số chiều không gian đặc trưng thường rất lớn (trên 10000) Có các đặc trưng độc lập nhau, sự kết hợp các đặc trưng này thường không có ý nghĩa trong phân loại Đặc trưng rời rạc : vector id có rất nhiều giá trị 0 do có nhiều đặc trưng không xuất hiện trong văn bản id"],[340,"Hầu hết các văn bản có thể được phân chia một cách tuyến tính bằng các hàm tuyến tính"],[341,"Việc phân loại sẽ tốt hơn nếu các thuật toán tận dụng được những đặc trưng này"],[342,"Phần tiếp theo sẽ nói rõ hơn về các thuật toán phân loại"],[343,"2.2.2"],[344,"Support vector Machine(SVM) SVM là phương pháp tiếp cận phân loại rất hiệu quả được Vapnik giới thiệu năm 1995 [Vapnik, 1995] để giải quyết vấn đề nhận dạng mẫu 2 lớp sử dụng nguyên lý Cực tiểu hóa Rủi ro có Cấu trúc (Structural Risk Minimization) [Vapnik, Cortes, 1995]"],[345,""],[346,"11 2.2.2.1"],[347,"Ý tưởng Cho trước một tập huấn luyện được biểu diễn trong không gian vector trong đó mỗi tài liệu là một điểm, phương pháp này tìm ra một siêu mặt phẳng h quyết định tốt nhất có thể chia các điểm trên không gian này thành hai lớp riêng biệt tương ứng lớp + và lớp \u2013"],[348,"Chất lượng của siêu mặt phẳng này được quyết định bởi khoảng cách (gọi là biên) của điểm dữ liệu gần nhất của mỗi lớp đến mặt phẳng này"],[349,"Khoảng cách biên càng lớn thì mặt phẳng quyết định càng tốt đồng thời việc phân loại càng chính xác"],[350,"Mục đích thuật toán SVM tìm được khoảng cách biên lớn nhất"],[351,"Hình sau minh họa cho thuật toán này : Hình 2"],[352,"2"],[353,"Siêu mặt phẳng h phân chia dữ liệu huấn huyện thành 2 lớp + và \u2013 với khoảng cách biên lớn nhất"],[354,"Các điểm gần h nhất là các vector hỗ trợ ,Support Vector (được khoanh tròn) 2.2.2.2"],[355,"Công thức chính SVM thực chất là một bài toán tối ưu, mục tiêu của thuật toán này là tìm được một không gian H và siêu mặt phẳng quyết định h trên H sao cho sai số phân loại là thấp nhất Phương trình siêu mặt phẳng chứa vector id trong không gian như sau : 0=+⋅ bwdi Đặt ⎪⎩ ⎪ ⎨ ⎧ <+⋅− >+⋅+ =+⋅= 0,1 0,1 )()( bwd bwd bwdsigndh i i ii"],[356,"12 Như thế )( idh biểu diễn sự phân lớp của id vào hai lớp như đã nói"],[357,"Gọi { }1±=iy , iy = + 1, văn bản id ∈ lớp +; iy = - 1, văn bản id ∈ lớp - Khi này để có siêu mặt phẳng h ta sẽ phải giải bài toán sau : Tìm Min w với w và b thõa điều kiên sau : ( ) 1)(:,1 ≥+⋅∈∀ bwdsignyni ii Bài toán SVM có thể giải bằng kỹ thuật sử dụng toán tử Lagrange để biến đổi thành dạng đẳng thức"],[358,"Điểm thú vị ở SVM là mặt phẳng quyết định chỉ phụ thuộc vào các vector hỗ trợ (Support Vector) có khoảng cách đến mặt phẳng quyết định là w 1"],[359,"Khi các điểm khác bị xóa đi thì thuật toán vẫn cho kết quả giống như ban đầu"],[360,"Chính đặc điểm này làm cho SVM khác với các thuật toán khác như kNN,LLSF, NNet và NB vì tất cả dữ liệu trong tập huấn luyện đều được dùng để tối ưu hóa kết quả"],[361,"Các phiên bản SVM tốt có thể kể đến là SVMLight [Joachims, 1998] và Sequential Minimal Optimization (SMO) [Platt, 1998] 2.2.3"],[362,"K\u2013Nearest Neighbor (kNN) kNN là phương pháp truyền thống khá nổi tiếng về hướng tiếp cận dựa trên thống kê đã được nghiên cứu trong nhận dạng mẫu hơn bốn thập kỷ qua [Dasarathy, 1991]"],[363,"kNN được đánh giá là một trong những phương pháp tốt nhất (áp dụng trên tập dữ liệu Reuters phiên bản 21450), được sử dụng từ những thời kỳ đầu của việc phân loại văn bản [Marsand et al, 1992] [Yang, 1994] [Iwayama, Tokunaga, 1995]"],[364,"2.2.3.1"],[365,"Ý tưởng Khi cần phân loại một văn bản mới, thuật toán sẽ tính khoảng cách (khoảng cách Euclide, Cosine ...) của tất cả các văn bản trong tập huấn luyện đến văn bản này để tìm ra k văn bản gần nhất (gọi là k \u201cláng giềng\u201d), sau đó dùng các khoảng cách này đánh trọng số cho tất cả chủ đề"],[366,"Trọng số của một chủ đề chính là tổng tất cả khoảng cách ở trên của các văn bản trong k láng giềng có cùng chủ đề, chủ đề nào"],[367,"13 không xuất hiện trong k láng giềng sẽ có trọng số bằng 0"],[368,"Sau đó các chủ đề sẽ được sắp xếp theo mức độ trọng số giảm dần và các chủ đề có trọng số cao sẽ được chọn là chủ đề của văn bản cần phân loại"],[369,"2.2.3.2"],[370,"Công thức chính Trọng số của chủ đề jc đối với văn bản x : { } W( , ) ( , )"],[371,"( , ) i j i i j j d kNN x c sim x d y d c b ∈ = −∑ Trong đó ( ),i jy d c ∈ {0,1}, với y = 0 : văn bản id không thuộc về chủ đề cj y = 1 : văn bản id thuộc về chủ đề cj ( ), isim x d : độ giống nhau giữa văn bản cần phân loại x và văn bản id"],[372,"Có thể sử dụng độ đo cosine để tính ( ), isim x d ( ) ii x.d, os(x,d )="],[373,"isim x d c x di = jb là ngưỡng phân loại của chủ đề cj được tự động học sử dụng một tập văn bản hợp lệ được chọn ra từ tập huấn luyện Để chọn được tham số k tốt nhất cho việc phân loại, thuật toán phải được chạy thử nghiệm trên nhiều giá trị k khác nhau, giá trị k càng lớn thì thuật toán càng ổn định và sai sót càng thấp [Yang, 1997]"],[374,"Giá trị tốt nhất được sử dụng tương ứng trên hai bộ dữ liệu Reuter và Oshumed là k = 45 [Joachims, 1997]"],[375,"2.2.4"],[376,"Naïve Bayes (NB) NB là phương pháp phân loại dựa vào xác suất được sử dụng rộng rãi trong lĩnh vực máy học [Mitchell, 1996] [Joachims, 1997] [Jason, 2001] được sử dụng lần đầu tiên trong lĩnh vực phân loại bởi Maron vào năm 1961 [Maron, 1961] sau đó trở nên phổ biến dùng trong nhiều lĩnh vực như trong các công cụ tìm kiếm [Rijsbergen et al, 1970], các bộ lọc mail [Sahami et al, 1998].."],[377,""],[378,"14 2.2.4.1"],[379,"Ý tưởng Ý tưởng cơ bản của cách tiếp cận Naïve Bayes là sử dụng xác suất có điều kiện giữa từ và chủ đề để dự đoán xác suất chủ đề của một văn bản cần phân loại"],[380,"Điểm quan trọng của phương pháp này chính là ở chỗ giả định rằng sự xuất hiện của tất cả các từ trong văn bản đều độc lập với nhau"],[381,"Như thế NB không tận dụng được sự phụ thuộc của nhiều từ vào một chủ đề cụ thể Giả định đó làm cho việc tính toán NB hiệu quả và nhanh chóng hơn các phương pháp khác với độ phức tạp theo số mũ vì nó không sử dụng việc kếp hợp các từ để đưa ra phán đoán chủ đề"],[382,"2.2.4.2"],[383,"Công thức chính Mục đích chính là tính được xác suất Pr( , )Cj d \u2032 , xác suất để văn bản d \u2032 nằm trong lớp Cj"],[384,"Theo luật Bayes, văn bản d \u2032 sẽ được gán vào lớp Cj nào có xác suất Pr( , )Cj d \u2032 cao nhất"],[385,"Công thức sau dùng để tính Pr( , )Cj d \u2032 [Joachims, 1997] 1 1 ( , ) ( , ) Pr( )"],[386,"Pr( | ) ( ) arg max Pr( )"],[387,"Pr( | ) Pr( )"],[388,"Pr( | ) arg max Pr( )"],[389,"Pr( | ) d j i j i BAYES d Cj C i C C i TF w d j w F TF w d Cj C C C w F C w C H d C w C Cj w C C w C \u2032 = \u2032 ∈ \u2032∈ = \u2032 ∈ \u2032 ∈ \u2032∈ ∈ ⎛ ⎞ ⎜ ⎟ ⎜ ⎟\u2032 = ⎜ ⎟ \u2032 \u2032⎜ ⎟ ⎝ ⎠ ⎛ ⎞ ⎜ ⎟= ⎜ ⎟\u2032 \u2032⎜ ⎟ ⎝ ⎠ ∏ ∑ ∏ ∏ ∑ ∏ Với ( , )iTF w d \u2032 là số lần xuất hiện của từ iw trong văn bản d \u2032 d \u2032 là số lượng các từ trong văn bản d \u2032 iw là một từ trong không gian đặc trưng F với số chiều là F Pr( )jC được tính dựa trên tỷ lệ phần trăm của số văn bản mỗi lớp tương ứng trong tập dữ liệu luyện : Pr( ) j jj C C C C C C C \u2032∈ = = \u2032∑"],[390,"15 Pr( | )i jw C được tính sử dụng phép ước lượng Laplace [Napnik, 1982] : 1 ( , ) Pr( | ) ( , ) i j i j j w F TF w C w C F TF w C \u2032∈ + = \u2032+ ∑ Ngoài ra còn có các phương pháp NB khác có thể kể ra như sau ML Naive Bayes, MAP Naive Bayes, Expected Naive Bayes, Bayesian Naive Bayes [Jason, 2001]"],[391,"Naive Bayes là một công cụ rất hiệu quả trong một số trường hợp"],[392,"Kết quả có thể rất tồi nếu dữ liệu huấn luyện nghèo nàn và các tham số dự đoán (như không gian đặc trưng) có chất lượng kém"],[393,"Nhìn chung đây là một thuật toán phân loại tuyến tính thích hợp trong phân loại văn bản nhiều chủ đề"],[394,"NB có ưu điểm là cài đặt đơn giản, tốc độ nhanh, dễ dàng cập nhật dữ liệu huấn luyện mới và có tính độc lập cao với tập huấn luyện, có thể sử dụng kết hợp nhiều tập huấn luyện khác nhau"],[395,"Tuy nhiên NB ngoài giả định tính độc lập giữa các từ còn phải cần đến một ngưỡng tối ưu để cho kết quả khả quan"],[396,"Nhằm mục đích cải thiện hiệu năng của NB, các phương pháp như multiclass-boosting, ECOC [Berger, 1999] [Ghani, 2000] có thể được dùng kết hợp"],[397,"2.2.5"],[398,"Neural Network (NNet) Nnet được nghiên cứu mạnh trong hướng trí tuệ nhân tạo"],[399,"Wiener là người đã sử dụng Nnet để phân loại văn bản, sử dụng 2 hướng tiếp cận : kiến trúc phẳng (không sử dụng lớp ẩn) và mạng nơron 3 lớp (bao gồm một lớp ẩn)[Wiener et al, 1995] Cả hai hệ thống trên đều sử dụng một mạng nơron riêng rẽ cho từng chủ đề, NNet học cách ánh xạ phi tuyến tính những yếu tố đầu vào như từ, hay mô hình vector của một văn bản vào một chủ đề cụ thể"],[400,"Khuyết điểm của phương pháp NNet là tiêu tốn nhiều thời gian dành cho việc huấn luyện mạng nơron"],[401,"2.2.5.1"],[402,"Ý tưởng Mô hình mạng neural gồm có ba thành phần chính như sau: kiến trúc (architecture), hàm chi phí (cost function), và thuật toán tìm kiếm (search"],[403,"16 algorithm)"],[404,"Kiến trúc định nghĩa dạng chức năng (functional form) liên quan giá trị nhập (inputs) đến giá trị xuất (outputs)"],[405,"Kiến trúc phẳng ( flat architecture ) : Mạng phân loại đơn giản nhất ( còn gọi là mạng logic) có một đơn vị xuất là kích hoạt kết quả (logistic activation) và không có lớp ẩn, kết quả trả về ở dạng hàm (functional form) tương đương với mô hình hồi quy logic"],[406,"Thuật toán tìm kiếm chia nhỏ mô hình mạng để thích hợp với việc điều chỉnh mô hình ứng với tập huấn luyện"],[407,"Ví dụ, chúng ta có thể học trọng số trong mạng kết quả (logistic network) bằng cách sử dụng không gian trọng số giảm dần (gradient descent in weight space) hoặc sử dụng thuật toán interated-reweighted least squares là thuật toán truyền thống trong hồi quy (logistic regression)"],[408,"Kiến trúc mô dun (modular architecture ): Việc sử dụng một hay nhiều lớp ẩn của những hàm kích hoạt phi tuyến tính cho phép mạng thiết lập các mối quan hệ giữa những biến nhập và biến xuất"],[409,"Mỗi lớp ẩn học để biểu diễn lại dữ liệu đầu vào bằng cách khám phá ra những đặc trưng ở mức cao hơn từ sự kết hợp đặc trưng ở mức trước"],[410,"Hình 2"],[411,"3"],[412,"Hình Kiến trúc mô đun (Modular Architecture)"],[413,"Các kết quả của từng mạng con sẽ là giá trị đầu vào cho mạng siêu chủ đề và được nhân lại với nhau để dự đoán chủ đề cuối cùng"],[414,"2.2.5.2"],[415,"Công thức chính Trong công trình của Wiener et al (1995) dựa theo khung của mô hình hồi quy, liên quan từ đặc trưng đầu vào cho đến kết quả gán chủ đề tương ứng được học từ"],[416,"17 tập dữ liệu"],[417,"Do vậy, để phân tích một cách tuyến tính, tác giả dùng hàm sigmoid sau làm hàm truyền trong mạng neural: 1 1 p e η− = + Trong đó, T xη β= là sự kết hợp của những đặc trưng đầu vào và p phải thỏa điều kiện (0,1)p∈ 2.2.6"],[418,"Linear Least Square Fit (LLSF) LLSF là một cách tiếp cận ánh xạ được phát triển bởi Yang và Chute vào năm 1992 [Yang & Chute, 1992] Đầu tiên, LLSF được Yang và Chute thử nghiệm trong lĩnh vực xác định từ đồng nghĩa sau đó sử dụng trong phân loại vào năm 1994 [Yang & Chute, 1994]"],[419,"Các thử nghiệm của Ỵang cho thấy hiệu suất phân loại của LLSF có thể ngang bằng với phương pháp kNN kinh điển"],[420,"2.2.6.1"],[421,"Ý tưởng LLSF sử dụng phương pháp hồi quy để học từ tập huấn luyện và các chủ đề có sẵn [Yang & Chute, 1994]"],[422,"Tập huấn luyện được biểu diễn dưới dạng một cặp vector đầu vào và đầu ra như sau : Vector đầu vào một văn bản bao gồm các từ và trọng số Vector đầu ra gồm các chủ đề cùng với trọng số nhị phân của văn bản ứng với vector đầu vào Giải phương trình các cặp vector đầu vào/ đầu ra, ta sẽ được ma trận đồng hiện của hệ số hồi quy của từ và chủ đề(matrix of word-category regression coefficients) 2.2.6.2"],[423,"Công thức chính 2arg minLS F F FA B= − Trong đó A, B là ma trận đại diện tập dữ liệu huấn luyện ( các cột trong ma trận tương ứng là các vector đầu vào và đầu ra ) FLS là ma trận kết quả chỉ ra một ánh xạ từ một văn bản bất kỳ vào vector của chủ đề đã gán trọng số"],[424,"18 Nhờ vào việc sắp xếp trọng số của các chủ đề, ta được một danh sách chủ đề có thể gán cho văn bản cần phân loại"],[425,"Nhờ đặt ngưỡng lên trọng số của các chủ đề mà ta tìm được chủ đề thích hợp cho văn bản đầu vào"],[426,"Hệ thống tự động học các ngưỡng tối ưu cho từng chủ đề, giống với kNN"],[427,"Mặc dù LLSF và kNN khác nhau về mặt thống kê, nhưng ta vẫn tìm thấy điểm chung ở hoạt động của hai phương pháp là việc học ngưỡng tối ưu"],[428,"2.2.7"],[429,"Centroid- based vector Là một phương pháp phân loại đơn giản, dễ cài đặt và tốc độ nhanh do có độ phức tạp tuyến tính O(n) [Han, Karypis 2000] 2.2.7.1"],[430,"Ý tưởng Mỗi lớp trong dữ liệu luyện sẽ được biểu diễn bởi một vector trọng tâm"],[431,"Việc xác định lớp của một văn bản thử bất kì sẽ thông qua viêc tìm vector trọng tâm nào gần với vector biểu diễn văn bản thử nhất"],[432,"Lớp của văn bản thử chính là lớp mà vector trọng tâm đại diện"],[433,"Khoảng cách được tính theo độ đo cosine"],[434,"2.2.7.2"],[435,"Công thức chính Công thức tính vector trọng tâm của lớp i { } 1 { } j i j d i C d i ∈ = ∑ Độ đo khoảng cách giữa vector x và iC ( )cos , * i i i x Cx C x C ⋅ = Trong đó : x là vector văn bản cần phân loại { }i là tập hợp các văn bản thuộc chủ đề Ci Chủ đề của x là Cx thõa cos( , ) arg max(cos( , ))x ix C x C="],[436,"19 2.3"],[437,"Kết luận Các thuật toán phân loại trên từ thuật toán phân loại 2 lớp (SVM) đến các thuật toán phân loại đa lớp (kNN) đều có điểm chung là yêu cầu văn bản phải được biểu diễn dưới dạng vector đặc trưng"],[438,"Ngoài ra các thuật toán như kNN,NB,LLSF đều phải sử dụng các ước lượng tham số và ngưỡng tối ưu trong khi đó thuật toán SVM có thể tự tìm ra các tham số tối ưu này"],[439,"Trong các phương pháp SVM là phương pháp sử dụng không gian vector đặc trưng lớn nhất (hơn 10000 chiều) trong khi đó chỉ là 2000 đối với NB, 2415 cho kNN và LLSF, 1000 cho Nnet [Yang, 1997]"],[440,"Thời gian huấn luyện cũng khác nhau đối với từng phương pháp, Nnet (sử dụng mỗi mạng tương ứng một chủ đề) và SVM là hai phương pháp có thời gian huấn luyện lâu nhất trong khi đó kNN,NB,LLSF và Centroid là các phương pháp có tốc độ (thời gian huấn luyện, phân loại) nhanh và cài đặt dễ dàng"],[441,"Về hiệu suất, dựa vào thử nghiệm của Yang [Yang, Liu, 1997] trên tập dữ liệu Reuter-21578 với hơn 90 chủ đề và trên 7769 văn bản, ta có thể sắp xếp các phương pháp phân loại văn bản theo thứ tự như sau SVM > kNN >> {LLSF,NB,Nnet}"],[442,"Tuy nhiên kết quả trên có thể không còn đúng khi áp dụng thử nghiệm phân loại trên Tiếng Việt"],[443,"Các lý do chính như sau : Thứ nhất: không có một tập dữ liệu chuẩn dành riêng cho việc phân loại"],[444,"Thứ hai: hiện tại chưa có chuẩn thống nhất nào cho vấn đề font và dấu câu cho Tiếng Việt"],[445,"Thứ ba: viêc biểu diễn văn bản Tiếng Việt bằng vector đặc trưng gặp nhiều trở ngại do bị phụ thuộc nhiều vào các phương pháp tách từ"],[446,"Trong khi đó các phương pháp này không đạt được hiệu quả cao như trong tiếng Anh"],[447,"Để có thể áp dụng các phương pháp phân loại văn bản đã được sử dụng thành công trên nhiều ngôn ngữ (Anh, Pháp,\u2026) như đã liệt kê trên, điều kiện tiên quyết là phải tìm ra một phương pháp tách từ tốt để thông qua đó cải thiện hiệu quả của các thuật toán phân loại"],[448,"Trong tiếng Anh, đơn vị nhỏ nhất là \u201ctừ\u201d nên việc tách từ trở nên khá đơn giản, trong khi đối với một số ngôn ngữ như tiếng Hoa, Nhật, Hàn Quốc.."],[449,"và Tiếng Việt của chúng ta phải xử lý hoàn toàn khác do đơn vị nhỏ nhất lại"],[450,"20 là \u201ctiếng\u201d"],[451,"Do đó, trước khi thực hiện phân loại, chúng ta phải tìm hiểu về các hướng tiếp cận cho việc tách từ tiếng Việt, một vấn đề khá thú vị không kém các phương pháp phân loại"],[452,""],[453,"21 CChhưươơnngg 33 CCÁÁCC PPHHƯƯƠƠNNGG PPHHÁÁPP TTÁÁCCHH TTỪỪ TTIIẾẾNNGG VVIIỆỆTT HHIIỆỆNN NNAAYY Tại sao tách từ tiếng Việt là một thách thức"],[454,"So sánh giữa tiếng Việt và tiếng Anh Nhận xét Bối cảnh các phương pháp tách từ hiện nay Bối cảnh chung Các hướng tiếp cận dựa trên từ Các hướng tiếp cận dựa trên ký tự Một số phương pháp tách từ tiếng Việt hiện nay Phương pháp Maximum Matching: forward/backward Phương pháp giải thuật học cải tiến Mô hình tách từ bằng WFST và mạng Neural Phương pháp quy hoạch động Phương pháp tách từ tiếng Việt dựa trên thống kê từ Internet và thuật toán di truyền Kết luận"],[455,"22 Chương 3"],[456,"CÁC PHƯƠNG PHÁP TÁCH TỪ TIẾNG VIỆT HIỆN NAY 3.1"],[457,"Tại sao tách từ tiếng Việt là một thách thức"],[458,"3.1.1"],[459,"So sánh giữa tiếng Việt và tiếng Anh Dựa vào các đặc điểm của tiếng Anh và tiếng Việt được trình bày trong [Đinh Điền, 2004], chúng em lập bảng so sánh các đặc điểm chủ yếu giữa tiếng Anh và tiếng Việt như sau Đặc điểm của Tiếng Việt Đặc điểm của Tiếng Anh Được xếp là loại hình đơn lập (isolate) hay còn gọi là loại hình phi hình thái, không biến hình, đơn tiết Từ không biến đổi hình thái, ý nghĩa ngữ pháp nằm ở ngoài từ Ví dụ : Chị ngã em nâng và Em ngã chị nâng Phương thức ngữ pháp chủ yếu: trật tự từ và hư từ"],[460,"Ví dụ: Gạo xay và Xay gạo; đang học và học rồi ; \u201cnó bảo sao không tới\u201d, \u201csao không bảo nó tới\u201d, \u201csao không tới bảo nó\u201d."],[461,"Ranh giới từ không được xác định mặc nhiên bằng khoảng trắng Tồn tại loại từ đặc biệt \u201c từ chỉ loại\u201d (classifier) hay còn gọi là Là loại hình biến cách (flexion) hay còn gọi là loại hình khuất chiết Từ có biến đổi hình thái, ý nghĩa ngữ pháp nằm ở trong từ"],[462,"Ví dụ: I see him và He sees me"],[463,"Phương thức ngữ pháp chủ yếu là : phụ tố"],[464,"Ví dụ: studying và studied Kết hợp giữa các hình vị là chặt chẽ, khó xác định, được nhận diện bằng khoảng trắng hoặc dấu câu"],[465,"Hiện tượng cấu tạo bằng từ ghép thêm phụ tố (affix) vào gốc từ là"],[466,"23 phó danh từ chỉ loại kèm theo với danh từ, như: cái bàn, cuốn sách, bức thư, con chó, con sông, vì sao\u2026 Có hiện tượng láy và nói lái trong tiếng Việt Ví dụ: lấp lánh, lung linh Hiện đại -> hại điện, thầy giáo-> tháo giầy\u2026 rất phổ biến"],[467,"Ví dụ: anticomputerizational ( anti- compute-er-ize-ation-al) Bảng 3"],[468,"1"],[469,"So sánh giữa tiếng Việt và tiếng Anh 3.1.2"],[470,"Nhận xét Tiếng Việt là loại hình phi hình thái nên việc phân biệt loại từ (danh từ, động từ, tính từ \u2026) và ý nghĩa từ là rất khó, cho dù có sử dụng từ điển"],[471,"Việc tiền xử lý văn bản (tách từ, tách đoạn, tách câu\u2026) sẽ thêm phức tạp với phần xử lý các hư từ, phụ từ, từ láy\u2026 Phương thức ngữ pháp chủ yếu là trật tự từ nên nếu áp dụng phương pháp tính xác suất xuất hiện của từ có thể không chính xác như mong đợi Ranh giới từ không được xác định mặc nhiên bằng khoảng trắng"],[472,"Điều này khiến cho việc phân tích hình thái (tách từ) tiếng Việt trở nên khó khăn"],[473,"Việc nhận diện ranh giới từ là quan trọng làm tiền đề cho các xử lý tiếp theo sau đó, như: kiểm lỗi chính tả, gán nhãn từ loại, thống kê tần suất từ,\u2026 Vì giữa tiếng Anh và tiếng Việt có nhiều điểm khác biệt nên chúng ta không thể áp dụng y nguyên các thuật toán tiếng Anh cho tiếng Việt 3.2"],[474,"Bối cảnh các phương pháp tách từ hiện nay 3.2.1"],[475,"Bối cảnh chung Dựa trên cơ sở thống kê các phương pháp tách từ trên tiếng Hoa của [Foo and Li, 2004], chúng em xin trình bày bối cảnh các phương pháp tách từ hiện nay cho tiếng Việt như sau:"],[476,"24 Hình 3.4"],[477,"Các hướng tiếp cận cơ bản trong tách từ tiếng Hoa và các hướng tiếp cận hiện tại được công bố trong tách từ tiếng Việt 3.2.2"],[478,"Các hướng tiếp cận dựa trên từ (Word-based approaches) Hướng tiếp cận dựa trên từ với mục tiêu tách được các từ hoàn chỉnh trong câu"],[479,"Hướng tiếp cận này có thể chia ra là ba hướng: dựa trên thống kê (statistics-based), dựa trên từ điển (dictionary-based) và hydrid (kết hợp nhiều phương pháp với hy vọng đạt được những ưu điểm của các phương pháp này) 3.2.2.1"],[480,"Các công trình tách từ tiếng Hoa Hướng tiếp cận dựa trên thống kê (statistics-based) dựa trên các thông tin như tần số xuất hiện của từ trong tập dữ liệu huấn luyện đầu"],[481,"Hướng tiếp cận này đặc Hybrid Chinese segmentation Character-based Word-based Unigram N-gram Statistic Dictionary Vietnamese segmentation Lê An Hà (03) H"],[482,"Nguyễn et al (05) Full word / Phrase Component Shortest Match Longest Match Overlap Match Đinh Điền et al (01) Luận văn này (05)"],[483,"25 biệt dựa trên tập ngữ liệu huấn luyện, nhờ vậy nên hướng tiếp cận này tỏ ra rất linh hoạt và hữu dụng trong nhiều lãnh vực riêng biệt [Nie et al.,1996]"],[484,"Hướng tiếp cận dựa trên từ điển (dictionary-based) thường được sử dụng trong tách từ"],[485,"Ý tưởng của hướng tiếp cận này là những cụm từ được tách ra từ văn bản phải khớp với các từ trong từ điển"],[486,"Những hướng tiếp cận khác nhau sẽ sử dụng những loại từ điển khác nhau"],[487,"Hướng tiếp cận \u201cfull word / phrase\u201d cần sử dụng một từ điển hoàn chỉnh để có thể tách được đầy đủ các từ hoặc ngữ trong văn bản, trong khi đó, hướng tiếp cận thành phần (component) lại sử dụng từ điển thành phần (component dictionary)[Wu & Tseng, 1993]"],[488,"Từ điển hoàn chỉnh chứa tất cả các từ và ngữ được dùng trong tiếng Hoa, trong khi từ điển thành phần (component dictionary) chỉ chứa các thành phần của từ và ngữ như hình vị và các từ đơn giản trong tiếng Hoa"],[489,"Tùy theo cách chọn để khớp từ (match), hướng tiếp cận \u201cfull word/ phrase\u201d có thể được chia ra thành khớp dài nhất (longest match \u2013 bằng cách duyệt văn bản tuần tự để tìm ra từ dài nhất có trong từ điển) và khớp ngắn nhất (shortest match \u2013 bằng cách duyệt văn bản tuần tự và chọn từ đầu tiên có trong từ điển )"],[490,"Ngoài hai cách thông dụng nhất là khớp dài nhất và khớp ngắn nhất, He et"],[491,"al"],[492,"(1996)còn đề nghị một cách thứ ba là cách kết hợp (overlap)"],[493,"Trong cách kết hợp này, mỗi chuỗi được phát sinh từ văn bản có thể chồng lấp lên chuỗi khác nếu chuỗi đó có trong từ điển (ví dụ : học sinh học, ta sẽ có các token là \u201chọc sinh\u201d, \u201csinh học\u201d chứ không phải chỉ có một cách như khớp dài nhất hoặc khớp ngắn nhất)"],[494,"Tại thời điểm hiện tại, hướng tiếp cận khớp dài nhất được xem là phương pháp quan trọng và hiệu quả nhất trong hướng tiếp cận dựa trên từ điển [Foo & Li, 2002]"],[495,"Tuy nhiên, hướng tiếp cận dựa trên từ điển vẫn có một số hạn chế trong việc tách từ vì thực hiện hoàn toàn dựa trên một từ điển hoàn chỉnh"],[496,"Trong thực tế, để xây dựng một bộ từ điển thật sự hoàn hảo chứa tất cả các từ tiếng Hoa là không thật sự cần thiết và khó thành hiện thực"],[497,"Hướng tiếp cận dựa trên thành phần (component) phát triển cũng với mục đích làm nhẹ bớt mặt hạn chế này bằng cách nối các hình vị và từ thành những từ và ngữ hoàn chỉnh [Wu & Tseng,1993,1995]"],[498,""],[499,"26 Hướng tiếp cận Hybrid với mục đích kết hợp các hướng tiếp cận khác nhau để thừa hưởng được ưu điểm của nhiều kỹ thuật khác nhau"],[500,"Hướng tiếp cận này thường kết hợp giữa hướng dựa trên thống kê và dựa trên từ điển nhằm lấy được ưu thế chung và các mặt vượt trội riêng của mỗi phương pháp"],[501,"Một số thành công của phương pháp này được trình bày trong [Nie et al, 1996]"],[502,"Mặc dù hướng tiếp cận hibrid có được những ưu điểm của phương pháp khác nhưng lại gặp phải các phức tạp khác như thời gian xử lý, không gian đĩa và đòi hỏi nhiều chi phí"],[503,"3.2.2.2"],[504,"Các công trình tách từ tiếng Việt Công trình của Đinh Điền et al (2001) đã cố gắng xây dựng tập ngữ liệu huấn luyện riêng (khoảng 10M) dựa trên các thông tin có nguồn gốc từ Internet như tin tức, e-book\u2026 Tuy nhiên tập ngữ liệu vẫn còn khá nhỏ để đảm bảo dung lượng và độ phong phú cho việc tách từ"],[505,"Mặc khác, do tập ngữ liệu được xây dựng một cách thủ công, nên sẽ phần nào mang tính chủ quan"],[506,"Và một hạn chế nữa là việc đánh giá lại được những thay đổi hằng ngày rất chậm, và có thể xảy ra hiện tượng flip-flop ( hiện tượng khi khắc phục lỗi này lại dẫn đến lỗi khác không ngờ tới) Ở hướng tiếp cận dựa trên từ điển, các từ được tách phải tương ứng với những từ có trong từ điển"],[507,"Hiện tại, ta vẫn chưa xây dựng được một bộ từ điển Việt Nam chứa toàn bộ các từ và ngữ"],[508,"3.2.3"],[509,"Các hướng tiếp cận dựa trên ký tự (Character-based approaches) Cần phân biệt rằng hình vị nhỏ nhất của tiếng Việt là \u201ctiếng\u201d, được cấu tạo bởi nhiều ký tự trong bảng chữ cái, trong khi hình vị nhỏ nhất của tiếng Hoa là một ký tự"],[510,"Vì chữ viết tiếng Hoa là chữ tượng hình, không dựa trên bảng chữ cái Latin như tiếng Việt nên trong trường hợp tiếng Hoa, người ta xét hình vị là \u201cký tự\u201d"],[511,"Tuy nhiên, mỗi ký tự (character) trong tiếng Hoa được phát âm thành một \u201ctiếng\u201d, nên xét về mặt âm vị, ta có thể xem \u201ctiếng\u201d trong tiếng Hoa và tiếng Việt là tương tự nhau"],[512,"Vì vậy, để tránh sự hiểu nhằm ý nghĩa giữa ký tự trong tiếng Hoa và tiếng trong tiếng Việt, chúng em xin phép dùng từ \u201ctiếng\u201d để chỉ cho ký tự tiếng Hoa và tiếng trong tiếng Việt ở một số trường hợp trình bày về cách tách từ"],[513,""],[514,"27 Mặc dù có cách viết khác nhau, nhưng về cấu tạo từ và ngữ pháp của tiếng Hoa và tiếng Việt có nhiều điểm tương đồng nhau"],[515,"Xét về nguồn gốc, tiếng Việt là hình thức phiên âm của chữ Nôm do nhân dân ta sáng tạo nên, vốn có nguồn gốc từ tiếng Trung Hoa thời xưa"],[516,"3.2.3.1"],[517,"Các công trình tách từ tiếng Hoa Hướng tiếp cận này đơn thuần rút trích một số lượng nhất định các tiếng trong văn bản như rút trích từ 1 ký tự (unigram) hay nhiều ký tự (n-gram)"],[518,"Mặc dù hướng tiếp cận này tương đối đơn giản hơn các hướng khác, nhưng nó cũng mang lại nhiều kết quả khả quan trong tiếng Hoa [Foo and Li, 2004]"],[519,"Hướng tiếp cận dựa trên một ký tự (unigram) chia văn bản ra các ký tự đơn lẻ để thực hiện việc tách từ"],[520,"Ngày nay, hầu như người ta không sử dụng phương pháp này như hướng tiếp cận chính trong việc tách từ nữa"],[521,"Hướng tiếp cận dựa trên nhiều ký tự (n-gram) chia văn bản ra thành nhiều chuỗi, mỗi chuỗi gồm hai, ba ký tự trở lên"],[522,"So với hướng tiếp cận dựa trên một ký tự, hướng tiếp cận này cho nhiều kết quả ổn định hơn [Kwok, 1997a;1997b]"],[523,"Do hơn 75% từ trong tiếng Hoa là từ gồm hai ký tự, nên các phương pháp phổ biến là dựa trên việc tách từ gồm hai ký tự sẽ cho kết quả nhiều từ đúng hơn [Wu & Tseng, 1993].Ví dụ, ta có một câu ABCDEF, hướng tiếp cận trên sẽ chia câu thành AB CD EF"],[524,"Một biến thể của phương pháp tách từ hai ký tự là hướng tiếp cận cách chia chồng lên nhau, ví dụ ta có ABCDEFG, hướng tiếp cận này sẽ chia thành AB BC CD DE DF FG"],[525,"Nhóm nghiên cứu của Swiss Federal Institute of Technology (ETH) áp dụng phương pháp biến thể và có thể cải tiến là sử dụng thêm danh sách stoplist (tương tự như các hư từ trong tiếng Việt như à, ơi..) để tách các ngữ của câu trước khi tách từ [Mateev et al, 1997]"],[526,"Nhờ vậy, mà kích thước văn bản cần tách từ được giảm xuống nhưng có khuyết điểm là nó có thể làm mất ý nghĩa của câu gốc"],[527,"Ưu điểm nổi bật của hướng tiếp cận dựa trên nhiều ký tự là tính đơn giản và dễ ứng dụng, ngoài ra còn có thuận lợi là ít tốn chi phí cho việc tạo chỉ mục (index) và xử lý nhiều câu truy vấn (query processing)"],[528,"Qua nhiều công trình nghiên cứu,"],[529,"28 hướng tiếp cận tách từ dựa trên nhiều ký tự, đặc biệt là cách tách từ hai ký tự được xem là sự lựa chọn thích hợp[Foo & Li, 2002]"],[530,"3.2.3.2"],[531,"Các công trình tách từ tiếng Việt Trong trường hợp tiếng Việt, hướng tiếp cận này được xem là hướng tiếp cận dựa trên tiếng, khác với tiếng Hoa là dựa trên ký tự"],[532,"Ở Việt Nam, hướng tiếp cận này cũng đã có một số công trình được phổ biến"],[533,"[Lê An Hà, 2003] xây dựng tập ngữ liệu thô 10M, sử dụng phương pháp quy hoạch động để cực đại hóa tổng xác suất xuất hiện của các ngữ"],[534,"Gần đây nhất có thể kể đến công trình của [H"],[535,"Nguyen et al, 2005], thay vì sử dụng ngữ liệu thô, công trình của họ có sáng tạo là lấy thông tin thống kê từ Internet và sử dụng thuật toán di truyền (Genetic Algorithm) để tìm cách tách từ tối ưu nhất"],[536,"Mặc dù công trình của họ còn mang tính sơ bộ, và việc thử nghiệm chưa hoàn chỉnh, nhưng chúng em tin rằng ý tưởng mới lạ này đem lại nhiều hứa hẹn khả quan"],[537,"Hướng tiếp cận cho việc tách từ của chúng em mở rộng trên ý tưởng này, ngoài ra, chúng em thực hiện một số thay đổi quan trọng nhằm nâng cao tính chính xác của việc tách từ"],[538,"Thêm nữa, chúng em đã thực hiện một số thử nghiệm trên số lượng dữ liệu đáng kể nhằm đưa ra các đánh giá một cách bao quát hơn, chính xác hơn"],[539,"3.3"],[540,"Một số phương pháp tách từ tiếng Việt hiện nay 3.3.1"],[541,"Phương pháp Maximum Matching: forward/backward 3.3.1.1"],[542,"Nội dung Phương pháp khớp tối đa (Maximum Matching) còn gọi là Left Right Maximum Matching (LRMM)"],[543,"Theo phương pháp này, ta sẽ duyệt một ngữ hoặc câu từ trái sang phải và chọn từ có nhiều âm tiết nhất có mặt trong từ điển, rồi cứ thể tiếp tục cho từ kế tiếp cho đến hết câu"],[544,"Thuật toán được trình bày trong [Chih-Hao Tsai, 2000] Dạng đơn giản được dùng giải quyết nhập nhằng từ đơn"],[545,"Giả sử có một chuỗi ký tự (tương đương với chuỗi tiếng trong tiếng Việt) C1, C2, .."],[546,", C2"],[547,"Ta bắt đầu từ đầu chuỗi"],[548,"Đầu tiên kiểm tra xem C1, có phải là từ hay không, sau đó kiểm tra xem C1C2"],[549,"29 có phải là từ hay không"],[550,"Tiếp tục tìm cho đến khi tìm được từ dài nhất"],[551,"Từ có vẻ hợp lý nhất sẽ là từ dài nhất"],[552,"Chọn từ đó, sau đó tìm tiếp như trên cho những từ còn lại cho đến khi xác định được toàn bộ chuỗi từ"],[553,"Dạng phức tạp: Quy tắc của dạng này là phân đoạn có vẻ hợp lý nhất là đoạn ba từ với chiều dài tối đa"],[554,"Thuật toán bắt đầu như dạng đơn giản"],[555,"Nếu phát hiện ra những cách tách từ gây nhập nhằng (ví dụ, C1 là từ và C1C2 cũng là từ), ta xem các chữ kế tiếp để tìm tất cả các đoạn ba từ có thể có bắt đầu với C1 hoặc C1C2"],[556,"Ví dụ ta được những đoạn sau: C1 C2 C3 C4 C1C2 C3 C4 C5 C1C2 C3 C4 C5 C6 Chuỗi dài nhất sẽ là chuỗi thứ ba"],[557,"Vậy từ đầu tiên của chuỗi thứ ba (C1C2) sẽ được chọn"],[558,"Thực hiện lại các bước cho đến khi được chuỗi từ hoàn chỉnh"],[559,"3.3.1.2"],[560,"Ưu điểm Với cách này, ta dễ dàng tách được chính xác các ngữ/câu như \u201c hợp tác xã || mua bán\u201d, \u201cthành lập || nước || Việt Nam || dân chủ || cộng hòa\u201d Cách tách từ đơn giản, nhanh, chỉ cần dựa vào từ điển Trong tiếng Hoa, cách này đạt được độ chính xác 98,41% [Chih-Hao Tsai, 2000]"],[561,"3.3.1.3"],[562,"Hạn chế Độ chính xác của phương pháp phụ thuộc hoàn toàn vào tính đủ và tính chính xác của từ điển Phương pháp này sẽ tách từ sai trong các trường hợp \u201c học sinh || học sinh|| học\u201d, \u201cmột || ông || quan tài || giỏi\u201d, \u201ctrước || bàn là || một || ly || nước\u201d\u2026"],[563,"30 3.3.2"],[564,"Phương pháp giải thuật học cải biến (Transformation-based Learning, TBL) 3.3.2.1"],[565,"Nội dung Đây là cách tiếp cận dựa trên ngữ liệu đã đánh dấu"],[566,"Theo cách tiếp cận này, để huấn luyện cho máy tính biết cách nhận diện ranh giới từ tiếng Việt, ta có thể cho máy \u201chọc\u201d trên ngữ liệu hàng vạn câu tiếng Việt đã được đánh dấu ranh giới từ đúng"],[567,"Sau khi học xong, máy sẽ xác định được các tham số (các xác suất) cần thiết cho mô hình nhận diện từ"],[568,"3.3.2.2"],[569,"Ưu điểm Đặc điểm của phương pháp này là khả năng tự rút ra quy luật của ngôn ngữ Nó có những ưu điểm của cách tiếp cận dựa trên luật vì cuối cùng nó cũng dựa trên luật được rút ra) nhưng nó khắc phục được khuyết điểm của việc xây dựng các luật một cách thủ công bởi các chuyên gia"],[570,"Các luật được thử nghiệm tại chỗ để đánh giá độ chính xác và hiệu quả của luật (dựa trên ngữ liệu huấn luyện) Có khả năng khử được một số nhập nhằng như \u201cThe singer sang a lot of a??as\u201d, thì hệ có thể xác định được \u201ca??as\u201d là \u201carias\u201d (dân ca) thay vì \u201careas\u201d (khu vực) của các mô hình ngôn ngữ theo kiểu thống kê"],[571,"3.3.2.3"],[572,"Hạn chế Phương pháp này \u201cdùng ngữ liệu có gán nhãn ngôn ngữ để học tự động các qui luật đó\u201d[Đinh Điền, 2004]"],[573,"Như đã nói ở chương 1, việc xây dựng một tập ngữ liệu đạt được đầy đủ các tiêu chí của tập ngữ liệu trong tiếng Việt là một điều rất khó, tốn kém nhiều về mặt thời gian và công sức"],[574,"Hệ phải trải qua một thời gian huấn luyện khá lâu để có thể rút ra các luật tương đối đầy đủ Cài đặt phức tạp"],[575,"31 3.3.3"],[576,"Mô hình tách từ bằng WFST và mạng Neural 3.3.3.1"],[577,"Nội dung Mô hình mạng chuyển dịch trạng thái hữu hạn có trọng số WFST (Weighted finit\u2013state Transducer) đã được [Richard et al, 1996] áp dụng để tách từ tiếng Trung Quốc"],[578,"Ý tưởng cơ bản là áp dụng WFST kết hợp với trọng số là xác suất xuất hiện của mỗi từ trong ngữ liệu"],[579,"Dùng WFST để duyệt qua câu cần xét"],[580,"Cách duyệt có trọng số lớn nhất sẽ là cách tách từ được chọn"],[581,"Giải pháp này cũng đã đượng áp dụng trong [Đinh Điền et al, 2001] kèm với mạng neutral để khử nhập nhằng"],[582,"Hệ thống tách từ tiếng Việt của [Đinh Điền, 2001] gồm hai tầng: tầng WFST ngoài việc tách từ còn xử lý thêm các vấn đề liên quan đến đặc thù của tiếng Việt như từ láy, tên riêng\u2026 và tầng mạng neural dùng để khử nhập nhằng nếu có"],[583,"Hình 3.5"],[584,"Sơ đồ hệ thống WFST Bắt đầu Tiền xử lý Bắt đầu Tiền xử lý Tiền xử lý t < T0 Y"],[585,"32 Tầng WFST :gồm có ba bước Xây dựng từ điển trọng số : theo mô hình WFST, việc phân đoạn từ được xem như là một sự chuyển dịch trạng thái có xác suất (Stochastic Transduction)"],[586,"Chúng ta miêu tả từ điển D là một đồ thị biến đổi trạng thái hữu hạn có trọng số"],[587,"Giả sử: H: là tập các từ chính tả tiếng Việt (còn gọi là \u201ctiếng\u201d) P: là từ loại của từ (POS: Part \u2013 Of \u2013 Speech)"],[588,"Mỗi cung của D có thể là: Từ một phần tử của H tới một phần tử của H, hoặc Từ ε (ký hiệu kết thúc từ) tối một phần tử của P Các nhãn trong D biểu thị một chi phí ước lượng (estimated cost) bằng công thức : Cost = - log(f/N) Với f: tần số của từ, N: kích thước tập mẫu"],[589,"Đối với các trường hợp từ mới chưa gặp, tác giả áp dụng xác suất có điều kiện Goog-Turning (Baayen) để tính toán trọng số"],[590,"Xây dựng các khả năng phân đoạn từ : Để giảm sự bùng nổ tổ hợp khi sinh ra các dãy các từ có thể từ một dãy các tiếng trong câu, tác giả đề xuất một phương pháp mới là kết hợp dùng từ điển để hạn chế sinh ra các bùng nổ tổ hợp"],[591,"Khi phát hiện thấy một cách phân đoạn từ nào đó không phù hợp (không có trong từ điển, không phải là từ láy, không phải là danh từ riêng\u2026) thì tác giả loại bỏ các nhánh xuất phát từ cách phân đoạn từ đó"],[592,"Lựa chọn khả năng phân đoạn từ tối ưu : Sau khi được một danh sách các cách phân đoạn từ có thể có của câu, tác giả chọn trường hợp phân đoạn từ có trọng số bé nhất như sau: Ví dụ: input = \u201cTốc độ truyền thông tin sẽ tăng cao\u201d o Dictionary \u201ctốc độ\u201d 8.68 \u201ctruyền\u201d 12.31"],[593,"33 \u201ctruyền thông\u201d 1231 \u201cthông tin\u201d 7.24 \u201ctin\u201d 7.33 \u201csẽ\u201d 6.09 \u201ctăng\u201d 7.43 \u201ccao\u201d 6.95 Id(D)*D* = \u201cTốc độ # truyền thông # tin # sẽ # tăng # cao.\u201d 48.79 (8.68 +12.31 + 7.33 + 6.09 + 7.43 +6.95 = 48.79 ) Id(D)*D* = \u201cTốc độ # truyền # thông tin # sẽ # tăng # cao.\u201d 48.70 (8.68 +12.31 + 7.24 + 6.09 + 7.43 +6.95 = 48.79 ) Do đó, ta có được phân đoạn tối ưu là \u201cTốc độ # truyền # thông tin # sẽ # tăng # cao.\u201d Tầng mạng neural : Mô hình mạng neural mà tác giả đề xuất được dùng để lượng giá 3 dãy từ loại: NNV,NVN, VNN (N: Noun, V: Verb)"],[594,"Mô hình này được học bằng chính các câu mà cách phân đoạn từ vẫn còn nhập nhằng sau khi qua mô hình thứ nhất"],[595,"3.3.3.2"],[596,"Ưu điểm Độ chính xác trên 97% [Đinh Điền et al, 2001] Mô hình cho kết quả phân đoạn từ với độ tin cậy (xác suất) kèm theo"],[597,"Nhờ có tầng mạng neural nên mô hình có thể khử nhập nhằng các trường hợp tầng WFST cho ra nhiều ứng viên có kết quả ngang nhau Phương pháp này cho kết quả với độ chính xác khá cao vì mục đích của tác giả muốn nhắm đến việc tách từ thật chính xác để là nền tảng cho việc dịch máy"],[598,"3.3.3.3"],[599,"Hạn chế Cũng tương tự như phương pháp TBL, việc xây dựng tập ngữ liệu là rất công phu, nhưng thật sự rất cần thiết để phục vụ cho mục đích dịch máy sau này của tác giả"],[600,""],[601,"34 3.3.4"],[602,"Phương pháp quy hoạch động (dynamic programming) 3.3.4.1"],[603,"Nội dung Phương pháp quy hoạch động [Le An Ha, 2003] chỉ sử dụng tập ngữ liệu thô để lấy thông tin về tần số thống kê của từ , làm tăng độ tin cậy cho việc tính toán"],[604,"Việc tính toán bắt đầu với những đơn vị chắc chắn như câu, các ngữ (chunk) được phân cách bởi dấu câu ( như dấu phẩy, gạch nối, chấm phẩy\u2026) vì những thành phần này không có tính nhập nhằng ngay cả trong văn viết cũng như nói"],[605,"Sau đó, tác giả cố gắng tối đa hoá xác suất của ngữ bằng cách tìm ra nhiều cách tách ngữ đó"],[606,"Cách tách cuối cùng là cách tách là cho ngữ đó có xác suất cao nhất"],[607,"Ý tưởng của cách tách từ này cho một ngữ cần tách từ, ta phải tìm ra các tổ hợp từ tạo nên ngữ đó sao cho tổ hợp đó đạt được xác suất tối đa"],[608,"Tuy nhiên trong phương pháp tính toán này, tác giả gặp phải vấn đề bùng nổ tổ hợp và phân tích ngữ liệu thô"],[609,"Để giải quyết vấn đề trên, tác giả đã sử dụng phương pháp quy hoạch động (dynamic programming) vì lúc đó, xác suất cực đại của một ngữ nhỏ hơn chỉ phải tính toán một lần và sử dụng lại trong các lần sau"],[610,"3.3.4.2"],[611,"Ưu điểm Không cần sử dụng tập ngữ liệu đã đánh dấu chính xác 3.3.4.3"],[612,"Hạn chế Trong thí nghiệm, tác giả chỉ dừng lại ở việc tách các từ có ba tiếng bởi vì tập ngữ liệu đầu vào vẫn còn khá nhỏ"],[613,"Xác suất từ đúng là 51%, xác suất từ chấp nhận được 65% [Le An Ha, 2003]"],[614,"Xác suất này tương đối thấp so với các phương pháp tách từ khác đã đề cập ở trên"],[615,"3.3.5"],[616,"Phương pháp tách từ tiếng Việt dựa trên thống kê từ Internet và thuật toán di truyền (Internet and Genetics Algorithm-based Text Categorization for Documents in Vietnamese - IGATEC) 3.3.5.1"],[617,"Nội dung Phương pháp IGATEC do H.Nguyễn et al (2005) giới thiệu là một hướng tiếp cận mới cho việc tách từ với mục đích phân loại văn bản mà không cần dùng đến"],[618,"35 một từ điển hay tập huấn luyện nào"],[619,"Trong hướng tiếp cận này, tác giả kết hợp giữa thuật toán di truyền (Genetics Algorithm - GA) với dữ liệu thống kê được trích xuất từ Internet tiến hoá một quần thể gồm các cá thể là các khả năng tách từ trong câu"],[620,"Hệ thống gồm ba phần Hình 3.6"],[621,"Toàn cảnh hệ thống IGATEC Online Extractor : Phần này có tác dụng lấy thông tin về tần số xuất hiện của các từ trong văn bản bằng cách sử dụng một search engine nổi tiếng như Google"],[622,"Sau đó, tác giả sử dụng các công thức sau đây để tính toán mức độ phụ thuộc lẫn nhau (mutual information) để là cơ sở tính fitness cho GA engine"],[623,"Tính xác suất các từ xuất hiện trên Internet ( )(w)= count wp MAX 1 21 2 ( & )( & ) count w wp w w MAX = Trong đó, MAX = 4 * 109 ; count(w) số lượng văn bản trên Internet được tìm thấy có chứa từ w hoặc cùng chứa w1 và w2 đối với count(w1 & w2) Tính xác suất độ phụ thuộc của một từ lên một từ khác Online Extractor Online Extractor Online Extractor Online Extractor segmentation segmentation segmentation \u2026"],[624,"36 1 21 2 1 ( & )( | ) ( ) p w wp w w p w = Thông tin phụ thuộc lẫn nhau (mutual information) của các từ ghép được cấu tạo bởi n tiếng (cw = w1w2\u2026wn) 1 2 1 2 1 ( & & .."],[625,"& ) ( ) = ( ) - ( & & .."],[626,"& ) n n j n j p w w wMI cw p w p w w w = ∑ GA Engine for Text Segmentation : mỗi cá thể trong quần thể được biểu diễn bởi chuỗi các bit 0,1, trong đó, mỗi bit đại diện cho một tiếng trong văn bản, mỗi nhóm bit cùng loại đại diện cho một segment"],[627,"Các cá thể được khởi tạo ngẫu nhiên, trong đó, mỗi segment được giới hạn trong khoảng 5"],[628,"GA engine sau đó thực hiện các bước đột biến và lai ghép nhằm mục đích làm tăng giá trị fitness của các cá thể, để đạt được cách tách từ tốt nhất có thể"],[629,"Text Categorization : tác giả dùng độ hỗ trợ (support degree) của văn bản cần phân loại cho các từ khoá để phân loại văn bản"],[630,"3.3.5.2"],[631,"Ưu điểm Không cần sử dụng bất cứ tập huấn luyện hoặc từ điển nào Phương pháp tương đối đơn giản"],[632,"Không tốn thời gian huấn luyện 3.3.5.3"],[633,"Hạn chế So với các phương pháp trước, IGATEC có độ chính xác thấp hơn LRMM và WFST nhưng vẫn chấp nhận được đối với mục đích tách từ dành cho phân loại văn bản"],[634,"Thời gian chạy ban đầu khá chậm do phải lấy thông tin từ Internet mà đường truyền ở Việt Nam còn hạn chế"],[635,"Chưa có các thử nghiệm trên tập dữ liệu đủ lớn"],[636,""],[637,"37 3.4"],[638,"So sánh các phương pháp tách từ Tiếng Việt hiện nay Nhìn một cách tổng quan, phương pháp dựa trên từ (word-base) cho độ chính xác khá cao ( trên 95%) nhờ vào tập ngữ liệu huấn luyện lớn, được đánh dấu chính xác, tuy nhiên hiệu suất của thuật toán phụ thuộc hoàn toàn vào ngữ liệu huấn luyên"],[639,"Bởi vì mục đích của các tác giả [Đinh Điền et al, 2001] là thực hiện tách từ thật chính xác để phục vụ cho việc dịch máy nên tác giả đã chọn phương pháp WFST"],[640,"Với các phương pháp cần phải sử dụng từ điển hoặc tập huấn luyện, ngoài việc tách từ thật chính xác, ta còn có thể nhờ vào các thông tin đánh dấu trong tập ngữ liệu để thực hiện các mục đích khác cần đến việc xác định từ loại như dịch máy, kiểm lỗi chính tả, từ điển đồng nghĩa.."],[641,"Do vậy, mặc dù thời gian huấn luyện khá lâu, cài đặt khá phức tạp, chi phí tạo tập ngữ liệu huấn luyện rất tốn kém, nhưng kết quả mà hướng tiếp cận dựa trên từ mang lại cho mục đích dịch máy là rất xứng đáng cho công sức bỏ ra"],[642,"Hướng tiếp cận dựa trên ký tự (character-based) có ưu điểm là dễ thực hiện, thời gian thực thi tương đối nhanh, tuy nhiên lại có độ chính xác không cao bằng phương pháp dựa trên từ"],[643,"Hướng tiếp cận này thích hợp cho các mục đích nghiên cứu không cần đến độ chính xác tuyệt đối cũng như các thông tin về từ loại như phân loại văn bản, lọc spam, firewall.."],[644,"Nhìn trên bình diện chung, hướng tiếp cận dựa trên từ có nhiều ưu điểm đáng kể, và đem lại nhiều hứa hẹn lạc quan cho các hướng nghiên cứu tiếp theo để nâng cao độ chính xác của phương pháp tách từ này"],[645,"3.5"],[646,"Kết luận Dựa trên các phân tích về ưu khuyết điểm của các phương pháp, chúng em chọn hướng tiếp cận dựa trên \u201ctiếng\u201d (character-based) cho mục tiêu phân loại văn bản của mình"],[647,"Bởi vì, mục tiêu của luận văn là phân loại tin tức báo điện tử, một loại hình cực kỳ phong phú về nội dung và ngôn ngữ, nên việc tạo ra một từ điển hoàn chỉnh và có khả năng cập nhật các thay diễn ra liên tục của ngôn ngữ là khó thực hiện được"],[648,"Hệ thống xử lý cần phải có khả năng linh hoạt, tự động cập nhật những thay đổi"],[649,"38 hằng ngày, nên hướng tiếp cận không dựa trên từ điển hoặc tập ngữ liệu là cực kỳ thích hợp"],[650,"Hơn nữa, hệ thống phân loại tin tức cần có tốc độ xử lý chấp nhận được để có thể xử lý kịp thời các thông tin mới xuất bản hằng ngày"],[651,"Do đó, với ưu điểm đơn giản, tốc độ thực thi chấp nhận đươc, hướng tiếp cận IGATEC là một lựa chọn hoàn toàn phù hợp"],[652,"Mặt khác, việc phân loại văn bản không yêu cầu việc tách từ phải có độ chính xác cao đến mức từng từ"],[653,"Ta có hoàn toàn có thể thực hiện thêm việc loại bỏ các từ không cần thiết cho việc phân loại như các hư từ, thán từ.."],[654,"để tăng tốc độ và sự chính xác của bước tách từ, chuẩn bị cho việc phân loại văn bản"],[655,""],[656,"39 CChhưươơnngg 44 TTÁÁCCHH TTỪỪ TTIIẾẾNNGG VVIIỆỆTT KKHHÔÔNNGG DDỰỰAA TTRRÊÊNN TTẬẬPP NNGGỮỮ LLIIỆỆUU HHAAYY TTỪỪ ĐĐIIỂỂNN \u2013\u2013 MMỘỘTT TTHHÁÁCCHH TTHHỨỨCC Giới thiệu Các nghiên cứu về thống kê dựa trên Internet Các phương pháp tính độ liên quan giữa các từ dựa trên thống kê Tiền xử lý Hướng tiếp cận tách từ dựa trên thống kê từ Internet và thuật toán di truyền Công cụ trích xuất thông tin từ Google Công cụ tách từ dùng thuật toán di truyền Kết quả thực nghiệm Kết luận"],[657,"40 Chương 4"],[658,"TÁCH TỪ TIẾNG VIỆT KHÔNG DỰA TRÊN TẬP NGỮ LIỆU ĐÁNH DẤU (ANNOTATED CORPUS) HAY TỪ ĐIỂN (LEXICON) \u2013 MỘT THÁCH THỨC 4.1"],[659,"Giới thiệu Như chúng ta đã tìm hiểu ở những phần trên, việc khó xác định ranh giới từ đã làm cho việc xử lý tính nhập nhằng trong ngôn ngữ tiếng Việt càng thêm phức tạp.Ví dụ như: câu \u201công lão già đi rất nhanh\u201d, ta có thể phân chia từ theo nhiều cách mà câu vẫn có nghĩa \u201công ||già đi || rất || nhanh\u201d, \u201công già || đi || rất || nhanh\u201d, \u201công || già || đi || rất || nhanh\u201d \u2026 Nhìn chung, đối với tiếng Anh, về mặt lý thuyết tiếng Anh có nhiều thuận lợi vì là loại ngôn ngữ hoà kết hay biến cách (flexion) [Đinh Điền, 2004] , hệ thống ngữ pháp và từ loại đã được quy định rõ ràng, do đó việc phân định ranh giới từ cũng như xây dựng tập ngữ liệu đánh dấu là tương đối đễ dàng"],[660,"Còn đối với tiếng Việt, về mặt lý thuyết tiếng Việt là loại hình đơn lập [Đinh Điền, 2004], phương thức ngữ pháp chủ yếu là trật tự từ và hư từ, vì vậy chỉ xét về mặt phân định ranh giới từ đã có thể có nhiều cách phân định cho cùng một câu mà vẫn đúng ngữ pháp Việt Nam"],[661,"Ở phần này, chúng em xin trình bày hướng tiếp cận cho việc tách từ tiếng Việt theo một hướng mới mà không cần sử dụng tập ngữ liệu huấn luyện hay từ điển"],[662,"Hướng tiếp cận của chúng em dựa trên ý tưởng của bài báo IGATEC, và có nhiều cải tiến đang kể hàm làm tăng chất lượng cho bước tách từ tiếng Việt phục vụ cho việc phân loại tin tức báo điện tử"],[663,"4.2"],[664,"Các nghiên cứu về thống kê dựa trên Internet 4.2.1"],[665,"Giới thiệu Với sự phát triển nhanh chóng của Internet, world-wide-web đã trở thành nguồn dữ liệu lớn nhất trên thế giới, và là nguồn thông tin ngữ nghĩa tiềm tàng được hàng triệu người dùng trên thế giới tạo ra"],[666,"Đối với con người, việc xem xét mức độ liên quan giữa hai từ là rất dễ dàng bởi vì con người có thể dựa vào kiến thức thông"],[667,"41 thường của mình để suy ra ngữ cảnh thích hợp, ví dụ giữa từ \u201ccái nón\u201d và \u201cmàu đỏ\u201d, con người dễ dàng nhận ra sự liên quan là \u201ccái nón có màu đỏ\u201d"],[668,"Tuy nhiên, máy tính của chúng ta không có khả năng như con người, vì vậy, chúng ta phải tìm ra một cách biểu diễn ngữ nghĩa mà máy tính có thể \u201ctiêu hoá\u201d được"],[669,"Có ý kiến cho rằng ta có thể tạo một mạng ngữ nghĩa đồ sộ như một hệ thống trí tuệ ban đầu, sau đó các kiến thức về cuộc sống thực sẽ tự động xuất hiện"],[670,"Tuy nhiên hướng giải quyết này đòi hỏi lượng chi phí khổng lồ cho việc thiết kế cấu trúc có khả năng tính toán tri thức và việc nhập các dữ liệu chuẩn xác do các chuyên gia thực hiện"],[671,"Trong khi nỗ lực này vẫn còn đang trong cuộc đua đường dài, chúng ta hãy sử dụng những thông tin hiện có trên world-wide-web để thực hiện việc biểu diễn ngữ nghĩa"],[672,"Chúng ta đều biết rằng Internet là kho dữ liệu vô tận, do vậy việc khai thác các thông tin trên đó không thể thực hiện thủ công mà chúng ta phải thông qua sự hỗ trợ của một công cụ tìm kiếm trên mạng"],[673,"Nói đến công cụ tìm kiếm (search engine), có lẽ tên tuổi đầu tiên mà chúng ta nghĩ đến là Google, một công cụ tìm kiếm hàng đầu bởi tốc độ và chất lượng mà Google đem lại cho người dùng"],[674,"Và điều đó càng được chứng minh cụ thể hơn khi có ngày càng nhiều các công trình nghiên cứu về thống kê trên Internet dựa vào công cụ tìm kiếm Google như trong phần trình bày tiếp theo sau đây"],[675,"4.2.2"],[676,"Một số công trình nghiên cứu về thống kê dựa trên Internet Theo Rudi Cilibrasi & Paul Vitanyi (2005), công cụ tìm kiếm Google có thể dùng để tự động khám phá ý nghĩa của từ"],[677,"Ví dụ : Google tìm thấy từ \u201cstudent\u201d và \u201cbook\u201d cùng xuất hiện với nhau trên Internet với tần số là 57.600.000, trong khi từ \u201cstudent\u201d và \u201capple\u201d lại chỉ xuất hiện 8.110.000"],[678,"Rõ ràng, chúng ta có thể nhận thấy \u201cstudent\u201d và \u201cbook\u201d có liên quan với nhau mật thiết hơn là \u201cstudent\u201d và \u201capple\u201d"],[679,"Tác giả đã sử dụng kết quả tìm kiếm của Google để huấn luyện ngữ nghĩa của các từ (semantic meaning of words) cho phần mềm \u2013 một vấn đề trọng tâm trong ngành trí tuệ nhân tạo"],[680,"Giả sử muốn tính toán mức độ liên quan giữa từ x với từ y, Rudi & Paul (2005) đã đưa ra công thức tính khoảng cách NGD (Normalise Google Distance) như sau:"],[681,"42 max{log ( ), log ( )} log ( , ) log min{log ( ), log ( )} f x f y f x yNGD M f x f y − = − (1) Trong đó : f(x) :số trang web chứa từ x mà Goole trả về f(x,y) : số trang web chứa đồng thời từ x và từ y M = 8.058.044.651 là số trang web hiện tại mà Google đã đánh chỉ mục Với công thức trên, giá trị của NGD càng nhỏ thì mức độ liên quan giữa hai từ càng cao"],[682,"Ví dụ: tần số xuất hiện của \u201cstudent\u201d= 401.000.000, \u201cbook\u201d = 387.000.000, đồng thời là 57.600.000, còn \u201capple\u201d là 144.000.000, \u201cstudent\u201d & \u201capple\u201d= 8.110.000"],[683,"Với M = 8.058.044.651, ta có 6 6 6 log 401.10 log 57,6.10( , ) 0.64 log8058044651 log 387.10 NGD student book −≈ ≈ − 6 6 6 log 401.10 log8,11.10( , ) 0.97 log8058044651 log144.10 NGD student apple −≈ ≈ − Từ kết quả trên, ta có NGD(student,book) ≈0.64 < NGD(student,apple) ≈0.97, nên có thể kết luận là \u201cstudent\u201d liên quan với \u201cbook\u201d nhiều hơn là \u201capple\u201d"],[684,"Nếu NGD của hai từ lớn hơn 1 thì tác giả nhận xét rằng hai từ đó thường xuất hiện cùng với nhau trong trang web mà không vì một mối liên quan nào cả"],[685,"Ví dụ: tần số xuất hiện của \u201cby\u201d là 2.770.000.000, \u201cwith\u201d là 2.566.000.000, đồng thời \u201cby\u201d và \u201cwith\u201d là 49.700.000"],[686,"Với M = 8.058.044.651, ta có NGD(by,with) ≈ 3.51 Hơn nữa, NGD là số tỉ lệ bất biến (scale-invariant) nên có tính ổn định với sự tăng trưởng số lượng trang web trên Google"],[687,"Đây là tính chất rất quan trọng bởi vì M số lượng trang web do Google đánh chỉ mục tăng thường xuyên, do đó, số trang web chứa các ngữ tìm kiếm cũng tăng lên ứng với tỉ lệ đó"],[688,"Điều này có nghĩa là nếu M tăng gấp đôi thì tần số xuất hiện của các ngữ cũng tăng gấp đôi"],[689,"Công trình của Rudi & Paul (2005) đã mở ra một hướng tiếp cận mới cho các công trình nghiên cứu khác nhờ tính chất không giới hạn bởi dữ liệu, dễ dàng thực thi và là nền móng cho các phương pháp nghiên cứu khác [Rudi & Paul, 2005]"],[690,""],[691,"43 Ngoài ra, theo James & Daniel (2005) còn có một số công trình nghiên cứu về phương pháp thống kê khác trên Internet như tính toán kết quả tìm kiếm bằng hàm luỹ thừa [Simkin & Roychowdhurry, 2003] [Bagrow et al, 2004] , hay phương pháp được đánh giá tốt hơn là dựa vào giá trị tương tự cực đại (Maximum Likelihood) [James & Daniel, 2005]\u2026"],[692,"Mục đích của việc sử dụng giá trị tương tự cực đại để tìm ra chỉ số gần giống nhau nhất giữa hai khái niệm"],[693,"Tuy nhiên, theo kết luận của James & Daniel(2005), các phương pháp tính toán dựa trên hàm mũ cho kết quả chưa khả quan lắm và còn mang tính chủ quan"],[694,"4.2.3"],[695,"Nhận xét Hướng thống kê dựa trên Internet hứa hẹn nhiều kết quả khả quan vì không cần phụ thuộc vào tập dữ liệu huấn luyện truyền thống mà chúng ta có thể tận dụng khả năng vô tận của Internet thông qua công cụ tìm kiếm"],[696,"Dựa trên nhận xét của Rudi & Paul (2005), tỉ lệ xuất hiện của từ trên Internet là khá ổn định, điều này cho phép ta thực hiện các tính toán chính xác và ổn định vì ít phụ thuộc vào số lượng trang web trên Internet tăng lên theo thời gian"],[697,"Hiện nay, các công trình nghiên cứu theo hướng tiếp cận mới này chủ yếu được thực hiện trên tiếng Anh, còn đối với tiếng Việt thì có thể nói IGATEC là công trình đầu tiên áp dụng phương pháp này nhưng đã đạt được kết quả rất đáng quan tâm"],[698,"Chúng em hy vọng rằng rằng những nỗ lực nghiên cứu và cải tiến phương pháp IGATEC sẽ đạt được kết quả tốt hơn"],[699,"4.3"],[700,"Các phương pháp tính độ liên quan giữa các từ dựa trên thống kê Trong ngôn ngữ tự nhiên, nhất là loại ngôn ngữ phụ thuộc nhiều vào ngữ cảnh như tiếng Việt, đối với con người, chúng ta có thể dễ dàng xác định được ranh giới từ trong câu"],[701,"Tuy nhiên, do chưa có một quy định cụ thể nào về ranh giới từ tiếng Việt, nên có thể nhiều người Việt có nhiều cách tách từ khác nhau"],[702,"Đối với người chúng ta vẫn chưa thống nhất được, nên khi dùng máy tính để xử lý ngôn ngữ ta vẫn chưa có một chuẩn nào để xác định đâu là ranh giới từ"],[703,"Vì vậy, đã có rất nhiều công"],[704,"44 trình nghiên cứu cách tính toán độ liên quan giữa các từ để khắc phục các công việc phức tạp do cách phân tích cấu trúc ngữ pháp trong câu đem lại"],[705,"Trong phần này, chúng em sẽ trình bày hai nội dung chính: Hai thước đo chuẩn dùng để tính toán độ liên quan giữa hai từ trong tiếng Anh là thông tin tương hỗ (Mutual Information ) và t-score"],[706,"Một số ứng dụng và cải tiến của hai công cụ đo trên trong việc tách từ tiếng Hoa và tiếng Việt"],[707,"4.3.1"],[708,"Thông tin tương hỗ (Mutual Information) và t-score dùng trong tiếng Anh Thông tin tương hỗ (Mutual Information) và t-score là hai khái niệm rất quan trọng trong học thuyết về thông tin (Information Theory) và thống kê được trình bày trong [Church et al, 1991] cho mục đích tính toán mức độ liên quan của hai từ trong tiếng Anh"],[709,"4.3.1.1"],[710,"Thông tin tương hỗ MI (Mutual Information) \u2013 thước đo đặc điểm tương tự (A Measure of Similarity) Theo Church et al (1991), việc thống kê thông tin tương hỗ (Mutual Information) dùng để nhận biết các trường hợp ngôn ngữ thú vị, bao gồm từ mối quan hệ ngữ nghĩa (semantic relations) như bác sĩ/y tá (dạng content word/content word) cho đến mối quan hệ từ vựng-cú pháp (lexico-syntactic) như sự xuất hiện đồng thời giữa động từ và giới từ (dạng content word/ funtion word)"],[711,"MI có nhiệm vụ so sánh xác suất xuất hiện đồng thời (joint probability) của từ x và từ y so với xác suất tìm thấy x và y xuất hiện độc lập"],[712,"Công thức tính MI cho hai từ tiếng Anh trong [Church et al, 1991] như sau: 2 ( , )( ; ) log ( ) ( ) P x yI x y P x P y ≡"],[713,"45 Trong đó: x và y là hai từ tiếng Anh cần kiểm tra mức độ kết hợp lẫn nhau"],[714,"I(x;y) là thông tin tương hỗ của hai từ"],[715,"P(x), P(y) là xác suất xuất hiện độc lập của x và của y"],[716,"P(x,y) là xác suất xuất hiện đồng thời x và y"],[717,"Theo Church et al (1991), giá trị I(x,y) càng lớn thì khả năng kết hợp của x và y càng cao"],[718,"4.3.1.2"],[719,"t-score \u2013 thước đo sự khác biệt (A Measure of Dissimilarity) Chúng ta dễ dàng nhận ra sự giống nhau giữa strong và powerful, tuy nhiên làm cách nào để phân biệt sự khác nhau giữa chúng"],[720,"Ví dụ, chúng ta đều biết rằng người ta thường nói strong tea, powerful car hơn là nói powerful tea và strong car"],[721,"Nhưng làm sao cho máy tính nhận ra được sự khác biệt này"],[722,"Giả sử , ta biết rằng strong support được dùng phổ biến hơn là powerful support, Church et al (1991) đã đưa ra công thức tính t-score để đo sự khác biệt trên: 1 2 2 2 1 2 ( | ) - ( | ) ( ( | ) ( | )) P w w P w wt P w w w wσ σ = − + Trong đó: w1,w2 là hai từ tương tự nhau cần phải phân biệt (ở ví dụ trên là strong và powerful)"],[723,"w là từ dùng để phân biệt (ở ví dụ trên là support)"],[724,"P(w|w1), P(w|w2) là xác suất của từ w xuất hiện đi kèm với từ w1, w2 Lúc đó: 2 2 2 2 ( ) - ( ) ( ( )) ( ( )) ( ) f ( ) - ( ) ( ) 2 175 13 2 175 P powerful support P strong supportt P powerful support P strong support f powerful support strong support N N f powerful support f strong support N N σ σ = − + ≈ − + − ≈ − ≈ − +"],[725,"46 Ta nói rằng powerful support có độ lệch chuẩn (standard deviation) kém strong support 13 lần"],[726,"Nhờ vậy, ta có thể phân biệt được sự khác nhau giữa powerful và strong trong việc sử dụng hai từ này"],[727,"4.3.2"],[728,"Một số cải tiến trong cách tính độ liên quan ứng dụng trong tách từ tiếng Hoa và tiếng Việt 4.3.2.1"],[729,"Thông tin tương hỗ (Mutual Information) Khi áp dụng thông tin tương hỗ MI trong tách từ tiếng Hoa, Su et al (1993) cho rằng thông tin tương hỗ (Mutual Information) là thước đo mức độ kết hợp của một từ"],[730,"Nó có nhiệm vụ so sánh xác suất một nhóm các ký tự (tương tự như \u201ctiếng\u201d trong tiếng Việt \u2013 xem giải thích ở mục 3.2.3.) xuất hiện đồng thời (joint probability) so với xác suất tìm thấy từng ký tự xuất hiện độc lập"],[731,"Theo Su et al (1993) cách tính MI cho từ có 2 ký tự có thể áp dụng công thức của Church et al (1991) với ý nghĩa của x và y lúc này không còn là \u201ctừ\u201d (word) như trong tiếng Anh mà được hiểu là tiếng (xem giải thích ở mục 3.2.3.) trong tiếng Hoa"],[732,"2 ( , )( ; ) log ( ) ( ) P x yI x y P x P y ≡ (1a) Trong đó: x và y là hai tiếng cần kiểm tra mức độ kết hợp lẫn nhau trong tiếng Hoa"],[733,"I(x;y) là thông tin tương hỗ của hai tiếng"],[734,"P(x), P(y) là xác suất xuất hiện độc lập của tiếng x và của tiếng y"],[735,"P(x,y) là xác suất xuất hiện đồng thời tiếng x và tiếng y"],[736,"Cách tính MI dành cho từ ghép 3 tiếng như sau [Su et al, 1991]: 2 ( , , )( ; ; ) log ( , , ) D I P x y zI x y z P x y z ≡ (1b) Trong đó: PD(x,y,z) ≡ P(x,y,z) là xác suất xuất hiện đồng thời của x, y và x, (Dependently)"],[737,"47 PI(x,y,z) là xác suất xuất hiện độc lập của x,y, z (Independently) với PI(x,y,z) ≡ P(x)P(y)P(z) + P(x)P(y,z) + P(x,y)P(z)"],[738,"Nhìn chung I(.) >>0 sẽ cho biết từ ghép đó có mức độ liên quan giữa các tiếng là rất chặt chẽ"],[739,"Ngược lại, các tiếng có xu hướng xuất hiện một cách độc lập"],[740,"Một cách tính MI khác cũng được Ong & Chen (1999) đề nghị như sau: 1 2 1 2 ( & & .."],[741,"& ) ( ) = ( ) ( ) ( & & .."],[742,"& ) n n p w w wMI cw p lw p rw p w w w+ − (2) Trong đó cw = p( w1 & w2 ...& wn-1 ) lw = p( w1 & w2 ...& wn-1 ) rw = p ( w2 & w3 ...& wn) Theo nghiên cứu của chúng em, hiện nay công trình nghiên cứu về cách tách từ dựa trên độ tương hỗ MI trên tiếng Việt chưa nhiều"],[743,"Ở đây, chúng em xin giới thiệu cách tính MI được đề nghị trong IGATEC trong [H"],[744,"Nguyen et al, 2005] 1 2 1 2 1 ( & & .."],[745,"& ) ( ) = ( ) - ( & & .."],[746,"& ) n n j n j p w w wMI cw p w p w w w = ∑ (3) Nhìn vào các công thức tính MI, ta có thể dự đoán được mỗi công thức ưu tiên cho một loại từ khác nhau"],[747,"Phần tiếp theo sau đây sẽ trình bày một số nhận xét về các công thức trên để làm cơ sở đưa ra lựa chọn phù hợp nhất"],[748,"4.3.2.2"],[749,"Cách tính tần số tương đối (Relative Frequency Count) Cách tính tần số tương đối cho từ ghép có i tiếng được định nghĩa như sau [Su et al, 1993]: i i fr K = Trong đó, fi là số lần xuất hiện của từ ghép có i tiếng (ith n-gram) trong tập ngữ liệu, và K là số lần xuất hiện trung bình của một từ"],[750,"Nói một cách khác, fi được bình thường hoá bằng cách chia cho K để lấy tỉ lệ liên quan"],[751,"Một cách trực quan, ta sẽ"],[752,"48 nhận ra, cách tính RFC sẽ ưu tiên cho những từ xuất hiện với tần số rất cao mà nó sẽ bỏ mất những xuất hiện trong từ điển với tần số thấp"],[753,"Vì vậy, RFC được dùng như một thuộc tính hỗ trợ thêm cho việc tách từ"],[754,"4.3.2.3"],[755,"Nhận xét về cách sử dụng MI và RFC Nếu ta sử dụng đồng thời MI và RFC cho việc tách từ sẽ đem lại kết quả như mong đợi bởi vì nếu chỉ sử dụng một công cụ tính toán, kết quả chúng ta đạt được có thể chỉ ưu tiên cho một cách tách nào đó"],[756,"Nếu chỉ sử dụng RFC, hệ thống của chúng ta có xu hướng chọn những từ xuất hiện nhiều lần nhưng lại có độ liên quan MI thấp"],[757,"Ví dụ, nếu P(x) và P(y) rất lớn, nó có thể tạo ra P(x,y) cũng rất lớn mặc dù x và y không hề liên quan gì cả vì P(x,y)/ P(x) x P(y) rất nhỏ"],[758,"Mặc khác, nếu chỉ sử dụng MI thôi, thì ở trường hợp P(x) và P(y) quá nhỏ sẽ dẫn đến kết quả không đáng tin cậy"],[759,"Một từ n-gram có thể có MI cao không bởi vì chúng kết hợp chặt chẽ với nhau mà bởi vì khi chia hai số cùng nhỏ như nhau, ta sẽ có số MI lớn"],[760,"Tóm lại, ta nên sử dụng cả hai thông tin MI và RFC vì thực tế, một nhóm các từ vừa có RFC và MI cao sẽ có xu hướng vừa kết hợp chặt chẽ với nhau, vừa được sử dụng rộng rãi"],[761,"4.3.3"],[762,"Nhận xét về các cách tính độ liên quan khi áp dụng cho tiếng Việt Tiếng Hoa là loại ngôn ngữ đơn lập giống tiếng Việt, nên ta có thể áp dụng một số công tình nghiên cứu trên tiếng Hoa lên tiếng Việt"],[763,"Về mặt lý thuyết, ta hoàn toàn có thể sử dụng các công thức MI trên để áp dụng cho tiếng Việt, và quan thực nghiệm, chúng ta sẽ đề xuất thêm một số cải tiến để công thức tính MI phù hợp với việc tách tiếng Việt hơn nữa"],[764,"Đối với công thức RFC, ta cần phân biệt khái niệm f trong công thức là tần số xuất hiện của từ trong tập ngữ liệu, K là số lần xuất hiện trung bình của một từ (real word) trong tập ngữ liệu"],[765,"Khi sử dụng tập ngữ liệu, các số f và K là hoàn toàn tính được"],[766,"Tuy nhiên, phương pháp IGATEC mà chúng em sử dụng lại lấy kết quả số lượng trang web p chứa từ cần tìm nên chúng ta không thể tính được số K ( vì không thể dựa vào số lượng trang web trả về"],[767,"49 mà quyết định đó là từ hay không)"],[768,"Do vậy, hiện tại, chúng em vẫn chưa áp dụng cách tính RFC trên tiếng Việt"],[769,"Bản chất của phương pháp tính t-score là tìm sự khác nhau trong việc sử dụng từ trong tiếng Anh, chúng em nhận thấy chưa thật sự cần thiết trong việc tách từ làm tăng tính phức tạp của việc tính toán"],[770,"Do đó, chứng em chưa áp dụng t-score vào tách từ"],[771,"4.4"],[772,"Tiền xử lý (Pre-processing) Bởi vì các bài báo điện tử được trình bày dưới dạng html, nên trước khi thực hiện tách từ để phân loại, chúng em phải xử lý văn bản để lấy ra những nội dung quan tâm"],[773,"4.4.1"],[774,"Xử lý văn bản đầu vào Nội dung tóm tắt của bài báo là rất quan trọng vì nó thể hiện nội dung bài báo một cách cô đọng, súc tích, rõ ràng, giúp người xem dự đoán được đề tài của bài báo muốn đề cập đến"],[775,"Chính vì lý do đó, chúng em quyết định thực hiện việc phân loại tin tức dựa trên phần tóm tắt của bài báo để tiết kiệm thời gian xử lý và đạt được kết quả chính xác cao"],[776,"Trong mỗi văn bản, khối tiền xử lý sẽ nhận diện tiêu đề, tóm tắt\u2026 của bài báo bằng cách dựa vào thông tin định dang của các thẻ trong trang html"],[777,"Theo khảo sát của chúng em về cấu trúc hiển thị nội dung trang báo điện tử ở các trang web tin tức ở Việt Nam, tác giả luôn trình bày nội dung tóm tắt (abstract) của bài báo trước bài viết chi tiết, nên hướng phân loại dựa trên tóm tắt của bài báo là khả thi"],[778,""],[779,"50 Hình 4"],[780,"1"],[781,"Nội dung thông tin cần lấy Sau khi rút trích được nội dung cần thiết, chúng em tiếp tục thực hiện tách ngữ, phục vụ cho công việc tách từ"],[782,"4.4.2"],[783,"Tách ngữ & tách stopwords Tách ngữ: Ứng với mỗi văn bản đã rút trích từ trang web, chúng em tiến hành loại bỏ các ký hiệu, các chữ số không cần thiết, sau đó, phân tích văn bản thành các ngữ phân cách bởi dấu câu"],[784,"Tách stopword: Nhằm làm tăng tốc độ tính toán của GA và lượt bớt các từ không có nghĩa phân loại trong câu, chúng em có thử nghiệm tách stopword trước khi tiến hành tách từ"],[785,"Bước tách stopword tỏ ra khá hiệu quả trong việc làm tăng tốc độ GA nhờ chia nhỏ các ngữ ra thành những ngữ nhỏ hơn"],[786,"Tuy nhiên, cách tách stopword không phải lúc nào cũng cho kết quả như mong đợi bởi vì tách stopword trước khi tách từ sẽ có nhiều khả năng làm sai lạc ý nghĩa của câu, ảnh hưởng đến việc phân loại sau đó"],[787,"Do đó, chúng em đã thử nghiệm việc tách stopword sau khi"],[788,"51 đã tách từ, kết quả phân loại sau khi đã loại bỏ stopword là khả quan hơn cách thực hiện ban đầu"],[789,"(Xin xem chương 6 để biết kết quả thực nghiệm.) 4.5"],[790,"Hướng tiếp cận tách từ dựa trên thống kê từ Internet và thuật toán di truyền (Internet and Genetic Algorithm-based ) Chúng em xây dựng hai công cụ hỗ trợ cho việc tách từ gồm: công cụ trích xuất thông tin từ Google và công cụ tách từ dùng thuật toán di truyền"],[791,"4.5.1"],[792,"Công cụ trích xuất thông tin từ Google 4.5.1.1"],[793,"Mục đích Ngày nay, cùng với sự phát triển nhanh chóng của các công nghệ thông tin hiện đại, Internet đã trở thành một thư viện tuyệt vời với một khối lượng văn bản đồ sộ"],[794,"Do đó, việc khai thác thông tin từ world-wide-web như một tập ngữ liệu khổng lồ cho các công trình nghiên cứu sẽ rút ngắn được thời gian và công sức tự xây dựng một tập ngữ liệu riêng"],[795,"Với sự giúp sức của công cụ tìm kiếm miễn phí trên mạng, những thông tin cần thiết sẽ được lấy về một cách nhanh chóng và chính xác"],[796,"Chúng em chọn Google là công cụ tìm kiếm chính bởi vì những ưu thế về tính nhanh chóng, chính xác, và phổ biến của nó so với các công cụ tìm kiếm khác"],[797,"Trong luận văn này, chúng em cần hai loại thông tin: Tần số xuất hiện của các văn bản chứa các từ (document frequency) trên các trang web để làm tính công thức MI, dự đoán khả năng tồn tại của một từ là đúng hay không Tần số các văn bản chứa từ với từ khóa đại diện cho chủ đề dùng để tính mức độ liên quan của từ với các chủ đề cần phân loại"],[798,"Do vây, nhiệm vụ của công cụ trích xuất thông tin từ Google sẽ lấy kết quả tìm kiếm của Google, trả về cho chương trình khi chúng ta đưa yêu cầu tìm kiếm"],[799,""],[800,"52 4.5.1.2"],[801,"Các công thức tính xác suất và độ tương hỗ 4.5.1.2.1"],[802,"Các công thức tính xác suất Khi nhận được kết quả trả về, dựa vào nền tảng của các công trình nghiên cứu về thống kê trên Internet của Rudi & Paul (2005), chúng em sẽ sử dụng các công thức sau đây để tính toán chỉ số MI"],[803,"Các công thức tính xác suất các từ xuất hiện trên Internet : Gọi count(w) là số lượng trang web chứa từ w count(w1 & w2) là số trang web chứa đồng thời w1 và w2 ( )(w)= count wp MAX 1 21 2 ( & )( & ) count w wp w w MAX = Trong đó, MAX = 4 * 109; 4.5.1.2.2"],[804,"Các công thức tính độ tương hỗ (Mutual Information \u2013 MI) Đối với hướng tiếp cận N-Gram để tách từ, công thức MI để tính toán khả năng tồn tại một ngữ cần tách trong câu là rất quan trọng"],[805,"Độ tương hỗ (Mutual Information) cho biết thông tin phụ thuộc lẫn nhau của các từ ghép được cấu tạo bởi n tiếng (cw = w1 w2 \u2026 wn)"],[806,"Đối với từ một tiếng, ta quy ước MI = p(w)"],[807,"Đối với từ ghép từ 2 tiếng trở lên, chúng em thử nghiệm 3 cách tính MI để tìm ra các tính hiệu quả nhất"],[808,"MI theo cách tính của IGATEC [H"],[809,"Nguyen et al, 2005] ) (đã được trình bày ở mục 4.3.2.1.) 1 2 1 2 1 ( & & .."],[810,"& ) ( ) = ( ) - ( & & .."],[811,"& ) n n j n j p w w wMI cw p w p w w w = ∑ (2) MI theo cách tính của [Ong & Chen, 1999] (đã được trình bày ở mục 4.3.2.1.) Giả sử ta có cw = p( w1 & w2 ...& wn-1 ) lw = p( w1 & w2 ...& wn-1 )"],[812,"53 rw = p ( w2 & w3 ...& wn) 1 2 1 2 ( & & .."],[813,"& ) ( ) = ( ) ( ) ( & & .."],[814,"& ) n n p w w wMI cw p lw p rw p w w w+ − (3) MI do chúng em đề nghị: Giả sử ta có cw = p( w1 & w2 ...& wn-1 ) Với n chẵn : lw = p( w1 & w2 ...& wn/2 ), rw = p ( wn/2+1 & wn/2+2 ...& wn) Với n lẻ: lw = p( w1 & w2 ...& wn-1 ) , rw = p ( w2 & w3 ...& wn) 1 2 1 2 ( & & .."],[815,"& ) ( ) = ( ) ( ) ( & & .."],[816,"& ) n n p w w wMI cw p lw p rw p w w w+ − (4) Chúng ta sẽ sử dụng các công thức trên để tính độ thích nghi của các cá thể trong thuật toán di truyền dưới đây"],[817,"Kết quả của mỗi công thức tính MI sẽ ưu tiên cho những loại từ ghép khác nhau mà ta sẽ hiểu rõ hơn trong kết quả thực nghiệm ở chương 6"],[818,"4.5.2"],[819,"Công cụ tách từ dùng thuật toán di truyền (Genetic Algorithm \u2013 GA) Mục đích của chúng ta là tìm ra các cách tách từ hợp lý nhất cho văn bản, tuy nhiên, chúng ta gặp phải trở ngại là không gian tìm kiếm (search space) quá lớn do sự bùng nổ tổ hợp khi sinh ra dãy các từ"],[820,"Như chúng ta đều biết, thuật toán di truyền (Genetic Algorithm \u2013 GA) được biết đến với khả năng duyệt tắt qua những không gian tìm kiếm lớn một cách hiệu quả và đưa ra những giải pháp toàn cục tối ưu nhất"],[821,"GA thực hiện tiến hoá một số thế hệ để tạo ra một quần thể gồm những cá thể tối ưu nhờ vào các bước lai ghép (cross-over), đột biến (mutation), sinh sản (reproduction), và cách chọn lựa cá thể"],[822,"Chất lượng của mỗi cá thể được tính toán dựa trên chỉ số fitness cho mỗi cá thể và quần thể"],[823,"Trong quá trình thử nghiệm, chúng em chọn top N cá thể chất lượng nhất sau khi thực hiện các bước lai ghép, đột biến, sinh sản"],[824,"4.5.2.1"],[825,"Khảo sát độ dài của \u201ctừ\u201d trên từ điển"],[826,"54 Như chúng ta đều biết, thuật toán di truyền đòi hỏi phải có rất nhiều tham số cho các bước thực hiện như số cá thể trong quần thể, số thế hệ tiến hoá, tỉ lệ lai ghép, tỉ lệ đột biến\u2026 Do vậy, chất lượng lựa chọn các tham số trên sẽ quyết định kết quả của thuật toán di truyền"],[827,"Chính vì tính chất quan trọng của các tham số, chúng em thực hiện một khảo sát nhỏ về số lượng từ tương ứng với chiều dài từ trên từ điển thông dụng tại http://dict.vietfun.com để làm cơ sở cho các tham số sau này"],[828,"Độ dài từ (tiếng) Tần số xuất hiện Tỉ lệ 1 8933 12.2 2 48995 67.1 3 5727 7.9 4 7040 9.7 ≥ 5 2301 3.1 Tổng cộng 72994 100 Bảng 4"],[829,"1"],[830,"Thống kê độ dài từ trong từ điển Có một điều cần lưu ý là tại thời điểm này, chúng ta vẫn chưa có một từ điển chuẩn nào được dùng cho việc xử lý ngôn ngữ, do đó, chúng em quyết định dùng loại từ điển phổ dụng để thống kê"],[831,"Theo kết quả thống kê, trên 67% là từ ghép hai tiếng, còn lại khoảng 30% là các từ ghép một, ba, bốn tiếng"],[832,"Các cụm từ dài hơn bốn tiếng chiếm khoảng 3%, tuy nhiên các cụm từ đó đa số là các câu thành ngữ của Việt Nam"],[833,"Kết quả thống kê trên có ý nghĩa rất quan trọng đối với công cụ tách từ bằng GA của chúng em"],[834,"Dựa trên tỉ lệ của các loại từ, chúng em thực hiện việc khởi tạo cá thể ngẫu nhiên có thêm thông tin về xác suất xuất hiện của từ và đó là cơ sở để chúng em quyết định cách tách từ phù hợp với thực tế của tiếng Việt"],[835,"Chi tiết về các ứng dụng của kết quả khảo sát sẽ được chúng em trình bày ở các phần sau"],[836,"4.5.2.2"],[837,"Khởi tạo quần thể"],[838,"55 4.5.2.2.1"],[839,"Biểu diễn cá thể Giả sử văn bản đầu vào t được tạo thành bởi n tiếng (syllables) như sau: t=s1s2...sn"],[840,"Mục đích của quá trình chạy GA là tìm ra cách tách từ có độ chấp nhận cao nhất : t=w1w2\u2026wm , với wk= si\u2026 sj (1 ≤ k ≤ m, 1 ≤ i,j ≤ n) Tương tự như IGATEC, chúng em cũng biểu diễn mỗi cá thể (id) trong quần thể (pop) bởi chuỗi các bit 0,1, trong đó, mỗi bit đại diện cho một tiếng trong văn bản, mỗi nhóm bit cùng loại đại diện cho một từ (word)"],[841,"Ví dụ: Với câu \u201cNhững || con || khủng long || trong || phim hoạt hình || rất || ngộ nghĩnh\u201d, chúng em sẽ biểu diễn dưới dạng các bit 0, 1 như sau: Hình 4"],[842,"2"],[843,"Biểu diễn cá thể bằng các bit 0,1 4.5.2.2.2"],[844,"Khởi tạo các tham số Ở bước khởi tạo tham số, ta phải thiết lập một vài tham số cơ bản cho GA như số thế hệ tiến hoá (generations), kích thước quần thể (population size), tỉ lệ lai ghép (reproduction fraction)\u2026 Ngoài ra, vì mỗi cá thể của chúng ta là một thể hiện cách tách từ trong câu, nên ta sẽ lợi dụng tính chất liên kết của các từ để thực hiện khởi tạo cá thể ngẫu nhiên ban đầu"],[845,"Tính chất liên kết của từ được thể hiện qua tỉ lệ của các từ trong từ điển, nên ta sẽ có thêm tham số về khả năng xuất hiện từ trong câu ở bảng tham số dưới đây"],[846,""],[847,"56 Tham số Giá trị Số thế hệ tiến hoá 100 Kích thước quần thể 50 Tỉ lệ lai ghép 95% Tỉ lệ đột biến 5% Top N cá thể được chọn 100 Tỉ lệ từ 1 tiếng (mono-gram) 10% Tỉ lệ từ 2 tiếng (bigram) 70% Tỉ lệ từ 3 tiếng (trigram) 10% Tỉ lệ từ 4 tiếng (quadgram) 10% Bảng 4"],[848,"2"],[849,"Tham số thực hiện GA 4.5.2.2.3"],[850,"Khởi tạo cá thể Như chúng ta đều biết, quy tắc của thuật toán di truyền là thực hiện tiến hoá các cá thể qua các thế hệ nhằm đạt đến độ hội tụ của chỉ số thích nghi (sẽ được nói rõ ở mục 4.5.2.3)"],[851,"Nếu cá thể được khởi tạo ngẫu nhiên sẽ có độ thích nghi thấp, chúng ta phải tiến hoá qua rất nhiều thế hệ để đạt đến độ hội tụ cần thiết"],[852,"Và hậu quả là số thế hệ tiến hoá càng nhiều thì thời gian tiêu tốn và chi phí tính toán càng cao"],[853,"Giải pháp khắc phục nhược điểm trên là khởi tạo một số cá thể ban đầu gần với điểm hội tụ, nhờ vậy có thể rút ngắn được số thế hệ tiến hoá, tăng tốc độ"],[854,"Ở bước khởi tạo quần thể, chúng em tạo ra cá các thể bằng hai cách: khởi tạo ngẫu nhiên và khởi tạo dựa trên phương pháp MM:forward/backward [Chih-Hao Tsai, 2000]"],[855,"4.5.2.2.3.1"],[856,"Khởi tạo cá thể ngẫu nhiên Theo thống kê ở bảng 4.1, chúng em quyết định đặt ra một số giới hạn cho việc tạo cá thể ngẫu nhiên"],[857,"Đầu tiên, tất cả các từ ghép wk tạo ra có độ dài không quá 4"],[858,""],[859,"57 Thứ hai, chúng em khởi tạo ngẫu nhiên các cá thể có số lượng từ tương ứng với tỉ lệ về độ dài từ ở trên, nhằm tạo ra điểm xuất phát tốt cho quá trình thực hiện GA"],[860,"Ví dụ: Giả sử ta có câu đầu vào \u201cNhững con khủng long trong phim hoạt hình rất đáng yêu\u201d gồm 11 tiếng"],[861,"Theo các tham số khởi tạo của bảng 4.2., chúng em thiết lập giới hạn tạo từ ngẫu nhiên trong câu: Hình 4"],[862,"3"],[863,"Thang tỉ lệ phát sinh loại từ Một bộ phát sinh ngẫu nhiên sẽ phát sinh xác suất f (0 ≤ f ≤ 1) để chọn loại từ: Nếu 0 ≤ f < 0.1 : phát sinh loại từ 1 tiếng Nếu 0.1 ≤ f < 0.8 : phát sinh loại từ 2 tiếng Nếu 0.8 ≤ f < 0.9 : phát sinh loại từ 3 tiếng Nếu 0.9 ≤ f ≤ 1: phát sinh loại từ 4 tiếng 4.5.2.2.3.2"],[864,"Khởi tạo cá thể bằng Maximum Matching : forward/backward (Phương pháp Maximum Matching : forward/backward [Chih-Hao Tsai, 2000] đã được trình bày ở mục 3.2.1.) Đây là bước khởi tạo rất quan trọng và điểm cải tiến đáng kể so với IGATEC"],[865,"Chúng em chọn phương pháp MM: forward/backward để khởi tạo cá thể ban đầu vì độ chính xác khá cao của phương pháp này sẽ tạo ra cá các thể gần đúng nhất, giúp tăng tốc quá trình tiến hoá"],[866,"Ngoài ra, việc áp dụng phương pháp MM theo dạng đơn giản chỉ cần duyệt tuyến tính, sẽ giảm thiểu được chi phí và thời gian tính toán so với các phương pháp khác"],[867,"Chúng em thực hiện tách từ theo hai hướng từ trái sang phải, và từ phải sang trái"],[868,"Nếu hai cách tách từ trên trùng nhau, chúng em sẽ chọn một và gộp vào các cá thể đã được phát sinh ngẫu nhiên ở trên"],[869,""],[870,"58 Sau khi khởi tạo xong, quần thể sẽ được tiến hóa qua các quá trình lai ghép, đột biến, sinh sản, 4.5.2.3"],[871,"Thực hiện tiến hoá 4.5.2.3.1"],[872,"Quá trình lai ghép (cross-over) Chúng em áp dụng phương pháp chuẩn của lai ghép là dựa trên một điểm ngẫu nhiên trong chuỗi bit của cá thể"],[873,"Khi có một cặp cá thể bố mẹ , thế hệ con được tạo ra dựa trên sự kết hợp từ phần đầu tiên của bố với phần cuối của mẹ và ngược lại"],[874,"Tuy nhiên, trong quá trình lai ghép, chúng em nhận thấy giới hạn từ ghép tối đa 4 tiếng có thể bị phá vỡ, do đó, đối với những phân đoạn wk nào có độ dài hơn chúng em sẽ thực hiện việc chuẩn hóa từ vị trí đó đến cuối sao cho không có một từ nào vượt quá 4 tiếng"],[875,"Ví dụ: Hình 4"],[876,"4.Quá trình lai ghép 4.5.2.3.2"],[877,"Quá trình đột biến (mutation) Thay vì thực hiện phương pháp bật tắt bit (bit flip), chúng em thực hiện việc hoán chuyển vị trí của hai bit liền nhau tại một vị trí ngẫn nhiên"],[878,"Ý tưởng thực hiện"],[879,"59 đột biến như thế này bởi vì, trong việc phân định ranh giới từ, ta dễ dàng nhận ra rằng một tiếng nếu kết hợp với tiếng trước không phù hợp thì có thể kết hợp với từ đứng sau sẽ phù hợp hơn, hoặc là đứng một mình"],[880,"Tương tự như phần lai ghép, chúng em thực hiện chuẩn hoá các cá thể sau khi đột biến"],[881,"Ví dụ: Hình 4"],[882,"5"],[883,"Quá trình đột biến 4.5.2.3.3"],[884,"Quá trình sinh sản (reproduction) Sau khi lai ghép và đột biến, chúng em kết hợp các cá thể bố mẹ với cá thể con vừa được tạo ra để phục vụ cho bước chọn cá thể"],[885,"Sau khi kết hợp, chúng em lọc bỏ các cá thể trong quần thể, để đạt được nhiều cách tách từ tốt"],[886,"Ví dụ: Hình 4"],[887,"6"],[888,"Quá trình sinh sản"],[889,"60 4.5.2.3.4"],[890,"Quá trình chọn cá thể (selection) Ở mỗi thế hệ, chúng em chỉ chọn top N cá thể từ quá trình sinh sản ở trên"],[891,"Trước tiên, các cá thể sẽ được tính độ thích nghi (fitness) chính là tổng giá trị MI của các từ được tách trong câu"],[892,"Sau đó, quần thể sẽ được sắp xếp theo giá trị của độ thích nghi giảm dần, quá trình chọn lọc cá thể sẽ chọn top N cá thể có độ thích nghi cao nhất để tạo nên quần thể tiếp tục tiến hoá ở các thế hệ sau"],[893,"Cách thức lựa chọn cá thể như sau: 1 2 m k 1 ( ) (w w ...w ) (w ) m k fit id fit MI = = =∑ 1 ( ) ( ) N i i fit pop fit id = =∑ Trong đó, id = w1w1.."],[894,"w1 là một cá thể trong quần thể pop = {id1, id2} Ví dụ: Hình 4"],[895,"7"],[896,"Quá trình chọn cá thể Có thể nói đây là quá trình quan trọng nhất trong cả tiến trình tiến hoá vì sự lựa chọn cá thể ở bước này sẽ quyết định cá thể tiến hoá có tốt hay không"],[897,"Ở quá trình chọn lọc cá thể này, chúng em đã thử nghiệm một số công thức tính độ tương hỗ (Mutual Information) như đã trình bày ở trên, và thu được các kết quả khác nhau khi sử dụng các công thức khác nhau"],[898,"Từ đó, chúng em rút ra một số kết luận và nhận xét quan trọng về ưu khuyết điểm của các công thức MI"],[899,"Kết quả thực nghiệm và nhận xét về các công thức MI sẽ được chúng em trình bày ở chương 6"],[900,""],[901,"61 4.5.2.3.5"],[902,"Độ hội tụ (convergence) Quá trình thực hiện GA cố gắng làm tăng độ thích nghi (fitness) của mỗi cá thể cũng đồng nghĩa với việc tăng chất lượng của từ được tách"],[903,"Ở mỗi thế hệ tiến hoá, chỉ số thích nghi của quần thể sẽ tăng dần đến một ngưỡng gọi là độ hội tụ α"],[904,"Khi đó, độ chênh lệnh chỉ số thích nghi của quần thể giữa hai thế hệ sẽ nhỏ dần và tiến dần đến 0"],[905,"Vì vậy, chúng em thực hiện việc ngừng GA một cách tự động khi giá trị fitness của các thế hệ đạt đến độ hội tụ có chỉ số α = 10-7 hoặc số thế hệ đạt đến số lượng mặc định đã trình bày ở trên"],[906,"Việc ngừng GA tự động sẽ giúp chúng ta giảm thiểu thời gian và chi phí tính toán không cần thiết, đồng thời là tăng tốc độ của việc tách từ"],[907,"4.6"],[908,"Kết luận Phương pháp tách từ dựa trên thống kê Internet và thuật toán di truyền tương đối đơn giản hơn các phương pháp khác và tỏ ra khá linh hoạt với sự biến động của ngôn ngữ trong tin tức điện tử"],[909,"Ngoài ra, đây là hướng tiếp cận khá mới mẻ, hạn chế được khuyết điểm cơ bản của các phương pháp tách từ lâu nay là dựa trên tập ngữ liệu đã đánh dấu và từ điển chuyên biệt"],[910,"Với ưu điểm là thuật toán đơn giản, dễ hiểu, dễ cài đặt, nhưng phương pháp IGATEC vẫn cho một kết quả tách từ chấp nhận được, có thể dùng trong phân loại văn bản"],[911,""],[912,"62 CChhưươơnngg 55 BBÀÀII TTOOÁÁNN PPHHÂÂNN LLOOẠẠII TTIINN TTỨỨCC ĐĐIIỆỆNN TTỬỬ Lý do chọn phương pháp Naïve Bayes Thuật toán Naïve Bayes Công thức xác suất đầy đủ Bayes Tính độc lập có điều kiện (Conditional Independence) Nguồn gốc Naïve Bayes Naïve Bayes trong phân loại văn bản Hai mô hình sự kiện trong phân loại văn bản bằng Naïve Bayes Bài toán phân loại tin tức điện tử tiếng Việt Kết quả"],[913,"63 Chương 5"],[914,"BÀI TOÁN PHÂN LOẠI TIN TỨC ĐIỆN TỬ Nhằm tận dụng phương pháp tách từ IGATEC đã được đề cập ở chương trên, trong chương này chúng em sẽ giới thiệu cách phân loại tin tức điện tử tự động sử dụng phương pháp Naïve Bayes và giải thích sự phù hợp của Naïve Bayes với phương pháp tách từ IGATEC"],[915,"5.1"],[916,"Lý do chọn phương pháp Naïve Bayes Như đã được giới thiệu trong chương 2, Naïve Bayes là một phương pháp rất phổ biến sử dụng xác suất có điều kiện giữa từ và chủ đề để xác định chủ đề của văn bản"],[917,"Các xác suất này dựa trên việc thống kê sự xuất hiện của từ và chủ đề trong tập huấn luyện"],[918,"Tập huấn luyện lớn có thể mang lại kết quả khả quan cho Naïve Bayes"],[919,"Internet với hơn 10 tỷ trang web là một tập huấn luyện rất phong phú về mọi chủ đề trong cuộc sống"],[920,"Hơn nữa, với số lượng chủ đề tin tức điện tử không nhiều (khoảng 20 chủ đề) thì việc sử dụng Internet như cơ sở dữ liệu huấn luyện rất phù hợp"],[921,"Trong báo chí, với mỗi chủ đề luôn có các từ chuyên môn với tần số xuất hiện rất cao, việc tận dụng tần số phụ thuộc của các từ này vào chủ đề có thể đem lại kết quả khả quan cho phân loại"],[922,"Với dữ liệu được tạo ra nhờ công cụ tách từ GA và trích xuất thông tin từ Google, theo đánh giá của chúng em, thì phương pháp Naïve Bayes là khá phù hợp vì các dữ liệu đầu vào cho hướng phân loại này hoàn toàn phù hợp với dữ liệu hiện có"],[923,"Điều này sẽ giúp chúng em tiết kiệm được rất nhiều thời gian và công sức tạo thêm nhiều tập dữ liệu nếu chọn phương pháp phân loại khác"],[924,"Mặt khác, phương pháp Naïve Bayes là phương pháp khá cổ điển được sử dụng đầu tiên bởi Maron vào năm 1961 [Maron, 1961], và sau đó rất phổ biến trong các lãnh vực tìm kiếm, lọc mail, các bộ lọc mail\u2026 nên chúng ta có thể tin tưởng về xác suất chính xác và các ưu khuyết điểm của phương pháp này để áp dụng phù hợp"],[925,"Một lý do nữa mà chúng em chọn Naïve Bayes bởi phương pháp đơn giản, tốc độ nhanh, cài đặt tương đối không quá phức tạp phù hợp với thời gian cho phép của luận văn"],[926,"Chúng em không sử dụng kNN, do tập dữ liệu thử nghiệm hiện có là tập"],[927,"64 các tin tức vắn tắt lấy ngẫu nhiên từ trang VnExpress.net còn khá nhỏ (dưới 1000)"],[928,"Trong khi đó để có thể sử dụng phương pháp kNN hiệu quả số lượng chủ đề và dữ liệu thử nghiệm phải lớn hơn nhiều"],[929,"SVM tuy là một phương pháp được cho là có hiệu suất cao, nhưng thời gian huấn luyện lại rất lâu"],[930,"Nnet lại cài đặt quá phức tạp"],[931,"Với những lý do trên, chúng em đề xuất chọn phương pháp Naïve Bayes để phân loại văn bản"],[932,"5.2"],[933,"Thuật toán Naïve Bayes Theo tác giả Mitchell (2005), thuật toán phân loại Naïve Bayes có đặc điểm nổi bật là có khả năng giảm độ phức tạp tính toán từ 2(2n \u2013 1) về còn 2n"],[934,"Thế đặc điểm nào giúp Naïve Bayes có khả năng đó"],[935,"5.2.1"],[936,"Công thức xác suất đầy đủ Bayes Giả sử ta muốn tính toán một hàm không biết giá trị đích :f X Y→ tương đương với P(Y|X)"],[937,"Đầu tiên, ta cho rằng Y là biến ngẫu nhiên có giá trị luận lý (boolean)"],[938,"X là vector gồm n thuộc tính luận lý (boolean), 1 2, ,..., nX X X X= 〈 〉 Áp dụng luật Bayes, P(Y=yi|X) được tính như sau: ( | ) ( )( | ) ( | ) ( ) k i i i k k j i j P X x Y c P Y yP Y y X x P X x Y c P Y y = = = = = = = = =∑ (2.1) Trong đó P(X|Y) và P(Y) được học từ tập huấn luyện"],[939,"Tuy nhiên để tính toán chính xác P(X|Y) thường đòi hỏi rất nhiều dữ liệu huấn luyện"],[940,"Để hiểu tại sao, chúng ta sẽ tính toán số lượng tham số cần thiết khi Y là biến boolean, X là vector gồm n thuộc tính boolean : ( | )ij i jP X x Y yθ = = = Trong i phải dựa trên 2n giá trị có thể cho những giá trị của vector X và j cần 2 giá trị"],[941,"Do đó, chúng ta cần tính toán khoảng 2n+1 tham số"],[942,"Mặc khác, ta phải đảm bảo 1 1 n ij i θ = =∑ cho bất kỳ j cố định nào"],[943,"Vì vậy, ứng với một giá trị đặc biệt yj, và 2n"],[944,"65 giá trị có thể của xi, chúng ta chỉ cần tính toán 2n -1 tham số độc lập"],[945,"Dựa trên giá trị của Y (Y là biến boolean), chúng ta cần tính tổng cộng là 2(2n -1) tham số θij"],[946,"5.2.2"],[947,"Tính độc lập có điều kiện (Conditional Independence) Định nghĩa: cho các biến ngẫu nhiên X, Y và Z, chúng ta nói rằng X là độc lập có điều kiện với Y gây ra Z, nếu và chỉ nếu xác suất phân phối chủ đạo X là độc lập với giá trị của Y gây ra Z"],[948,"Lúc đó: ( , , ) ( | , ) ( | )i j k i ki j k P X x Y y Z z P X x Z z∀ = = = = = = Ví dụ: ta xem ba biến luận lý (boolean) ngẫu nhiên trên đại diện cho các trạng thái của thời tiết là : Sấm , Mưa, và Sét"],[949,"Chúng ta đều biết rằng sự kiện Sấm xảy ra hoàn toàn độc lập với sự kiện Mưa gây ra Sét"],[950,"Bởi vì khi có Sét sẽ gây ra tiếng Sấm, nên một khi chúng ta biết rằng có Sét hay không thì ta có thể biết được giá trị của Sấm mà không cần thêm thông tin nào từ Mưa"],[951,"Trên thực tế, rõ ràng có sự phụ thuộc giữa Mưa và Sấm, tuy nhiên ta không cần thêm thông tin đó một khi ta đã có thông tin về Sét"],[952,"5.2.3"],[953,"Nguồn gốc thuật toán Naïve Bayes Thuật toán phân loại Naïve Bayes dựa trên luật Bayes, với giả định tất cả các thuộc tính X1\u2026Xn đều độc lập có điều kiện với nhau do sự kiện Y gây ra"],[954,"Chính giả thiết này đã đơn giản hóa cách tính của P(X|Y), và vấn đề ước lượng P(X|Y) từ tập ngữ liệu huấn luyện"],[955,"Chúng ta hãy xét ví dụ sau, giả sử ta có 1 2,X X X= 〈 〉 , lúc đó 1 2 1 2 2 1 2 ( | ) ( , | ) ( | , ) ( | ) ( | ) ( | ) P X Y P X X Y P X X Y P X Y P X Y P X Y = = = Kết quả của dòng thứ nhất là theo cách tính thông thường của xác suất, và dòng thứ ba là phân tích trực tiếp theo định nghĩa về độc lập có điều kiện"],[956,"Từ đó, ta tổng quát hóa lên khi X chứa n thuộc tính đều độc lập với nhau do sự kiện Y gây ra được biểu diễn như sau: 1 1 ( .."],[957,"| ) ( | ) n n i i P X X Y P X Y = =∏ (2.2)"],[958,"66 Chú ý, khi Y và Xi là biến luận lý (boolean), chúng ta chỉ cần 2n tham số để định nghĩa P(Xi=xik|Y=yj)"],[959,"Bây giờ, chúng ta hãy xét đến nguồn gốc của thuật toán Naïve Bayes"],[960,"Giả sử Y là một biến bất kỳ mang giá trị riêng biệt, và các thuộc tính Xi\u2026Xn là thuộc tính rời rạc hoặc liên tục"],[961,"Mục đích của chúng ta là huấn luyện để thuật toán phân loại trả ra sự phân phối xác suất trên các giá trị của Y đối với mỗi thể hiện X mà ta cần phân loại"],[962,"Biểu thức sau đây biểu diễn cho xác suất ứng với giá trị thứ k của Y: 1 1 1 ( ) ( .."],[963,"| )( | .."],[964,") ( ) ( .."],[965,"| ) k n k k n j n jj P Y y P X X Y yP Y y X X P Y y P X X Y y = = = = = =∑ Trong đó, tổng giá trị ở mẫu của biểu thức là tổng cho bởi tất cả các giá trị yj của Y"],[966,"Lúc này, sử dụng công thức (2.2), ta có thể viết lại công thức trên như sau: 1 ( ) ( | ) ( | .."],[967,") ( ) ( | ) k i ki k n j i jj i P Y y P X Y y P Y y X X P Y y P X Y y = = = = = = ∏ ∑ ∏ (2.3) Công thức (2.3) là công thức cơ bản của phương pháp phân loại Naïve Bayes"],[968,"Khi cho một thể hiện w 1= ...ne nX X X〈 〉 , theo công thức trên, ta sẽ tính toán được các xác suất của Y gây ra bởi Xnew bằng cách dựa vào P(Y) và p(Xi|Y) được ước lượng từ tập ngữ liệu.Nếu chúng ta chỉ quan tâm đến giá trị lớn nhất của Y, thì sử dụng công thức sau: ( ) ( | ) argmax ( ) ( | )k k i ki y j i jj i P Y y P X Y y Y P Y y P X Y y = = ← = = ∏ ∑ ∏ 5.2.4"],[969,"Phương pháp Naïve Bayes trong phân loại văn bản 5.2.4.1"],[970,"Công thức xác suất đầy đủ Bayes Phương pháp Naïve Bayes tìm chủ đề của văn bản d bằng các xác định chủ đề có xác suất P( | )iY c X d= = , xác suất để văn bản d nằm trong lớp ic , lớn nhất thông qua việc sử dụng công thức xác suất đầy đủ Bayes : ( | ) ( )( | ) ( | ) ( ) i i i j j j P X d Y c P Y cP Y c X d P X d Y c P Y c = = = = = = = = =∑ (2.7)"],[971,"67 Trong đó jc là chủ đề thứ j 1 2( , ,..., )nd w w w= là văn bản cần phân loại"],[972,"P(Y=ci | X=d) gọi là xác suất xảy ra văn bản d thuộc về chủ đề ci"],[973,"P(X=d | Y=ci) gọi là xác suất chủ đề ci có chứa văn bản d trong tập huấn luyện"],[974,"Một cách để xác định ( | )P Y X là sử dụng tập huấn luyện để ước lượng ( | )P X Y và ( )P Y"],[975,"Sau đó sử dụng công thức xác suất đầy đủ trên để xác định ( | )iP Y c X d= = với d bất kỳ"],[976,"5.2.4.2"],[977,"Uớc lượng P(X|Y) Giả sử với mỗi chủ đề, ta có biến cố các từ phụ thuộc vào chủ đề là độc lập có điều kiện (conditional independence) với nhau"],[978,"Ta có công thức của biểu diễn sự độc lập có điều kiện của 2 biến cố X,Z vào Y được trình bày ở 5.2.2 như sau : ( | , ) ( | )P X Y Z P X Z= Sử dụng giả định trên ta tính được ( | )iP X d Y c= = : 1 2 1 2 1 ( | ) ( , ,.., | ) ( | ) ( | ).."],[979,"( | ) ( | ) i n i i i n i n j j P X d Y c P w w w Y c P w Y c P w Y c P w Y c P w Y ci = = = = = = = = = = =∏ (2.8) Từ (2.8), (2.7) được viết lại như sau : 1 2 ( ) ( | ) ( | , ,..., ) ( ) ( | ) i k ik i n j k jj k P Y c P w Y c P Y c w w w P Y c P w Y c = = = = = = ∏ ∑ ∏ (2.9) Nhờ thống kê trên tập huấn luyện D, ( | )P X Y có thể được ước lượng theo : { } { } # ( | ) # j i j i i D X w Y c P X w Y c D Y c = ∧ = = = = (2.10)"],[980,"68 Trong đó { }# j iD X w Y c= ∧ = : số văn bản trong tập huấn luyện chứa đồng thời wj và ci { }# iD Y c= : số văn bản trong tập huấn luyện chứa ci Công thức ước lượng trên sẽ cho kết quả ( | ) 0j iP X w Y c= = = khi không có văn bản chứa đồng thời cả hai (wj và ci)"],[981,"Nhằm tránh trường hợp này, ta nên sử dụng phép ước lượng đã được làm mịn sau : { } { } # ( | ) # j i j i i D X w Y c l P X w Y c D Y c lR = ∧ = + = = = + (2.11) Với R : số lượng chủ đề l : quyết định độ mịn của phép ước lượng 5.2.4.3"],[982,"Ước lượng P(Y) Việc ước lượng P(Y=ci) đơn giản là tính phần trăm số văn bản trong tập huấn luyện có chủ đề ci : { }#( ) ii D Y c P Y c D = = = (2.12) 5.2.5"],[983,"Hai mô hình sự kiện trong phân loại văn bản bằng phương pháp Naïve Bayes 5.2.5.1"],[984,"Giới thiệu Phân loại văn bản là một lĩnh vực có phạm vi thuộc tính (attribute) rất nhiều bởi vì thuộc tính của những văn bản cần phân loại là từ (word), mà số lượng từ khác nhau thì vô cùng lớn"],[985,"Và thuật toán Naïve Bayes đã thành công trong việc ứng dụng vào lĩnh vực phân loại với khả năng làm giảm độ phức tạp trên"],[986,"Mặc dù đây là thuật toán khá phổ biến, nhưng trong cộng đồng phân loại văn bản vẫn có một vài điều lẫn lộn về phương pháp phân loại Naïve Bayes bởi vì có hai mô hình phát sinh khác nhau vẫn thường được sử dụng"],[987,"Cả hai mô hình đều sử dụng \u201cnaïve Bayes assumption\u201d và cả hai đều được giới phân loại gọi là \u201cnaïve Bayes\u201d"],[988,""],[989,"69 5.2.5.2"],[990,"Mô hình đa biến trạng Bernoulli (Multi-variate Bernoulli Model) Một mô hình biểu diễn một văn bản là một vector có thuộc tính nhị phân cho biết rằng từ nào có hay không xuất hiện trong văn bản"],[991,"Số lần xuất hiện của một từ trong văn bản là không cần thiết"],[992,"Ở đây chúng ta có thể hiểu rằng văn bản là sự kiện (event) và sự có mặt hay vắng mặt của các từ trở thành thuộc tính của sợ kiện"],[993,"Đấy chính là mô hình sự kiện đa biến trạng Bernoulli (multi-variate Bernoulli event model), một mô hình khá truyền thống, đã được nhiều người sử dụng trong phân loại văn bản"],[994,"Theo McCallum & Nigam (1998), một số công trình tiêu biểu về hướng tiếp cận này là Robertson & Sparck-Jones (1976), Lewis(1992), Kalt & Croft (1996), Larkey & Croft (1996), Koller & Sahami (1997), Sahami (1996)"],[995,"5.2.5.3"],[996,"Mô hình đa thức (Multinomial Model) Mô hình thứ hai cho rằng một văn bản đại diện tập hợp tần số xuất hiện của từ trong văn bản"],[997,"Do đó, thứ tự xuất hiện của từ được bỏ qua nhưng tần số xuất hiện được giữ lại"],[998,"Ở đây, chúng ta có thể hiểu rằng những tần số xuất hiện của các từ là những sự kiện (events) và văn bản trở thành tập hợp các sự kiện của từ (word events)"],[999,"Chúng ta gọi đây là sự kiện mô hinh đa thức (Multinomial event model)"],[1000,"Đây là hướng tiếp cận thông thường trong mô hình ngôn ngữ học thống kê"],[1001,"Hướng tiếp cận này cũng được rất nhiều người sử dụng mà theo McCallum & Nigam (1998) các công trình tiêu biểu như Lewis & Gale (1994), Kalt & Croft (1996), Joachims (1997), Mitchell (1997), McCallum et al (1998)\u2026 5.2.5.4"],[1002,"Nhận xét Đối với phương pháp multi-variate model, việc không nắm bắt thông tin tần số xuất hiện của từ có thể đưa đến khuyết điểm không phân biệt được văn bản ưu tiên cho chủ đề nào hơn nếu cả 2 văn bản đều xuất hiện cùng một từ nào đó nhưng tần số lại khác nhau rất nhiều"],[1003,"Ví dụ, nếu từ \u201cthể thao\u201d sẽ xuất hiện nhiều trong các tin tức về thể thao, và sẽ ít xuất hiện trong các tin tức có nội dung khác, nhưng do phương pháp multi-variate không sử dụng thông tin tần số nên không phân biệt được văn bản ưu tiên cho thể thao hơn"],[1004,"Trong khi đó, hướng tiếp cận multinomial model rõ ràng đã sử dụng thông tin về xác suất phân phối từ trong văn bản"],[1005,""],[1006,"70 Đối với phương pháp mulnomial, do sử dụng tần số xuất hiện của từ nên sẽ phụ thuộc vào chiều dài văn bản, vì tài liệu càng dài, sự xuất hiện của các từ càng nhiều"],[1007,"Theo kết quả đạt được của thí nghiệm so sánh giữa hai phương pháp Naïve Bayes trên, McCallum & Nigam (1998) đã đưa ra kết quả là hướng tiếp cận đa biến trạng thực hiện tốt với kích thước từ vựng nhỏ (<500 từ), còn phương pháp mô hình đa thức thường cho kết quả tốt hơn đối với kích thước từ vựng lớn (>500 từ)"],[1008,"5.3"],[1009,"Bài toán phân loại tin tức điện tử tiếng Việt 5.3.1"],[1010,"Quy ước Với mỗi văn bản d , sau khi sử dụng GA để loại bỏ dấu câu và stopword, ta thu được d được tách thành nhiều ngữ g dưới dạng sau d={g1,g2,\u2026, gm} , với gi là tập hợp gồm n cách tách của một ngữ, gi = {ti1,ti2,\u2026,tin} trong đó tij là một cách tách ngữ., tij = {w1,w2,\u2026,wp}"],[1011,"Ví dụ: Hình 5"],[1012,"1"],[1013,"Minh họa quy ước cho văn bản Việc phân loại sẽ gán một chủ đề ch ∈ C={c1,c2,\u2026,cq} cho văn bản, mỗi chủ đề lại bao gồm nhiều từ khóa (keyword) K={k1,\u2026,kr}"],[1014,"Cây phân cấp chủ đề và từ khóa thể hiện như sau : Hình 5"],[1015,"2.Minh họa chủ đề \u201cXã hội\u201d"],[1016,"71 Trong phần này chúng em sẽ trình bày các phương pháp tính toán được sử dụng trong phân loại bao gồm: công thức được dùng trong IGATEC [H.Nguyen et al, 2005]và công thức Naïve Bayes [Mitchell, 2005]"],[1017,"5.3.2"],[1018,"Công thức phân loại văn bản trong IGATEC [H"],[1019,"Nguyen et al, 2005] Công thức phân loại văn bản trong IGATEC [H.Nguyen et al, 2005] do chính tác giả đề nghị theo cách sử dụng độ phụ thuộc của văn bản vào chủ đề"],[1020,"Độ phụ thuộc này được tính dựa vào xác suất đồng xuất hiện của các từ trong văn bản với một từ khóa nhất định"],[1021,"Chi tiết cách tính này như sau : Cho trước một từ khóa k , độ phụ thuộc của từ w vào k được tính như sau: ( & )( | ) ( ) p k wp k w p w = Trong đó p(w) là xác suất xuất hiện của từ w trên Google được tính theo công thức ( )( )= count wp w MAX (đã trình bày ở mục 4.5.1.2) p( k & w ) là xác suất xuất hiện đồng thời của chủ đề k và từ wi trên Google với: ( & )( & ) count k wp k w MAX = (đã trình bày ở mục 4.5.1.2.) Tiếp theo, độ liên quan (relative) của một cách tách ngữ t với từ khóa k bằng tổng xác suất của tất cả các từ w xuất hiện đồng thời với từ khóa k như sau: 1 ( , ) ( | ) p i i rel t k p k w = =∑ Độ hỗ trợ (support) của cách tách ngữ t trên vào chủ đề c={k1,k2,\u2026,ks} là : 1 1( , ) ( , ) s i i SP t c rel t k s = = ∑ Theo công thức trên, tác giả cho rằng văn bản có độ hỗ trợ vào một chủ đề càng cao thì khả năng văn bản đó thuộc về chủ đề này càng lớn"],[1022,"Dựa vào các công thức, độ phụ thuộc của câu được xác định theo công thức: 1 1 1 1( , ) ( , ) ( , ) m m n i ij i i j SP d c SP g c SP t c n= = = = =∑ ∑ ∑"],[1023,"72 Theo các công thức trên, văn bản d sẽ thuộc về chủ đề có SP(d,c) lớn nhất"],[1024,"5.3.3"],[1025,"Công thức Naïve Bayes trong bài toán phân loại tin tức điện tử tiếng Việt sử dụng thống kê từ Google Ở mục 5.2, chúng em đã trình bày các công thức Naïve Bayes cơ bản dùng thông tin xác suất học được từ tập dữ liệu huấn luyện"],[1026,"Tuy nhiên, hướng tiếp cận của chúng em không sử dụng tập ngữ liệu mà sử dụng thông tin thống kê từ Google nên các công thức trên được chúng em cải tiến cho phù hợp"],[1027,"5.3.3.1"],[1028,"Ước lượng P(X|Y) Với công thức (2.11) được trình bày ở mục 5.2"],[1029,"như sau: { } { } # ( | ) # j i j i i D X w Y c P X w Y c D Y c = ∧ = = = = nếu sử dụng cho tập ngữ liệu có sẵn, công thức có ý nghĩa là xác suất chủ đề ci chứa văn văn bản có wj bằng số văn bản có chứa wj thuộc ci trên tổng số văn bản thuộc chủ đề ci"],[1030,"Tuy nhiên, trong hướng tiếp cận dựa trên Google, chúng ta không thể xác định được số lượng văn bản thực sự thuộc chủ đề ci"],[1031,"Do đó, chúng em đề xuất cách tính xác suất khác phù hợp với hướng tiếp cận dựa trên thống kê Google: { } { } # ( & ) 1 ( | ) # ( & ) | | j i j i j i i j kk D X w Y c p w c P X w Y c D Y c p w c Y = ∧ = + = = = = +∑ (4.1) Trong đó: p(wj & ci ) là xác suất xuất hiện đồng thời wj và ci"],[1032,"k số thứ tự của các chủ đề, {1,...,| |}k Y∈ Công thức trên cho kết quả dựa trên xác suất xuất hiện đồng thời wj và ci trên tổng số lần xuất hiện số lần xuất hiện wj trong tất cả các chủ đề"],[1033,"5.3.3.2"],[1034,"Ước lượng P(Y) Với công thức (2.12) được trình bày ở mục 5.2 là: { }#( ) ii D Y c P Y c D = = = (4.2)"],[1035,"73 Ở công thức này, ta giả sử các trang web chứa từ khóa ci đều thuộc chủ đề ci"],[1036,"Lúc đó, P(Y=ci) bằng xác suất xuất hiện ci trên tổng số trang web chứa tất cả các chủ đề: { }# ( )( ) ( ) i i i jj D Y c p cP Y c D p c = = = = ∑ Trong đó p(ci) : tần số xuất hiện của chủ đề ci trên Google j : là chỉ số của các chủ đề cần phân loại 5.3.3.3"],[1037,"Ước lượng P(Y|X) Khi đó công thức Naïve Bayes cho phân loại văn bản (2.9) sẽ có dạng : 1 2 ( ) ( & ) ( | , ,..., ) ( ) ( & ) i k ik i n j k jj k p c p w c P Y c w w w p c p w c = = ∏ ∑ ∏ (4.3) Vì tần số xuất hiện p(w) (mục 4.5.1) của từ trên Google rất nhỏ nên việc tính xác suất 1 2( | , ,..., )i nP Y c w w w= theo công thức (4.3) có thể dẫn đến việc tràn số do nhân các số thực gần với 0"],[1038,"Chúng em khắc phục vấn đề này bằng cách chuyển công thức (4.3) sang sử dụng log : ( ) ( ) ( ) ( ) ( ) ( )( ) 1 2 log ( ) ( & ) ( | , ,..., ) log ( ) ( & ) log ( ) log ( & ) log ( ) log ( & ) i k ik i n j k jj k i k ik j k jj k p c p w c P Y c w w w p c p w c p c p w c p c p w c \u2032 = = − + = − + ∏ ∑ ∏ ∑ ∑ ∑ Văn bản d sẽ được phân loại vào chủ đề ci có giá trị 1 2( | , ,..., )i nP Y c w w w\u2032 = cao nhất"],[1039,""],[1040,"74 5.4"],[1041,"Kết luận Các phương pháp phân loại văn bản dựa trên công thức của IGATEC và phương pháp Naïve đều tương đối đơn giản, không bị hạn chế về tập huấn luyện như khi sử dụng các phương pháp khác"],[1042,"Ngoài ra, các phương pháp trên cũng không gặp trường hợp sai lạc do có sự thay đổi trong tập huấn luyện bởi tính linh hoạt đối với sự thay đổi nhờ dùng thông tin thống kê từ Google"],[1043,"Các kết quả trên thu nhận được thông qua việc chạy hệ thống thử nghiệm phân loại ViKass sẽ được mô tả chi tiết trong chương tiếp theo"],[1044,""],[1045,"75 CChhưươơnngg 66 HHỆỆ TTHHỐỐNNGG TTHHỬỬ NNGGHHIIỆỆMM PPHHÂÂNN LLOOẠẠII VVĂĂNN BBẢẢNN Giới thiệu hệ thống thử nghiệm Vikass Thử nghiệm các cách trích xuất thông tin Dữ liệu thử nghiệm Thử nghiệm các công thức tính độ tương hỗ MI Thử nghiệm phân loại tin tức điện tử"],[1046,"76 Chương 6"],[1047,"HỆ THỐNG THỬ NGHIỆM PHÂN LOẠI VĂN BẢN 6.1"],[1048,"Giới thiệu hệ thống thử nghiệm Vikass 6.1.1"],[1049,"Chức năng hệ thống Vikass Hệ thống thử nghiệm phân loại văn bản Vikass được xây dựng nhằm mục đích kiểm nghiệm phương pháp tách từ IGATEC và các phương pháp phân loại đề cập ở chương trước nhằm tìm ra được các tham số tối ưu trước khi tích hợp vào toà soạn báo điện tử"],[1050,"Các tham số này bao gồm các tham số chạy thuật toán di truyền như số lượng cá thể ban đầu, số thế hệ tối ưu, tỉ lệ lai ghép, tỉ lệ đột biến; cách tính MI hiệu quả và phương pháp phân loại nào cho kết quả tốt hơn"],[1051,"Ngoài tích hợp mô-đun trích tần số xuất hiện từ Google, hệ thống còn cung cấp các tính năng khác như trích tin tức, chỉnh sửa từ khóa"],[1052,"Chức năng của hệ thống sẽ được mô tả chi tiết trong các phần tiếp theo"],[1053,"6.1.2"],[1054,"Tổ chức và xử lý dữ liệu 6.1.2.1"],[1055,"Giới thiệu chung Hướng tiếp cận của luận văn dựa trên thống kê từ Google, điều đó có nghĩa là mỗi lần cần lấy tần số xuất hiện của một từ mới, hệ thống phải thực hiện lấy thông tin từ Internet"],[1056,"Điều này làm tiêu tốn rất nhiều thời gian chờ đợi, do vậy mỗi khi lấy được thông tin từ Google, chúng em lưu lại vào một file dữ liệu đệm để có thể sử dụng lại mỗi khi cần đến"],[1057,"Với mục đích làm tăng tốc độ xử lý của chương trình thử nghiệm, việc quản lý dữ liệu hoàn toàn được thực hiện trên file văn bản thông thường trên kiểu phông phổ biến của tiếng Việt là phông Unicode UTF8"],[1058,"Hệ thống thử nghiệm cần hai loại thông tin như sau: Đối với thử nghiệm tách từ tiếng Việt, hệ thống cần thông tin về xác suất xuất hiện của các từ trên Google"],[1059,"Đối với việc thử nghiệm phân loại văn bản, hệ thống cần thông tin về xác suất xuất hiện đồng thời của từ và từ khoá tương ứng với chủ đề"],[1060,""],[1061,"77 6.1.2.2"],[1062,"Tổ chức dữ liệu Từ những yêu cầu trên, hệ thống dữ liệu được thiết kế thành ba file có nội dung như sau: Hình 6"],[1063,"1"],[1064,"Tổ chức file dữ liệu File CACHE: là dạng file văn bản thông thường, chứa thông tin: Từ: từ đã tìm từ Google Xác suất: xác suất của từ đó trên Google Loại từ: mang một trong các giá trị W(là từ), NW (không là từ), WC ( có thể là từ), NWC (không thể là từ), UD (chưa phân loại)"],[1065,"File KEYWORD: File được viết dưới dạng xml bao gồm thông tin về tên chủ đề các cấp: Tên chủ đề: tên của chủ đề các cấp (cấp 1 và cấp 2) Chỉ số: chỉ số của mỗi chủ đề cho biết vị trí của chủ đề trong danh sách xác suất của từ với từng chủ đề trong file Relevant"],[1066,"Chọn dạng xml để lưu tên chủ đề vì tính chất lồng nhau ở từng cấp của chủ đề rất thích hợp với cấu trúc dạng cây của tài liệu xml"],[1067,"Ví dụ, ta có các chủ đề cấp 1 là \u201cthể thao\u201d và các chủ đề cấp 2 của nó là \u201cBóng đá\u201d, \u201cQuần vợt\u201d như hình vẽ dưới đây\u201d Hình 6"],[1068,"2"],[1069,"Chủ đề Thể thao Lúc đó, nội dung file chủ đề sẽ có nội dung như sau:"],[1070,"78 File RELEVANT: chứa thông tin: Từ: từ đã tìm Danh sách xác suất của từ với từng chủ đề: xác suất xuất hiện đồng thời của từ ứng với từng chủ đề theo chỉ số được lưu trong file KEYWORD"],[1071,"Sau khi thực hiện thử nghiệm, dung lượng file CACHE đã lên đến gần 10M và file RELEVANT xấp xỉ 50M"],[1072,"Với khối lượng dữ liệu lớn như vậy, việc sử dụng một hệ quản trị cơ sở dữ liệu là không cần thiết bởi vì việc xử lý thông tin trong hệ thống là đơn giản và yêu cầu tiên quyết của chương trình là tốc độ xử lý cao"],[1073,"Như vậy, chọn lựa lưu trữ thông tin dưới dạng văn bản bình thường là phù hợp với yêu cầu hệ thống"],[1074,"6.1.2.3"],[1075,"Xử lý dữ liệu Khi bắt đầu hoạt động, hệ thống tự động thực hiện đọc các file dữ liệu, phân tích chuỗi trong file để lấy thông tin và đưa vào bộ nhớ dưới dạng \u201cbảng băm\u201d (hashtable)"],[1076,"Hệ thống thử nghiệm được phát triển nên ngôn ngữ C#, là một ngôn ngữ khá mạnh hỗ trợ nhiều cấu trúc lưu trữ thông tin trong đó có hỗ trợ bảng băm"],[1077,"Nhờ vậy mà việc tổ chức dữ liệu trở nên đơn giản hơn rất nhiều"],[1078,"Ngoài ra, cách xử lý như vậy sẽ làm tăng tốc độ tìm kiếm thông tin của từ nhờ các ưu điểm tổ chức dữ liệu của bảng băm"],[1079,"<?xml version=\"1.0\" encoding=\"utf-8\" ?> <keyword> <topic name=\"thể thao\" value=\"1\"> <topic name=\"bóng đá\" value=\"2\" /> <topic name=\"quần vợt\" value=\"3\" /> <\/topic> <\/keyword>"],[1080,"79 6.1.3"],[1081,"Một số màn hình của hệ thống Vikass Hình 6"],[1082,"3"],[1083,"Màn hình tách từ và phân loại STT Mô tả 1 Chọn thư mục chứa các tập tin cần tách từ và phân loại 2 Chọn thư mục lưu kết quả 3 Liệt kê tên các tập tin được chọn tách từ và phân loại 4 Di chuyển các tập tin qua lại để chọn các tập tin thực hiện tách từ 5 Liệt kê tên tất cả các tập tin có trong thư mục (1) 6 Thực hiện tách từ và phân loại 7 Dừng tách thực thi 8 Xem tập tin kết quả phân loại 9 Tab tùy chọn các thông số chạy GA 10 Tab tùy chọn các thông số như loại MI sử dụng, có sử dụng stopword hay không"],[1084,"11 Tab chọn các từ khóa sẽ sử dụng cho việc phân loại Bảng 6"],[1085,"1"],[1086,"Mô tả một số control của màn hình tách từ"],[1087,"80 Màn hình môđun trích xuất từ Google: Hình 6"],[1088,"4"],[1089,"Màn hình trích xuất từ Google STT Mô tả 1 Chọn thư mục chứa các tập tin như tập tin đệm, tập tin chứa độ liên quan của từ và từ khóa,\u2026 2 Các tùy chọn như chỉ tìm kiếm các từ có tần số 0, chỉ tìm các trang .vn, tìm kiếm độ liên quan của từ và từ khóa\u2026 3 Các phương pháp tải về sử dụng 4 Thanh biểu thị tiến trình tìm kiếm và trích từ 5 Thực hiện tìm kiếm và trích xuất 6 Lưu lại tập tin đệm và tập tin chứa độ liên quan 7 Dừng việc tìm kiếm 8 Danh sách các từ đã được tìm kiếm Bảng 6.2"],[1090,"Mô tả một số control của màn hình trích từ Google"],[1091,"81 Màn hình phân loại tin tức điện tử hỗ trợ toà soạn báo điện tử : Hình 6"],[1092,"5"],[1093,"Màn hình phân loại tin tức điện tử STT Mô tả 1 Thiết lập các tham số kết nối đến SQL server 2 Lấy các tin tức được toà soạn báo điện tử tải về 3 Thực hiện phân loại 4 Cập nhật các tin tức đã được phân loại vào SQL server 5 Thực hiện tất cả các bước (2),(3),(4) 6 Hiển thị các thông tin như : nội dung tin, tên của chủ đề được phân loại,\u2026 Bảng 6.3"],[1094,"Bảng mô tả một số control của màn hình phân loại tin tức điện tử"],[1095,"82 6.2"],[1096,"Thử nghiệm các cách trích xuất thông tin Việc trích xuất thông tin về tần số xuất hiện của từ, độ liên quan giữa từ và chủ đề được thực hiện thông qua module Google Extractor"],[1097,"Nhằm mục đích tăng tốc trích thông tin từ Google, chúng em đã thử nghiệm trích thông tin bằng nhiều cách khác nhau và thực hiện kết nối đến Google sử dụng nhiều luồng (>=15)"],[1098,"Bên cạnh đó, để tránh việc phải thực hiện tìm kiếm nhiều lần, các tập tin đệm được sử dụng với mục đích lưu lại hay cập nhất kết quả các lần tìm kiếm trước"],[1099,"6.2.1"],[1100,"Các phương pháp thử nghiệm Chúng em sử dụng 3 cách khác nhau để lấy kết quả tìm kiếm bao gồm sử dụng dịch vụ web do Google cung cấp, tải trang kết quả về máy cục bộ sau đó sử dụng XPath hay tìm kiếm chuỗi"],[1101,"6.2.1.1"],[1102,"Google web service Dịch vụ web là một ứng dụng cung cấp giao diện lập trình, hỗ trợ sự truyền thông từ ứng dụng này đến ứng dụng khác qua mạng dùng XML"],[1103,"Dịch vụ web của Google tại địa chỉ http://api.google.com/GoogleSearch.wsdl là một phương pháp tiện lợi để khai thác công cụ tìm kiếm này"],[1104,"Tuy nhiên, ta phải đăng kí tài khoản trước khi sử dụng"],[1105,"Với mỗi tài khoản Google giới hạn số lượng truy vấn là 1000 truy vấn/ngày"],[1106,"Các tham số cần biết khi sử dụng dịch vụ : Tham số tìm kiếm q Câu truy vấn n Số kết quả trả về trên từng trang lr Giới hạn phạm vi ngôn ngữ tìm kiếm ie Bảng mã câu truy vấn sử dụng oe Bảng mã của kết quả trả về Bảng 6"],[1107,"4"],[1108,"Tham số sử dụng dịch vụ Google Một số câu truy vấn đặc biệt trên Google :"],[1109,"83 Truy vấn đặc biệt Câu truy vấn Ý nghĩa Loại bỏ một từ bass \u2013music \u201c-\u201d để loại bỏ 1 từ ra khỏi kết quả tìm kiếm Từ khóa OR vacation london OR paris OR Giới hạn site Admission site:www.stanford.edu site: chỉ tìm kiếm trong site được chỉ định Giới hạn ngày Star Wars daterange:2452122- 2452234 daterange: chỉ trả về các file có nhãn thời gian thõa điều kiện Lọc file Google filetype:doc OR filetype:pdf filetype: chỉ tìm kiếm các file có kiểu mở rộng được liệt kê Loại trừ file Google doc -filetype: -filetype:pdf -filetype: ngược lại với filetype: Tìm theo tiêu đề intitle:Google search intitle: chỉ tìm kiếm tiêu đề web Bảng 6"],[1110,"5"],[1111,"Một số câu truy vấn đặc biệt của Google Trong quá trình thử nghiệm sử dụng dịch vụ web của Google, chúng em nhận thấy thời gian đáp ứng không được nhanh (khoảng >5s cho một truy vấn-sử dụng mạng Internet của trường) hơn nữa còn tồn tại nhiều lỗi"],[1112,"Lý do có thể kể đến như phiên bản dịch vụ đang trong quá trình thử nghiệm (bản β), hạn chế do dung lượng mạng, chi phí chứng thực"],[1113,"Giới hạn 1000truy vấn/ngày cũng ảnh hưởng đến chương trình khi phải thực hiện trích xuất trên lượng lớn các từ"],[1114,"Để khắc phục vấn đề này, chúng em sử dụng biện pháp tải trang kết quả về"],[1115,"6.2.1.2"],[1116,"Xpath và tìm kiếm chuỗi Trang kết quả trả về sẽ được chuyển sang định dạng xHTML dùng cho việc trích xuất dùng Xpath (http://www.w3.org/TR/XPath20) hay thực hiện tìm kiếm trên chuỗi"],[1117,"Cả hai phương pháp này đều cho hiệu suất tốt (khoảng 1-3s/truy vấn)"],[1118,"Xpath là định dạng được W3C đề nghị được sử dụng rộng rãi trong việc truy vấn tập tin XML"],[1119,"Sử dụng Xpath có thuận lợi hơn tìm kiếm chuỗi ở chỗ có thể sử dụng trích xuất trên nhiều ngôn ngữ trả về từ Google và nếu cấu trúc của trang web thay"],[1120,"84 đổi thì ta vẫn lấy được thông tin trả về của Google"],[1121,"Trong khi đó việc tìm kiếm chuỗi sẽ phụ thuộc vào các câu đặc biệt (như \u201ccác kết quả \u201d.."],[1122,")"],[1123,"Do đó, nếu các trang trả về của Google trình bày khác đi, cách tìm kiếm chuỗi sẽ không cho kết quả mong muốn"],[1124,"Tuy nhiên, sử dụng cách tìm kiếm chuỗi sẽ cho kết quả nhanh hơn dùng Xpath vì hệ thống không phải tốn một thời gian phân tích dữ liệu thành dạng tài liệu XML"],[1125,"6.2.2"],[1126,"Nhận xét Hiện tại, điều chúng ta quan tâm hàng đầu là tốc độ trích thông tin từ Google"],[1127,"Mặt khác, trang web Google có cấu trúc khả ổn định, hầu như không thay đổi"],[1128,"Vì vậy khi thực hiện thử nghiệm, chúng em sử dụng cách thức tìm kiếm chuỗi để đạt tối độ cao nhất"],[1129,"Tuy nhiên, chúng em vẫn xây dựng các lựa chọn rút trích để tạo tính linh hoạt trong thử nghiệm"],[1130,"6.3"],[1131,"Dữ liệu thử nghiệm 6.3.1"],[1132,"Nguồn dữ liệu Dữ liệu thử nghiệm được lấy từ trang tin tức VnExpress.net (www.vnexpress.net) tại thời điểm tháng 6/2005"],[1133,"Đây là một trong những trang tin tức điện tử đầu tiên tại Việt Nam ra đời vào ngày 26/2/2001, đến nay đã hơn bốn năm hoạt động với lượng độc giả đông đảo trong cả nước và quốc tế"],[1134,"Ngoài các trang mục do phóng viên của tờ báo viết, VnExpress.net còn mở rộng đón nhận các bài viết do độc giả gửi về từ khắp nơi để làm phong phú thêm cho nội dung của tờ báo và cập nhật tin tức thường xuyên nhanh chóng"],[1135,"6.3.2"],[1136,"Số lượng dữ liệu thử nghiệm Từ các mục của VnExpress.net, đầu tiên chúng em chọn lọc ra một số mục chính để lấy dữ liệu thử nghiệm"],[1137,"Vì chúng em quy định từ khóa cho chủ đề chính là tên chủ đề đó nên trong quá trình thử nghiệm, chúng em phát hiện ra một số trường hợp nhập nhằng"],[1138,""],[1139,"85 Đầu tiên, từ khóa Thế giới, Xã hội có ý nghĩa bao quát có thể về Kinh tế thế giới, chính trị thế giới, văn hóa xã hội\u2026, nên khả năng các tin tức được phân loại vào chủ đề này là rất cao do tần số xuất hiện của chủ đề này với các từ phổ biến lớn"],[1140,"Thứ hai, một số mục có tên không đồng nhất giữa các tờ báo điện tử như trang VnExpress.net dùng Vi tính trong khi đó TuoiTre.com.vn lại dùng Nhịp sống số, Vnn.vn dùng Công nghệ thông tin và Viễn thông..."],[1141,"Việc này làm giảm kết quả khi sử dụng từ khóa khóa Vi tính cho chủ đề này vì từ khóa này không bao quát được cho các trang sử dụng tên chủ đề khác mặc dù cùng trình bày một nội dung"],[1142,"Do vậy, chúng em chỉ sử dụng một số mục có từ khóa rõ ràng"],[1143,"Đối với mỗi tin tức, chúng em chỉ tách lấy phần tiêu đề, phần tóm lược và phần chú thích ảnh"],[1144,"Đây là các phần có ý nghĩa phân loại cao do được người viết bài tóm lược và chọn lọc"],[1145,"Ứng mỗi chủ đề, chúng em lấy ngẫu nhiên 100 tin"],[1146,"Còn cách giải quyết phần nhập nhằng trình bày ở trên sẽ là hướng mở rộng của luận văn"],[1147,"Tổng dữ liệu thử nghiệm là 1500 tập tin bao gồm 15 chủ đề cấp 2, mỗi chủ đề 100 tập tin"],[1148,""],[1149,"86 Hình 6"],[1150,"6"],[1151,"Cây chủ đề 6.3.3"],[1152,"Nhận xét Mặc dù dữ liệu dùng thử nghiệm khá nhỏ do hạn chế về mặt thời gian, nhưng cách thức chọn dữ liệu và chủ đề thử nghiệm phân loại của chúng em đã mở rộng rất nhiều so với 35 văn bản thử nghiệm của [H"],[1153,"Nguyen et al, 2005] trên 5 chủ đề Chính trị, Giáo dục, Kinh doanh, Sức khỏe, Thể thao"],[1154,""],[1155,"87 6.4"],[1156,"Thử nghiệm các công thức tính độ tương hỗ MI 6.4.1"],[1157,"Các phương pháp thử nghiệm Nhằm xác định hiệu quả của các cách tính MI trong việc tách từ tiếng Việt, chúng em thực hiện thử nghiệm 3 công thức MI đã được trình bày ở mục 4.5: một công thức tính MI của [H.Nguyen et al, 2005] (gọi là MI1) , một của [Ong & Chen, 1999] (gọi là MI2), một do chúng em đề nghị (gọi là MI3)"],[1158,"Ứng với mỗi công thức tính MI trên, chúng em thử nghiệm thêm việc tách stopword và không tách stopword trước khi tách từ"],[1159,"Mục đích của việc tách stopword trước khi tách từ nhằm tạo ra nhiều ngữ nhỏ hơn khi đã bỏ các từ không có ý nghĩa, để làm tăng tốc độ tách từ của hệ thống"],[1160,"Như vậy, tổng cộng có 6 thử nghiệm tách từ như sau: MI1 tách stop word (MI1_NonSW) MI1 không tách stop word (MI1_SW) MI2 tách stop word (MI2_NonSW) MI2 không tách stop word (MI2_NonSW) MI3 tách stop word (MI3_NonSW) MI3 không tách stop word (MI3_NonSW) Chúng em thử nghiệm các công thức trên 1500 nội dung tóm tắt các tin tức của VnExpress.net 6.4.2"],[1161,"Kết quả Độ chính xác của các công thức tính độ tương hỗ như sau: Cách tính MI Không tách stop word Có tách stopword MI 1 [H"],[1162,"Nguyen et al, 2005] 74% 72% MI 2 [Ong & Chen, 1999] 60% 55% MI 3 (chúng em đề nghị) 72% 69% Bảng 6"],[1163,"6"],[1164,"Kết quả thực nghiệm các công thức tính độ tương hỗ MI"],[1165,"88 0% 10% 20% 30% 40% 50% 60% 70% 80% MI1 MI2 MI3 Loại MI Độ c hí nh x ác Non SW SW Hình 6"],[1166,"7"],[1167,"Biểu đồ so sánh kết quả các công thức tính độ tương hỗ MI 6.4.3"],[1168,"Nhận xét Trong 6 cách thử nghiệm, cách tách từ dùng công thức MI1"],[1169,"có độ chính xác cao nhất"],[1170,"Thời gian chạy tách từ lúc đầu khá lâu (trung bình khoảng 10 phút cho một mẫu tóm tắt dài khoảng 100 tiếng) đa phần là do thời gian lấy thông tin từ Google"],[1171,"Nhưng khi thông tin về tần số xuất hiện của các từ đã được lưu lại tương đối lớn (độ lớn file cache khoảng 10M), thì tốc độ tách từ giảm xuống đáng kể (trung bình <1giây đối với các văn bản không cần lấy thông tin từ Internet) Cách tiếp cận của công thức MI1 là ưu tiên dựa trên từ ghép có hai tiếng, mà theo thống kê dựa trên từ điển của chúng em, số từ 2 tiếng chiếm đa số trong từ vựng tiếng Việt"],[1172,"Cách tính này cho kết quả khá tốt vì vừa thoả mãn được tính chất tự nhiên dựa trên ưu thế áp đảo của từ 2 tiếng, vừa được chứng minh bằng thực nghiệm"],[1173,"Trong các trường hợp thử nghiệm có tách stopword, thời gian tách từ giảm đi rất nhiều (trung bình 5 phút cho văn bản mới)"],[1174,"Tuy nhiên, trong quá trình thử nghiệm, chúng em nhận thấy việc tách stopword có thể làm sai lạc ý nghĩa của văn bản ban"],[1175,"89 đầu do danh sách stopword đưa vào không hoàn chỉnh"],[1176,"Vì vậy kết quả tách từ có tách stopword không cao như cách tách thuần tuý"],[1177,"6.5"],[1178,"Thử nghiệm phân loại tin tức điện tử 6.5.1"],[1179,"Thước đo kết quả phân loại văn bản Để đánh giá hiệu quả phân loại văn bản, thông thường người ta dùng các chỉ số về độ thu về-recall và độ chính xác-precision [Yang, 2000]"],[1180,"Cho một phương pháp phân loại văn bản, đầu vào là một văn bản, và kết quả trả về là một danh sách các chủ đề được gán cho văn bản đó, chỉ số độ thu về, độ chính xác có thể được tính như sau: Hình 6"],[1181,"8"],[1182,"Các thông số dùng tính độ thu về, độ chính xác Hình trên mô tả các thông số sau: (A) là tất cả văn bản thực hiện phân loại văn bản cho chủ đề T (B) là số văn bản được phân loại lấy về cho chủ đề T (C) là số văn bản thực sự thuộc về chủ đề T (D) là số văn bản lấy về chính xác"],[1183,"Các tham số trên được dùng trong công thức tính độ thu về-recall, độ chính xác- precision dưới đây:"],[1184,"90 Việc gán nhãn chủ đề của các phương pháp phân loại văn bản có thể được đánh giá bằng cách dùng bảng trường hợp hai chiều ứng với từng loại chủ đề: Chủ đề đang xét ĐÚNG với chủ đề văn bản Chủ đề đang xét SAI với chủ đề văn bản Phân loại ĐÚNG với chủ đề văn bản a b Phân loại SAI với chủ đề văn bản c d Bảng 6"],[1185,"7"],[1186,"Bốn trường hợp của phân loại văn bản Như vậy, với mỗi kết quả phân loại cho một văn bản, ta sẽ có được một trong 4 trường hợp a,b,c hoặc d"],[1187,"Từ đó, ta tính được các chỉ số sau: arecall a c = + nếu a + c >0, ngược lại là không xác định"],[1188,"aprecision a b = + nếu a + b >0, ngược lại là không xác định"],[1189,"Tuy nhiên, cách tính với độ thu về, độ chính xác riêng rẽ sẽ cho kết quả không cân đối"],[1190,"Ví dụ nếu số văn bản lấy về đúng (D) gần bằng với số văn bản đúng thực sự (C) thì chỉ số độ thu về sẽ cao, tuy nhiên nếu số văn bản lấy về (B) khá nhiều so với (D) sẽ cho chỉ số độ chính xác nhỏ"],[1191,"Do vậy, thông thường người ta thêm một chỉ số F1 [Yang , 1997] để phản ánh sự cân đối giữa 2 độ đo trên: 21 1 1F recall precision = + Ngoài ra, để tính toán hiệu quả thực thi trên toàn bộ chủ đề, thông thường người ta còn sử dụng hai phương pháp macro-averaging và micro-averaging"],[1192,"Macro-averaging tính trung bình các chỉ số recall, precision, fallout, Acc,Err của tất cả các chủ đề"],[1193,""],[1194,"91 Micro-averaging tính toán các chỉ số dựa trên tổng giá trị a, b, c, d của từng chủ đề dựa theo các công thức áp dụng tính cho một chủ đề"],[1195,"Sự khác nhau chủ yếu giữa hai cách tính macro-averaging và micro-averaging là : micro-averaging tính toán dựa trên trọng số của mỗi văn bản, nên cho kết quả trung bình trên mỗi văn bản (per-document average); trong khi đó, macro- averaging tính toán trọng số trên mỗi chủ đề, do đó, kết quả cho sẽ đại diện cho giá trị trung bình trên mỗi chủ đề (per-category average)"],[1196,"6.5.2"],[1197,"Các phương pháp thử nghiệm Ở phần phân loại văn bản, chúng em thử nghiệm 2 công thức đã được trình bày ở 5.3"],[1198,"là công thức phân loại được sử dụng trong [H"],[1199,"Nguyen et al, 2005] (gọi tắt là công thức IClass) và công thức tính Naïve Bayes được cải tiến cho phù hợp với hướng tiếp cận dựa trên Google (gọi tắt là NBClass)"],[1200,"Ứng với công thức phân loại, chúng em thử nghiệm với 2 công thức tính MI: một của [H"],[1201,"Nguyen et al, 2005] (gọi tắt là MI1) và một công thức MI do chúng em đề xuất (gọi tắt là MI3) cho hai trường hợp tách và không tách stopword.Ở phần này chúng em không thử nghiệm với MI2 của [Ong & Chen, 1999] vì kết quả tách từ của công thức này thấp hơn các công thức khác khá nhiều sẽ cho kết quả không tốt"],[1202,"Như vậy tổng cộng chúng em thực hiện 8 lần thử nghiệm phân loại như sau: Công thức IClass + MI1 + tách stop word Công thức IClass + MI1 + không tách stop word Công thức IClass + MI3 + tách stop word Công thức IClass + MI3 + không tách stop word Công thức NBClass + MI1 + tách stop word Công thức NBClass + MI1 + không tách stop word Công thức NBClass + MI3 + tách stop word Công thức NBClass + MI3 + không tách stop word 6.5.3"],[1203,"Kết quả"],[1204,"92 Sau khi thực hiện phân loại văn bản, chúng em sử dụng các độ đo đã được trình bày ở mục 6.5.1"],[1205,"để tính toán kết quả chính xác của các thử nghiệm phân loại"],[1206,"Kết quả tính toán được trình bày trong bảng thống kê sau: Phương pháp Tên chủ đề R P F1 Xã hội 0.62625 0.654047 0.639847 Khoa học 0.72 0.975434 0.828475 Thể thao 0.765 0.968245 0.854706 Kinh doanh 0.795 0.293358 0.428571 Macro 0.763437 0.892427 0.822908 IClass + MI 1 +tách stopword Micro 0.663 0.682801 0.672755 Xã hội 0.764 0.636667 0.694545 Khoa học 0.7216 0.942131 0.81725 Thể thao 0.65625 0.975 0.784483 Kinh doanh 0.816 0.348718 0.488623 Macro 0.814333 0.951923 0.877769 IClass + MI 1 +không tách stopword Micro 0.656 0.672131 0.663968 Xã hội 0.630 0.660 0.645 Khoa học 0.857 0.873 0.865 Thể thao 0.861 0.915 0.887 Kinh doanh 0.630 0.740 0.681 Macro 0.913 0.892 0.903 IClass + MI 3 +tách stopword Micro 0.678 0.700 0.689 Xã hội 0.772 0.784 0.778IClass + MI 3 Khoa học 0.808 0.851 0.829"],[1207,"93 Thể thao 0.882 0.825 0.853 Kinh doanh 0.637 0.523 0.575 Macro 0.858 0.830 0.844 +không tách stopword Micro 0.553 0.566 0.559 Xã hội 0.680 0.738 0.708 Khoa học 0.810 0.841 0.825 Thể thao 0.924 0.918 0.921 Kinh doanh 0.725 0.620 0.668 Macro 0.785 0.779 0.782 NBClass + MI 1 +tách stopword Micro 0.648 0.633 0.640 Xã hội 0.591 0.697 0.640 Khoa học 0.704 0.897 0.789 Thể thao 0.886 0.918 0.902 Kinh doanh 0.675 0.581 0.625 Macro 0.714 0.773 0.742 NBClass + MI 1 +không tách stopword Micro 0.783 0.633 0.700 Xã hội 0.544 0.636 0.586 Khoa học 0.680 0.855 0.757 Thể thao 0.708 1.142 0.874 Kinh doanh 1.404 0.332 0.537 Macro 0.748 0.721 0.734 NBClass + MI 3 +tách stopword Micro 0.725 0.648 0.684 Xã hội 0.611 0.590 0.600 Khoa học 0.485 0.616 0.543 NBClass + MI 3 Thể thao 0.749 1.095 0.890"],[1208,"94 Kinh doanh 0.660 0.739 0.697 Macro 0.626 0.760 0.687 +không tách stopword Micro 0.647 0.647 0.647 Bảng 6"],[1209,"8"],[1210,"Kết quả phân loại văn bản cho từng chủ đề ở cấp 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 I M I1 SW I M I1 No nS W I M I3 SW I M I3 No nS W Ba ye s M I1 SW Ba ye s M I1 No n S W Ba ye s M I3 SW Ba ye s M I3 No nS W Xã hội Khoa học Thể thao Kinh doanh Macro Micro Hình 6"],[1211,"9"],[1212,"Biểu đồ F1 cho cấp 1 Vì kết quả của phần thử nghiệm phân loại ở cấp hai rất dài, nên chúng em chỉ xin trình bày biểu đồ kết quả phân loại mà không trình bày chi tiết bảng kết quả cho từng chủ đề"],[1213,"Sau đây là kết quả phân loại cho các chủ đề cấp 2"],[1214,""],[1215,"95 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 I M I1 SW I M I1 No nS W I M I3 SW I M I3 No nS W Ba ye s M I1 SW Ba ye s M I1 No n S W Ba ye s M I3 SW Ba ye s M I3 No nS W Giáo dục Du học Lối sống Du Lịch Khoa học Bóng đá 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 I M I1 SW I M I1 No nS W I M I3 SW I M I3 No nS W Ba ye s M I1 SW Ba ye s M I1 No n S W Ba ye s M I3 SW Ba ye s M I3 No nS W Quần vợt Bất động sản Chứng khoán Quốc tế Âm nhạc Thời trang"],[1216,"96 0 0.1 0.2 0.3 0.4 0.5 0.6 I M I1 SW I M I1 No nS W I M I3 SW I M I3 No nS W Ba ye s M I1 SW Ba ye s M I1 No n S W Ba ye s M I3 SW Ba ye s M I3 No nS W Điện ảnh Làm đẹp Giới tính macro micro Hình 6"],[1217,"10"],[1218,"Biểu đồ F1 cho cấp 2 6.5.4"],[1219,"Nhận xét Trong hai mức phân loại chủ đề, ta nhận thấy kết quả phân loại ở mức 1 cho độ chính xác cao hơn mức 2"],[1220,"Lý do là vì số lượng chủ đề của cấp 2 nhiều hơn cấp 1 rất nhiều (15 so với 4 ở cấp 1) và một số chủ đề của cấp 2 chưa thực sự tốt như Bất động sản, Lối sống, Làm đẹp, Giới tính"],[1221,"Từ đó, ta thấy được việc xây dựng danh sách từ khoá cho mỗi chủ đề một yêu cầu cần thiết để nâng hiệu suất phân loại văn bản"],[1222,"Dựa vào kết quả thử nghiệm ta nhận thấy rằng trong việc phân loại sử dụng Bayes tốt hơn công thức phân loại của H"],[1223,"Nguyen et al (2005) trong nhiều trường hợp"],[1224,"Trong các thử nghiệm công thức của H.Nguyen et al (2005), độ hỗ trợ của kết quả vào chủ đề đối có giá trị rất gần nhau, khi áp dụng cho các chủ đề hầu như không có sự khác biệt"],[1225,"Trong khi đó, với công thức Naïve Bayes, có một số chủ đề"],[1226,"97 nổi trội hơn hẳn các chủ đề khác và kết quả thống kê cũng cho thấy Naïve Bayes cho kết quả chính xác hơn"],[1227,"Kết quả của thử nghiệm công thức trong [H.Nguyen et al, 2005] với độ chính xác chưa cao lắm bởi vì đấy là công thức do chính tác giả đề nghị chưa dựa trên cơ sở lý thuyết vững chắc"],[1228,"Trong khi đó, phương pháp Naïve Bayes đã xuất hiện khá lâu, được chứng minh trên lý thuyết và thực nghiệm nên độ tin cậy rất cao"],[1229,"Việc sử dụng hướng tiếp cận Naïve Bayes cho phân loại văn bản dựa trên Google có thể nói là bước cải tiến đáng khíck lệ so với cách phân loại cũ"],[1230,"Dựa vào biểu đồ, ta nhận thấy sự kết hợp giữa phương pháp phân loại Naïve Bayes và công thức tính độ tương hỗ (MI) của [H"],[1231,"Nguyen et al, 2005] cho kết quả phân loại tốt nhất"],[1232,"Trong đó, tỉ lệ trung bình của phương pháp cho các chủ đề ở cấp 1 là 75%, và cho các chủ đề ở cấp 2 là 67%"],[1233,"Kết quả này hợp lý vì thực nghiệm cho thấy công thức MI1 của H.Nguyen et al (2005) cho kết quả tách từ chính xác cao nhất nên đã góp phần làm cho kết quả phân loại tốt hơn"],[1234,"Kết quả phân loại văn bản trung bình giữa 8 cặp là 75%, là kết quả chấp nhận được đối với phân loại văn bản tiếng Việt"],[1235,"Kết quả không cao so với kết quả phân loại bằng tiếng Anh bởi vì như chúng ta đã biết phần tách từ tiếng Việt gặp rất nhiều phức tạp"],[1236,""],[1237,"98 CChhưươơnngg 77 ỨỨNNGG DDỤỤNNGG PPHHÂÂNN LLOOẠẠII TTIINN TTỨỨCC ĐĐIIỆỆNN TTỬỬ TTỰỰ ĐĐỘỘNNGG Giới thiệu tòa soạn báo điện tử Tính cần thiết của phân loại tin tức tự động Phân tích hiện trạng Mô hình DFD quan niệm cấp 2 hiện hành cho ô xử lý Nhận bài và Trả bài Phê phán hiện trạng Mô hình DFD quan niệm cấp 2 mới cho ô xử lý Nhận bài và Trả bài Triển khai DLL Chương trình cài đặt \u201cTòa soạn báo điện tử\u201d đã tích hợp module phân loại tin tức Kết quả"],[1238,"99 Chương 7"],[1239,"ỨNG DỤNG PHÂN LOẠI TIN TỨC ĐIỆN TỬ TỰ ĐỘNG Nhằm đánh giá hiệu quả thực tế của việc phân loại sử dụng IGATEC và Naïve Bayes, chúng em đã xây dựng công cụ phân loại thành một module đồng thời tích họp vào trong tòa soạn báo điện tử"],[1240,"Trong chương này, chúng em sẽ giới thiệu sơ lược về tòa soạn báo điện tử và mô tả cách thức tích hợp module phân loại"],[1241,"7.1"],[1242,"Giới thiệu tòa soạn báo điện tử Phần mềm tòa soạn báo điện tử (Luận văn khóa 2000-Hoàng Minh Ngọc và Nguyễn Duy Hiệp) xây dựng trên nền tảng DotNetNuke tuân thủ theo qui trình của một tòa soạn thực tế đi từ soạn bài, duyệt bài và đăng bài"],[1243,"Mỗi biên tập viên sẽ phụ trách một mảng chủ đề"],[1244,"Cộng tác viên hay người dùng sau khi viết bài phải được biên tập viên duyệt"],[1245,"Nếu nội dung và hình thức chấp nhận được thì bài được chuyển lên vị trí có chức năng đưa bài lên website chính thức"],[1246,"Người quản trị sẽ phân công chuyên mục và chủ đề cho các biên tập viên"],[1247,"Nếu đã qua các cấp kiểm duyệt, bài viết được phép đưa lên website"],[1248,"Nếu tại một cấp nào đó, người quản lý thấy bài viết cần được chỉnh sửa thì bài viết sẽ được trả về đúng cấp có thẩm quyền"],[1249,"Ngoài ra, tòa soạn báo điên tử còn hỗ trợ việc thu thập tin tức điện tử từ nhiều nguồn khác nhau"],[1250,"Tin tức được tải về sau đó phải được các biên tập viên xác định chủ đề và chuyên mục mà bài báo thuộc về để tiến hành thủ tục đăng bài"],[1251,"Việc phân loại tin tức ở giai đoạn thực hiện luận văn này là hoàn toàn thủ công"],[1252,"7.2"],[1253,"Tính cần thiết của phân loại tin tức tự động Việc thực hiện phân loại thủ công trên số lương lớn các tin tức được tải về có thể ngốn rất nhiều thời gian và công sức"],[1254,"Nhằm làm tăng tính hiệu quả cũng như hỗ trợ tối đa cho các biên tập viên tập trung vào các công việc khác quan trọng hơn"],[1255,"Module phân loại tin tức tự động đã được xây dựng"],[1256,"Nhiệm vụ của module này là thực hiện phân loại tự động các tin tức tải về nhằm đề xuất sắp xếp tin tức này vào một chuyên mục hợp lý"],[1257,"Module được viết dưới dạng một thư viện dll thực hiện các"],[1258,"100 công việc như sau: lấy các tin tức được tải về, tiến hành phân loại và cập nhật vào cơ sở dữ liệu"],[1259,"7.3"],[1260,"Phân tích hiện trạng Mục đích của luận văn chúng em là tích hợp phần xử lý phân loại trang web tự động vào phần duyệt bài viết và sửa bài viết nên chúng em chỉ trình bày mô hình DFD cho ô xử lý \u201cNhận bài và Trả bài\u201d"],[1261,"Để tìm hiểu về toàn cảnh mô hình DFD của toà soạn báo điện tử, xin tham khảo luận văn \u201cToà soạn báo điện tử\u201d của Hoàng Minh Ngọc Hải (0012545), Nguyễn Duy Hiệp (0012038)) 7.3.1"],[1262,"Mô hình DFD quan niệm cấp 2 hiện hành cho ô xử lý Nhận bài và Trả bài 7.3.1.1"],[1263,"Mô hình Hình 7"],[1264,"1.Mô hình DFD hiện hành 7.3.1.2"],[1265,"Mô tả mô hình Thành viên có chức năng viết bài nhận bài viết mới được giao, sau khi hoàn thành thì lưu xuống kho dữ liệu những bài viết chưa đăng để chờ duyệt"],[1266,"Sau khi bài viết được duyệt, thành viên kiểm tra xem bài viết có cần chỉnh sửa không, nếu có thì"],[1267,"101 thực hiện chỉnh sửa sau đó lưu phiên bản mới của bài viết chờ duyệt tiếp"],[1268,"Ngoài ra, các bài báo được lấy tự động từ Internet xuống cũng được lưu trong kho dữ liệu các bài viết chưa đăng để chờ duyệt"],[1269,"7.3.1.2.1"],[1270,"Mô tả kho dữ liệu Hệ thống thông tin: Xây dựng toà soạn báo điện tử Mô hình quan niệm xử lý Hiện tại [] Tương lai[] Trang : Ứng dụng : Xây dựng toà soạn báo điện tử Mô tả kho dữ liệu : NHỮNG BÀI VIẾT CHƯA ĐƯỢC ĐĂNG Tờ : Ngày lập : 28/6/2004 Người lập : 1"],[1271,"Hoàng Minh Ngọc Hải 2"],[1272,"Nguyễn Duy Hiệp Dòng dữ liệu vào : Bài viết đã chỉnh sửa Bài viết mới Dòng dữ liệu ra : Bài viết cần chỉnh sửa Diễn giải : Kho này lưu trữ những bài viết đang nằm trong dây chuyền Cấu trúc dữ liệu: MA_BAI_VIET MA_CHUYEN_MUC MA_TAC_GIA"],[1273,"102 NGAY_VIET TIEU_DE NOI_DUNG DUONG_DAN_ANH KICH_THUOC_ANH CHIEU_DAI CHIEU_RONG Khối lượng : - Hiện tại : Không xác định - Tương lai : Không xác định Thông tin thường truy xuất : MA_BAI_VIET MA_CHUYEN_MUC TIEU_DE NOI_DUNG Bảng 7"],[1274,"1"],[1275,"Bảng kho dữ liệu những bài viết chưa được đăng 7.3.1.2.2"],[1276,"Mô tả ô xử lý Ô xử lý Tên Dòng dữ liệu vào Dòng dữ liệu ra Diễn giải (1.1) Nhận bài viết mới Bài viết Bài viết mới Phóng viên sau khi viết một bài mới sẽ gửi vào hệ thống"],[1277,"Những bài viết này được lưu dưới dạng những bài viết chưa được xử lý"],[1278,"(1.2) Lưu bài viết mới Bài viết mới Bài viết mới Lưu bài viết dưới tình trạng \u201cChưa xử lý\u201d"],[1279,"103 (1.3) Kiểm tra những bài viết cần xử lý Nhu cầu kiểm tra Thông tin cá nhân Bài viết cần chỉnh sửa Kiểm tra các bài viết đã được duyệt xem có cần chỉnh sửa không (1.4) Nhận bài viết đã chỉnh sửa Bài viết đã chỉnh sửa Bài viết đã chỉnh sửa Bài viết sau khi thành viên (có chức năng chỉnh sửa) duyệt, chỉnh sửa và trả lại cho thành viên phụ trách bài viết đó"],[1280,"(1.5) Lưu phiên bản mới của bài viết Bài viết đã chỉnh sửa Bài viết đã chỉnh sửa Bài viết đã chỉnh sửa được lưu vào CSDL dưới tình trạng \u201cĐã xử lý\u201d tại cấp vừa chỉnh sửa và dưới tình trạng \u201cChưa xử lý\u201d tại cấp được chuyển bài về (1.6) Lấy tin tự động Tin tức điện tử Tin tức điện tử Hệ thống tự động lấy tin tức từ các trang báo khác và lưu xuống kho dữ liệu Bảng 7"],[1281,"2"],[1282,"Bảng mô tả các ô xử lý của mô hình DFD hiện hành 7.3.2"],[1283,"Phê phán hiện trạng Hiện tại, hệ thống tự động lấy tin tức từ các trang báo điện tử khác về và gán vào các mục đã được chỉ định sẵn"],[1284,"Tuy nhiên, việc chỉ định chủ đề cho các tin tức lấy về một cách cứng nhắc chỉ đúng trong trường hợp trang web lấy tin có cấu trúc chủ đề tương ứng với chủ đề trong toà soạn báo điện tử của mình"],[1285,"Đối với những trang báo có cấu trúc khác đi, việc gán nhãn mặc định cho các bài báo sẽ không còn đúng nữa"],[1286,"Ví dụ ở toà soạn báo điện tử của chúng ta có mục Kinh doanh\\Quốc tế, còn ở báo www.vnexpress.net có mục Thế giới bao gồm nhiều nội dung, trong đó có một số tin tức về Kinh doanh quốc tế, một số tin tức về chính trị thế giới, một số bài về văn hoá chẳng hạn"],[1287,"Như vậy nếu ta chỉ định các bài báo lấy từ mục tin Thế giới ở www.vnexpress.net đều được xếp vào mục Kinh doanh\\Quốc tế thì kết quả không còn đúng hoàn toàn nữa"],[1288,"Lúc đó, các thành viên duyệt bài lại phải đọc lần lượt các"],[1289,"104 bài báo được lấy về một cách thủ công để phân loại chủ đề của tin tức cho phù hợp với cấu trúc chủ đề của mình"],[1290,"Để hạn chế trường hợp trên, chúng em đưa ra giải pháp là tích hợp module phân loại văn bản vào việc xử lý lấy tin tự động từ Internet"],[1291,"Các tin tức vừa được lấy về sẽ được module phân loại văn bản phân loại tự động vào các chủ đề có sẵn của toà soạn báo"],[1292,"Như vậy, chúng ta sẽ tiết kiệm được nhiều công sức và thời gian duyệt bài của các thành viên một cách đáng kể"],[1293,"7.3.3"],[1294,"Mô hình DFD quan niệm cấp 2 mới cho ô xử lý Nhận bài và Trả bài 7.3.3.1"],[1295,"Mô hình Hình 7"],[1296,"2"],[1297,"Mô hình DFD cải tiến 7.3.3.2"],[1298,"Mô tả mô hình Mô hình mới chỉ thêm một ô xử lý việc phân loại tin tức tự động sau khi hệ thống lấy tin tức từ trang web khác về"],[1299,""],[1300,"105 7.3.3.2.1"],[1301,"Mô tả ô xử lý Ô xử lý Tên Dòng dữ liệu vào Dòng dữ liệu ra Diễn giải (1.7) Phân loại tin tức tự động Tin tức điện tử Tin tức điện tử đã phân loại Module phân loại văn bản mới tích hợp vào hệ thống thực hiện phân loại tự động các tin tức vừa lấy về"],[1302,"Bảng 7"],[1303,"3"],[1304,"Bảng mô tả ô xử lý phân loại tin tức tự động 7.4"],[1305,"Triển khai DLL Chương trình phân loại văn bản tự động được viết trên ngôn ngữ C#, trong khi \u201cTòa soạn báo điện tử\u201d của luận văn khóa 2000 được viết mã trên nền VB.Net"],[1306,"Do đó, để tích hợp hai hệ thống lại, chúng em đã xây dựng các thành phần chính dùng trong phân loại văn bản thành DLL"],[1307,"Có thể nói, việc đóng gói chương trình thành dạng DLL ngoài tính tiện lợi trong việc tích hợp giữa các hệ thống xây dựng trên các ngôn ngữ khác nhau, goíi DLL còn có ưu điểm là khả năng sử dụng đơn giản, dễ mang chuyển, là yếu tố quan trọng trong việc xây dựng chương trình"],[1308,"\u201cTòa soạn báo điện tử\u201d của luận văn khóa 2000 được xây dựng khá công phu về mặt hình thức lẫn nội dung, cho nên khi tích hợp DLL mới vào, chúng em nhận thấy không cần thiết phải thiết lập thêm giao diện nào nữa"],[1309,"Chúng em chỉ tạo thêm một số lựa chọn cho người dụng có thể bật tắt chức năng phân loại"],[1310,""],[1311,"106 Hình 7"],[1312,"3"],[1313,"Màn hình lấy tin tức cho phép phân loại tự động 7.5"],[1314,"Chương trình cài đặt \u201cTòa soạn báo điện tử\u201d đã tích hợp module phân loại tin tức \u201cTòa soạn báo điện tử\u201d của luận văn khóa 2000 hiện tại chưa xây dựng công cụ cài đặt vài gỡ chương trình tự động (Install và Uninstall), đòi hỏi người dùng phải có nhiều kiến thức về SQL Server để có thể cài đặt cơ sở dữ liệu một cách thủ công"],[1315,"Vì vậy, nhằm tăng thêm tính tiện dụng của \u201cTòa soạn báo điện tử\u201d, chúng em tự xây dựng công cụ cài đặt tự động \u201cTòa soạn báo điện tử\u201d vào máy chỉ với thao tác click chuột"],[1316,"Công cụ cài đặt thực hiện việc thiết lập cơ sở dữ liệu vào hệ quản trị SQL Server, thư mục ảo chứa nội dung trang web trong IIS, và tạo shorcut trên desktop"],[1317,"Một số giao diện của công cụ cài đặt:"],[1318,"107 Hình 7"],[1319,"4"],[1320,"Màn hình bắt đầu"],[1321,"Click Next để bắt đầu cài đặt Hình 7"],[1322,"5.Màn hình chọn chế độ cài đặt hoặc tháo gỡ chương trình"],[1323,"Chọn Install và click Next để sang bước tiếp theo"],[1324,"108 Hình 7"],[1325,"6.Màn hình chọn đường dẫn để cài đặt chương trình"],[1326,"Sau khi chọn xong các đường dẫn phù hợp, nhấp vào Next để thực hiện cài đặt"],[1327,"Hình 7"],[1328,"7.Màn hình cài đặt chương trình"],[1329,"109 Hình 7"],[1330,"8.Màn hình chọn chức năng gỡ chương trình"],[1331,"Chọn Remove để gỡ chương trình đã cài đặt trên máy"],[1332,"Hình 7"],[1333,"9.Màn hình gỡ chương trình thành công"],[1334,"110 7.6"],[1335,"Kết quả Nhờ việc tích hợp module phân loại văn bản vào trong web \u201cTòa soạn báo điện tử\u201d mà giờ đây công việc phân loại tin tức điện tử đã trở nên nhanh chóng và tiện lợi hơn"],[1336,"Tuy xác suất phân loại đúng chưa đảm bảo cho hệ thống phân loại văn bản hoàn toàn tự động, mà cần có sự duyệt bài lại để đảm bào chính xác hoàn toàn, nhưng module phân loại văn bản bán tự động cũng đã cung cấp cho người dùng một tiện ích vô cùng hữu hiệu"],[1337,""],[1338,"111 CChhưươơnngg 88 TTỔỔNNGG KKẾẾTT Kết quả đạt được Về mặt lý thuyết Về mặt thực hành Hạn chế và hướng giải quyết Kết luận"],[1339,"112 Chương 8"],[1340,"TỔNG KẾT 8.1"],[1341,"Kết quả đạt được 8.1.1"],[1342,"Về mặt lý thuyết Phân loại văn bản là một bài toán khó và rất thú vị"],[1343,"Khó bởi vì vấn đề phân loại văn bản cần phải thực hiện xử lý ngôn ngữ, mà như chúng ta đều biết, ngôn ngữ tự nhiên là muôn hình vạn trạng, không chỉ phong phú về từ vựng, cú pháp mà còn phức tạp về ngữ nghĩa"],[1344,"Nhưng đây lại là bài toán rất thú vị vì với mỗi ngôn ngữ khác nhau, chúng ta phải thực hiện những cách xử lý khác nhau đối với ngôn ngữ"],[1345,"Trong khuôn khổ luận văn này, những vấn đề liên quan đến đề tài như các phương pháp tách từ và phương pháp phân loại văn bản đã được chúng em tiến hành nghiên cứu khá công phu theo cả chiều rộng lẫn chiều sâu về"],[1346,"Trên cơ sở nghiên cứu đó, các hướng tiếp cận áp dụng cho tiếng Anh và tiếng Hoa phù hợp đã được lựa chọn và thử nghiệm lên tiếng Việt"],[1347,"Đặc biệt, ở giai đoạn tách từ chuẩn bị cho phân loại, chúng em đã tìm hiểu một cách sâu sắc về hướng thống kê dựa trên Internet"],[1348,"Dựa trên nền tảng đó, chúng em mạnh dạn thực hiện cải tiến phương pháp tách từ dựa trên Internet và thuật toán di truyền thay vì sử dụng lại các công cụ tách từ tiếng Việt đã được công bố trước đây"],[1349,"Hướng tiếp cận mới này không những hạn chế được nhược điểm phụ thuộc vào tập ngữ liệu của các phương pháp khác mà còn đem lại khả năng khai thác vô tận nguồn dữ liệu khổng lồ của nhân loại : word-wide-web"],[1350,"Kết quả đạt được của phương pháp này là hoàn toàn khả quan và chấp nhận được đối với một hướng tiếp cận mới cho tách từ tiếng Việt dùng trong phân loại văn bản"],[1351,"Phương pháp phân loại văn bản Naïve Bayes thường được dùng trong phân loại văn bản tiếng Anh, nay được áp dụng trong tiếng Việt với hướng tiếp cận dựa trên thống kê từ Google tỏ ra khá hiệu bởi"],[1352,"Nhờ tính đơn giản, các thông số tính toán không cần quá lớn như các phương pháp khác, khả năng linh hoạt đối với sự thay đổi về thông tin huấn luyện, thời gian phân loại phù hợp yêu cầu, Naïve Bayes đã tở ra rất phù hợp với các yêu cầu đề ra"],[1353,""],[1354,"113 8.1.2"],[1355,"Về mặt thực nghiệm Công trình nghiên cứu của luận văn đã thực hiện được nhiều thử nghiệm đối với từng hướng tiếp cận tách từ tiếng Việt dựa trên Google cũng như phân loại văn bản"],[1356,"Nhờ vậy, kết quả thực nghiệm đã chứng minh được tính hiệu quả cho các công thức trên lý thuyết"],[1357,"Qua kết quả thực nghiệm, chúng em nhận thấy công thức tách từ của [H"],[1358,"Nguyen et al, 2005] và công thức MI do chúng em đề nghị cho hiệu quả gần tương đương nhau, tuy cách tính của [H"],[1359,"Nguyen et al, 2005] có vẻ chính xác hơn cho các từ có hai tiếng"],[1360,"Kết quả thực nghiệm ở phần phân loại văn bản cho thấy công thức phân loại trong [H"],[1361,"Nguyen et al, 2005] là mang tính chủ quan của tác giả, và dữ liệu thực nghiệm không đủ lớn để có thể kết luận"],[1362,"Nhưng khi áp dụng thử nghiệm trên số lượng văn bản và chủ đề nhiều hơn thì cách tính này cho ra kết quả thấp hơn nhiều so với kết quả mà tác giả trình bày"],[1363,"Kết quả sử dụng công thức Naïve Bayes đã cho kết quả khả quan hơn nhờ dựa vào lý thuyết đã được chứng minh từ các công trình trước"],[1364,"8.2"],[1365,"Hạn chế và hướng phát triển Với những kết quả thử nghiệm ban đầu, hệ thống phân loại văn bản đã bước đầu hoạt động hiệu quả , góp phần thực hiện phân loại văn bản bán tự động, giúp tiết kiệm được thời gian và công sức đọc văn bản một cách thủ công"],[1366,"Mặc dù những kết quả của hệ thống là chấp nhận được, tuy nhiên hệ thống có thể được cải thiện về độ chính xác và tốc độ nếu ta khắc phục một số hạn chế của hệ thống và thực hiện thêm các hướng mở rộng khác được trình bày sau đây"],[1367,"Phương pháp tách từ dựa trên Internet và thuật toán di truyền tỏ ra khá linh hoạt trong việc xử lý ngôn ngữ"],[1368,"Tuy nhiên với mặt bằng chất lượng Internet hiện nay ở Việt Nam, bước đầu thực hiện việc tách từ sẽ khá lâu vì phải mất thời gian lấy thông tin từ công cụ tìm kiếm trên mạng"],[1369,"Nhưng khi các thông tin trên được lưu lại tương đối lớn, tốc độ phân định ranh giới từ sẽ được cải thiện"],[1370,""],[1371,"114 Trong phần thử nghiệm phân loại văn bản, hiện tại chúng em quy định một chủ đề chỉ có một từ khóa chính là tên của chủ đề đó"],[1372,"Chính đây là một điểm hạn chế dẫn đến kết quả phân loại văn bản chưa cao như trong các công trình phân loại văn bản tiếng Anh"],[1373,"Do vậy, nhu cầu xây dựng một công cụ chiết xuất từ khóa tự động từ tập dữ liệu tin tức thô là rất cần thiết"],[1374,"Khi đã có tập từ khóa, độ chính xác của việc phân loại văn bản sẽ tăng lên đáng kể"],[1375,"Hiện tại, luận văn thực hiện phân loại theo hướng tiếp cận Naïve Bayes với các từ được tách trong câu mà không có sự chọn lựa những từ đặc trưng để thực hiện phân loại"],[1376,"Điều này dẫn đến một số từ không có ý nghĩa phân loại vẫn xem như có vai trò tương tự như những từ có ý nghĩa phân loại cao"],[1377,"Nếu chúng ta nghiên cứu thực hiện chọn lựa các đặc trưng của văn bản (feature selection) rồi mới"]],"downloaded":true,"m":[-1,-1],"n":"tim_hieu_cac_huong_tiep_can_bai_toan_phan_loai_van_ban_va_xa_6703.txt","o":"https://tailieu.vn/docview/tailieu/2015/20151204/gaugau1905/tim_hieu_cac_huong_tiep_can_bai_toan_phan_loai_van_ban_va_xa_6703.pdf"},{"saved_path":"temp/Tim hieu cac huong tiep can bai toan phan loai van ban va xa.txt","r":0,"s":[],"t":"\nKHOA CÔNG NGHỆ THÔNG TIN \n\nBỘ MÔN HỆ THỐNG THÔNG TIN \n \n\n \n\nSINH VIÊN THỰC HIỆN \nNGUYỄN TRẦN THIÊN THANH  - TRẦN KHẢI HOÀNG             \n\n \n\n \n\nTÌM HIỂU CÁC HƯỚNG TIẾP CẬN \nBÀI TOÁN PHÂN LOẠI VĂN BẢN VÀ  \n\nXÂY DỰNG PHẦN MỀM  \nPHÂN LOẠI TIN TỨC BÁO ĐIỆN TỬ \n\n \n\n \nKHÓA LUẬN CỬ NHÂN TIN HỌC \n\n \n\n \n\n \n\n \n\n \nTp.HCM, 2005 \n\n\n\n \n  \n\n \n\nTRƯỜNG ĐẠI HỌC KHOA HỌC TỰ NHIÊN \nKHOA CÔNG NGHỆ THÔNG TIN \n\nBỘ MÔN HỆ THỐNG THÔNG TIN \n \n\n \n\nSINH VIÊN THỰC HIỆN \n NGUYỄN TRẦN THIÊN THANH  - 0112243 \n TRẦN KHẢI HOÀNG            - 0112305 \n\n \n\n \n\nTÌM HIỂU CÁC HƯỚNG TIẾP CẬN \nBÀI TOÁN PHÂN LOẠI VĂN BẢN VÀ  \n\nXÂY DỰNG PHẦN MỀM  \nPHÂN LOẠI TIN TỨC BÁO ĐIỆN TỬ \n\n \n\nKHÓA LUẬN CỬ NHÂN TIN HỌC \n\nGIÁO VIÊN HƯỚNG DẪN \nCử nhân : NGUYỄN VIỆT THÀNH \nThạc sĩ : NGUYỄN THANH HÙNG \n\n \n\n \nNiên khóa 2001-2005 \n\n\n\n \n \n\ni \n\nLỜI CẢM ƠN \n \n\nChúng em xin gửi lời cảm ơn chân thành và sâu sắc nhất đến thầy Nguyễn \n\nViệt Thành và thầy Nguyễn Thanh Hùng đã tận tụy hướng dẫn, động viên, \n\ngiúp đỡ chúng em trong suốt thời gian thực hiện đề tài. \n\nChúng em xin chân thành cảm ơn quý Thầy Cô trong Khoa Công Nghệ \n\nThông Tin truyền đạt kiến thức quý báu cho chúng em trong những năm học \n\nvừa qua. \n\nChúng con xin nói lên lòng biết ơn đối với Ông Bà, Cha Mẹ luôn là nguồn \n\nchăm sóc, động viên trên mỗi bước đường học vấn của chúng con. \n\nXin chân thành cám ơn các anh chị và bạn bè đã ủng hộ, giúp đỡ và động \n\nviên chúng em trong thời gian học tập và nghiên cứu. \n\nMặc dù chúng em đã cố gắng hoàn thành luận văn trong phạm vi và khả \n\nnăng cho phép nhưng chắc chắn sẽ không tránh khỏi những thiếu sót. Chúng \n\nem kính mong nhận được sự cảm thông và tận tình chỉ bảo của quý Thầy Cô \n\nvà các bạn. \n\n \n\n \n Nguyễn Trần Thiên Thanh & Trần Khải Hoàng \n\n 07/2005 \n \n\n \n\n \n\n \n\n \n\n\n\n \n  \n\n \n\n ii \n\nLỜI NÓI ĐẦU \nTrong những năm gần đây, sự phát triển vượt bậc của công nghệ thông tin đã \n\nlàm tăng số lượng giao dịch thông tin trên mạng Internet một cách đáng kể đặc biệt \n\nlà thư viện điện tử, tin tức điện tử.... Do đó mà số lượng văn bản xuất hiện trên \n\nmạng Internet cũng tăng theo với một tốc độ chóng mặt. Theo số lượng thống kê từ \n\nBroder et al (2003), lượng thông tin đó lại tăng gấp đôi sau từ 9 đến 12 tháng, và tốc \n\nđộ thay đổi thông tin là cực kỳ nhanh chóng.  \n\nVới lượng thông tin đồ sộ như vậy, một yêu cầu lớn đặt ra đối với chúng ta là \n\nlàm sao tổ chức và tìm kiếm thông tin có hiệu quả nhất. Phân loại thông tin là một \n\ntrong những giải pháp hợp lý cho yêu cầu trên. Nhưng một thực tế là khối lượng \n\nthông tin quá lớn, việc phân loại dữ liệu thủ công là điều không tưởng. Hướng giải \n\nquyết là một chương trình máy tính tự động phân loại các thông tin trên. \n\nChúng em đã tập trung thực hiện đề tài \u201cTìm hiểu các hướng tiếp cận cho bài \n\ntoán phân loại văn bản và xây dựng ứng dụng phân loại tin tức báo điện tử\u201d \n\nnhằm tìm hiểu và thử nghiệm các phương pháp phân loại văn bản áp dụng trên tiếng \n\nViệt. Để thực hiện việc phân loại, điều bắt buộc đối với tiếng Việt đó là việc tách từ. \n\nTrong luận văn này, chúng em cũng tìm hiểu một số cách tách từ tiếng Việt và thử \n\nnghiệm một phương pháp tách từ mới thích hợp cho việc phân loại mà không dùng \n\nbất kỳ từ điển hoặc tập ngữ liệu nào. Cuối cùng, chúng em xây dựng phần mềm \n\nphân loại văn bản tích hợp vào trang web \u201cToà soạn báo điện tử\u201d (Luận văn khoá \n\n2000 - Hoàng Minh Ngọc Hải (0012545), Nguyễn Duy Hiệp (0012038)) nhằm phục \n\nvụ cho việc phân loại tin tức báo điện tử.  \n\nHiện nay, trang web của khoa chúng ta vẫn chưa thực hiện được việc phân loại \n\ntự động các tin tức lấy về, do đó gây ra rất nhiều lãng phí về thời gian và công sức \n\ncủa nhà quản trị cũng như làm giới hạn việc thu thập tin tức từ nhiều nguồn khác \n\nnhau. Ứng dụng phân loại tin tức báo điện tử tích hợp với việc lấy tin tức tự động \n\ncủa chúng em hy vọng sẽ đem đến một cách quản trị mới, nhanh chóng và hiệu quả \n\nhơn cách lấy tin truyền thống. Ngoài ra, trong điều kiện cần cập nhật thông tin một \n\n\n\n \n  \n\n \n\n iii \n\ncách nhanh chóng như hiện nay, phần mềm phân loại văn bản tự động của chúng \n\nem còn có khả năng ứng dụng cho nhiều loại trang báo điện tử tiếng Việt khác. \n\nNội dung của luận văn được trình bày bao gồm 8 chương; trong đó, 3 chương \n\nđầu trình bày các hướng tiếp cận cho phân loại văn bản và tách từ tiếng Việt hiện \n\nnay; 2 chương tiếp theo trình bày hướng tiếp cận của luận văn đối với phân loại văn \n\nbản và tách từ tiếng Việt; 3 chương cuối trình bày hệ thống thử nghiệm văn bản, \n\nứng dụng vào phân loại tin tức bán tự động, và cuối cùng là đánh giá, kết luận quá \n\ntrình nghiên cứu của luận văn. \n\n Chương 1. Tổng quan: giới thiệu sơ lược về các phương pháp phân loại văn \n\nbản và các hướng tiếp cận cho việc tách từ tiếng Việt; đồng thời xác định \n\nmục tiêu của đề tài. \n\n Chương 2. Một số phương pháp phân loại văn bản: giới thiệu tóm tắt một \n\nsố phương pháp phân loại văn bản dành cho tiếng Anh. \n\n Chương 3. Phương pháp tách từ tiếng Việt hiện nay: trình bày tóm tắt \n\nmột số phương pháp tách từ tiếng Việt hiện nay, ưu điểm và hạn chế của các \n\nphương pháp đó. \n\n Chương 4. Phương Tách từ Tiếng Việt không dựa trên tập ngữ liệu \n\nđánh dấu (annotated corpus) hay từ điển (lexicon) \u2013 Một thách thức: \n\ntrình bày phương pháp tách từ tiếng Việt mới chỉ dựa vào việc thống kê từ \n\nInternet thông qua Google mà không cần bất kỳ từ điển hay tập ngữ liệu nào. \n\n Chương 5. Bài toán phân loại tin tức báo điện tử: trình bày hướng tiếp cận \n\ncho bài toán phân loại tin tức báo điện tử. \n\n Chương 6. Hệ thống thử nghiệm phân loại văn bản: giới thiệu về hệ thống \n\nthử nghiệm các phương pháp tách từ và phân loại văn bản do chúng em xây \n\ndựng. Ngoài ra, trong chương 6, chúng em trình bày về dữ liệu dùng để thử \n\nnghiệm và các kết quả thử nghiệm thu được. \n\n Chương 7. Ứng dụng phân loại tin tức báo điện tử bán tự động: giới \n\nthiệu ứng dụng phân loại tin tức báo điện tử do chúng em xây dựng tích hợp \n\n\n\n \n  \n\n \n\n iv \n\ntrên trang web do luận văn \u201cTòa soạn báo điện tử\u201d khóa 2000 xây dựng của \n\nsinh viên Hoàng Minh Ngọc Hải (0012545), Nguyễn Duy Hiệp (0012038) \n\n Chương 8. Tổng kết: là chương cuối cùng của đề tài, tóm lại các vấn đề đã \n\ngiải quyết và nêu một số hướng phát triển trong tương lai. \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n\n\n \n  \n\n \n\n v \n\nMỤC LỤC \nChương 1. TỔNG QUAN............................................................................................2 \n\n1.1. Đặt vấn đề ............................................................................................................2 \n\n1.2. Các  phương pháp phân loại văn bản...................................................................2 \n\n1.3. Tách từ Tiếng Việt \u2013 Một thách thức thú vị ........................................................3 \n\n1.4. Mục tiêu của luận văn..........................................................................................5 \n\n1.4.1. Phần tìm hiểu các thuật toán phân loại văn bản.........................................5 \n\n1.4.2. Phần tách từ tiếng Việt...............................................................................5 \n\n1.4.3. Phần mềm phân loại tin tức báo điện tử bán tự động ................................5 \n\n1.4.4. Đóng góp của luận văn ..............................................................................6 \n\nChương 2. CÁC PHƯƠNG PHÁP PHÂN LOẠI VĂN BẢN TIẾNG ANH..............8 \n\n2.1. Bối cảnh các phương pháp phân loại văn bản hiện nay.......................................8 \n\n2.2. Các phương pháp phân loại văn bản tiếng Anh hiện hành ..................................8 \n\n2.2.1. Biểu diễn văn bản ......................................................................................8 \n\n2.2.2. Support vector Machine(SVM) ...............................................................10 \n\n2.2.3. K\u2013Nearest Neighbor (kNN).....................................................................12 \n\n2.2.4. Naïve Bayes (NB)....................................................................................13 \n\n2.2.5. Neural Network (NNet) ...........................................................................15 \n\n2.2.6. Linear Least Square Fit (LLSF)...............................................................17 \n\n2.2.7. Centroid- based vector .............................................................................18 \n\n2.3. Kết luận..............................................................................................................19 \n\nChương 3. CÁC PHƯƠNG PHÁP TÁCH TỪ TIẾNG VIỆT HIỆN NAY ..............22 \n\n3.1. Tại sao tách từ tiếng Việt là một thách thức? ....................................................22 \n\n3.1.1. So sánh giữa tiếng Việt và tiếng Anh ......................................................22 \n\n3.1.2. Nhận xét ...................................................................................................23 \n\n3.2. Bối cảnh các phương pháp tách từ hiện nay ......................................................23 \n\n3.2.1. Bối cảnh chung ........................................................................................23 \n\n3.2.2. Các hướng tiếp cận dựa trên từ (Word-based approaches)......................24 \n\n3.2.3. Các hướng tiếp cận dựa trên ký tự (Character-based approaches) ..........26 \n\n3.3. Một số phương pháp tách từ tiếng Việt hiện nay...............................................28 \n\n3.3.1. Phương pháp Maximum Matching: forward/backward...........................28 \n\n\n\n \n  \n\n \n\n vi \n\n3.3.2. Phương pháp giải thuật học cải biến ( TBL)............................................30 \n\n3.3.3. Mô hình tách từ bằng WFST và mạng Neural.........................................31 \n\n3.3.4. Phương pháp quy hoạch động (dynamic programming) .........................34 \n\n3.3.5. Phương pháp tách từ tiếng Việt dựa trên thống kê từ Internet và thuật \n\ntoán di truyền (Internet and Genetics Algorithm-based Text Categorization for \n\nDocuments in Vietnamese - IGATEC)........................................................................34 \n\n3.4. So sánh các phương pháp tách từ Tiếng Việt hiện nay......................................37 \n\n3.5. Kết luận..............................................................................................................37 \n\nChương 4. TÁCH TỪ TIẾNG VIỆT KHÔNG DỰA TRÊN TẬP NGỮ LIỆU ĐÁNH \n\nDẤU (ANNOTATED CORPUS) HAY TỪ ĐIỂN (LEXICON) \u2013 MỘT THÁCH THỨC 40 \n\n4.1. Giới thiệu ...........................................................................................................40 \n\n4.2. Các nghiên cứu về thống kê dựa trên Internet ...................................................40 \n\n4.2.1. Giới thiệu .................................................................................................40 \n\n4.2.2. Một số công trình nghiên cứu về thống kê dựa trên Internet...................41 \n\n4.2.3. Nhận xét ...................................................................................................43 \n\n4.3. Các phương pháp tính độ liên quan giữa các từ dựa trên thống kê ...................43 \n\n4.3.1. Thông tin tương hỗ  và t-score dùng  trong tiếng Anh ............................44 \n\n4.3.2. Một số cải tiến trong cách tính độ liên quan ứng dụng trong tách từ tiếng \n\nHoa và tiếng Việt .........................................................................................................46 \n\n4.3.3. Nhận xét  về các cách tính độ liên quan khi áp dụng cho tiếng Việt .......48 \n\n4.4. Tiền xử lý (Pre-processing) ...............................................................................49 \n\n4.4.1. Xử lý văn bản đầu vào .............................................................................49 \n\n4.4.2. Tách ngữ & tách stopwords .....................................................................50 \n\n4.5. Hướng tiếp cận tách từ dựa trên thống kê từ Internet  và thuật toán di truyền \n\n(Internet and Genetic Algorithm - based ) .......................................................................51 \n\n4.5.1. Công cụ trích xuất thông tin từ Google ...................................................51 \n\n4.5.2. Công cụ tách từ dùng thuật toán di truyền (Genetic Algorithm \u2013 GA) ...53 \n\n4.6. Kết luận..............................................................................................................61 \n\nChương 5. BÀI TOÁN PHÂN LOẠI TIN TỨC ĐIỆN TỬ ......................................63 \n\n5.1. Lý do chọn phương pháp Naïve Bayes..............................................................63 \n\n5.2. Thuật toán Naïve Bayes.....................................................................................64 \n\n5.2.1. Công thức xác suất đầy đủ Bayes ............................................................64 \n\n\n\n \n  \n\n \n\n vii \n\n5.2.2. Tính độc lập có điều kiện (Conditional Independence) ...........................65 \n\n5.2.3. Nguồn gốc thuật toán Naïve Bayes..........................................................65 \n\n5.2.4. Phương pháp Naïve Bayes trong phân loại văn bản ................................66 \n\n5.2.5. Hai mô hình sự kiện trong phân loại văn bản bằng phương pháp Naïve \n\nBayes 68 \n\n5.3. Bài toán phân loại tin tức điện tử tiếng Việt ......................................................70 \n\n5.3.1. Quy ước ...................................................................................................70 \n\n5.3.2. Công thức phân loại văn bản trong IGATEC [H. Nguyen et al, 2005] ...71 \n\n5.3.3. Công thức Naïve Bayes trong bài toán phân loại tin tức điện tử tiếng Việt \n\nsử dụng thống kê từ Google.........................................................................................72 \n\n5.4. Kết luận..............................................................................................................74 \n\nChương 6. HỆ THỐNG THỬ NGHIỆM PHÂN LOẠI    VĂN BẢN ......................76 \n\n6.1. Giới thiệu hệ thống thử nghiệm Vikass .............................................................76 \n\n6.1.1. Chức năng hệ thống Vikass .....................................................................76 \n\n6.1.2. Tổ chức và xử lý dữ liệu ..........................................................................76 \n\n6.1.3. Một số màn hình của hệ thống Vikass.....................................................79 \n\n6.2. Thử nghiệm các cách trích xuất thông tin..........................................................82 \n\n6.2.1. Các phương pháp thử nghiệm..................................................................82 \n\n6.2.2. Nhận xét ...................................................................................................84 \n\n6.3. Dữ liệu thử nghiệm ............................................................................................84 \n\n6.3.1. Nguồn dữ liệu ..........................................................................................84 \n\n6.3.2. Số lượng dữ liệu thử nghiệm ...................................................................84 \n\n6.3.3. Nhận xét ...................................................................................................86 \n\n6.4. Thử nghiệm các công thức tính độ tương hỗ MI ...............................................87 \n\n6.4.1. Các phương pháp thử nghiệm..................................................................87 \n\n6.4.2. Kết quả .....................................................................................................87 \n\n6.4.3. Nhận xét ...................................................................................................88 \n\n6.5. Thử nghiệm phân loại tin tức điện tử.................................................................89 \n\n6.5.1. Thước đo kết quả phân loại văn bản........................................................89 \n\n6.5.2. Các phương pháp thử nghiệm..................................................................91 \n\n6.5.3. Kết quả .....................................................................................................91 \n\n6.5.4. Nhận xét ...................................................................................................96 \n\n\n\n \n  \n\n \n\n viii \n\nChương 7. ỨNG DỤNG PHÂN LOẠI TIN TỨC ĐIỆN TỬ TỰ ĐỘNG ................99 \n\n7.1. Giới thiệu tòa soạn báo điện tử ..........................................................................99 \n\n7.2. Tính cần thiết của phân loại tin tức tự động ......................................................99 \n\n7.3. Phân tích hiện trạng .........................................................................................100 \n\n7.3.1. Mô hình DFD quan niệm cấp 2 hiện hành cho ô xử lý Nhận bài và Trả bài\n\n 100 \n\n7.3.2. Phê phán hiện trạng................................................................................103 \n\n7.3.3. Mô hình DFD quan niệm cấp 2 mới cho ô xử lý Nhận bài và Trả bài ..104 \n\n7.4. Triển khai DLL ................................................................................................105 \n\n7.5. Chương trình cài đặt \u201cTòa soạn báo điện tử\u201d đã tích hợp module phân loại tin \n\ntức 106 \n\n7.6. Kết quả .............................................................................................................110 \n\nChương 8. TỔNG KẾT............................................................................................112 \n\n8.1. Kết quả đạt được ..............................................................................................112 \n\n8.1.1. Về mặt lý thuyết.....................................................................................112 \n\n8.1.2. Về mặt thực nghiệm...............................................................................113 \n\n8.2. Hạn chế và hướng phát triển............................................................................113 \n\n8.3. Kết luận............................................................................................................114 \n\n \n\n\n\n \n  \n\n \n\n ix \n\nDANH SÁCH HÌNH \nHình 2. 1. Biểu diễn văn bản .................................................................................................9 \n\nHình 2. 2. Siêu mặt phẳng h phân chia dữ liệu huấn huyện thành 2 lớp + và \u2013 với khoảng \n\ncách biên lớn nhất. Các điểm gần h nhất là các vector hỗ trợ ,Support Vector (được \n\nkhoanh tròn).............................................................................................................11 \n\nHình 2. 3. Hình Kiến trúc mô đun (Modular Architecture) . Các kết quả của từng mạng con \n\nsẽ là giá trị đầu vào cho mạng siêu chủ đề và được nhân lại với nhau để dự đoán \n\nchủ đề cuối cùng . ....................................................................................................16 \n\nHình 3.4. Các hướng tiếp cận cơ bản trong tách từ tiếng Hoa và các hướng tiếp cận hiện tại \n\nđược công bố trong tách từ tiếng Việt .....................................................................24 \n\nHình 3.5. Sơ đồ hệ thống WFST..........................................................................................31 \n\nHình 3.6. Toàn cảnh hệ thống IGATEC ..............................................................................35 \n\nHình 4. 1. Nội dung thông tin cần lấy..................................................................................50 \n\nHình 4. 2. Biểu diễn cá thể bằng các bit 0,1 ........................................................................55 \n\nHình 4. 3. Thang tỉ lệ phát sinh loại từ ................................................................................57 \n\nHình 4. 4.Quá trình lai ghép ................................................................................................58 \n\nHình 4. 5. Quá trình đột biến ...............................................................................................59 \n\nHình 4. 6. Quá trình sinh sản ...............................................................................................59 \n\nHình 4. 7. Quá trình chọn cá thể ..........................................................................................60 \n\nHình 5. 1. Minh họa quy ước cho văn bản...........................................................................70 \n\nHình 5. 2.Minh họa chủ đề \u201cXã hội\u201d ...................................................................................70 \n\nHình 6. 1. Tổ chức file dữ liệu.............................................................................................77 \n\nHình 6. 2. Chủ đề Thể thao..................................................................................................77 \n\nHình 6. 3. Màn hình tách từ .................................................................................................79 \n\nHình 6. 4.  Màn hình trích xuất từ Google...........................................................................80 \n\nHình 6. 5. Màn hình phân loại tin tức điện tử......................................................................81 \n\nHình 6. 6. Cây chủ đề ..........................................................................................................86 \n\nHình 6. 7. Biểu đồ so sánh kết quả các công thức tính độ tương hỗ MI..............................88 \n\nHình 6. 8. Các thông số dùng tính độ thu về, độ chính xác .................................................89 \n\nHình 6. 9. Biểu đồ F1 cho cấp 1 ..........................................................................................94 \n\nHình 6. 10. Biểu đồ F1 cho cấp 2 ........................................................................................96 \n\n\n\n \n  \n\n \n\n x \n\nHình 7. 1.Mô hình DFD hiện hành ....................................................................................100 \n\nHình 7. 2. Mô hình DFD cải tiến .......................................................................................104 \n\nHình 7. 3. Màn hình lấy tin tức cho phép phân loại tự động .............................................106 \n\nHình 7. 4. Màn hình bắt đầu. Click Next để bắt đầu cài đặt ..............................................107 \n\nHình 7. 5.Màn hình chọn chế độ cài đặt hoặc tháo gỡ chương trình. ................................107 \n\nHình 7. 6.Màn hình chọn đường dẫn để cài đặt chương trình. ..........................................108 \n\nHình 7. 7.Màn hình cài đặt chương trình...........................................................................108 \n\nHình 7. 8.Màn hình chọn chức năng gỡ chương trình. ......................................................109 \n\nHình 7. 9.Màn hình gỡ chương trình thành công...............................................................109 \n\n \n \n \n \n\n\n\n \n  \n\n \n\n xi \n\nDANH SÁCH BẢNG \nBảng 3. 1. So sánh giữa tiếng Việt và tiếng Anh.................................................................23 \n\nBảng 4. 1. Thống kê độ dài từ trong từ điển ........................................................................54 \n\nBảng 4. 2. Tham số thực hiện GA .......................................................................................56 \n\nBảng 6. 1. Mô tả một số control của màn hình tách từ ........................................................79 \n\nBảng 6.2. Mô tả một số control của màn hình trích từ Google ...........................................80 \n\nBảng 6.3. Bảng mô tả một số control của màn hình phân loại tin tức điện tử.....................81 \n\nBảng 6. 4. Tham số sử dụng dịch vụ Google.......................................................................82 \n\nBảng 6. 5. Một số câu truy vấn đặc biệt của Google ...........................................................83 \n\nBảng 6. 6. Kết quả thực nghiệm các công thức tính độ tương hỗ MI..................................87 \n\nBảng 6. 7. Bốn trường hợp của phân loại văn bản...............................................................90 \n\nBảng 6. 8. Kết quả phân loại văn bản cho từng chủ đề........................................................94 \n\nBảng 7. 1. Bảng kho dữ liệu những bài viết chưa được đăng............................................102 \n\nBảng 7. 2. Bảng mô tả các ô xử lý của mô hình DFD hiện hành.......................................103 \n\nBảng 7. 3. Bảng mô tả ô xử lý phân loại tin tức tự động...................................................105 \n\n \n \n \n\n\n\n \n \n\n1 \n\n \n\nCChhưươơnngg  11  \n\nTTỔỔNNGG  QQUUAANN  \n \n \n\nĐặt vấn đề \n\nCác phương pháp phân loại văn bản \n\nTách từ tiếng Việt \u2013 Một thách thức thú vị \n\nMục tiêu của luận văn \n\nPhần tìm hiểu các thuật toán phân loại văn bản \n\nPhần tách từ tiếng Việt  \n\nPhần mềm phân loại tin tức báo điện tử bán tự động \n\n\n\n \n  \n\n \n\n 2 \n\nChương 1. TỔNG QUAN \n\n1.1. Đặt vấn đề \nTrong thời đại bùng nổ công nghệ thông tin hiện nay, phương thức sử dụng giấy \n\ntờ trong giao dịch đã dần được số hoá chuyển sang các dạng văn bản lưu trữ trên \n\nmáy tính hoặc truyền tải trên mạng. Bởi nhiều tính năng ưu việt của tài liệu số như \n\ncách lưu trữ gọn nhẹ, thời gian lưu trữ lâu dài, tiện dụng trong trao đổi đặc biệt là \n\nqua Internet, dễ dàng sửa đổi\u2026 nên ngày nay, số lượng văn bản số tăng lên một \n\ncách chóng mặt đặc biệt là trên world-wide-web. Cùng với sự gia tăng về số lượng \n\nvăn bản, nhu cầu tìm kiếm văn bản cũng tăng theo. Với số lượng văn bản đồ sộ thì \n\nviệc phân loại văn bản tự động là một nhu cầu bức thiết. \n\nTại sao phải phân loại văn bản tự động? Việc phân loại văn bản sẽ giúp chúng ta \n\ntìm kiếm thông tin dễ dàng và nhanh chóng hơn rất nhiều so với việc phải bới tung \n\nmọi thứ trong ổ đĩa lưu trữ để tìm kiếm thông tin. Mặt khác, lượng thông tin ngày \n\nmột tăng lên đáng kể, việc phân loại văn bản tự động sẽ giúp con người tiết kiệm \n\nđược rất nhiều thời gian và công sức.  \n\nDo vậy, các phương pháp phân loại văn bản tự động đã ra đời để phục vụ cho \n\nnhu cầu chính đáng đó. \n\n1.2. Các  phương pháp phân loại văn bản \nTheo Yang & Xiu (1999),  \u201cviệc phân loại văn bản tự động là việc gán các nhãn \n\nphân loại lên một văn bản mới dựa trên mức độ tương tự của văn bản đó so với các \n\nvăn bản đã được gán nhãn trong tập huấn luyện\u201d.  \n\nTừ trước đến nay, phân loại văn bản tự động trong tiếng Anh đã có rất nhiều \n\ncông trình nghiên cứu và đạt được kết quả đáng khích lệ. Dựa trên các thống kê của \n\nYang & Xiu (1999) và nghiên cứu của chúng em, một số phương pháp phân loại \n\nthông dụng hiện nay là: Support Vector Machine [Joachims, 1998], k-Nearest \n\nNeighbor [Yang, 1994], Linear Least Squares Fit [Yang and Chute, 1994] Neural \n\nNetwork [Wiener et al, 1995], Naïve Bayes [Baker and Mccallum, 2000], Centroid-\n\nbased [Shankar and Karypis, 1998]. Các phương pháp trên đều dựa vào xác suất \n\n\n\n \n  \n\n \n\n 3 \n\nthống kê hoặc thông tin về trọng số của từ trong văn bản. Chi tiết về ý tưởng và \n\ncông thức tính toán của mỗi phương pháp sẽ được chúng em trình bày ở chương 3, \n\nmục 3.3. \n\nMỗi phương pháp phân loại văn bản đều có cách tính toán khác nhau, tuy nhiên, \n\nnhìn một cách tổng quan thì các phương pháp đó đều phải thực hiện một số bước \n\nchung như sau: đầu tiên, mỗi phương pháp sẽ dựa trên các thông tin về sự xuất hiện \n\ncủa từ trong văn bản (ví dụ tần số, số văn bản chứa từ\u2026) để biểu diễn văn bản thành \n\ndạng vector; sau đó, tuỳ từng phương pháp mà ta sẽ áp dụng công thức và phương \n\nthức tính toán khác nhau để thực hiện việc phân loại.  \n\nĐối với tiếng Anh, các kết quả trong lĩnh vực này rất khả quan, còn đối với tiếng \n\nViệt, các công trình nghiên cứu về phân loại văn bản gần đây đã có một số kết quả \n\nban đầu nhưng vẫn còn nhiều hạn chế. Nguyên nhân là ngay ở bước đầu tiên, chúng \n\nta đã gặp khó khăn trong việc xử lý văn bản để rút ra tần số xuất hiện của từ. Trong \n\nkhi đó, để phân loại văn bản thì có thể nói bước đầu tiên là quan trọng nhất bởi vì \n\nnếu ở bước tách từ đã sai thì việc phân loại hầu như không thể thành công được. \n\nPhần trình bày tiếp theo sẽ cho chúng ta biết những thách thức đặt ra trong việc tách \n\ntừ tiếng Việt, cũng như những ứng dụng thú vị của nó. \n\n1.3. Tách từ Tiếng Việt \u2013 Một thách thức thú vị \nĐối với tiếng Anh, \u201ctừ là một nhóm các ký tự có nghĩa được tách biệt với nhau \n\nbởi khoảng trắng trong câu\u201d (Webster Dictionary), do vậy việc tách từ trở nên rất \n\nđơn giản. Trong khi đối với tiếng Việt, ranh giới từ không được xác định mặc định \n\nlà khoảng trắng mà tùy thuộc vào ngữ cảnh dùng câu tiếng Việt. Ví dụ các từ trong \n\ntiếng Anh là \u201cbook\u201d , \u201ccat\u201d, \u201cstadium\u201d  thì trong tiếng Việt là \u201cquyển sách\u201d, \u201ccon \n\nmèo\u201d, \u201csân vận động\u201d \u2026 Vấn đề trên thực sự đưa ra một thách thức đối với chúng \n\nta - những người làm tin học. \n\nTuy nhiên, thách thức nào cũng có cái thú vị của nó. Nếu chúng ta giải quyết \n\nđược việc tách từ một cách thoả đáng, thì thành quả mà chúng ta đạt được là một \n\nnền tảng để phát triển cho các hướng nghiên cứu khác có liên quan đến việc xử lý \n\nngôn ngữ tự nhiên như: phân loại văn bản, dịch tự động, kiểm tra lỗi chính tả, kiểm \n\n\n\n \n  \n\n \n\n 4 \n\ntra ngữ pháp\u2026 Đó là các ứng dụng rất thiết thực với đời sống con người và là mục \n\ntiêu của con người đang chinh phục. \n\nMột số nước châu Á như Trung Quốc, Nhật Bản, Hàn Quốc, Việt Nam sử dụng \n\nloại hình ngôn ngữ gần như tương tự nhau về mặt hình thái và cú pháp. Do đó ta có \n\nthể áp dụng, cải tiến một số phương pháp tách từ của các nước bạn đặc biệt là Trung \n\nQuốc vào việc tách từ tiếng Việt.  \n\nTheo Đinh Điền (2004), các phương pháp tách từ sau có nguồn gốc từ tiếng Hoa \n\nđã được thử nghiệm trên tiếng Việt : Maximum Matching: forward/backward hay \n\ncòn gọi LRMM (Left Right Maximum Matching); giải thuật học cải biến TBL; \n\nmạng chuyển dịch trạng thái hữu hạn có trọng số WFST (Weighted finite-state \n\nTransducer); giải thuật dựa trên nén (compression);\u2026.Theo các cách tiếp cận trên, \n\nđiều kiện quan trọng cần có là một hệ thống từ điển (LRMM) và ngữ liệu đánh dấu \n\n(TBL, WFST) đầy đủ, chuẩn xác. Một từ điển hay một tập ngữ liệu không hoàn \n\nchỉnh sẽ làm giảm hiệu suất của thuật toán.  \n\nTuy nhiên, khó có thể tạo ra được một từ điển hoàn chỉnh nhất là trong thời đại \n\nngày nay, ngôn ngữ còn tiếp tục phát triển và thay đổi từng ngày. Xét về mặt phổ \n\nbiến, tiếng Anh là ngôn ngữ được dùng rộng rãi trong giao dịch trên thế giới. Do đó \n\nđể tạo ra một tập ngữ liệu tiếng Anh thỏa các tiêu chí chọn mẫu ngữ liệu là không \n\nquá phức tạp. Trong khi đó, Việt Nam chỉ mới cho phép truy cập Internet trong \n\nvòng chục năm trở lại đây, do đó số lượng trang web tiếng Việt là không nhiều. Cho \n\nđến nay, vẫn chưa có một tập ngữ liệu huấn luyện chuẩn nào dành cho việc tách từ \n\nvà phân loại trang web tiếng Việt được công bố. \n\nGần đây, một phương pháp tách từ mới được giới thiệu có ưu điểm là không cần \n\ndùng tập ngữ liệu hay từ điển để lấy thông tin thống kê hay trọng số của từ, đó là \n\nphương pháp Internet and Genetics Algorithm-based Text Categorization \n\n(IGATEC) của H. Nguyen et al (2005). Điểm sáng tạo của thuật toán là kết hợp \n\nthuật toán di truyền với việc trích xuất thông tin thống kê từ Internet thông qua một \n\ncông cụ tìm kiếm (như Google chẳng hạn) thay vì lấy từ tập ngữ liệu như các \n\nphương pháp trước. \n\n\n\n \n  \n\n \n\n 5 \n\nChúng em thực hiện bước tách từ trong luận văn này dựa trên ý tưởng của thuật \n\ntoán IGATEC nhưng có bổ sung nhiều cải tiến đáng kể để tăng độ chính xác đồng \n\nthời thực hiện các thí nghiệm chi tiết nhằm so sánh các cách áp dụng thuật toán để \n\ntìm ra cách tối ưu nhất. \n\n1.4. Mục tiêu của luận văn \n\n1.4.1. Phần tìm hiểu các thuật toán phân loại văn bản \nTrong khuôn khổ luận văn này, chúng em tìm hiểu ở mức cơ bản một số phương \n\npháp phân loại văn bản hiện có đang áp dụng cho tiếng Anh và đưa ra một số so \n\nsánh nhất định giữa các phương pháp: Support Vector Machine (Joachims, 1998), k-\n\nNearest Neighbor (Yang, 1994), Linear Least Squares Fit (Yang and Chute, 1994) \n\nNeural Network (Wiener et al, 1995), Naïve Bayes (Baker and Mccallum, 2000), \n\nCentroid-based (Shankar and Karypis, 1998).  \n\nSau đó, chúng em sẽ chọn và áp dụng một phương pháp cho bài toán phân loại \n\ntin tức báo điện tử tiếng Việt chấp nhận được, phù hợp với mức độ và thời gian cho \n\nphép của một luận văn đại học. \n\n1.4.2. Phần tách từ tiếng Việt \nHiện nay các phương pháp tách từ tiếng Việt được công bố vẫn chưa nhiều và \n\nhướng tiếp cận chủ yếu dựa vào tập huấn luyện và từ điển. Như chúng ta đã biết, \n\nviệc tạo ra hệ thống dữ liệu đó không phải là một sớm một chiều, mà yêu cầu đầu tư \n\nkhá nhiều công sức, thời gian và tiền bạc.  \n\nTrong luận văn này, chúng em cố gắng tìm hiểu, cải tiến, cài đặt, thử nghiệm \n\nmột phương pháp tách từ tiếng Việt theo hướng tiếp cận IGATEC, có độ chính xác \n\nchấp nhận được, và điều quan trọng là không cần dùng tập ngữ liệu (corpus) để \n\nphân định ranh giới từ. \n\nSau đó, chúng em sẽ cài đặt, thử nghiệm độ chính xác của phương pháp tách từ \n\nnày trong khía cạnh phân loại văn bản \n\n1.4.3. Phần mềm phân loại tin tức báo điện tử bán tự động \n\n\n\n \n  \n\n \n\n 6 \n\nĐể thử nghiệm hướng nghiên cứu tách từ tiếng Việt và phân loại văn bản của \n\nluận văn, chúng em tích hợp phần mềm phân loại tin tức vào trang web báo điện tử \n\ncó sẵn được xây dựng trên nền DotNetNuke Portal của luận văn khoá 2000 ( Hoàng \n\nMinh Ngọc Hải (0012545), Nguyễn Duy Hiệp (0012038) ) \n\nNhư chúng ta đều biết, điều kiện mạng cung cấp cho các trường đại học ở nước \n\nta hiện nay là khá hạn chế, khó đáp ứng được hoàn toàn việc cho phép các sinh viên \n\nlên mạng Internet để xem các tin tức mới hằng ngày. Để giải quyết phần nào vấn đề \n\ntrên, chúng ta có thể chọn lọc một số tin tức từ các nguồn khác, đăng tải trên trang \n\nweb nội bộ của trường. Trên cơ sở đó, chúng em tích hợp phần mềm phân loại tin \n\ntức báo điện tử tự động vào toà soạn báo điện tử cho phép lấy tin tự động từ các \n\ntrang web khác. Nhờ vậy, công việc lấy tin và phân loại tin tức giờ đây đã trở nên \n\nrất dễ dàng và nhanh chóng, tiết kiệm nhiều công sức và thời gian cho nhà quản trị. \n\nKhông chỉ ứng dụng cho các trường đại học, phần mềm phân loại tin tức của \n\nchúng em còn có thể ứng dụng, hỗ trợ cho nhiều công việc khác như : lưu trữ \n\n(clipping) báo chí, xây dựng bộ ngữ liệu cho các bài toán cần dữ liệu được phân \n\nloại, tiền đề cho các bài toán khác như phân loại website. \n\n1.4.4. Đóng góp của luận văn \nLuận văn đã thực hiện việc được nhiều cải tiến của hướng tiếp cận tách từ tiếng \n\nViệt dùng trong phân loại văn bản theo phương pháp dựa trên thống kê Internet.  \n\nĐối với tách từ tiếng Việt, chúng em đề nghị thêm một công thức tính toán độ \n\ntương hỗ mới, từ đó thực hiện thử nghiệm tính hiệu quả của cách tính này so với \n\ncách công thức ở những công trình khác.  \n\nTrong quá trình xây dựng thuật toán di truyền dùng trong tách từ, chúng em đã \n\ncải tiến hình thức đột biến mới phù hợp với hình thức cấu tạo từ trong câu. \n\nĐối với việc phân loại văn bản, chúng em cải tiến công thức tính trong hướng \n\ntiếp cận Naïve Bayes phù hợp với phương pháp tính dựa trên thống kê từ Google. \n\n  \n\n  \n\n\n\n \n  \n\n \n\n 7 \n\nCChhưươơnngg  22  \n\nCCÁÁCC  PPHHƯƯƠƠNNGG  PPHHÁÁPP  \n\nPPHHÂÂNN  LLOOẠẠII  VVĂĂNN  BBẢẢNN  \n\nTTIIẾẾNNGG  AANNHH    \n \n\n \n\nBối cảnh các phương pháp phân loại văn bản hiện nay \n\nCác phương pháp phân loại văn bản tiếng Anh hiện hành \n\nBiểu diễn văn bản \n\nSupport vector Machine (SVM) \n\nK\u2013Nearest Neighbor (kNN) \n\nNaïve Bayes (NB) \n\nNeural Network (NNet) \n\nLinear Least Square Fit (LLSF) \n\nCentroid- based vector \n\nKết luận  \n\n\n\n \n  \n\n \n\n 8 \n\nChương 2. CÁC PHƯƠNG PHÁP PHÂN LOẠI VĂN BẢN \nTIẾNG ANH \n\n2.1. Bối cảnh các phương pháp phân loại văn bản hiện nay \n Phân loại văn bản tự động là một lĩnh vực được chú ý nhất trong những năm \n\ngần đây. Để phân loại người ta sử dụng nhiều cách tiếp cận khác nhau như dựa trên \n\ntừ khóa,  dựa trên ngữ nghĩa các từ có tần số xuất hiện cao, mô hình Maximum \n\nEntropy, tập thô \u2026 Tiếng Anh là một trong những ngôn ngữ được nghiên cứu sớm \n\nvà rộng rãi nhất với kết quả đạt được rất khả quan. Một số lượng lớn các phương \n\npháp phân loại đã được áp dụng thành công trên ngôn ngữ này : mô hình hồi quy \n\n[Fuhr et al,1991], phân loại dựa trên láng giềng gần nhất (k-nearest neighbors) \n\n[Dasarathy, 1991], phương pháp dựa trên xác suất Naïve Bayes [Joachims, 1997], \n\ncây quyết định [Fuhr et al,1991], học luật quy nạp [William & Yoram, 1996], mạng \n\nnơron (neural network)[Wiener et al, 1995], học trực tuyến[William & Yoram, \n\n1996], và máy vector hỗ trợ (SVM-support vector machine) [Vapnik, 1995].  Hiệu \n\nquả của các phương pháp này rất khác nhau ngay cả khi áp dụng cho tiếng Anh. \n\nViệc đánh giá gặp nhiều khó khăn do việc thiếu các tập ngữ liệu huấn luyện chuẩn. \n\nThậm chí đối với tập dữ liệu được sử dụng rộng rãi nhất, Reuter cũng có nhiều \n\nphiên bản khác nhau. Hơn nữa, có rất nhiều độ đo được sử dụng như recall, \n\nprecision, accuracy hoặc error, break-even point, F-measure \u2026Chương này giới \n\nthiệu các thuật toán phân loại được sử dụng phổ biến nhất đồng thời so sánh giữa \n\ncác phương pháp sử dụng kết quả của [Yang, 1997]. \n\n2.2. Các phương pháp phân loại văn bản tiếng Anh hiện hành \n\n2.2.1. Biểu diễn văn bản \nBước đầu tiên của mọi phương pháp phân loại là chuyển việc mô tả văn bản \n\ndùng chuỗi ký tự thành một dạng mô tả khác, phù hợp với các thuật toán học theo \n\nmẫu và phân lớp. Hầu hết các thuật toán đều sử dụng cách biểu diễn văn bản sử \n\ndụng vector đặc trưng, sự khác nhau có chăng là việc chọn không gian đặc trưng \n\nkhác nhau. Vì vậy ở phần này chúng em sẽ trình bày sơ lược về vector đặc trưng. \n\n\n\n \n  \n\n \n\n 9 \n\nÝ tưởng chính là xem mỗi văn bản id  tương ứng là một vector đặc trưng \n\n( )1 2( ), ( ),..., ( )i nd TF w TF w TF w  trong không gian các từ nW ( iw là một từ, một đặc \n\ntrưng, tương ứng một chiều của không gian). Gía trị của ( )iTF w chính là số lần xuất \n\nhiện của từ iw  trong văn bản id  . Từ được chọn là một đặc trưng khi nó xuất hiện \n\ntrong ít nhất 3 văn bản [Joachims, 1997]. Để không bị phụ thuộc vào chiều dài văn \n\nbản vector đặc trưng sẽ được chuẩn hóa về chiều dài đơn vị : \n\n1 2\n2 2 2\n\n( )( ) ( )( , ,..., )\n( ) ( ) ( )\n\nn\n\ni i i\n\nTF wTF w TF wdi\nTF w TF w TF w∑ ∑ ∑\n\n \n\n \n\nHình 2. 1. Biểu diễn văn bản \n\nTrong thực tế để cải thiện tốc độ và kết quả người ta thường sử dụng )( iwIDF  \n\nhoặc i(w )TFIDF thay cho ( )iTF w :  \n\n( ) log( )\n( )i i\n\nmIDF w\nDF w\n\n=  \n\n( ) ( ). ( )i i iTFIDF w TF w IDF w=  \n\nVới  \n\n m chính là số văn bản huấn luyện \n\n\n\n \n  \n\n \n\n 10 \n\n DF(wi) là số văn bản có chứa từ iw . \n\nMột vấn đề nảy sinh khi biểu diễn văn bản theo hướng vector đặc trưng chính là \n\nviệc chọn đặc trưng và số chiều cho không gian. Cần phải chọn bao nhiêu từ và \n\nchọn những từ nào ? theo những cách nào ? Có nhiều hướng tiếp cận trong vấn đề \n\nnày mà tiêu biểu là sử dụng Information Gain [Yang & Petersen, 1997] ngoài ra còn \n\ncó các phương pháp như DF-Thresolding [Yang & Petersen, 1997], Test−2χ  \n\n[Schütze et al,1995] hoặc Term Strength [Yang & Wilbur,1997]. Phương pháp \n\nInformation Gain sử dụng độ đo Mutual Information(MI) [Yang & Petersen, 1997] \n\nđể chọn ra tập đặc trưng con f  gồm những từ có giá trị MI cao nhất. \n\nCác đặc trưng của văn bản khi biểu diễn dưới dạng vector : \n\n Số chiều không gian đặc trưng thường rất lớn (trên 10000) \n\n Có các đặc trưng độc lập nhau, sự kết hợp các đặc trưng này thường không \n\ncó ý nghĩa trong phân loại \n\n Đặc trưng rời rạc : vector id có rất nhiều giá trị 0 do có nhiều đặc trưng \n\nkhông xuất hiện trong văn bản id . \n\n Hầu hết các văn bản có thể được phân chia một cách tuyến tính bằng các \n\nhàm tuyến tính. \n\nViệc phân loại sẽ tốt hơn nếu các thuật toán tận dụng được những đặc trưng này. \n\nPhần tiếp theo sẽ nói rõ hơn về các thuật toán phân loại. \n\n2.2.2. Support vector Machine(SVM) \nSVM là phương pháp tiếp cận phân loại rất hiệu quả  được Vapnik giới thiệu \n\nnăm 1995 [Vapnik, 1995] để giải quyết vấn đề nhận dạng mẫu 2 lớp sử dụng \n\nnguyên lý Cực tiểu hóa Rủi ro có Cấu trúc (Structural Risk Minimization) [Vapnik, \n\nCortes, 1995].  \n\n\n\n \n  \n\n \n\n 11 \n\n2.2.2.1. Ý tưởng \nCho trước một tập huấn luyện được biểu diễn trong không gian vector trong đó \n\nmỗi tài liệu là một điểm, phương pháp này tìm ra một siêu mặt phẳng h quyết định \n\ntốt nhất có thể chia các điểm trên không gian này thành hai lớp riêng biệt tương ứng \n\nlớp + và lớp \u2013. Chất lượng của siêu mặt phẳng này được quyết định bởi khoảng \n\ncách (gọi là biên) của điểm dữ liệu gần nhất của mỗi lớp đến mặt phẳng này. \n\nKhoảng cách biên càng lớn thì mặt phẳng quyết định càng tốt đồng thời việc phân \n\nloại càng chính xác. Mục đích thuật toán SVM tìm được khoảng cách biên lớn nhất. \n\nHình sau minh họa cho thuật toán này : \n\n \n\nHình 2. 2. Siêu mặt phẳng h phân chia dữ liệu huấn huyện thành 2 lớp + và \u2013 \n\nvới khoảng cách biên lớn nhất. Các điểm gần h nhất là các vector hỗ trợ \n\n,Support Vector (được khoanh tròn) \n\n2.2.2.2. Công thức chính \nSVM thực chất là một bài toán tối ưu, mục tiêu của thuật toán này là tìm được \n\nmột không gian H và siêu mặt phẳng quyết định h trên H sao cho sai số phân loại là \n\nthấp nhất \n\nPhương trình siêu mặt phẳng chứa vector id  trong không gian như sau : \n\n0=+⋅ bwdi  \n\nĐặt \n⎪⎩\n\n⎪\n⎨\n⎧\n\n<+⋅−\n\n>+⋅+\n=+⋅=\n\n0,1\n\n0,1\n)()(\n\nbwd\n\nbwd\nbwdsigndh\n\ni\n\ni\nii  \n\n\n\n \n  \n\n \n\n 12 \n\nNhư thế )( idh biểu diễn sự phân lớp của id  vào hai lớp như đã nói. Gọi { }1±=iy , \n\niy  = + 1, văn bản id  ∈ lớp +; iy  = - 1, văn bản id  ∈ lớp -  Khi này để có siêu mặt \n\nphẳng h ta sẽ phải giải bài toán sau : \n\n \n\nTìm Min w  với w  và b  thõa điều kiên sau : \n\n( ) 1)(:,1 ≥+⋅∈∀ bwdsignyni ii  \nBài toán SVM có thể giải bằng kỹ thuật sử dụng toán tử Lagrange để biến đổi \n\nthành dạng đẳng thức. \n\nĐiểm thú vị ở SVM là mặt phẳng quyết định chỉ phụ thuộc vào các vector hỗ trợ \n\n(Support Vector) có khoảng cách đến mặt phẳng quyết định là \nw\n1 . Khi các điểm \n\nkhác bị xóa đi thì thuật toán vẫn cho kết quả giống như ban đầu. Chính đặc điểm \n\nnày làm cho SVM khác với các thuật toán khác như kNN,LLSF, NNet và NB vì tất \n\ncả dữ liệu trong tập huấn luyện đều được dùng để tối ưu hóa kết quả. Các phiên bản \n\nSVM tốt có thể kể đến là SVMLight [Joachims, 1998] và Sequential Minimal \n\nOptimization (SMO) [Platt, 1998] \n\n2.2.3.  K\u2013Nearest Neighbor (kNN) \nkNN là phương pháp truyền thống khá nổi tiếng về hướng tiếp cận dựa trên \n\nthống kê đã được nghiên cứu trong nhận dạng mẫu hơn bốn thập kỷ qua [Dasarathy, \n\n1991]. kNN được đánh giá là một trong những phương pháp tốt nhất (áp dụng trên \n\ntập dữ liệu Reuters phiên bản 21450), được sử dụng từ những thời kỳ đầu của việc \n\nphân loại văn bản [Marsand et al, 1992] [Yang, 1994] [Iwayama, Tokunaga, 1995]. \n\n2.2.3.1. Ý tưởng \nKhi cần phân loại một văn bản mới, thuật toán sẽ tính khoảng cách (khoảng cách \n\nEuclide, Cosine ...) của tất cả các văn bản trong tập huấn luyện đến văn bản này để \n\ntìm ra k văn bản gần nhất (gọi là k \u201cláng giềng\u201d), sau đó dùng các khoảng cách này \n\nđánh trọng số cho tất cả chủ đề. Trọng số của một chủ đề chính là tổng tất cả \n\nkhoảng cách ở trên của các văn bản trong k láng giềng có cùng chủ đề, chủ đề nào \n\n\n\n \n  \n\n \n\n 13 \n\nkhông xuất hiện trong k láng giềng sẽ có trọng số bằng 0. Sau đó các chủ đề sẽ được \n\nsắp xếp theo mức độ trọng số giảm dần và các chủ đề có trọng số cao sẽ được chọn \n\nlà chủ đề của văn bản cần phân loại.  \n\n2.2.3.2. Công thức chính \nTrọng số của chủ đề jc  đối với văn bản x  : \n\n{ }\n\nW( , ) ( , ). ( , )\ni\n\nj i i j j\nd kNN\n\nx c sim x d y d c b\n∈\n\n= −∑  \n\nTrong đó  \n\n ( ),i jy d c  ∈ {0,1}, với  \n y = 0 : văn bản id  không thuộc về chủ đề cj \n\n y = 1 : văn bản id  thuộc về chủ đề cj \n\n ( ), isim x d  : độ giống nhau giữa văn bản cần phân loại x  và văn bản id . Có \nthể sử dụng độ đo cosine để tính ( ), isim x d  \n\n( ) ii x.d, os(x,d )=\n.\n\nisim x d c\nx di\n\n=  \n\n jb  là ngưỡng phân loại của chủ đề cj được tự động học sử dụng một tập văn \n\nbản hợp lệ được chọn ra từ tập huấn luyện \n\nĐể chọn được tham số k tốt nhất cho việc phân loại, thuật toán phải được chạy \n\nthử nghiệm trên nhiều giá trị k khác nhau, giá trị k càng lớn thì thuật toán càng ổn \n\nđịnh và sai sót càng thấp [Yang, 1997]. Giá trị tốt nhất được sử dụng tương ứng trên \n\nhai bộ dữ liệu Reuter và Oshumed là k = 45 [Joachims, 1997].  \n\n2.2.4. Naïve Bayes (NB) \nNB là phương pháp phân loại dựa vào xác suất được sử dụng rộng rãi trong lĩnh \n\nvực máy học [Mitchell, 1996] [Joachims, 1997] [Jason, 2001] được sử dụng lần đầu \n\ntiên trong lĩnh vực phân loại bởi Maron vào năm 1961 [Maron, 1961] sau đó trở nên \n\nphổ biến dùng trong nhiều lĩnh vực như trong các công cụ tìm kiếm [Rijsbergen et \n\nal, 1970], các bộ lọc mail [Sahami et al, 1998]...  \n\n\n\n \n  \n\n \n\n 14 \n\n2.2.4.1. Ý tưởng \nÝ tưởng cơ bản của cách tiếp cận Naïve Bayes là sử dụng xác suất có điều kiện \n\ngiữa từ và chủ đề để dự đoán xác suất chủ đề của một văn bản cần phân loại. Điểm \n\nquan trọng của phương pháp này chính là ở chỗ giả định rằng sự xuất hiện của tất cả \n\ncác từ trong văn bản đều độc lập với nhau. Như thế NB không tận dụng được sự phụ \n\nthuộc của nhiều từ vào một chủ đề cụ thể \n\nGiả định đó làm cho việc tính toán NB hiệu quả và nhanh chóng hơn các \n\nphương pháp khác với độ phức tạp theo số mũ vì nó không sử dụng việc kếp hợp \n\ncác từ để đưa ra phán đoán chủ đề. \n\n2.2.4.2. Công thức chính \nMục đích chính là tính được xác suất Pr( , )Cj d \u2032 , xác suất để văn bản d \u2032  nằm \n\ntrong lớp Cj . Theo luật Bayes, văn bản d \u2032  sẽ được gán vào lớp Cj  nào có xác suất \n\nPr( , )Cj d \u2032 cao nhất. Công thức sau dùng để tính Pr( , )Cj d \u2032  [Joachims, 1997] \n\n1\n\n1\n\n( , )\n\n( , )\n\nPr( ). Pr( | )\n( ) arg max\n\nPr( ). Pr( | )\n\nPr( ). Pr( | )\narg max\n\nPr( ). Pr( | )\n\nd\n\nj i j\ni\n\nBAYES d\nCj C\n\ni\nC C i\n\nTF w d\nj\n\nw F\nTF w d\n\nCj C\nC C w F\n\nC w C\nH d\n\nC w C\n\nCj w C\n\nC w C\n\n\u2032\n\n=\n\u2032\n\n∈\n\n\u2032∈ =\n\n\u2032\n\n∈\n\u2032\n\n∈\n\n\u2032∈ ∈\n\n⎛ ⎞\n⎜ ⎟\n⎜ ⎟\u2032 =\n⎜ ⎟\n\n\u2032 \u2032⎜ ⎟\n⎝ ⎠\n\n⎛ ⎞\n⎜ ⎟= ⎜ ⎟\u2032 \u2032⎜ ⎟\n⎝ ⎠\n\n∏\n\n∑ ∏\n\n∏\n∑ ∏\n\n \n\n \n\nVới  \n\n ( , )iTF w d \u2032 là số lần xuất hiện của từ iw  trong văn bản d \u2032  \n\n d \u2032  là số lượng các từ trong văn bản d \u2032  \n\n iw  là một từ trong không gian đặc trưng F  với số chiều là F  \n\n Pr( )jC được tính dựa trên tỷ lệ phần trăm của số văn bản mỗi lớp tương ứng \n\ntrong tập dữ liệu luyện : Pr( ) j jj\nC C\n\nC C\nC\n\nC C\n\u2032∈\n\n= =\n\u2032∑\n\n \n\n\n\n \n  \n\n \n\n 15 \n\n Pr( | )i jw C  được tính sử dụng phép ước lượng Laplace [Napnik, 1982] : \n\n \n1 ( , )\n\nPr( | )\n( , )\n\ni j\ni j\n\nj\nw F\n\nTF w C\nw C\n\nF TF w C\n\u2032∈\n\n+\n=\n\n\u2032+ ∑\n \n\nNgoài ra còn có các phương pháp NB khác có thể kể ra như sau ML Naive \n\nBayes, MAP Naive Bayes, Expected Naive Bayes, Bayesian Naive Bayes [Jason, \n\n2001]. Naive Bayes là một công cụ rất hiệu quả trong một số trường hợp. Kết quả \n\ncó thể rất tồi nếu dữ liệu huấn luyện nghèo nàn và các tham số dự đoán (như không \n\ngian đặc trưng) có chất lượng kém. Nhìn chung đây là một thuật toán phân loại \n\ntuyến tính thích hợp trong phân loại văn bản nhiều chủ đề. NB có ưu điểm là cài đặt \n\nđơn giản, tốc độ nhanh, dễ dàng cập nhật dữ liệu huấn luyện mới và có tính độc lập \n\ncao với tập huấn luyện, có thể sử dụng kết hợp nhiều tập huấn luyện khác nhau. Tuy \n\nnhiên NB ngoài giả định tính độc lập giữa các từ còn phải cần đến một ngưỡng tối \n\nưu để cho kết quả khả quan. Nhằm mục đích cải thiện hiệu năng của NB, các \n\nphương pháp như multiclass-boosting, ECOC [Berger, 1999] [Ghani, 2000] có thể \n\nđược dùng kết hợp. \n\n2.2.5. Neural Network (NNet) \nNnet được nghiên cứu mạnh trong hướng trí tuệ nhân tạo. Wiener là người đã sử \n\ndụng Nnet để phân loại văn bản, sử dụng 2 hướng tiếp cận : kiến trúc phẳng (không \n\nsử dụng lớp ẩn) và mạng nơron 3 lớp (bao gồm một lớp ẩn)[Wiener et al, 1995] \n\nCả hai hệ thống trên đều sử dụng một mạng nơron riêng rẽ cho từng chủ đề, \n\nNNet học cách ánh xạ phi tuyến tính những yếu tố đầu vào như từ, hay mô hình \n\nvector của một văn bản vào một chủ đề cụ thể. \n\nKhuyết điểm của phương pháp NNet là tiêu tốn nhiều thời gian dành cho việc \n\nhuấn luyện mạng nơron. \n\n2.2.5.1. Ý tưởng \nMô hình mạng neural gồm có ba thành phần chính như sau: kiến trúc \n\n(architecture), hàm chi phí (cost function), và thuật toán tìm kiếm (search \n\n\n\n \n  \n\n \n\n 16 \n\nalgorithm). Kiến trúc định nghĩa dạng chức năng (functional form) liên quan giá trị \n\nnhập (inputs) đến giá trị xuất (outputs).  \n\nKiến trúc phẳng ( flat architecture ) : Mạng phân loại đơn giản nhất ( còn gọi là \n\nmạng logic) có một đơn vị xuất là kích hoạt kết quả (logistic activation) và không \n\ncó lớp ẩn, kết quả trả về ở dạng hàm (functional form) tương đương với mô hình hồi \n\nquy logic. Thuật toán tìm kiếm chia nhỏ mô hình mạng để thích hợp với việc điều \n\nchỉnh mô hình ứng với tập huấn luyện. Ví dụ, chúng ta có thể học trọng số trong \n\nmạng kết quả (logistic network) bằng cách sử dụng không gian trọng số giảm dần \n\n(gradient descent in weight space) hoặc sử dụng thuật toán interated-reweighted \n\nleast squares là thuật toán truyền thống trong hồi quy (logistic regression).  \n\nKiến trúc mô dun (modular architecture ):  Việc sử dụng một hay nhiều lớp ẩn \n\ncủa những hàm kích hoạt phi tuyến tính cho phép mạng thiết lập các mối quan hệ \n\ngiữa những biến nhập và biến xuất. Mỗi lớp ẩn học để biểu diễn lại dữ liệu đầu vào \n\nbằng cách khám phá ra những đặc trưng ở mức cao hơn từ sự kết hợp đặc trưng ở \n\nmức trước.  \n\n \n\nHình 2. 3. Hình Kiến trúc mô đun (Modular Architecture) . Các kết quả của \n\ntừng mạng con sẽ là giá trị đầu vào cho mạng siêu chủ đề và được nhân lại với \n\nnhau để dự đoán chủ đề cuối cùng . \n\n2.2.5.2. Công thức chính \nTrong công trình của Wiener et al (1995) dựa theo khung của mô hình hồi quy, \n\nliên quan từ đặc trưng đầu vào cho đến kết quả gán chủ đề tương ứng được học từ \n\n\n\n \n  \n\n \n\n 17 \n\ntập dữ liệu. Do vậy, để phân tích một cách tuyến tính, tác giả dùng hàm sigmoid sau \n\nlàm hàm truyền trong mạng neural: \n\n1\n1\n\np\ne η−\n\n=\n+\n\n \n\nTrong đó, T xη β=  là sự kết hợp của những đặc trưng đầu vào và p phải thỏa \n\nđiều kiện (0,1)p∈  \n\n2.2.6. Linear Least Square Fit (LLSF) \nLLSF là một cách tiếp cận ánh xạ được phát triển bởi Yang và Chute vào năm \n\n1992 [Yang & Chute, 1992]  Đầu tiên, LLSF được Yang và Chute  thử nghiệm \n\ntrong lĩnh vực xác định từ đồng nghĩa sau đó sử dụng trong phân loại vào năm 1994 \n\n[Yang & Chute, 1994]. Các thử nghiệm của Ỵang cho thấy hiệu suất phân loại của \n\nLLSF có thể ngang bằng với phương pháp kNN kinh điển. \n\n2.2.6.1. Ý tưởng \nLLSF sử dụng phương pháp hồi quy để học từ tập huấn luyện và các chủ đề có \n\nsẵn [Yang & Chute, 1994]. Tập huấn luyện được biểu diễn dưới dạng một cặp \n\nvector đầu vào và đầu ra như sau : \n\nVector đầu vào một văn bản bao gồm các từ và trọng số \n\nVector đầu ra gồm các chủ đề cùng với trọng số nhị phân của văn bản ứng với \n\nvector đầu vào \n\nGiải phương trình các cặp vector đầu vào/ đầu ra, ta sẽ được ma trận đồng hiện \n\ncủa hệ số hồi quy của từ và chủ đề(matrix of word-category regression coefficients) \n\n2.2.6.2. Công thức chính \n2arg minLS\n\nF\nF FA B= −  \n\nTrong đó  \n\n A, B là ma trận đại diện tập dữ liệu huấn luyện ( các cột trong ma trận tương \n\nứng là các vector đầu vào và đầu ra ) \n\n FLS là ma trận kết quả chỉ ra một ánh xạ từ một văn bản bất kỳ vào vector của \n\nchủ đề đã gán trọng số \n\n\n\n \n  \n\n \n\n 18 \n\nNhờ vào việc sắp xếp trọng số của các chủ đề, ta được một danh sách chủ đề có \n\nthể gán cho văn bản cần phân loại. Nhờ đặt ngưỡng lên trọng số của các chủ đề mà \n\nta tìm được chủ đề thích hợp cho văn bản đầu vào. Hệ thống tự động học các \n\nngưỡng tối ưu cho từng chủ đề, giống với kNN. Mặc dù LLSF và kNN khác nhau \n\nvề mặt thống kê, nhưng ta vẫn tìm thấy điểm chung ở hoạt động của hai phương \n\npháp là việc học ngưỡng tối ưu. \n\n2.2.7. Centroid- based vector \nLà một phương pháp phân loại đơn giản, dễ cài đặt và tốc độ nhanh do có độ \n\nphức tạp tuyến tính O(n) [Han, Karypis 2000] \n\n2.2.7.1. Ý tưởng \nMỗi lớp trong dữ liệu luyện sẽ được biểu diễn bởi một vector trọng tâm. Việc \n\nxác định lớp của một văn bản thử bất kì sẽ thông qua viêc tìm vector trọng tâm nào \n\ngần với vector biểu diễn văn bản thử nhất. Lớp của văn bản thử chính là lớp mà \n\nvector trọng tâm đại diện. Khoảng cách được tính theo độ đo cosine. \n\n2.2.7.2. Công thức chính \nCông thức tính vector trọng tâm của lớp i  \n\n{ }\n\n1\n{ }\n\nj\n\ni j\nd i\n\nC d\ni ∈\n\n= ∑  \n\nĐộ đo khoảng cách giữa vector x  và iC  \n\n( )cos ,\n*\n\ni\ni\n\ni\n\nx Cx C\nx C\n⋅\n\n=  \n\nTrong đó : \n\n x  là vector văn bản cần phân loại \n\n { }i là tập hợp các văn bản thuộc chủ đề Ci \n\nChủ đề của x  là Cx thõa cos( , ) arg max(cos( , ))x ix C x C=  \n\n\n\n \n  \n\n \n\n 19 \n\n2.3. Kết luận \nCác thuật toán phân loại trên từ thuật toán phân loại 2 lớp (SVM) đến các thuật \n\ntoán phân loại đa lớp (kNN) đều có điểm chung là yêu cầu văn bản phải được biểu \n\ndiễn dưới dạng vector đặc trưng. Ngoài ra các thuật toán như kNN,NB,LLSF đều \n\nphải sử dụng các ước lượng tham số và ngưỡng tối ưu trong khi đó thuật toán SVM \n\ncó thể tự tìm ra các tham số tối ưu này. Trong các phương pháp SVM là phương \n\npháp sử dụng không gian vector đặc trưng lớn nhất (hơn 10000 chiều) trong khi đó \n\nchỉ là 2000 đối với NB, 2415 cho kNN và LLSF, 1000 cho Nnet [Yang, 1997]. Thời \n\ngian huấn luyện cũng khác nhau đối với từng phương pháp, Nnet (sử dụng mỗi \n\nmạng tương ứng một chủ đề) và SVM là hai phương pháp có thời gian huấn luyện \n\nlâu nhất trong khi đó kNN,NB,LLSF và Centroid là các phương pháp có tốc độ \n\n(thời gian huấn luyện, phân loại) nhanh và cài đặt dễ dàng. \n\nVề hiệu suất, dựa vào thử nghiệm của Yang [Yang, Liu, 1997] trên tập dữ liệu \n\nReuter-21578 với hơn 90 chủ đề và trên 7769 văn bản, ta có thể sắp xếp các phương \n\npháp phân loại văn bản theo thứ tự như sau SVM > kNN >> {LLSF,NB,Nnet}. Tuy \n\nnhiên kết quả trên có thể không còn đúng khi áp dụng thử nghiệm phân loại trên \n\nTiếng Việt. Các lý do chính như sau : \n\nThứ nhất:  không có một tập dữ liệu chuẩn dành riêng cho việc phân loại.  \n\nThứ hai: hiện tại chưa có chuẩn thống nhất nào cho vấn đề font và dấu câu cho \n\nTiếng Việt.  \n\nThứ ba: viêc biểu diễn văn bản Tiếng Việt bằng vector đặc trưng gặp nhiều trở \n\nngại do bị phụ thuộc nhiều vào các phương pháp tách từ. Trong khi đó các phương \n\npháp này không đạt được hiệu quả cao như trong tiếng Anh.  \n\nĐể có thể áp dụng các phương pháp phân loại văn bản đã được sử dụng thành \n\ncông trên nhiều ngôn ngữ (Anh, Pháp,\u2026) như đã liệt kê trên, điều kiện tiên quyết là \n\nphải tìm ra một phương pháp tách từ tốt để thông qua đó cải thiện hiệu quả của các \n\nthuật toán phân loại. Trong tiếng Anh, đơn vị nhỏ nhất là \u201ctừ\u201d nên việc tách từ trở \n\nnên khá đơn giản, trong khi đối với một số ngôn ngữ như tiếng Hoa, Nhật, Hàn \n\nQuốc... và Tiếng Việt của chúng ta phải xử lý hoàn toàn khác do đơn vị nhỏ nhất lại \n\n\n\n \n  \n\n \n\n 20 \n\nlà \u201ctiếng\u201d. Do đó, trước khi thực hiện phân loại, chúng ta phải tìm hiểu về các \n\nhướng tiếp cận cho việc tách từ tiếng Việt, một vấn đề khá thú vị không kém các \n\nphương pháp phân loại. \n\n\n\n \n  \n\n \n\n 21 \n\n  \n\nCChhưươơnngg  33  \n\nCCÁÁCC  PPHHƯƯƠƠNNGG  PPHHÁÁPP  \n\nTTÁÁCCHH  TTỪỪ  TTIIẾẾNNGG  VVIIỆỆTT  \n\nHHIIỆỆNN  NNAAYY  \nTại sao tách từ tiếng Việt là một thách thức? \n\nSo sánh giữa tiếng Việt và tiếng Anh \n\nNhận xét \n\nBối cảnh các phương pháp tách từ hiện nay \n\nBối cảnh chung \n\nCác hướng tiếp cận dựa trên từ  \n\nCác hướng tiếp cận dựa trên ký tự \n\nMột số phương pháp tách từ tiếng Việt hiện nay \n\nPhương pháp Maximum Matching: forward/backward \n\nPhương pháp giải thuật học cải tiến \n\nMô hình tách từ bằng WFST và mạng Neural \n\nPhương pháp quy hoạch động \n\nPhương pháp tách từ tiếng Việt dựa trên thống kê từ Internet \n\nvà thuật toán di truyền \n\nKết luận \n\n\n\n \n  \n\n \n\n 22 \n\nChương 3. CÁC PHƯƠNG PHÁP TÁCH TỪ TIẾNG VIỆT \nHIỆN NAY \n\n3.1. Tại sao tách từ tiếng Việt là một thách thức? \n\n3.1.1. So sánh giữa tiếng Việt và tiếng Anh \nDựa vào các đặc điểm của tiếng Anh và tiếng Việt được trình bày trong [Đinh \n\nĐiền, 2004], chúng em lập bảng so sánh các đặc điểm chủ yếu giữa tiếng Anh và \n\ntiếng Việt như sau \n\nĐặc điểm của Tiếng Việt Đặc điểm của Tiếng Anh \n\n Được xếp là loại hình đơn lập \n\n(isolate) hay còn gọi là loại hình \n\nphi hình thái, không biến hình, \n\nđơn tiết \n\n Từ không biến đổi hình thái, ý \n\nnghĩa ngữ pháp nằm ở ngoài từ \n\nVí dụ : Chị ngã em nâng và Em ngã \n\n chị nâng \n\n Phương thức ngữ pháp chủ yếu: \n\ntrật tự từ và hư từ. \n\nVí dụ: Gạo xay và Xay gạo; đang \n\n học và học rồi ; \u201cnó bảo sao \n\n không tới\u201d, \u201csao không bảo nó \n\n tới\u201d, \u201csao không tới bảo nó\u201d.. \n\n Ranh giới từ không được xác \n\nđịnh mặc nhiên bằng khoảng \n\ntrắng \n\n \n\n Tồn tại loại từ đặc biệt \u201c từ chỉ \n\nloại\u201d (classifier) hay còn gọi là \n\n  Là loại hình biến cách (flexion) \n\nhay còn gọi là loại hình khuất \n\nchiết \n\n \n\n Từ có biến đổi hình thái, ý nghĩa \n\nngữ pháp nằm ở trong từ. \n\nVí dụ: I see him và He sees me. \n\n \n\n Phương thức ngữ pháp chủ yếu \n\nlà : phụ tố.  \n\nVí dụ: studying và studied \n\n \n\n \n\n \n\n Kết hợp giữa các hình vị là chặt \n\nchẽ, khó xác định, được nhận \n\ndiện bằng khoảng trắng hoặc dấu \n\ncâu. \n\n Hiện tượng cấu tạo bằng từ ghép \n\nthêm phụ tố (affix) vào gốc từ là \n\n\n\n \n  \n\n \n\n 23 \n\nphó danh từ chỉ loại kèm theo \n\nvới danh từ, như: cái bàn, cuốn \n\nsách, bức thư, con chó, con sông, \n\nvì sao\u2026 \n\n Có hiện tượng láy và nói lái \n\ntrong tiếng Việt  \n\nVí dụ: lấp lánh, lung linh \n\n Hiện đại -> hại điện, thầy giáo-> \n\n tháo giầy\u2026 \n\nrất phổ biến. \n\nVí dụ: anticomputerizational ( anti-\n\n compute-er-ize-ation-al) \n\n \n\n \n\nBảng 3. 1. So sánh giữa tiếng Việt và tiếng Anh \n\n3.1.2. Nhận xét \n Tiếng Việt là loại hình phi hình thái nên việc phân biệt loại từ (danh từ, động \n\ntừ, tính từ \u2026) và ý nghĩa từ là rất khó, cho dù có sử dụng từ điển. \n\n Việc tiền xử lý văn bản (tách từ, tách đoạn, tách câu\u2026) sẽ thêm phức tạp với \n\nphần xử lý các hư từ, phụ từ, từ láy\u2026 \n\n Phương thức ngữ pháp chủ yếu là trật tự từ nên nếu áp dụng phương pháp \n\ntính xác suất xuất hiện của từ có thể không chính xác như mong đợi \n\n Ranh giới từ không được xác định mặc nhiên bằng khoảng trắng. Điều này \n\nkhiến cho việc phân tích hình thái (tách từ) tiếng Việt trở nên khó khăn. Việc \n\nnhận diện ranh giới từ là quan trọng làm tiền đề cho các xử lý tiếp theo sau \n\nđó, như: kiểm lỗi chính tả, gán nhãn từ loại, thống kê tần suất từ,\u2026 \n\n Vì giữa tiếng Anh và tiếng Việt có nhiều điểm khác biệt nên chúng ta không \n\nthể  áp dụng y nguyên các thuật toán tiếng Anh cho tiếng Việt \n\n3.2. Bối cảnh các phương pháp tách từ hiện nay \n\n3.2.1. Bối cảnh chung \nDựa trên cơ sở thống kê các phương pháp tách từ trên tiếng Hoa của [Foo and \n\nLi, 2004], chúng em xin trình bày bối cảnh các phương pháp tách từ hiện nay cho \n\ntiếng Việt như sau: \n\n\n\n \n  \n\n \n\n 24 \n\n \n\nHình 3.4. Các hướng tiếp cận cơ bản trong tách từ tiếng Hoa và các hướng \n\ntiếp cận hiện tại được công bố trong tách từ tiếng Việt \n\n3.2.2. Các hướng tiếp cận dựa trên từ (Word-based approaches) \nHướng tiếp cận dựa trên từ với mục tiêu tách được các từ hoàn chỉnh trong câu. \n\nHướng tiếp cận này có thể chia ra là ba hướng: dựa trên thống kê (statistics-based), \n\ndựa trên từ điển (dictionary-based) và hydrid (kết hợp nhiều phương pháp với hy \n\nvọng đạt được những ưu điểm của các phương pháp này) \n\n \n\n3.2.2.1. Các công trình tách từ tiếng Hoa \nHướng tiếp cận dựa trên thống kê (statistics-based) dựa trên các thông tin như \n\ntần số xuất hiện của từ trong tập dữ liệu huấn luyện đầu. Hướng tiếp cận này đặc \n\nHybrid \n\nChinese segmentation \n\nCharacter-based Word-based \n\nUnigram N-gram Statistic Dictionary \n\nVietnamese segmentation \n\nLê An Hà (03) H. Nguyễn et al (05) \n\nFull word / Phrase Component \n\nShortest Match Longest Match Overlap Match \n\nĐinh Điền \n\net al (01) \n\nLuận văn này (05) \n\n\n\n \n  \n\n \n\n 25 \n\nbiệt dựa trên tập ngữ liệu huấn luyện, nhờ vậy nên hướng tiếp cận này tỏ ra rất linh \n\nhoạt và hữu dụng trong nhiều lãnh vực riêng biệt [Nie et al.,1996]. \n\nHướng tiếp cận dựa trên từ điển (dictionary-based) thường được sử dụng trong \n\ntách từ. Ý tưởng của hướng tiếp cận này là những cụm từ được tách ra từ văn bản \n\nphải khớp với các từ trong từ điển. Những hướng tiếp cận khác nhau sẽ sử dụng \n\nnhững loại từ điển khác nhau. Hướng tiếp cận \u201cfull word / phrase\u201d cần sử dụng một \n\ntừ điển hoàn chỉnh để có thể tách được đầy đủ các từ hoặc ngữ trong văn bản, trong \n\nkhi đó, hướng tiếp cận thành phần (component) lại sử dụng từ điển thành phần \n\n(component dictionary)[Wu & Tseng, 1993] . Từ điển hoàn chỉnh chứa tất cả các từ \n\nvà ngữ được dùng trong tiếng Hoa, trong khi từ điển thành phần (component \n\ndictionary) chỉ chứa các thành phần của từ và ngữ như hình vị và các từ đơn giản \n\ntrong tiếng Hoa. \n\nTùy theo cách chọn để khớp từ (match), hướng tiếp cận \u201cfull word/ phrase\u201d có \n\nthể được chia ra thành khớp dài nhất (longest match \u2013 bằng cách duyệt văn bản tuần \n\ntự  để tìm ra từ dài nhất có trong từ điển) và khớp ngắn nhất (shortest match \u2013 bằng \n\ncách duyệt văn bản tuần tự và chọn từ đầu tiên có trong từ điển ). Ngoài hai cách \n\nthông dụng nhất là khớp dài nhất và khớp ngắn nhất, He et. al. (1996)còn đề nghị \n\nmột cách thứ ba là cách kết hợp (overlap). Trong cách kết hợp này, mỗi chuỗi được \n\nphát sinh từ văn bản có thể chồng lấp lên chuỗi khác nếu chuỗi đó có trong từ điển  \n\n(ví dụ : học sinh học, ta sẽ có các token là \u201chọc sinh\u201d, \u201csinh học\u201d chứ không phải \n\nchỉ có một cách như khớp dài nhất hoặc khớp ngắn nhất). Tại thời điểm hiện tại, \n\nhướng tiếp cận khớp dài nhất được xem là phương pháp quan trọng và hiệu quả \n\nnhất trong hướng tiếp cận dựa trên từ điển [Foo & Li, 2002]. \n\nTuy nhiên, hướng tiếp cận dựa trên từ điển vẫn có một số hạn chế trong việc \n\ntách từ vì thực hiện hoàn toàn dựa trên một từ điển hoàn chỉnh. Trong thực tế, để \n\nxây dựng một bộ từ điển thật sự hoàn hảo chứa tất cả các từ tiếng Hoa là không thật \n\nsự cần thiết và khó thành hiện thực. Hướng tiếp cận dựa trên thành phần \n\n(component) phát triển cũng với mục đích làm nhẹ bớt mặt hạn chế này bằng cách \n\nnối các hình vị và từ thành những từ và ngữ hoàn chỉnh [Wu & Tseng,1993,1995].  \n\n\n\n \n  \n\n \n\n 26 \n\nHướng tiếp cận Hybrid với mục đích kết hợp các hướng tiếp cận khác nhau để \n\nthừa hưởng được ưu điểm của nhiều kỹ thuật khác nhau. Hướng tiếp cận này thường \n\nkết hợp giữa hướng dựa trên thống kê và dựa trên từ điển nhằm lấy được ưu thế \n\nchung và các mặt vượt trội riêng của mỗi phương pháp. Một số thành công của \n\nphương pháp này được trình bày trong [Nie et al, 1996]. Mặc dù hướng tiếp cận \n\nhibrid có được những ưu điểm của phương pháp khác nhưng lại gặp phải các phức \n\ntạp khác như thời gian xử lý, không gian đĩa và đòi hỏi nhiều chi phí. \n\n3.2.2.2. Các công trình tách từ tiếng Việt \nCông trình của Đinh Điền et al (2001) đã cố gắng xây dựng tập ngữ liệu huấn \n\nluyện riêng (khoảng 10M) dựa trên các thông tin có nguồn gốc từ Internet như tin \n\ntức, e-book\u2026 Tuy nhiên tập ngữ liệu vẫn còn khá nhỏ để đảm bảo dung lượng và \n\nđộ phong phú cho việc tách từ. Mặc khác, do tập ngữ liệu được xây dựng một cách \n\nthủ công, nên sẽ phần nào mang tính chủ quan. Và một hạn chế nữa là việc đánh giá \n\nlại được những thay đổi hằng ngày rất chậm, và có thể xảy ra hiện tượng flip-flop ( \n\nhiện tượng khi khắc phục lỗi này lại dẫn đến lỗi khác không ngờ tới) \n\nỞ hướng tiếp cận dựa trên từ điển, các từ được tách phải tương ứng với những từ \n\ncó trong từ điển. Hiện tại, ta vẫn chưa xây dựng được một bộ từ điển Việt Nam \n\nchứa toàn bộ các từ và ngữ. \n\n3.2.3. Các hướng tiếp cận dựa trên ký tự (Character-based approaches) \nCần phân biệt rằng hình vị nhỏ nhất của tiếng Việt là \u201ctiếng\u201d, được cấu tạo bởi \n\nnhiều ký tự trong bảng chữ cái, trong khi hình vị nhỏ nhất của tiếng Hoa là một ký \n\ntự. Vì chữ viết tiếng Hoa là chữ tượng hình, không dựa trên bảng chữ cái Latin như \n\ntiếng Việt nên trong trường hợp tiếng Hoa, người ta xét hình vị là \u201cký tự\u201d. Tuy \n\nnhiên, mỗi ký tự (character) trong tiếng Hoa được phát âm thành một \u201ctiếng\u201d, nên  \n\nxét về mặt âm vị, ta có thể xem \u201ctiếng\u201d trong tiếng Hoa và tiếng Việt là tương tự \n\nnhau. Vì vậy, để tránh sự hiểu nhằm ý nghĩa giữa ký tự trong tiếng Hoa và tiếng \n\ntrong tiếng Việt, chúng em xin phép dùng từ \u201ctiếng\u201d để chỉ cho ký tự tiếng Hoa và \n\ntiếng trong tiếng Việt ở một số trường hợp trình bày về cách tách từ. \n\n\n\n \n  \n\n \n\n 27 \n\nMặc dù có cách viết khác nhau, nhưng về cấu tạo từ và ngữ pháp của tiếng Hoa \n\nvà tiếng Việt có nhiều điểm tương đồng nhau. Xét về nguồn gốc, tiếng Việt là hình \n\nthức phiên âm của chữ Nôm do nhân dân ta sáng tạo nên, vốn có nguồn gốc từ tiếng \n\nTrung Hoa thời xưa. \n\n3.2.3.1.  Các công trình tách từ tiếng Hoa \nHướng tiếp cận này đơn thuần rút trích một số lượng nhất định các tiếng trong \n\nvăn bản như rút trích từ 1 ký tự (unigram) hay nhiều ký tự (n-gram). Mặc dù hướng \n\ntiếp cận này tương đối đơn giản hơn các hướng khác, nhưng nó cũng mang lại nhiều \n\nkết quả khả quan trong tiếng Hoa [Foo and Li, 2004]. \n\nHướng tiếp cận dựa trên một ký tự (unigram) chia văn bản ra các ký tự đơn lẻ để \n\nthực hiện việc tách từ. Ngày nay, hầu như người ta không sử dụng phương pháp này \n\nnhư hướng tiếp cận chính trong việc tách từ nữa. \n\nHướng tiếp cận dựa trên nhiều ký tự (n-gram) chia văn bản ra thành nhiều chuỗi, \n\nmỗi chuỗi gồm hai, ba ký tự trở lên. So với hướng tiếp cận dựa trên một ký tự, \n\nhướng tiếp cận này cho nhiều kết quả ổn định hơn [Kwok, 1997a;1997b]. Do hơn \n\n75% từ trong tiếng Hoa là từ gồm hai ký tự, nên các phương pháp phổ biến là dựa \n\ntrên việc tách từ gồm hai ký tự sẽ cho kết quả nhiều từ đúng hơn [Wu & Tseng, \n\n1993].Ví dụ, ta có một câu ABCDEF, hướng tiếp cận trên sẽ chia câu thành AB CD \n\nEF.  Một biến thể của phương pháp tách từ hai ký tự là hướng tiếp cận cách chia \n\nchồng lên nhau, ví dụ ta có ABCDEFG, hướng tiếp cận này sẽ chia thành AB BC \n\nCD DE DF FG. Nhóm nghiên cứu của Swiss Federal Institute of Technology (ETH) \n\náp dụng phương pháp biến thể và có thể cải tiến là sử dụng thêm danh sách  stoplist \n\n(tương tự như các hư từ trong tiếng Việt như à, ơi..) để tách các ngữ của câu trước \n\nkhi tách từ [Mateev et al, 1997]. Nhờ vậy, mà kích thước văn bản cần tách từ được \n\ngiảm xuống nhưng có khuyết điểm là nó có thể làm mất ý nghĩa của câu gốc. \n\nƯu điểm nổi bật của hướng tiếp cận dựa trên nhiều ký tự là tính đơn giản và dễ \n\nứng dụng, ngoài ra còn có thuận lợi là ít tốn chi phí cho việc tạo chỉ mục (index) và \n\nxử lý nhiều câu truy vấn (query processing). Qua nhiều công trình nghiên cứu, \n\n\n\n \n  \n\n \n\n 28 \n\nhướng tiếp cận tách từ dựa trên nhiều ký tự, đặc biệt là cách tách từ hai ký tự được \n\nxem là sự lựa chọn thích hợp[Foo & Li, 2002]. \n\n3.2.3.2.  Các công trình tách từ tiếng Việt \nTrong trường hợp tiếng Việt, hướng tiếp cận này được xem là hướng tiếp cận \n\ndựa trên tiếng, khác với tiếng Hoa là dựa trên ký tự. Ở Việt Nam, hướng tiếp cận \n\nnày cũng đã có một số công trình được phổ biến. [Lê An Hà, 2003] xây dựng tập \n\nngữ liệu thô 10M, sử dụng phương pháp quy hoạch động để cực đại hóa tổng xác \n\nsuất xuất hiện của các ngữ. Gần đây nhất có thể kể đến công trình của [H. Nguyen \n\net al, 2005], thay vì sử dụng ngữ liệu thô, công trình của họ có sáng tạo là lấy thông \n\ntin thống kê từ Internet và sử dụng thuật toán di truyền (Genetic Algorithm) để tìm \n\ncách tách từ tối ưu nhất. Mặc dù công trình của họ còn mang tính sơ bộ, và việc thử \n\nnghiệm chưa hoàn chỉnh, nhưng chúng em tin rằng ý tưởng mới lạ này đem lại \n\nnhiều hứa hẹn khả quan.  \n\nHướng tiếp cận cho việc tách từ của chúng em mở rộng trên ý tưởng này, ngoài \n\nra, chúng em thực hiện một số thay đổi quan trọng nhằm nâng cao tính chính xác \n\ncủa việc tách từ. Thêm nữa, chúng em đã thực hiện một số thử nghiệm trên số lượng \n\ndữ liệu đáng kể nhằm đưa ra các đánh giá một cách bao quát hơn, chính xác hơn. \n\n3.3. Một số phương pháp tách từ tiếng Việt hiện nay \n\n3.3.1. Phương pháp Maximum Matching: forward/backward \n\n3.3.1.1. Nội dung \nPhương pháp khớp tối đa (Maximum Matching) còn gọi là Left Right Maximum \n\nMatching (LRMM). Theo phương pháp này, ta sẽ duyệt một ngữ hoặc câu từ trái \n\nsang phải và chọn từ có nhiều âm tiết nhất có mặt trong từ điển, rồi cứ thể tiếp tục \n\ncho từ kế tiếp cho đến hết câu. Thuật toán được trình bày trong [Chih-Hao Tsai, \n\n2000] \n\nDạng đơn giản được dùng giải quyết nhập nhằng từ đơn. Giả sử có một chuỗi ký \n\ntự (tương đương với chuỗi tiếng trong tiếng Việt) C1, C2, ... , C2. Ta bắt đầu từ đầu \n\nchuỗi. Đầu tiên kiểm tra xem C1, có phải là từ hay không, sau đó kiểm tra xem C1C2 \n\n\n\n \n  \n\n \n\n 29 \n\ncó phải là từ hay không. Tiếp tục tìm cho đến khi tìm được từ dài nhất. Từ có vẻ \n\nhợp lý nhất sẽ là từ dài nhất. Chọn từ đó, sau đó tìm tiếp như trên cho những từ còn \n\nlại cho đến khi xác định được toàn bộ chuỗi từ. \n\nDạng phức tạp: Quy tắc của dạng này là phân đoạn có vẻ hợp lý nhất là đoạn ba \n\ntừ với chiều dài tối đa. Thuật toán bắt đầu như dạng đơn giản. Nếu phát hiện ra \n\nnhững cách tách từ gây nhập nhằng (ví dụ, C1 là từ và C1C2 cũng là từ), ta xem các \n\nchữ kế tiếp để tìm tất cả các đoạn ba từ có thể có bắt đầu với C1 hoặc C1C2. Ví dụ ta \n\nđược những đoạn sau: \n\n C1  C2   C3 C4 \n\n C1C2   C3 C4  C5 \n\n C1C2   C3 C4  C5 C6 \n\nChuỗi dài nhất sẽ là chuỗi thứ ba. Vậy từ đầu tiên của chuỗi thứ ba (C1C2) sẽ \n\nđược chọn. Thực hiện lại các bước cho đến khi được chuỗi từ hoàn chỉnh.  \n\n3.3.1.2. Ưu điểm \n Với cách này, ta dễ dàng tách được chính xác các ngữ/câu như \u201c hợp tác xã || \n\nmua bán\u201d, \u201cthành lập || nước || Việt Nam || dân chủ || cộng hòa\u201d  \n\n Cách tách từ đơn giản, nhanh, chỉ cần dựa vào từ điển \n\n Trong tiếng Hoa, cách này đạt được độ chính xác 98,41% [Chih-Hao Tsai, \n\n2000]. \n\n3.3.1.3. Hạn chế \n Độ chính xác của phương pháp phụ thuộc hoàn toàn vào tính đủ và tính \n\nchính xác của từ điển \n\n Phương pháp này sẽ tách từ sai trong các trường hợp \u201c học sinh || học sinh|| \n\nhọc\u201d, \u201cmột || ông || quan tài || giỏi\u201d, \u201ctrước || bàn là || một || ly || nước\u201d\u2026  \n\n\n\n \n  \n\n \n\n 30 \n\n3.3.2. Phương pháp giải thuật học cải biến (Transformation-based \nLearning, TBL) \n\n3.3.2.1. Nội dung \nĐây là cách tiếp cận dựa trên ngữ liệu đã đánh dấu. Theo cách tiếp cận này, để \n\nhuấn luyện cho máy tính biết cách nhận diện ranh giới từ tiếng Việt, ta có thể cho \n\nmáy \u201chọc\u201d trên ngữ liệu hàng vạn câu tiếng Việt đã được đánh dấu ranh giới từ \n\nđúng.  \n\n Sau khi học xong, máy sẽ xác định được các tham số (các xác suất) cần thiết \n\ncho mô hình nhận diện từ. \n\n3.3.2.2. Ưu điểm \n Đặc điểm của phương pháp này là khả năng tự rút ra quy luật của ngôn ngữ \n\n Nó có những ưu điểm của cách tiếp cận dựa trên luật  vì cuối cùng nó cũng \n\ndựa trên luật được rút ra) nhưng nó khắc phục được khuyết điểm của việc \n\nxây dựng các luật một cách thủ công bởi các chuyên gia. \n\n Các luật được thử nghiệm tại chỗ để đánh giá độ chính xác và hiệu quả của \n\nluật (dựa trên ngữ liệu huấn luyện) \n\n Có khả năng khử được một số nhập nhằng như \u201cThe singer sang a lot of \n\na??as\u201d, thì hệ có thể xác định được \u201ca??as\u201d là \u201carias\u201d (dân ca) thay vì \u201careas\u201d \n\n(khu vực) của các mô hình ngôn ngữ theo kiểu thống kê.  \n\n3.3.2.3. Hạn chế \n Phương pháp này \u201cdùng ngữ liệu có gán nhãn ngôn ngữ để học tự động các \n\nqui luật đó\u201d[Đinh Điền, 2004]. Như đã nói ở chương 1, việc xây dựng một \n\ntập ngữ liệu đạt được đầy đủ các tiêu chí của tập ngữ liệu trong tiếng Việt là \n\nmột điều rất khó, tốn kém nhiều về mặt thời gian và công sức. \n\n Hệ phải trải qua một thời gian huấn luyện khá lâu để có thể rút ra các luật \n\ntương đối đầy đủ \n\n Cài đặt phức tạp \n\n\n\n \n  \n\n \n\n 31 \n\n3.3.3. Mô hình tách từ bằng WFST và mạng Neural  \n\n3.3.3.1. Nội dung \nMô hình mạng chuyển dịch trạng thái hữu hạn có trọng số WFST (Weighted  \n\nfinit\u2013state Transducer) đã được [Richard et al, 1996]  áp dụng để tách từ tiếng \n\nTrung Quốc. Ý tưởng cơ bản là áp dụng WFST kết hợp với trọng số là xác suất xuất \n\nhiện của mỗi từ trong ngữ liệu. Dùng WFST để duyệt qua câu cần xét. Cách duyệt \n\ncó trọng số lớn nhất sẽ là cách tách từ được chọn. Giải pháp này cũng đã đượng áp \n\ndụng trong [Đinh Điền et al, 2001] kèm với mạng neutral để khử nhập nhằng. Hệ \n\nthống tách từ tiếng Việt của [Đinh Điền, 2001] gồm hai tầng: tầng WFST ngoài việc \n\ntách từ còn xử lý thêm các vấn đề liên quan đến đặc thù của tiếng Việt như từ láy, \n\ntên riêng\u2026 và tầng mạng neural dùng để khử nhập nhằng nếu có. \n\n \n\nHình 3.5. Sơ đồ hệ thống WFST \n\nBắt đầu\n\nTiền xử lý \n\nBắt đầu\n\nTiền xử lý \n\nTiền xử lý \n\nt <  T0 \nY\n\n\n\n \n  \n\n \n\n 32 \n\n Tầng WFST :gồm có ba bước \n\n Xây dựng từ điển trọng số : theo mô hình WFST, việc phân đoạn từ \n\nđược xem như là một sự chuyển dịch trạng thái có xác suất \n\n(Stochastic Transduction). Chúng ta miêu tả từ điển D là một đồ thị \n\nbiến đổi trạng thái hữu hạn có trọng số.  Giả sử: \n\n H: là tập các từ chính tả tiếng Việt (còn gọi là \u201ctiếng\u201d) \n\n P: là từ loại của từ (POS: Part \u2013 Of \u2013 Speech). \n\nMỗi cung của D có thể là: \n\n Từ một phần tử của H tới một phần tử của H, hoặc \n\n Từ ε (ký hiệu kết thúc từ) tối một phần tử của P \n\nCác nhãn trong D biểu thị một chi phí ước lượng (estimated cost) \n\nbằng công thức :    \n\nCost = - log(f/N) \n\n Với f: tần số của từ, N: kích thước tập mẫu. \n\nĐối với các trường hợp từ mới chưa gặp, tác giả áp dụng xác suất \n\ncó điều kiện Goog-Turning (Baayen) để tính toán trọng số. \n\n Xây dựng các khả năng phân đoạn từ : Để giảm sự bùng nổ tổ hợp khi \n\nsinh ra các dãy các từ có thể từ một dãy các tiếng trong câu, tác giả đề \n\nxuất một phương pháp mới là kết hợp dùng từ điển để hạn chế sinh ra \n\ncác bùng nổ tổ hợp. Khi phát hiện thấy một cách phân đoạn từ nào đó \n\nkhông phù hợp (không có trong từ điển, không phải là từ láy, không \n\nphải là danh từ riêng\u2026) thì tác giả loại bỏ các nhánh xuất phát từ cách \n\nphân đoạn từ đó. \n\n Lựa chọn khả năng phân đoạn từ tối ưu : Sau khi được một danh sách \n\ncác cách phân đoạn từ có thể có của câu, tác giả chọn trường hợp phân \n\nđoạn từ có trọng số bé nhất như sau: \n\n Ví dụ: input  = \u201cTốc độ truyền thông tin sẽ tăng cao\u201d \n\no Dictionary    \u201ctốc độ\u201d 8.68 \n\n \u201ctruyền\u201d 12.31 \n\n\n\n \n  \n\n \n\n 33 \n\n \u201ctruyền thông\u201d  1231 \n\n \u201cthông tin\u201d 7.24 \n\n \u201ctin\u201d 7.33 \n\n \u201csẽ\u201d 6.09 \n\n \u201ctăng\u201d 7.43 \n\n \u201ccao\u201d 6.95 \n\nId(D)*D* = \u201cTốc độ # truyền thông # tin # sẽ # tăng # cao.\u201d    48.79 \n\n(8.68 +12.31 + 7.33 + 6.09 + 7.43 +6.95 = 48.79 ) \n\nId(D)*D* = \u201cTốc độ # truyền # thông  tin # sẽ # tăng # cao.\u201d  48.70 \n\n(8.68 +12.31 + 7.24 + 6.09 + 7.43 +6.95 = 48.79 ) \n\nDo đó, ta có được phân đoạn tối ưu là \u201cTốc độ # truyền # thông  tin # sẽ # tăng # \n\ncao.\u201d \n\n Tầng mạng neural : Mô hình mạng neural mà tác giả đề xuất được dùng để \n\nlượng giá 3 dãy từ loại: NNV,NVN, VNN (N: Noun, V: Verb). Mô hình này \n\nđược học bằng chính các câu mà cách phân đoạn từ vẫn còn nhập nhằng sau \n\nkhi qua mô hình thứ nhất. \n\n3.3.3.2. Ưu điểm \n Độ chính xác trên 97% [Đinh Điền et al, 2001] \n\n Mô hình cho kết quả phân đoạn từ với độ tin cậy (xác suất) kèm theo. \n\n Nhờ có tầng mạng neural nên mô hình có thể khử nhập nhằng các trường hợp \n\ntầng WFST cho ra nhiều ứng viên có kết quả ngang nhau \n\n Phương pháp này cho kết quả với độ chính xác khá cao vì mục đích của tác \n\ngiả muốn nhắm đến việc tách từ thật chính xác để là nền tảng cho việc dịch \n\nmáy.  \n\n3.3.3.3. Hạn chế \n Cũng tương tự như phương pháp TBL, việc xây dựng tập ngữ liệu là rất công \n\nphu, nhưng thật sự rất cần thiết để phục vụ cho mục đích dịch máy sau này \n\ncủa tác giả. \n\n\n\n \n  \n\n \n\n 34 \n\n3.3.4. Phương pháp quy hoạch động (dynamic programming)  \n\n3.3.4.1. Nội dung \nPhương pháp quy hoạch động [Le An Ha, 2003] chỉ sử dụng tập ngữ liệu thô để \n\nlấy thông tin về tần số thống kê của từ , làm tăng độ tin cậy cho việc tính toán. Việc \n\ntính toán bắt đầu với những đơn vị chắc chắn như câu, các ngữ (chunk) được phân \n\ncách bởi dấu câu ( như dấu phẩy, gạch nối, chấm phẩy\u2026) vì những thành phần này \n\nkhông có tính nhập nhằng ngay cả trong văn viết cũng như nói. Sau đó, tác giả cố \n\ngắng tối đa hoá xác suất của ngữ bằng cách tìm ra nhiều cách tách ngữ đó. Cách \n\ntách cuối cùng là cách tách là cho ngữ đó có xác suất cao nhất. Ý tưởng của cách \n\ntách từ này cho một ngữ cần tách từ, ta phải tìm ra các tổ hợp từ tạo nên ngữ đó sao \n\ncho tổ hợp đó đạt được xác suất tối đa. Tuy nhiên trong phương pháp tính toán này, \n\ntác giả gặp phải vấn đề bùng nổ tổ hợp và phân tích ngữ liệu thô. Để giải quyết vấn \n\nđề trên, tác giả đã sử dụng phương pháp quy hoạch động (dynamic programming) vì \n\nlúc đó, xác suất cực đại của một ngữ nhỏ hơn chỉ phải tính toán một lần và sử dụng \n\nlại trong các lần sau. \n\n3.3.4.2. Ưu điểm \n Không cần sử dụng tập ngữ liệu đã đánh dấu chính xác \n\n3.3.4.3. Hạn chế \n Trong thí nghiệm, tác giả chỉ dừng lại ở việc tách các từ có ba tiếng bởi vì \n\ntập ngữ liệu đầu vào vẫn còn khá nhỏ. \n\n Xác suất từ đúng là 51%, xác suất từ chấp nhận được 65% [Le An Ha, 2003]. \n\nXác suất này tương đối thấp so với các phương pháp tách từ khác đã đề cập ở \n\ntrên. \n\n3.3.5. Phương pháp tách từ tiếng Việt dựa trên thống kê từ Internet và \nthuật toán di truyền (Internet and Genetics Algorithm-based Text \nCategorization for Documents in Vietnamese - IGATEC)  \n\n3.3.5.1. Nội dung \nPhương pháp IGATEC do H.Nguyễn et al (2005) giới thiệu là một hướng tiếp \n\ncận mới cho việc tách từ với mục đích phân loại văn bản mà không cần dùng đến \n\n\n\n \n  \n\n \n\n 35 \n\nmột từ điển hay tập huấn luyện nào. Trong hướng tiếp cận này, tác giả kết hợp giữa \n\nthuật toán di truyền (Genetics Algorithm - GA) với dữ liệu thống kê được trích xuất \n\ntừ Internet tiến hoá một quần thể gồm các cá thể là các khả năng tách từ trong câu. \n\nHệ thống gồm ba phần \n\n \n\nHình 3.6. Toàn cảnh hệ thống IGATEC \n\n Online Extractor : Phần này có tác dụng lấy thông tin về tần số xuất hiện của \n\ncác từ trong văn bản bằng cách sử dụng một search engine nổi tiếng như \n\nGoogle. Sau đó, tác giả sử dụng các công thức sau đây để tính toán mức độ \n\nphụ thuộc lẫn nhau (mutual information) để là cơ sở tính fitness cho GA \n\nengine. \n\n Tính xác suất các từ xuất hiện trên Internet \n\n ( )(w)= count wp\nMAX\n\n  \n\n 1 21 2\n( & )( & ) count w wp w w\n\nMAX\n=  \n\nTrong đó, MAX = 4 * 109 ;  \n\ncount(w) số lượng văn bản trên Internet được tìm thấy có chứa từ \n\nw hoặc cùng chứa w1 và w2 đối với count(w1 & w2) \n\n Tính xác suất độ phụ thuộc của một từ lên một từ khác \n\nOnline Extractor \n\nOnline Extractor Online Extractor \n\nOnline Extractor \n\nsegmentation\n\nsegmentation\n\nsegmentation\n\n\u2026\n\n\n\n \n  \n\n \n\n 36 \n\n 1 21 2\n1\n\n( & )( | )\n( )\n\np w wp w w\np w\n\n=   \n\n Thông tin phụ thuộc lẫn nhau (mutual information) của các từ ghép \n\nđược cấu tạo bởi n tiếng (cw = w1w2\u2026wn) \n\n 1 2\n\n1 2\n1\n\n(  &   &  ... &  ) ( ) = \n( ) -  (  &   &  ... &  )  \n\nn\nn\n\nj n\nj\n\np w w wMI cw\np w p w w w\n\n=\n∑\n\n \n\n GA Engine for Text Segmentation : mỗi cá thể trong quần thể được biểu diễn \n\nbởi chuỗi các bit 0,1, trong đó, mỗi bit đại diện cho một tiếng trong văn bản, \n\nmỗi nhóm bit cùng loại đại diện cho một segment.  \n\n Các cá thể được khởi tạo ngẫu nhiên, trong đó, mỗi segment được giới \n\nhạn trong khoảng 5. GA engine sau đó thực hiện các bước đột biến và \n\nlai ghép nhằm mục đích làm tăng giá trị fitness của các cá thể, để đạt \n\nđược cách tách từ tốt nhất có thể. \n\n Text Categorization  : tác giả dùng độ hỗ trợ (support degree) của văn bản \n\ncần phân loại cho các từ khoá để phân loại văn bản. \n\n3.3.5.2. Ưu điểm \n Không cần sử dụng bất cứ tập huấn luyện hoặc từ điển nào \n\n Phương pháp tương đối đơn giản. \n\n Không tốn thời gian huấn luyện \n\n3.3.5.3. Hạn chế \n So với các phương pháp trước, IGATEC có độ chính xác thấp hơn LRMM \n\nvà WFST nhưng vẫn chấp nhận được đối với mục đích tách từ dành cho phân \n\nloại văn bản. \n\n Thời gian chạy ban đầu khá chậm do phải lấy thông tin từ Internet mà đường \n\ntruyền ở Việt Nam còn hạn chế. \n\n Chưa có các thử nghiệm trên tập dữ liệu đủ lớn. \n\n\n\n \n  \n\n \n\n 37 \n\n3.4. So sánh các phương pháp tách từ Tiếng Việt hiện nay \nNhìn một cách tổng quan, phương pháp dựa trên từ (word-base) cho độ chính \n\nxác khá cao ( trên 95%) nhờ vào tập ngữ liệu huấn luyện lớn, được đánh dấu chính \n\nxác, tuy nhiên hiệu suất của thuật toán phụ thuộc hoàn toàn vào ngữ liệu huấn \n\nluyên. Bởi vì mục đích của các tác giả [Đinh Điền et al, 2001] là thực hiện tách từ \n\nthật chính xác để phục vụ cho việc dịch máy nên tác giả đã chọn phương pháp \n\nWFST. Với các phương pháp cần phải sử dụng từ điển hoặc tập huấn luyện, ngoài \n\nviệc tách từ thật chính xác, ta còn có thể nhờ vào các thông tin đánh dấu trong tập \n\nngữ liệu để thực hiện các mục đích khác cần đến việc xác định từ loại như dịch \n\nmáy, kiểm lỗi chính tả, từ điển đồng nghĩa... Do vậy, mặc dù thời gian huấn luyện \n\nkhá lâu, cài đặt khá phức tạp, chi phí tạo tập ngữ liệu huấn luyện rất tốn kém, nhưng \n\nkết quả mà hướng tiếp cận dựa trên từ mang lại cho mục đích dịch máy là rất xứng \n\nđáng cho công sức bỏ ra. \n\nHướng tiếp cận dựa trên ký tự (character-based) có ưu điểm là dễ thực hiện, thời \n\ngian thực thi tương đối nhanh, tuy nhiên lại có độ chính xác không cao bằng \n\nphương pháp dựa trên từ. Hướng tiếp cận này thích hợp cho các mục đích nghiên \n\ncứu không cần đến độ chính xác tuyệt đối cũng như các thông tin về từ loại như \n\nphân loại văn bản, lọc spam, firewall... Nhìn trên bình diện chung, hướng tiếp cận \n\ndựa trên từ có nhiều ưu điểm đáng kể, và đem lại nhiều hứa hẹn lạc quan cho các \n\nhướng nghiên cứu tiếp theo để nâng cao độ chính xác của phương pháp tách từ này. \n\n3.5. Kết luận \nDựa trên các phân tích về ưu khuyết điểm của các phương pháp, chúng em chọn \n\nhướng tiếp cận dựa trên \u201ctiếng\u201d (character-based) cho mục tiêu phân loại văn bản \n\ncủa mình.  \n\nBởi vì, mục tiêu của luận văn là phân loại tin tức báo điện tử, một loại hình cực \n\nkỳ phong phú về nội dung và ngôn ngữ, nên việc tạo ra một từ điển hoàn chỉnh và \n\ncó khả năng cập nhật các thay diễn ra liên tục của ngôn ngữ là khó thực hiện được. \n\nHệ thống xử lý cần phải có khả năng linh hoạt, tự động cập nhật những thay đổi \n\n\n\n \n  \n\n \n\n 38 \n\nhằng ngày, nên hướng tiếp cận không dựa trên từ điển hoặc tập ngữ liệu là cực kỳ \n\nthích hợp. \n\nHơn nữa, hệ thống phân loại tin tức cần có tốc độ xử lý chấp nhận được để có \n\nthể xử lý kịp thời các thông tin mới xuất bản hằng ngày. Do đó, với ưu điểm đơn \n\ngiản, tốc độ thực thi chấp nhận đươc, hướng tiếp cận IGATEC là một lựa chọn hoàn \n\ntoàn phù hợp. \n\nMặt khác, việc phân loại văn bản không yêu cầu việc tách từ phải có độ chính \n\nxác cao đến mức từng từ. Ta có hoàn toàn có thể thực hiện thêm việc loại bỏ các từ \n\nkhông cần thiết cho việc phân loại như các hư từ, thán từ... để tăng tốc độ và sự \n\nchính xác của bước tách từ, chuẩn bị cho việc phân loại văn bản. \n\n\n\n \n  \n\n \n\n 39 \n\n  \n\nCChhưươơnngg  44  \n\nTTÁÁCCHH  TTỪỪ  TTIIẾẾNNGG  VVIIỆỆTT  \n\nKKHHÔÔNNGG  DDỰỰAA  TTRRÊÊNN  TTẬẬPP  \n\nNNGGỮỮ  LLIIỆỆUU  HHAAYY  TTỪỪ  ĐĐIIỂỂNN    \n\n\u2013\u2013  MMỘỘTT  TTHHÁÁCCHH  TTHHỨỨCC    \n \n\nGiới thiệu \n\nCác nghiên cứu về thống kê dựa trên Internet \n\nCác phương pháp tính độ liên quan giữa các từ dựa trên thống kê \n\nTiền xử lý  \n\nHướng tiếp cận tách từ dựa trên thống kê từ Internet và thuật toán \n\ndi truyền \n\nCông cụ trích xuất thông tin từ Google \n\nCông cụ tách từ dùng thuật toán di truyền  \n\nKết quả thực nghiệm \n\nKết luận \n\n\n\n \n  \n\n \n\n 40 \n\nChương 4. TÁCH TỪ TIẾNG VIỆT KHÔNG DỰA TRÊN \nTẬP NGỮ LIỆU ĐÁNH DẤU (ANNOTATED CORPUS) \n\nHAY TỪ ĐIỂN (LEXICON) \u2013 MỘT THÁCH THỨC \n\n4.1. Giới thiệu \nNhư chúng ta đã tìm hiểu ở những phần trên, việc khó xác định ranh giới từ đã \n\nlàm cho việc xử lý tính nhập nhằng trong ngôn ngữ tiếng Việt càng thêm phức \n\ntạp.Ví dụ như: câu \u201công lão già đi rất nhanh\u201d, ta có thể phân chia từ theo nhiều cách \n\nmà câu vẫn có nghĩa \u201công ||già đi || rất || nhanh\u201d, \u201công già || đi || rất || nhanh\u201d, \u201công || \n\ngià || đi || rất || nhanh\u201d \u2026   \n\nNhìn chung, đối với tiếng Anh, về mặt lý thuyết tiếng Anh có nhiều thuận lợi vì \n\nlà loại ngôn ngữ hoà kết hay biến cách (flexion) [Đinh Điền, 2004] , hệ thống ngữ \n\npháp và từ loại đã được quy định rõ ràng, do đó việc phân định ranh giới từ cũng \n\nnhư xây dựng tập ngữ liệu đánh dấu là tương đối đễ dàng.  \n\nCòn đối với tiếng Việt, về mặt lý thuyết tiếng Việt là loại hình đơn lập [Đinh \n\nĐiền, 2004], phương thức ngữ pháp chủ yếu là trật tự từ và hư từ, vì vậy chỉ xét về \n\nmặt phân định ranh giới từ đã có thể có nhiều cách phân định cho cùng một câu mà \n\nvẫn đúng ngữ pháp Việt Nam. \n\nỞ phần này, chúng em xin trình bày hướng tiếp cận cho việc tách từ tiếng Việt \n\ntheo một hướng mới mà không cần sử dụng tập ngữ liệu huấn luyện hay từ điển. \n\nHướng tiếp cận của chúng em dựa trên ý tưởng của bài báo IGATEC, và có nhiều \n\ncải tiến đang kể hàm làm tăng chất lượng cho bước tách từ tiếng Việt phục vụ cho \n\nviệc phân loại tin tức báo điện tử. \n\n4.2. Các nghiên cứu về thống kê dựa trên Internet \n\n4.2.1. Giới thiệu \nVới sự phát triển nhanh chóng của Internet, world-wide-web đã trở thành nguồn \n\ndữ liệu lớn nhất trên thế giới, và là nguồn thông tin ngữ nghĩa tiềm tàng được hàng \n\ntriệu người dùng trên thế giới tạo ra. Đối với con người, việc xem xét mức độ liên \n\nquan giữa hai từ là rất dễ dàng bởi vì con người có thể dựa vào kiến thức  thông \n\n\n\n \n  \n\n \n\n 41 \n\nthường của mình để suy ra ngữ cảnh thích hợp, ví dụ giữa từ \u201ccái nón\u201d và \u201cmàu \n\nđỏ\u201d, con người dễ dàng nhận ra sự liên quan là \u201ccái nón có màu đỏ\u201d. Tuy nhiên, \n\nmáy tính của chúng ta không có khả năng như con người, vì vậy, chúng ta phải tìm \n\nra một cách biểu diễn ngữ nghĩa mà máy tính có thể \u201ctiêu hoá\u201d được. Có ý kiến cho \n\nrằng ta có thể tạo một mạng ngữ nghĩa đồ sộ như một hệ thống trí tuệ ban đầu, sau \n\nđó các kiến thức về cuộc sống thực sẽ tự động xuất hiện. Tuy nhiên hướng giải \n\nquyết này đòi hỏi lượng chi phí khổng lồ cho việc thiết kế cấu trúc có khả năng tính \n\ntoán tri thức và việc nhập các dữ liệu chuẩn xác do các chuyên gia thực hiện. Trong \n\nkhi nỗ lực này vẫn còn đang trong cuộc đua đường dài, chúng ta hãy sử dụng những \n\nthông tin hiện có trên world-wide-web để thực hiện việc biểu diễn ngữ nghĩa. \n\nChúng ta đều biết rằng Internet là kho dữ liệu vô tận, do vậy việc khai thác các \n\nthông tin trên đó không thể thực hiện thủ công mà chúng ta phải thông qua sự hỗ trợ \n\ncủa một công cụ tìm kiếm trên mạng. Nói đến công cụ tìm kiếm (search engine), có \n\nlẽ tên tuổi đầu tiên mà chúng ta nghĩ đến là Google, một công cụ tìm kiếm hàng đầu \n\nbởi tốc độ và chất lượng mà Google đem lại cho người dùng. Và điều đó càng được \n\nchứng minh cụ thể hơn khi có ngày càng nhiều các công trình nghiên cứu về thống \n\nkê trên Internet dựa vào công cụ tìm kiếm Google như trong phần trình bày tiếp \n\ntheo sau đây. \n\n4.2.2. Một số công trình nghiên cứu về thống kê dựa trên Internet \nTheo Rudi Cilibrasi & Paul Vitanyi (2005), công cụ tìm kiếm Google có thể \n\ndùng để tự động khám phá ý nghĩa của từ. Ví dụ : Google tìm thấy từ \u201cstudent\u201d và \n\n\u201cbook\u201d cùng xuất hiện với nhau trên Internet với tần số là 57.600.000, trong khi từ \n\n\u201cstudent\u201d và \u201capple\u201d lại chỉ xuất hiện 8.110.000. Rõ ràng, chúng ta có thể nhận thấy \n\n\u201cstudent\u201d và \u201cbook\u201d có liên quan với nhau mật thiết hơn là \u201cstudent\u201d và \u201capple\u201d.  \n\n  Tác giả đã sử dụng kết quả tìm kiếm của Google để huấn luyện ngữ nghĩa của \n\ncác từ (semantic meaning of words) cho phần mềm \u2013 một vấn đề trọng tâm trong \n\nngành trí tuệ nhân tạo. Giả sử muốn tính toán mức độ liên quan giữa từ x với từ y, \n\nRudi & Paul (2005) đã đưa ra công thức tính khoảng cách NGD (Normalise Google \n\nDistance) như sau: \n\n\n\n \n  \n\n \n\n 42 \n\nmax{log ( ), log ( )} log ( , )\nlog min{log ( ), log ( )}\n\nf x f y f x yNGD\nM f x f y\n\n−\n=\n\n−\n (1) \n\nTrong đó :  \n\n f(x) :số trang web chứa từ x mà Goole trả về \n\n  f(x,y) : số trang web chứa đồng thời từ x và từ y \n\n M = 8.058.044.651 là số trang web hiện tại mà Google đã đánh chỉ mục \n\nVới công thức trên, giá trị của NGD càng nhỏ thì mức độ liên quan giữa hai từ \n\ncàng cao. \n\nVí dụ: tần số xuất hiện của \u201cstudent\u201d= 401.000.000, \u201cbook\u201d = 387.000.000, \n\nđồng thời là 57.600.000, còn \u201capple\u201d là 144.000.000, \u201cstudent\u201d & \u201capple\u201d= \n\n8.110.000. Với M = 8.058.044.651, ta có  \n6 6\n\n6\n\nlog 401.10 log 57,6.10( , ) 0.64\nlog8058044651 log 387.10\n\nNGD student book −≈ ≈\n−\n\n \n\n6 6\n\n6\n\nlog 401.10 log8,11.10( , ) 0.97\nlog8058044651 log144.10\n\nNGD student apple −≈ ≈\n−\n\n \n\nTừ kết quả trên, ta có NGD(student,book) ≈0.64 < NGD(student,apple) ≈0.97, \n\nnên có thể kết luận là \u201cstudent\u201d liên quan với \u201cbook\u201d nhiều hơn là \u201capple\u201d. \n\nNếu NGD của hai từ lớn hơn 1 thì tác giả nhận xét rằng hai từ đó thường xuất \n\nhiện cùng với nhau trong trang web mà không vì một mối liên quan nào cả. \n\nVí dụ: tần số xuất hiện của \u201cby\u201d là 2.770.000.000, \u201cwith\u201d là 2.566.000.000, \n\nđồng thời \u201cby\u201d và \u201cwith\u201d là 49.700.000. Với M = 8.058.044.651, ta có \n\nNGD(by,with) ≈ 3.51 \n\nHơn nữa, NGD là số tỉ lệ bất biến (scale-invariant) nên có tính ổn định với sự \n\ntăng trưởng số lượng trang web trên Google. Đây là tính chất rất quan trọng bởi vì  \n\nM số lượng trang web do Google đánh chỉ mục tăng thường xuyên, do đó, số trang \n\nweb chứa các ngữ tìm kiếm cũng tăng lên ứng với tỉ lệ đó. Điều này có nghĩa là nếu \n\nM tăng gấp đôi thì tần số xuất hiện của các ngữ cũng tăng gấp đôi. Công trình của \n\nRudi & Paul (2005) đã mở ra một hướng tiếp cận mới cho các công trình nghiên \n\ncứu khác nhờ tính chất không giới hạn bởi dữ liệu, dễ dàng thực thi và là nền móng \n\ncho các phương pháp nghiên cứu khác [Rudi & Paul, 2005]. \n\n\n\n \n  \n\n \n\n 43 \n\nNgoài ra, theo James & Daniel (2005) còn có một số công trình nghiên cứu về \n\nphương pháp thống kê khác trên Internet như tính toán kết quả tìm kiếm bằng hàm \n\nluỹ thừa [Simkin & Roychowdhurry, 2003] [Bagrow et al, 2004] , hay phương pháp \n\nđược đánh giá tốt hơn là dựa vào giá trị tương tự cực đại (Maximum Likelihood) \n\n[James & Daniel, 2005]\u2026. Mục đích của việc sử dụng giá trị tương tự cực đại để \n\ntìm ra chỉ số gần giống nhau nhất giữa hai khái niệm. Tuy nhiên, theo kết luận của \n\nJames & Daniel(2005), các phương pháp tính toán dựa trên hàm mũ cho kết quả \n\nchưa khả quan lắm và còn mang tính chủ quan. \n\n4.2.3. Nhận xét \n Hướng thống kê dựa trên Internet hứa hẹn nhiều kết quả khả quan vì không \n\ncần phụ thuộc vào tập dữ liệu huấn luyện truyền thống mà chúng ta có thể \n\ntận dụng khả năng vô tận của Internet thông qua công cụ tìm kiếm.  \n\n Dựa trên nhận xét của Rudi & Paul (2005), tỉ lệ xuất hiện của từ trên Internet \n\nlà khá ổn định, điều này cho phép ta thực hiện các tính toán chính xác và ổn \n\nđịnh vì ít phụ thuộc vào số lượng trang web trên Internet tăng lên theo thời \n\ngian.  \n\n Hiện nay, các công trình nghiên cứu theo hướng tiếp cận mới này chủ yếu \n\nđược thực hiện trên tiếng Anh, còn đối với tiếng Việt thì có thể nói IGATEC \n\nlà công trình đầu tiên áp dụng phương pháp này nhưng đã đạt được kết quả \n\nrất đáng quan tâm. Chúng em hy vọng rằng rằng những nỗ lực nghiên cứu và \n\ncải tiến phương pháp IGATEC sẽ đạt được kết quả tốt hơn. \n\n4.3. Các phương pháp tính độ liên quan giữa các từ dựa trên \nthống kê \n\nTrong ngôn ngữ tự nhiên, nhất là loại ngôn ngữ phụ thuộc nhiều vào ngữ cảnh \n\nnhư tiếng Việt, đối với con người, chúng ta có thể dễ dàng xác định được ranh giới \n\ntừ trong câu. Tuy nhiên, do chưa có một quy định cụ thể nào về ranh giới từ tiếng \n\nViệt, nên có thể nhiều người Việt có nhiều cách tách từ khác nhau. Đối với người \n\nchúng ta vẫn chưa thống nhất được, nên khi dùng máy tính để xử lý ngôn ngữ ta vẫn \n\nchưa có một chuẩn nào để xác định đâu là ranh giới từ. Vì vậy, đã có rất nhiều công \n\n\n\n \n  \n\n \n\n 44 \n\ntrình nghiên cứu cách tính toán độ liên quan giữa các từ để khắc phục các công việc \n\nphức tạp do cách phân tích cấu trúc ngữ pháp trong câu đem lại.  \n\nTrong phần này, chúng em sẽ trình bày hai nội dung chính: \n\n Hai thước đo chuẩn dùng để tính toán độ liên quan giữa hai từ trong tiếng \n\nAnh là thông tin tương hỗ (Mutual Information ) và t-score. \n\n Một số ứng dụng và cải tiến của hai công cụ đo trên trong việc tách từ tiếng \n\nHoa và tiếng Việt. \n\n4.3.1. Thông tin tương hỗ (Mutual Information) và t-score dùng  trong \ntiếng Anh \n\nThông tin tương hỗ (Mutual Information) và t-score là hai khái niệm rất quan \n\ntrọng trong học thuyết về thông tin (Information Theory) và thống kê được trình bày \n\ntrong [Church et al, 1991] cho mục đích tính toán mức độ liên quan của hai từ trong \n\ntiếng Anh.   \n\n4.3.1.1. Thông tin tương hỗ MI (Mutual Information) \u2013 thước đo đặc điểm \ntương tự (A Measure of Similarity) \n\nTheo Church et al (1991), việc thống kê thông tin tương hỗ (Mutual \n\nInformation) dùng để nhận biết các trường hợp ngôn ngữ thú vị, bao gồm từ mối \n\nquan hệ ngữ nghĩa (semantic relations) như bác sĩ/y tá (dạng content word/content \n\nword) cho đến mối quan hệ từ vựng-cú pháp (lexico-syntactic) như sự xuất hiện \n\nđồng thời giữa động từ và giới từ (dạng content word/ funtion word). \n\nMI có nhiệm vụ so sánh xác suất xuất hiện đồng thời  (joint probability) của từ x \n\nvà từ y so với xác suất tìm thấy x và y xuất hiện độc lập. Công thức tính MI cho hai \n\ntừ tiếng Anh trong [Church et al, 1991] như sau: \n\n2\n( , )( ; ) log\n\n( ) ( )\nP x yI x y\n\nP x P y\n≡  \n\n\n\n \n  \n\n \n\n 45 \n\nTrong đó: \n\n x và y là hai từ tiếng Anh cần kiểm tra mức độ kết hợp lẫn nhau. \n\n I(x;y) là thông tin tương hỗ của hai từ.  \n\n P(x), P(y) là xác suất xuất hiện độc lập của x và của y. \n\n P(x,y) là xác suất xuất hiện đồng thời x và y. \n\nTheo Church et al (1991), giá trị I(x,y) càng lớn thì khả năng kết hợp của x và y \n\ncàng cao. \n\n4.3.1.2. t-score \u2013 thước đo sự khác biệt (A Measure of Dissimilarity) \nChúng ta dễ dàng nhận ra sự  giống nhau giữa strong và powerful, tuy nhiên làm \n\ncách nào để phân biệt sự khác nhau giữa chúng. Ví dụ, chúng ta đều biết rằng người \n\nta thường nói strong tea, powerful car hơn là nói powerful tea và strong car. Nhưng \n\nlàm sao cho máy tính nhận ra được sự khác biệt này? \n\nGiả sử , ta biết rằng strong support được dùng phổ biến hơn là powerful support, \n\nChurch et al (1991) đã đưa ra công thức tính t-score để đo sự khác biệt trên: \n\n1 2\n2 2\n\n1 2\n\n( | ) -  ( | )\n( ( | )  ( | ))\nP w w P w wt\nP w w w wσ σ\n\n= −\n+\n\n \n\nTrong đó:  \n\n w1,w2 là hai từ tương tự nhau cần phải phân biệt (ở ví dụ trên là strong và \n\npowerful) . \n\n w là từ dùng để phân biệt (ở ví dụ trên là support). \n\n P(w|w1), P(w|w2) là xác suất của từ w xuất hiện đi kèm với từ w1, w2  \n\nLúc đó:  \n\n2 2\n\n2 2\n\n(  ) -  (  )\n( (  )) ( (  ))\n\n(  ) f (  ) -  \n\n(  ) (  )\n\n2 175 13\n2 175\n\nP powerful support P strong supportt\nP powerful support P strong support\n\nf powerful support strong support\nN N\n\nf powerful support f strong support\nN N\n\nσ σ\n= −\n\n+\n\n≈ −\n+\n\n−\n≈ − ≈ −\n\n+\n\n \n\n\n\n \n  \n\n \n\n 46 \n\nTa nói rằng powerful support có độ lệch chuẩn (standard deviation) kém strong \n\nsupport 13 lần. Nhờ vậy, ta có thể phân biệt được sự khác nhau giữa powerful và \n\nstrong trong việc sử dụng hai từ này. \n\n4.3.2. Một số cải tiến trong cách tính độ liên quan ứng dụng trong tách \ntừ tiếng Hoa và tiếng Việt \n\n4.3.2.1. Thông tin tương hỗ (Mutual Information) \nKhi áp dụng thông tin tương hỗ MI trong tách từ tiếng Hoa, Su et al (1993)  cho \n\nrằng thông tin tương hỗ (Mutual Information) là thước đo mức độ kết hợp của một \n\ntừ. Nó có nhiệm vụ so sánh xác suất một nhóm các ký tự (tương tự như \u201ctiếng\u201d \n\ntrong tiếng Việt \u2013 xem giải thích ở mục 3.2.3.) xuất hiện đồng thời (joint \n\nprobability) so với xác suất tìm thấy từng ký tự  xuất hiện độc lập.  \n\nTheo Su et al (1993) cách tính MI cho từ có 2 ký tự có thể áp dụng công thức \n\ncủa Church et al (1991) với ý nghĩa của x và y lúc này không còn là \u201ctừ\u201d (word) như \n\ntrong tiếng Anh mà được hiểu là tiếng (xem giải thích ở mục 3.2.3.) trong tiếng \n\nHoa. \n\n2\n( , )( ; ) log\n\n( ) ( )\nP x yI x y\n\nP x P y\n≡      (1a) \n\nTrong đó: \n\n x và y là hai tiếng cần kiểm tra mức độ kết hợp lẫn nhau trong tiếng Hoa. \n\n I(x;y) là thông tin tương hỗ của hai tiếng.  \n\n P(x), P(y) là xác suất xuất hiện độc lập của tiếng x và của tiếng y. \n\n P(x,y) là xác suất xuất hiện đồng thời tiếng x và tiếng y. \n\n \n\nCách tính MI dành cho từ ghép 3 tiếng như sau [Su et al, 1991]: \n\n2\n( , , )( ; ; ) log\n( , , )\n\nD\n\nI\n\nP x y zI x y z\nP x y z\n\n≡      (1b) \n\nTrong đó:  \n\n PD(x,y,z) ≡ P(x,y,z) là xác suất xuất hiện đồng thời của x, y và x, \n\n(Dependently) \n\n\n\n \n  \n\n \n\n 47 \n\n PI(x,y,z) là xác suất xuất hiện độc lập của x,y, z (Independently) với   \n\nPI(x,y,z) ≡ P(x)P(y)P(z) + P(x)P(y,z) + P(x,y)P(z). \n\nNhìn chung I(.) >>0 sẽ cho biết từ ghép đó có mức độ liên quan giữa các tiếng là \n\nrất chặt chẽ. Ngược lại, các tiếng có xu hướng xuất hiện một cách độc lập. \n\n \n\nMột cách tính MI khác cũng được Ong & Chen (1999) đề nghị như sau:   \n\n1 2\n\n1 2\n\n( & &  ... & ) ( ) = \n( ) ( ) ( & &  ... & )\n\nn\n\nn\n\np w w wMI cw\np lw p rw p w w w+ −\n\n     (2) \n\nTrong đó \n\n cw = p( w1 & w2 ...& wn-1 )  \n\n lw = p( w1 & w2 ...&  wn-1 ) \n\n rw = p ( w2 & w3 ...& wn) \n\n \n\nTheo nghiên cứu của chúng em, hiện nay công trình nghiên cứu về cách tách từ \n\ndựa trên độ tương hỗ MI trên tiếng Việt chưa nhiều. Ở đây, chúng em xin giới thiệu  \n\ncách tính MI được đề nghị trong IGATEC trong [H. Nguyen et al, 2005] \n\n1 2\n\n1 2\n1\n\n(  &   &  ... &  ) ( ) = \n( ) -  (  &   &  ... &  )  \n\nn\nn\n\nj n\nj\n\np w w wMI cw\np w p w w w\n\n=\n∑\n\n   (3) \n\nNhìn vào các công thức tính MI, ta có thể dự đoán được mỗi công thức ưu tiên \n\ncho một loại từ khác nhau. Phần tiếp theo sau đây sẽ trình bày một số nhận xét về \n\ncác công thức trên để làm cơ sở đưa ra lựa chọn phù hợp nhất. \n\n4.3.2.2. Cách tính tần số tương đối (Relative Frequency Count) \nCách tính tần số tương đối cho từ ghép có i tiếng được định nghĩa như sau [Su et \n\nal, 1993]: \n\ni\ni\n\nfr\nK\n\n=  \n\nTrong đó, fi là số lần xuất hiện của từ ghép có i tiếng (ith n-gram) trong tập ngữ \n\nliệu, và K là số lần xuất hiện trung bình của một từ. Nói một cách khác, fi được bình \n\nthường hoá bằng cách chia cho K để lấy tỉ lệ liên quan. Một cách trực quan, ta sẽ \n\n\n\n \n  \n\n \n\n 48 \n\nnhận ra, cách tính RFC sẽ ưu tiên cho những từ xuất hiện với tần số rất cao mà nó sẽ \n\nbỏ mất những xuất hiện trong từ điển với tần số thấp. Vì vậy, RFC được dùng như \n\nmột thuộc tính hỗ trợ thêm cho việc tách từ. \n\n4.3.2.3. Nhận xét về cách sử dụng MI và RFC \nNếu ta sử dụng đồng thời MI và RFC cho việc tách từ sẽ đem lại kết quả như \n\nmong đợi bởi vì nếu chỉ sử dụng một công cụ tính toán, kết quả chúng ta đạt được \n\ncó thể chỉ ưu tiên cho một cách tách nào đó. Nếu chỉ sử dụng RFC, hệ thống của \n\nchúng ta có xu hướng chọn những từ xuất hiện nhiều lần nhưng lại có độ liên quan \n\nMI thấp. Ví dụ, nếu P(x) và P(y) rất lớn, nó có thể tạo ra P(x,y) cũng rất lớn mặc dù \n\nx và y không hề liên quan gì cả vì P(x,y)/ P(x) x P(y) rất nhỏ.  \n\nMặc khác, nếu chỉ sử dụng MI thôi, thì ở trường hợp P(x) và P(y) quá nhỏ sẽ \n\ndẫn đến kết quả không đáng tin cậy. Một từ n-gram có thể có MI cao không bởi vì \n\nchúng kết hợp chặt chẽ với nhau mà bởi vì khi chia hai số cùng nhỏ như nhau, ta sẽ \n\ncó số MI lớn. \n\nTóm lại, ta nên sử dụng cả hai thông tin MI và RFC vì thực tế, một nhóm các từ \n\nvừa có RFC và MI cao sẽ có xu hướng vừa kết hợp chặt chẽ với nhau, vừa được sử \n\ndụng rộng rãi. \n\n4.3.3. Nhận xét  về các cách tính độ liên quan khi áp dụng cho tiếng Việt \n Tiếng Hoa là loại ngôn ngữ đơn lập giống tiếng Việt, nên ta có thể áp dụng \n\nmột số công tình nghiên cứu trên tiếng Hoa lên tiếng Việt. \n\n Về mặt lý thuyết, ta hoàn toàn có thể sử dụng các công thức MI trên để áp \n\ndụng cho tiếng Việt, và quan thực nghiệm, chúng ta sẽ đề xuất thêm một số \n\ncải tiến để công thức tính MI phù hợp với việc tách tiếng Việt hơn nữa. \n\n Đối với công thức RFC, ta cần phân biệt khái niệm  f  trong công thức là tần \n\nsố xuất hiện của từ trong tập ngữ liệu, K là số lần xuất hiện trung bình của \n\nmột từ (real word) trong tập ngữ liệu. Khi sử dụng tập ngữ liệu, các số f và K \n\nlà hoàn toàn tính được. Tuy nhiên, phương pháp IGATEC mà chúng em sử \n\ndụng lại lấy kết quả số lượng trang web p chứa từ cần tìm nên chúng ta \n\nkhông thể tính được số K ( vì không thể dựa vào số lượng trang web trả về \n\n\n\n \n  \n\n \n\n 49 \n\nmà quyết định đó là từ hay không). Do vậy, hiện tại, chúng em vẫn chưa áp \n\ndụng cách tính RFC trên tiếng Việt. \n\n Bản chất của phương pháp tính t-score là tìm sự khác nhau trong việc sử \n\ndụng từ trong tiếng Anh, chúng em nhận thấy chưa thật sự cần thiết trong \n\nviệc tách từ  làm tăng tính phức tạp của việc tính toán. Do đó, chứng em \n\nchưa áp dụng t-score vào tách từ. \n\n4.4. Tiền xử lý (Pre-processing) \nBởi vì các bài báo điện tử được trình bày dưới dạng html, nên trước khi thực \n\nhiện tách từ để phân loại, chúng em phải xử lý văn bản để lấy ra những nội dung \n\nquan tâm.  \n\n4.4.1. Xử lý văn bản đầu vào \nNội dung tóm tắt của bài báo là rất quan trọng vì nó thể hiện nội dung bài báo \n\nmột cách cô đọng, súc tích, rõ ràng, giúp người xem dự đoán được đề tài của bài \n\nbáo muốn đề cập đến. Chính vì lý do đó, chúng em quyết định thực hiện việc phân \n\nloại tin tức dựa trên phần tóm tắt của bài báo để tiết kiệm thời gian xử lý và đạt \n\nđược kết quả chính xác cao. \n\nTrong mỗi văn bản, khối tiền xử lý sẽ nhận diện tiêu đề, tóm tắt\u2026 của bài báo \n\nbằng cách dựa vào thông tin định dang của các thẻ trong trang html. Theo khảo sát \n\ncủa chúng em về cấu trúc hiển thị nội dung trang báo điện tử ở các trang web tin tức \n\nở Việt Nam, tác giả luôn trình bày nội dung tóm tắt (abstract) của bài báo trước bài \n\nviết chi tiết, nên hướng phân loại dựa trên tóm tắt của bài báo là khả thi.  \n\n\n\n \n  \n\n \n\n 50 \n\n \n\nHình 4. 1. Nội dung thông tin cần lấy \n\nSau khi rút trích được nội dung cần thiết, chúng em tiếp tục thực hiện tách ngữ, \n\nphục vụ cho công việc tách từ. \n\n4.4.2. Tách ngữ & tách stopwords \nTách ngữ: Ứng với mỗi văn bản đã rút trích từ trang web, chúng em tiến hành \n\nloại bỏ các ký hiệu, các chữ số không cần thiết, sau đó, phân tích văn bản thành các \n\nngữ phân cách bởi dấu câu.  \n\nTách stopword: Nhằm làm tăng tốc độ tính toán của GA và lượt bớt các từ \n\nkhông có nghĩa phân loại trong câu, chúng em có thử nghiệm tách stopword trước \n\nkhi tiến hành tách từ. Bước tách stopword tỏ ra khá hiệu quả trong việc làm tăng tốc \n\nđộ GA nhờ chia nhỏ các ngữ ra thành những ngữ nhỏ hơn. Tuy nhiên, cách tách \n\nstopword không phải lúc nào cũng cho kết quả như mong đợi bởi vì tách stopword \n\ntrước khi tách từ sẽ có nhiều khả năng làm sai lạc ý nghĩa của câu, ảnh hưởng đến \n\nviệc phân loại sau đó. Do đó, chúng em đã thử nghiệm việc tách stopword sau khi \n\n\n\n \n  \n\n \n\n 51 \n\nđã tách từ,  kết quả phân loại sau khi đã loại bỏ stopword là khả quan hơn cách thực \n\nhiện ban đầu. (Xin xem chương 6 để biết kết quả thực nghiệm.) \n\n4.5. Hướng tiếp cận tách từ dựa trên thống kê từ Internet  và \nthuật toán di truyền (Internet and Genetic Algorithm-based ) \n\nChúng em xây dựng hai công cụ hỗ trợ cho việc tách từ gồm: công cụ trích xuất \n\nthông tin từ Google và công cụ tách từ dùng thuật toán di truyền. \n\n4.5.1. Công cụ trích xuất thông tin từ Google \n\n4.5.1.1. Mục đích \nNgày nay, cùng với sự phát triển nhanh chóng của các công nghệ thông tin hiện \n\nđại, Internet đã trở thành một thư viện tuyệt vời với một khối lượng văn bản đồ sộ. \n\nDo đó, việc khai thác thông tin từ world-wide-web như một tập ngữ liệu khổng lồ \n\ncho các công trình nghiên cứu sẽ rút ngắn được thời gian và công sức tự xây dựng \n\nmột tập ngữ liệu riêng. Với sự giúp sức của công cụ tìm kiếm miễn phí trên mạng, \n\nnhững thông tin cần thiết sẽ được lấy về một cách nhanh chóng và chính xác. Chúng \n\nem chọn Google là công cụ tìm kiếm chính bởi vì những ưu thế về tính nhanh \n\nchóng, chính xác, và phổ biến của nó so với các công cụ tìm kiếm khác.  \n\nTrong luận văn này, chúng em cần hai loại thông tin: \n\n Tần số xuất hiện của các văn bản chứa các từ (document frequency) trên các \n\ntrang web để làm tính công thức MI, dự đoán khả năng tồn tại của một từ là \n\nđúng hay không \n\n Tần số các văn bản chứa  từ với từ khóa đại diện cho chủ đề dùng để tính \n\nmức độ liên quan của từ với các chủ đề cần phân loại. \n\nDo vây, nhiệm vụ của công cụ trích xuất thông tin từ Google sẽ lấy kết quả tìm \n\nkiếm của Google, trả về cho chương trình khi chúng ta đưa yêu cầu tìm kiếm. \n\n\n\n \n  \n\n \n\n 52 \n\n4.5.1.2. Các công thức tính xác suất và độ tương hỗ \n\n4.5.1.2.1. Các công thức tính xác suất \nKhi nhận được kết quả trả về, dựa vào nền tảng của các công trình nghiên cứu về \n\nthống kê trên Internet của Rudi & Paul (2005), chúng em sẽ sử dụng các công thức \n\nsau đây để tính toán chỉ số MI. \n\nCác công thức tính xác suất các từ xuất hiện trên Internet :  \n\n Gọi count(w) là số lượng trang web chứa từ w \n\ncount(w1 & w2) là số trang web chứa đồng thời w1 và w2 \n\n ( )(w)= count wp\nMAX\n\n \n\n 1 21 2\n( & )( & ) count w wp w w\n\nMAX\n=    \n\n Trong đó, MAX = 4 * 109;  \n\n4.5.1.2.2. Các công thức tính độ tương hỗ (Mutual Information \u2013 MI) \nĐối với hướng tiếp cận N-Gram để tách từ, công thức MI để tính toán khả năng \n\ntồn tại một ngữ cần tách trong câu là rất quan trọng. Độ tương hỗ (Mutual \n\nInformation) cho biết thông tin phụ thuộc lẫn nhau của các từ ghép được cấu tạo bởi \n\nn tiếng (cw = w1 w2 \u2026 wn) . Đối với từ một tiếng, ta quy ước MI = p(w). Đối với từ \n\nghép từ 2 tiếng trở lên, chúng em thử nghiệm 3 cách tính MI  để tìm ra các tính hiệu \n\nquả nhất.  \n\n MI theo cách tính của IGATEC [H. Nguyen et al, 2005] ) (đã được trình bày \n\nở mục 4.3.2.1.) \n\n 1 2\n\n1 2\n1\n\n(  &   &  ... &  ) ( ) = \n( ) -  (  &   &  ... &  )  \n\nn\nn\n\nj n\nj\n\np w w wMI cw\np w p w w w\n\n=\n∑\n\n (2) \n\n MI theo cách tính của [Ong & Chen, 1999] (đã được trình bày ở mục \n\n4.3.2.1.) \n\n Giả sử ta có   \n\n cw = p( w1 & w2 ...& wn-1 )  \n\n lw = p( w1 & w2 ...&  wn-1 ) \n\n\n\n \n  \n\n \n\n 53 \n\n rw = p ( w2 & w3 ...& wn) \n\n 1 2\n1 2\n\n( & &  ... & ) ( ) = \n( ) ( ) ( & &  ... & )\n\nn\n\nn\n\np w w wMI cw\np lw p rw p w w w+ −\n\n (3) \n\n MI do chúng em đề nghị: \n\n Giả sử ta có   \n\n cw = p( w1 & w2 ...& wn-1 )   \n\n Với n chẵn : lw = p( w1 & w2 ...&  wn/2 ),  rw = p ( wn/2+1 & \n\nwn/2+2 ...& wn) \n\n Với n lẻ: lw = p( w1 & w2 ...&  wn-1 ) , rw = p ( w2 & w3 ...& wn) \n\n 1 2\n1 2\n\n( & &  ... & ) ( ) = \n( ) ( ) ( & &  ... & )\n\nn\n\nn\n\np w w wMI cw\np lw p rw p w w w+ −\n\n  (4) \n\nChúng ta sẽ sử dụng các công thức trên để tính độ thích nghi của các cá thể \n\ntrong thuật toán di truyền dưới đây. Kết quả của mỗi công thức tính MI sẽ ưu tiên \n\ncho những loại từ ghép khác nhau  mà ta sẽ hiểu rõ hơn trong kết quả thực nghiệm ở \n\nchương 6.  \n\n4.5.2. Công cụ tách từ dùng thuật toán di truyền (Genetic Algorithm \u2013 \nGA) \n\nMục đích của chúng ta là tìm ra các cách tách từ hợp lý nhất cho văn bản, tuy \n\nnhiên, chúng ta gặp phải trở ngại là không gian tìm kiếm (search space) quá lớn do \n\nsự bùng nổ tổ hợp khi sinh ra dãy các từ. Như chúng ta đều biết, thuật toán di truyền \n\n(Genetic Algorithm \u2013 GA) được biết đến với khả năng duyệt tắt qua những không \n\ngian tìm kiếm lớn một cách hiệu quả và đưa ra những giải pháp toàn cục tối ưu nhất. \n\nGA thực hiện tiến hoá một số thế hệ để tạo ra một quần thể gồm những cá thể tối ưu \n\nnhờ vào các bước lai ghép (cross-over), đột biến (mutation), sinh sản \n\n(reproduction), và cách chọn lựa cá thể. Chất lượng của mỗi cá thể được tính toán \n\ndựa trên chỉ số fitness cho mỗi cá thể và quần thể. Trong quá trình thử nghiệm, \n\nchúng em chọn top N cá thể chất lượng nhất sau khi thực hiện các bước lai ghép, \n\nđột biến, sinh sản. \n\n4.5.2.1. Khảo sát độ dài của \u201ctừ\u201d trên từ điển \n\n\n\n \n  \n\n \n\n 54 \n\nNhư chúng ta đều biết, thuật toán di truyền đòi hỏi phải có rất nhiều tham số cho \n\ncác bước thực hiện như số cá thể trong quần thể, số thế hệ tiến hoá, tỉ lệ lai ghép, tỉ \n\nlệ đột biến\u2026 Do vậy, chất lượng lựa chọn các tham số trên sẽ quyết định kết quả \n\ncủa thuật toán di truyền. Chính vì tính chất quan trọng của các tham số, chúng em \n\nthực hiện một khảo sát nhỏ về số lượng từ tương ứng với chiều dài từ trên từ điển \n\nthông dụng tại http://dict.vietfun.com để làm cơ sở cho các tham số sau này. \n\n \n\nĐộ dài từ (tiếng) Tần số xuất hiện Tỉ lệ \n\n1 8933 12.2 \n\n2 48995 67.1 \n\n3 5727 7.9 \n\n4 7040 9.7 \n\n≥ 5 2301 3.1 \n\nTổng cộng 72994 100 \n\nBảng 4. 1. Thống kê độ dài từ trong từ điển \n\nCó một điều cần lưu ý là tại thời điểm này, chúng ta vẫn chưa có một từ điển \n\nchuẩn nào được dùng cho việc xử lý ngôn ngữ, do đó, chúng em quyết định dùng \n\nloại từ điển phổ dụng để thống kê. Theo kết quả thống kê, trên 67% là từ ghép hai \n\ntiếng, còn lại khoảng 30% là các từ ghép một, ba, bốn tiếng. Các cụm từ dài hơn \n\nbốn tiếng chiếm khoảng 3%, tuy nhiên các cụm từ đó đa số là các câu thành ngữ của \n\nViệt Nam. \n\nKết quả thống kê trên có ý nghĩa rất quan trọng đối với công cụ tách từ bằng GA \n\ncủa chúng em. Dựa trên tỉ lệ của các loại từ,  chúng em thực hiện việc khởi tạo cá \n\nthể ngẫu nhiên có thêm thông tin về xác suất xuất hiện của từ và đó là cơ sở để \n\nchúng em quyết định cách tách từ phù hợp với thực tế của tiếng Việt. Chi tiết về các \n\nứng dụng của kết quả khảo sát sẽ được chúng em trình bày ở các phần sau.  \n\n4.5.2.2. Khởi tạo quần thể \n\n\n\n \n  \n\n \n\n 55 \n\n4.5.2.2.1. Biểu diễn cá thể \nGiả sử văn bản đầu vào t được tạo thành bởi n tiếng (syllables) như sau: \n\nt=s1s2...sn . Mục đích của quá trình chạy GA là tìm ra cách tách từ có độ chấp nhận \n\ncao nhất : t=w1w2\u2026wm , với wk= si\u2026 sj (1 ≤ k ≤ m, 1  ≤  i,j ≤ n) \n\nTương tự như IGATEC, chúng em cũng biểu diễn mỗi cá thể (id) trong quần thể \n\n(pop) bởi chuỗi các bit 0,1, trong đó, mỗi bit đại diện cho một tiếng trong văn bản, \n\nmỗi nhóm bit cùng loại đại diện cho một từ (word).  \n\nVí dụ: Với câu \u201cNhững || con || khủng long || trong || phim hoạt hình || rất || ngộ \n\nnghĩnh\u201d, chúng em sẽ biểu diễn dưới dạng các bit 0, 1 như sau: \n\n \n\n \n\nHình 4. 2. Biểu diễn cá thể bằng các bit 0,1  \n\n4.5.2.2.2. Khởi tạo các tham số \nỞ bước khởi tạo tham số, ta phải thiết lập một vài tham số cơ bản cho GA như \n\nsố thế hệ   tiến hoá (generations), kích thước quần thể (population size), tỉ lệ lai \n\nghép (reproduction fraction)\u2026 Ngoài ra, vì mỗi cá thể của chúng ta là một thể hiện \n\ncách tách từ trong câu, nên ta sẽ lợi dụng tính chất liên kết của các từ để thực hiện \n\nkhởi tạo cá thể ngẫu nhiên ban đầu. Tính chất liên kết của từ được thể hiện qua tỉ lệ \n\ncủa các từ trong từ điển, nên ta sẽ có thêm tham số về khả năng xuất hiện từ trong \n\ncâu ở bảng tham số dưới đây. \n\n\n\n \n  \n\n \n\n 56 \n\n \n\nTham số Giá trị \n\nSố thế hệ tiến hoá  100 \n\nKích thước quần thể  50 \n\nTỉ lệ lai ghép  95% \n\nTỉ lệ đột biến  5% \n\nTop N cá thể được chọn  100 \n\nTỉ lệ từ 1 tiếng (mono-gram) 10% \n\nTỉ lệ từ 2 tiếng (bigram) 70% \n\nTỉ lệ từ 3 tiếng (trigram) 10% \n\nTỉ lệ từ 4 tiếng (quadgram) 10% \n\nBảng 4. 2. Tham số thực hiện GA \n\n4.5.2.2.3. Khởi tạo cá thể \nNhư chúng ta đều biết, quy tắc của  thuật toán di truyền là thực hiện tiến hoá các \n\ncá thể qua các thế hệ nhằm đạt đến độ hội tụ của chỉ số thích nghi (sẽ được nói rõ ở \n\nmục 4.5.2.3). Nếu cá thể được khởi tạo ngẫu nhiên sẽ có độ thích nghi thấp, chúng \n\nta phải tiến hoá qua rất nhiều thế hệ để đạt đến độ hội tụ cần thiết. Và hậu quả là số \n\nthế hệ tiến hoá càng nhiều thì thời gian tiêu tốn và chi phí tính toán càng cao. Giải \n\npháp khắc phục nhược điểm trên là khởi tạo một số cá thể ban đầu gần với điểm hội \n\ntụ, nhờ vậy có thể rút ngắn được số thế hệ tiến hoá, tăng tốc độ. Ở bước khởi tạo \n\nquần thể, chúng em tạo ra cá các thể bằng hai cách: khởi tạo ngẫu nhiên và khởi tạo \n\ndựa trên phương pháp MM:forward/backward [Chih-Hao Tsai, 2000]. \n\n4.5.2.2.3.1. Khởi tạo cá thể ngẫu nhiên  \nTheo thống kê ở bảng 4.1, chúng em quyết định đặt ra một số giới hạn cho việc \n\ntạo cá thể ngẫu nhiên. Đầu tiên, tất cả các từ ghép wk tạo ra có độ dài không quá 4. \n\n\n\n \n  \n\n \n\n 57 \n\nThứ hai, chúng em khởi tạo ngẫu nhiên các cá thể có số lượng từ tương ứng với tỉ lệ \n\nvề độ dài từ ở trên, nhằm tạo ra điểm xuất phát tốt cho quá trình thực hiện GA. \n\nVí dụ: Giả sử ta có câu đầu vào \u201cNhững con khủng long trong phim hoạt hình \n\nrất đáng yêu\u201d gồm 11 tiếng. Theo các tham số khởi tạo của bảng 4.2., chúng em \n\nthiết lập giới hạn tạo từ ngẫu nhiên trong câu:  \n\n \n\n Hình 4. 3. Thang tỉ lệ phát sinh loại từ \n\nMột bộ phát sinh ngẫu nhiên sẽ phát sinh xác suất f  (0 ≤ f ≤ 1) để chọn loại từ: \n\n Nếu 0 ≤ f < 0.1 :  phát sinh loại từ 1 tiếng \n\n Nếu 0.1 ≤ f < 0.8 :  phát sinh loại từ 2 tiếng \n\n Nếu 0.8 ≤ f < 0.9 :  phát sinh loại từ 3 tiếng \n\n Nếu 0.9 ≤ f ≤ 1: phát sinh loại từ 4 tiếng \n\n4.5.2.2.3.2. Khởi tạo cá thể bằng Maximum Matching : \nforward/backward  \n\n(Phương pháp Maximum Matching : forward/backward [Chih-Hao Tsai, 2000] \n\nđã được trình bày ở mục 3.2.1.)  \n\nĐây là bước khởi tạo rất quan trọng và điểm cải tiến đáng kể so với IGATEC. \n\nChúng em chọn phương pháp MM: forward/backward để khởi tạo cá thể ban đầu vì \n\nđộ chính xác khá cao của phương pháp này sẽ tạo ra cá các thể gần đúng nhất, giúp \n\ntăng tốc quá trình tiến hoá. Ngoài ra, việc áp dụng phương pháp MM theo dạng đơn \n\ngiản chỉ cần duyệt tuyến tính, sẽ giảm thiểu được chi phí và thời gian tính toán so \n\nvới các phương pháp khác.  \n\nChúng em thực hiện tách từ theo hai hướng từ trái sang phải, và từ phải sang \n\ntrái. Nếu hai cách tách từ trên trùng nhau, chúng em sẽ chọn một và gộp vào các cá \n\nthể đã được phát sinh ngẫu nhiên ở trên. \n\n\n\n \n  \n\n \n\n 58 \n\nSau khi khởi tạo xong, quần thể sẽ được tiến hóa qua các quá trình lai ghép, đột \n\nbiến, sinh sản,    \n\n4.5.2.3. Thực hiện tiến hoá \n\n4.5.2.3.1. Quá trình lai ghép (cross-over) \nChúng em áp dụng phương pháp chuẩn của lai ghép là dựa trên một điểm ngẫu \n\nnhiên trong chuỗi bit của cá thể. Khi có một cặp cá thể bố mẹ , thế hệ con được tạo \n\nra dựa trên sự kết hợp từ phần đầu tiên của bố với phần cuối của mẹ và ngược lại. \n\nTuy nhiên, trong quá trình lai ghép, chúng em nhận thấy giới hạn từ ghép tối đa 4 \n\ntiếng có thể bị phá vỡ, do đó, đối với những phân đoạn wk nào có độ dài hơn chúng \n\nem sẽ thực hiện việc chuẩn hóa từ vị trí đó đến cuối sao cho không có một từ nào \n\nvượt quá 4 tiếng. \n\nVí dụ:  \n\n \n\nHình 4. 4.Quá trình lai ghép \n\n4.5.2.3.2. Quá trình đột biến (mutation) \nThay vì thực hiện phương pháp bật tắt bit (bit flip), chúng em thực hiện việc \n\nhoán chuyển vị trí của hai bit liền nhau tại một vị trí ngẫn nhiên. Ý tưởng thực hiện \n\n\n\n \n  \n\n \n\n 59 \n\nđột biến như thế này bởi vì, trong việc phân định ranh giới từ, ta dễ dàng nhận ra \n\nrằng một tiếng nếu kết hợp với tiếng trước không phù hợp thì có thể kết hợp với từ \n\nđứng sau sẽ phù hợp hơn, hoặc là đứng một mình. Tương tự như phần lai ghép, \n\nchúng em thực hiện chuẩn hoá các cá thể sau khi đột biến. \n\nVí dụ: \n\n \n\nHình 4. 5. Quá trình đột biến \n\n4.5.2.3.3. Quá trình sinh sản (reproduction) \nSau khi lai ghép và đột biến, chúng em kết hợp các cá thể bố mẹ với cá thể con \n\nvừa được tạo ra để phục vụ cho bước chọn cá thể. Sau khi kết hợp, chúng em lọc bỏ \n\ncác cá thể trong quần thể, để đạt được nhiều cách tách từ tốt. Ví dụ:  \n\n \n\nHình 4. 6. Quá trình sinh sản \n\n\n\n \n  \n\n \n\n 60 \n\n4.5.2.3.4. Quá trình chọn cá thể (selection) \nỞ mỗi thế hệ, chúng em chỉ chọn top N cá thể từ quá trình sinh sản ở trên. Trước \n\ntiên, các cá thể sẽ được tính độ thích nghi (fitness) chính là tổng giá trị MI của các \n\ntừ được tách trong câu. Sau đó, quần thể sẽ được sắp xếp theo giá trị của độ thích \n\nnghi giảm dần, quá trình chọn lọc cá thể sẽ chọn top N cá thể có độ thích nghi cao \n\nnhất để tạo nên quần thể tiếp tục tiến hoá ở các thế hệ sau. \n\nCách thức lựa chọn cá thể như sau: \n\n1 2 m k\n1\n\n( ) (w w ...w ) (w )\nm\n\nk\nfit id fit MI\n\n=\n\n= =∑  \n\n1\n( ) ( )\n\nN\n\ni\ni\n\nfit pop fit id\n=\n\n=∑  \n\nTrong đó, id = w1w1... w1 là một cá thể trong quần thể pop = {id1, id2} \n\nVí dụ:  \n\n \n\nHình 4. 7. Quá trình chọn cá thể \n\nCó thể nói đây là quá trình quan trọng nhất trong cả tiến trình tiến hoá vì sự lựa \n\nchọn cá thể ở bước này sẽ quyết định cá thể tiến hoá có tốt hay không. Ở quá trình \n\nchọn lọc cá thể này, chúng em đã thử nghiệm một số công thức tính độ tương hỗ \n\n(Mutual Information) như đã trình bày ở trên, và thu được các kết quả khác nhau \n\nkhi sử dụng các công thức khác nhau. Từ đó, chúng em rút ra một số kết luận và \n\nnhận xét quan trọng về ưu khuyết điểm của các công thức MI. \n\n Kết quả thực nghiệm và nhận xét về các công thức MI sẽ được chúng em trình \n\nbày ở chương 6. \n\n\n\n \n  \n\n \n\n 61 \n\n4.5.2.3.5. Độ hội tụ (convergence) \nQuá trình thực hiện GA cố gắng làm tăng độ thích nghi (fitness) của mỗi cá thể \n\ncũng đồng nghĩa với việc tăng chất lượng của từ được tách. Ở mỗi thế hệ tiến hoá, \n\nchỉ số thích nghi của quần thể sẽ tăng dần đến một ngưỡng gọi là độ hội tụ α. Khi \n\nđó, độ chênh lệnh chỉ số thích nghi của quần thể giữa hai thế hệ sẽ nhỏ dần và tiến \n\ndần đến 0. Vì vậy, chúng em thực hiện việc ngừng GA một cách tự động khi giá trị \n\nfitness của các thế hệ đạt đến độ hội tụ có chỉ số α = 10-7 hoặc số thế hệ đạt đến số \n\nlượng mặc định đã trình bày ở trên.  \n\nViệc ngừng GA tự động sẽ giúp chúng ta giảm thiểu thời gian và chi phí tính \n\ntoán không cần thiết, đồng thời là tăng tốc độ của việc tách từ. \n\n4.6. Kết luận \nPhương pháp tách từ dựa trên thống kê Internet và thuật toán di truyền tương đối \n\nđơn giản hơn các phương pháp khác và tỏ ra khá linh hoạt với sự biến động của \n\nngôn ngữ trong tin tức điện tử. Ngoài ra, đây là hướng tiếp cận khá mới mẻ, hạn chế \n\nđược khuyết điểm cơ bản của các phương pháp tách từ lâu nay là dựa trên tập ngữ \n\nliệu đã đánh dấu và từ điển chuyên biệt. Với ưu điểm là thuật toán đơn giản, dễ \n\nhiểu, dễ cài đặt, nhưng phương pháp IGATEC vẫn cho một kết quả tách từ chấp \n\nnhận được, có thể dùng trong phân loại văn bản.  \n\n\n\n \n  \n\n \n\n 62 \n\n  \n\nCChhưươơnngg  55  \n\nBBÀÀII  TTOOÁÁNN  PPHHÂÂNN  LLOOẠẠII  \n\nTTIINN  TTỨỨCC  ĐĐIIỆỆNN  TTỬỬ  \n \n\n \n\nLý do chọn phương pháp Naïve Bayes \n\nThuật toán Naïve Bayes \n\nCông thức xác suất đầy đủ Bayes \n\nTính độc lập có điều kiện (Conditional Independence) \n\nNguồn gốc Naïve Bayes \n\nNaïve Bayes trong phân loại văn bản \n\nHai mô hình sự kiện trong phân loại văn bản bằng Naïve \n\nBayes \n\nBài toán phân loại tin tức điện tử tiếng Việt \n\nKết quả \n\n \n\n\n\n \n  \n\n \n\n 63 \n\nChương 5. BÀI TOÁN PHÂN LOẠI TIN TỨC ĐIỆN TỬ \nNhằm tận dụng phương pháp tách từ  IGATEC đã được đề cập ở chương trên, \n\ntrong chương này chúng em sẽ giới thiệu cách phân loại tin tức điện tử tự động sử \n\ndụng phương pháp Naïve Bayes và giải thích sự phù hợp của Naïve Bayes với \n\nphương pháp tách từ IGATEC. \n\n5.1. Lý do chọn phương pháp Naïve Bayes \n Như đã được giới thiệu trong chương 2, Naïve Bayes là một phương pháp rất \n\nphổ biến sử dụng xác suất có điều kiện giữa từ và chủ đề để xác định chủ đề của văn \n\nbản. Các xác suất này dựa trên việc thống kê sự xuất hiện của từ và chủ đề trong tập \n\nhuấn luyện. Tập huấn luyện lớn có thể mang lại kết quả khả quan cho Naïve Bayes. \n\nInternet với hơn 10 tỷ trang web là một tập huấn luyện rất phong phú về mọi chủ đề \n\ntrong cuộc sống. Hơn nữa, với số lượng chủ đề tin tức điện tử không nhiều (khoảng \n\n20 chủ đề) thì việc sử dụng Internet như cơ sở dữ liệu  huấn luyện rất phù hợp. \n\nTrong báo chí, với mỗi chủ đề luôn có các từ chuyên môn với tần số xuất hiện rất \n\ncao, việc tận dụng tần số phụ thuộc của các từ này vào chủ đề có thể đem lại kết quả \n\nkhả quan cho phân loại.  \n\nVới dữ liệu được tạo ra nhờ công cụ tách từ GA và trích xuất thông tin từ \n\nGoogle, theo đánh giá của chúng em, thì phương pháp Naïve Bayes là khá phù hợp \n\nvì các dữ liệu đầu vào cho hướng phân loại này hoàn toàn phù hợp với dữ liệu hiện \n\ncó. Điều này sẽ giúp chúng em tiết kiệm được rất nhiều thời gian và công sức tạo \n\nthêm nhiều tập dữ liệu nếu chọn phương pháp phân loại khác. \n\nMặt khác, phương pháp Naïve Bayes là phương pháp khá cổ điển được sử dụng \n\nđầu tiên bởi Maron vào năm 1961 [Maron, 1961], và sau đó rất phổ biến trong các \n\nlãnh vực tìm kiếm, lọc mail, các bộ lọc mail\u2026 nên chúng ta có thể tin tưởng về xác \n\nsuất chính xác và các ưu khuyết điểm của phương pháp này để áp dụng phù hợp. \n\nMột lý do nữa mà chúng em chọn Naïve Bayes bởi phương pháp đơn giản, tốc \n\nđộ nhanh, cài đặt tương đối không quá phức tạp phù hợp với thời gian cho phép của \n\nluận văn. Chúng em không sử dụng kNN, do tập dữ liệu thử nghiệm hiện có là tập \n\n\n\n \n  \n\n \n\n 64 \n\ncác tin tức vắn tắt lấy ngẫu nhiên từ trang VnExpress.net còn khá nhỏ (dưới 1000). \n\nTrong khi đó để có thể sử dụng phương pháp kNN hiệu quả số lượng chủ đề và dữ \n\nliệu thử nghiệm phải lớn hơn nhiều. SVM tuy là một phương pháp được cho là có \n\nhiệu suất cao, nhưng thời gian huấn luyện lại rất lâu. Nnet lại cài đặt quá phức tạp. \n\nVới những lý do trên, chúng em đề xuất chọn phương pháp Naïve Bayes để phân \n\nloại văn bản. \n\n5.2. Thuật toán Naïve Bayes \nTheo tác giả Mitchell (2005), thuật toán phân loại Naïve Bayes có đặc điểm nổi \n\nbật là có khả năng giảm độ phức tạp tính toán từ 2(2n \u2013 1)  về còn 2n. Thế đặc điểm \n\nnào giúp Naïve Bayes có khả năng đó?  \n\n5.2.1. Công thức xác suất đầy đủ Bayes \nGiả sử ta muốn tính toán một hàm không biết giá trị đích :f X Y→  tương \n\nđương với P(Y|X). \n\nĐầu tiên, ta cho rằng Y là biến ngẫu nhiên có giá trị luận lý (boolean). \n\nX là vector gồm n thuộc tính luận lý (boolean), 1 2, ,..., nX X X X= 〈 〉  \n\nÁp dụng luật Bayes, P(Y=yi|X) được tính như sau: \n\n ( | ) ( )( | )\n( | ) ( )\n\nk i i\ni k\n\nk j i\nj\n\nP X x Y c P Y yP Y y X x\nP X x Y c P Y y\n\n= = =\n= = =\n\n= = =∑\n (2.1) \n\nTrong đó P(X|Y) và P(Y) được học từ tập huấn luyện. Tuy nhiên để tính toán \n\nchính xác P(X|Y) thường đòi hỏi rất nhiều dữ liệu huấn luyện. Để hiểu tại sao, \n\nchúng ta sẽ tính toán số lượng tham số cần thiết khi Y là biến boolean, X là vector \n\ngồm n thuộc tính boolean : \n\n( | )ij i jP X x Y yθ = = =  \n\nTrong i phải dựa trên 2n giá trị có thể cho những giá trị của vector X và j cần 2 \n\ngiá trị. Do đó, chúng ta cần tính toán khoảng 2n+1 tham số. Mặc khác, ta phải đảm \n\nbảo \n1\n\n1\nn\n\nij\ni\nθ\n\n=\n\n=∑ cho bất kỳ j cố định nào. Vì vậy, ứng với một giá trị đặc biệt yj, và 2n \n\n\n\n \n  \n\n \n\n 65 \n\ngiá trị có thể của xi, chúng ta chỉ cần tính toán 2n -1 tham số độc lập. Dựa trên giá trị \n\ncủa Y (Y là biến boolean), chúng ta cần tính tổng cộng là 2(2n -1) tham số θij . \n\n5.2.2. Tính độc lập có điều kiện (Conditional Independence) \nĐịnh nghĩa: cho các biến ngẫu nhiên X, Y và Z, chúng ta nói rằng X là độc lập có \n\nđiều kiện với Y gây ra Z, nếu và chỉ nếu xác suất phân phối chủ đạo X là độc lập với \n\ngiá trị của Y  gây ra Z. Lúc đó: \n\n( , , ) ( | , ) ( | )i j k i ki j k P X x Y y Z z P X x Z z∀ = = = = = =  \n\nVí dụ: ta xem ba biến luận lý (boolean) ngẫu nhiên trên đại diện cho các trạng \n\nthái của thời tiết là : Sấm , Mưa, và Sét. Chúng ta đều biết rằng sự kiện Sấm xảy ra \n\nhoàn toàn độc lập với sự kiện Mưa gây ra Sét. Bởi vì khi có Sét sẽ gây ra tiếng Sấm, \n\nnên một khi chúng ta biết rằng có Sét hay không thì ta có thể biết được giá trị của \n\nSấm mà không cần thêm thông tin nào từ Mưa. Trên thực tế, rõ ràng có sự phụ \n\nthuộc giữa Mưa và Sấm, tuy nhiên ta không cần thêm thông tin đó một khi ta đã có \n\nthông tin về Sét. \n\n5.2.3. Nguồn gốc thuật toán Naïve Bayes \nThuật toán phân loại Naïve Bayes dựa trên luật Bayes, với giả định tất cả các \n\nthuộc tính X1\u2026Xn đều độc lập có điều kiện với nhau do sự kiện Y gây ra. Chính giả \n\nthiết này đã đơn giản hóa cách tính của P(X|Y), và vấn đề ước lượng P(X|Y) từ tập \n\nngữ liệu huấn luyện. \n\nChúng ta hãy xét ví dụ sau, giả sử ta có 1 2,X X X= 〈 〉 , lúc đó \n\n1 2\n\n1 2 2\n\n1 2\n\n( | ) ( , | )\n( | , ) ( | )\n( | ) ( | )\n\nP X Y P X X Y\nP X X Y P X Y\nP X Y P X Y\n\n=\n=\n=\n\n \n\nKết quả của dòng thứ nhất là theo cách tính thông thường của xác suất, và dòng \n\nthứ ba là phân tích trực tiếp theo định nghĩa về độc lập có điều kiện. \n\nTừ đó, ta tổng quát hóa lên khi X chứa n thuộc tính đều độc lập với nhau do sự \n\nkiện Y gây ra được biểu diễn như sau: \n\n1\n1\n\n( ... | ) ( | )\nn\n\nn i\ni\n\nP X X Y P X Y\n=\n\n=∏  (2.2) \n\n\n\n \n  \n\n \n\n 66 \n\n Chú ý, khi Y và Xi là biến luận lý (boolean), chúng ta chỉ cần 2n tham số để định \n\nnghĩa P(Xi=xik|Y=yj).  \n\nBây giờ, chúng ta hãy xét đến nguồn gốc của thuật toán Naïve Bayes. Giả sử Y \n\nlà một biến bất kỳ mang giá trị riêng biệt, và các thuộc tính Xi\u2026Xn là thuộc tính rời \n\nrạc hoặc liên tục. Mục đích của chúng ta là huấn luyện để thuật toán phân loại trả ra \n\nsự phân phối xác suất trên các giá trị của Y  đối với mỗi thể hiện X mà ta cần phân \n\nloại. Biểu thức sau đây biểu diễn cho xác suất ứng với giá trị thứ k của Y: \n\n1\n1\n\n1\n\n( ) ( ... | )( | ... )\n( ) ( ... | )\n\nk n k\nk n\n\nj n jj\n\nP Y y P X X Y yP Y y X X\nP Y y P X X Y y\n= =\n\n= =\n= =∑\n\n \n\nTrong đó, tổng giá trị ở mẫu của biểu thức là tổng cho bởi tất cả các giá trị yj của \n\nY. Lúc này, sử dụng công thức (2.2), ta có thể viết lại công thức trên như sau: \n\n1\n\n( ) ( | )\n( | ... )\n\n( ) ( | )\nk i ki\n\nk n\nj i jj i\n\nP Y y P X Y y\nP Y y X X\n\nP Y y P X Y y\n= =\n\n= =\n= =\n∏\n\n∑ ∏\n  (2.3) \n\nCông thức (2.3) là công thức cơ bản của phương pháp phân loại Naïve Bayes. \n\nKhi cho một thể hiện  w 1= ...ne nX X X〈 〉 , theo công thức trên, ta sẽ tính toán được các \n\nxác suất của Y gây ra bởi Xnew bằng cách dựa vào P(Y) và p(Xi|Y) được ước lượng \n\ntừ tập ngữ liệu.Nếu chúng ta chỉ quan tâm đến giá trị lớn nhất của Y, thì sử dụng \n\ncông thức sau: \n\n( ) ( | )\nargmax\n\n( ) ( | )k\nk i ki\n\ny j i jj i\n\nP Y y P X Y y\nY\n\nP Y y P X Y y\n= =\n\n←\n= =\n∏\n\n∑ ∏\n  \n\n5.2.4. Phương pháp Naïve Bayes trong phân loại văn bản \n\n5.2.4.1. Công thức xác suất đầy đủ Bayes \nPhương pháp Naïve Bayes tìm chủ đề của văn bản d bằng các xác định chủ đề có \n\nxác suất P( | )iY c X d= = , xác suất để văn bản d nằm trong lớp ic , lớn nhất thông \n\nqua việc sử dụng công thức xác suất đầy đủ Bayes : \n\n ( | ) ( )( | )\n( | ) ( )\n\ni i\ni\n\nj j\nj\n\nP X d Y c P Y cP Y c X d\nP X d Y c P Y c\n\n= = =\n= = =\n\n= = =∑\n (2.7) \n\n\n\n \n  \n\n \n\n 67 \n\nTrong đó  \n\n jc  là chủ đề thứ j \n\n 1 2( , ,..., )nd w w w=  là văn bản cần phân loại.  \n\n P(Y=ci | X=d) gọi là xác suất xảy ra văn bản d thuộc về chủ đề ci . \n\n P(X=d | Y=ci) gọi là xác suất chủ đề ci có chứa văn bản d trong tập huấn \n\nluyện. \n\nMột cách để xác định ( | )P Y X là sử dụng tập huấn luyện để ước lượng ( | )P X Y  \n\nvà ( )P Y . Sau đó sử dụng công thức xác suất đầy đủ trên để xác định \n\n( | )iP Y c X d= =  với  d  bất kỳ. \n\n5.2.4.2. Uớc lượng P(X|Y) \nGiả sử với mỗi chủ đề, ta có biến cố các từ phụ thuộc vào chủ đề là độc lập có \n\nđiều kiện (conditional independence) với nhau. Ta có công thức của biểu diễn sự \n\nđộc lập có điều kiện của 2 biến cố X,Z vào Y  được trình bày ở 5.2.2 như sau : \n\n( | , ) ( | )P X Y Z P X Z=  \n\nSử dụng giả định trên ta tính được ( | )iP X d Y c= =  : \n\n1 2\n\n1 2\n\n1\n\n( | ) ( , ,.., | )\n( | ) ( | )... ( | )\n\n( | )\n\ni n i\n\ni i n i\nn\n\nj\nj\n\nP X d Y c P w w w Y c\nP w Y c P w Y c P w Y c\n\nP w Y ci\n=\n\n= = = =\n= = = =\n\n= =∏\n\n (2.8) \n\nTừ (2.8), (2.7) được viết lại như sau : \n\n  1 2\n( ) ( | )\n\n( | , ,..., )\n( ) ( | )\n\ni k ik\ni n\n\nj k jj k\n\nP Y c P w Y c\nP Y c w w w\n\nP Y c P w Y c\n= =\n\n= =\n= =\n∏\n\n∑ ∏\n (2.9) \n\nNhờ thống kê trên tập huấn luyện D, ( | )P X Y có thể được ước lượng theo : \n\n \n{ }\n\n{ }\n#\n\n( | )\n#\n\nj i\nj i\n\ni\n\nD X w Y c\nP X w Y c\n\nD Y c\n= ∧ =\n\n= =\n=\n\n (2.10) \n\n\n\n \n  \n\n \n\n 68 \n\nTrong đó \n\n { }# j iD X w Y c= ∧ = : số văn bản trong tập huấn luyện chứa đồng thời wj và ci \n { }# iD Y c= : số văn bản trong tập huấn luyện chứa ci \n\nCông thức ước lượng trên sẽ cho kết quả ( | ) 0j iP X w Y c= = =  khi không có văn \n\nbản chứa đồng thời cả hai (wj và ci). Nhằm tránh trường hợp này, ta nên sử dụng \n\nphép ước lượng đã được làm mịn sau : \n\n \n{ }\n\n{ }\n#\n\n( | )\n#\n\nj i\nj i\n\ni\n\nD X w Y c l\nP X w Y c\n\nD Y c lR\n= ∧ = +\n\n= =\n= +\n\n (2.11) \n\nVới  \n\n R : số lượng chủ đề \n\n l : quyết định độ mịn của phép ước lượng \n\n5.2.4.3. Ước lượng P(Y)  \nViệc ước lượng P(Y=ci) đơn giản là tính phần trăm số văn bản trong tập huấn \n\nluyện có chủ đề ci : \n\n { }#( ) ii\nD Y c\n\nP Y c\nD\n=\n\n= =  (2.12) \n\n5.2.5. Hai mô hình sự kiện trong phân loại văn bản bằng phương pháp \nNaïve Bayes \n\n5.2.5.1. Giới thiệu \nPhân loại văn bản là một lĩnh vực có phạm vi thuộc tính (attribute) rất nhiều bởi \n\nvì thuộc tính của những văn bản cần phân loại là từ (word), mà số lượng từ khác \n\nnhau thì vô cùng lớn. Và thuật toán Naïve Bayes đã thành công trong việc ứng dụng \n\nvào lĩnh vực phân loại với khả năng làm giảm độ phức tạp trên. Mặc dù đây là thuật \n\ntoán khá phổ biến, nhưng trong cộng đồng phân loại văn bản vẫn có một vài điều \n\nlẫn lộn về phương pháp phân loại Naïve Bayes bởi vì có hai mô hình phát sinh khác \n\nnhau vẫn thường được sử dụng. Cả hai mô hình đều sử dụng \u201cnaïve Bayes \n\nassumption\u201d và cả hai đều được giới phân loại gọi là \u201cnaïve Bayes\u201d. \n\n \n\n\n\n \n  \n\n \n\n 69 \n\n5.2.5.2. Mô hình đa biến trạng Bernoulli (Multi-variate Bernoulli Model) \nMột mô hình biểu diễn một văn bản là một vector có thuộc tính nhị phân cho \n\nbiết rằng từ nào có hay không xuất hiện trong văn bản. Số lần xuất hiện của một từ \n\ntrong văn bản là không cần thiết. Ở đây chúng ta có thể hiểu rằng văn bản là sự kiện \n\n(event) và sự có mặt hay vắng mặt của các từ trở thành thuộc tính của sợ kiện. Đấy \n\nchính là mô hình sự kiện đa biến trạng Bernoulli (multi-variate Bernoulli event \n\nmodel), một mô hình khá truyền thống, đã được nhiều người sử dụng trong phân \n\nloại văn bản. Theo McCallum & Nigam (1998), một số công trình tiêu biểu về \n\nhướng tiếp cận này là Robertson & Sparck-Jones (1976), Lewis(1992), Kalt & Croft \n\n(1996), Larkey & Croft (1996), Koller & Sahami (1997), Sahami (1996).  \n\n5.2.5.3. Mô hình đa thức (Multinomial Model) \nMô hình thứ hai cho rằng một văn bản đại diện tập hợp tần số xuất hiện của từ \n\ntrong văn bản. Do đó, thứ tự xuất hiện của từ được bỏ qua nhưng tần số xuất hiện \n\nđược giữ lại. Ở đây, chúng ta có thể hiểu rằng những tần số xuất hiện của các từ là \n\nnhững sự kiện (events) và văn bản trở thành tập hợp các sự kiện của từ (word \n\nevents). Chúng ta gọi đây là sự kiện mô hinh đa thức (Multinomial event model). \n\nĐây là hướng tiếp cận thông thường trong mô hình ngôn ngữ học thống kê. Hướng \n\ntiếp cận này cũng được rất nhiều người sử dụng mà theo McCallum & Nigam \n\n(1998) các công trình tiêu biểu như Lewis & Gale (1994), Kalt & Croft (1996), \n\nJoachims (1997), Mitchell (1997), McCallum et al (1998)\u2026 \n\n5.2.5.4. Nhận xét \nĐối với phương pháp multi-variate model, việc không nắm bắt thông tin tần số \n\nxuất hiện của từ có thể đưa đến khuyết điểm không phân biệt được văn bản ưu tiên \n\ncho chủ đề nào hơn nếu cả 2 văn bản đều xuất hiện cùng một từ nào đó nhưng tần \n\nsố lại khác nhau rất nhiều. Ví dụ, nếu từ \u201cthể thao\u201d sẽ xuất hiện nhiều trong các tin \n\ntức về thể thao, và sẽ ít xuất hiện trong các tin tức có nội dung khác, nhưng do \n\nphương pháp multi-variate không sử dụng thông tin tần số nên không phân biệt \n\nđược văn bản ưu tiên cho thể thao hơn.  Trong khi đó, hướng tiếp cận multinomial \n\nmodel rõ ràng đã sử dụng thông tin về xác suất phân phối từ trong văn bản. \n\n\n\n \n  \n\n \n\n 70 \n\nĐối với phương pháp mulnomial, do sử dụng tần số xuất hiện của từ nên sẽ phụ \n\nthuộc vào chiều dài văn bản, vì tài liệu càng dài, sự xuất hiện của các từ càng nhiều. \n\nTheo kết quả đạt được của thí nghiệm so sánh giữa hai phương pháp Naïve \n\nBayes trên, McCallum & Nigam (1998) đã đưa ra kết quả là hướng tiếp cận đa biến \n\ntrạng thực hiện tốt với kích thước từ vựng nhỏ (<500 từ), còn phương pháp mô hình \n\nđa thức thường cho kết quả tốt hơn đối với kích thước từ vựng lớn (>500 từ). \n\n5.3. Bài toán phân loại tin tức điện tử tiếng Việt \n\n5.3.1. Quy ước \n Với mỗi văn bản d , sau khi sử dụng GA để loại bỏ dấu câu và stopword, ta thu \n\nđược d được tách thành nhiều ngữ g dưới dạng sau d={g1,g2,\u2026, gm} , với gi là tập \n\nhợp gồm n cách tách của một ngữ, gi =  {ti1,ti2,\u2026,tin} trong đó tij là một cách tách \n\nngữ., tij = {w1,w2,\u2026,wp}.  \n\nVí dụ:  \n\n \n\nHình 5. 1. Minh họa quy ước cho văn bản \n\nViệc phân loại sẽ gán một chủ đề ch ∈ C={c1,c2,\u2026,cq} cho văn bản, mỗi chủ đề \n\nlại bao gồm nhiều từ khóa (keyword) K={k1,\u2026,kr}. Cây phân cấp chủ đề và từ khóa \n\nthể hiện như sau : \n\n \n\nHình 5. 2.Minh họa chủ đề \u201cXã hội\u201d \n\n\n\n \n  \n\n \n\n 71 \n\nTrong phần này chúng em sẽ trình bày các phương pháp tính toán được sử dụng \n\ntrong phân loại bao gồm: công thức được dùng trong IGATEC [H.Nguyen et al, \n\n2005]và công thức Naïve Bayes [Mitchell, 2005].  \n\n5.3.2. Công thức phân loại văn bản trong IGATEC [H. Nguyen et al, 2005] \nCông thức phân loại văn bản trong IGATEC [H.Nguyen et al, 2005] do chính \n\ntác giả đề nghị theo cách sử dụng độ phụ thuộc của văn bản vào chủ đề. Độ phụ \n\nthuộc này được tính dựa vào xác suất đồng xuất hiện của các từ trong văn bản với \n\nmột từ khóa nhất định. Chi tiết cách tính này như sau :  \n\nCho trước một từ khóa k , độ phụ thuộc của từ w vào k được tính như sau: \n\n( & )( | )  \n( )\n\np k wp k w\np w\n\n=  \n\nTrong đó  \n\n p(w) là xác suất xuất hiện của từ w trên Google được tính  theo công thức  \n\n( )( )= count wp w\nMAX\n\n (đã trình bày ở mục  4.5.1.2) \n\n p( k & w ) là xác suất xuất hiện đồng thời của chủ đề k và từ wi  trên Google \n\nvới:   ( & )( & ) count k wp k w\nMAX\n\n=   (đã trình bày ở mục 4.5.1.2.) \n\nTiếp theo, độ liên quan (relative) của một cách tách ngữ t với từ khóa k bằng \n\ntổng xác suất của tất cả các từ w xuất hiện đồng thời với từ khóa k như sau: \n\n1\n\n( , ) ( | )\np\n\ni\ni\n\nrel t k p k w\n=\n\n=∑  \n\nĐộ hỗ trợ (support) của cách tách ngữ t trên vào chủ đề c={k1,k2,\u2026,ks} là : \n\n1\n\n1( , ) ( , )\ns\n\ni\ni\n\nSP t c rel t k\ns =\n\n= ∑  \n\nTheo công thức trên, tác giả cho rằng văn bản có độ hỗ trợ vào một chủ đề càng \n\ncao thì khả năng văn bản đó thuộc về chủ đề này càng lớn. Dựa vào các công thức, \n\nđộ phụ thuộc của câu được xác định theo công thức: \n\n1 1 1\n\n1( , ) ( , ) ( , )\nm m n\n\ni ij\ni i j\n\nSP d c SP g c SP t c\nn= = =\n\n= =∑ ∑ ∑  \n\n\n\n \n  \n\n \n\n 72 \n\nTheo các công thức trên, văn bản d sẽ thuộc về chủ đề có SP(d,c) lớn nhất. \n\n5.3.3. Công thức Naïve Bayes trong bài toán phân loại tin tức điện tử \ntiếng Việt sử dụng thống kê từ Google \n\nỞ mục 5.2, chúng em đã trình bày các công thức Naïve Bayes cơ bản dùng \n\nthông tin xác suất học được từ tập dữ liệu huấn luyện. Tuy nhiên, hướng tiếp cận \n\ncủa chúng em không sử dụng tập ngữ liệu mà sử dụng thông tin thống kê từ Google \n\nnên các công thức trên được chúng em cải tiến cho phù hợp.  \n\n5.3.3.1. Ước lượng P(X|Y) \nVới công thức (2.11) được trình bày ở mục 5.2.  như sau:  \n\n{ }\n{ }\n\n#\n( | )\n\n#\nj i\n\nj i\ni\n\nD X w Y c\nP X w Y c\n\nD Y c\n= ∧ =\n\n= =\n=\n\n \n\nnếu sử dụng cho tập ngữ liệu có sẵn, công thức có ý nghĩa là xác suất chủ đề ci  \n\nchứa văn văn bản có wj  bằng số văn bản có chứa wj thuộc ci trên tổng số văn bản \n\nthuộc chủ đề ci. Tuy nhiên, trong hướng tiếp cận dựa trên Google, chúng ta không \n\nthể xác định được số lượng văn bản thực sự thuộc chủ đề ci . Do đó, chúng em đề \n\nxuất cách tính xác suất khác phù hợp với hướng tiếp cận dựa trên thống kê Google: \n\n \n{ }\n\n{ }\n# ( & ) 1\n\n( | )\n# ( & ) | |\n\nj i j i\nj i\n\ni j kk\n\nD X w Y c p w c\nP X w Y c\n\nD Y c p w c Y\n= ∧ = +\n\n= = =\n= +∑\n\n (4.1) \n\nTrong đó:  \n\n p(wj & ci ) là xác suất xuất hiện đồng thời wj và ci . \n\n k số thứ tự của các chủ đề, {1,...,| |}k Y∈  \n\nCông thức trên cho kết quả dựa trên xác suất xuất hiện đồng thời wj và ci trên \n\ntổng số lần xuất hiện số lần xuất hiện wj trong tất cả các chủ đề. \n\n5.3.3.2. Ước lượng P(Y) \nVới công thức (2.12) được trình bày ở mục 5.2 là: \n\n { }#( ) ii\nD Y c\n\nP Y c\nD\n=\n\n= =  (4.2)  \n\n\n\n \n  \n\n \n\n 73 \n\nỞ công thức này, ta giả sử các trang web chứa từ khóa ci đều thuộc chủ đề ci.  \n\nLúc đó, P(Y=ci) bằng xác suất xuất hiện ci trên tổng số trang web chứa tất cả các \n\nchủ đề: \n\n { }# ( )( )\n( )\n\ni i\ni\n\njj\n\nD Y c p cP Y c\nD p c\n=\n\n= = =\n∑\n\n \n\nTrong đó \n\n p(ci) : tần số xuất hiện của chủ đề ci  trên Google \n\n j : là chỉ số của các chủ đề cần phân loại \n\n5.3.3.3. Ước lượng P(Y|X) \nKhi đó công thức Naïve Bayes cho phân loại văn bản (2.9) sẽ có dạng : \n\n 1 2\n( ) ( & )\n\n( | , ,..., )\n( ) ( & )\ni k ik\n\ni n\nj k jj k\n\np c p w c\nP Y c w w w\n\np c p w c\n= = ∏\n\n∑ ∏\n (4.3) \n\nVì tần số xuất hiện p(w) (mục 4.5.1)  của từ trên Google rất nhỏ nên việc tính \n\nxác suất 1 2( | , ,..., )i nP Y c w w w=  theo công thức (4.3) có thể dẫn đến việc tràn số do \n\nnhân các số thực gần với 0. Chúng em khắc phục vấn đề này bằng cách chuyển \n\ncông thức (4.3) sang sử dụng log : \n\n( )\n( )\n( ) ( )\n( ) ( )( )\n\n1 2\n\nlog ( ) ( & )\n( | , ,..., )\n\nlog ( ) ( & )\n\nlog ( ) log ( & )\n\nlog ( ) log ( & )\n\ni k ik\ni n\n\nj k jj k\n\ni k ik\n\nj k jj k\n\np c p w c\nP Y c w w w\n\np c p w c\n\np c p w c\n\np c p w c\n\n\u2032 = = −\n\n+\n= −\n\n+\n\n∏\n∑ ∏\n\n∑\n∑ ∑\n\n \n\nVăn bản d sẽ được phân loại vào chủ đề ci có giá trị 1 2( | , ,..., )i nP Y c w w w\u2032 =  cao \n\nnhất. \n\n\n\n \n  \n\n \n\n 74 \n\n5.4. Kết luận \nCác phương pháp phân loại văn bản dựa trên công thức của IGATEC và phương \n\npháp Naïve đều tương đối đơn giản, không bị hạn chế về tập huấn luyện như khi sử \n\ndụng các phương pháp khác. Ngoài ra, các phương pháp trên cũng không gặp \n\ntrường hợp sai lạc do có sự thay đổi trong tập huấn luyện bởi tính linh hoạt đối với \n\nsự thay đổi nhờ dùng thông tin thống kê từ Google. \n\nCác kết quả trên thu nhận được thông qua việc chạy hệ thống thử nghiệm phân \n\nloại ViKass sẽ được mô tả chi tiết trong chương tiếp theo. \n\n \n\n\n\n \n  \n\n \n\n 75 \n\n  \n\nCChhưươơnngg  66  \n\nHHỆỆ  TTHHỐỐNNGG  TTHHỬỬ  \n\nNNGGHHIIỆỆMM  PPHHÂÂNN  LLOOẠẠII  VVĂĂNN  \n\nBBẢẢNN  \n \n\n \n\nGiới thiệu hệ thống thử nghiệm Vikass \n\nThử nghiệm các cách trích xuất thông tin \n\nDữ liệu thử nghiệm \n\nThử nghiệm các công thức tính độ tương hỗ MI  \n\nThử nghiệm phân loại tin tức điện tử \n\n \n\n\n\n \n  \n\n \n\n 76 \n\nChương 6. HỆ THỐNG THỬ NGHIỆM PHÂN LOẠI    \nVĂN BẢN \n\n6.1.  Giới thiệu hệ thống thử nghiệm Vikass \n\n6.1.1. Chức năng hệ thống Vikass \nHệ thống thử nghiệm phân loại văn bản Vikass được xây dựng nhằm mục đích \n\nkiểm nghiệm phương pháp tách từ IGATEC và các phương pháp phân loại đề cập ở \n\nchương trước nhằm tìm ra được các tham số tối ưu trước khi tích hợp vào toà soạn \n\nbáo điện tử. Các tham số này bao gồm các tham số chạy thuật toán di truyền như số \n\nlượng cá thể ban đầu, số thế hệ tối ưu,  tỉ lệ lai ghép, tỉ lệ đột biến; cách tính MI \n\nhiệu quả và phương pháp phân loại nào cho kết quả tốt hơn. Ngoài tích hợp mô-đun \n\ntrích tần số xuất hiện từ Google, hệ thống còn cung cấp các tính năng khác như trích \n\ntin tức, chỉnh sửa từ khóa. Chức năng của hệ thống sẽ được mô tả chi tiết trong các \n\nphần tiếp theo. \n\n6.1.2. Tổ chức và xử lý dữ liệu \n\n6.1.2.1. Giới thiệu chung \nHướng tiếp cận của luận văn dựa trên thống kê từ Google, điều đó có nghĩa là \n\nmỗi lần cần lấy tần số xuất hiện của một từ mới, hệ thống phải thực hiện lấy thông \n\ntin từ Internet. Điều này làm tiêu tốn rất nhiều thời gian chờ đợi, do vậy mỗi khi lấy \n\nđược thông tin từ Google, chúng em lưu lại vào một file dữ liệu đệm để có thể sử \n\ndụng lại mỗi khi cần đến.  \n\nVới mục đích làm tăng tốc độ xử lý của chương trình thử nghiệm, việc quản lý \n\ndữ liệu hoàn toàn được thực hiện trên file văn bản thông thường trên kiểu phông \n\nphổ biến của tiếng Việt là phông Unicode UTF8.  \n\nHệ thống thử nghiệm cần hai loại thông tin như sau: \n\n Đối với thử nghiệm tách từ tiếng Việt, hệ thống cần thông tin về xác suất \n\nxuất  hiện của các từ trên Google. \n\n Đối với việc thử nghiệm phân loại văn bản, hệ thống cần thông tin về xác \n\nsuất xuất hiện đồng thời của từ và từ khoá tương ứng với chủ đề. \n\n\n\n \n  \n\n \n\n 77 \n\n6.1.2.2. Tổ chức dữ liệu \nTừ những yêu cầu trên, hệ thống dữ liệu được thiết kế thành ba file có nội dung \n\nnhư sau: \n\n \n\nHình 6. 1. Tổ chức file dữ liệu \n\n File CACHE: là dạng file văn bản thông thường, chứa thông tin: \n\n Từ: từ đã tìm từ Google \n\n Xác suất: xác suất của từ đó trên Google \n\n Loại từ: mang một trong các giá trị W(là từ), NW (không là từ), WC ( \n\ncó thể là từ), NWC (không thể là từ), UD (chưa phân loại). \n\n File KEYWORD: File được viết dưới dạng xml bao gồm thông tin về tên chủ \n\nđề các cấp: \n\n Tên chủ đề: tên của chủ đề các cấp (cấp 1 và cấp 2) \n\n Chỉ số: chỉ số của mỗi chủ đề cho biết vị trí của chủ đề trong danh \n\nsách xác suất của từ với từng chủ đề trong file Relevant.  \n\n Chọn dạng xml để lưu tên chủ đề vì tính chất lồng nhau ở từng cấp \n\ncủa chủ đề rất thích hợp với cấu trúc dạng cây của tài liệu xml.  \n\n Ví dụ, ta có các chủ đề cấp 1 là \u201cthể thao\u201d và các chủ đề cấp 2 của nó \n\nlà \u201cBóng đá\u201d, \u201cQuần vợt\u201d như hình vẽ dưới đây\u201d \n\n \n\nHình 6. 2. Chủ đề Thể thao \n\nLúc đó, nội dung file chủ đề sẽ có nội dung như sau: \n\n\n\n \n  \n\n \n\n 78 \n\n \n File RELEVANT: chứa thông tin: \n\n Từ: từ đã tìm \n\n Danh sách xác suất của từ với từng chủ đề: xác suất xuất hiện đồng \n\nthời của từ ứng với từng chủ đề theo chỉ số được lưu trong file \n\nKEYWORD. \n\nSau khi thực hiện thử nghiệm, dung lượng file CACHE đã lên đến gần 10M và \n\nfile RELEVANT xấp xỉ 50M. Với khối lượng dữ liệu lớn như vậy, việc sử dụng \n\nmột hệ quản trị cơ sở dữ liệu là không cần thiết bởi vì việc xử lý thông tin trong hệ \n\nthống là đơn giản và yêu cầu tiên quyết của chương trình là tốc độ xử lý cao. Như \n\nvậy, chọn lựa lưu trữ thông tin dưới dạng văn bản bình thường là phù hợp với yêu \n\ncầu hệ thống. \n\n6.1.2.3. Xử lý dữ liệu \nKhi bắt đầu hoạt động, hệ thống tự động thực hiện đọc các file dữ liệu, phân tích \n\nchuỗi trong file để lấy thông tin và đưa vào bộ nhớ dưới dạng \u201cbảng băm\u201d \n\n(hashtable). Hệ thống thử nghiệm được phát triển nên ngôn ngữ C#, là một ngôn \n\nngữ khá mạnh hỗ trợ nhiều cấu trúc lưu trữ thông tin trong đó có hỗ trợ bảng băm. \n\nNhờ vậy mà việc tổ chức dữ liệu trở nên đơn giản hơn rất nhiều. Ngoài ra, cách xử \n\nlý như vậy sẽ làm tăng tốc độ tìm kiếm thông tin của từ nhờ các ưu điểm tổ chức dữ \n\nliệu của bảng băm.  \n\n<?xml version=\"1.0\" encoding=\"utf-8\" ?> \n\n<keyword> \n\n <topic name=\"thể thao\" value=\"1\"> \n\n  <topic name=\"bóng đá\" value=\"2\" /> \n\n  <topic name=\"quần vợt\" value=\"3\" /> \n\n <\/topic> \n\n<\/keyword> \n\n\n\n \n  \n\n \n\n 79 \n\n6.1.3. Một số màn hình của hệ thống Vikass \n\n \n\nHình 6. 3. Màn hình tách từ và phân loại \n\nSTT Mô tả \n1 Chọn thư mục chứa các tập tin cần tách từ và phân loại \n2 Chọn thư mục lưu kết quả \n3 Liệt kê tên các tập tin được chọn tách từ và phân loại \n4 Di chuyển các tập tin qua lại để chọn các tập tin thực hiện tách từ \n5 Liệt kê tên tất cả các tập tin có trong thư mục (1) \n6 Thực hiện tách từ và phân loại \n7 Dừng tách thực thi \n8 Xem tập tin kết quả phân loại \n9 Tab tùy chọn các thông số chạy GA \n10 Tab tùy chọn các thông số như loại MI sử dụng, có sử dụng stopword hay \n\nkhông ? \n11 Tab chọn các từ khóa sẽ sử dụng cho việc phân loại \n\nBảng 6. 1. Mô tả một số control của màn hình tách từ \n\n\n\n \n  \n\n \n\n 80 \n\nMàn hình môđun trích xuất từ Google: \n\n \n\nHình 6. 4.  Màn hình trích xuất từ Google \n\nSTT Mô tả \n1 Chọn thư mục chứa các tập tin như tập tin đệm, tập tin chứa độ liên quan \n\ncủa từ và từ khóa,\u2026 \n2 Các tùy chọn như chỉ tìm kiếm các từ có tần số 0, chỉ tìm các trang .vn, tìm \n\nkiếm độ liên quan của từ và từ khóa\u2026 \n3 Các phương pháp tải về sử dụng \n4 Thanh biểu thị tiến trình tìm kiếm và trích từ \n5 Thực hiện tìm kiếm và trích xuất \n6 Lưu lại tập tin đệm và tập tin chứa độ liên quan \n7 Dừng việc tìm kiếm \n8 Danh sách các từ đã được tìm kiếm \n\nBảng 6.2. Mô tả một số control của màn hình trích từ Google \n\n \n\n\n\n \n  \n\n \n\n 81 \n\nMàn hình phân loại tin tức điện tử hỗ trợ toà soạn báo điện tử : \n\n \n\nHình 6. 5. Màn hình phân loại tin tức điện tử \n\nSTT Mô tả \n1 Thiết lập các tham số kết nối đến SQL server \n2 Lấy các tin tức được toà soạn báo điện tử tải về \n3 Thực hiện phân loại \n4 Cập nhật các tin tức đã được phân loại vào SQL server \n5 Thực hiện tất cả các bước (2),(3),(4) \n6 Hiển thị các thông tin như : nội dung tin, tên của chủ đề được phân loại,\u2026 \n\nBảng 6.3. Bảng mô tả một số control của màn hình phân loại tin tức điện tử \n\n \n\n \n\n\n\n \n  \n\n \n\n 82 \n\n6.2. Thử nghiệm các cách trích xuất thông tin \nViệc trích xuất thông tin về tần số xuất hiện của từ, độ liên quan giữa từ và chủ \n\nđề được thực hiện thông qua module Google Extractor. Nhằm mục đích tăng tốc \n\ntrích thông tin từ Google, chúng em đã thử nghiệm trích thông tin bằng nhiều cách \n\nkhác nhau và thực hiện kết nối đến Google sử dụng nhiều luồng (>=15). Bên cạnh \n\nđó, để tránh việc phải thực hiện tìm kiếm nhiều lần, các tập tin đệm được sử dụng \n\nvới mục đích lưu lại hay cập nhất kết quả các lần tìm kiếm trước.  \n\n6.2.1. Các phương pháp thử nghiệm \nChúng em sử dụng 3 cách khác nhau để lấy kết quả tìm kiếm bao gồm sử dụng \n\ndịch vụ web do Google cung cấp, tải trang kết quả về máy cục bộ sau đó sử dụng \n\nXPath hay tìm kiếm chuỗi.  \n\n6.2.1.1. Google web service \nDịch vụ web là một ứng dụng cung cấp giao diện lập trình, hỗ trợ sự truyền  \n\nthông từ ứng dụng này đến ứng dụng khác qua mạng dùng XML. Dịch vụ web của \n\nGoogle tại địa chỉ http://api.google.com/GoogleSearch.wsdl là một phương pháp \n\ntiện lợi để khai thác công cụ tìm kiếm này. Tuy nhiên, ta phải đăng kí tài khoản \n\ntrước khi sử dụng. Với mỗi tài khoản Google giới hạn số lượng truy vấn là 1000 \n\ntruy vấn/ngày. Các tham số cần biết khi sử dụng dịch vụ : \n\n \n\nTham số tìm kiếm \n\nq Câu truy vấn  \n\nn Số kết quả trả về trên từng trang \n\nlr Giới hạn phạm vi ngôn ngữ tìm kiếm \n\nie Bảng mã câu truy vấn sử dụng \n\noe Bảng mã của kết quả trả về \n\nBảng 6. 4. Tham số sử dụng dịch vụ Google \n\nMột số câu truy vấn đặc biệt trên Google : \n\n \n\n\n\n \n  \n\n \n\n 83 \n\nTruy vấn đặc biệt Câu truy vấn Ý nghĩa \n\nLoại bỏ một từ bass \u2013music \u201c-\u201d để loại bỏ 1 từ ra khỏi kết \n\nquả tìm kiếm \n\nTừ khóa OR vacation london OR \nparis \n\nOR  \n\nGiới hạn site Admission \nsite:www.stanford.edu \n\nsite: chỉ tìm kiếm trong site \n\nđược chỉ định \n\nGiới hạn ngày Star Wars \ndaterange:2452122-\n\n2452234 \n\ndaterange: chỉ trả về các file có \n\nnhãn thời gian thõa điều kiện \n\nLọc file Google filetype:doc OR \nfiletype:pdf \n\nfiletype: chỉ tìm kiếm các file \n\ncó kiểu mở rộng được liệt kê \n\nLoại trừ file Google doc -filetype: \n-filetype:pdf \n\n-filetype: ngược lại với \n\nfiletype: \n\nTìm theo tiêu đề intitle:Google search intitle: chỉ tìm kiếm tiêu đề web\n\nBảng 6. 5. Một số câu truy vấn đặc biệt của Google \n\nTrong quá trình thử nghiệm sử dụng dịch vụ web của Google, chúng em nhận \n\nthấy thời gian đáp ứng không được nhanh (khoảng >5s cho một truy vấn-sử dụng \n\nmạng Internet của trường) hơn nữa còn tồn tại nhiều lỗi. Lý do có thể kể đến như \n\nphiên bản dịch vụ đang trong quá trình thử nghiệm (bản β), hạn chế do dung lượng \n\nmạng, chi phí chứng thực. Giới hạn 1000truy vấn/ngày cũng ảnh hưởng đến chương \n\ntrình khi phải thực hiện trích xuất trên lượng lớn các từ. Để khắc phục vấn đề này, \n\nchúng em sử dụng biện pháp tải trang kết quả về. \n\n6.2.1.2.  Xpath và tìm kiếm chuỗi \nTrang kết quả trả về sẽ được chuyển sang định dạng xHTML dùng cho việc trích \n\nxuất dùng Xpath (http://www.w3.org/TR/XPath20)  hay thực hiện tìm kiếm trên \n\nchuỗi. Cả hai phương pháp này đều cho hiệu suất tốt (khoảng 1-3s/truy vấn). \n\nXpath là định dạng được W3C đề nghị được sử dụng rộng rãi trong việc truy vấn \n\ntập tin XML. Sử dụng Xpath có thuận lợi hơn tìm kiếm chuỗi ở chỗ có thể sử dụng \n\ntrích xuất trên nhiều ngôn ngữ trả về từ Google và nếu cấu trúc của trang web thay \n\n\n\n \n  \n\n \n\n 84 \n\nđổi thì ta vẫn lấy được thông tin trả về của Google. Trong khi đó việc tìm kiếm \n\nchuỗi sẽ phụ thuộc vào các câu đặc biệt (như \u201ccác kết quả \u201d... ). Do đó, nếu các \n\ntrang trả về của Google trình bày khác đi, cách tìm kiếm chuỗi sẽ không cho kết quả \n\nmong muốn. Tuy nhiên, sử dụng cách tìm kiếm chuỗi sẽ cho kết quả nhanh hơn \n\ndùng Xpath vì hệ thống không phải tốn một thời gian phân tích dữ liệu thành dạng \n\ntài liệu XML. \n\n6.2.2. Nhận xét \nHiện tại, điều chúng ta quan tâm hàng đầu là tốc độ trích thông tin từ Google. \n\nMặt khác, trang web Google có cấu trúc khả ổn định, hầu như không thay đổi. Vì \n\nvậy khi thực hiện thử nghiệm, chúng em sử dụng cách thức tìm kiếm chuỗi để đạt \n\ntối độ cao nhất. Tuy nhiên, chúng em vẫn xây dựng các lựa chọn rút trích để tạo tính \n\nlinh hoạt trong thử nghiệm. \n\n6.3. Dữ liệu thử nghiệm \n\n6.3.1. Nguồn dữ liệu \nDữ liệu thử nghiệm được lấy từ trang tin tức VnExpress.net \n\n(www.vnexpress.net) tại thời điểm tháng 6/2005. Đây là một trong  những trang tin \n\ntức điện tử đầu tiên tại Việt Nam ra đời vào ngày 26/2/2001, đến nay đã hơn bốn \n\nnăm hoạt động với lượng độc giả đông đảo trong cả nước và quốc tế. Ngoài các \n\ntrang mục do phóng viên của tờ báo viết, VnExpress.net còn mở rộng đón nhận các \n\nbài viết do độc giả gửi về từ khắp nơi để làm phong phú thêm cho nội dung của tờ \n\nbáo và cập nhật tin tức thường xuyên nhanh chóng.  \n\n6.3.2. Số lượng dữ liệu thử nghiệm \nTừ các mục của VnExpress.net, đầu tiên chúng em chọn lọc ra một số mục  \n\nchính để lấy dữ liệu thử nghiệm.  \n\nVì chúng em quy định từ khóa cho chủ đề chính là tên chủ đề đó nên trong quá \n\ntrình thử nghiệm, chúng em phát hiện ra một số trường hợp nhập nhằng.  \n\n\n\n \n  \n\n \n\n 85 \n\nĐầu tiên, từ khóa Thế giới, Xã hội có ý nghĩa bao quát có thể về Kinh tế thế \n\ngiới, chính trị thế giới, văn hóa xã hội\u2026,  nên khả năng các tin tức được phân loại \n\nvào chủ đề này là rất cao do tần số xuất hiện của chủ đề này với các từ phổ biến lớn.  \n\nThứ hai, một số mục có tên không đồng nhất giữa các tờ báo điện tử như trang \n\nVnExpress.net dùng Vi tính trong khi đó TuoiTre.com.vn lại dùng Nhịp sống số, \n\nVnn.vn dùng Công nghệ thông tin và Viễn thông.... Việc này làm giảm kết quả khi \n\nsử dụng từ khóa khóa Vi tính cho chủ đề này vì từ khóa này không bao quát được \n\ncho các trang sử dụng tên chủ đề khác mặc dù cùng trình bày một nội dung.  \n\nDo vậy, chúng em chỉ sử dụng một số mục có từ khóa rõ ràng. Đối với mỗi tin \n\ntức, chúng em chỉ tách lấy phần tiêu đề, phần tóm lược và phần chú thích ảnh. Đây \n\nlà các phần có ý nghĩa phân loại cao do được người viết bài tóm lược và chọn lọc. \n\nỨng mỗi chủ đề, chúng em lấy ngẫu nhiên 100 tin. Còn cách giải quyết phần nhập \n\nnhằng trình bày ở trên sẽ là hướng mở rộng của luận văn. Tổng dữ liệu thử nghiệm \n\nlà 1500 tập tin bao gồm 15 chủ đề cấp 2, mỗi chủ đề 100 tập tin. \n\n \n\n\n\n \n  \n\n \n\n 86 \n\n \n\nHình 6. 6. Cây chủ đề \n\n6.3.3. Nhận xét \nMặc dù dữ liệu dùng thử nghiệm khá nhỏ do hạn chế về mặt thời gian, nhưng \n\ncách thức chọn dữ liệu và chủ đề thử nghiệm phân loại của chúng em đã mở rộng \n\nrất nhiều so với 35 văn bản thử nghiệm của [H. Nguyen et al, 2005] trên 5 chủ đề \n\nChính trị, Giáo dục, Kinh doanh, Sức khỏe, Thể thao. \n\n\n\n \n  \n\n \n\n 87 \n\n6.4. Thử nghiệm các công thức tính độ tương hỗ MI  \n\n6.4.1. Các phương pháp thử nghiệm \nNhằm xác định hiệu quả của các cách tính MI trong việc tách từ tiếng Việt, \n\nchúng em thực hiện thử nghiệm 3 công thức MI đã được trình bày ở mục 4.5: một \n\ncông thức tính MI của [H.Nguyen et al, 2005] (gọi là MI1) , một của [Ong & Chen, \n\n1999] (gọi là MI2), một do chúng em đề nghị (gọi là MI3) . Ứng với mỗi công thức \n\ntính MI trên, chúng em thử nghiệm thêm việc tách stopword và không tách \n\nstopword trước khi tách từ. Mục đích của việc tách stopword trước khi tách từ nhằm \n\ntạo ra nhiều ngữ nhỏ hơn khi đã bỏ các từ không có ý nghĩa, để làm tăng tốc độ tách \n\ntừ của hệ thống.  \n\nNhư vậy, tổng cộng có 6 thử nghiệm tách từ như sau:  \n\n MI1 tách stop word (MI1_NonSW) \n\n MI1 không tách stop word (MI1_SW)  \n\n MI2 tách stop word (MI2_NonSW) \n\n MI2 không tách stop word (MI2_NonSW) \n\n MI3 tách stop word (MI3_NonSW) \n\n MI3 không tách stop word (MI3_NonSW) \n\nChúng em thử nghiệm các công thức trên 1500 nội dung tóm tắt các tin tức của \n\nVnExpress.net \n\n6.4.2. Kết quả \nĐộ chính xác của các công thức tính độ tương hỗ như sau: \n\n \n\nCách tính MI Không tách stop word Có tách stopword \n\nMI 1 [H. Nguyen et al, 2005] 74% 72% \n\nMI 2 [Ong & Chen, 1999] 60% 55% \n\nMI 3 (chúng em đề nghị) 72% 69% \n\nBảng 6. 6. Kết quả thực nghiệm các công thức tính độ tương hỗ MI \n\n\n\n \n  \n\n \n\n 88 \n\n0%\n\n10%\n\n20%\n\n30%\n\n40%\n\n50%\n\n60%\n\n70%\n\n80%\n\nMI1 MI2 MI3\nLoại MI\n\nĐộ\n c\n\nhí\nnh\n\n x\nác\n\nNon SW\nSW\n\n \n\nHình 6. 7. Biểu đồ so sánh kết quả các công thức tính độ tương hỗ MI \n\n6.4.3. Nhận xét \nTrong 6 cách thử nghiệm, cách tách từ dùng công thức MI1. có độ chính xác cao \n\nnhất.  \n\nThời gian chạy tách từ lúc đầu khá lâu (trung bình khoảng 10 phút cho một mẫu \n\ntóm tắt dài khoảng 100 tiếng) đa phần là do thời gian lấy thông tin từ Google. \n\nNhưng khi thông tin về tần số xuất hiện của các từ đã được lưu lại tương đối lớn (độ \n\nlớn file cache khoảng 10M), thì tốc độ tách từ giảm xuống đáng kể (trung bình \n\n<1giây đối với các văn bản không cần lấy thông tin từ Internet) \n\nCách tiếp cận của công thức MI1 là ưu tiên dựa trên từ ghép có hai tiếng, mà \n\ntheo thống kê dựa trên từ điển của chúng em, số từ 2 tiếng chiếm đa số trong từ \n\nvựng tiếng Việt. Cách tính này cho kết quả khá tốt vì vừa thoả mãn được tính chất \n\ntự  nhiên dựa trên ưu thế áp đảo của từ 2 tiếng, vừa được chứng minh bằng thực \n\nnghiệm. \n\nTrong các trường hợp thử nghiệm có tách stopword, thời gian tách từ giảm đi rất \n\nnhiều (trung bình 5 phút cho văn bản mới). Tuy nhiên, trong quá trình thử nghiệm, \n\nchúng em nhận thấy việc tách stopword có thể làm sai lạc ý nghĩa của văn bản ban \n\n\n\n \n  \n\n \n\n 89 \n\nđầu do danh sách stopword đưa vào không hoàn chỉnh. Vì vậy kết quả tách từ có \n\ntách stopword không cao như  cách tách thuần tuý. \n\n6.5. Thử nghiệm phân loại tin tức điện tử \n\n6.5.1. Thước đo kết quả phân loại văn bản \nĐể đánh giá hiệu quả phân loại văn bản, thông thường người ta dùng các chỉ số \n\nvề độ thu về-recall và độ chính xác-precision [Yang, 2000]. Cho một phương pháp \n\nphân loại văn bản, đầu vào là một văn bản, và kết quả trả về là một danh sách các \n\nchủ đề được gán cho văn bản đó, chỉ số độ thu về, độ chính xác có thể được tính \n\nnhư sau: \n\n \n\n \n\nHình 6. 8. Các thông số dùng tính độ thu về, độ chính xác \n\nHình trên mô tả các thông số sau:  \n\n (A) là tất cả văn bản thực hiện phân loại văn bản cho chủ đề T  \n\n (B) là số văn bản được phân loại lấy về cho chủ đề T  \n\n (C) là số văn bản thực sự thuộc về chủ đề T  \n\n (D) là số văn bản lấy về chính xác.  \n\nCác tham số trên được dùng trong công thức tính độ thu về-recall, độ chính xác-\n\nprecision dưới đây:  \n\n \n\n\n\n \n  \n\n \n\n 90 \n\n \nViệc gán nhãn chủ đề của các phương pháp phân loại văn bản có thể được đánh \n\ngiá bằng cách dùng bảng trường hợp hai chiều ứng với từng loại chủ đề: \n\n \n\n Chủ đề đang xét ĐÚNG \nvới chủ đề văn bản \n\nChủ đề đang xét SAI \nvới chủ đề văn bản \n\nPhân loại ĐÚNG \n với chủ đề văn bản \n\na b \n\nPhân loại SAI  \nvới chủ đề văn bản \n\nc d \n\nBảng 6. 7. Bốn trường hợp của phân loại văn bản \n\nNhư vậy, với mỗi kết quả phân loại cho một văn bản, ta sẽ có được một trong 4 \n\ntrường hợp a,b,c hoặc d. Từ đó, ta tính được các chỉ số sau: \n\n arecall\na c\n\n=\n+\n\n nếu a + c >0, ngược lại là không xác định. \n\n aprecision\na b\n\n=\n+\n\n nếu a + b >0, ngược lại là không xác định. \n\n Tuy nhiên, cách tính với độ thu về, độ chính xác riêng rẽ sẽ cho kết quả \n\nkhông cân đối. Ví dụ nếu số văn bản lấy về đúng (D) gần bằng với số văn \n\nbản đúng thực sự (C) thì chỉ số độ thu về sẽ cao, tuy nhiên nếu số văn bản lấy \n\nvề (B) khá nhiều so với (D) sẽ cho chỉ số độ chính xác nhỏ. Do vậy, thông \n\nthường người ta thêm một chỉ số F1 [Yang , 1997] để phản ánh sự cân đối \n\ngiữa 2 độ đo trên: \n\n21 1 1F\n\nrecall precision\n\n=\n+\n\n \n\nNgoài ra, để tính toán hiệu quả thực thi trên toàn bộ chủ đề, thông thường người \n\nta còn sử dụng hai phương pháp macro-averaging và micro-averaging. \n\nMacro-averaging tính trung bình các chỉ số recall, precision, fallout, Acc,Err \n\ncủa tất cả các chủ đề. \n\n\n\n \n  \n\n \n\n 91 \n\nMicro-averaging tính toán các chỉ số dựa trên tổng giá trị a, b, c, d của từng chủ \n\nđề dựa theo các công thức áp dụng tính cho một chủ đề. \n\nSự khác nhau chủ yếu giữa hai cách tính macro-averaging và micro-averaging \n\nlà :  micro-averaging tính toán dựa trên trọng số của mỗi văn bản, nên cho kết quả \n\ntrung bình trên mỗi văn bản (per-document average); trong khi đó, macro-\n\naveraging tính toán trọng số trên mỗi chủ đề, do đó, kết quả cho sẽ đại diện cho giá \n\ntrị trung bình trên mỗi chủ đề (per-category average). \n\n6.5.2. Các phương pháp thử nghiệm \nỞ phần phân loại văn bản, chúng em thử nghiệm 2 công thức đã được trình bày \n\nở 5.3. là công thức phân loại được sử dụng trong [H. Nguyen et al, 2005] (gọi tắt là \n\ncông thức IClass) và công thức tính Naïve Bayes được cải tiến cho phù hợp với \n\nhướng tiếp cận dựa trên Google (gọi tắt là NBClass). \n\nỨng với công thức phân loại, chúng em thử nghiệm với 2 công thức tính MI: \n\nmột của [H. Nguyen et al, 2005] (gọi tắt là MI1) và một công thức MI do chúng em \n\nđề xuất (gọi tắt là MI3) cho hai trường hợp tách và không tách stopword.Ở phần này \n\nchúng em không thử nghiệm với MI2 của [Ong & Chen, 1999] vì kết quả tách từ \n\ncủa công thức này thấp hơn các công thức khác khá nhiều sẽ cho kết quả không tốt. \n\nNhư vậy tổng cộng chúng em thực hiện 8 lần thử nghiệm phân loại như sau: \n\n Công thức IClass + MI1 + tách stop word \n\n Công thức IClass + MI1 + không tách stop word \n\n Công thức IClass + MI3 + tách stop word \n\n Công thức IClass + MI3 + không tách stop word \n\n Công thức NBClass + MI1 + tách stop word \n\n Công thức NBClass + MI1 + không tách stop word \n\n Công thức NBClass + MI3 + tách stop word \n\n Công thức NBClass + MI3 + không tách stop word \n\n6.5.3. Kết quả \n\n\n\n \n  \n\n \n\n 92 \n\nSau khi thực hiện phân loại văn bản, chúng em sử dụng các độ đo đã được trình \n\nbày ở mục 6.5.1. để tính toán kết quả chính xác của các thử nghiệm phân loại. Kết \n\nquả tính toán được trình bày trong bảng thống kê sau: \n\n \n\nPhương \npháp Tên chủ đề R P F1 \n\nXã hội 0.62625 0.654047 0.639847\n\nKhoa học 0.72 0.975434 0.828475\n\nThể thao 0.765 0.968245 0.854706\n\nKinh doanh 0.795 0.293358 0.428571\n\nMacro 0.763437 0.892427 0.822908\n\nIClass  \n\n+ MI 1 \n\n+tách \n\nstopword \n\nMicro 0.663 0.682801 0.672755\n\nXã hội 0.764 0.636667 0.694545\n\nKhoa học 0.7216 0.942131 0.81725\n\nThể thao 0.65625 0.975 0.784483\n\nKinh doanh 0.816 0.348718 0.488623\n\nMacro 0.814333 0.951923 0.877769\n\nIClass  \n\n+ MI 1 \n\n+không \n\ntách \n\nstopword \n\nMicro 0.656 0.672131 0.663968\n\nXã hội 0.630 0.660 0.645\n\nKhoa học 0.857 0.873 0.865\n\nThể thao 0.861 0.915 0.887\n\nKinh doanh 0.630 0.740 0.681\n\nMacro 0.913 0.892 0.903\n\nIClass  \n\n+ MI 3 \n\n+tách \n\nstopword \n\nMicro 0.678 0.700 0.689\n\nXã hội 0.772 0.784 0.778IClass  \n\n+ MI 3 Khoa học 0.808 0.851 0.829\n\n\n\n \n  \n\n \n\n 93 \n\nThể thao 0.882 0.825 0.853\n\nKinh doanh 0.637 0.523 0.575\n\nMacro 0.858 0.830 0.844\n\n+không \n\ntách \n\nstopword \n\nMicro 0.553 0.566 0.559\n\nXã hội 0.680 0.738 0.708\n\nKhoa học 0.810 0.841 0.825\n\nThể thao 0.924 0.918 0.921\n\nKinh doanh 0.725 0.620 0.668\n\nMacro 0.785 0.779 0.782\n\nNBClass  \n\n+ MI 1 \n\n+tách \n\nstopword \n\nMicro 0.648 0.633 0.640\n\nXã hội 0.591 0.697 0.640\n\nKhoa học 0.704 0.897 0.789\n\nThể thao 0.886 0.918 0.902\n\nKinh doanh 0.675 0.581 0.625\n\nMacro 0.714 0.773 0.742\n\nNBClass  \n\n+ MI 1 \n\n+không \n\ntách \n\nstopword \n\nMicro 0.783 0.633 0.700\n\nXã hội 0.544 0.636 0.586\n\nKhoa học 0.680 0.855 0.757\n\nThể thao 0.708 1.142 0.874\n\nKinh doanh 1.404 0.332 0.537\n\nMacro 0.748 0.721 0.734\n\nNBClass  \n\n+ MI 3 \n\n+tách \n\nstopword \n\nMicro 0.725 0.648 0.684\n\nXã hội 0.611 0.590 0.600\n\nKhoa học 0.485 0.616 0.543\n\n \n\nNBClass  \n\n+ MI 3  \nThể thao 0.749 1.095 0.890\n\n\n\n \n  \n\n \n\n 94 \n\nKinh doanh 0.660 0.739 0.697\n\nMacro 0.626 0.760 0.687\n\n+không \n\ntách \n\nstopword \nMicro 0.647 0.647 0.647\n\nBảng 6. 8. Kết quả phân loại văn bản cho từng chủ đề ở cấp 1 \n\n0\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\n0.5\n\n0.6\n\n0.7\n\n0.8\n\n0.9\n\n1\n\nI M\nI1 \n\nSW\n\nI M\nI1 \n\nNo\nnS\n\nW\n\nI M\nI3 \n\nSW\n\nI M\nI3 \n\nNo\nnS\n\nW\n\nBa\nye\n\ns M\nI1 \n\nSW\n\nBa\nye\n\ns M\nI1 \n\nNo\nn S\n\nW\n\nBa\nye\n\ns M\nI3 \n\nSW\n\nBa\nye\n\ns M\nI3 \n\nNo\nnS\n\nW\n\nXã hội\nKhoa học\nThể thao\nKinh doanh\nMacro\nMicro\n\n \n\nHình 6. 9. Biểu đồ F1 cho cấp 1 \n\nVì kết quả của phần thử nghiệm phân loại ở cấp hai rất dài, nên chúng em chỉ \n\nxin trình bày biểu đồ kết quả phân loại mà không trình bày chi tiết bảng kết quả cho \n\ntừng chủ đề. \n\nSau đây là kết quả phân loại cho các chủ đề cấp 2. \n\n\n\n \n  \n\n \n\n 95 \n\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n\nI M\nI1 \n\nSW\n\nI M\nI1 \n\nNo\nnS\n\nW\n\nI M\nI3 \n\nSW\n\nI M\nI3 \n\nNo\nnS\n\nW\n\nBa\nye\n\ns M\nI1 \n\nSW\n\nBa\nye\n\ns M\nI1 \n\nNo\nn S\n\nW\n\nBa\nye\n\ns M\nI3 \n\nSW\n\nBa\nye\n\ns M\nI3 \n\nNo\nnS\n\nW\n\nGiáo dục\nDu học\nLối sống\nDu Lịch\nKhoa học\nBóng đá\n\n \n\n0\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\n0.5\n\n0.6\n\n0.7\n\n0.8\n\nI M\nI1 \n\nSW\n\nI M\nI1 \n\nNo\nnS\n\nW\n\nI M\nI3 \n\nSW\n\nI M\nI3 \n\nNo\nnS\n\nW\n\nBa\nye\n\ns M\nI1 \n\nSW\n\nBa\nye\n\ns M\nI1 \n\nNo\nn S\n\nW\n\nBa\nye\n\ns M\nI3 \n\nSW\n\nBa\nye\n\ns M\nI3 \n\nNo\nnS\n\nW\n\nQuần vợt\nBất động sản\nChứng khoán\nQuốc tế\nÂm nhạc\nThời trang\n\n \n\n\n\n \n  \n\n \n\n 96 \n\n0\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\n0.5\n\n0.6\n\nI M\nI1 \n\nSW\n\nI M\nI1 \n\nNo\nnS\n\nW\n\nI M\nI3 \n\nSW\n\nI M\nI3 \n\nNo\nnS\n\nW\n\nBa\nye\n\ns M\nI1 \n\nSW\n\nBa\nye\n\ns M\nI1 \n\nNo\nn S\n\nW\n\nBa\nye\n\ns M\nI3 \n\nSW\n\nBa\nye\n\ns M\nI3 \n\nNo\nnS\n\nW\n\nĐiện ảnh\nLàm đẹp\nGiới tính\nmacro\nmicro\n\n \n\nHình 6. 10. Biểu đồ F1 cho cấp 2 \n\n6.5.4. Nhận xét \nTrong hai mức phân loại chủ đề, ta nhận thấy kết quả phân loại ở mức 1 cho độ \n\nchính xác cao hơn mức 2. Lý do là vì số lượng chủ đề của cấp 2 nhiều hơn cấp 1 rất \n\nnhiều (15 so với 4 ở cấp 1) và một số chủ đề của cấp 2 chưa thực sự tốt như Bất \n\nđộng sản, Lối sống, Làm đẹp, Giới tính. Từ đó, ta thấy được việc xây dựng danh \n\nsách từ khoá cho mỗi chủ đề một yêu cầu cần thiết để nâng hiệu suất phân loại văn \n\nbản.  \n\nDựa vào kết quả thử  nghiệm ta nhận thấy rằng trong việc phân loại sử dụng \n\nBayes tốt hơn công thức phân loại của H. Nguyen et al (2005) trong nhiều trường \n\nhợp. Trong các thử  nghiệm công thức của H.Nguyen et al (2005), độ hỗ trợ của kết \n\nquả vào chủ đề đối có giá trị rất gần nhau, khi áp dụng cho các chủ đề hầu như \n\nkhông có sự khác biệt. Trong khi đó, với công thức Naïve Bayes, có một số chủ đề \n\n\n\n \n  \n\n \n\n 97 \n\nnổi trội hơn hẳn các chủ đề khác và kết quả thống kê cũng cho thấy Naïve Bayes \n\ncho kết quả chính xác hơn.  \n\nKết quả của thử nghiệm công thức trong [H.Nguyen et al, 2005] với độ chính \n\nxác chưa cao lắm bởi vì đấy là công thức do chính tác giả đề nghị chưa dựa trên cơ \n\nsở lý thuyết vững chắc. Trong khi đó, phương pháp Naïve Bayes đã xuất hiện khá \n\nlâu, được chứng minh trên lý thuyết và thực nghiệm nên độ tin cậy rất cao. Việc sử \n\ndụng hướng tiếp cận Naïve Bayes cho phân loại văn bản dựa trên Google có thể nói \n\nlà bước cải tiến đáng khíck lệ so với cách phân loại cũ. \n\nDựa vào biểu đồ, ta nhận thấy sự kết hợp giữa phương pháp phân loại Naïve \n\nBayes và công thức tính độ tương hỗ (MI) của [H. Nguyen et al, 2005] cho kết quả \n\nphân loại tốt nhất. Trong đó, tỉ lệ trung bình của phương pháp cho các chủ đề ở cấp \n\n1 là 75%, và cho các chủ đề ở cấp 2 là 67%. Kết quả này hợp lý vì thực nghiệm cho \n\nthấy công thức MI1 của H.Nguyen et al (2005) cho kết quả tách từ chính xác cao \n\nnhất nên đã góp phần làm cho kết quả phân loại tốt hơn.  \n\nKết quả phân loại văn bản trung bình giữa 8 cặp  là 75%, là kết quả chấp nhận \n\nđược đối với phân loại văn bản tiếng Việt. Kết quả không cao so với kết quả phân \n\nloại bằng tiếng Anh bởi vì như chúng ta đã biết phần tách từ tiếng Việt gặp rất nhiều \n\nphức tạp. \n\n \n\n\n\n \n  \n\n \n\n 98 \n\nCChhưươơnngg  77  \n\nỨỨNNGG  DDỤỤNNGG  PPHHÂÂNN  LLOOẠẠII  \n\nTTIINN  TTỨỨCC  ĐĐIIỆỆNN  TTỬỬ  TTỰỰ  \n\nĐĐỘỘNNGG  \n \n\nGiới thiệu tòa soạn báo điện tử \n\nTính cần thiết của phân loại tin tức tự động \n\nPhân tích hiện trạng \n\nMô hình DFD quan niệm cấp 2 hiện hành cho ô xử lý Nhận \n\nbài và Trả bài \n\nPhê phán hiện trạng \n\nMô hình DFD quan niệm cấp 2 mới cho ô xử lý Nhận bài và \n\nTrả bài \n\nTriển khai DLL \n\nChương trình cài đặt \u201cTòa soạn báo điện tử\u201d đã tích hợp module \n\nphân loại tin tức \n\nKết quả \n\n\n\n \n  \n\n \n\n 99 \n\nChương 7. ỨNG DỤNG PHÂN LOẠI TIN TỨC ĐIỆN TỬ \nTỰ ĐỘNG  \n\nNhằm đánh giá hiệu quả thực tế của việc phân loại sử dụng IGATEC và Naïve \n\nBayes, chúng em đã xây dựng công cụ phân loại thành một module đồng thời tích \n\nhọp vào trong tòa soạn báo điện tử. Trong chương này, chúng em sẽ giới thiệu sơ \n\nlược về tòa soạn báo điện tử và mô tả cách thức tích hợp module phân loại. \n\n7.1. Giới thiệu tòa soạn báo điện tử \nPhần mềm tòa soạn báo điện tử (Luận văn khóa 2000-Hoàng Minh Ngọc và \n\nNguyễn Duy Hiệp) xây dựng trên nền tảng DotNetNuke tuân thủ theo qui trình của \n\nmột tòa soạn thực tế đi từ soạn bài, duyệt bài và đăng bài. Mỗi biên tập viên sẽ phụ \n\ntrách một mảng chủ đề. Cộng tác viên hay người dùng sau khi viết bài phải được \n\nbiên tập viên duyệt. Nếu nội dung và hình thức chấp nhận được thì bài được chuyển \n\nlên vị trí có chức năng đưa bài lên website chính thức. Người quản trị sẽ phân công \n\nchuyên mục và chủ đề cho các biên tập viên. Nếu đã qua các cấp kiểm duyệt, bài \n\nviết được phép đưa lên website. Nếu tại một cấp nào đó, người quản lý thấy bài viết \n\ncần được chỉnh sửa thì bài viết sẽ được trả về đúng cấp có thẩm quyền. \n\nNgoài ra, tòa soạn báo điên tử còn hỗ trợ việc thu thập tin tức điện tử từ nhiều \n\nnguồn khác nhau. Tin tức được tải về sau đó phải được các biên tập viên xác định \n\nchủ đề và chuyên mục mà bài báo thuộc về để tiến hành thủ tục đăng bài. Việc phân \n\nloại tin tức ở giai đoạn thực hiện luận văn này là hoàn toàn thủ công. \n\n7.2. Tính cần thiết của phân loại tin tức tự động \nViệc thực hiện phân loại thủ công trên số lương lớn các tin tức được tải về có thể \n\nngốn rất nhiều thời gian và công sức. Nhằm làm tăng tính hiệu quả cũng như hỗ trợ \n\ntối đa cho các biên tập viên tập trung vào các công việc khác quan trọng hơn. \n\nModule phân loại tin tức tự động đã được xây dựng. Nhiệm vụ của module này là \n\nthực hiện phân loại tự động các tin tức tải về nhằm đề xuất sắp xếp tin tức này vào \n\nmột chuyên mục hợp lý. Module được viết dưới dạng một thư viện dll thực hiện các \n\n\n\n \n  \n\n \n\n 100 \n\ncông việc như sau: lấy các tin tức được tải về, tiến hành phân loại và cập nhật vào \n\ncơ sở dữ liệu. \n\n7.3.  Phân tích hiện trạng \nMục đích của luận văn chúng em là tích hợp phần xử lý phân loại trang web tự \n\nđộng vào phần duyệt bài viết và sửa bài viết nên chúng em chỉ trình bày mô hình  \n\nDFD cho ô xử lý \u201cNhận bài và Trả bài\u201d. Để tìm hiểu về toàn cảnh mô hình DFD \n\ncủa toà soạn báo điện tử, xin tham khảo luận văn \u201cToà soạn báo điện tử\u201d  của \n\nHoàng Minh Ngọc Hải (0012545), Nguyễn Duy Hiệp (0012038)) \n\n7.3.1. Mô hình DFD quan niệm cấp 2 hiện hành cho ô xử lý Nhận bài và \nTrả bài \n\n7.3.1.1. Mô hình \n \n\n \n\nHình 7. 1.Mô hình DFD hiện hành \n\n7.3.1.2. Mô tả mô hình \nThành viên có chức năng viết bài nhận bài viết mới được giao, sau khi hoàn \n\nthành thì lưu xuống kho dữ liệu những bài viết chưa đăng để chờ duyệt. Sau khi bài \n\nviết được duyệt, thành viên kiểm tra xem bài viết có cần chỉnh sửa không, nếu có thì \n\n\n\n \n  \n\n \n\n 101 \n\nthực hiện chỉnh sửa sau đó lưu phiên bản mới của bài viết chờ duyệt tiếp. Ngoài ra, \n\ncác bài báo được lấy tự động từ Internet xuống cũng được lưu trong kho dữ liệu các \n\nbài viết chưa đăng để chờ duyệt. \n\n7.3.1.2.1. Mô tả kho dữ liệu \n\n \nHệ thống thông \n\ntin: \n\nXây dựng toà \n\nsoạn báo điện tử \n\nMô hình quan niệm xử lý \n\nHiện tại [] \n\nTương lai[]  \n\nTrang :  \n\nỨng dụng :  \n\nXây dựng toà \n\nsoạn báo điện tử \n\n \n\nMô tả kho dữ liệu : \n\nNHỮNG BÀI VIẾT CHƯA \n\nĐƯỢC ĐĂNG \n\nTờ : \n\nNgày lập : 28/6/2004 \n\nNgười lập :  \n\n1. Hoàng Minh Ngọc Hải \n2. Nguyễn Duy Hiệp \n\n \n\nDòng dữ liệu vào : \n\nBài viết đã chỉnh sửa \n\nBài viết mới \n\n \n\nDòng dữ liệu ra : \n\nBài viết cần chỉnh sửa \n\n \n\nDiễn giải : \n\nKho này lưu trữ những bài viết đang nằm trong dây chuyền \n\n \n\nCấu trúc dữ liệu: \n\nMA_BAI_VIET \n\nMA_CHUYEN_MUC \n\nMA_TAC_GIA \n\n\n\n \n  \n\n \n\n 102 \n\nNGAY_VIET \n\nTIEU_DE \n\nNOI_DUNG \n\nDUONG_DAN_ANH \n\nKICH_THUOC_ANH \n\nCHIEU_DAI \n\nCHIEU_RONG \n\n \n\nKhối lượng : \n\n- Hiện tại : Không xác định \n- Tương lai : Không xác định \n\n \n\nThông tin thường truy xuất : \n\nMA_BAI_VIET \n\nMA_CHUYEN_MUC \n\nTIEU_DE \n\nNOI_DUNG \n\n \n\nBảng 7. 1. Bảng kho dữ liệu những bài viết chưa được đăng \n\n7.3.1.2.2. Mô tả ô xử lý \n\n \n\nÔ xử \nlý Tên \n\nDòng dữ \nliệu vào \n\nDòng dữ \nliệu ra Diễn giải \n\n(1.1) Nhận bài \nviết mới \n\nBài viết Bài viết mới Phóng viên sau khi viết một bài \nmới sẽ gửi vào hệ thống. \nNhững bài viết này được lưu \ndưới dạng những bài viết chưa \nđược xử lý. \n\n(1.2) Lưu bài \nviết mới \n\nBài viết mới Bài viết mới Lưu bài viết dưới tình trạng \n\u201cChưa xử lý\u201d \n\n\n\n \n  \n\n \n\n 103 \n\n(1.3) Kiểm tra \nnhững bài \nviết cần \nxử lý \n\nNhu cầu \nkiểm tra \n\nThông tin cá \nnhân \n\nBài viết cần \nchỉnh sửa \n\nKiểm tra các bài viết đã được \nduyệt xem có cần chỉnh sửa \nkhông \n\n(1.4) Nhận bài \nviết đã \nchỉnh sửa \n\nBài viết đã \nchỉnh sửa \n\nBài viết đã \nchỉnh sửa \n\nBài viết sau khi thành viên (có \nchức năng chỉnh sửa) duyệt, \nchỉnh sửa và trả lại cho thành \nviên phụ trách bài viết đó. \n\n(1.5) Lưu \nphiên bản \nmới của \nbài viết \n\nBài viết đã \nchỉnh sửa \n\nBài viết đã \nchỉnh sửa \n\nBài viết đã chỉnh sửa được lưu \nvào CSDL dưới tình trạng \u201cĐã \nxử lý\u201d tại cấp vừa chỉnh sửa và \ndưới tình trạng \u201cChưa xử lý\u201d \ntại cấp được chuyển bài về \n\n(1.6) Lấy tin tự \nđộng \n\nTin tức điện \ntử \n\nTin tức điện \ntử \n\nHệ thống tự động lấy tin tức từ \ncác trang báo khác và lưu \nxuống kho dữ liệu \n\n \n\nBảng 7. 2. Bảng mô tả các ô xử lý của mô hình DFD hiện hành \n\n7.3.2. Phê phán hiện trạng \nHiện tại, hệ thống tự động lấy tin tức từ các trang báo điện tử khác về và gán vào \n\ncác mục đã được chỉ định sẵn. Tuy nhiên, việc chỉ định chủ đề cho các tin tức lấy về \n\nmột cách cứng nhắc chỉ đúng trong trường hợp trang web lấy tin có cấu trúc chủ đề \n\ntương ứng với chủ đề trong  toà soạn báo điện tử của mình. Đối với những trang báo \n\ncó cấu trúc khác đi, việc gán nhãn mặc định cho các bài báo sẽ không còn đúng nữa.  \n\nVí dụ ở toà soạn báo điện tử của chúng ta có mục Kinh doanh\\Quốc tế, còn ở \n\nbáo www.vnexpress.net có mục Thế giới bao gồm nhiều nội dung, trong đó có một \n\nsố tin tức về Kinh doanh quốc tế, một số tin tức về chính trị thế giới, một số bài về \n\nvăn hoá chẳng hạn. Như vậy nếu ta chỉ định các bài báo lấy từ mục tin Thế giới ở \n\nwww.vnexpress.net  đều được xếp vào mục Kinh doanh\\Quốc tế thì kết quả không \n\ncòn đúng hoàn toàn nữa. Lúc đó, các thành viên duyệt bài lại phải đọc lần lượt các \n\n\n\n \n  \n\n \n\n 104 \n\nbài báo được lấy về một cách thủ công để phân loại chủ đề của tin tức cho phù hợp \n\nvới cấu trúc chủ đề của mình. \n\nĐể hạn chế trường hợp trên, chúng em đưa ra giải pháp là tích hợp module phân \n\nloại văn bản vào việc xử lý lấy tin tự động từ Internet. Các tin tức vừa được lấy về \n\nsẽ được module phân loại văn bản phân loại tự động vào các chủ đề có sẵn của toà \n\nsoạn báo. Như vậy, chúng ta sẽ tiết kiệm được nhiều công sức và thời gian duyệt bài \n\ncủa các thành viên một cách đáng kể. \n\n7.3.3. Mô hình DFD quan niệm cấp 2 mới cho ô xử lý Nhận bài và Trả bài \n\n7.3.3.1. Mô hình \n \n\n \n\nHình 7. 2. Mô hình DFD cải tiến \n\n7.3.3.2. Mô tả mô hình \nMô hình mới chỉ thêm một ô xử lý việc phân loại tin tức tự động sau khi hệ \n\nthống lấy tin tức từ trang web khác về.  \n\n\n\n \n  \n\n \n\n 105 \n\n7.3.3.2.1. Mô tả ô xử lý \n\nÔ xử \nlý Tên \n\nDòng dữ \nliệu vào \n\nDòng dữ \nliệu ra Diễn giải \n\n(1.7) Phân loại \ntin tức tự \nđộng \n\nTin tức điện \ntử \n\nTin tức điện \ntử đã phân \nloại \n\nModule phân loại văn bản mới \ntích hợp vào hệ thống thực hiện \nphân loại tự động các tin tức \nvừa lấy về. \n\nBảng 7. 3. Bảng mô tả ô xử lý phân loại tin tức tự động \n\n7.4. Triển khai DLL \nChương trình phân loại văn bản tự động được viết trên ngôn ngữ C#, trong khi \n\n\u201cTòa soạn báo điện tử\u201d của luận văn khóa 2000 được viết mã trên nền VB.Net. Do \n\nđó, để tích hợp hai hệ thống lại, chúng em đã xây dựng các thành phần chính dùng \n\ntrong phân loại văn bản thành DLL.  \n\nCó thể nói, việc đóng gói chương trình thành dạng DLL ngoài tính tiện lợi trong \n\nviệc tích hợp giữa các hệ thống xây dựng trên các ngôn ngữ khác nhau, goíi DLL \n\ncòn có ưu điểm là khả năng sử dụng đơn giản, dễ mang chuyển, là yếu tố quan trọng \n\ntrong việc xây dựng chương trình. \n\n\u201cTòa soạn báo điện tử\u201d của luận văn khóa 2000 được xây dựng khá công phu về \n\nmặt hình thức lẫn nội dung, cho nên khi tích hợp DLL mới vào,  chúng em nhận \n\nthấy không cần thiết phải thiết lập thêm giao diện nào nữa. Chúng em chỉ tạo thêm \n\nmột số lựa chọn cho người dụng có thể bật tắt chức năng phân loại. \n\n\n\n \n  \n\n \n\n 106 \n\n \n\nHình 7. 3. Màn hình lấy tin tức cho phép phân loại tự động \n\n7.5. Chương trình cài đặt \u201cTòa soạn báo điện tử\u201d đã tích hợp \nmodule phân loại tin tức \n\n\u201cTòa soạn báo điện tử\u201d của luận văn khóa 2000 hiện tại chưa xây dựng công cụ \n\ncài đặt vài gỡ chương trình tự động (Install và Uninstall), đòi hỏi người dùng phải \n\ncó nhiều kiến thức về SQL Server để có thể cài đặt cơ sở dữ liệu một cách thủ công. \n\nVì vậy, nhằm tăng thêm tính tiện dụng của \u201cTòa soạn báo điện tử\u201d, chúng em tự xây \n\ndựng công cụ cài đặt tự động \u201cTòa soạn báo điện tử\u201d vào máy chỉ với thao tác click \n\nchuột. Công cụ cài đặt thực hiện việc thiết lập cơ sở dữ liệu vào hệ quản trị SQL \n\nServer, thư mục ảo chứa nội dung trang web trong IIS, và tạo shorcut trên desktop.  \n\nMột số giao diện của công cụ cài đặt: \n\n\n\n \n  \n\n \n\n 107 \n\n \n\nHình 7. 4. Màn hình bắt đầu. Click Next để bắt đầu cài đặt \n\n \n\nHình 7. 5.Màn hình chọn chế độ cài đặt hoặc tháo gỡ chương trình.  \n\nChọn Install và click Next để sang bước tiếp theo \n\n\n\n \n  \n\n \n\n 108 \n\n \n\nHình 7. 6.Màn hình chọn đường dẫn để cài đặt chương trình.  \n\nSau khi chọn xong các đường dẫn phù hợp, nhấp vào Next để thực hiện cài đặt. \n\n \n\nHình 7. 7.Màn hình cài đặt chương trình \n\n\n\n \n  \n\n \n\n 109 \n\n \n\nHình 7. 8.Màn hình chọn chức năng gỡ chương trình. \n\nChọn Remove để gỡ chương trình đã cài đặt trên máy. \n\n \n\nHình 7. 9.Màn hình gỡ chương trình thành công \n\n\n\n \n  \n\n \n\n 110 \n\n7.6. Kết quả \nNhờ việc tích hợp module phân loại văn bản vào trong web \u201cTòa soạn báo điện \n\ntử\u201d mà giờ đây công việc phân loại tin tức điện tử đã trở nên nhanh chóng và tiện \n\nlợi hơn. Tuy xác suất phân loại đúng chưa đảm bảo cho hệ thống phân loại văn bản \n\nhoàn toàn tự động, mà cần có sự duyệt bài lại để đảm bào chính xác hoàn toàn, \n\nnhưng module phân loại văn bản bán tự động cũng đã cung cấp cho người dùng một \n\ntiện ích vô cùng hữu hiệu. \n\n\n\n \n  \n\n \n\n 111 \n\n  \n\nCChhưươơnngg  88  \n\nTTỔỔNNGG  KKẾẾTT  \n \n\n \n\n \n\nKết quả đạt được  \n\nVề mặt lý thuyết \n\nVề mặt thực hành \n\nHạn chế và hướng giải quyết \n\nKết luận \n\n\n\n \n  \n\n \n\n 112 \n\nChương 8. TỔNG KẾT \n\n8.1. Kết quả đạt được \n\n8.1.1. Về mặt lý thuyết \nPhân loại văn bản là một bài toán khó và rất thú vị. Khó bởi vì vấn đề phân loại \n\nvăn bản cần phải thực hiện xử lý ngôn ngữ, mà như chúng ta đều biết, ngôn ngữ tự \n\nnhiên là muôn hình vạn trạng, không chỉ phong phú về từ vựng, cú pháp mà còn \n\nphức tạp về ngữ nghĩa. Nhưng đây lại là bài toán rất thú vị vì với mỗi ngôn ngữ \n\nkhác nhau, chúng ta phải thực hiện những cách xử lý khác nhau đối với ngôn ngữ. \n\nTrong khuôn khổ luận văn này, những vấn đề liên quan đến đề tài như các \n\nphương pháp tách từ và phương pháp phân loại văn bản đã được chúng em tiến \n\nhành nghiên cứu khá công phu theo cả chiều rộng lẫn chiều sâu về. Trên cơ sở \n\nnghiên cứu đó, các hướng tiếp cận áp dụng cho tiếng Anh và tiếng Hoa phù hợp đã \n\nđược lựa chọn và thử nghiệm lên tiếng Việt.  \n\nĐặc biệt, ở giai đoạn tách từ chuẩn bị cho phân loại, chúng em đã tìm hiểu một \n\ncách sâu sắc về hướng thống kê dựa trên Internet. Dựa trên nền tảng đó, chúng em  \n\nmạnh dạn thực hiện cải tiến phương pháp tách từ dựa trên Internet và thuật toán di \n\ntruyền thay vì sử dụng lại các công cụ tách từ tiếng Việt đã được công bố trước đây. \n\nHướng tiếp cận mới này không những hạn chế được nhược điểm phụ thuộc vào tập \n\nngữ liệu của các phương pháp khác mà còn đem lại khả năng khai thác vô tận nguồn \n\ndữ liệu khổng lồ của nhân loại : word-wide-web. Kết quả đạt được của phương pháp \n\nnày là hoàn toàn khả quan và chấp nhận được đối với một hướng tiếp cận mới cho \n\ntách từ tiếng Việt dùng trong phân loại văn bản.  \n\nPhương pháp phân loại văn bản Naïve Bayes thường được dùng trong phân loại \n\nvăn bản tiếng Anh, nay được áp dụng trong tiếng Việt với hướng tiếp cận dựa trên \n\nthống kê từ Google tỏ ra khá hiệu bởi. Nhờ tính đơn giản, các thông số tính toán \n\nkhông cần quá lớn như các phương pháp khác, khả năng linh hoạt đối với sự thay \n\nđổi về thông tin huấn luyện, thời gian phân loại phù hợp yêu cầu, Naïve Bayes đã tở \n\nra rất phù hợp với các yêu cầu đề ra.  \n\n\n\n \n  \n\n \n\n 113 \n\n8.1.2. Về mặt thực nghiệm \nCông trình nghiên cứu của luận văn đã thực hiện được nhiều thử nghiệm đối với \n\ntừng hướng tiếp cận tách từ tiếng Việt dựa trên Google cũng như phân loại văn bản. \n\nNhờ vậy, kết quả thực nghiệm đã chứng minh được tính hiệu quả cho các công thức \n\ntrên lý thuyết. \n\nQua kết quả thực nghiệm, chúng em nhận thấy công thức tách từ của [H. \n\nNguyen et al, 2005] và công thức MI do chúng em đề nghị cho hiệu quả gần tương \n\nđương nhau, tuy cách tính của [H. Nguyen et al, 2005] có vẻ chính xác hơn cho các \n\ntừ có hai tiếng. \n\nKết quả thực nghiệm ở phần phân loại văn bản cho thấy công thức phân loại \n\ntrong [H. Nguyen et al, 2005] là mang tính chủ quan của tác giả, và dữ liệu thực \n\nnghiệm không đủ lớn để có thể kết luận. Nhưng khi áp dụng thử nghiệm trên số \n\nlượng văn bản và chủ đề nhiều hơn thì cách tính này cho ra kết quả thấp hơn nhiều \n\nso với kết quả mà tác giả trình bày. Kết quả sử dụng công thức Naïve Bayes đã cho \n\nkết quả khả quan hơn nhờ dựa vào lý thuyết đã được chứng minh từ các công trình \n\ntrước. \n\n8.2. Hạn chế và hướng phát triển \nVới những kết quả thử  nghiệm ban đầu, hệ thống phân loại văn bản đã bước đầu \n\nhoạt động hiệu quả , góp phần thực hiện phân loại văn bản bán tự động, giúp tiết \n\nkiệm được thời gian và công sức đọc văn bản một cách thủ công. Mặc dù những kết \n\nquả của hệ thống là chấp nhận được, tuy nhiên hệ thống có thể được cải thiện về độ \n\nchính xác và tốc độ nếu ta khắc phục một số hạn chế của hệ thống và thực hiện \n\nthêm các hướng mở rộng khác được trình bày sau đây. \n\nPhương pháp tách từ dựa trên Internet và thuật toán di truyền tỏ ra khá linh hoạt \n\ntrong việc xử lý ngôn ngữ. Tuy nhiên với mặt bằng chất lượng Internet hiện nay ở \n\nViệt Nam, bước đầu thực hiện việc tách từ sẽ khá lâu vì phải mất thời gian lấy \n\nthông tin từ  công cụ tìm kiếm trên mạng. Nhưng khi các thông tin trên được lưu lại \n\ntương đối lớn, tốc độ phân định ranh giới từ sẽ được cải thiện. \n\n\n\n \n  \n\n \n\n 114 \n\nTrong phần thử nghiệm phân loại văn bản, hiện tại chúng em quy định một chủ \n\nđề chỉ có một từ khóa chính là tên của chủ đề đó. Chính đây là một điểm hạn chế \n\ndẫn đến kết quả phân loại văn bản chưa cao như  trong các công trình phân loại văn \n\nbản tiếng Anh. Do vậy, nhu cầu xây dựng một công cụ chiết xuất từ khóa tự động từ \n\ntập dữ  liệu tin tức thô là rất cần thiết. Khi đã có tập từ khóa, độ chính xác của việc \n\nphân loại văn bản sẽ tăng lên đáng kể. \n\nHiện tại, luận văn thực hiện phân loại theo hướng tiếp cận Naïve Bayes với các \n\ntừ được tách trong câu mà không có sự chọn lựa những từ đặc trưng để thực hiện \n\nphân loại. Điều này dẫn đến một số từ  không có ý nghĩa phân loại vẫn xem như có \n\nvai trò tương tự như  những từ có ý nghĩa phân loại cao. Nếu chúng ta nghiên cứu \n\nthực hiện chọn lựa các đặc trưng của văn bản (feature selection)  rồi mới","u":"http://202.191.57.85:8000/InternetData/Data/khoDATN/DATN-20190523T073801Z-001/CNTT/Tim hieu cac huong tiep can bai toan phan loai van ban va xa.txt","sentences":[[1,"TRƯỜNG ĐẠI HỌC KHOA HỌC TỰ NHIÊN KHOA CÔNG NGHỆ THÔNG TIN BỘ MÔN HỆ THỐNG THÔNG TIN SINH VIÊN THỰC HIỆN NGUYỄN TRẦN THIÊN THANH - 0112243 TRẦN KHẢI HOÀNG - 0112305 TÌM HIỂU CÁC HƯỚNG TIẾP CẬN BÀI TOÁN PHÂN LOẠI VĂN BẢN VÀ XÂY DỰNG PHẦN MỀM PHÂN LOẠI TIN TỨC BÁO ĐIỆN TỬ KHÓA LUẬN CỬ NHÂN TIN HỌC GIÁO VIÊN HƯỚNG DẪN Cử nhân : NGUYỄN VIỆT THÀNH Thạc sĩ : NGUYỄN THANH HÙNG Niên khóa 2001-2005"],[2,"i LỜI CẢM ƠN Chúng em xin gửi lời cảm ơn chân thành và sâu sắc nhất đến thầy Nguyễn Việt Thành và thầy Nguyễn Thanh Hùng đã tận tụy hướng dẫn, động viên, giúp đỡ chúng em trong suốt thời gian thực hiện đề tài"],[3,"Chúng em xin chân thành cảm ơn quý Thầy Cô trong Khoa Công Nghệ Thông Tin truyền đạt kiến thức quý báu cho chúng em trong những năm học vừa qua"],[4,"Chúng con xin nói lên lòng biết ơn đối với Ông Bà, Cha Mẹ luôn là nguồn chăm sóc, động viên trên mỗi bước đường học vấn của chúng con"],[5,"Xin chân thành cám ơn các anh chị và bạn bè đã ủng hộ, giúp đỡ và động viên chúng em trong thời gian học tập và nghiên cứu"],[6,"Mặc dù chúng em đã cố gắng hoàn thành luận văn trong phạm vi và khả năng cho phép nhưng chắc chắn sẽ không tránh khỏi những thiếu sót"],[7,"Chúng em kính mong nhận được sự cảm thông và tận tình chỉ bảo của quý Thầy Cô và các bạn"],[8,"Nguyễn Trần Thiên Thanh & Trần Khải Hoàng 07/2005"],[9,"ii LỜI NÓI ĐẦU Trong những năm gần đây, sự phát triển vượt bậc của công nghệ thông tin đã làm tăng số lượng giao dịch thông tin trên mạng Internet một cách đáng kể đặc biệt là thư viện điện tử, tin tức điện tử..."],[10,"Do đó mà số lượng văn bản xuất hiện trên mạng Internet cũng tăng theo với một tốc độ chóng mặt"],[11,"Theo số lượng thống kê từ Broder et al (2003), lượng thông tin đó lại tăng gấp đôi sau từ 9 đến 12 tháng, và tốc độ thay đổi thông tin là cực kỳ nhanh chóng"],[12,"Với lượng thông tin đồ sộ như vậy, một yêu cầu lớn đặt ra đối với chúng ta là làm sao tổ chức và tìm kiếm thông tin có hiệu quả nhất"],[13,"Phân loại thông tin là một trong những giải pháp hợp lý cho yêu cầu trên"],[14,"Nhưng một thực tế là khối lượng thông tin quá lớn, việc phân loại dữ liệu thủ công là điều không tưởng"],[15,"Hướng giải quyết là một chương trình máy tính tự động phân loại các thông tin trên"],[16,"Chúng em đã tập trung thực hiện đề tài \u201cTìm hiểu các hướng tiếp cận cho bài toán phân loại văn bản và xây dựng ứng dụng phân loại tin tức báo điện tử\u201d nhằm tìm hiểu và thử nghiệm các phương pháp phân loại văn bản áp dụng trên tiếng Việt"],[17,"Để thực hiện việc phân loại, điều bắt buộc đối với tiếng Việt đó là việc tách từ"],[18,"Trong luận văn này, chúng em cũng tìm hiểu một số cách tách từ tiếng Việt và thử nghiệm một phương pháp tách từ mới thích hợp cho việc phân loại mà không dùng bất kỳ từ điển hoặc tập ngữ liệu nào"],[19,"Cuối cùng, chúng em xây dựng phần mềm phân loại văn bản tích hợp vào trang web \u201cToà soạn báo điện tử\u201d (Luận văn khoá 2000 - Hoàng Minh Ngọc Hải (0012545), Nguyễn Duy Hiệp (0012038)) nhằm phục vụ cho việc phân loại tin tức báo điện tử"],[20,"Hiện nay, trang web của khoa chúng ta vẫn chưa thực hiện được việc phân loại tự động các tin tức lấy về, do đó gây ra rất nhiều lãng phí về thời gian và công sức của nhà quản trị cũng như làm giới hạn việc thu thập tin tức từ nhiều nguồn khác nhau"],[21,"Ứng dụng phân loại tin tức báo điện tử tích hợp với việc lấy tin tức tự động của chúng em hy vọng sẽ đem đến một cách quản trị mới, nhanh chóng và hiệu quả hơn cách lấy tin truyền thống"],[22,"Ngoài ra, trong điều kiện cần cập nhật thông tin một"],[23,"iii cách nhanh chóng như hiện nay, phần mềm phân loại văn bản tự động của chúng em còn có khả năng ứng dụng cho nhiều loại trang báo điện tử tiếng Việt khác"],[24,"Nội dung của luận văn được trình bày bao gồm 8 chương; trong đó, 3 chương đầu trình bày các hướng tiếp cận cho phân loại văn bản và tách từ tiếng Việt hiện nay; 2 chương tiếp theo trình bày hướng tiếp cận của luận văn đối với phân loại văn bản và tách từ tiếng Việt; 3 chương cuối trình bày hệ thống thử nghiệm văn bản, ứng dụng vào phân loại tin tức bán tự động, và cuối cùng là đánh giá, kết luận quá trình nghiên cứu của luận văn"],[25,"Chương 1"],[26,"Tổng quan: giới thiệu sơ lược về các phương pháp phân loại văn bản và các hướng tiếp cận cho việc tách từ tiếng Việt; đồng thời xác định mục tiêu của đề tài"],[27,"Chương 2"],[28,"Một số phương pháp phân loại văn bản: giới thiệu tóm tắt một số phương pháp phân loại văn bản dành cho tiếng Anh"],[29,"Chương 3"],[30,"Phương pháp tách từ tiếng Việt hiện nay: trình bày tóm tắt một số phương pháp tách từ tiếng Việt hiện nay, ưu điểm và hạn chế của các phương pháp đó"],[31,"Chương 4"],[32,"Phương Tách từ Tiếng Việt không dựa trên tập ngữ liệu đánh dấu (annotated corpus) hay từ điển (lexicon) \u2013 Một thách thức: trình bày phương pháp tách từ tiếng Việt mới chỉ dựa vào việc thống kê từ Internet thông qua Google mà không cần bất kỳ từ điển hay tập ngữ liệu nào"],[33,"Chương 5"],[34,"Bài toán phân loại tin tức báo điện tử: trình bày hướng tiếp cận cho bài toán phân loại tin tức báo điện tử"],[35,"Chương 6"],[36,"Hệ thống thử nghiệm phân loại văn bản: giới thiệu về hệ thống thử nghiệm các phương pháp tách từ và phân loại văn bản do chúng em xây dựng"],[37,"Ngoài ra, trong chương 6, chúng em trình bày về dữ liệu dùng để thử nghiệm và các kết quả thử nghiệm thu được"],[38,"Chương 7"],[39,"Ứng dụng phân loại tin tức báo điện tử bán tự động: giới thiệu ứng dụng phân loại tin tức báo điện tử do chúng em xây dựng tích hợp"],[40,"iv trên trang web do luận văn \u201cTòa soạn báo điện tử\u201d khóa 2000 xây dựng của sinh viên Hoàng Minh Ngọc Hải (0012545), Nguyễn Duy Hiệp (0012038) Chương 8"],[41,"Tổng kết: là chương cuối cùng của đề tài, tóm lại các vấn đề đã giải quyết và nêu một số hướng phát triển trong tương lai"],[42,""],[43,"v MỤC LỤC Chương 1"],[44,"TỔNG QUAN............................................................................................2 1.1"],[45,"Đặt vấn đề ............................................................................................................2 1.2"],[46,"Các phương pháp phân loại văn bản...................................................................2 1.3"],[47,"Tách từ Tiếng Việt \u2013 Một thách thức thú vị ........................................................3 1.4"],[48,"Mục tiêu của luận văn..........................................................................................5 1.4.1"],[49,"Phần tìm hiểu các thuật toán phân loại văn bản.........................................5 1.4.2"],[50,"Phần tách từ tiếng Việt...............................................................................5 1.4.3"],[51,"Phần mềm phân loại tin tức báo điện tử bán tự động ................................5 1.4.4"],[52,"Đóng góp của luận văn ..............................................................................6 Chương 2"],[53,"CÁC PHƯƠNG PHÁP PHÂN LOẠI VĂN BẢN TIẾNG ANH..............8 2.1"],[54,"Bối cảnh các phương pháp phân loại văn bản hiện nay.......................................8 2.2"],[55,"Các phương pháp phân loại văn bản tiếng Anh hiện hành ..................................8 2.2.1"],[56,"Biểu diễn văn bản ......................................................................................8 2.2.2"],[57,"Support vector Machine(SVM) ...............................................................10 2.2.3"],[58,"K\u2013Nearest Neighbor (kNN).....................................................................12 2.2.4"],[59,"Naïve Bayes (NB)....................................................................................13 2.2.5"],[60,"Neural Network (NNet) ...........................................................................15 2.2.6"],[61,"Linear Least Square Fit (LLSF)...............................................................17 2.2.7"],[62,"Centroid- based vector .............................................................................18 2.3"],[63,"Kết luận..............................................................................................................19 Chương 3"],[64,"CÁC PHƯƠNG PHÁP TÁCH TỪ TIẾNG VIỆT HIỆN NAY ..............22 3.1"],[65,"Tại sao tách từ tiếng Việt là một thách thức"],[66,"....................................................22 3.1.1"],[67,"So sánh giữa tiếng Việt và tiếng Anh ......................................................22 3.1.2"],[68,"Nhận xét ...................................................................................................23 3.2"],[69,"Bối cảnh các phương pháp tách từ hiện nay ......................................................23 3.2.1"],[70,"Bối cảnh chung ........................................................................................23 3.2.2"],[71,"Các hướng tiếp cận dựa trên từ (Word-based approaches)......................24 3.2.3"],[72,"Các hướng tiếp cận dựa trên ký tự (Character-based approaches) ..........26 3.3"],[73,"Một số phương pháp tách từ tiếng Việt hiện nay...............................................28 3.3.1"],[74,"Phương pháp Maximum Matching: forward/backward...........................28"],[75,"vi 3.3.2"],[76,"Phương pháp giải thuật học cải biến ( TBL)............................................30 3.3.3"],[77,"Mô hình tách từ bằng WFST và mạng Neural.........................................31 3.3.4"],[78,"Phương pháp quy hoạch động (dynamic programming) .........................34 3.3.5"],[79,"Phương pháp tách từ tiếng Việt dựa trên thống kê từ Internet và thuật toán di truyền (Internet and Genetics Algorithm-based Text Categorization for Documents in Vietnamese - IGATEC)........................................................................34 3.4"],[80,"So sánh các phương pháp tách từ Tiếng Việt hiện nay......................................37 3.5"],[81,"Kết luận..............................................................................................................37 Chương 4"],[82,"TÁCH TỪ TIẾNG VIỆT KHÔNG DỰA TRÊN TẬP NGỮ LIỆU ĐÁNH DẤU (ANNOTATED CORPUS) HAY TỪ ĐIỂN (LEXICON) \u2013 MỘT THÁCH THỨC 40 4.1"],[83,"Giới thiệu ...........................................................................................................40 4.2"],[84,"Các nghiên cứu về thống kê dựa trên Internet ...................................................40 4.2.1"],[85,"Giới thiệu .................................................................................................40 4.2.2"],[86,"Một số công trình nghiên cứu về thống kê dựa trên Internet...................41 4.2.3"],[87,"Nhận xét ...................................................................................................43 4.3"],[88,"Các phương pháp tính độ liên quan giữa các từ dựa trên thống kê ...................43 4.3.1"],[89,"Thông tin tương hỗ và t-score dùng trong tiếng Anh ............................44 4.3.2"],[90,"Một số cải tiến trong cách tính độ liên quan ứng dụng trong tách từ tiếng Hoa và tiếng Việt .........................................................................................................46 4.3.3"],[91,"Nhận xét về các cách tính độ liên quan khi áp dụng cho tiếng Việt .......48 4.4"],[92,"Tiền xử lý (Pre-processing) ...............................................................................49 4.4.1"],[93,"Xử lý văn bản đầu vào .............................................................................49 4.4.2"],[94,"Tách ngữ & tách stopwords .....................................................................50 4.5"],[95,"Hướng tiếp cận tách từ dựa trên thống kê từ Internet và thuật toán di truyền (Internet and Genetic Algorithm - based ) .......................................................................51 4.5.1"],[96,"Công cụ trích xuất thông tin từ Google ...................................................51 4.5.2"],[97,"Công cụ tách từ dùng thuật toán di truyền (Genetic Algorithm \u2013 GA) ...53 4.6"],[98,"Kết luận..............................................................................................................61 Chương 5"],[99,"BÀI TOÁN PHÂN LOẠI TIN TỨC ĐIỆN TỬ ......................................63 5.1"],[100,"Lý do chọn phương pháp Naïve Bayes..............................................................63 5.2"],[101,"Thuật toán Naïve Bayes.....................................................................................64 5.2.1"],[102,"Công thức xác suất đầy đủ Bayes ............................................................64"],[103,"vii 5.2.2"],[104,"Tính độc lập có điều kiện (Conditional Independence) ...........................65 5.2.3"],[105,"Nguồn gốc thuật toán Naïve Bayes..........................................................65 5.2.4"],[106,"Phương pháp Naïve Bayes trong phân loại văn bản ................................66 5.2.5"],[107,"Hai mô hình sự kiện trong phân loại văn bản bằng phương pháp Naïve Bayes 68 5.3"],[108,"Bài toán phân loại tin tức điện tử tiếng Việt ......................................................70 5.3.1"],[109,"Quy ước ...................................................................................................70 5.3.2"],[110,"Công thức phân loại văn bản trong IGATEC [H"],[111,"Nguyen et al, 2005] ...71 5.3.3"],[112,"Công thức Naïve Bayes trong bài toán phân loại tin tức điện tử tiếng Việt sử dụng thống kê từ Google.........................................................................................72 5.4"],[113,"Kết luận..............................................................................................................74 Chương 6"],[114,"HỆ THỐNG THỬ NGHIỆM PHÂN LOẠI VĂN BẢN ......................76 6.1"],[115,"Giới thiệu hệ thống thử nghiệm Vikass .............................................................76 6.1.1"],[116,"Chức năng hệ thống Vikass .....................................................................76 6.1.2"],[117,"Tổ chức và xử lý dữ liệu ..........................................................................76 6.1.3"],[118,"Một số màn hình của hệ thống Vikass.....................................................79 6.2"],[119,"Thử nghiệm các cách trích xuất thông tin..........................................................82 6.2.1"],[120,"Các phương pháp thử nghiệm..................................................................82 6.2.2"],[121,"Nhận xét ...................................................................................................84 6.3"],[122,"Dữ liệu thử nghiệm ............................................................................................84 6.3.1"],[123,"Nguồn dữ liệu ..........................................................................................84 6.3.2"],[124,"Số lượng dữ liệu thử nghiệm ...................................................................84 6.3.3"],[125,"Nhận xét ...................................................................................................86 6.4"],[126,"Thử nghiệm các công thức tính độ tương hỗ MI ...............................................87 6.4.1"],[127,"Các phương pháp thử nghiệm..................................................................87 6.4.2"],[128,"Kết quả .....................................................................................................87 6.4.3"],[129,"Nhận xét ...................................................................................................88 6.5"],[130,"Thử nghiệm phân loại tin tức điện tử.................................................................89 6.5.1"],[131,"Thước đo kết quả phân loại văn bản........................................................89 6.5.2"],[132,"Các phương pháp thử nghiệm..................................................................91 6.5.3"],[133,"Kết quả .....................................................................................................91 6.5.4"],[134,"Nhận xét ...................................................................................................96"],[135,"viii Chương 7"],[136,"ỨNG DỤNG PHÂN LOẠI TIN TỨC ĐIỆN TỬ TỰ ĐỘNG ................99 7.1"],[137,"Giới thiệu tòa soạn báo điện tử ..........................................................................99 7.2"],[138,"Tính cần thiết của phân loại tin tức tự động ......................................................99 7.3"],[139,"Phân tích hiện trạng .........................................................................................100 7.3.1"],[140,"Mô hình DFD quan niệm cấp 2 hiện hành cho ô xử lý Nhận bài và Trả bài 100 7.3.2"],[141,"Phê phán hiện trạng................................................................................103 7.3.3"],[142,"Mô hình DFD quan niệm cấp 2 mới cho ô xử lý Nhận bài và Trả bài ..104 7.4"],[143,"Triển khai DLL ................................................................................................105 7.5"],[144,"Chương trình cài đặt \u201cTòa soạn báo điện tử\u201d đã tích hợp module phân loại tin tức 106 7.6"],[145,"Kết quả .............................................................................................................110 Chương 8"],[146,"TỔNG KẾT............................................................................................112 8.1"],[147,"Kết quả đạt được ..............................................................................................112 8.1.1"],[148,"Về mặt lý thuyết.....................................................................................112 8.1.2"],[149,"Về mặt thực nghiệm...............................................................................113 8.2"],[150,"Hạn chế và hướng phát triển............................................................................113 8.3"],[151,"Kết luận............................................................................................................114"],[152,"ix DANH SÁCH HÌNH Hình 2"],[153,"1"],[154,"Biểu diễn văn bản .................................................................................................9 Hình 2"],[155,"2"],[156,"Siêu mặt phẳng h phân chia dữ liệu huấn huyện thành 2 lớp + và \u2013 với khoảng cách biên lớn nhất"],[157,"Các điểm gần h nhất là các vector hỗ trợ ,Support Vector (được khoanh tròn).............................................................................................................11 Hình 2"],[158,"3"],[159,"Hình Kiến trúc mô đun (Modular Architecture)"],[160,"Các kết quả của từng mạng con sẽ là giá trị đầu vào cho mạng siêu chủ đề và được nhân lại với nhau để dự đoán chủ đề cuối cùng"],[161,"....................................................................................................16 Hình 3.4"],[162,"Các hướng tiếp cận cơ bản trong tách từ tiếng Hoa và các hướng tiếp cận hiện tại được công bố trong tách từ tiếng Việt .....................................................................24 Hình 3.5"],[163,"Sơ đồ hệ thống WFST..........................................................................................31 Hình 3.6"],[164,"Toàn cảnh hệ thống IGATEC ..............................................................................35 Hình 4"],[165,"1"],[166,"Nội dung thông tin cần lấy..................................................................................50 Hình 4"],[167,"2"],[168,"Biểu diễn cá thể bằng các bit 0,1 ........................................................................55 Hình 4"],[169,"3"],[170,"Thang tỉ lệ phát sinh loại từ ................................................................................57 Hình 4"],[171,"4.Quá trình lai ghép ................................................................................................58 Hình 4"],[172,"5"],[173,"Quá trình đột biến ...............................................................................................59 Hình 4"],[174,"6"],[175,"Quá trình sinh sản ...............................................................................................59 Hình 4"],[176,"7"],[177,"Quá trình chọn cá thể ..........................................................................................60 Hình 5"],[178,"1"],[179,"Minh họa quy ước cho văn bản...........................................................................70 Hình 5"],[180,"2.Minh họa chủ đề \u201cXã hội\u201d ...................................................................................70 Hình 6"],[181,"1"],[182,"Tổ chức file dữ liệu.............................................................................................77 Hình 6"],[183,"2"],[184,"Chủ đề Thể thao..................................................................................................77 Hình 6"],[185,"3"],[186,"Màn hình tách từ .................................................................................................79 Hình 6"],[187,"4"],[188,"Màn hình trích xuất từ Google...........................................................................80 Hình 6"],[189,"5"],[190,"Màn hình phân loại tin tức điện tử......................................................................81 Hình 6"],[191,"6"],[192,"Cây chủ đề ..........................................................................................................86 Hình 6"],[193,"7"],[194,"Biểu đồ so sánh kết quả các công thức tính độ tương hỗ MI..............................88 Hình 6"],[195,"8"],[196,"Các thông số dùng tính độ thu về, độ chính xác .................................................89 Hình 6"],[197,"9"],[198,"Biểu đồ F1 cho cấp 1 ..........................................................................................94 Hình 6"],[199,"10"],[200,"Biểu đồ F1 cho cấp 2 ........................................................................................96"],[201,"x Hình 7"],[202,"1.Mô hình DFD hiện hành ....................................................................................100 Hình 7"],[203,"2"],[204,"Mô hình DFD cải tiến .......................................................................................104 Hình 7"],[205,"3"],[206,"Màn hình lấy tin tức cho phép phân loại tự động .............................................106 Hình 7"],[207,"4"],[208,"Màn hình bắt đầu"],[209,"Click Next để bắt đầu cài đặt ..............................................107 Hình 7"],[210,"5.Màn hình chọn chế độ cài đặt hoặc tháo gỡ chương trình"],[211,"................................107 Hình 7"],[212,"6.Màn hình chọn đường dẫn để cài đặt chương trình"],[213,"..........................................108 Hình 7"],[214,"7.Màn hình cài đặt chương trình...........................................................................108 Hình 7"],[215,"8.Màn hình chọn chức năng gỡ chương trình"],[216,"......................................................109 Hình 7"],[217,"9.Màn hình gỡ chương trình thành công...............................................................109"],[218,"xi DANH SÁCH BẢNG Bảng 3"],[219,"1"],[220,"So sánh giữa tiếng Việt và tiếng Anh.................................................................23 Bảng 4"],[221,"1"],[222,"Thống kê độ dài từ trong từ điển ........................................................................54 Bảng 4"],[223,"2"],[224,"Tham số thực hiện GA .......................................................................................56 Bảng 6"],[225,"1"],[226,"Mô tả một số control của màn hình tách từ ........................................................79 Bảng 6.2"],[227,"Mô tả một số control của màn hình trích từ Google ...........................................80 Bảng 6.3"],[228,"Bảng mô tả một số control của màn hình phân loại tin tức điện tử.....................81 Bảng 6"],[229,"4"],[230,"Tham số sử dụng dịch vụ Google.......................................................................82 Bảng 6"],[231,"5"],[232,"Một số câu truy vấn đặc biệt của Google ...........................................................83 Bảng 6"],[233,"6"],[234,"Kết quả thực nghiệm các công thức tính độ tương hỗ MI..................................87 Bảng 6"],[235,"7"],[236,"Bốn trường hợp của phân loại văn bản...............................................................90 Bảng 6"],[237,"8"],[238,"Kết quả phân loại văn bản cho từng chủ đề........................................................94 Bảng 7"],[239,"1"],[240,"Bảng kho dữ liệu những bài viết chưa được đăng............................................102 Bảng 7"],[241,"2"],[242,"Bảng mô tả các ô xử lý của mô hình DFD hiện hành.......................................103 Bảng 7"],[243,"3"],[244,"Bảng mô tả ô xử lý phân loại tin tức tự động...................................................105"],[245,"1 CChhưươơnngg 11 TTỔỔNNGG QQUUAANN Đặt vấn đề Các phương pháp phân loại văn bản Tách từ tiếng Việt \u2013 Một thách thức thú vị Mục tiêu của luận văn Phần tìm hiểu các thuật toán phân loại văn bản Phần tách từ tiếng Việt Phần mềm phân loại tin tức báo điện tử bán tự động"],[246,"2 Chương 1"],[247,"TỔNG QUAN 1.1"],[248,"Đặt vấn đề Trong thời đại bùng nổ công nghệ thông tin hiện nay, phương thức sử dụng giấy tờ trong giao dịch đã dần được số hoá chuyển sang các dạng văn bản lưu trữ trên máy tính hoặc truyền tải trên mạng"],[249,"Bởi nhiều tính năng ưu việt của tài liệu số như cách lưu trữ gọn nhẹ, thời gian lưu trữ lâu dài, tiện dụng trong trao đổi đặc biệt là qua Internet, dễ dàng sửa đổi\u2026 nên ngày nay, số lượng văn bản số tăng lên một cách chóng mặt đặc biệt là trên world-wide-web"],[250,"Cùng với sự gia tăng về số lượng văn bản, nhu cầu tìm kiếm văn bản cũng tăng theo"],[251,"Với số lượng văn bản đồ sộ thì việc phân loại văn bản tự động là một nhu cầu bức thiết"],[252,"Tại sao phải phân loại văn bản tự động"],[253,"Việc phân loại văn bản sẽ giúp chúng ta tìm kiếm thông tin dễ dàng và nhanh chóng hơn rất nhiều so với việc phải bới tung mọi thứ trong ổ đĩa lưu trữ để tìm kiếm thông tin"],[254,"Mặt khác, lượng thông tin ngày một tăng lên đáng kể, việc phân loại văn bản tự động sẽ giúp con người tiết kiệm được rất nhiều thời gian và công sức"],[255,"Do vậy, các phương pháp phân loại văn bản tự động đã ra đời để phục vụ cho nhu cầu chính đáng đó"],[256,"1.2"],[257,"Các phương pháp phân loại văn bản Theo Yang & Xiu (1999), \u201cviệc phân loại văn bản tự động là việc gán các nhãn phân loại lên một văn bản mới dựa trên mức độ tương tự của văn bản đó so với các văn bản đã được gán nhãn trong tập huấn luyện\u201d"],[258,"Từ trước đến nay, phân loại văn bản tự động trong tiếng Anh đã có rất nhiều công trình nghiên cứu và đạt được kết quả đáng khích lệ"],[259,"Dựa trên các thống kê của Yang & Xiu (1999) và nghiên cứu của chúng em, một số phương pháp phân loại thông dụng hiện nay là: Support Vector Machine [Joachims, 1998], k-Nearest Neighbor [Yang, 1994], Linear Least Squares Fit [Yang and Chute, 1994] Neural Network [Wiener et al, 1995], Naïve Bayes [Baker and Mccallum, 2000], Centroid- based [Shankar and Karypis, 1998]"],[260,"Các phương pháp trên đều dựa vào xác suất"],[261,"3 thống kê hoặc thông tin về trọng số của từ trong văn bản"],[262,"Chi tiết về ý tưởng và công thức tính toán của mỗi phương pháp sẽ được chúng em trình bày ở chương 3, mục 3.3"],[263,"Mỗi phương pháp phân loại văn bản đều có cách tính toán khác nhau, tuy nhiên, nhìn một cách tổng quan thì các phương pháp đó đều phải thực hiện một số bước chung như sau: đầu tiên, mỗi phương pháp sẽ dựa trên các thông tin về sự xuất hiện của từ trong văn bản (ví dụ tần số, số văn bản chứa từ\u2026) để biểu diễn văn bản thành dạng vector; sau đó, tuỳ từng phương pháp mà ta sẽ áp dụng công thức và phương thức tính toán khác nhau để thực hiện việc phân loại"],[264,"Đối với tiếng Anh, các kết quả trong lĩnh vực này rất khả quan, còn đối với tiếng Việt, các công trình nghiên cứu về phân loại văn bản gần đây đã có một số kết quả ban đầu nhưng vẫn còn nhiều hạn chế"],[265,"Nguyên nhân là ngay ở bước đầu tiên, chúng ta đã gặp khó khăn trong việc xử lý văn bản để rút ra tần số xuất hiện của từ"],[266,"Trong khi đó, để phân loại văn bản thì có thể nói bước đầu tiên là quan trọng nhất bởi vì nếu ở bước tách từ đã sai thì việc phân loại hầu như không thể thành công được"],[267,"Phần trình bày tiếp theo sẽ cho chúng ta biết những thách thức đặt ra trong việc tách từ tiếng Việt, cũng như những ứng dụng thú vị của nó"],[268,"1.3"],[269,"Tách từ Tiếng Việt \u2013 Một thách thức thú vị Đối với tiếng Anh, \u201ctừ là một nhóm các ký tự có nghĩa được tách biệt với nhau bởi khoảng trắng trong câu\u201d (Webster Dictionary), do vậy việc tách từ trở nên rất đơn giản"],[270,"Trong khi đối với tiếng Việt, ranh giới từ không được xác định mặc định là khoảng trắng mà tùy thuộc vào ngữ cảnh dùng câu tiếng Việt"],[271,"Ví dụ các từ trong tiếng Anh là \u201cbook\u201d , \u201ccat\u201d, \u201cstadium\u201d thì trong tiếng Việt là \u201cquyển sách\u201d, \u201ccon mèo\u201d, \u201csân vận động\u201d \u2026 Vấn đề trên thực sự đưa ra một thách thức đối với chúng ta - những người làm tin học"],[272,"Tuy nhiên, thách thức nào cũng có cái thú vị của nó"],[273,"Nếu chúng ta giải quyết được việc tách từ một cách thoả đáng, thì thành quả mà chúng ta đạt được là một nền tảng để phát triển cho các hướng nghiên cứu khác có liên quan đến việc xử lý ngôn ngữ tự nhiên như: phân loại văn bản, dịch tự động, kiểm tra lỗi chính tả, kiểm"],[274,"4 tra ngữ pháp\u2026 Đó là các ứng dụng rất thiết thực với đời sống con người và là mục tiêu của con người đang chinh phục"],[275,"Một số nước châu Á như Trung Quốc, Nhật Bản, Hàn Quốc, Việt Nam sử dụng loại hình ngôn ngữ gần như tương tự nhau về mặt hình thái và cú pháp"],[276,"Do đó ta có thể áp dụng, cải tiến một số phương pháp tách từ của các nước bạn đặc biệt là Trung Quốc vào việc tách từ tiếng Việt"],[277,"Theo Đinh Điền (2004), các phương pháp tách từ sau có nguồn gốc từ tiếng Hoa đã được thử nghiệm trên tiếng Việt : Maximum Matching: forward/backward hay còn gọi LRMM (Left Right Maximum Matching); giải thuật học cải biến TBL; mạng chuyển dịch trạng thái hữu hạn có trọng số WFST (Weighted finite-state Transducer); giải thuật dựa trên nén (compression);\u2026.Theo các cách tiếp cận trên, điều kiện quan trọng cần có là một hệ thống từ điển (LRMM) và ngữ liệu đánh dấu (TBL, WFST) đầy đủ, chuẩn xác"],[278,"Một từ điển hay một tập ngữ liệu không hoàn chỉnh sẽ làm giảm hiệu suất của thuật toán"],[279,"Tuy nhiên, khó có thể tạo ra được một từ điển hoàn chỉnh nhất là trong thời đại ngày nay, ngôn ngữ còn tiếp tục phát triển và thay đổi từng ngày"],[280,"Xét về mặt phổ biến, tiếng Anh là ngôn ngữ được dùng rộng rãi trong giao dịch trên thế giới"],[281,"Do đó để tạo ra một tập ngữ liệu tiếng Anh thỏa các tiêu chí chọn mẫu ngữ liệu là không quá phức tạp"],[282,"Trong khi đó, Việt Nam chỉ mới cho phép truy cập Internet trong vòng chục năm trở lại đây, do đó số lượng trang web tiếng Việt là không nhiều"],[283,"Cho đến nay, vẫn chưa có một tập ngữ liệu huấn luyện chuẩn nào dành cho việc tách từ và phân loại trang web tiếng Việt được công bố"],[284,"Gần đây, một phương pháp tách từ mới được giới thiệu có ưu điểm là không cần dùng tập ngữ liệu hay từ điển để lấy thông tin thống kê hay trọng số của từ, đó là phương pháp Internet and Genetics Algorithm-based Text Categorization (IGATEC) của H"],[285,"Nguyen et al (2005)"],[286,"Điểm sáng tạo của thuật toán là kết hợp thuật toán di truyền với việc trích xuất thông tin thống kê từ Internet thông qua một công cụ tìm kiếm (như Google chẳng hạn) thay vì lấy từ tập ngữ liệu như các phương pháp trước"],[287,""],[288,"5 Chúng em thực hiện bước tách từ trong luận văn này dựa trên ý tưởng của thuật toán IGATEC nhưng có bổ sung nhiều cải tiến đáng kể để tăng độ chính xác đồng thời thực hiện các thí nghiệm chi tiết nhằm so sánh các cách áp dụng thuật toán để tìm ra cách tối ưu nhất"],[289,"1.4"],[290,"Mục tiêu của luận văn 1.4.1"],[291,"Phần tìm hiểu các thuật toán phân loại văn bản Trong khuôn khổ luận văn này, chúng em tìm hiểu ở mức cơ bản một số phương pháp phân loại văn bản hiện có đang áp dụng cho tiếng Anh và đưa ra một số so sánh nhất định giữa các phương pháp: Support Vector Machine (Joachims, 1998), k- Nearest Neighbor (Yang, 1994), Linear Least Squares Fit (Yang and Chute, 1994) Neural Network (Wiener et al, 1995), Naïve Bayes (Baker and Mccallum, 2000), Centroid-based (Shankar and Karypis, 1998)"],[292,"Sau đó, chúng em sẽ chọn và áp dụng một phương pháp cho bài toán phân loại tin tức báo điện tử tiếng Việt chấp nhận được, phù hợp với mức độ và thời gian cho phép của một luận văn đại học"],[293,"1.4.2"],[294,"Phần tách từ tiếng Việt Hiện nay các phương pháp tách từ tiếng Việt được công bố vẫn chưa nhiều và hướng tiếp cận chủ yếu dựa vào tập huấn luyện và từ điển"],[295,"Như chúng ta đã biết, việc tạo ra hệ thống dữ liệu đó không phải là một sớm một chiều, mà yêu cầu đầu tư khá nhiều công sức, thời gian và tiền bạc"],[296,"Trong luận văn này, chúng em cố gắng tìm hiểu, cải tiến, cài đặt, thử nghiệm một phương pháp tách từ tiếng Việt theo hướng tiếp cận IGATEC, có độ chính xác chấp nhận được, và điều quan trọng là không cần dùng tập ngữ liệu (corpus) để phân định ranh giới từ"],[297,"Sau đó, chúng em sẽ cài đặt, thử nghiệm độ chính xác của phương pháp tách từ này trong khía cạnh phân loại văn bản 1.4.3"],[298,"Phần mềm phân loại tin tức báo điện tử bán tự động"],[299,"6 Để thử nghiệm hướng nghiên cứu tách từ tiếng Việt và phân loại văn bản của luận văn, chúng em tích hợp phần mềm phân loại tin tức vào trang web báo điện tử có sẵn được xây dựng trên nền DotNetNuke Portal của luận văn khoá 2000 ( Hoàng Minh Ngọc Hải (0012545), Nguyễn Duy Hiệp (0012038) ) Như chúng ta đều biết, điều kiện mạng cung cấp cho các trường đại học ở nước ta hiện nay là khá hạn chế, khó đáp ứng được hoàn toàn việc cho phép các sinh viên lên mạng Internet để xem các tin tức mới hằng ngày"],[300,"Để giải quyết phần nào vấn đề trên, chúng ta có thể chọn lọc một số tin tức từ các nguồn khác, đăng tải trên trang web nội bộ của trường"],[301,"Trên cơ sở đó, chúng em tích hợp phần mềm phân loại tin tức báo điện tử tự động vào toà soạn báo điện tử cho phép lấy tin tự động từ các trang web khác"],[302,"Nhờ vậy, công việc lấy tin và phân loại tin tức giờ đây đã trở nên rất dễ dàng và nhanh chóng, tiết kiệm nhiều công sức và thời gian cho nhà quản trị"],[303,"Không chỉ ứng dụng cho các trường đại học, phần mềm phân loại tin tức của chúng em còn có thể ứng dụng, hỗ trợ cho nhiều công việc khác như : lưu trữ (clipping) báo chí, xây dựng bộ ngữ liệu cho các bài toán cần dữ liệu được phân loại, tiền đề cho các bài toán khác như phân loại website"],[304,"1.4.4"],[305,"Đóng góp của luận văn Luận văn đã thực hiện việc được nhiều cải tiến của hướng tiếp cận tách từ tiếng Việt dùng trong phân loại văn bản theo phương pháp dựa trên thống kê Internet"],[306,"Đối với tách từ tiếng Việt, chúng em đề nghị thêm một công thức tính toán độ tương hỗ mới, từ đó thực hiện thử nghiệm tính hiệu quả của cách tính này so với cách công thức ở những công trình khác"],[307,"Trong quá trình xây dựng thuật toán di truyền dùng trong tách từ, chúng em đã cải tiến hình thức đột biến mới phù hợp với hình thức cấu tạo từ trong câu"],[308,"Đối với việc phân loại văn bản, chúng em cải tiến công thức tính trong hướng tiếp cận Naïve Bayes phù hợp với phương pháp tính dựa trên thống kê từ Google"],[309,""],[310,"7 CChhưươơnngg 22 CCÁÁCC PPHHƯƯƠƠNNGG PPHHÁÁPP PPHHÂÂNN LLOOẠẠII VVĂĂNN BBẢẢNN TTIIẾẾNNGG AANNHH Bối cảnh các phương pháp phân loại văn bản hiện nay Các phương pháp phân loại văn bản tiếng Anh hiện hành Biểu diễn văn bản Support vector Machine (SVM) K\u2013Nearest Neighbor (kNN) Naïve Bayes (NB) Neural Network (NNet) Linear Least Square Fit (LLSF) Centroid- based vector Kết luận"],[311,"8 Chương 2"],[312,"CÁC PHƯƠNG PHÁP PHÂN LOẠI VĂN BẢN TIẾNG ANH 2.1"],[313,"Bối cảnh các phương pháp phân loại văn bản hiện nay Phân loại văn bản tự động là một lĩnh vực được chú ý nhất trong những năm gần đây"],[314,"Để phân loại người ta sử dụng nhiều cách tiếp cận khác nhau như dựa trên từ khóa, dựa trên ngữ nghĩa các từ có tần số xuất hiện cao, mô hình Maximum Entropy, tập thô \u2026 Tiếng Anh là một trong những ngôn ngữ được nghiên cứu sớm và rộng rãi nhất với kết quả đạt được rất khả quan"],[315,"Một số lượng lớn các phương pháp phân loại đã được áp dụng thành công trên ngôn ngữ này : mô hình hồi quy [Fuhr et al,1991], phân loại dựa trên láng giềng gần nhất (k-nearest neighbors) [Dasarathy, 1991], phương pháp dựa trên xác suất Naïve Bayes [Joachims, 1997], cây quyết định [Fuhr et al,1991], học luật quy nạp [William & Yoram, 1996], mạng nơron (neural network)[Wiener et al, 1995], học trực tuyến[William & Yoram, 1996], và máy vector hỗ trợ (SVM-support vector machine) [Vapnik, 1995]"],[316,"Hiệu quả của các phương pháp này rất khác nhau ngay cả khi áp dụng cho tiếng Anh"],[317,"Việc đánh giá gặp nhiều khó khăn do việc thiếu các tập ngữ liệu huấn luyện chuẩn"],[318,"Thậm chí đối với tập dữ liệu được sử dụng rộng rãi nhất, Reuter cũng có nhiều phiên bản khác nhau"],[319,"Hơn nữa, có rất nhiều độ đo được sử dụng như recall, precision, accuracy hoặc error, break-even point, F-measure \u2026Chương này giới thiệu các thuật toán phân loại được sử dụng phổ biến nhất đồng thời so sánh giữa các phương pháp sử dụng kết quả của [Yang, 1997]"],[320,"2.2"],[321,"Các phương pháp phân loại văn bản tiếng Anh hiện hành 2.2.1"],[322,"Biểu diễn văn bản Bước đầu tiên của mọi phương pháp phân loại là chuyển việc mô tả văn bản dùng chuỗi ký tự thành một dạng mô tả khác, phù hợp với các thuật toán học theo mẫu và phân lớp"],[323,"Hầu hết các thuật toán đều sử dụng cách biểu diễn văn bản sử dụng vector đặc trưng, sự khác nhau có chăng là việc chọn không gian đặc trưng khác nhau"],[324,"Vì vậy ở phần này chúng em sẽ trình bày sơ lược về vector đặc trưng"],[325,""],[326,"9 Ý tưởng chính là xem mỗi văn bản id tương ứng là một vector đặc trưng ( )1 2( ), ( ),..., ( )i nd TF w TF w TF w trong không gian các từ nW ( iw là một từ, một đặc trưng, tương ứng một chiều của không gian)"],[327,"Gía trị của ( )iTF w chính là số lần xuất hiện của từ iw trong văn bản id"],[328,"Từ được chọn là một đặc trưng khi nó xuất hiện trong ít nhất 3 văn bản [Joachims, 1997]"],[329,"Để không bị phụ thuộc vào chiều dài văn bản vector đặc trưng sẽ được chuẩn hóa về chiều dài đơn vị : 1 2 2 2 2 ( )( ) ( )( , ,..., ) ( ) ( ) ( ) n i i i TF wTF w TF wdi TF w TF w TF w∑ ∑ ∑ Hình 2"],[330,"1"],[331,"Biểu diễn văn bản Trong thực tế để cải thiện tốc độ và kết quả người ta thường sử dụng )( iwIDF hoặc i(w )TFIDF thay cho ( )iTF w : ( ) log( ) ( )i i mIDF w DF w = ( ) ( )"],[332,"( )i i iTFIDF w TF w IDF w= Với m chính là số văn bản huấn luyện"],[333,"10 DF(wi) là số văn bản có chứa từ iw"],[334,"Một vấn đề nảy sinh khi biểu diễn văn bản theo hướng vector đặc trưng chính là việc chọn đặc trưng và số chiều cho không gian"],[335,"Cần phải chọn bao nhiêu từ và chọn những từ nào"],[336,"theo những cách nào"],[337,"Có nhiều hướng tiếp cận trong vấn đề này mà tiêu biểu là sử dụng Information Gain [Yang & Petersen, 1997] ngoài ra còn có các phương pháp như DF-Thresolding [Yang & Petersen, 1997], Test−2χ [Schütze et al,1995] hoặc Term Strength [Yang & Wilbur,1997]"],[338,"Phương pháp Information Gain sử dụng độ đo Mutual Information(MI) [Yang & Petersen, 1997] để chọn ra tập đặc trưng con f gồm những từ có giá trị MI cao nhất"],[339,"Các đặc trưng của văn bản khi biểu diễn dưới dạng vector : Số chiều không gian đặc trưng thường rất lớn (trên 10000) Có các đặc trưng độc lập nhau, sự kết hợp các đặc trưng này thường không có ý nghĩa trong phân loại Đặc trưng rời rạc : vector id có rất nhiều giá trị 0 do có nhiều đặc trưng không xuất hiện trong văn bản id"],[340,"Hầu hết các văn bản có thể được phân chia một cách tuyến tính bằng các hàm tuyến tính"],[341,"Việc phân loại sẽ tốt hơn nếu các thuật toán tận dụng được những đặc trưng này"],[342,"Phần tiếp theo sẽ nói rõ hơn về các thuật toán phân loại"],[343,"2.2.2"],[344,"Support vector Machine(SVM) SVM là phương pháp tiếp cận phân loại rất hiệu quả được Vapnik giới thiệu năm 1995 [Vapnik, 1995] để giải quyết vấn đề nhận dạng mẫu 2 lớp sử dụng nguyên lý Cực tiểu hóa Rủi ro có Cấu trúc (Structural Risk Minimization) [Vapnik, Cortes, 1995]"],[345,""],[346,"11 2.2.2.1"],[347,"Ý tưởng Cho trước một tập huấn luyện được biểu diễn trong không gian vector trong đó mỗi tài liệu là một điểm, phương pháp này tìm ra một siêu mặt phẳng h quyết định tốt nhất có thể chia các điểm trên không gian này thành hai lớp riêng biệt tương ứng lớp + và lớp \u2013"],[348,"Chất lượng của siêu mặt phẳng này được quyết định bởi khoảng cách (gọi là biên) của điểm dữ liệu gần nhất của mỗi lớp đến mặt phẳng này"],[349,"Khoảng cách biên càng lớn thì mặt phẳng quyết định càng tốt đồng thời việc phân loại càng chính xác"],[350,"Mục đích thuật toán SVM tìm được khoảng cách biên lớn nhất"],[351,"Hình sau minh họa cho thuật toán này : Hình 2"],[352,"2"],[353,"Siêu mặt phẳng h phân chia dữ liệu huấn huyện thành 2 lớp + và \u2013 với khoảng cách biên lớn nhất"],[354,"Các điểm gần h nhất là các vector hỗ trợ ,Support Vector (được khoanh tròn) 2.2.2.2"],[355,"Công thức chính SVM thực chất là một bài toán tối ưu, mục tiêu của thuật toán này là tìm được một không gian H và siêu mặt phẳng quyết định h trên H sao cho sai số phân loại là thấp nhất Phương trình siêu mặt phẳng chứa vector id trong không gian như sau : 0=+⋅ bwdi Đặt ⎪⎩ ⎪ ⎨ ⎧ <+⋅− >+⋅+ =+⋅= 0,1 0,1 )()( bwd bwd bwdsigndh i i ii"],[356,"12 Như thế )( idh biểu diễn sự phân lớp của id vào hai lớp như đã nói"],[357,"Gọi { }1±=iy , iy = + 1, văn bản id ∈ lớp +; iy = - 1, văn bản id ∈ lớp - Khi này để có siêu mặt phẳng h ta sẽ phải giải bài toán sau : Tìm Min w với w và b thõa điều kiên sau : ( ) 1)(:,1 ≥+⋅∈∀ bwdsignyni ii Bài toán SVM có thể giải bằng kỹ thuật sử dụng toán tử Lagrange để biến đổi thành dạng đẳng thức"],[358,"Điểm thú vị ở SVM là mặt phẳng quyết định chỉ phụ thuộc vào các vector hỗ trợ (Support Vector) có khoảng cách đến mặt phẳng quyết định là w 1"],[359,"Khi các điểm khác bị xóa đi thì thuật toán vẫn cho kết quả giống như ban đầu"],[360,"Chính đặc điểm này làm cho SVM khác với các thuật toán khác như kNN,LLSF, NNet và NB vì tất cả dữ liệu trong tập huấn luyện đều được dùng để tối ưu hóa kết quả"],[361,"Các phiên bản SVM tốt có thể kể đến là SVMLight [Joachims, 1998] và Sequential Minimal Optimization (SMO) [Platt, 1998] 2.2.3"],[362,"K\u2013Nearest Neighbor (kNN) kNN là phương pháp truyền thống khá nổi tiếng về hướng tiếp cận dựa trên thống kê đã được nghiên cứu trong nhận dạng mẫu hơn bốn thập kỷ qua [Dasarathy, 1991]"],[363,"kNN được đánh giá là một trong những phương pháp tốt nhất (áp dụng trên tập dữ liệu Reuters phiên bản 21450), được sử dụng từ những thời kỳ đầu của việc phân loại văn bản [Marsand et al, 1992] [Yang, 1994] [Iwayama, Tokunaga, 1995]"],[364,"2.2.3.1"],[365,"Ý tưởng Khi cần phân loại một văn bản mới, thuật toán sẽ tính khoảng cách (khoảng cách Euclide, Cosine ...) của tất cả các văn bản trong tập huấn luyện đến văn bản này để tìm ra k văn bản gần nhất (gọi là k \u201cláng giềng\u201d), sau đó dùng các khoảng cách này đánh trọng số cho tất cả chủ đề"],[366,"Trọng số của một chủ đề chính là tổng tất cả khoảng cách ở trên của các văn bản trong k láng giềng có cùng chủ đề, chủ đề nào"],[367,"13 không xuất hiện trong k láng giềng sẽ có trọng số bằng 0"],[368,"Sau đó các chủ đề sẽ được sắp xếp theo mức độ trọng số giảm dần và các chủ đề có trọng số cao sẽ được chọn là chủ đề của văn bản cần phân loại"],[369,"2.2.3.2"],[370,"Công thức chính Trọng số của chủ đề jc đối với văn bản x : { } W( , ) ( , )"],[371,"( , ) i j i i j j d kNN x c sim x d y d c b ∈ = −∑ Trong đó ( ),i jy d c ∈ {0,1}, với y = 0 : văn bản id không thuộc về chủ đề cj y = 1 : văn bản id thuộc về chủ đề cj ( ), isim x d : độ giống nhau giữa văn bản cần phân loại x và văn bản id"],[372,"Có thể sử dụng độ đo cosine để tính ( ), isim x d ( ) ii x.d, os(x,d )="],[373,"isim x d c x di = jb là ngưỡng phân loại của chủ đề cj được tự động học sử dụng một tập văn bản hợp lệ được chọn ra từ tập huấn luyện Để chọn được tham số k tốt nhất cho việc phân loại, thuật toán phải được chạy thử nghiệm trên nhiều giá trị k khác nhau, giá trị k càng lớn thì thuật toán càng ổn định và sai sót càng thấp [Yang, 1997]"],[374,"Giá trị tốt nhất được sử dụng tương ứng trên hai bộ dữ liệu Reuter và Oshumed là k = 45 [Joachims, 1997]"],[375,"2.2.4"],[376,"Naïve Bayes (NB) NB là phương pháp phân loại dựa vào xác suất được sử dụng rộng rãi trong lĩnh vực máy học [Mitchell, 1996] [Joachims, 1997] [Jason, 2001] được sử dụng lần đầu tiên trong lĩnh vực phân loại bởi Maron vào năm 1961 [Maron, 1961] sau đó trở nên phổ biến dùng trong nhiều lĩnh vực như trong các công cụ tìm kiếm [Rijsbergen et al, 1970], các bộ lọc mail [Sahami et al, 1998].."],[377,""],[378,"14 2.2.4.1"],[379,"Ý tưởng Ý tưởng cơ bản của cách tiếp cận Naïve Bayes là sử dụng xác suất có điều kiện giữa từ và chủ đề để dự đoán xác suất chủ đề của một văn bản cần phân loại"],[380,"Điểm quan trọng của phương pháp này chính là ở chỗ giả định rằng sự xuất hiện của tất cả các từ trong văn bản đều độc lập với nhau"],[381,"Như thế NB không tận dụng được sự phụ thuộc của nhiều từ vào một chủ đề cụ thể Giả định đó làm cho việc tính toán NB hiệu quả và nhanh chóng hơn các phương pháp khác với độ phức tạp theo số mũ vì nó không sử dụng việc kếp hợp các từ để đưa ra phán đoán chủ đề"],[382,"2.2.4.2"],[383,"Công thức chính Mục đích chính là tính được xác suất Pr( , )Cj d \u2032 , xác suất để văn bản d \u2032 nằm trong lớp Cj"],[384,"Theo luật Bayes, văn bản d \u2032 sẽ được gán vào lớp Cj nào có xác suất Pr( , )Cj d \u2032 cao nhất"],[385,"Công thức sau dùng để tính Pr( , )Cj d \u2032 [Joachims, 1997] 1 1 ( , ) ( , ) Pr( )"],[386,"Pr( | ) ( ) arg max Pr( )"],[387,"Pr( | ) Pr( )"],[388,"Pr( | ) arg max Pr( )"],[389,"Pr( | ) d j i j i BAYES d Cj C i C C i TF w d j w F TF w d Cj C C C w F C w C H d C w C Cj w C C w C \u2032 = \u2032 ∈ \u2032∈ = \u2032 ∈ \u2032 ∈ \u2032∈ ∈ ⎛ ⎞ ⎜ ⎟ ⎜ ⎟\u2032 = ⎜ ⎟ \u2032 \u2032⎜ ⎟ ⎝ ⎠ ⎛ ⎞ ⎜ ⎟= ⎜ ⎟\u2032 \u2032⎜ ⎟ ⎝ ⎠ ∏ ∑ ∏ ∏ ∑ ∏ Với ( , )iTF w d \u2032 là số lần xuất hiện của từ iw trong văn bản d \u2032 d \u2032 là số lượng các từ trong văn bản d \u2032 iw là một từ trong không gian đặc trưng F với số chiều là F Pr( )jC được tính dựa trên tỷ lệ phần trăm của số văn bản mỗi lớp tương ứng trong tập dữ liệu luyện : Pr( ) j jj C C C C C C C \u2032∈ = = \u2032∑"],[390,"15 Pr( | )i jw C được tính sử dụng phép ước lượng Laplace [Napnik, 1982] : 1 ( , ) Pr( | ) ( , ) i j i j j w F TF w C w C F TF w C \u2032∈ + = \u2032+ ∑ Ngoài ra còn có các phương pháp NB khác có thể kể ra như sau ML Naive Bayes, MAP Naive Bayes, Expected Naive Bayes, Bayesian Naive Bayes [Jason, 2001]"],[391,"Naive Bayes là một công cụ rất hiệu quả trong một số trường hợp"],[392,"Kết quả có thể rất tồi nếu dữ liệu huấn luyện nghèo nàn và các tham số dự đoán (như không gian đặc trưng) có chất lượng kém"],[393,"Nhìn chung đây là một thuật toán phân loại tuyến tính thích hợp trong phân loại văn bản nhiều chủ đề"],[394,"NB có ưu điểm là cài đặt đơn giản, tốc độ nhanh, dễ dàng cập nhật dữ liệu huấn luyện mới và có tính độc lập cao với tập huấn luyện, có thể sử dụng kết hợp nhiều tập huấn luyện khác nhau"],[395,"Tuy nhiên NB ngoài giả định tính độc lập giữa các từ còn phải cần đến một ngưỡng tối ưu để cho kết quả khả quan"],[396,"Nhằm mục đích cải thiện hiệu năng của NB, các phương pháp như multiclass-boosting, ECOC [Berger, 1999] [Ghani, 2000] có thể được dùng kết hợp"],[397,"2.2.5"],[398,"Neural Network (NNet) Nnet được nghiên cứu mạnh trong hướng trí tuệ nhân tạo"],[399,"Wiener là người đã sử dụng Nnet để phân loại văn bản, sử dụng 2 hướng tiếp cận : kiến trúc phẳng (không sử dụng lớp ẩn) và mạng nơron 3 lớp (bao gồm một lớp ẩn)[Wiener et al, 1995] Cả hai hệ thống trên đều sử dụng một mạng nơron riêng rẽ cho từng chủ đề, NNet học cách ánh xạ phi tuyến tính những yếu tố đầu vào như từ, hay mô hình vector của một văn bản vào một chủ đề cụ thể"],[400,"Khuyết điểm của phương pháp NNet là tiêu tốn nhiều thời gian dành cho việc huấn luyện mạng nơron"],[401,"2.2.5.1"],[402,"Ý tưởng Mô hình mạng neural gồm có ba thành phần chính như sau: kiến trúc (architecture), hàm chi phí (cost function), và thuật toán tìm kiếm (search"],[403,"16 algorithm)"],[404,"Kiến trúc định nghĩa dạng chức năng (functional form) liên quan giá trị nhập (inputs) đến giá trị xuất (outputs)"],[405,"Kiến trúc phẳng ( flat architecture ) : Mạng phân loại đơn giản nhất ( còn gọi là mạng logic) có một đơn vị xuất là kích hoạt kết quả (logistic activation) và không có lớp ẩn, kết quả trả về ở dạng hàm (functional form) tương đương với mô hình hồi quy logic"],[406,"Thuật toán tìm kiếm chia nhỏ mô hình mạng để thích hợp với việc điều chỉnh mô hình ứng với tập huấn luyện"],[407,"Ví dụ, chúng ta có thể học trọng số trong mạng kết quả (logistic network) bằng cách sử dụng không gian trọng số giảm dần (gradient descent in weight space) hoặc sử dụng thuật toán interated-reweighted least squares là thuật toán truyền thống trong hồi quy (logistic regression)"],[408,"Kiến trúc mô dun (modular architecture ): Việc sử dụng một hay nhiều lớp ẩn của những hàm kích hoạt phi tuyến tính cho phép mạng thiết lập các mối quan hệ giữa những biến nhập và biến xuất"],[409,"Mỗi lớp ẩn học để biểu diễn lại dữ liệu đầu vào bằng cách khám phá ra những đặc trưng ở mức cao hơn từ sự kết hợp đặc trưng ở mức trước"],[410,"Hình 2"],[411,"3"],[412,"Hình Kiến trúc mô đun (Modular Architecture)"],[413,"Các kết quả của từng mạng con sẽ là giá trị đầu vào cho mạng siêu chủ đề và được nhân lại với nhau để dự đoán chủ đề cuối cùng"],[414,"2.2.5.2"],[415,"Công thức chính Trong công trình của Wiener et al (1995) dựa theo khung của mô hình hồi quy, liên quan từ đặc trưng đầu vào cho đến kết quả gán chủ đề tương ứng được học từ"],[416,"17 tập dữ liệu"],[417,"Do vậy, để phân tích một cách tuyến tính, tác giả dùng hàm sigmoid sau làm hàm truyền trong mạng neural: 1 1 p e η− = + Trong đó, T xη β= là sự kết hợp của những đặc trưng đầu vào và p phải thỏa điều kiện (0,1)p∈ 2.2.6"],[418,"Linear Least Square Fit (LLSF) LLSF là một cách tiếp cận ánh xạ được phát triển bởi Yang và Chute vào năm 1992 [Yang & Chute, 1992] Đầu tiên, LLSF được Yang và Chute thử nghiệm trong lĩnh vực xác định từ đồng nghĩa sau đó sử dụng trong phân loại vào năm 1994 [Yang & Chute, 1994]"],[419,"Các thử nghiệm của Ỵang cho thấy hiệu suất phân loại của LLSF có thể ngang bằng với phương pháp kNN kinh điển"],[420,"2.2.6.1"],[421,"Ý tưởng LLSF sử dụng phương pháp hồi quy để học từ tập huấn luyện và các chủ đề có sẵn [Yang & Chute, 1994]"],[422,"Tập huấn luyện được biểu diễn dưới dạng một cặp vector đầu vào và đầu ra như sau : Vector đầu vào một văn bản bao gồm các từ và trọng số Vector đầu ra gồm các chủ đề cùng với trọng số nhị phân của văn bản ứng với vector đầu vào Giải phương trình các cặp vector đầu vào/ đầu ra, ta sẽ được ma trận đồng hiện của hệ số hồi quy của từ và chủ đề(matrix of word-category regression coefficients) 2.2.6.2"],[423,"Công thức chính 2arg minLS F F FA B= − Trong đó A, B là ma trận đại diện tập dữ liệu huấn luyện ( các cột trong ma trận tương ứng là các vector đầu vào và đầu ra ) FLS là ma trận kết quả chỉ ra một ánh xạ từ một văn bản bất kỳ vào vector của chủ đề đã gán trọng số"],[424,"18 Nhờ vào việc sắp xếp trọng số của các chủ đề, ta được một danh sách chủ đề có thể gán cho văn bản cần phân loại"],[425,"Nhờ đặt ngưỡng lên trọng số của các chủ đề mà ta tìm được chủ đề thích hợp cho văn bản đầu vào"],[426,"Hệ thống tự động học các ngưỡng tối ưu cho từng chủ đề, giống với kNN"],[427,"Mặc dù LLSF và kNN khác nhau về mặt thống kê, nhưng ta vẫn tìm thấy điểm chung ở hoạt động của hai phương pháp là việc học ngưỡng tối ưu"],[428,"2.2.7"],[429,"Centroid- based vector Là một phương pháp phân loại đơn giản, dễ cài đặt và tốc độ nhanh do có độ phức tạp tuyến tính O(n) [Han, Karypis 2000] 2.2.7.1"],[430,"Ý tưởng Mỗi lớp trong dữ liệu luyện sẽ được biểu diễn bởi một vector trọng tâm"],[431,"Việc xác định lớp của một văn bản thử bất kì sẽ thông qua viêc tìm vector trọng tâm nào gần với vector biểu diễn văn bản thử nhất"],[432,"Lớp của văn bản thử chính là lớp mà vector trọng tâm đại diện"],[433,"Khoảng cách được tính theo độ đo cosine"],[434,"2.2.7.2"],[435,"Công thức chính Công thức tính vector trọng tâm của lớp i { } 1 { } j i j d i C d i ∈ = ∑ Độ đo khoảng cách giữa vector x và iC ( )cos , * i i i x Cx C x C ⋅ = Trong đó : x là vector văn bản cần phân loại { }i là tập hợp các văn bản thuộc chủ đề Ci Chủ đề của x là Cx thõa cos( , ) arg max(cos( , ))x ix C x C="],[436,"19 2.3"],[437,"Kết luận Các thuật toán phân loại trên từ thuật toán phân loại 2 lớp (SVM) đến các thuật toán phân loại đa lớp (kNN) đều có điểm chung là yêu cầu văn bản phải được biểu diễn dưới dạng vector đặc trưng"],[438,"Ngoài ra các thuật toán như kNN,NB,LLSF đều phải sử dụng các ước lượng tham số và ngưỡng tối ưu trong khi đó thuật toán SVM có thể tự tìm ra các tham số tối ưu này"],[439,"Trong các phương pháp SVM là phương pháp sử dụng không gian vector đặc trưng lớn nhất (hơn 10000 chiều) trong khi đó chỉ là 2000 đối với NB, 2415 cho kNN và LLSF, 1000 cho Nnet [Yang, 1997]"],[440,"Thời gian huấn luyện cũng khác nhau đối với từng phương pháp, Nnet (sử dụng mỗi mạng tương ứng một chủ đề) và SVM là hai phương pháp có thời gian huấn luyện lâu nhất trong khi đó kNN,NB,LLSF và Centroid là các phương pháp có tốc độ (thời gian huấn luyện, phân loại) nhanh và cài đặt dễ dàng"],[441,"Về hiệu suất, dựa vào thử nghiệm của Yang [Yang, Liu, 1997] trên tập dữ liệu Reuter-21578 với hơn 90 chủ đề và trên 7769 văn bản, ta có thể sắp xếp các phương pháp phân loại văn bản theo thứ tự như sau SVM > kNN >> {LLSF,NB,Nnet}"],[442,"Tuy nhiên kết quả trên có thể không còn đúng khi áp dụng thử nghiệm phân loại trên Tiếng Việt"],[443,"Các lý do chính như sau : Thứ nhất: không có một tập dữ liệu chuẩn dành riêng cho việc phân loại"],[444,"Thứ hai: hiện tại chưa có chuẩn thống nhất nào cho vấn đề font và dấu câu cho Tiếng Việt"],[445,"Thứ ba: viêc biểu diễn văn bản Tiếng Việt bằng vector đặc trưng gặp nhiều trở ngại do bị phụ thuộc nhiều vào các phương pháp tách từ"],[446,"Trong khi đó các phương pháp này không đạt được hiệu quả cao như trong tiếng Anh"],[447,"Để có thể áp dụng các phương pháp phân loại văn bản đã được sử dụng thành công trên nhiều ngôn ngữ (Anh, Pháp,\u2026) như đã liệt kê trên, điều kiện tiên quyết là phải tìm ra một phương pháp tách từ tốt để thông qua đó cải thiện hiệu quả của các thuật toán phân loại"],[448,"Trong tiếng Anh, đơn vị nhỏ nhất là \u201ctừ\u201d nên việc tách từ trở nên khá đơn giản, trong khi đối với một số ngôn ngữ như tiếng Hoa, Nhật, Hàn Quốc.."],[449,"và Tiếng Việt của chúng ta phải xử lý hoàn toàn khác do đơn vị nhỏ nhất lại"],[450,"20 là \u201ctiếng\u201d"],[451,"Do đó, trước khi thực hiện phân loại, chúng ta phải tìm hiểu về các hướng tiếp cận cho việc tách từ tiếng Việt, một vấn đề khá thú vị không kém các phương pháp phân loại"],[452,""],[453,"21 CChhưươơnngg 33 CCÁÁCC PPHHƯƯƠƠNNGG PPHHÁÁPP TTÁÁCCHH TTỪỪ TTIIẾẾNNGG VVIIỆỆTT HHIIỆỆNN NNAAYY Tại sao tách từ tiếng Việt là một thách thức"],[454,"So sánh giữa tiếng Việt và tiếng Anh Nhận xét Bối cảnh các phương pháp tách từ hiện nay Bối cảnh chung Các hướng tiếp cận dựa trên từ Các hướng tiếp cận dựa trên ký tự Một số phương pháp tách từ tiếng Việt hiện nay Phương pháp Maximum Matching: forward/backward Phương pháp giải thuật học cải tiến Mô hình tách từ bằng WFST và mạng Neural Phương pháp quy hoạch động Phương pháp tách từ tiếng Việt dựa trên thống kê từ Internet và thuật toán di truyền Kết luận"],[455,"22 Chương 3"],[456,"CÁC PHƯƠNG PHÁP TÁCH TỪ TIẾNG VIỆT HIỆN NAY 3.1"],[457,"Tại sao tách từ tiếng Việt là một thách thức"],[458,"3.1.1"],[459,"So sánh giữa tiếng Việt và tiếng Anh Dựa vào các đặc điểm của tiếng Anh và tiếng Việt được trình bày trong [Đinh Điền, 2004], chúng em lập bảng so sánh các đặc điểm chủ yếu giữa tiếng Anh và tiếng Việt như sau Đặc điểm của Tiếng Việt Đặc điểm của Tiếng Anh Được xếp là loại hình đơn lập (isolate) hay còn gọi là loại hình phi hình thái, không biến hình, đơn tiết Từ không biến đổi hình thái, ý nghĩa ngữ pháp nằm ở ngoài từ Ví dụ : Chị ngã em nâng và Em ngã chị nâng Phương thức ngữ pháp chủ yếu: trật tự từ và hư từ"],[460,"Ví dụ: Gạo xay và Xay gạo; đang học và học rồi ; \u201cnó bảo sao không tới\u201d, \u201csao không bảo nó tới\u201d, \u201csao không tới bảo nó\u201d."],[461,"Ranh giới từ không được xác định mặc nhiên bằng khoảng trắng Tồn tại loại từ đặc biệt \u201c từ chỉ loại\u201d (classifier) hay còn gọi là Là loại hình biến cách (flexion) hay còn gọi là loại hình khuất chiết Từ có biến đổi hình thái, ý nghĩa ngữ pháp nằm ở trong từ"],[462,"Ví dụ: I see him và He sees me"],[463,"Phương thức ngữ pháp chủ yếu là : phụ tố"],[464,"Ví dụ: studying và studied Kết hợp giữa các hình vị là chặt chẽ, khó xác định, được nhận diện bằng khoảng trắng hoặc dấu câu"],[465,"Hiện tượng cấu tạo bằng từ ghép thêm phụ tố (affix) vào gốc từ là"],[466,"23 phó danh từ chỉ loại kèm theo với danh từ, như: cái bàn, cuốn sách, bức thư, con chó, con sông, vì sao\u2026 Có hiện tượng láy và nói lái trong tiếng Việt Ví dụ: lấp lánh, lung linh Hiện đại -> hại điện, thầy giáo-> tháo giầy\u2026 rất phổ biến"],[467,"Ví dụ: anticomputerizational ( anti- compute-er-ize-ation-al) Bảng 3"],[468,"1"],[469,"So sánh giữa tiếng Việt và tiếng Anh 3.1.2"],[470,"Nhận xét Tiếng Việt là loại hình phi hình thái nên việc phân biệt loại từ (danh từ, động từ, tính từ \u2026) và ý nghĩa từ là rất khó, cho dù có sử dụng từ điển"],[471,"Việc tiền xử lý văn bản (tách từ, tách đoạn, tách câu\u2026) sẽ thêm phức tạp với phần xử lý các hư từ, phụ từ, từ láy\u2026 Phương thức ngữ pháp chủ yếu là trật tự từ nên nếu áp dụng phương pháp tính xác suất xuất hiện của từ có thể không chính xác như mong đợi Ranh giới từ không được xác định mặc nhiên bằng khoảng trắng"],[472,"Điều này khiến cho việc phân tích hình thái (tách từ) tiếng Việt trở nên khó khăn"],[473,"Việc nhận diện ranh giới từ là quan trọng làm tiền đề cho các xử lý tiếp theo sau đó, như: kiểm lỗi chính tả, gán nhãn từ loại, thống kê tần suất từ,\u2026 Vì giữa tiếng Anh và tiếng Việt có nhiều điểm khác biệt nên chúng ta không thể áp dụng y nguyên các thuật toán tiếng Anh cho tiếng Việt 3.2"],[474,"Bối cảnh các phương pháp tách từ hiện nay 3.2.1"],[475,"Bối cảnh chung Dựa trên cơ sở thống kê các phương pháp tách từ trên tiếng Hoa của [Foo and Li, 2004], chúng em xin trình bày bối cảnh các phương pháp tách từ hiện nay cho tiếng Việt như sau:"],[476,"24 Hình 3.4"],[477,"Các hướng tiếp cận cơ bản trong tách từ tiếng Hoa và các hướng tiếp cận hiện tại được công bố trong tách từ tiếng Việt 3.2.2"],[478,"Các hướng tiếp cận dựa trên từ (Word-based approaches) Hướng tiếp cận dựa trên từ với mục tiêu tách được các từ hoàn chỉnh trong câu"],[479,"Hướng tiếp cận này có thể chia ra là ba hướng: dựa trên thống kê (statistics-based), dựa trên từ điển (dictionary-based) và hydrid (kết hợp nhiều phương pháp với hy vọng đạt được những ưu điểm của các phương pháp này) 3.2.2.1"],[480,"Các công trình tách từ tiếng Hoa Hướng tiếp cận dựa trên thống kê (statistics-based) dựa trên các thông tin như tần số xuất hiện của từ trong tập dữ liệu huấn luyện đầu"],[481,"Hướng tiếp cận này đặc Hybrid Chinese segmentation Character-based Word-based Unigram N-gram Statistic Dictionary Vietnamese segmentation Lê An Hà (03) H"],[482,"Nguyễn et al (05) Full word / Phrase Component Shortest Match Longest Match Overlap Match Đinh Điền et al (01) Luận văn này (05)"],[483,"25 biệt dựa trên tập ngữ liệu huấn luyện, nhờ vậy nên hướng tiếp cận này tỏ ra rất linh hoạt và hữu dụng trong nhiều lãnh vực riêng biệt [Nie et al.,1996]"],[484,"Hướng tiếp cận dựa trên từ điển (dictionary-based) thường được sử dụng trong tách từ"],[485,"Ý tưởng của hướng tiếp cận này là những cụm từ được tách ra từ văn bản phải khớp với các từ trong từ điển"],[486,"Những hướng tiếp cận khác nhau sẽ sử dụng những loại từ điển khác nhau"],[487,"Hướng tiếp cận \u201cfull word / phrase\u201d cần sử dụng một từ điển hoàn chỉnh để có thể tách được đầy đủ các từ hoặc ngữ trong văn bản, trong khi đó, hướng tiếp cận thành phần (component) lại sử dụng từ điển thành phần (component dictionary)[Wu & Tseng, 1993]"],[488,"Từ điển hoàn chỉnh chứa tất cả các từ và ngữ được dùng trong tiếng Hoa, trong khi từ điển thành phần (component dictionary) chỉ chứa các thành phần của từ và ngữ như hình vị và các từ đơn giản trong tiếng Hoa"],[489,"Tùy theo cách chọn để khớp từ (match), hướng tiếp cận \u201cfull word/ phrase\u201d có thể được chia ra thành khớp dài nhất (longest match \u2013 bằng cách duyệt văn bản tuần tự để tìm ra từ dài nhất có trong từ điển) và khớp ngắn nhất (shortest match \u2013 bằng cách duyệt văn bản tuần tự và chọn từ đầu tiên có trong từ điển )"],[490,"Ngoài hai cách thông dụng nhất là khớp dài nhất và khớp ngắn nhất, He et"],[491,"al"],[492,"(1996)còn đề nghị một cách thứ ba là cách kết hợp (overlap)"],[493,"Trong cách kết hợp này, mỗi chuỗi được phát sinh từ văn bản có thể chồng lấp lên chuỗi khác nếu chuỗi đó có trong từ điển (ví dụ : học sinh học, ta sẽ có các token là \u201chọc sinh\u201d, \u201csinh học\u201d chứ không phải chỉ có một cách như khớp dài nhất hoặc khớp ngắn nhất)"],[494,"Tại thời điểm hiện tại, hướng tiếp cận khớp dài nhất được xem là phương pháp quan trọng và hiệu quả nhất trong hướng tiếp cận dựa trên từ điển [Foo & Li, 2002]"],[495,"Tuy nhiên, hướng tiếp cận dựa trên từ điển vẫn có một số hạn chế trong việc tách từ vì thực hiện hoàn toàn dựa trên một từ điển hoàn chỉnh"],[496,"Trong thực tế, để xây dựng một bộ từ điển thật sự hoàn hảo chứa tất cả các từ tiếng Hoa là không thật sự cần thiết và khó thành hiện thực"],[497,"Hướng tiếp cận dựa trên thành phần (component) phát triển cũng với mục đích làm nhẹ bớt mặt hạn chế này bằng cách nối các hình vị và từ thành những từ và ngữ hoàn chỉnh [Wu & Tseng,1993,1995]"],[498,""],[499,"26 Hướng tiếp cận Hybrid với mục đích kết hợp các hướng tiếp cận khác nhau để thừa hưởng được ưu điểm của nhiều kỹ thuật khác nhau"],[500,"Hướng tiếp cận này thường kết hợp giữa hướng dựa trên thống kê và dựa trên từ điển nhằm lấy được ưu thế chung và các mặt vượt trội riêng của mỗi phương pháp"],[501,"Một số thành công của phương pháp này được trình bày trong [Nie et al, 1996]"],[502,"Mặc dù hướng tiếp cận hibrid có được những ưu điểm của phương pháp khác nhưng lại gặp phải các phức tạp khác như thời gian xử lý, không gian đĩa và đòi hỏi nhiều chi phí"],[503,"3.2.2.2"],[504,"Các công trình tách từ tiếng Việt Công trình của Đinh Điền et al (2001) đã cố gắng xây dựng tập ngữ liệu huấn luyện riêng (khoảng 10M) dựa trên các thông tin có nguồn gốc từ Internet như tin tức, e-book\u2026 Tuy nhiên tập ngữ liệu vẫn còn khá nhỏ để đảm bảo dung lượng và độ phong phú cho việc tách từ"],[505,"Mặc khác, do tập ngữ liệu được xây dựng một cách thủ công, nên sẽ phần nào mang tính chủ quan"],[506,"Và một hạn chế nữa là việc đánh giá lại được những thay đổi hằng ngày rất chậm, và có thể xảy ra hiện tượng flip-flop ( hiện tượng khi khắc phục lỗi này lại dẫn đến lỗi khác không ngờ tới) Ở hướng tiếp cận dựa trên từ điển, các từ được tách phải tương ứng với những từ có trong từ điển"],[507,"Hiện tại, ta vẫn chưa xây dựng được một bộ từ điển Việt Nam chứa toàn bộ các từ và ngữ"],[508,"3.2.3"],[509,"Các hướng tiếp cận dựa trên ký tự (Character-based approaches) Cần phân biệt rằng hình vị nhỏ nhất của tiếng Việt là \u201ctiếng\u201d, được cấu tạo bởi nhiều ký tự trong bảng chữ cái, trong khi hình vị nhỏ nhất của tiếng Hoa là một ký tự"],[510,"Vì chữ viết tiếng Hoa là chữ tượng hình, không dựa trên bảng chữ cái Latin như tiếng Việt nên trong trường hợp tiếng Hoa, người ta xét hình vị là \u201cký tự\u201d"],[511,"Tuy nhiên, mỗi ký tự (character) trong tiếng Hoa được phát âm thành một \u201ctiếng\u201d, nên xét về mặt âm vị, ta có thể xem \u201ctiếng\u201d trong tiếng Hoa và tiếng Việt là tương tự nhau"],[512,"Vì vậy, để tránh sự hiểu nhằm ý nghĩa giữa ký tự trong tiếng Hoa và tiếng trong tiếng Việt, chúng em xin phép dùng từ \u201ctiếng\u201d để chỉ cho ký tự tiếng Hoa và tiếng trong tiếng Việt ở một số trường hợp trình bày về cách tách từ"],[513,""],[514,"27 Mặc dù có cách viết khác nhau, nhưng về cấu tạo từ và ngữ pháp của tiếng Hoa và tiếng Việt có nhiều điểm tương đồng nhau"],[515,"Xét về nguồn gốc, tiếng Việt là hình thức phiên âm của chữ Nôm do nhân dân ta sáng tạo nên, vốn có nguồn gốc từ tiếng Trung Hoa thời xưa"],[516,"3.2.3.1"],[517,"Các công trình tách từ tiếng Hoa Hướng tiếp cận này đơn thuần rút trích một số lượng nhất định các tiếng trong văn bản như rút trích từ 1 ký tự (unigram) hay nhiều ký tự (n-gram)"],[518,"Mặc dù hướng tiếp cận này tương đối đơn giản hơn các hướng khác, nhưng nó cũng mang lại nhiều kết quả khả quan trong tiếng Hoa [Foo and Li, 2004]"],[519,"Hướng tiếp cận dựa trên một ký tự (unigram) chia văn bản ra các ký tự đơn lẻ để thực hiện việc tách từ"],[520,"Ngày nay, hầu như người ta không sử dụng phương pháp này như hướng tiếp cận chính trong việc tách từ nữa"],[521,"Hướng tiếp cận dựa trên nhiều ký tự (n-gram) chia văn bản ra thành nhiều chuỗi, mỗi chuỗi gồm hai, ba ký tự trở lên"],[522,"So với hướng tiếp cận dựa trên một ký tự, hướng tiếp cận này cho nhiều kết quả ổn định hơn [Kwok, 1997a;1997b]"],[523,"Do hơn 75% từ trong tiếng Hoa là từ gồm hai ký tự, nên các phương pháp phổ biến là dựa trên việc tách từ gồm hai ký tự sẽ cho kết quả nhiều từ đúng hơn [Wu & Tseng, 1993].Ví dụ, ta có một câu ABCDEF, hướng tiếp cận trên sẽ chia câu thành AB CD EF"],[524,"Một biến thể của phương pháp tách từ hai ký tự là hướng tiếp cận cách chia chồng lên nhau, ví dụ ta có ABCDEFG, hướng tiếp cận này sẽ chia thành AB BC CD DE DF FG"],[525,"Nhóm nghiên cứu của Swiss Federal Institute of Technology (ETH) áp dụng phương pháp biến thể và có thể cải tiến là sử dụng thêm danh sách stoplist (tương tự như các hư từ trong tiếng Việt như à, ơi..) để tách các ngữ của câu trước khi tách từ [Mateev et al, 1997]"],[526,"Nhờ vậy, mà kích thước văn bản cần tách từ được giảm xuống nhưng có khuyết điểm là nó có thể làm mất ý nghĩa của câu gốc"],[527,"Ưu điểm nổi bật của hướng tiếp cận dựa trên nhiều ký tự là tính đơn giản và dễ ứng dụng, ngoài ra còn có thuận lợi là ít tốn chi phí cho việc tạo chỉ mục (index) và xử lý nhiều câu truy vấn (query processing)"],[528,"Qua nhiều công trình nghiên cứu,"],[529,"28 hướng tiếp cận tách từ dựa trên nhiều ký tự, đặc biệt là cách tách từ hai ký tự được xem là sự lựa chọn thích hợp[Foo & Li, 2002]"],[530,"3.2.3.2"],[531,"Các công trình tách từ tiếng Việt Trong trường hợp tiếng Việt, hướng tiếp cận này được xem là hướng tiếp cận dựa trên tiếng, khác với tiếng Hoa là dựa trên ký tự"],[532,"Ở Việt Nam, hướng tiếp cận này cũng đã có một số công trình được phổ biến"],[533,"[Lê An Hà, 2003] xây dựng tập ngữ liệu thô 10M, sử dụng phương pháp quy hoạch động để cực đại hóa tổng xác suất xuất hiện của các ngữ"],[534,"Gần đây nhất có thể kể đến công trình của [H"],[535,"Nguyen et al, 2005], thay vì sử dụng ngữ liệu thô, công trình của họ có sáng tạo là lấy thông tin thống kê từ Internet và sử dụng thuật toán di truyền (Genetic Algorithm) để tìm cách tách từ tối ưu nhất"],[536,"Mặc dù công trình của họ còn mang tính sơ bộ, và việc thử nghiệm chưa hoàn chỉnh, nhưng chúng em tin rằng ý tưởng mới lạ này đem lại nhiều hứa hẹn khả quan"],[537,"Hướng tiếp cận cho việc tách từ của chúng em mở rộng trên ý tưởng này, ngoài ra, chúng em thực hiện một số thay đổi quan trọng nhằm nâng cao tính chính xác của việc tách từ"],[538,"Thêm nữa, chúng em đã thực hiện một số thử nghiệm trên số lượng dữ liệu đáng kể nhằm đưa ra các đánh giá một cách bao quát hơn, chính xác hơn"],[539,"3.3"],[540,"Một số phương pháp tách từ tiếng Việt hiện nay 3.3.1"],[541,"Phương pháp Maximum Matching: forward/backward 3.3.1.1"],[542,"Nội dung Phương pháp khớp tối đa (Maximum Matching) còn gọi là Left Right Maximum Matching (LRMM)"],[543,"Theo phương pháp này, ta sẽ duyệt một ngữ hoặc câu từ trái sang phải và chọn từ có nhiều âm tiết nhất có mặt trong từ điển, rồi cứ thể tiếp tục cho từ kế tiếp cho đến hết câu"],[544,"Thuật toán được trình bày trong [Chih-Hao Tsai, 2000] Dạng đơn giản được dùng giải quyết nhập nhằng từ đơn"],[545,"Giả sử có một chuỗi ký tự (tương đương với chuỗi tiếng trong tiếng Việt) C1, C2, .."],[546,", C2"],[547,"Ta bắt đầu từ đầu chuỗi"],[548,"Đầu tiên kiểm tra xem C1, có phải là từ hay không, sau đó kiểm tra xem C1C2"],[549,"29 có phải là từ hay không"],[550,"Tiếp tục tìm cho đến khi tìm được từ dài nhất"],[551,"Từ có vẻ hợp lý nhất sẽ là từ dài nhất"],[552,"Chọn từ đó, sau đó tìm tiếp như trên cho những từ còn lại cho đến khi xác định được toàn bộ chuỗi từ"],[553,"Dạng phức tạp: Quy tắc của dạng này là phân đoạn có vẻ hợp lý nhất là đoạn ba từ với chiều dài tối đa"],[554,"Thuật toán bắt đầu như dạng đơn giản"],[555,"Nếu phát hiện ra những cách tách từ gây nhập nhằng (ví dụ, C1 là từ và C1C2 cũng là từ), ta xem các chữ kế tiếp để tìm tất cả các đoạn ba từ có thể có bắt đầu với C1 hoặc C1C2"],[556,"Ví dụ ta được những đoạn sau: C1 C2 C3 C4 C1C2 C3 C4 C5 C1C2 C3 C4 C5 C6 Chuỗi dài nhất sẽ là chuỗi thứ ba"],[557,"Vậy từ đầu tiên của chuỗi thứ ba (C1C2) sẽ được chọn"],[558,"Thực hiện lại các bước cho đến khi được chuỗi từ hoàn chỉnh"],[559,"3.3.1.2"],[560,"Ưu điểm Với cách này, ta dễ dàng tách được chính xác các ngữ/câu như \u201c hợp tác xã || mua bán\u201d, \u201cthành lập || nước || Việt Nam || dân chủ || cộng hòa\u201d Cách tách từ đơn giản, nhanh, chỉ cần dựa vào từ điển Trong tiếng Hoa, cách này đạt được độ chính xác 98,41% [Chih-Hao Tsai, 2000]"],[561,"3.3.1.3"],[562,"Hạn chế Độ chính xác của phương pháp phụ thuộc hoàn toàn vào tính đủ và tính chính xác của từ điển Phương pháp này sẽ tách từ sai trong các trường hợp \u201c học sinh || học sinh|| học\u201d, \u201cmột || ông || quan tài || giỏi\u201d, \u201ctrước || bàn là || một || ly || nước\u201d\u2026"],[563,"30 3.3.2"],[564,"Phương pháp giải thuật học cải biến (Transformation-based Learning, TBL) 3.3.2.1"],[565,"Nội dung Đây là cách tiếp cận dựa trên ngữ liệu đã đánh dấu"],[566,"Theo cách tiếp cận này, để huấn luyện cho máy tính biết cách nhận diện ranh giới từ tiếng Việt, ta có thể cho máy \u201chọc\u201d trên ngữ liệu hàng vạn câu tiếng Việt đã được đánh dấu ranh giới từ đúng"],[567,"Sau khi học xong, máy sẽ xác định được các tham số (các xác suất) cần thiết cho mô hình nhận diện từ"],[568,"3.3.2.2"],[569,"Ưu điểm Đặc điểm của phương pháp này là khả năng tự rút ra quy luật của ngôn ngữ Nó có những ưu điểm của cách tiếp cận dựa trên luật vì cuối cùng nó cũng dựa trên luật được rút ra) nhưng nó khắc phục được khuyết điểm của việc xây dựng các luật một cách thủ công bởi các chuyên gia"],[570,"Các luật được thử nghiệm tại chỗ để đánh giá độ chính xác và hiệu quả của luật (dựa trên ngữ liệu huấn luyện) Có khả năng khử được một số nhập nhằng như \u201cThe singer sang a lot of a??as\u201d, thì hệ có thể xác định được \u201ca??as\u201d là \u201carias\u201d (dân ca) thay vì \u201careas\u201d (khu vực) của các mô hình ngôn ngữ theo kiểu thống kê"],[571,"3.3.2.3"],[572,"Hạn chế Phương pháp này \u201cdùng ngữ liệu có gán nhãn ngôn ngữ để học tự động các qui luật đó\u201d[Đinh Điền, 2004]"],[573,"Như đã nói ở chương 1, việc xây dựng một tập ngữ liệu đạt được đầy đủ các tiêu chí của tập ngữ liệu trong tiếng Việt là một điều rất khó, tốn kém nhiều về mặt thời gian và công sức"],[574,"Hệ phải trải qua một thời gian huấn luyện khá lâu để có thể rút ra các luật tương đối đầy đủ Cài đặt phức tạp"],[575,"31 3.3.3"],[576,"Mô hình tách từ bằng WFST và mạng Neural 3.3.3.1"],[577,"Nội dung Mô hình mạng chuyển dịch trạng thái hữu hạn có trọng số WFST (Weighted finit\u2013state Transducer) đã được [Richard et al, 1996] áp dụng để tách từ tiếng Trung Quốc"],[578,"Ý tưởng cơ bản là áp dụng WFST kết hợp với trọng số là xác suất xuất hiện của mỗi từ trong ngữ liệu"],[579,"Dùng WFST để duyệt qua câu cần xét"],[580,"Cách duyệt có trọng số lớn nhất sẽ là cách tách từ được chọn"],[581,"Giải pháp này cũng đã đượng áp dụng trong [Đinh Điền et al, 2001] kèm với mạng neutral để khử nhập nhằng"],[582,"Hệ thống tách từ tiếng Việt của [Đinh Điền, 2001] gồm hai tầng: tầng WFST ngoài việc tách từ còn xử lý thêm các vấn đề liên quan đến đặc thù của tiếng Việt như từ láy, tên riêng\u2026 và tầng mạng neural dùng để khử nhập nhằng nếu có"],[583,"Hình 3.5"],[584,"Sơ đồ hệ thống WFST Bắt đầu Tiền xử lý Bắt đầu Tiền xử lý Tiền xử lý t < T0 Y"],[585,"32 Tầng WFST :gồm có ba bước Xây dựng từ điển trọng số : theo mô hình WFST, việc phân đoạn từ được xem như là một sự chuyển dịch trạng thái có xác suất (Stochastic Transduction)"],[586,"Chúng ta miêu tả từ điển D là một đồ thị biến đổi trạng thái hữu hạn có trọng số"],[587,"Giả sử: H: là tập các từ chính tả tiếng Việt (còn gọi là \u201ctiếng\u201d) P: là từ loại của từ (POS: Part \u2013 Of \u2013 Speech)"],[588,"Mỗi cung của D có thể là: Từ một phần tử của H tới một phần tử của H, hoặc Từ ε (ký hiệu kết thúc từ) tối một phần tử của P Các nhãn trong D biểu thị một chi phí ước lượng (estimated cost) bằng công thức : Cost = - log(f/N) Với f: tần số của từ, N: kích thước tập mẫu"],[589,"Đối với các trường hợp từ mới chưa gặp, tác giả áp dụng xác suất có điều kiện Goog-Turning (Baayen) để tính toán trọng số"],[590,"Xây dựng các khả năng phân đoạn từ : Để giảm sự bùng nổ tổ hợp khi sinh ra các dãy các từ có thể từ một dãy các tiếng trong câu, tác giả đề xuất một phương pháp mới là kết hợp dùng từ điển để hạn chế sinh ra các bùng nổ tổ hợp"],[591,"Khi phát hiện thấy một cách phân đoạn từ nào đó không phù hợp (không có trong từ điển, không phải là từ láy, không phải là danh từ riêng\u2026) thì tác giả loại bỏ các nhánh xuất phát từ cách phân đoạn từ đó"],[592,"Lựa chọn khả năng phân đoạn từ tối ưu : Sau khi được một danh sách các cách phân đoạn từ có thể có của câu, tác giả chọn trường hợp phân đoạn từ có trọng số bé nhất như sau: Ví dụ: input = \u201cTốc độ truyền thông tin sẽ tăng cao\u201d o Dictionary \u201ctốc độ\u201d 8.68 \u201ctruyền\u201d 12.31"],[593,"33 \u201ctruyền thông\u201d 1231 \u201cthông tin\u201d 7.24 \u201ctin\u201d 7.33 \u201csẽ\u201d 6.09 \u201ctăng\u201d 7.43 \u201ccao\u201d 6.95 Id(D)*D* = \u201cTốc độ # truyền thông # tin # sẽ # tăng # cao.\u201d 48.79 (8.68 +12.31 + 7.33 + 6.09 + 7.43 +6.95 = 48.79 ) Id(D)*D* = \u201cTốc độ # truyền # thông tin # sẽ # tăng # cao.\u201d 48.70 (8.68 +12.31 + 7.24 + 6.09 + 7.43 +6.95 = 48.79 ) Do đó, ta có được phân đoạn tối ưu là \u201cTốc độ # truyền # thông tin # sẽ # tăng # cao.\u201d Tầng mạng neural : Mô hình mạng neural mà tác giả đề xuất được dùng để lượng giá 3 dãy từ loại: NNV,NVN, VNN (N: Noun, V: Verb)"],[594,"Mô hình này được học bằng chính các câu mà cách phân đoạn từ vẫn còn nhập nhằng sau khi qua mô hình thứ nhất"],[595,"3.3.3.2"],[596,"Ưu điểm Độ chính xác trên 97% [Đinh Điền et al, 2001] Mô hình cho kết quả phân đoạn từ với độ tin cậy (xác suất) kèm theo"],[597,"Nhờ có tầng mạng neural nên mô hình có thể khử nhập nhằng các trường hợp tầng WFST cho ra nhiều ứng viên có kết quả ngang nhau Phương pháp này cho kết quả với độ chính xác khá cao vì mục đích của tác giả muốn nhắm đến việc tách từ thật chính xác để là nền tảng cho việc dịch máy"],[598,"3.3.3.3"],[599,"Hạn chế Cũng tương tự như phương pháp TBL, việc xây dựng tập ngữ liệu là rất công phu, nhưng thật sự rất cần thiết để phục vụ cho mục đích dịch máy sau này của tác giả"],[600,""],[601,"34 3.3.4"],[602,"Phương pháp quy hoạch động (dynamic programming) 3.3.4.1"],[603,"Nội dung Phương pháp quy hoạch động [Le An Ha, 2003] chỉ sử dụng tập ngữ liệu thô để lấy thông tin về tần số thống kê của từ , làm tăng độ tin cậy cho việc tính toán"],[604,"Việc tính toán bắt đầu với những đơn vị chắc chắn như câu, các ngữ (chunk) được phân cách bởi dấu câu ( như dấu phẩy, gạch nối, chấm phẩy\u2026) vì những thành phần này không có tính nhập nhằng ngay cả trong văn viết cũng như nói"],[605,"Sau đó, tác giả cố gắng tối đa hoá xác suất của ngữ bằng cách tìm ra nhiều cách tách ngữ đó"],[606,"Cách tách cuối cùng là cách tách là cho ngữ đó có xác suất cao nhất"],[607,"Ý tưởng của cách tách từ này cho một ngữ cần tách từ, ta phải tìm ra các tổ hợp từ tạo nên ngữ đó sao cho tổ hợp đó đạt được xác suất tối đa"],[608,"Tuy nhiên trong phương pháp tính toán này, tác giả gặp phải vấn đề bùng nổ tổ hợp và phân tích ngữ liệu thô"],[609,"Để giải quyết vấn đề trên, tác giả đã sử dụng phương pháp quy hoạch động (dynamic programming) vì lúc đó, xác suất cực đại của một ngữ nhỏ hơn chỉ phải tính toán một lần và sử dụng lại trong các lần sau"],[610,"3.3.4.2"],[611,"Ưu điểm Không cần sử dụng tập ngữ liệu đã đánh dấu chính xác 3.3.4.3"],[612,"Hạn chế Trong thí nghiệm, tác giả chỉ dừng lại ở việc tách các từ có ba tiếng bởi vì tập ngữ liệu đầu vào vẫn còn khá nhỏ"],[613,"Xác suất từ đúng là 51%, xác suất từ chấp nhận được 65% [Le An Ha, 2003]"],[614,"Xác suất này tương đối thấp so với các phương pháp tách từ khác đã đề cập ở trên"],[615,"3.3.5"],[616,"Phương pháp tách từ tiếng Việt dựa trên thống kê từ Internet và thuật toán di truyền (Internet and Genetics Algorithm-based Text Categorization for Documents in Vietnamese - IGATEC) 3.3.5.1"],[617,"Nội dung Phương pháp IGATEC do H.Nguyễn et al (2005) giới thiệu là một hướng tiếp cận mới cho việc tách từ với mục đích phân loại văn bản mà không cần dùng đến"],[618,"35 một từ điển hay tập huấn luyện nào"],[619,"Trong hướng tiếp cận này, tác giả kết hợp giữa thuật toán di truyền (Genetics Algorithm - GA) với dữ liệu thống kê được trích xuất từ Internet tiến hoá một quần thể gồm các cá thể là các khả năng tách từ trong câu"],[620,"Hệ thống gồm ba phần Hình 3.6"],[621,"Toàn cảnh hệ thống IGATEC Online Extractor : Phần này có tác dụng lấy thông tin về tần số xuất hiện của các từ trong văn bản bằng cách sử dụng một search engine nổi tiếng như Google"],[622,"Sau đó, tác giả sử dụng các công thức sau đây để tính toán mức độ phụ thuộc lẫn nhau (mutual information) để là cơ sở tính fitness cho GA engine"],[623,"Tính xác suất các từ xuất hiện trên Internet ( )(w)= count wp MAX 1 21 2 ( & )( & ) count w wp w w MAX = Trong đó, MAX = 4 * 109 ; count(w) số lượng văn bản trên Internet được tìm thấy có chứa từ w hoặc cùng chứa w1 và w2 đối với count(w1 & w2) Tính xác suất độ phụ thuộc của một từ lên một từ khác Online Extractor Online Extractor Online Extractor Online Extractor segmentation segmentation segmentation \u2026"],[624,"36 1 21 2 1 ( & )( | ) ( ) p w wp w w p w = Thông tin phụ thuộc lẫn nhau (mutual information) của các từ ghép được cấu tạo bởi n tiếng (cw = w1w2\u2026wn) 1 2 1 2 1 ( & & .."],[625,"& ) ( ) = ( ) - ( & & .."],[626,"& ) n n j n j p w w wMI cw p w p w w w = ∑ GA Engine for Text Segmentation : mỗi cá thể trong quần thể được biểu diễn bởi chuỗi các bit 0,1, trong đó, mỗi bit đại diện cho một tiếng trong văn bản, mỗi nhóm bit cùng loại đại diện cho một segment"],[627,"Các cá thể được khởi tạo ngẫu nhiên, trong đó, mỗi segment được giới hạn trong khoảng 5"],[628,"GA engine sau đó thực hiện các bước đột biến và lai ghép nhằm mục đích làm tăng giá trị fitness của các cá thể, để đạt được cách tách từ tốt nhất có thể"],[629,"Text Categorization : tác giả dùng độ hỗ trợ (support degree) của văn bản cần phân loại cho các từ khoá để phân loại văn bản"],[630,"3.3.5.2"],[631,"Ưu điểm Không cần sử dụng bất cứ tập huấn luyện hoặc từ điển nào Phương pháp tương đối đơn giản"],[632,"Không tốn thời gian huấn luyện 3.3.5.3"],[633,"Hạn chế So với các phương pháp trước, IGATEC có độ chính xác thấp hơn LRMM và WFST nhưng vẫn chấp nhận được đối với mục đích tách từ dành cho phân loại văn bản"],[634,"Thời gian chạy ban đầu khá chậm do phải lấy thông tin từ Internet mà đường truyền ở Việt Nam còn hạn chế"],[635,"Chưa có các thử nghiệm trên tập dữ liệu đủ lớn"],[636,""],[637,"37 3.4"],[638,"So sánh các phương pháp tách từ Tiếng Việt hiện nay Nhìn một cách tổng quan, phương pháp dựa trên từ (word-base) cho độ chính xác khá cao ( trên 95%) nhờ vào tập ngữ liệu huấn luyện lớn, được đánh dấu chính xác, tuy nhiên hiệu suất của thuật toán phụ thuộc hoàn toàn vào ngữ liệu huấn luyên"],[639,"Bởi vì mục đích của các tác giả [Đinh Điền et al, 2001] là thực hiện tách từ thật chính xác để phục vụ cho việc dịch máy nên tác giả đã chọn phương pháp WFST"],[640,"Với các phương pháp cần phải sử dụng từ điển hoặc tập huấn luyện, ngoài việc tách từ thật chính xác, ta còn có thể nhờ vào các thông tin đánh dấu trong tập ngữ liệu để thực hiện các mục đích khác cần đến việc xác định từ loại như dịch máy, kiểm lỗi chính tả, từ điển đồng nghĩa.."],[641,"Do vậy, mặc dù thời gian huấn luyện khá lâu, cài đặt khá phức tạp, chi phí tạo tập ngữ liệu huấn luyện rất tốn kém, nhưng kết quả mà hướng tiếp cận dựa trên từ mang lại cho mục đích dịch máy là rất xứng đáng cho công sức bỏ ra"],[642,"Hướng tiếp cận dựa trên ký tự (character-based) có ưu điểm là dễ thực hiện, thời gian thực thi tương đối nhanh, tuy nhiên lại có độ chính xác không cao bằng phương pháp dựa trên từ"],[643,"Hướng tiếp cận này thích hợp cho các mục đích nghiên cứu không cần đến độ chính xác tuyệt đối cũng như các thông tin về từ loại như phân loại văn bản, lọc spam, firewall.."],[644,"Nhìn trên bình diện chung, hướng tiếp cận dựa trên từ có nhiều ưu điểm đáng kể, và đem lại nhiều hứa hẹn lạc quan cho các hướng nghiên cứu tiếp theo để nâng cao độ chính xác của phương pháp tách từ này"],[645,"3.5"],[646,"Kết luận Dựa trên các phân tích về ưu khuyết điểm của các phương pháp, chúng em chọn hướng tiếp cận dựa trên \u201ctiếng\u201d (character-based) cho mục tiêu phân loại văn bản của mình"],[647,"Bởi vì, mục tiêu của luận văn là phân loại tin tức báo điện tử, một loại hình cực kỳ phong phú về nội dung và ngôn ngữ, nên việc tạo ra một từ điển hoàn chỉnh và có khả năng cập nhật các thay diễn ra liên tục của ngôn ngữ là khó thực hiện được"],[648,"Hệ thống xử lý cần phải có khả năng linh hoạt, tự động cập nhật những thay đổi"],[649,"38 hằng ngày, nên hướng tiếp cận không dựa trên từ điển hoặc tập ngữ liệu là cực kỳ thích hợp"],[650,"Hơn nữa, hệ thống phân loại tin tức cần có tốc độ xử lý chấp nhận được để có thể xử lý kịp thời các thông tin mới xuất bản hằng ngày"],[651,"Do đó, với ưu điểm đơn giản, tốc độ thực thi chấp nhận đươc, hướng tiếp cận IGATEC là một lựa chọn hoàn toàn phù hợp"],[652,"Mặt khác, việc phân loại văn bản không yêu cầu việc tách từ phải có độ chính xác cao đến mức từng từ"],[653,"Ta có hoàn toàn có thể thực hiện thêm việc loại bỏ các từ không cần thiết cho việc phân loại như các hư từ, thán từ.."],[654,"để tăng tốc độ và sự chính xác của bước tách từ, chuẩn bị cho việc phân loại văn bản"],[655,""],[656,"39 CChhưươơnngg 44 TTÁÁCCHH TTỪỪ TTIIẾẾNNGG VVIIỆỆTT KKHHÔÔNNGG DDỰỰAA TTRRÊÊNN TTẬẬPP NNGGỮỮ LLIIỆỆUU HHAAYY TTỪỪ ĐĐIIỂỂNN \u2013\u2013 MMỘỘTT TTHHÁÁCCHH TTHHỨỨCC Giới thiệu Các nghiên cứu về thống kê dựa trên Internet Các phương pháp tính độ liên quan giữa các từ dựa trên thống kê Tiền xử lý Hướng tiếp cận tách từ dựa trên thống kê từ Internet và thuật toán di truyền Công cụ trích xuất thông tin từ Google Công cụ tách từ dùng thuật toán di truyền Kết quả thực nghiệm Kết luận"],[657,"40 Chương 4"],[658,"TÁCH TỪ TIẾNG VIỆT KHÔNG DỰA TRÊN TẬP NGỮ LIỆU ĐÁNH DẤU (ANNOTATED CORPUS) HAY TỪ ĐIỂN (LEXICON) \u2013 MỘT THÁCH THỨC 4.1"],[659,"Giới thiệu Như chúng ta đã tìm hiểu ở những phần trên, việc khó xác định ranh giới từ đã làm cho việc xử lý tính nhập nhằng trong ngôn ngữ tiếng Việt càng thêm phức tạp.Ví dụ như: câu \u201công lão già đi rất nhanh\u201d, ta có thể phân chia từ theo nhiều cách mà câu vẫn có nghĩa \u201công ||già đi || rất || nhanh\u201d, \u201công già || đi || rất || nhanh\u201d, \u201công || già || đi || rất || nhanh\u201d \u2026 Nhìn chung, đối với tiếng Anh, về mặt lý thuyết tiếng Anh có nhiều thuận lợi vì là loại ngôn ngữ hoà kết hay biến cách (flexion) [Đinh Điền, 2004] , hệ thống ngữ pháp và từ loại đã được quy định rõ ràng, do đó việc phân định ranh giới từ cũng như xây dựng tập ngữ liệu đánh dấu là tương đối đễ dàng"],[660,"Còn đối với tiếng Việt, về mặt lý thuyết tiếng Việt là loại hình đơn lập [Đinh Điền, 2004], phương thức ngữ pháp chủ yếu là trật tự từ và hư từ, vì vậy chỉ xét về mặt phân định ranh giới từ đã có thể có nhiều cách phân định cho cùng một câu mà vẫn đúng ngữ pháp Việt Nam"],[661,"Ở phần này, chúng em xin trình bày hướng tiếp cận cho việc tách từ tiếng Việt theo một hướng mới mà không cần sử dụng tập ngữ liệu huấn luyện hay từ điển"],[662,"Hướng tiếp cận của chúng em dựa trên ý tưởng của bài báo IGATEC, và có nhiều cải tiến đang kể hàm làm tăng chất lượng cho bước tách từ tiếng Việt phục vụ cho việc phân loại tin tức báo điện tử"],[663,"4.2"],[664,"Các nghiên cứu về thống kê dựa trên Internet 4.2.1"],[665,"Giới thiệu Với sự phát triển nhanh chóng của Internet, world-wide-web đã trở thành nguồn dữ liệu lớn nhất trên thế giới, và là nguồn thông tin ngữ nghĩa tiềm tàng được hàng triệu người dùng trên thế giới tạo ra"],[666,"Đối với con người, việc xem xét mức độ liên quan giữa hai từ là rất dễ dàng bởi vì con người có thể dựa vào kiến thức thông"],[667,"41 thường của mình để suy ra ngữ cảnh thích hợp, ví dụ giữa từ \u201ccái nón\u201d và \u201cmàu đỏ\u201d, con người dễ dàng nhận ra sự liên quan là \u201ccái nón có màu đỏ\u201d"],[668,"Tuy nhiên, máy tính của chúng ta không có khả năng như con người, vì vậy, chúng ta phải tìm ra một cách biểu diễn ngữ nghĩa mà máy tính có thể \u201ctiêu hoá\u201d được"],[669,"Có ý kiến cho rằng ta có thể tạo một mạng ngữ nghĩa đồ sộ như một hệ thống trí tuệ ban đầu, sau đó các kiến thức về cuộc sống thực sẽ tự động xuất hiện"],[670,"Tuy nhiên hướng giải quyết này đòi hỏi lượng chi phí khổng lồ cho việc thiết kế cấu trúc có khả năng tính toán tri thức và việc nhập các dữ liệu chuẩn xác do các chuyên gia thực hiện"],[671,"Trong khi nỗ lực này vẫn còn đang trong cuộc đua đường dài, chúng ta hãy sử dụng những thông tin hiện có trên world-wide-web để thực hiện việc biểu diễn ngữ nghĩa"],[672,"Chúng ta đều biết rằng Internet là kho dữ liệu vô tận, do vậy việc khai thác các thông tin trên đó không thể thực hiện thủ công mà chúng ta phải thông qua sự hỗ trợ của một công cụ tìm kiếm trên mạng"],[673,"Nói đến công cụ tìm kiếm (search engine), có lẽ tên tuổi đầu tiên mà chúng ta nghĩ đến là Google, một công cụ tìm kiếm hàng đầu bởi tốc độ và chất lượng mà Google đem lại cho người dùng"],[674,"Và điều đó càng được chứng minh cụ thể hơn khi có ngày càng nhiều các công trình nghiên cứu về thống kê trên Internet dựa vào công cụ tìm kiếm Google như trong phần trình bày tiếp theo sau đây"],[675,"4.2.2"],[676,"Một số công trình nghiên cứu về thống kê dựa trên Internet Theo Rudi Cilibrasi & Paul Vitanyi (2005), công cụ tìm kiếm Google có thể dùng để tự động khám phá ý nghĩa của từ"],[677,"Ví dụ : Google tìm thấy từ \u201cstudent\u201d và \u201cbook\u201d cùng xuất hiện với nhau trên Internet với tần số là 57.600.000, trong khi từ \u201cstudent\u201d và \u201capple\u201d lại chỉ xuất hiện 8.110.000"],[678,"Rõ ràng, chúng ta có thể nhận thấy \u201cstudent\u201d và \u201cbook\u201d có liên quan với nhau mật thiết hơn là \u201cstudent\u201d và \u201capple\u201d"],[679,"Tác giả đã sử dụng kết quả tìm kiếm của Google để huấn luyện ngữ nghĩa của các từ (semantic meaning of words) cho phần mềm \u2013 một vấn đề trọng tâm trong ngành trí tuệ nhân tạo"],[680,"Giả sử muốn tính toán mức độ liên quan giữa từ x với từ y, Rudi & Paul (2005) đã đưa ra công thức tính khoảng cách NGD (Normalise Google Distance) như sau:"],[681,"42 max{log ( ), log ( )} log ( , ) log min{log ( ), log ( )} f x f y f x yNGD M f x f y − = − (1) Trong đó : f(x) :số trang web chứa từ x mà Goole trả về f(x,y) : số trang web chứa đồng thời từ x và từ y M = 8.058.044.651 là số trang web hiện tại mà Google đã đánh chỉ mục Với công thức trên, giá trị của NGD càng nhỏ thì mức độ liên quan giữa hai từ càng cao"],[682,"Ví dụ: tần số xuất hiện của \u201cstudent\u201d= 401.000.000, \u201cbook\u201d = 387.000.000, đồng thời là 57.600.000, còn \u201capple\u201d là 144.000.000, \u201cstudent\u201d & \u201capple\u201d= 8.110.000"],[683,"Với M = 8.058.044.651, ta có 6 6 6 log 401.10 log 57,6.10( , ) 0.64 log8058044651 log 387.10 NGD student book −≈ ≈ − 6 6 6 log 401.10 log8,11.10( , ) 0.97 log8058044651 log144.10 NGD student apple −≈ ≈ − Từ kết quả trên, ta có NGD(student,book) ≈0.64 < NGD(student,apple) ≈0.97, nên có thể kết luận là \u201cstudent\u201d liên quan với \u201cbook\u201d nhiều hơn là \u201capple\u201d"],[684,"Nếu NGD của hai từ lớn hơn 1 thì tác giả nhận xét rằng hai từ đó thường xuất hiện cùng với nhau trong trang web mà không vì một mối liên quan nào cả"],[685,"Ví dụ: tần số xuất hiện của \u201cby\u201d là 2.770.000.000, \u201cwith\u201d là 2.566.000.000, đồng thời \u201cby\u201d và \u201cwith\u201d là 49.700.000"],[686,"Với M = 8.058.044.651, ta có NGD(by,with) ≈ 3.51 Hơn nữa, NGD là số tỉ lệ bất biến (scale-invariant) nên có tính ổn định với sự tăng trưởng số lượng trang web trên Google"],[687,"Đây là tính chất rất quan trọng bởi vì M số lượng trang web do Google đánh chỉ mục tăng thường xuyên, do đó, số trang web chứa các ngữ tìm kiếm cũng tăng lên ứng với tỉ lệ đó"],[688,"Điều này có nghĩa là nếu M tăng gấp đôi thì tần số xuất hiện của các ngữ cũng tăng gấp đôi"],[689,"Công trình của Rudi & Paul (2005) đã mở ra một hướng tiếp cận mới cho các công trình nghiên cứu khác nhờ tính chất không giới hạn bởi dữ liệu, dễ dàng thực thi và là nền móng cho các phương pháp nghiên cứu khác [Rudi & Paul, 2005]"],[690,""],[691,"43 Ngoài ra, theo James & Daniel (2005) còn có một số công trình nghiên cứu về phương pháp thống kê khác trên Internet như tính toán kết quả tìm kiếm bằng hàm luỹ thừa [Simkin & Roychowdhurry, 2003] [Bagrow et al, 2004] , hay phương pháp được đánh giá tốt hơn là dựa vào giá trị tương tự cực đại (Maximum Likelihood) [James & Daniel, 2005]\u2026"],[692,"Mục đích của việc sử dụng giá trị tương tự cực đại để tìm ra chỉ số gần giống nhau nhất giữa hai khái niệm"],[693,"Tuy nhiên, theo kết luận của James & Daniel(2005), các phương pháp tính toán dựa trên hàm mũ cho kết quả chưa khả quan lắm và còn mang tính chủ quan"],[694,"4.2.3"],[695,"Nhận xét Hướng thống kê dựa trên Internet hứa hẹn nhiều kết quả khả quan vì không cần phụ thuộc vào tập dữ liệu huấn luyện truyền thống mà chúng ta có thể tận dụng khả năng vô tận của Internet thông qua công cụ tìm kiếm"],[696,"Dựa trên nhận xét của Rudi & Paul (2005), tỉ lệ xuất hiện của từ trên Internet là khá ổn định, điều này cho phép ta thực hiện các tính toán chính xác và ổn định vì ít phụ thuộc vào số lượng trang web trên Internet tăng lên theo thời gian"],[697,"Hiện nay, các công trình nghiên cứu theo hướng tiếp cận mới này chủ yếu được thực hiện trên tiếng Anh, còn đối với tiếng Việt thì có thể nói IGATEC là công trình đầu tiên áp dụng phương pháp này nhưng đã đạt được kết quả rất đáng quan tâm"],[698,"Chúng em hy vọng rằng rằng những nỗ lực nghiên cứu và cải tiến phương pháp IGATEC sẽ đạt được kết quả tốt hơn"],[699,"4.3"],[700,"Các phương pháp tính độ liên quan giữa các từ dựa trên thống kê Trong ngôn ngữ tự nhiên, nhất là loại ngôn ngữ phụ thuộc nhiều vào ngữ cảnh như tiếng Việt, đối với con người, chúng ta có thể dễ dàng xác định được ranh giới từ trong câu"],[701,"Tuy nhiên, do chưa có một quy định cụ thể nào về ranh giới từ tiếng Việt, nên có thể nhiều người Việt có nhiều cách tách từ khác nhau"],[702,"Đối với người chúng ta vẫn chưa thống nhất được, nên khi dùng máy tính để xử lý ngôn ngữ ta vẫn chưa có một chuẩn nào để xác định đâu là ranh giới từ"],[703,"Vì vậy, đã có rất nhiều công"],[704,"44 trình nghiên cứu cách tính toán độ liên quan giữa các từ để khắc phục các công việc phức tạp do cách phân tích cấu trúc ngữ pháp trong câu đem lại"],[705,"Trong phần này, chúng em sẽ trình bày hai nội dung chính: Hai thước đo chuẩn dùng để tính toán độ liên quan giữa hai từ trong tiếng Anh là thông tin tương hỗ (Mutual Information ) và t-score"],[706,"Một số ứng dụng và cải tiến của hai công cụ đo trên trong việc tách từ tiếng Hoa và tiếng Việt"],[707,"4.3.1"],[708,"Thông tin tương hỗ (Mutual Information) và t-score dùng trong tiếng Anh Thông tin tương hỗ (Mutual Information) và t-score là hai khái niệm rất quan trọng trong học thuyết về thông tin (Information Theory) và thống kê được trình bày trong [Church et al, 1991] cho mục đích tính toán mức độ liên quan của hai từ trong tiếng Anh"],[709,"4.3.1.1"],[710,"Thông tin tương hỗ MI (Mutual Information) \u2013 thước đo đặc điểm tương tự (A Measure of Similarity) Theo Church et al (1991), việc thống kê thông tin tương hỗ (Mutual Information) dùng để nhận biết các trường hợp ngôn ngữ thú vị, bao gồm từ mối quan hệ ngữ nghĩa (semantic relations) như bác sĩ/y tá (dạng content word/content word) cho đến mối quan hệ từ vựng-cú pháp (lexico-syntactic) như sự xuất hiện đồng thời giữa động từ và giới từ (dạng content word/ funtion word)"],[711,"MI có nhiệm vụ so sánh xác suất xuất hiện đồng thời (joint probability) của từ x và từ y so với xác suất tìm thấy x và y xuất hiện độc lập"],[712,"Công thức tính MI cho hai từ tiếng Anh trong [Church et al, 1991] như sau: 2 ( , )( ; ) log ( ) ( ) P x yI x y P x P y ≡"],[713,"45 Trong đó: x và y là hai từ tiếng Anh cần kiểm tra mức độ kết hợp lẫn nhau"],[714,"I(x;y) là thông tin tương hỗ của hai từ"],[715,"P(x), P(y) là xác suất xuất hiện độc lập của x và của y"],[716,"P(x,y) là xác suất xuất hiện đồng thời x và y"],[717,"Theo Church et al (1991), giá trị I(x,y) càng lớn thì khả năng kết hợp của x và y càng cao"],[718,"4.3.1.2"],[719,"t-score \u2013 thước đo sự khác biệt (A Measure of Dissimilarity) Chúng ta dễ dàng nhận ra sự giống nhau giữa strong và powerful, tuy nhiên làm cách nào để phân biệt sự khác nhau giữa chúng"],[720,"Ví dụ, chúng ta đều biết rằng người ta thường nói strong tea, powerful car hơn là nói powerful tea và strong car"],[721,"Nhưng làm sao cho máy tính nhận ra được sự khác biệt này"],[722,"Giả sử , ta biết rằng strong support được dùng phổ biến hơn là powerful support, Church et al (1991) đã đưa ra công thức tính t-score để đo sự khác biệt trên: 1 2 2 2 1 2 ( | ) - ( | ) ( ( | ) ( | )) P w w P w wt P w w w wσ σ = − + Trong đó: w1,w2 là hai từ tương tự nhau cần phải phân biệt (ở ví dụ trên là strong và powerful)"],[723,"w là từ dùng để phân biệt (ở ví dụ trên là support)"],[724,"P(w|w1), P(w|w2) là xác suất của từ w xuất hiện đi kèm với từ w1, w2 Lúc đó: 2 2 2 2 ( ) - ( ) ( ( )) ( ( )) ( ) f ( ) - ( ) ( ) 2 175 13 2 175 P powerful support P strong supportt P powerful support P strong support f powerful support strong support N N f powerful support f strong support N N σ σ = − + ≈ − + − ≈ − ≈ − +"],[725,"46 Ta nói rằng powerful support có độ lệch chuẩn (standard deviation) kém strong support 13 lần"],[726,"Nhờ vậy, ta có thể phân biệt được sự khác nhau giữa powerful và strong trong việc sử dụng hai từ này"],[727,"4.3.2"],[728,"Một số cải tiến trong cách tính độ liên quan ứng dụng trong tách từ tiếng Hoa và tiếng Việt 4.3.2.1"],[729,"Thông tin tương hỗ (Mutual Information) Khi áp dụng thông tin tương hỗ MI trong tách từ tiếng Hoa, Su et al (1993) cho rằng thông tin tương hỗ (Mutual Information) là thước đo mức độ kết hợp của một từ"],[730,"Nó có nhiệm vụ so sánh xác suất một nhóm các ký tự (tương tự như \u201ctiếng\u201d trong tiếng Việt \u2013 xem giải thích ở mục 3.2.3.) xuất hiện đồng thời (joint probability) so với xác suất tìm thấy từng ký tự xuất hiện độc lập"],[731,"Theo Su et al (1993) cách tính MI cho từ có 2 ký tự có thể áp dụng công thức của Church et al (1991) với ý nghĩa của x và y lúc này không còn là \u201ctừ\u201d (word) như trong tiếng Anh mà được hiểu là tiếng (xem giải thích ở mục 3.2.3.) trong tiếng Hoa"],[732,"2 ( , )( ; ) log ( ) ( ) P x yI x y P x P y ≡ (1a) Trong đó: x và y là hai tiếng cần kiểm tra mức độ kết hợp lẫn nhau trong tiếng Hoa"],[733,"I(x;y) là thông tin tương hỗ của hai tiếng"],[734,"P(x), P(y) là xác suất xuất hiện độc lập của tiếng x và của tiếng y"],[735,"P(x,y) là xác suất xuất hiện đồng thời tiếng x và tiếng y"],[736,"Cách tính MI dành cho từ ghép 3 tiếng như sau [Su et al, 1991]: 2 ( , , )( ; ; ) log ( , , ) D I P x y zI x y z P x y z ≡ (1b) Trong đó: PD(x,y,z) ≡ P(x,y,z) là xác suất xuất hiện đồng thời của x, y và x, (Dependently)"],[737,"47 PI(x,y,z) là xác suất xuất hiện độc lập của x,y, z (Independently) với PI(x,y,z) ≡ P(x)P(y)P(z) + P(x)P(y,z) + P(x,y)P(z)"],[738,"Nhìn chung I(.) >>0 sẽ cho biết từ ghép đó có mức độ liên quan giữa các tiếng là rất chặt chẽ"],[739,"Ngược lại, các tiếng có xu hướng xuất hiện một cách độc lập"],[740,"Một cách tính MI khác cũng được Ong & Chen (1999) đề nghị như sau: 1 2 1 2 ( & & .."],[741,"& ) ( ) = ( ) ( ) ( & & .."],[742,"& ) n n p w w wMI cw p lw p rw p w w w+ − (2) Trong đó cw = p( w1 & w2 ...& wn-1 ) lw = p( w1 & w2 ...& wn-1 ) rw = p ( w2 & w3 ...& wn) Theo nghiên cứu của chúng em, hiện nay công trình nghiên cứu về cách tách từ dựa trên độ tương hỗ MI trên tiếng Việt chưa nhiều"],[743,"Ở đây, chúng em xin giới thiệu cách tính MI được đề nghị trong IGATEC trong [H"],[744,"Nguyen et al, 2005] 1 2 1 2 1 ( & & .."],[745,"& ) ( ) = ( ) - ( & & .."],[746,"& ) n n j n j p w w wMI cw p w p w w w = ∑ (3) Nhìn vào các công thức tính MI, ta có thể dự đoán được mỗi công thức ưu tiên cho một loại từ khác nhau"],[747,"Phần tiếp theo sau đây sẽ trình bày một số nhận xét về các công thức trên để làm cơ sở đưa ra lựa chọn phù hợp nhất"],[748,"4.3.2.2"],[749,"Cách tính tần số tương đối (Relative Frequency Count) Cách tính tần số tương đối cho từ ghép có i tiếng được định nghĩa như sau [Su et al, 1993]: i i fr K = Trong đó, fi là số lần xuất hiện của từ ghép có i tiếng (ith n-gram) trong tập ngữ liệu, và K là số lần xuất hiện trung bình của một từ"],[750,"Nói một cách khác, fi được bình thường hoá bằng cách chia cho K để lấy tỉ lệ liên quan"],[751,"Một cách trực quan, ta sẽ"],[752,"48 nhận ra, cách tính RFC sẽ ưu tiên cho những từ xuất hiện với tần số rất cao mà nó sẽ bỏ mất những xuất hiện trong từ điển với tần số thấp"],[753,"Vì vậy, RFC được dùng như một thuộc tính hỗ trợ thêm cho việc tách từ"],[754,"4.3.2.3"],[755,"Nhận xét về cách sử dụng MI và RFC Nếu ta sử dụng đồng thời MI và RFC cho việc tách từ sẽ đem lại kết quả như mong đợi bởi vì nếu chỉ sử dụng một công cụ tính toán, kết quả chúng ta đạt được có thể chỉ ưu tiên cho một cách tách nào đó"],[756,"Nếu chỉ sử dụng RFC, hệ thống của chúng ta có xu hướng chọn những từ xuất hiện nhiều lần nhưng lại có độ liên quan MI thấp"],[757,"Ví dụ, nếu P(x) và P(y) rất lớn, nó có thể tạo ra P(x,y) cũng rất lớn mặc dù x và y không hề liên quan gì cả vì P(x,y)/ P(x) x P(y) rất nhỏ"],[758,"Mặc khác, nếu chỉ sử dụng MI thôi, thì ở trường hợp P(x) và P(y) quá nhỏ sẽ dẫn đến kết quả không đáng tin cậy"],[759,"Một từ n-gram có thể có MI cao không bởi vì chúng kết hợp chặt chẽ với nhau mà bởi vì khi chia hai số cùng nhỏ như nhau, ta sẽ có số MI lớn"],[760,"Tóm lại, ta nên sử dụng cả hai thông tin MI và RFC vì thực tế, một nhóm các từ vừa có RFC và MI cao sẽ có xu hướng vừa kết hợp chặt chẽ với nhau, vừa được sử dụng rộng rãi"],[761,"4.3.3"],[762,"Nhận xét về các cách tính độ liên quan khi áp dụng cho tiếng Việt Tiếng Hoa là loại ngôn ngữ đơn lập giống tiếng Việt, nên ta có thể áp dụng một số công tình nghiên cứu trên tiếng Hoa lên tiếng Việt"],[763,"Về mặt lý thuyết, ta hoàn toàn có thể sử dụng các công thức MI trên để áp dụng cho tiếng Việt, và quan thực nghiệm, chúng ta sẽ đề xuất thêm một số cải tiến để công thức tính MI phù hợp với việc tách tiếng Việt hơn nữa"],[764,"Đối với công thức RFC, ta cần phân biệt khái niệm f trong công thức là tần số xuất hiện của từ trong tập ngữ liệu, K là số lần xuất hiện trung bình của một từ (real word) trong tập ngữ liệu"],[765,"Khi sử dụng tập ngữ liệu, các số f và K là hoàn toàn tính được"],[766,"Tuy nhiên, phương pháp IGATEC mà chúng em sử dụng lại lấy kết quả số lượng trang web p chứa từ cần tìm nên chúng ta không thể tính được số K ( vì không thể dựa vào số lượng trang web trả về"],[767,"49 mà quyết định đó là từ hay không)"],[768,"Do vậy, hiện tại, chúng em vẫn chưa áp dụng cách tính RFC trên tiếng Việt"],[769,"Bản chất của phương pháp tính t-score là tìm sự khác nhau trong việc sử dụng từ trong tiếng Anh, chúng em nhận thấy chưa thật sự cần thiết trong việc tách từ làm tăng tính phức tạp của việc tính toán"],[770,"Do đó, chứng em chưa áp dụng t-score vào tách từ"],[771,"4.4"],[772,"Tiền xử lý (Pre-processing) Bởi vì các bài báo điện tử được trình bày dưới dạng html, nên trước khi thực hiện tách từ để phân loại, chúng em phải xử lý văn bản để lấy ra những nội dung quan tâm"],[773,"4.4.1"],[774,"Xử lý văn bản đầu vào Nội dung tóm tắt của bài báo là rất quan trọng vì nó thể hiện nội dung bài báo một cách cô đọng, súc tích, rõ ràng, giúp người xem dự đoán được đề tài của bài báo muốn đề cập đến"],[775,"Chính vì lý do đó, chúng em quyết định thực hiện việc phân loại tin tức dựa trên phần tóm tắt của bài báo để tiết kiệm thời gian xử lý và đạt được kết quả chính xác cao"],[776,"Trong mỗi văn bản, khối tiền xử lý sẽ nhận diện tiêu đề, tóm tắt\u2026 của bài báo bằng cách dựa vào thông tin định dang của các thẻ trong trang html"],[777,"Theo khảo sát của chúng em về cấu trúc hiển thị nội dung trang báo điện tử ở các trang web tin tức ở Việt Nam, tác giả luôn trình bày nội dung tóm tắt (abstract) của bài báo trước bài viết chi tiết, nên hướng phân loại dựa trên tóm tắt của bài báo là khả thi"],[778,""],[779,"50 Hình 4"],[780,"1"],[781,"Nội dung thông tin cần lấy Sau khi rút trích được nội dung cần thiết, chúng em tiếp tục thực hiện tách ngữ, phục vụ cho công việc tách từ"],[782,"4.4.2"],[783,"Tách ngữ & tách stopwords Tách ngữ: Ứng với mỗi văn bản đã rút trích từ trang web, chúng em tiến hành loại bỏ các ký hiệu, các chữ số không cần thiết, sau đó, phân tích văn bản thành các ngữ phân cách bởi dấu câu"],[784,"Tách stopword: Nhằm làm tăng tốc độ tính toán của GA và lượt bớt các từ không có nghĩa phân loại trong câu, chúng em có thử nghiệm tách stopword trước khi tiến hành tách từ"],[785,"Bước tách stopword tỏ ra khá hiệu quả trong việc làm tăng tốc độ GA nhờ chia nhỏ các ngữ ra thành những ngữ nhỏ hơn"],[786,"Tuy nhiên, cách tách stopword không phải lúc nào cũng cho kết quả như mong đợi bởi vì tách stopword trước khi tách từ sẽ có nhiều khả năng làm sai lạc ý nghĩa của câu, ảnh hưởng đến việc phân loại sau đó"],[787,"Do đó, chúng em đã thử nghiệm việc tách stopword sau khi"],[788,"51 đã tách từ, kết quả phân loại sau khi đã loại bỏ stopword là khả quan hơn cách thực hiện ban đầu"],[789,"(Xin xem chương 6 để biết kết quả thực nghiệm.) 4.5"],[790,"Hướng tiếp cận tách từ dựa trên thống kê từ Internet và thuật toán di truyền (Internet and Genetic Algorithm-based ) Chúng em xây dựng hai công cụ hỗ trợ cho việc tách từ gồm: công cụ trích xuất thông tin từ Google và công cụ tách từ dùng thuật toán di truyền"],[791,"4.5.1"],[792,"Công cụ trích xuất thông tin từ Google 4.5.1.1"],[793,"Mục đích Ngày nay, cùng với sự phát triển nhanh chóng của các công nghệ thông tin hiện đại, Internet đã trở thành một thư viện tuyệt vời với một khối lượng văn bản đồ sộ"],[794,"Do đó, việc khai thác thông tin từ world-wide-web như một tập ngữ liệu khổng lồ cho các công trình nghiên cứu sẽ rút ngắn được thời gian và công sức tự xây dựng một tập ngữ liệu riêng"],[795,"Với sự giúp sức của công cụ tìm kiếm miễn phí trên mạng, những thông tin cần thiết sẽ được lấy về một cách nhanh chóng và chính xác"],[796,"Chúng em chọn Google là công cụ tìm kiếm chính bởi vì những ưu thế về tính nhanh chóng, chính xác, và phổ biến của nó so với các công cụ tìm kiếm khác"],[797,"Trong luận văn này, chúng em cần hai loại thông tin: Tần số xuất hiện của các văn bản chứa các từ (document frequency) trên các trang web để làm tính công thức MI, dự đoán khả năng tồn tại của một từ là đúng hay không Tần số các văn bản chứa từ với từ khóa đại diện cho chủ đề dùng để tính mức độ liên quan của từ với các chủ đề cần phân loại"],[798,"Do vây, nhiệm vụ của công cụ trích xuất thông tin từ Google sẽ lấy kết quả tìm kiếm của Google, trả về cho chương trình khi chúng ta đưa yêu cầu tìm kiếm"],[799,""],[800,"52 4.5.1.2"],[801,"Các công thức tính xác suất và độ tương hỗ 4.5.1.2.1"],[802,"Các công thức tính xác suất Khi nhận được kết quả trả về, dựa vào nền tảng của các công trình nghiên cứu về thống kê trên Internet của Rudi & Paul (2005), chúng em sẽ sử dụng các công thức sau đây để tính toán chỉ số MI"],[803,"Các công thức tính xác suất các từ xuất hiện trên Internet : Gọi count(w) là số lượng trang web chứa từ w count(w1 & w2) là số trang web chứa đồng thời w1 và w2 ( )(w)= count wp MAX 1 21 2 ( & )( & ) count w wp w w MAX = Trong đó, MAX = 4 * 109; 4.5.1.2.2"],[804,"Các công thức tính độ tương hỗ (Mutual Information \u2013 MI) Đối với hướng tiếp cận N-Gram để tách từ, công thức MI để tính toán khả năng tồn tại một ngữ cần tách trong câu là rất quan trọng"],[805,"Độ tương hỗ (Mutual Information) cho biết thông tin phụ thuộc lẫn nhau của các từ ghép được cấu tạo bởi n tiếng (cw = w1 w2 \u2026 wn)"],[806,"Đối với từ một tiếng, ta quy ước MI = p(w)"],[807,"Đối với từ ghép từ 2 tiếng trở lên, chúng em thử nghiệm 3 cách tính MI để tìm ra các tính hiệu quả nhất"],[808,"MI theo cách tính của IGATEC [H"],[809,"Nguyen et al, 2005] ) (đã được trình bày ở mục 4.3.2.1.) 1 2 1 2 1 ( & & .."],[810,"& ) ( ) = ( ) - ( & & .."],[811,"& ) n n j n j p w w wMI cw p w p w w w = ∑ (2) MI theo cách tính của [Ong & Chen, 1999] (đã được trình bày ở mục 4.3.2.1.) Giả sử ta có cw = p( w1 & w2 ...& wn-1 ) lw = p( w1 & w2 ...& wn-1 )"],[812,"53 rw = p ( w2 & w3 ...& wn) 1 2 1 2 ( & & .."],[813,"& ) ( ) = ( ) ( ) ( & & .."],[814,"& ) n n p w w wMI cw p lw p rw p w w w+ − (3) MI do chúng em đề nghị: Giả sử ta có cw = p( w1 & w2 ...& wn-1 ) Với n chẵn : lw = p( w1 & w2 ...& wn/2 ), rw = p ( wn/2+1 & wn/2+2 ...& wn) Với n lẻ: lw = p( w1 & w2 ...& wn-1 ) , rw = p ( w2 & w3 ...& wn) 1 2 1 2 ( & & .."],[815,"& ) ( ) = ( ) ( ) ( & & .."],[816,"& ) n n p w w wMI cw p lw p rw p w w w+ − (4) Chúng ta sẽ sử dụng các công thức trên để tính độ thích nghi của các cá thể trong thuật toán di truyền dưới đây"],[817,"Kết quả của mỗi công thức tính MI sẽ ưu tiên cho những loại từ ghép khác nhau mà ta sẽ hiểu rõ hơn trong kết quả thực nghiệm ở chương 6"],[818,"4.5.2"],[819,"Công cụ tách từ dùng thuật toán di truyền (Genetic Algorithm \u2013 GA) Mục đích của chúng ta là tìm ra các cách tách từ hợp lý nhất cho văn bản, tuy nhiên, chúng ta gặp phải trở ngại là không gian tìm kiếm (search space) quá lớn do sự bùng nổ tổ hợp khi sinh ra dãy các từ"],[820,"Như chúng ta đều biết, thuật toán di truyền (Genetic Algorithm \u2013 GA) được biết đến với khả năng duyệt tắt qua những không gian tìm kiếm lớn một cách hiệu quả và đưa ra những giải pháp toàn cục tối ưu nhất"],[821,"GA thực hiện tiến hoá một số thế hệ để tạo ra một quần thể gồm những cá thể tối ưu nhờ vào các bước lai ghép (cross-over), đột biến (mutation), sinh sản (reproduction), và cách chọn lựa cá thể"],[822,"Chất lượng của mỗi cá thể được tính toán dựa trên chỉ số fitness cho mỗi cá thể và quần thể"],[823,"Trong quá trình thử nghiệm, chúng em chọn top N cá thể chất lượng nhất sau khi thực hiện các bước lai ghép, đột biến, sinh sản"],[824,"4.5.2.1"],[825,"Khảo sát độ dài của \u201ctừ\u201d trên từ điển"],[826,"54 Như chúng ta đều biết, thuật toán di truyền đòi hỏi phải có rất nhiều tham số cho các bước thực hiện như số cá thể trong quần thể, số thế hệ tiến hoá, tỉ lệ lai ghép, tỉ lệ đột biến\u2026 Do vậy, chất lượng lựa chọn các tham số trên sẽ quyết định kết quả của thuật toán di truyền"],[827,"Chính vì tính chất quan trọng của các tham số, chúng em thực hiện một khảo sát nhỏ về số lượng từ tương ứng với chiều dài từ trên từ điển thông dụng tại http://dict.vietfun.com để làm cơ sở cho các tham số sau này"],[828,"Độ dài từ (tiếng) Tần số xuất hiện Tỉ lệ 1 8933 12.2 2 48995 67.1 3 5727 7.9 4 7040 9.7 ≥ 5 2301 3.1 Tổng cộng 72994 100 Bảng 4"],[829,"1"],[830,"Thống kê độ dài từ trong từ điển Có một điều cần lưu ý là tại thời điểm này, chúng ta vẫn chưa có một từ điển chuẩn nào được dùng cho việc xử lý ngôn ngữ, do đó, chúng em quyết định dùng loại từ điển phổ dụng để thống kê"],[831,"Theo kết quả thống kê, trên 67% là từ ghép hai tiếng, còn lại khoảng 30% là các từ ghép một, ba, bốn tiếng"],[832,"Các cụm từ dài hơn bốn tiếng chiếm khoảng 3%, tuy nhiên các cụm từ đó đa số là các câu thành ngữ của Việt Nam"],[833,"Kết quả thống kê trên có ý nghĩa rất quan trọng đối với công cụ tách từ bằng GA của chúng em"],[834,"Dựa trên tỉ lệ của các loại từ, chúng em thực hiện việc khởi tạo cá thể ngẫu nhiên có thêm thông tin về xác suất xuất hiện của từ và đó là cơ sở để chúng em quyết định cách tách từ phù hợp với thực tế của tiếng Việt"],[835,"Chi tiết về các ứng dụng của kết quả khảo sát sẽ được chúng em trình bày ở các phần sau"],[836,"4.5.2.2"],[837,"Khởi tạo quần thể"],[838,"55 4.5.2.2.1"],[839,"Biểu diễn cá thể Giả sử văn bản đầu vào t được tạo thành bởi n tiếng (syllables) như sau: t=s1s2...sn"],[840,"Mục đích của quá trình chạy GA là tìm ra cách tách từ có độ chấp nhận cao nhất : t=w1w2\u2026wm , với wk= si\u2026 sj (1 ≤ k ≤ m, 1 ≤ i,j ≤ n) Tương tự như IGATEC, chúng em cũng biểu diễn mỗi cá thể (id) trong quần thể (pop) bởi chuỗi các bit 0,1, trong đó, mỗi bit đại diện cho một tiếng trong văn bản, mỗi nhóm bit cùng loại đại diện cho một từ (word)"],[841,"Ví dụ: Với câu \u201cNhững || con || khủng long || trong || phim hoạt hình || rất || ngộ nghĩnh\u201d, chúng em sẽ biểu diễn dưới dạng các bit 0, 1 như sau: Hình 4"],[842,"2"],[843,"Biểu diễn cá thể bằng các bit 0,1 4.5.2.2.2"],[844,"Khởi tạo các tham số Ở bước khởi tạo tham số, ta phải thiết lập một vài tham số cơ bản cho GA như số thế hệ tiến hoá (generations), kích thước quần thể (population size), tỉ lệ lai ghép (reproduction fraction)\u2026 Ngoài ra, vì mỗi cá thể của chúng ta là một thể hiện cách tách từ trong câu, nên ta sẽ lợi dụng tính chất liên kết của các từ để thực hiện khởi tạo cá thể ngẫu nhiên ban đầu"],[845,"Tính chất liên kết của từ được thể hiện qua tỉ lệ của các từ trong từ điển, nên ta sẽ có thêm tham số về khả năng xuất hiện từ trong câu ở bảng tham số dưới đây"],[846,""],[847,"56 Tham số Giá trị Số thế hệ tiến hoá 100 Kích thước quần thể 50 Tỉ lệ lai ghép 95% Tỉ lệ đột biến 5% Top N cá thể được chọn 100 Tỉ lệ từ 1 tiếng (mono-gram) 10% Tỉ lệ từ 2 tiếng (bigram) 70% Tỉ lệ từ 3 tiếng (trigram) 10% Tỉ lệ từ 4 tiếng (quadgram) 10% Bảng 4"],[848,"2"],[849,"Tham số thực hiện GA 4.5.2.2.3"],[850,"Khởi tạo cá thể Như chúng ta đều biết, quy tắc của thuật toán di truyền là thực hiện tiến hoá các cá thể qua các thế hệ nhằm đạt đến độ hội tụ của chỉ số thích nghi (sẽ được nói rõ ở mục 4.5.2.3)"],[851,"Nếu cá thể được khởi tạo ngẫu nhiên sẽ có độ thích nghi thấp, chúng ta phải tiến hoá qua rất nhiều thế hệ để đạt đến độ hội tụ cần thiết"],[852,"Và hậu quả là số thế hệ tiến hoá càng nhiều thì thời gian tiêu tốn và chi phí tính toán càng cao"],[853,"Giải pháp khắc phục nhược điểm trên là khởi tạo một số cá thể ban đầu gần với điểm hội tụ, nhờ vậy có thể rút ngắn được số thế hệ tiến hoá, tăng tốc độ"],[854,"Ở bước khởi tạo quần thể, chúng em tạo ra cá các thể bằng hai cách: khởi tạo ngẫu nhiên và khởi tạo dựa trên phương pháp MM:forward/backward [Chih-Hao Tsai, 2000]"],[855,"4.5.2.2.3.1"],[856,"Khởi tạo cá thể ngẫu nhiên Theo thống kê ở bảng 4.1, chúng em quyết định đặt ra một số giới hạn cho việc tạo cá thể ngẫu nhiên"],[857,"Đầu tiên, tất cả các từ ghép wk tạo ra có độ dài không quá 4"],[858,""],[859,"57 Thứ hai, chúng em khởi tạo ngẫu nhiên các cá thể có số lượng từ tương ứng với tỉ lệ về độ dài từ ở trên, nhằm tạo ra điểm xuất phát tốt cho quá trình thực hiện GA"],[860,"Ví dụ: Giả sử ta có câu đầu vào \u201cNhững con khủng long trong phim hoạt hình rất đáng yêu\u201d gồm 11 tiếng"],[861,"Theo các tham số khởi tạo của bảng 4.2., chúng em thiết lập giới hạn tạo từ ngẫu nhiên trong câu: Hình 4"],[862,"3"],[863,"Thang tỉ lệ phát sinh loại từ Một bộ phát sinh ngẫu nhiên sẽ phát sinh xác suất f (0 ≤ f ≤ 1) để chọn loại từ: Nếu 0 ≤ f < 0.1 : phát sinh loại từ 1 tiếng Nếu 0.1 ≤ f < 0.8 : phát sinh loại từ 2 tiếng Nếu 0.8 ≤ f < 0.9 : phát sinh loại từ 3 tiếng Nếu 0.9 ≤ f ≤ 1: phát sinh loại từ 4 tiếng 4.5.2.2.3.2"],[864,"Khởi tạo cá thể bằng Maximum Matching : forward/backward (Phương pháp Maximum Matching : forward/backward [Chih-Hao Tsai, 2000] đã được trình bày ở mục 3.2.1.) Đây là bước khởi tạo rất quan trọng và điểm cải tiến đáng kể so với IGATEC"],[865,"Chúng em chọn phương pháp MM: forward/backward để khởi tạo cá thể ban đầu vì độ chính xác khá cao của phương pháp này sẽ tạo ra cá các thể gần đúng nhất, giúp tăng tốc quá trình tiến hoá"],[866,"Ngoài ra, việc áp dụng phương pháp MM theo dạng đơn giản chỉ cần duyệt tuyến tính, sẽ giảm thiểu được chi phí và thời gian tính toán so với các phương pháp khác"],[867,"Chúng em thực hiện tách từ theo hai hướng từ trái sang phải, và từ phải sang trái"],[868,"Nếu hai cách tách từ trên trùng nhau, chúng em sẽ chọn một và gộp vào các cá thể đã được phát sinh ngẫu nhiên ở trên"],[869,""],[870,"58 Sau khi khởi tạo xong, quần thể sẽ được tiến hóa qua các quá trình lai ghép, đột biến, sinh sản, 4.5.2.3"],[871,"Thực hiện tiến hoá 4.5.2.3.1"],[872,"Quá trình lai ghép (cross-over) Chúng em áp dụng phương pháp chuẩn của lai ghép là dựa trên một điểm ngẫu nhiên trong chuỗi bit của cá thể"],[873,"Khi có một cặp cá thể bố mẹ , thế hệ con được tạo ra dựa trên sự kết hợp từ phần đầu tiên của bố với phần cuối của mẹ và ngược lại"],[874,"Tuy nhiên, trong quá trình lai ghép, chúng em nhận thấy giới hạn từ ghép tối đa 4 tiếng có thể bị phá vỡ, do đó, đối với những phân đoạn wk nào có độ dài hơn chúng em sẽ thực hiện việc chuẩn hóa từ vị trí đó đến cuối sao cho không có một từ nào vượt quá 4 tiếng"],[875,"Ví dụ: Hình 4"],[876,"4.Quá trình lai ghép 4.5.2.3.2"],[877,"Quá trình đột biến (mutation) Thay vì thực hiện phương pháp bật tắt bit (bit flip), chúng em thực hiện việc hoán chuyển vị trí của hai bit liền nhau tại một vị trí ngẫn nhiên"],[878,"Ý tưởng thực hiện"],[879,"59 đột biến như thế này bởi vì, trong việc phân định ranh giới từ, ta dễ dàng nhận ra rằng một tiếng nếu kết hợp với tiếng trước không phù hợp thì có thể kết hợp với từ đứng sau sẽ phù hợp hơn, hoặc là đứng một mình"],[880,"Tương tự như phần lai ghép, chúng em thực hiện chuẩn hoá các cá thể sau khi đột biến"],[881,"Ví dụ: Hình 4"],[882,"5"],[883,"Quá trình đột biến 4.5.2.3.3"],[884,"Quá trình sinh sản (reproduction) Sau khi lai ghép và đột biến, chúng em kết hợp các cá thể bố mẹ với cá thể con vừa được tạo ra để phục vụ cho bước chọn cá thể"],[885,"Sau khi kết hợp, chúng em lọc bỏ các cá thể trong quần thể, để đạt được nhiều cách tách từ tốt"],[886,"Ví dụ: Hình 4"],[887,"6"],[888,"Quá trình sinh sản"],[889,"60 4.5.2.3.4"],[890,"Quá trình chọn cá thể (selection) Ở mỗi thế hệ, chúng em chỉ chọn top N cá thể từ quá trình sinh sản ở trên"],[891,"Trước tiên, các cá thể sẽ được tính độ thích nghi (fitness) chính là tổng giá trị MI của các từ được tách trong câu"],[892,"Sau đó, quần thể sẽ được sắp xếp theo giá trị của độ thích nghi giảm dần, quá trình chọn lọc cá thể sẽ chọn top N cá thể có độ thích nghi cao nhất để tạo nên quần thể tiếp tục tiến hoá ở các thế hệ sau"],[893,"Cách thức lựa chọn cá thể như sau: 1 2 m k 1 ( ) (w w ...w ) (w ) m k fit id fit MI = = =∑ 1 ( ) ( ) N i i fit pop fit id = =∑ Trong đó, id = w1w1.."],[894,"w1 là một cá thể trong quần thể pop = {id1, id2} Ví dụ: Hình 4"],[895,"7"],[896,"Quá trình chọn cá thể Có thể nói đây là quá trình quan trọng nhất trong cả tiến trình tiến hoá vì sự lựa chọn cá thể ở bước này sẽ quyết định cá thể tiến hoá có tốt hay không"],[897,"Ở quá trình chọn lọc cá thể này, chúng em đã thử nghiệm một số công thức tính độ tương hỗ (Mutual Information) như đã trình bày ở trên, và thu được các kết quả khác nhau khi sử dụng các công thức khác nhau"],[898,"Từ đó, chúng em rút ra một số kết luận và nhận xét quan trọng về ưu khuyết điểm của các công thức MI"],[899,"Kết quả thực nghiệm và nhận xét về các công thức MI sẽ được chúng em trình bày ở chương 6"],[900,""],[901,"61 4.5.2.3.5"],[902,"Độ hội tụ (convergence) Quá trình thực hiện GA cố gắng làm tăng độ thích nghi (fitness) của mỗi cá thể cũng đồng nghĩa với việc tăng chất lượng của từ được tách"],[903,"Ở mỗi thế hệ tiến hoá, chỉ số thích nghi của quần thể sẽ tăng dần đến một ngưỡng gọi là độ hội tụ α"],[904,"Khi đó, độ chênh lệnh chỉ số thích nghi của quần thể giữa hai thế hệ sẽ nhỏ dần và tiến dần đến 0"],[905,"Vì vậy, chúng em thực hiện việc ngừng GA một cách tự động khi giá trị fitness của các thế hệ đạt đến độ hội tụ có chỉ số α = 10-7 hoặc số thế hệ đạt đến số lượng mặc định đã trình bày ở trên"],[906,"Việc ngừng GA tự động sẽ giúp chúng ta giảm thiểu thời gian và chi phí tính toán không cần thiết, đồng thời là tăng tốc độ của việc tách từ"],[907,"4.6"],[908,"Kết luận Phương pháp tách từ dựa trên thống kê Internet và thuật toán di truyền tương đối đơn giản hơn các phương pháp khác và tỏ ra khá linh hoạt với sự biến động của ngôn ngữ trong tin tức điện tử"],[909,"Ngoài ra, đây là hướng tiếp cận khá mới mẻ, hạn chế được khuyết điểm cơ bản của các phương pháp tách từ lâu nay là dựa trên tập ngữ liệu đã đánh dấu và từ điển chuyên biệt"],[910,"Với ưu điểm là thuật toán đơn giản, dễ hiểu, dễ cài đặt, nhưng phương pháp IGATEC vẫn cho một kết quả tách từ chấp nhận được, có thể dùng trong phân loại văn bản"],[911,""],[912,"62 CChhưươơnngg 55 BBÀÀII TTOOÁÁNN PPHHÂÂNN LLOOẠẠII TTIINN TTỨỨCC ĐĐIIỆỆNN TTỬỬ Lý do chọn phương pháp Naïve Bayes Thuật toán Naïve Bayes Công thức xác suất đầy đủ Bayes Tính độc lập có điều kiện (Conditional Independence) Nguồn gốc Naïve Bayes Naïve Bayes trong phân loại văn bản Hai mô hình sự kiện trong phân loại văn bản bằng Naïve Bayes Bài toán phân loại tin tức điện tử tiếng Việt Kết quả"],[913,"63 Chương 5"],[914,"BÀI TOÁN PHÂN LOẠI TIN TỨC ĐIỆN TỬ Nhằm tận dụng phương pháp tách từ IGATEC đã được đề cập ở chương trên, trong chương này chúng em sẽ giới thiệu cách phân loại tin tức điện tử tự động sử dụng phương pháp Naïve Bayes và giải thích sự phù hợp của Naïve Bayes với phương pháp tách từ IGATEC"],[915,"5.1"],[916,"Lý do chọn phương pháp Naïve Bayes Như đã được giới thiệu trong chương 2, Naïve Bayes là một phương pháp rất phổ biến sử dụng xác suất có điều kiện giữa từ và chủ đề để xác định chủ đề của văn bản"],[917,"Các xác suất này dựa trên việc thống kê sự xuất hiện của từ và chủ đề trong tập huấn luyện"],[918,"Tập huấn luyện lớn có thể mang lại kết quả khả quan cho Naïve Bayes"],[919,"Internet với hơn 10 tỷ trang web là một tập huấn luyện rất phong phú về mọi chủ đề trong cuộc sống"],[920,"Hơn nữa, với số lượng chủ đề tin tức điện tử không nhiều (khoảng 20 chủ đề) thì việc sử dụng Internet như cơ sở dữ liệu huấn luyện rất phù hợp"],[921,"Trong báo chí, với mỗi chủ đề luôn có các từ chuyên môn với tần số xuất hiện rất cao, việc tận dụng tần số phụ thuộc của các từ này vào chủ đề có thể đem lại kết quả khả quan cho phân loại"],[922,"Với dữ liệu được tạo ra nhờ công cụ tách từ GA và trích xuất thông tin từ Google, theo đánh giá của chúng em, thì phương pháp Naïve Bayes là khá phù hợp vì các dữ liệu đầu vào cho hướng phân loại này hoàn toàn phù hợp với dữ liệu hiện có"],[923,"Điều này sẽ giúp chúng em tiết kiệm được rất nhiều thời gian và công sức tạo thêm nhiều tập dữ liệu nếu chọn phương pháp phân loại khác"],[924,"Mặt khác, phương pháp Naïve Bayes là phương pháp khá cổ điển được sử dụng đầu tiên bởi Maron vào năm 1961 [Maron, 1961], và sau đó rất phổ biến trong các lãnh vực tìm kiếm, lọc mail, các bộ lọc mail\u2026 nên chúng ta có thể tin tưởng về xác suất chính xác và các ưu khuyết điểm của phương pháp này để áp dụng phù hợp"],[925,"Một lý do nữa mà chúng em chọn Naïve Bayes bởi phương pháp đơn giản, tốc độ nhanh, cài đặt tương đối không quá phức tạp phù hợp với thời gian cho phép của luận văn"],[926,"Chúng em không sử dụng kNN, do tập dữ liệu thử nghiệm hiện có là tập"],[927,"64 các tin tức vắn tắt lấy ngẫu nhiên từ trang VnExpress.net còn khá nhỏ (dưới 1000)"],[928,"Trong khi đó để có thể sử dụng phương pháp kNN hiệu quả số lượng chủ đề và dữ liệu thử nghiệm phải lớn hơn nhiều"],[929,"SVM tuy là một phương pháp được cho là có hiệu suất cao, nhưng thời gian huấn luyện lại rất lâu"],[930,"Nnet lại cài đặt quá phức tạp"],[931,"Với những lý do trên, chúng em đề xuất chọn phương pháp Naïve Bayes để phân loại văn bản"],[932,"5.2"],[933,"Thuật toán Naïve Bayes Theo tác giả Mitchell (2005), thuật toán phân loại Naïve Bayes có đặc điểm nổi bật là có khả năng giảm độ phức tạp tính toán từ 2(2n \u2013 1) về còn 2n"],[934,"Thế đặc điểm nào giúp Naïve Bayes có khả năng đó"],[935,"5.2.1"],[936,"Công thức xác suất đầy đủ Bayes Giả sử ta muốn tính toán một hàm không biết giá trị đích :f X Y→ tương đương với P(Y|X)"],[937,"Đầu tiên, ta cho rằng Y là biến ngẫu nhiên có giá trị luận lý (boolean)"],[938,"X là vector gồm n thuộc tính luận lý (boolean), 1 2, ,..., nX X X X= 〈 〉 Áp dụng luật Bayes, P(Y=yi|X) được tính như sau: ( | ) ( )( | ) ( | ) ( ) k i i i k k j i j P X x Y c P Y yP Y y X x P X x Y c P Y y = = = = = = = = =∑ (2.1) Trong đó P(X|Y) và P(Y) được học từ tập huấn luyện"],[939,"Tuy nhiên để tính toán chính xác P(X|Y) thường đòi hỏi rất nhiều dữ liệu huấn luyện"],[940,"Để hiểu tại sao, chúng ta sẽ tính toán số lượng tham số cần thiết khi Y là biến boolean, X là vector gồm n thuộc tính boolean : ( | )ij i jP X x Y yθ = = = Trong i phải dựa trên 2n giá trị có thể cho những giá trị của vector X và j cần 2 giá trị"],[941,"Do đó, chúng ta cần tính toán khoảng 2n+1 tham số"],[942,"Mặc khác, ta phải đảm bảo 1 1 n ij i θ = =∑ cho bất kỳ j cố định nào"],[943,"Vì vậy, ứng với một giá trị đặc biệt yj, và 2n"],[944,"65 giá trị có thể của xi, chúng ta chỉ cần tính toán 2n -1 tham số độc lập"],[945,"Dựa trên giá trị của Y (Y là biến boolean), chúng ta cần tính tổng cộng là 2(2n -1) tham số θij"],[946,"5.2.2"],[947,"Tính độc lập có điều kiện (Conditional Independence) Định nghĩa: cho các biến ngẫu nhiên X, Y và Z, chúng ta nói rằng X là độc lập có điều kiện với Y gây ra Z, nếu và chỉ nếu xác suất phân phối chủ đạo X là độc lập với giá trị của Y gây ra Z"],[948,"Lúc đó: ( , , ) ( | , ) ( | )i j k i ki j k P X x Y y Z z P X x Z z∀ = = = = = = Ví dụ: ta xem ba biến luận lý (boolean) ngẫu nhiên trên đại diện cho các trạng thái của thời tiết là : Sấm , Mưa, và Sét"],[949,"Chúng ta đều biết rằng sự kiện Sấm xảy ra hoàn toàn độc lập với sự kiện Mưa gây ra Sét"],[950,"Bởi vì khi có Sét sẽ gây ra tiếng Sấm, nên một khi chúng ta biết rằng có Sét hay không thì ta có thể biết được giá trị của Sấm mà không cần thêm thông tin nào từ Mưa"],[951,"Trên thực tế, rõ ràng có sự phụ thuộc giữa Mưa và Sấm, tuy nhiên ta không cần thêm thông tin đó một khi ta đã có thông tin về Sét"],[952,"5.2.3"],[953,"Nguồn gốc thuật toán Naïve Bayes Thuật toán phân loại Naïve Bayes dựa trên luật Bayes, với giả định tất cả các thuộc tính X1\u2026Xn đều độc lập có điều kiện với nhau do sự kiện Y gây ra"],[954,"Chính giả thiết này đã đơn giản hóa cách tính của P(X|Y), và vấn đề ước lượng P(X|Y) từ tập ngữ liệu huấn luyện"],[955,"Chúng ta hãy xét ví dụ sau, giả sử ta có 1 2,X X X= 〈 〉 , lúc đó 1 2 1 2 2 1 2 ( | ) ( , | ) ( | , ) ( | ) ( | ) ( | ) P X Y P X X Y P X X Y P X Y P X Y P X Y = = = Kết quả của dòng thứ nhất là theo cách tính thông thường của xác suất, và dòng thứ ba là phân tích trực tiếp theo định nghĩa về độc lập có điều kiện"],[956,"Từ đó, ta tổng quát hóa lên khi X chứa n thuộc tính đều độc lập với nhau do sự kiện Y gây ra được biểu diễn như sau: 1 1 ( .."],[957,"| ) ( | ) n n i i P X X Y P X Y = =∏ (2.2)"],[958,"66 Chú ý, khi Y và Xi là biến luận lý (boolean), chúng ta chỉ cần 2n tham số để định nghĩa P(Xi=xik|Y=yj)"],[959,"Bây giờ, chúng ta hãy xét đến nguồn gốc của thuật toán Naïve Bayes"],[960,"Giả sử Y là một biến bất kỳ mang giá trị riêng biệt, và các thuộc tính Xi\u2026Xn là thuộc tính rời rạc hoặc liên tục"],[961,"Mục đích của chúng ta là huấn luyện để thuật toán phân loại trả ra sự phân phối xác suất trên các giá trị của Y đối với mỗi thể hiện X mà ta cần phân loại"],[962,"Biểu thức sau đây biểu diễn cho xác suất ứng với giá trị thứ k của Y: 1 1 1 ( ) ( .."],[963,"| )( | .."],[964,") ( ) ( .."],[965,"| ) k n k k n j n jj P Y y P X X Y yP Y y X X P Y y P X X Y y = = = = = =∑ Trong đó, tổng giá trị ở mẫu của biểu thức là tổng cho bởi tất cả các giá trị yj của Y"],[966,"Lúc này, sử dụng công thức (2.2), ta có thể viết lại công thức trên như sau: 1 ( ) ( | ) ( | .."],[967,") ( ) ( | ) k i ki k n j i jj i P Y y P X Y y P Y y X X P Y y P X Y y = = = = = = ∏ ∑ ∏ (2.3) Công thức (2.3) là công thức cơ bản của phương pháp phân loại Naïve Bayes"],[968,"Khi cho một thể hiện w 1= ...ne nX X X〈 〉 , theo công thức trên, ta sẽ tính toán được các xác suất của Y gây ra bởi Xnew bằng cách dựa vào P(Y) và p(Xi|Y) được ước lượng từ tập ngữ liệu.Nếu chúng ta chỉ quan tâm đến giá trị lớn nhất của Y, thì sử dụng công thức sau: ( ) ( | ) argmax ( ) ( | )k k i ki y j i jj i P Y y P X Y y Y P Y y P X Y y = = ← = = ∏ ∑ ∏ 5.2.4"],[969,"Phương pháp Naïve Bayes trong phân loại văn bản 5.2.4.1"],[970,"Công thức xác suất đầy đủ Bayes Phương pháp Naïve Bayes tìm chủ đề của văn bản d bằng các xác định chủ đề có xác suất P( | )iY c X d= = , xác suất để văn bản d nằm trong lớp ic , lớn nhất thông qua việc sử dụng công thức xác suất đầy đủ Bayes : ( | ) ( )( | ) ( | ) ( ) i i i j j j P X d Y c P Y cP Y c X d P X d Y c P Y c = = = = = = = = =∑ (2.7)"],[971,"67 Trong đó jc là chủ đề thứ j 1 2( , ,..., )nd w w w= là văn bản cần phân loại"],[972,"P(Y=ci | X=d) gọi là xác suất xảy ra văn bản d thuộc về chủ đề ci"],[973,"P(X=d | Y=ci) gọi là xác suất chủ đề ci có chứa văn bản d trong tập huấn luyện"],[974,"Một cách để xác định ( | )P Y X là sử dụng tập huấn luyện để ước lượng ( | )P X Y và ( )P Y"],[975,"Sau đó sử dụng công thức xác suất đầy đủ trên để xác định ( | )iP Y c X d= = với d bất kỳ"],[976,"5.2.4.2"],[977,"Uớc lượng P(X|Y) Giả sử với mỗi chủ đề, ta có biến cố các từ phụ thuộc vào chủ đề là độc lập có điều kiện (conditional independence) với nhau"],[978,"Ta có công thức của biểu diễn sự độc lập có điều kiện của 2 biến cố X,Z vào Y được trình bày ở 5.2.2 như sau : ( | , ) ( | )P X Y Z P X Z= Sử dụng giả định trên ta tính được ( | )iP X d Y c= = : 1 2 1 2 1 ( | ) ( , ,.., | ) ( | ) ( | ).."],[979,"( | ) ( | ) i n i i i n i n j j P X d Y c P w w w Y c P w Y c P w Y c P w Y c P w Y ci = = = = = = = = = = =∏ (2.8) Từ (2.8), (2.7) được viết lại như sau : 1 2 ( ) ( | ) ( | , ,..., ) ( ) ( | ) i k ik i n j k jj k P Y c P w Y c P Y c w w w P Y c P w Y c = = = = = = ∏ ∑ ∏ (2.9) Nhờ thống kê trên tập huấn luyện D, ( | )P X Y có thể được ước lượng theo : { } { } # ( | ) # j i j i i D X w Y c P X w Y c D Y c = ∧ = = = = (2.10)"],[980,"68 Trong đó { }# j iD X w Y c= ∧ = : số văn bản trong tập huấn luyện chứa đồng thời wj và ci { }# iD Y c= : số văn bản trong tập huấn luyện chứa ci Công thức ước lượng trên sẽ cho kết quả ( | ) 0j iP X w Y c= = = khi không có văn bản chứa đồng thời cả hai (wj và ci)"],[981,"Nhằm tránh trường hợp này, ta nên sử dụng phép ước lượng đã được làm mịn sau : { } { } # ( | ) # j i j i i D X w Y c l P X w Y c D Y c lR = ∧ = + = = = + (2.11) Với R : số lượng chủ đề l : quyết định độ mịn của phép ước lượng 5.2.4.3"],[982,"Ước lượng P(Y) Việc ước lượng P(Y=ci) đơn giản là tính phần trăm số văn bản trong tập huấn luyện có chủ đề ci : { }#( ) ii D Y c P Y c D = = = (2.12) 5.2.5"],[983,"Hai mô hình sự kiện trong phân loại văn bản bằng phương pháp Naïve Bayes 5.2.5.1"],[984,"Giới thiệu Phân loại văn bản là một lĩnh vực có phạm vi thuộc tính (attribute) rất nhiều bởi vì thuộc tính của những văn bản cần phân loại là từ (word), mà số lượng từ khác nhau thì vô cùng lớn"],[985,"Và thuật toán Naïve Bayes đã thành công trong việc ứng dụng vào lĩnh vực phân loại với khả năng làm giảm độ phức tạp trên"],[986,"Mặc dù đây là thuật toán khá phổ biến, nhưng trong cộng đồng phân loại văn bản vẫn có một vài điều lẫn lộn về phương pháp phân loại Naïve Bayes bởi vì có hai mô hình phát sinh khác nhau vẫn thường được sử dụng"],[987,"Cả hai mô hình đều sử dụng \u201cnaïve Bayes assumption\u201d và cả hai đều được giới phân loại gọi là \u201cnaïve Bayes\u201d"],[988,""],[989,"69 5.2.5.2"],[990,"Mô hình đa biến trạng Bernoulli (Multi-variate Bernoulli Model) Một mô hình biểu diễn một văn bản là một vector có thuộc tính nhị phân cho biết rằng từ nào có hay không xuất hiện trong văn bản"],[991,"Số lần xuất hiện của một từ trong văn bản là không cần thiết"],[992,"Ở đây chúng ta có thể hiểu rằng văn bản là sự kiện (event) và sự có mặt hay vắng mặt của các từ trở thành thuộc tính của sợ kiện"],[993,"Đấy chính là mô hình sự kiện đa biến trạng Bernoulli (multi-variate Bernoulli event model), một mô hình khá truyền thống, đã được nhiều người sử dụng trong phân loại văn bản"],[994,"Theo McCallum & Nigam (1998), một số công trình tiêu biểu về hướng tiếp cận này là Robertson & Sparck-Jones (1976), Lewis(1992), Kalt & Croft (1996), Larkey & Croft (1996), Koller & Sahami (1997), Sahami (1996)"],[995,"5.2.5.3"],[996,"Mô hình đa thức (Multinomial Model) Mô hình thứ hai cho rằng một văn bản đại diện tập hợp tần số xuất hiện của từ trong văn bản"],[997,"Do đó, thứ tự xuất hiện của từ được bỏ qua nhưng tần số xuất hiện được giữ lại"],[998,"Ở đây, chúng ta có thể hiểu rằng những tần số xuất hiện của các từ là những sự kiện (events) và văn bản trở thành tập hợp các sự kiện của từ (word events)"],[999,"Chúng ta gọi đây là sự kiện mô hinh đa thức (Multinomial event model)"],[1000,"Đây là hướng tiếp cận thông thường trong mô hình ngôn ngữ học thống kê"],[1001,"Hướng tiếp cận này cũng được rất nhiều người sử dụng mà theo McCallum & Nigam (1998) các công trình tiêu biểu như Lewis & Gale (1994), Kalt & Croft (1996), Joachims (1997), Mitchell (1997), McCallum et al (1998)\u2026 5.2.5.4"],[1002,"Nhận xét Đối với phương pháp multi-variate model, việc không nắm bắt thông tin tần số xuất hiện của từ có thể đưa đến khuyết điểm không phân biệt được văn bản ưu tiên cho chủ đề nào hơn nếu cả 2 văn bản đều xuất hiện cùng một từ nào đó nhưng tần số lại khác nhau rất nhiều"],[1003,"Ví dụ, nếu từ \u201cthể thao\u201d sẽ xuất hiện nhiều trong các tin tức về thể thao, và sẽ ít xuất hiện trong các tin tức có nội dung khác, nhưng do phương pháp multi-variate không sử dụng thông tin tần số nên không phân biệt được văn bản ưu tiên cho thể thao hơn"],[1004,"Trong khi đó, hướng tiếp cận multinomial model rõ ràng đã sử dụng thông tin về xác suất phân phối từ trong văn bản"],[1005,""],[1006,"70 Đối với phương pháp mulnomial, do sử dụng tần số xuất hiện của từ nên sẽ phụ thuộc vào chiều dài văn bản, vì tài liệu càng dài, sự xuất hiện của các từ càng nhiều"],[1007,"Theo kết quả đạt được của thí nghiệm so sánh giữa hai phương pháp Naïve Bayes trên, McCallum & Nigam (1998) đã đưa ra kết quả là hướng tiếp cận đa biến trạng thực hiện tốt với kích thước từ vựng nhỏ (<500 từ), còn phương pháp mô hình đa thức thường cho kết quả tốt hơn đối với kích thước từ vựng lớn (>500 từ)"],[1008,"5.3"],[1009,"Bài toán phân loại tin tức điện tử tiếng Việt 5.3.1"],[1010,"Quy ước Với mỗi văn bản d , sau khi sử dụng GA để loại bỏ dấu câu và stopword, ta thu được d được tách thành nhiều ngữ g dưới dạng sau d={g1,g2,\u2026, gm} , với gi là tập hợp gồm n cách tách của một ngữ, gi = {ti1,ti2,\u2026,tin} trong đó tij là một cách tách ngữ., tij = {w1,w2,\u2026,wp}"],[1011,"Ví dụ: Hình 5"],[1012,"1"],[1013,"Minh họa quy ước cho văn bản Việc phân loại sẽ gán một chủ đề ch ∈ C={c1,c2,\u2026,cq} cho văn bản, mỗi chủ đề lại bao gồm nhiều từ khóa (keyword) K={k1,\u2026,kr}"],[1014,"Cây phân cấp chủ đề và từ khóa thể hiện như sau : Hình 5"],[1015,"2.Minh họa chủ đề \u201cXã hội\u201d"],[1016,"71 Trong phần này chúng em sẽ trình bày các phương pháp tính toán được sử dụng trong phân loại bao gồm: công thức được dùng trong IGATEC [H.Nguyen et al, 2005]và công thức Naïve Bayes [Mitchell, 2005]"],[1017,"5.3.2"],[1018,"Công thức phân loại văn bản trong IGATEC [H"],[1019,"Nguyen et al, 2005] Công thức phân loại văn bản trong IGATEC [H.Nguyen et al, 2005] do chính tác giả đề nghị theo cách sử dụng độ phụ thuộc của văn bản vào chủ đề"],[1020,"Độ phụ thuộc này được tính dựa vào xác suất đồng xuất hiện của các từ trong văn bản với một từ khóa nhất định"],[1021,"Chi tiết cách tính này như sau : Cho trước một từ khóa k , độ phụ thuộc của từ w vào k được tính như sau: ( & )( | ) ( ) p k wp k w p w = Trong đó p(w) là xác suất xuất hiện của từ w trên Google được tính theo công thức ( )( )= count wp w MAX (đã trình bày ở mục 4.5.1.2) p( k & w ) là xác suất xuất hiện đồng thời của chủ đề k và từ wi trên Google với: ( & )( & ) count k wp k w MAX = (đã trình bày ở mục 4.5.1.2.) Tiếp theo, độ liên quan (relative) của một cách tách ngữ t với từ khóa k bằng tổng xác suất của tất cả các từ w xuất hiện đồng thời với từ khóa k như sau: 1 ( , ) ( | ) p i i rel t k p k w = =∑ Độ hỗ trợ (support) của cách tách ngữ t trên vào chủ đề c={k1,k2,\u2026,ks} là : 1 1( , ) ( , ) s i i SP t c rel t k s = = ∑ Theo công thức trên, tác giả cho rằng văn bản có độ hỗ trợ vào một chủ đề càng cao thì khả năng văn bản đó thuộc về chủ đề này càng lớn"],[1022,"Dựa vào các công thức, độ phụ thuộc của câu được xác định theo công thức: 1 1 1 1( , ) ( , ) ( , ) m m n i ij i i j SP d c SP g c SP t c n= = = = =∑ ∑ ∑"],[1023,"72 Theo các công thức trên, văn bản d sẽ thuộc về chủ đề có SP(d,c) lớn nhất"],[1024,"5.3.3"],[1025,"Công thức Naïve Bayes trong bài toán phân loại tin tức điện tử tiếng Việt sử dụng thống kê từ Google Ở mục 5.2, chúng em đã trình bày các công thức Naïve Bayes cơ bản dùng thông tin xác suất học được từ tập dữ liệu huấn luyện"],[1026,"Tuy nhiên, hướng tiếp cận của chúng em không sử dụng tập ngữ liệu mà sử dụng thông tin thống kê từ Google nên các công thức trên được chúng em cải tiến cho phù hợp"],[1027,"5.3.3.1"],[1028,"Ước lượng P(X|Y) Với công thức (2.11) được trình bày ở mục 5.2"],[1029,"như sau: { } { } # ( | ) # j i j i i D X w Y c P X w Y c D Y c = ∧ = = = = nếu sử dụng cho tập ngữ liệu có sẵn, công thức có ý nghĩa là xác suất chủ đề ci chứa văn văn bản có wj bằng số văn bản có chứa wj thuộc ci trên tổng số văn bản thuộc chủ đề ci"],[1030,"Tuy nhiên, trong hướng tiếp cận dựa trên Google, chúng ta không thể xác định được số lượng văn bản thực sự thuộc chủ đề ci"],[1031,"Do đó, chúng em đề xuất cách tính xác suất khác phù hợp với hướng tiếp cận dựa trên thống kê Google: { } { } # ( & ) 1 ( | ) # ( & ) | | j i j i j i i j kk D X w Y c p w c P X w Y c D Y c p w c Y = ∧ = + = = = = +∑ (4.1) Trong đó: p(wj & ci ) là xác suất xuất hiện đồng thời wj và ci"],[1032,"k số thứ tự của các chủ đề, {1,...,| |}k Y∈ Công thức trên cho kết quả dựa trên xác suất xuất hiện đồng thời wj và ci trên tổng số lần xuất hiện số lần xuất hiện wj trong tất cả các chủ đề"],[1033,"5.3.3.2"],[1034,"Ước lượng P(Y) Với công thức (2.12) được trình bày ở mục 5.2 là: { }#( ) ii D Y c P Y c D = = = (4.2)"],[1035,"73 Ở công thức này, ta giả sử các trang web chứa từ khóa ci đều thuộc chủ đề ci"],[1036,"Lúc đó, P(Y=ci) bằng xác suất xuất hiện ci trên tổng số trang web chứa tất cả các chủ đề: { }# ( )( ) ( ) i i i jj D Y c p cP Y c D p c = = = = ∑ Trong đó p(ci) : tần số xuất hiện của chủ đề ci trên Google j : là chỉ số của các chủ đề cần phân loại 5.3.3.3"],[1037,"Ước lượng P(Y|X) Khi đó công thức Naïve Bayes cho phân loại văn bản (2.9) sẽ có dạng : 1 2 ( ) ( & ) ( | , ,..., ) ( ) ( & ) i k ik i n j k jj k p c p w c P Y c w w w p c p w c = = ∏ ∑ ∏ (4.3) Vì tần số xuất hiện p(w) (mục 4.5.1) của từ trên Google rất nhỏ nên việc tính xác suất 1 2( | , ,..., )i nP Y c w w w= theo công thức (4.3) có thể dẫn đến việc tràn số do nhân các số thực gần với 0"],[1038,"Chúng em khắc phục vấn đề này bằng cách chuyển công thức (4.3) sang sử dụng log : ( ) ( ) ( ) ( ) ( ) ( )( ) 1 2 log ( ) ( & ) ( | , ,..., ) log ( ) ( & ) log ( ) log ( & ) log ( ) log ( & ) i k ik i n j k jj k i k ik j k jj k p c p w c P Y c w w w p c p w c p c p w c p c p w c \u2032 = = − + = − + ∏ ∑ ∏ ∑ ∑ ∑ Văn bản d sẽ được phân loại vào chủ đề ci có giá trị 1 2( | , ,..., )i nP Y c w w w\u2032 = cao nhất"],[1039,""],[1040,"74 5.4"],[1041,"Kết luận Các phương pháp phân loại văn bản dựa trên công thức của IGATEC và phương pháp Naïve đều tương đối đơn giản, không bị hạn chế về tập huấn luyện như khi sử dụng các phương pháp khác"],[1042,"Ngoài ra, các phương pháp trên cũng không gặp trường hợp sai lạc do có sự thay đổi trong tập huấn luyện bởi tính linh hoạt đối với sự thay đổi nhờ dùng thông tin thống kê từ Google"],[1043,"Các kết quả trên thu nhận được thông qua việc chạy hệ thống thử nghiệm phân loại ViKass sẽ được mô tả chi tiết trong chương tiếp theo"],[1044,""],[1045,"75 CChhưươơnngg 66 HHỆỆ TTHHỐỐNNGG TTHHỬỬ NNGGHHIIỆỆMM PPHHÂÂNN LLOOẠẠII VVĂĂNN BBẢẢNN Giới thiệu hệ thống thử nghiệm Vikass Thử nghiệm các cách trích xuất thông tin Dữ liệu thử nghiệm Thử nghiệm các công thức tính độ tương hỗ MI Thử nghiệm phân loại tin tức điện tử"],[1046,"76 Chương 6"],[1047,"HỆ THỐNG THỬ NGHIỆM PHÂN LOẠI VĂN BẢN 6.1"],[1048,"Giới thiệu hệ thống thử nghiệm Vikass 6.1.1"],[1049,"Chức năng hệ thống Vikass Hệ thống thử nghiệm phân loại văn bản Vikass được xây dựng nhằm mục đích kiểm nghiệm phương pháp tách từ IGATEC và các phương pháp phân loại đề cập ở chương trước nhằm tìm ra được các tham số tối ưu trước khi tích hợp vào toà soạn báo điện tử"],[1050,"Các tham số này bao gồm các tham số chạy thuật toán di truyền như số lượng cá thể ban đầu, số thế hệ tối ưu, tỉ lệ lai ghép, tỉ lệ đột biến; cách tính MI hiệu quả và phương pháp phân loại nào cho kết quả tốt hơn"],[1051,"Ngoài tích hợp mô-đun trích tần số xuất hiện từ Google, hệ thống còn cung cấp các tính năng khác như trích tin tức, chỉnh sửa từ khóa"],[1052,"Chức năng của hệ thống sẽ được mô tả chi tiết trong các phần tiếp theo"],[1053,"6.1.2"],[1054,"Tổ chức và xử lý dữ liệu 6.1.2.1"],[1055,"Giới thiệu chung Hướng tiếp cận của luận văn dựa trên thống kê từ Google, điều đó có nghĩa là mỗi lần cần lấy tần số xuất hiện của một từ mới, hệ thống phải thực hiện lấy thông tin từ Internet"],[1056,"Điều này làm tiêu tốn rất nhiều thời gian chờ đợi, do vậy mỗi khi lấy được thông tin từ Google, chúng em lưu lại vào một file dữ liệu đệm để có thể sử dụng lại mỗi khi cần đến"],[1057,"Với mục đích làm tăng tốc độ xử lý của chương trình thử nghiệm, việc quản lý dữ liệu hoàn toàn được thực hiện trên file văn bản thông thường trên kiểu phông phổ biến của tiếng Việt là phông Unicode UTF8"],[1058,"Hệ thống thử nghiệm cần hai loại thông tin như sau: Đối với thử nghiệm tách từ tiếng Việt, hệ thống cần thông tin về xác suất xuất hiện của các từ trên Google"],[1059,"Đối với việc thử nghiệm phân loại văn bản, hệ thống cần thông tin về xác suất xuất hiện đồng thời của từ và từ khoá tương ứng với chủ đề"],[1060,""],[1061,"77 6.1.2.2"],[1062,"Tổ chức dữ liệu Từ những yêu cầu trên, hệ thống dữ liệu được thiết kế thành ba file có nội dung như sau: Hình 6"],[1063,"1"],[1064,"Tổ chức file dữ liệu File CACHE: là dạng file văn bản thông thường, chứa thông tin: Từ: từ đã tìm từ Google Xác suất: xác suất của từ đó trên Google Loại từ: mang một trong các giá trị W(là từ), NW (không là từ), WC ( có thể là từ), NWC (không thể là từ), UD (chưa phân loại)"],[1065,"File KEYWORD: File được viết dưới dạng xml bao gồm thông tin về tên chủ đề các cấp: Tên chủ đề: tên của chủ đề các cấp (cấp 1 và cấp 2) Chỉ số: chỉ số của mỗi chủ đề cho biết vị trí của chủ đề trong danh sách xác suất của từ với từng chủ đề trong file Relevant"],[1066,"Chọn dạng xml để lưu tên chủ đề vì tính chất lồng nhau ở từng cấp của chủ đề rất thích hợp với cấu trúc dạng cây của tài liệu xml"],[1067,"Ví dụ, ta có các chủ đề cấp 1 là \u201cthể thao\u201d và các chủ đề cấp 2 của nó là \u201cBóng đá\u201d, \u201cQuần vợt\u201d như hình vẽ dưới đây\u201d Hình 6"],[1068,"2"],[1069,"Chủ đề Thể thao Lúc đó, nội dung file chủ đề sẽ có nội dung như sau:"],[1070,"78 File RELEVANT: chứa thông tin: Từ: từ đã tìm Danh sách xác suất của từ với từng chủ đề: xác suất xuất hiện đồng thời của từ ứng với từng chủ đề theo chỉ số được lưu trong file KEYWORD"],[1071,"Sau khi thực hiện thử nghiệm, dung lượng file CACHE đã lên đến gần 10M và file RELEVANT xấp xỉ 50M"],[1072,"Với khối lượng dữ liệu lớn như vậy, việc sử dụng một hệ quản trị cơ sở dữ liệu là không cần thiết bởi vì việc xử lý thông tin trong hệ thống là đơn giản và yêu cầu tiên quyết của chương trình là tốc độ xử lý cao"],[1073,"Như vậy, chọn lựa lưu trữ thông tin dưới dạng văn bản bình thường là phù hợp với yêu cầu hệ thống"],[1074,"6.1.2.3"],[1075,"Xử lý dữ liệu Khi bắt đầu hoạt động, hệ thống tự động thực hiện đọc các file dữ liệu, phân tích chuỗi trong file để lấy thông tin và đưa vào bộ nhớ dưới dạng \u201cbảng băm\u201d (hashtable)"],[1076,"Hệ thống thử nghiệm được phát triển nên ngôn ngữ C#, là một ngôn ngữ khá mạnh hỗ trợ nhiều cấu trúc lưu trữ thông tin trong đó có hỗ trợ bảng băm"],[1077,"Nhờ vậy mà việc tổ chức dữ liệu trở nên đơn giản hơn rất nhiều"],[1078,"Ngoài ra, cách xử lý như vậy sẽ làm tăng tốc độ tìm kiếm thông tin của từ nhờ các ưu điểm tổ chức dữ liệu của bảng băm"],[1079,"<?xml version=\"1.0\" encoding=\"utf-8\" ?> <keyword> <topic name=\"thể thao\" value=\"1\"> <topic name=\"bóng đá\" value=\"2\" /> <topic name=\"quần vợt\" value=\"3\" /> <\/topic> <\/keyword>"],[1080,"79 6.1.3"],[1081,"Một số màn hình của hệ thống Vikass Hình 6"],[1082,"3"],[1083,"Màn hình tách từ và phân loại STT Mô tả 1 Chọn thư mục chứa các tập tin cần tách từ và phân loại 2 Chọn thư mục lưu kết quả 3 Liệt kê tên các tập tin được chọn tách từ và phân loại 4 Di chuyển các tập tin qua lại để chọn các tập tin thực hiện tách từ 5 Liệt kê tên tất cả các tập tin có trong thư mục (1) 6 Thực hiện tách từ và phân loại 7 Dừng tách thực thi 8 Xem tập tin kết quả phân loại 9 Tab tùy chọn các thông số chạy GA 10 Tab tùy chọn các thông số như loại MI sử dụng, có sử dụng stopword hay không"],[1084,"11 Tab chọn các từ khóa sẽ sử dụng cho việc phân loại Bảng 6"],[1085,"1"],[1086,"Mô tả một số control của màn hình tách từ"],[1087,"80 Màn hình môđun trích xuất từ Google: Hình 6"],[1088,"4"],[1089,"Màn hình trích xuất từ Google STT Mô tả 1 Chọn thư mục chứa các tập tin như tập tin đệm, tập tin chứa độ liên quan của từ và từ khóa,\u2026 2 Các tùy chọn như chỉ tìm kiếm các từ có tần số 0, chỉ tìm các trang .vn, tìm kiếm độ liên quan của từ và từ khóa\u2026 3 Các phương pháp tải về sử dụng 4 Thanh biểu thị tiến trình tìm kiếm và trích từ 5 Thực hiện tìm kiếm và trích xuất 6 Lưu lại tập tin đệm và tập tin chứa độ liên quan 7 Dừng việc tìm kiếm 8 Danh sách các từ đã được tìm kiếm Bảng 6.2"],[1090,"Mô tả một số control của màn hình trích từ Google"],[1091,"81 Màn hình phân loại tin tức điện tử hỗ trợ toà soạn báo điện tử : Hình 6"],[1092,"5"],[1093,"Màn hình phân loại tin tức điện tử STT Mô tả 1 Thiết lập các tham số kết nối đến SQL server 2 Lấy các tin tức được toà soạn báo điện tử tải về 3 Thực hiện phân loại 4 Cập nhật các tin tức đã được phân loại vào SQL server 5 Thực hiện tất cả các bước (2),(3),(4) 6 Hiển thị các thông tin như : nội dung tin, tên của chủ đề được phân loại,\u2026 Bảng 6.3"],[1094,"Bảng mô tả một số control của màn hình phân loại tin tức điện tử"],[1095,"82 6.2"],[1096,"Thử nghiệm các cách trích xuất thông tin Việc trích xuất thông tin về tần số xuất hiện của từ, độ liên quan giữa từ và chủ đề được thực hiện thông qua module Google Extractor"],[1097,"Nhằm mục đích tăng tốc trích thông tin từ Google, chúng em đã thử nghiệm trích thông tin bằng nhiều cách khác nhau và thực hiện kết nối đến Google sử dụng nhiều luồng (>=15)"],[1098,"Bên cạnh đó, để tránh việc phải thực hiện tìm kiếm nhiều lần, các tập tin đệm được sử dụng với mục đích lưu lại hay cập nhất kết quả các lần tìm kiếm trước"],[1099,"6.2.1"],[1100,"Các phương pháp thử nghiệm Chúng em sử dụng 3 cách khác nhau để lấy kết quả tìm kiếm bao gồm sử dụng dịch vụ web do Google cung cấp, tải trang kết quả về máy cục bộ sau đó sử dụng XPath hay tìm kiếm chuỗi"],[1101,"6.2.1.1"],[1102,"Google web service Dịch vụ web là một ứng dụng cung cấp giao diện lập trình, hỗ trợ sự truyền thông từ ứng dụng này đến ứng dụng khác qua mạng dùng XML"],[1103,"Dịch vụ web của Google tại địa chỉ http://api.google.com/GoogleSearch.wsdl là một phương pháp tiện lợi để khai thác công cụ tìm kiếm này"],[1104,"Tuy nhiên, ta phải đăng kí tài khoản trước khi sử dụng"],[1105,"Với mỗi tài khoản Google giới hạn số lượng truy vấn là 1000 truy vấn/ngày"],[1106,"Các tham số cần biết khi sử dụng dịch vụ : Tham số tìm kiếm q Câu truy vấn n Số kết quả trả về trên từng trang lr Giới hạn phạm vi ngôn ngữ tìm kiếm ie Bảng mã câu truy vấn sử dụng oe Bảng mã của kết quả trả về Bảng 6"],[1107,"4"],[1108,"Tham số sử dụng dịch vụ Google Một số câu truy vấn đặc biệt trên Google :"],[1109,"83 Truy vấn đặc biệt Câu truy vấn Ý nghĩa Loại bỏ một từ bass \u2013music \u201c-\u201d để loại bỏ 1 từ ra khỏi kết quả tìm kiếm Từ khóa OR vacation london OR paris OR Giới hạn site Admission site:www.stanford.edu site: chỉ tìm kiếm trong site được chỉ định Giới hạn ngày Star Wars daterange:2452122- 2452234 daterange: chỉ trả về các file có nhãn thời gian thõa điều kiện Lọc file Google filetype:doc OR filetype:pdf filetype: chỉ tìm kiếm các file có kiểu mở rộng được liệt kê Loại trừ file Google doc -filetype: -filetype:pdf -filetype: ngược lại với filetype: Tìm theo tiêu đề intitle:Google search intitle: chỉ tìm kiếm tiêu đề web Bảng 6"],[1110,"5"],[1111,"Một số câu truy vấn đặc biệt của Google Trong quá trình thử nghiệm sử dụng dịch vụ web của Google, chúng em nhận thấy thời gian đáp ứng không được nhanh (khoảng >5s cho một truy vấn-sử dụng mạng Internet của trường) hơn nữa còn tồn tại nhiều lỗi"],[1112,"Lý do có thể kể đến như phiên bản dịch vụ đang trong quá trình thử nghiệm (bản β), hạn chế do dung lượng mạng, chi phí chứng thực"],[1113,"Giới hạn 1000truy vấn/ngày cũng ảnh hưởng đến chương trình khi phải thực hiện trích xuất trên lượng lớn các từ"],[1114,"Để khắc phục vấn đề này, chúng em sử dụng biện pháp tải trang kết quả về"],[1115,"6.2.1.2"],[1116,"Xpath và tìm kiếm chuỗi Trang kết quả trả về sẽ được chuyển sang định dạng xHTML dùng cho việc trích xuất dùng Xpath (http://www.w3.org/TR/XPath20) hay thực hiện tìm kiếm trên chuỗi"],[1117,"Cả hai phương pháp này đều cho hiệu suất tốt (khoảng 1-3s/truy vấn)"],[1118,"Xpath là định dạng được W3C đề nghị được sử dụng rộng rãi trong việc truy vấn tập tin XML"],[1119,"Sử dụng Xpath có thuận lợi hơn tìm kiếm chuỗi ở chỗ có thể sử dụng trích xuất trên nhiều ngôn ngữ trả về từ Google và nếu cấu trúc của trang web thay"],[1120,"84 đổi thì ta vẫn lấy được thông tin trả về của Google"],[1121,"Trong khi đó việc tìm kiếm chuỗi sẽ phụ thuộc vào các câu đặc biệt (như \u201ccác kết quả \u201d.."],[1122,")"],[1123,"Do đó, nếu các trang trả về của Google trình bày khác đi, cách tìm kiếm chuỗi sẽ không cho kết quả mong muốn"],[1124,"Tuy nhiên, sử dụng cách tìm kiếm chuỗi sẽ cho kết quả nhanh hơn dùng Xpath vì hệ thống không phải tốn một thời gian phân tích dữ liệu thành dạng tài liệu XML"],[1125,"6.2.2"],[1126,"Nhận xét Hiện tại, điều chúng ta quan tâm hàng đầu là tốc độ trích thông tin từ Google"],[1127,"Mặt khác, trang web Google có cấu trúc khả ổn định, hầu như không thay đổi"],[1128,"Vì vậy khi thực hiện thử nghiệm, chúng em sử dụng cách thức tìm kiếm chuỗi để đạt tối độ cao nhất"],[1129,"Tuy nhiên, chúng em vẫn xây dựng các lựa chọn rút trích để tạo tính linh hoạt trong thử nghiệm"],[1130,"6.3"],[1131,"Dữ liệu thử nghiệm 6.3.1"],[1132,"Nguồn dữ liệu Dữ liệu thử nghiệm được lấy từ trang tin tức VnExpress.net (www.vnexpress.net) tại thời điểm tháng 6/2005"],[1133,"Đây là một trong những trang tin tức điện tử đầu tiên tại Việt Nam ra đời vào ngày 26/2/2001, đến nay đã hơn bốn năm hoạt động với lượng độc giả đông đảo trong cả nước và quốc tế"],[1134,"Ngoài các trang mục do phóng viên của tờ báo viết, VnExpress.net còn mở rộng đón nhận các bài viết do độc giả gửi về từ khắp nơi để làm phong phú thêm cho nội dung của tờ báo và cập nhật tin tức thường xuyên nhanh chóng"],[1135,"6.3.2"],[1136,"Số lượng dữ liệu thử nghiệm Từ các mục của VnExpress.net, đầu tiên chúng em chọn lọc ra một số mục chính để lấy dữ liệu thử nghiệm"],[1137,"Vì chúng em quy định từ khóa cho chủ đề chính là tên chủ đề đó nên trong quá trình thử nghiệm, chúng em phát hiện ra một số trường hợp nhập nhằng"],[1138,""],[1139,"85 Đầu tiên, từ khóa Thế giới, Xã hội có ý nghĩa bao quát có thể về Kinh tế thế giới, chính trị thế giới, văn hóa xã hội\u2026, nên khả năng các tin tức được phân loại vào chủ đề này là rất cao do tần số xuất hiện của chủ đề này với các từ phổ biến lớn"],[1140,"Thứ hai, một số mục có tên không đồng nhất giữa các tờ báo điện tử như trang VnExpress.net dùng Vi tính trong khi đó TuoiTre.com.vn lại dùng Nhịp sống số, Vnn.vn dùng Công nghệ thông tin và Viễn thông..."],[1141,"Việc này làm giảm kết quả khi sử dụng từ khóa khóa Vi tính cho chủ đề này vì từ khóa này không bao quát được cho các trang sử dụng tên chủ đề khác mặc dù cùng trình bày một nội dung"],[1142,"Do vậy, chúng em chỉ sử dụng một số mục có từ khóa rõ ràng"],[1143,"Đối với mỗi tin tức, chúng em chỉ tách lấy phần tiêu đề, phần tóm lược và phần chú thích ảnh"],[1144,"Đây là các phần có ý nghĩa phân loại cao do được người viết bài tóm lược và chọn lọc"],[1145,"Ứng mỗi chủ đề, chúng em lấy ngẫu nhiên 100 tin"],[1146,"Còn cách giải quyết phần nhập nhằng trình bày ở trên sẽ là hướng mở rộng của luận văn"],[1147,"Tổng dữ liệu thử nghiệm là 1500 tập tin bao gồm 15 chủ đề cấp 2, mỗi chủ đề 100 tập tin"],[1148,""],[1149,"86 Hình 6"],[1150,"6"],[1151,"Cây chủ đề 6.3.3"],[1152,"Nhận xét Mặc dù dữ liệu dùng thử nghiệm khá nhỏ do hạn chế về mặt thời gian, nhưng cách thức chọn dữ liệu và chủ đề thử nghiệm phân loại của chúng em đã mở rộng rất nhiều so với 35 văn bản thử nghiệm của [H"],[1153,"Nguyen et al, 2005] trên 5 chủ đề Chính trị, Giáo dục, Kinh doanh, Sức khỏe, Thể thao"],[1154,""],[1155,"87 6.4"],[1156,"Thử nghiệm các công thức tính độ tương hỗ MI 6.4.1"],[1157,"Các phương pháp thử nghiệm Nhằm xác định hiệu quả của các cách tính MI trong việc tách từ tiếng Việt, chúng em thực hiện thử nghiệm 3 công thức MI đã được trình bày ở mục 4.5: một công thức tính MI của [H.Nguyen et al, 2005] (gọi là MI1) , một của [Ong & Chen, 1999] (gọi là MI2), một do chúng em đề nghị (gọi là MI3)"],[1158,"Ứng với mỗi công thức tính MI trên, chúng em thử nghiệm thêm việc tách stopword và không tách stopword trước khi tách từ"],[1159,"Mục đích của việc tách stopword trước khi tách từ nhằm tạo ra nhiều ngữ nhỏ hơn khi đã bỏ các từ không có ý nghĩa, để làm tăng tốc độ tách từ của hệ thống"],[1160,"Như vậy, tổng cộng có 6 thử nghiệm tách từ như sau: MI1 tách stop word (MI1_NonSW) MI1 không tách stop word (MI1_SW) MI2 tách stop word (MI2_NonSW) MI2 không tách stop word (MI2_NonSW) MI3 tách stop word (MI3_NonSW) MI3 không tách stop word (MI3_NonSW) Chúng em thử nghiệm các công thức trên 1500 nội dung tóm tắt các tin tức của VnExpress.net 6.4.2"],[1161,"Kết quả Độ chính xác của các công thức tính độ tương hỗ như sau: Cách tính MI Không tách stop word Có tách stopword MI 1 [H"],[1162,"Nguyen et al, 2005] 74% 72% MI 2 [Ong & Chen, 1999] 60% 55% MI 3 (chúng em đề nghị) 72% 69% Bảng 6"],[1163,"6"],[1164,"Kết quả thực nghiệm các công thức tính độ tương hỗ MI"],[1165,"88 0% 10% 20% 30% 40% 50% 60% 70% 80% MI1 MI2 MI3 Loại MI Độ c hí nh x ác Non SW SW Hình 6"],[1166,"7"],[1167,"Biểu đồ so sánh kết quả các công thức tính độ tương hỗ MI 6.4.3"],[1168,"Nhận xét Trong 6 cách thử nghiệm, cách tách từ dùng công thức MI1"],[1169,"có độ chính xác cao nhất"],[1170,"Thời gian chạy tách từ lúc đầu khá lâu (trung bình khoảng 10 phút cho một mẫu tóm tắt dài khoảng 100 tiếng) đa phần là do thời gian lấy thông tin từ Google"],[1171,"Nhưng khi thông tin về tần số xuất hiện của các từ đã được lưu lại tương đối lớn (độ lớn file cache khoảng 10M), thì tốc độ tách từ giảm xuống đáng kể (trung bình <1giây đối với các văn bản không cần lấy thông tin từ Internet) Cách tiếp cận của công thức MI1 là ưu tiên dựa trên từ ghép có hai tiếng, mà theo thống kê dựa trên từ điển của chúng em, số từ 2 tiếng chiếm đa số trong từ vựng tiếng Việt"],[1172,"Cách tính này cho kết quả khá tốt vì vừa thoả mãn được tính chất tự nhiên dựa trên ưu thế áp đảo của từ 2 tiếng, vừa được chứng minh bằng thực nghiệm"],[1173,"Trong các trường hợp thử nghiệm có tách stopword, thời gian tách từ giảm đi rất nhiều (trung bình 5 phút cho văn bản mới)"],[1174,"Tuy nhiên, trong quá trình thử nghiệm, chúng em nhận thấy việc tách stopword có thể làm sai lạc ý nghĩa của văn bản ban"],[1175,"89 đầu do danh sách stopword đưa vào không hoàn chỉnh"],[1176,"Vì vậy kết quả tách từ có tách stopword không cao như cách tách thuần tuý"],[1177,"6.5"],[1178,"Thử nghiệm phân loại tin tức điện tử 6.5.1"],[1179,"Thước đo kết quả phân loại văn bản Để đánh giá hiệu quả phân loại văn bản, thông thường người ta dùng các chỉ số về độ thu về-recall và độ chính xác-precision [Yang, 2000]"],[1180,"Cho một phương pháp phân loại văn bản, đầu vào là một văn bản, và kết quả trả về là một danh sách các chủ đề được gán cho văn bản đó, chỉ số độ thu về, độ chính xác có thể được tính như sau: Hình 6"],[1181,"8"],[1182,"Các thông số dùng tính độ thu về, độ chính xác Hình trên mô tả các thông số sau: (A) là tất cả văn bản thực hiện phân loại văn bản cho chủ đề T (B) là số văn bản được phân loại lấy về cho chủ đề T (C) là số văn bản thực sự thuộc về chủ đề T (D) là số văn bản lấy về chính xác"],[1183,"Các tham số trên được dùng trong công thức tính độ thu về-recall, độ chính xác- precision dưới đây:"],[1184,"90 Việc gán nhãn chủ đề của các phương pháp phân loại văn bản có thể được đánh giá bằng cách dùng bảng trường hợp hai chiều ứng với từng loại chủ đề: Chủ đề đang xét ĐÚNG với chủ đề văn bản Chủ đề đang xét SAI với chủ đề văn bản Phân loại ĐÚNG với chủ đề văn bản a b Phân loại SAI với chủ đề văn bản c d Bảng 6"],[1185,"7"],[1186,"Bốn trường hợp của phân loại văn bản Như vậy, với mỗi kết quả phân loại cho một văn bản, ta sẽ có được một trong 4 trường hợp a,b,c hoặc d"],[1187,"Từ đó, ta tính được các chỉ số sau: arecall a c = + nếu a + c >0, ngược lại là không xác định"],[1188,"aprecision a b = + nếu a + b >0, ngược lại là không xác định"],[1189,"Tuy nhiên, cách tính với độ thu về, độ chính xác riêng rẽ sẽ cho kết quả không cân đối"],[1190,"Ví dụ nếu số văn bản lấy về đúng (D) gần bằng với số văn bản đúng thực sự (C) thì chỉ số độ thu về sẽ cao, tuy nhiên nếu số văn bản lấy về (B) khá nhiều so với (D) sẽ cho chỉ số độ chính xác nhỏ"],[1191,"Do vậy, thông thường người ta thêm một chỉ số F1 [Yang , 1997] để phản ánh sự cân đối giữa 2 độ đo trên: 21 1 1F recall precision = + Ngoài ra, để tính toán hiệu quả thực thi trên toàn bộ chủ đề, thông thường người ta còn sử dụng hai phương pháp macro-averaging và micro-averaging"],[1192,"Macro-averaging tính trung bình các chỉ số recall, precision, fallout, Acc,Err của tất cả các chủ đề"],[1193,""],[1194,"91 Micro-averaging tính toán các chỉ số dựa trên tổng giá trị a, b, c, d của từng chủ đề dựa theo các công thức áp dụng tính cho một chủ đề"],[1195,"Sự khác nhau chủ yếu giữa hai cách tính macro-averaging và micro-averaging là : micro-averaging tính toán dựa trên trọng số của mỗi văn bản, nên cho kết quả trung bình trên mỗi văn bản (per-document average); trong khi đó, macro- averaging tính toán trọng số trên mỗi chủ đề, do đó, kết quả cho sẽ đại diện cho giá trị trung bình trên mỗi chủ đề (per-category average)"],[1196,"6.5.2"],[1197,"Các phương pháp thử nghiệm Ở phần phân loại văn bản, chúng em thử nghiệm 2 công thức đã được trình bày ở 5.3"],[1198,"là công thức phân loại được sử dụng trong [H"],[1199,"Nguyen et al, 2005] (gọi tắt là công thức IClass) và công thức tính Naïve Bayes được cải tiến cho phù hợp với hướng tiếp cận dựa trên Google (gọi tắt là NBClass)"],[1200,"Ứng với công thức phân loại, chúng em thử nghiệm với 2 công thức tính MI: một của [H"],[1201,"Nguyen et al, 2005] (gọi tắt là MI1) và một công thức MI do chúng em đề xuất (gọi tắt là MI3) cho hai trường hợp tách và không tách stopword.Ở phần này chúng em không thử nghiệm với MI2 của [Ong & Chen, 1999] vì kết quả tách từ của công thức này thấp hơn các công thức khác khá nhiều sẽ cho kết quả không tốt"],[1202,"Như vậy tổng cộng chúng em thực hiện 8 lần thử nghiệm phân loại như sau: Công thức IClass + MI1 + tách stop word Công thức IClass + MI1 + không tách stop word Công thức IClass + MI3 + tách stop word Công thức IClass + MI3 + không tách stop word Công thức NBClass + MI1 + tách stop word Công thức NBClass + MI1 + không tách stop word Công thức NBClass + MI3 + tách stop word Công thức NBClass + MI3 + không tách stop word 6.5.3"],[1203,"Kết quả"],[1204,"92 Sau khi thực hiện phân loại văn bản, chúng em sử dụng các độ đo đã được trình bày ở mục 6.5.1"],[1205,"để tính toán kết quả chính xác của các thử nghiệm phân loại"],[1206,"Kết quả tính toán được trình bày trong bảng thống kê sau: Phương pháp Tên chủ đề R P F1 Xã hội 0.62625 0.654047 0.639847 Khoa học 0.72 0.975434 0.828475 Thể thao 0.765 0.968245 0.854706 Kinh doanh 0.795 0.293358 0.428571 Macro 0.763437 0.892427 0.822908 IClass + MI 1 +tách stopword Micro 0.663 0.682801 0.672755 Xã hội 0.764 0.636667 0.694545 Khoa học 0.7216 0.942131 0.81725 Thể thao 0.65625 0.975 0.784483 Kinh doanh 0.816 0.348718 0.488623 Macro 0.814333 0.951923 0.877769 IClass + MI 1 +không tách stopword Micro 0.656 0.672131 0.663968 Xã hội 0.630 0.660 0.645 Khoa học 0.857 0.873 0.865 Thể thao 0.861 0.915 0.887 Kinh doanh 0.630 0.740 0.681 Macro 0.913 0.892 0.903 IClass + MI 3 +tách stopword Micro 0.678 0.700 0.689 Xã hội 0.772 0.784 0.778IClass + MI 3 Khoa học 0.808 0.851 0.829"],[1207,"93 Thể thao 0.882 0.825 0.853 Kinh doanh 0.637 0.523 0.575 Macro 0.858 0.830 0.844 +không tách stopword Micro 0.553 0.566 0.559 Xã hội 0.680 0.738 0.708 Khoa học 0.810 0.841 0.825 Thể thao 0.924 0.918 0.921 Kinh doanh 0.725 0.620 0.668 Macro 0.785 0.779 0.782 NBClass + MI 1 +tách stopword Micro 0.648 0.633 0.640 Xã hội 0.591 0.697 0.640 Khoa học 0.704 0.897 0.789 Thể thao 0.886 0.918 0.902 Kinh doanh 0.675 0.581 0.625 Macro 0.714 0.773 0.742 NBClass + MI 1 +không tách stopword Micro 0.783 0.633 0.700 Xã hội 0.544 0.636 0.586 Khoa học 0.680 0.855 0.757 Thể thao 0.708 1.142 0.874 Kinh doanh 1.404 0.332 0.537 Macro 0.748 0.721 0.734 NBClass + MI 3 +tách stopword Micro 0.725 0.648 0.684 Xã hội 0.611 0.590 0.600 Khoa học 0.485 0.616 0.543 NBClass + MI 3 Thể thao 0.749 1.095 0.890"],[1208,"94 Kinh doanh 0.660 0.739 0.697 Macro 0.626 0.760 0.687 +không tách stopword Micro 0.647 0.647 0.647 Bảng 6"],[1209,"8"],[1210,"Kết quả phân loại văn bản cho từng chủ đề ở cấp 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 I M I1 SW I M I1 No nS W I M I3 SW I M I3 No nS W Ba ye s M I1 SW Ba ye s M I1 No n S W Ba ye s M I3 SW Ba ye s M I3 No nS W Xã hội Khoa học Thể thao Kinh doanh Macro Micro Hình 6"],[1211,"9"],[1212,"Biểu đồ F1 cho cấp 1 Vì kết quả của phần thử nghiệm phân loại ở cấp hai rất dài, nên chúng em chỉ xin trình bày biểu đồ kết quả phân loại mà không trình bày chi tiết bảng kết quả cho từng chủ đề"],[1213,"Sau đây là kết quả phân loại cho các chủ đề cấp 2"],[1214,""],[1215,"95 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 I M I1 SW I M I1 No nS W I M I3 SW I M I3 No nS W Ba ye s M I1 SW Ba ye s M I1 No n S W Ba ye s M I3 SW Ba ye s M I3 No nS W Giáo dục Du học Lối sống Du Lịch Khoa học Bóng đá 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 I M I1 SW I M I1 No nS W I M I3 SW I M I3 No nS W Ba ye s M I1 SW Ba ye s M I1 No n S W Ba ye s M I3 SW Ba ye s M I3 No nS W Quần vợt Bất động sản Chứng khoán Quốc tế Âm nhạc Thời trang"],[1216,"96 0 0.1 0.2 0.3 0.4 0.5 0.6 I M I1 SW I M I1 No nS W I M I3 SW I M I3 No nS W Ba ye s M I1 SW Ba ye s M I1 No n S W Ba ye s M I3 SW Ba ye s M I3 No nS W Điện ảnh Làm đẹp Giới tính macro micro Hình 6"],[1217,"10"],[1218,"Biểu đồ F1 cho cấp 2 6.5.4"],[1219,"Nhận xét Trong hai mức phân loại chủ đề, ta nhận thấy kết quả phân loại ở mức 1 cho độ chính xác cao hơn mức 2"],[1220,"Lý do là vì số lượng chủ đề của cấp 2 nhiều hơn cấp 1 rất nhiều (15 so với 4 ở cấp 1) và một số chủ đề của cấp 2 chưa thực sự tốt như Bất động sản, Lối sống, Làm đẹp, Giới tính"],[1221,"Từ đó, ta thấy được việc xây dựng danh sách từ khoá cho mỗi chủ đề một yêu cầu cần thiết để nâng hiệu suất phân loại văn bản"],[1222,"Dựa vào kết quả thử nghiệm ta nhận thấy rằng trong việc phân loại sử dụng Bayes tốt hơn công thức phân loại của H"],[1223,"Nguyen et al (2005) trong nhiều trường hợp"],[1224,"Trong các thử nghiệm công thức của H.Nguyen et al (2005), độ hỗ trợ của kết quả vào chủ đề đối có giá trị rất gần nhau, khi áp dụng cho các chủ đề hầu như không có sự khác biệt"],[1225,"Trong khi đó, với công thức Naïve Bayes, có một số chủ đề"],[1226,"97 nổi trội hơn hẳn các chủ đề khác và kết quả thống kê cũng cho thấy Naïve Bayes cho kết quả chính xác hơn"],[1227,"Kết quả của thử nghiệm công thức trong [H.Nguyen et al, 2005] với độ chính xác chưa cao lắm bởi vì đấy là công thức do chính tác giả đề nghị chưa dựa trên cơ sở lý thuyết vững chắc"],[1228,"Trong khi đó, phương pháp Naïve Bayes đã xuất hiện khá lâu, được chứng minh trên lý thuyết và thực nghiệm nên độ tin cậy rất cao"],[1229,"Việc sử dụng hướng tiếp cận Naïve Bayes cho phân loại văn bản dựa trên Google có thể nói là bước cải tiến đáng khíck lệ so với cách phân loại cũ"],[1230,"Dựa vào biểu đồ, ta nhận thấy sự kết hợp giữa phương pháp phân loại Naïve Bayes và công thức tính độ tương hỗ (MI) của [H"],[1231,"Nguyen et al, 2005] cho kết quả phân loại tốt nhất"],[1232,"Trong đó, tỉ lệ trung bình của phương pháp cho các chủ đề ở cấp 1 là 75%, và cho các chủ đề ở cấp 2 là 67%"],[1233,"Kết quả này hợp lý vì thực nghiệm cho thấy công thức MI1 của H.Nguyen et al (2005) cho kết quả tách từ chính xác cao nhất nên đã góp phần làm cho kết quả phân loại tốt hơn"],[1234,"Kết quả phân loại văn bản trung bình giữa 8 cặp là 75%, là kết quả chấp nhận được đối với phân loại văn bản tiếng Việt"],[1235,"Kết quả không cao so với kết quả phân loại bằng tiếng Anh bởi vì như chúng ta đã biết phần tách từ tiếng Việt gặp rất nhiều phức tạp"],[1236,""],[1237,"98 CChhưươơnngg 77 ỨỨNNGG DDỤỤNNGG PPHHÂÂNN LLOOẠẠII TTIINN TTỨỨCC ĐĐIIỆỆNN TTỬỬ TTỰỰ ĐĐỘỘNNGG Giới thiệu tòa soạn báo điện tử Tính cần thiết của phân loại tin tức tự động Phân tích hiện trạng Mô hình DFD quan niệm cấp 2 hiện hành cho ô xử lý Nhận bài và Trả bài Phê phán hiện trạng Mô hình DFD quan niệm cấp 2 mới cho ô xử lý Nhận bài và Trả bài Triển khai DLL Chương trình cài đặt \u201cTòa soạn báo điện tử\u201d đã tích hợp module phân loại tin tức Kết quả"],[1238,"99 Chương 7"],[1239,"ỨNG DỤNG PHÂN LOẠI TIN TỨC ĐIỆN TỬ TỰ ĐỘNG Nhằm đánh giá hiệu quả thực tế của việc phân loại sử dụng IGATEC và Naïve Bayes, chúng em đã xây dựng công cụ phân loại thành một module đồng thời tích họp vào trong tòa soạn báo điện tử"],[1240,"Trong chương này, chúng em sẽ giới thiệu sơ lược về tòa soạn báo điện tử và mô tả cách thức tích hợp module phân loại"],[1241,"7.1"],[1242,"Giới thiệu tòa soạn báo điện tử Phần mềm tòa soạn báo điện tử (Luận văn khóa 2000-Hoàng Minh Ngọc và Nguyễn Duy Hiệp) xây dựng trên nền tảng DotNetNuke tuân thủ theo qui trình của một tòa soạn thực tế đi từ soạn bài, duyệt bài và đăng bài"],[1243,"Mỗi biên tập viên sẽ phụ trách một mảng chủ đề"],[1244,"Cộng tác viên hay người dùng sau khi viết bài phải được biên tập viên duyệt"],[1245,"Nếu nội dung và hình thức chấp nhận được thì bài được chuyển lên vị trí có chức năng đưa bài lên website chính thức"],[1246,"Người quản trị sẽ phân công chuyên mục và chủ đề cho các biên tập viên"],[1247,"Nếu đã qua các cấp kiểm duyệt, bài viết được phép đưa lên website"],[1248,"Nếu tại một cấp nào đó, người quản lý thấy bài viết cần được chỉnh sửa thì bài viết sẽ được trả về đúng cấp có thẩm quyền"],[1249,"Ngoài ra, tòa soạn báo điên tử còn hỗ trợ việc thu thập tin tức điện tử từ nhiều nguồn khác nhau"],[1250,"Tin tức được tải về sau đó phải được các biên tập viên xác định chủ đề và chuyên mục mà bài báo thuộc về để tiến hành thủ tục đăng bài"],[1251,"Việc phân loại tin tức ở giai đoạn thực hiện luận văn này là hoàn toàn thủ công"],[1252,"7.2"],[1253,"Tính cần thiết của phân loại tin tức tự động Việc thực hiện phân loại thủ công trên số lương lớn các tin tức được tải về có thể ngốn rất nhiều thời gian và công sức"],[1254,"Nhằm làm tăng tính hiệu quả cũng như hỗ trợ tối đa cho các biên tập viên tập trung vào các công việc khác quan trọng hơn"],[1255,"Module phân loại tin tức tự động đã được xây dựng"],[1256,"Nhiệm vụ của module này là thực hiện phân loại tự động các tin tức tải về nhằm đề xuất sắp xếp tin tức này vào một chuyên mục hợp lý"],[1257,"Module được viết dưới dạng một thư viện dll thực hiện các"],[1258,"100 công việc như sau: lấy các tin tức được tải về, tiến hành phân loại và cập nhật vào cơ sở dữ liệu"],[1259,"7.3"],[1260,"Phân tích hiện trạng Mục đích của luận văn chúng em là tích hợp phần xử lý phân loại trang web tự động vào phần duyệt bài viết và sửa bài viết nên chúng em chỉ trình bày mô hình DFD cho ô xử lý \u201cNhận bài và Trả bài\u201d"],[1261,"Để tìm hiểu về toàn cảnh mô hình DFD của toà soạn báo điện tử, xin tham khảo luận văn \u201cToà soạn báo điện tử\u201d của Hoàng Minh Ngọc Hải (0012545), Nguyễn Duy Hiệp (0012038)) 7.3.1"],[1262,"Mô hình DFD quan niệm cấp 2 hiện hành cho ô xử lý Nhận bài và Trả bài 7.3.1.1"],[1263,"Mô hình Hình 7"],[1264,"1.Mô hình DFD hiện hành 7.3.1.2"],[1265,"Mô tả mô hình Thành viên có chức năng viết bài nhận bài viết mới được giao, sau khi hoàn thành thì lưu xuống kho dữ liệu những bài viết chưa đăng để chờ duyệt"],[1266,"Sau khi bài viết được duyệt, thành viên kiểm tra xem bài viết có cần chỉnh sửa không, nếu có thì"],[1267,"101 thực hiện chỉnh sửa sau đó lưu phiên bản mới của bài viết chờ duyệt tiếp"],[1268,"Ngoài ra, các bài báo được lấy tự động từ Internet xuống cũng được lưu trong kho dữ liệu các bài viết chưa đăng để chờ duyệt"],[1269,"7.3.1.2.1"],[1270,"Mô tả kho dữ liệu Hệ thống thông tin: Xây dựng toà soạn báo điện tử Mô hình quan niệm xử lý Hiện tại [] Tương lai[] Trang : Ứng dụng : Xây dựng toà soạn báo điện tử Mô tả kho dữ liệu : NHỮNG BÀI VIẾT CHƯA ĐƯỢC ĐĂNG Tờ : Ngày lập : 28/6/2004 Người lập : 1"],[1271,"Hoàng Minh Ngọc Hải 2"],[1272,"Nguyễn Duy Hiệp Dòng dữ liệu vào : Bài viết đã chỉnh sửa Bài viết mới Dòng dữ liệu ra : Bài viết cần chỉnh sửa Diễn giải : Kho này lưu trữ những bài viết đang nằm trong dây chuyền Cấu trúc dữ liệu: MA_BAI_VIET MA_CHUYEN_MUC MA_TAC_GIA"],[1273,"102 NGAY_VIET TIEU_DE NOI_DUNG DUONG_DAN_ANH KICH_THUOC_ANH CHIEU_DAI CHIEU_RONG Khối lượng : - Hiện tại : Không xác định - Tương lai : Không xác định Thông tin thường truy xuất : MA_BAI_VIET MA_CHUYEN_MUC TIEU_DE NOI_DUNG Bảng 7"],[1274,"1"],[1275,"Bảng kho dữ liệu những bài viết chưa được đăng 7.3.1.2.2"],[1276,"Mô tả ô xử lý Ô xử lý Tên Dòng dữ liệu vào Dòng dữ liệu ra Diễn giải (1.1) Nhận bài viết mới Bài viết Bài viết mới Phóng viên sau khi viết một bài mới sẽ gửi vào hệ thống"],[1277,"Những bài viết này được lưu dưới dạng những bài viết chưa được xử lý"],[1278,"(1.2) Lưu bài viết mới Bài viết mới Bài viết mới Lưu bài viết dưới tình trạng \u201cChưa xử lý\u201d"],[1279,"103 (1.3) Kiểm tra những bài viết cần xử lý Nhu cầu kiểm tra Thông tin cá nhân Bài viết cần chỉnh sửa Kiểm tra các bài viết đã được duyệt xem có cần chỉnh sửa không (1.4) Nhận bài viết đã chỉnh sửa Bài viết đã chỉnh sửa Bài viết đã chỉnh sửa Bài viết sau khi thành viên (có chức năng chỉnh sửa) duyệt, chỉnh sửa và trả lại cho thành viên phụ trách bài viết đó"],[1280,"(1.5) Lưu phiên bản mới của bài viết Bài viết đã chỉnh sửa Bài viết đã chỉnh sửa Bài viết đã chỉnh sửa được lưu vào CSDL dưới tình trạng \u201cĐã xử lý\u201d tại cấp vừa chỉnh sửa và dưới tình trạng \u201cChưa xử lý\u201d tại cấp được chuyển bài về (1.6) Lấy tin tự động Tin tức điện tử Tin tức điện tử Hệ thống tự động lấy tin tức từ các trang báo khác và lưu xuống kho dữ liệu Bảng 7"],[1281,"2"],[1282,"Bảng mô tả các ô xử lý của mô hình DFD hiện hành 7.3.2"],[1283,"Phê phán hiện trạng Hiện tại, hệ thống tự động lấy tin tức từ các trang báo điện tử khác về và gán vào các mục đã được chỉ định sẵn"],[1284,"Tuy nhiên, việc chỉ định chủ đề cho các tin tức lấy về một cách cứng nhắc chỉ đúng trong trường hợp trang web lấy tin có cấu trúc chủ đề tương ứng với chủ đề trong toà soạn báo điện tử của mình"],[1285,"Đối với những trang báo có cấu trúc khác đi, việc gán nhãn mặc định cho các bài báo sẽ không còn đúng nữa"],[1286,"Ví dụ ở toà soạn báo điện tử của chúng ta có mục Kinh doanh\\Quốc tế, còn ở báo www.vnexpress.net có mục Thế giới bao gồm nhiều nội dung, trong đó có một số tin tức về Kinh doanh quốc tế, một số tin tức về chính trị thế giới, một số bài về văn hoá chẳng hạn"],[1287,"Như vậy nếu ta chỉ định các bài báo lấy từ mục tin Thế giới ở www.vnexpress.net đều được xếp vào mục Kinh doanh\\Quốc tế thì kết quả không còn đúng hoàn toàn nữa"],[1288,"Lúc đó, các thành viên duyệt bài lại phải đọc lần lượt các"],[1289,"104 bài báo được lấy về một cách thủ công để phân loại chủ đề của tin tức cho phù hợp với cấu trúc chủ đề của mình"],[1290,"Để hạn chế trường hợp trên, chúng em đưa ra giải pháp là tích hợp module phân loại văn bản vào việc xử lý lấy tin tự động từ Internet"],[1291,"Các tin tức vừa được lấy về sẽ được module phân loại văn bản phân loại tự động vào các chủ đề có sẵn của toà soạn báo"],[1292,"Như vậy, chúng ta sẽ tiết kiệm được nhiều công sức và thời gian duyệt bài của các thành viên một cách đáng kể"],[1293,"7.3.3"],[1294,"Mô hình DFD quan niệm cấp 2 mới cho ô xử lý Nhận bài và Trả bài 7.3.3.1"],[1295,"Mô hình Hình 7"],[1296,"2"],[1297,"Mô hình DFD cải tiến 7.3.3.2"],[1298,"Mô tả mô hình Mô hình mới chỉ thêm một ô xử lý việc phân loại tin tức tự động sau khi hệ thống lấy tin tức từ trang web khác về"],[1299,""],[1300,"105 7.3.3.2.1"],[1301,"Mô tả ô xử lý Ô xử lý Tên Dòng dữ liệu vào Dòng dữ liệu ra Diễn giải (1.7) Phân loại tin tức tự động Tin tức điện tử Tin tức điện tử đã phân loại Module phân loại văn bản mới tích hợp vào hệ thống thực hiện phân loại tự động các tin tức vừa lấy về"],[1302,"Bảng 7"],[1303,"3"],[1304,"Bảng mô tả ô xử lý phân loại tin tức tự động 7.4"],[1305,"Triển khai DLL Chương trình phân loại văn bản tự động được viết trên ngôn ngữ C#, trong khi \u201cTòa soạn báo điện tử\u201d của luận văn khóa 2000 được viết mã trên nền VB.Net"],[1306,"Do đó, để tích hợp hai hệ thống lại, chúng em đã xây dựng các thành phần chính dùng trong phân loại văn bản thành DLL"],[1307,"Có thể nói, việc đóng gói chương trình thành dạng DLL ngoài tính tiện lợi trong việc tích hợp giữa các hệ thống xây dựng trên các ngôn ngữ khác nhau, goíi DLL còn có ưu điểm là khả năng sử dụng đơn giản, dễ mang chuyển, là yếu tố quan trọng trong việc xây dựng chương trình"],[1308,"\u201cTòa soạn báo điện tử\u201d của luận văn khóa 2000 được xây dựng khá công phu về mặt hình thức lẫn nội dung, cho nên khi tích hợp DLL mới vào, chúng em nhận thấy không cần thiết phải thiết lập thêm giao diện nào nữa"],[1309,"Chúng em chỉ tạo thêm một số lựa chọn cho người dụng có thể bật tắt chức năng phân loại"],[1310,""],[1311,"106 Hình 7"],[1312,"3"],[1313,"Màn hình lấy tin tức cho phép phân loại tự động 7.5"],[1314,"Chương trình cài đặt \u201cTòa soạn báo điện tử\u201d đã tích hợp module phân loại tin tức \u201cTòa soạn báo điện tử\u201d của luận văn khóa 2000 hiện tại chưa xây dựng công cụ cài đặt vài gỡ chương trình tự động (Install và Uninstall), đòi hỏi người dùng phải có nhiều kiến thức về SQL Server để có thể cài đặt cơ sở dữ liệu một cách thủ công"],[1315,"Vì vậy, nhằm tăng thêm tính tiện dụng của \u201cTòa soạn báo điện tử\u201d, chúng em tự xây dựng công cụ cài đặt tự động \u201cTòa soạn báo điện tử\u201d vào máy chỉ với thao tác click chuột"],[1316,"Công cụ cài đặt thực hiện việc thiết lập cơ sở dữ liệu vào hệ quản trị SQL Server, thư mục ảo chứa nội dung trang web trong IIS, và tạo shorcut trên desktop"],[1317,"Một số giao diện của công cụ cài đặt:"],[1318,"107 Hình 7"],[1319,"4"],[1320,"Màn hình bắt đầu"],[1321,"Click Next để bắt đầu cài đặt Hình 7"],[1322,"5.Màn hình chọn chế độ cài đặt hoặc tháo gỡ chương trình"],[1323,"Chọn Install và click Next để sang bước tiếp theo"],[1324,"108 Hình 7"],[1325,"6.Màn hình chọn đường dẫn để cài đặt chương trình"],[1326,"Sau khi chọn xong các đường dẫn phù hợp, nhấp vào Next để thực hiện cài đặt"],[1327,"Hình 7"],[1328,"7.Màn hình cài đặt chương trình"],[1329,"109 Hình 7"],[1330,"8.Màn hình chọn chức năng gỡ chương trình"],[1331,"Chọn Remove để gỡ chương trình đã cài đặt trên máy"],[1332,"Hình 7"],[1333,"9.Màn hình gỡ chương trình thành công"],[1334,"110 7.6"],[1335,"Kết quả Nhờ việc tích hợp module phân loại văn bản vào trong web \u201cTòa soạn báo điện tử\u201d mà giờ đây công việc phân loại tin tức điện tử đã trở nên nhanh chóng và tiện lợi hơn"],[1336,"Tuy xác suất phân loại đúng chưa đảm bảo cho hệ thống phân loại văn bản hoàn toàn tự động, mà cần có sự duyệt bài lại để đảm bào chính xác hoàn toàn, nhưng module phân loại văn bản bán tự động cũng đã cung cấp cho người dùng một tiện ích vô cùng hữu hiệu"],[1337,""],[1338,"111 CChhưươơnngg 88 TTỔỔNNGG KKẾẾTT Kết quả đạt được Về mặt lý thuyết Về mặt thực hành Hạn chế và hướng giải quyết Kết luận"],[1339,"112 Chương 8"],[1340,"TỔNG KẾT 8.1"],[1341,"Kết quả đạt được 8.1.1"],[1342,"Về mặt lý thuyết Phân loại văn bản là một bài toán khó và rất thú vị"],[1343,"Khó bởi vì vấn đề phân loại văn bản cần phải thực hiện xử lý ngôn ngữ, mà như chúng ta đều biết, ngôn ngữ tự nhiên là muôn hình vạn trạng, không chỉ phong phú về từ vựng, cú pháp mà còn phức tạp về ngữ nghĩa"],[1344,"Nhưng đây lại là bài toán rất thú vị vì với mỗi ngôn ngữ khác nhau, chúng ta phải thực hiện những cách xử lý khác nhau đối với ngôn ngữ"],[1345,"Trong khuôn khổ luận văn này, những vấn đề liên quan đến đề tài như các phương pháp tách từ và phương pháp phân loại văn bản đã được chúng em tiến hành nghiên cứu khá công phu theo cả chiều rộng lẫn chiều sâu về"],[1346,"Trên cơ sở nghiên cứu đó, các hướng tiếp cận áp dụng cho tiếng Anh và tiếng Hoa phù hợp đã được lựa chọn và thử nghiệm lên tiếng Việt"],[1347,"Đặc biệt, ở giai đoạn tách từ chuẩn bị cho phân loại, chúng em đã tìm hiểu một cách sâu sắc về hướng thống kê dựa trên Internet"],[1348,"Dựa trên nền tảng đó, chúng em mạnh dạn thực hiện cải tiến phương pháp tách từ dựa trên Internet và thuật toán di truyền thay vì sử dụng lại các công cụ tách từ tiếng Việt đã được công bố trước đây"],[1349,"Hướng tiếp cận mới này không những hạn chế được nhược điểm phụ thuộc vào tập ngữ liệu của các phương pháp khác mà còn đem lại khả năng khai thác vô tận nguồn dữ liệu khổng lồ của nhân loại : word-wide-web"],[1350,"Kết quả đạt được của phương pháp này là hoàn toàn khả quan và chấp nhận được đối với một hướng tiếp cận mới cho tách từ tiếng Việt dùng trong phân loại văn bản"],[1351,"Phương pháp phân loại văn bản Naïve Bayes thường được dùng trong phân loại văn bản tiếng Anh, nay được áp dụng trong tiếng Việt với hướng tiếp cận dựa trên thống kê từ Google tỏ ra khá hiệu bởi"],[1352,"Nhờ tính đơn giản, các thông số tính toán không cần quá lớn như các phương pháp khác, khả năng linh hoạt đối với sự thay đổi về thông tin huấn luyện, thời gian phân loại phù hợp yêu cầu, Naïve Bayes đã tở ra rất phù hợp với các yêu cầu đề ra"],[1353,""],[1354,"113 8.1.2"],[1355,"Về mặt thực nghiệm Công trình nghiên cứu của luận văn đã thực hiện được nhiều thử nghiệm đối với từng hướng tiếp cận tách từ tiếng Việt dựa trên Google cũng như phân loại văn bản"],[1356,"Nhờ vậy, kết quả thực nghiệm đã chứng minh được tính hiệu quả cho các công thức trên lý thuyết"],[1357,"Qua kết quả thực nghiệm, chúng em nhận thấy công thức tách từ của [H"],[1358,"Nguyen et al, 2005] và công thức MI do chúng em đề nghị cho hiệu quả gần tương đương nhau, tuy cách tính của [H"],[1359,"Nguyen et al, 2005] có vẻ chính xác hơn cho các từ có hai tiếng"],[1360,"Kết quả thực nghiệm ở phần phân loại văn bản cho thấy công thức phân loại trong [H"],[1361,"Nguyen et al, 2005] là mang tính chủ quan của tác giả, và dữ liệu thực nghiệm không đủ lớn để có thể kết luận"],[1362,"Nhưng khi áp dụng thử nghiệm trên số lượng văn bản và chủ đề nhiều hơn thì cách tính này cho ra kết quả thấp hơn nhiều so với kết quả mà tác giả trình bày"],[1363,"Kết quả sử dụng công thức Naïve Bayes đã cho kết quả khả quan hơn nhờ dựa vào lý thuyết đã được chứng minh từ các công trình trước"],[1364,"8.2"],[1365,"Hạn chế và hướng phát triển Với những kết quả thử nghiệm ban đầu, hệ thống phân loại văn bản đã bước đầu hoạt động hiệu quả , góp phần thực hiện phân loại văn bản bán tự động, giúp tiết kiệm được thời gian và công sức đọc văn bản một cách thủ công"],[1366,"Mặc dù những kết quả của hệ thống là chấp nhận được, tuy nhiên hệ thống có thể được cải thiện về độ chính xác và tốc độ nếu ta khắc phục một số hạn chế của hệ thống và thực hiện thêm các hướng mở rộng khác được trình bày sau đây"],[1367,"Phương pháp tách từ dựa trên Internet và thuật toán di truyền tỏ ra khá linh hoạt trong việc xử lý ngôn ngữ"],[1368,"Tuy nhiên với mặt bằng chất lượng Internet hiện nay ở Việt Nam, bước đầu thực hiện việc tách từ sẽ khá lâu vì phải mất thời gian lấy thông tin từ công cụ tìm kiếm trên mạng"],[1369,"Nhưng khi các thông tin trên được lưu lại tương đối lớn, tốc độ phân định ranh giới từ sẽ được cải thiện"],[1370,""],[1371,"114 Trong phần thử nghiệm phân loại văn bản, hiện tại chúng em quy định một chủ đề chỉ có một từ khóa chính là tên của chủ đề đó"],[1372,"Chính đây là một điểm hạn chế dẫn đến kết quả phân loại văn bản chưa cao như trong các công trình phân loại văn bản tiếng Anh"],[1373,"Do vậy, nhu cầu xây dựng một công cụ chiết xuất từ khóa tự động từ tập dữ liệu tin tức thô là rất cần thiết"],[1374,"Khi đã có tập từ khóa, độ chính xác của việc phân loại văn bản sẽ tăng lên đáng kể"],[1375,"Hiện tại, luận văn thực hiện phân loại theo hướng tiếp cận Naïve Bayes với các từ được tách trong câu mà không có sự chọn lựa những từ đặc trưng để thực hiện phân loại"],[1376,"Điều này dẫn đến một số từ không có ý nghĩa phân loại vẫn xem như có vai trò tương tự như những từ có ý nghĩa phân loại cao"],[1377,"Nếu chúng ta nghiên cứu thực hiện chọn lựa các đặc trưng của văn bản (feature selection) rồi mới"]],"downloaded":true,"m":[-1,-1],"n":"Tim hieu cac huong tiep can bai toan phan loai van ban va xa.txt","o":"TRƯỜNG ĐẠI HỌC KHOA HỌC TỰ NHIÊN "}],"t":"\nTRƯỜNG ĐẠI HỌC BÁCH KHOA HÀ NỘI \n\nVIỆN CÔNG NGHỆ THÔNG TIN VÀ TRUYỀN THÔNG \n\n──────── * ──────── \n\n \n\n \n\nĐỒ ÁN \n\nTỐT NGHIỆP ĐẠI HỌC \nNGÀNH CÔNG NGHỆ THÔNG TIN \n\n \n\n \n\nTÓM TẮT VĂN BẢN HƯỚNG TRUY VẤN \n\n \n\n \n\n\nLớp       : HTTT-K53 \n\nGiáo viên hướng dẫn :  PGS.TS Lê Thanh Hương \n\n \n\n \n\n \n\n \n\n \n\n \n\nHÀ NỘI, 5-2013  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 2 \n\n   \n\nPHIẾU GIAO NHIỆM VỤ ĐỒ ÁN TỐT NGHIỆP \n\n1. Thông tin về sinh viên \n\nHọ và tên sinh viên: Hoàng Đức Thọ \n\nĐiện thoại liên lạc: 0988238277  Email: hoangtho2010@gmail.com \n\nLớp: Hệ thống thông tin K53   Hệ đào tạo: Kỹ sư \n\nĐồ án tốt nghiệp được thực hiện tại: Trường ĐHBK Hà Nội \n\nThời gian làm ĐATN: Từ ngày  01/01/2013  đến 01/05/2013 \n\n2. Mục đích nội dung của ĐATN \n\nĐề xuất và thử nghiệm phương pháp tóm tắt văn bản hướng truy vấn cho tiếng Việt, \n\náp dụng cho đơn văn bản. \n\n3. Các nhiệm vụ cụ thể của ĐATN \n\n- Tìm hiểu về tóm tắt văn bản tự động \n\n- Đề xuất và phân tích các bước thực hiện một mô hình tóm tắt văn bản hướng truy \n\nvấn cho tiếng Việt \n\n- Cài đặt chương trình thử nghiệm và đánh giá kết quả \n\n4. Lời cam đoan của sinh viên: \n\nTôi \u2013 Hoàng Đức Thọ - cam kết ĐATN là công trình nghiên cứu của bản thân tôi \n\ndưới sự hướng dẫn của PGS.TS Lê Thanh Hương. Các kết quả nêu trong ĐATN là trung \n\nthực, không phải là sao chép toàn văn của bất kỳ công trình nào khác. \n\nHà Nội, ngày 19 tháng 5 năm 2013 \n\n    Tác giả ĐATN   \n\n \n\nHoàng Đức Thọ   \n\n5. Xác nhận của giáo viên hướng dẫn về mức độ hoàn thành của ĐATN và cho phép \n\nbảo vệ: \n\n \n\n \n\n \n\nHà Nội, ngày     tháng     năm   \n\nGiáo viên hướng dẫn   \n\n \n\n  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 3 \n\n   \n\n \n\nLỜI CẢM ƠN \n\nTrong thời gian học tập tại trường Đại học Bách khoa Hà Nội, em đã học hỏi được \n\nrất nhiều kiến thức bổ ích từ các thầy cô giáo, đặc biệt là các thầy cô trong viện Công \n\nnghệ thông tin và Truyền thông. Thầy cô đã trang bị cho em rất nhiều kiến thức quý \n\nbáu, đó cũng như là hành trang và nền tảng để em vững bước hơn khi vào môi trường \n\nlàm việc đầy thử thách ngoài xã hội. \n\nEm xin gửi lời cảm ơn chân thành tới các thầy cô trong viện, đặc biệt là cô Lê \n\nThanh Hương, người đã tận tình hướng dẫn em trong thời gian thực hiện đồ án này.  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 4 \n\n   \n\nTÓM TẮT NỘI DUNG ĐỒ ÁN TỐT NGHIỆP \n\nNgày nay, việc truy cập thông tin qua mạng internet đã trở nên rất phổ biến. Tuy nhiên \n\nvới lượng thông tin khổng lồ và tăng lên nhanh chóng mỗi ngày, con người không đủ thời \n\ngian và sức lực đọc hết các tài liệu để tìm thông tin cần thiết cho mình. Tóm tắt văn bản \n\nhướng truy vấn là giải pháp cho vấn đề đó, đây là một dạng đặc biệt của bài toán tóm tắt văn \n\nbản tự động mà văn bản sẽ được tóm tắt theo mong muốn của người sử dụng. \n\nTrong đồ án này em đề xuất và thử nghiệm một phương pháp tóm tắt văn bản hướng \n\ntruy vấn dành cho các văn bản tiếng Việt dựa trên tần số từ và độ tương đồng câu. Nội dung \n\ncủa đồ án gồm 3 phần chính sau: \n\n- Phần 1. Đặt vấn đề và định hướng giải quyết: Mô tả bài toán, tìm hiểu tóm tắt \n\nvăn bản, tóm tắt hướng truy vấn, đề xuất hướng giải quyết cho tiếng Việt. \n\n- Phần 2: Giải quyết vấn đề: Phân tích chi tiết các bước thực hiện mô hình, xây \n\ndựng các công cụ và kiểm thử trên tập mẫu. \n\n- Phần 3: Kết luận và đề xuất: Đánh giá các phần đã làm được, các tồn tại, đề xuất \n\nhướng phát triển. \n\nKết quả kiểm thử cho thấy mô hình này cho kết quả tương đối chính xác, tốc độ xử lý \n\nnhanh, có thể cài đặt sử dụng trong thực tế. \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 5 \n\n   \n\nMục lục \n\nDANH MỤC CÁC BẢNG .......................................................................................... 8 \n\nDANH MỤC CÁC HÌNH VẼ..................................................................................... 9 \n\nDANH MỤC TỪ VIẾT TẮT .................................................................................... 10 \n\nMỞ ĐẦU ................................................................................................................... 11 \n\n1. Lý do chọn đề tài ........................................................................................... 11 \n\n2. Phạm vi nghiên cứu ....................................................................................... 11 \n\n3. Tóm tắt báo cáo ............................................................................................. 11 \n\nPHẦN 1. ĐẶT VẤN ĐỀ VÀ ĐỊNH HƯỚNG GIẢI QUYẾT ................................. 13 \n\nI. ĐẶT VẤN ĐỀ ................................................................................................... 13 \n\nII. TỔNG QUAN VỀ TÓM TẮT VĂN BẢN TỰ ĐỘNG .................................... 13 \n\n2.1. Định nghĩa ................................................................................................... 13 \n\n2.2. Các tiêu chí đánh giá ................................................................................... 13 \n\n2.3. Ứng dụng của tóm tắt văn bản ..................................................................... 14 \n\n2.4. Phân loại tóm tắt văn bản ............................................................................ 14 \n\n2.4.1. Theo đầu vào hệ thống ...................................................................... 14 \n\n2.4.2. Theo đầu ra hệ thống ......................................................................... 14 \n\n2.4.3. Theo mục đích tóm tắt ....................................................................... 14 \n\n2.5. Mô hình biểu diễn văn bản .......................................................................... 15 \n\n2.5.1. Mô hình boolean ................................................................................ 15 \n\n2.5.2. Mô hình không gian vector ............................................................... 15 \n\n2.5.3. Mô hình tập thô dung sai ................................................................... 17 \n\n2.6. Mô hình tóm tắt văn bản .............................................................................. 17 \n\n2.7. Các phương pháp áp dụng trong các pha .................................................... 18 \n\n2.7.1. Pha Phân tích ..................................................................................... 18 \n\n2.7.1.1. Phương pháp thống kê ................................................................... 18 \n\n2.7.1.2. Phương pháp cấu trúc .................................................................... 19 \n\n2.7.2. Pha Biến đổi ...................................................................................... 20 \n\n2.7.2.1. Giản lược về cấu trúc câu .............................................................. 20 \n\n2.7.2.2. Giản lược về mặt ngữ nghĩa .......................................................... 20 \n\n2.7.3. Pha Hiển thị ....................................................................................... 21 \n\n2.7.3.1. Phương pháp hiển thị phân đoạn ................................................... 21 \n\n2.7.3.2. Phương pháp hiển thị liên kết ........................................................ 21 \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 6 \n\n   \n\n2.8. Đánh giá kết quả tóm tắt .............................................................................. 21 \n\n2.8.1. Sử dụng so khớp n-gram ................................................................... 22 \n\n2.8.2. Sử dụng các độ đo ROUGE .............................................................. 22 \n\n2.9. Một số hệ thống tóm tắt văn bản tiêu biểu .................................................. 22 \n\nIII. BÀI TOÁN TÓM TẮT VĂN BẢN HƯỚNG TRUY VẤN ......................... 24 \n\n3.1. Định nghĩa ................................................................................................... 24 \n\n3.2. Ứng dụng của bài toán ................................................................................. 24 \n\n3.3. Một số hướng tiếp cận phổ biến .................................................................. 24 \n\n3.3.1. Dựa trên đồ thị ................................................................................... 24 \n\n3.3.2. Dựa trên cấu trúc diễn ngôn .............................................................. 25 \n\n3.3.3. Dựa trên tần số từ và độ tương đồng câu .......................................... 25 \n\n3.4. Đề xuất hướng giải quyết cho tiếng Việt ..................................................... 25 \n\nPHẦN 2. GIẢI QUYẾT VẤN ĐỀ ............................................................................ 28 \n\nI. PHÂN TÍCH MÔ HÌNH THỰC HIỆN BÀI TOÁN ........................................ 28 \n\n1.1. Giai đoạn phân tích ...................................................................................... 29 \n\n1.1.1. Chuẩn hóa .......................................................................................... 29 \n\n1.1.2. Tách câu, tách từ ................................................................................ 29 \n\n1.1.3. Loại bỏ từ dừng ................................................................................. 30 \n\n1.1.4. Xử lý từ đồng nghĩa ........................................................................... 31 \n\n1.1.5. Mô hình hóa văn bản ......................................................................... 32 \n\n1.1.6. Chọn câu phù hợp tạo tóm tắt............................................................ 32 \n\n1.2. Giai đoạn hiển thị ........................................................................................ 34 \n\nII. CÀI ĐẶT THỬ NGHIỆM ................................................................................ 35 \n\n2.1. Chương trình thử nghiệm ............................................................................ 35 \n\n2.1.1. Các công cụ đã xây dựng................................................................... 35 \n\n2.1.1.1. Chương trình tóm tắt ...................................................................... 35 \n\n2.1.1.2. Công cụ tạo tập mẫu ...................................................................... 35 \n\n2.1.1.3. Công cụ kiểm thử ........................................................................... 36 \n\n2.2. Thử nghiệm một văn bản ............................................................................. 37 \n\n2.2.1. Đầu vào .............................................................................................. 37 \n\n2.2.2. Kết quả tóm tắt .................................................................................. 38 \n\n2.2.3. Nhận xét............................................................................................. 38 \n\n2.3. Thử nghiệm trên tập mẫu ............................................................................. 38 \n\n2.3.1. Dữ liệu thử nghiệm ............................................................................ 38 \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 7 \n\n   \n\n2.3.2. Độ đo BLEUS ................................................................................... 39 \n\n2.3.3. Kết quả thử nghiệm ........................................................................... 40 \n\n2.3.4. Nhận xét, đánh giá mô hình............................................................... 41 \n\nPHẦN 3. KẾT LUẬN VÀ ĐỀ XUẤT ...................................................................... 42 \n\n1. Các công việc đã thực hiện được .................................................................. 42 \n\n2. Đề xuất hướng phát triển ............................................................................... 42 \n\nTÀI LIỆU THAM KHẢO ......................................................................................... 43 \n\n \n\n  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 8 \n\n   \n\nDANH MỤC CÁC BẢNG \n\n \n\nBảng 1: Ví dụ một số từ dừng ................................................................................... 31 \n\nBảng 2: Một số mục từ đồng nghĩa ........................................................................... 32 \n\nBảng 3: Thông tin tập mẫu sử dụng để đánh giá ...................................................... 39 \n\nBảng 4: Ví dụ về n-gram ........................................................................................... 39 \n\nBảng 5: Kết quả kiểm thử độ đo BLEUS của tập mẫu ............................................. 40 \n\n  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 9 \n\n   \n\nDANH MỤC CÁC HÌNH VẼ \n\n \n\nHình 1: Mô hình chung của tóm tắt văn bản ............................................................. 17 \n\nHình 2: Mô hình tóm tắt văn bản trích rút ................................................................ 18 \n\nHình 3: Mô hình tóm tắt văn bản hướng truy vấn ..................................................... 28 \n\nHình 4: Minh họa quá trình chọn câu quan trọng ..................................................... 33 \n\nHình 5: Giao diện chương trình demo ...................................................................... 35 \n\nHình 6: Chương trình quản lý tập mẫu ..................................................................... 36 \n\nHình 7: Giao diện chương trình kiểm thử ................................................................. 36 \n\n  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 10 \n\n   \n\nDANH MỤC TỪ VIẾT TẮT \n\n \n\nViết tắt Ý nghĩa \n\nVSM Vector Space Model \n\nTF.IDF Term Frequency. Inverse Document Frequyency \n\nTF.ISF Term Frequency. Inverse Sentence Frequyency \n\nDUC Document Understanding Conferences \n\nTAC Text Analysis Conference \n\n   \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 11 \n\n   \n\nMỞ ĐẦU \n\n1. Lý do chọn đề tài \n\nNgày nay, sự phát triển nhanh chóng của công nghệ thông tin cùng các thiết bị sử \n\ndụng, việc chia sẻ, truy cập thông tin qua internet đã trở nên rất phổ biến. Mỗi ngày, \n\nvô số thông tin về tình hình kinh tế, xã hội, kinh nghiệm sống, học tập, làm việc\u2026 \n\nđược chia sẻ trên các báo mạng, diễn đàn... Tuy nhiên do lượng thông tin rất lớn hơn \n\nnữa còn trùng lặp, dư thừa nhiều, nên con người không đủ thời gian và công sức duyệt \n\nhết các văn bản để tìm thông tin hữu ích cho mình. Do đó, cần các hệ thống tổng hợp \n\nthông tin một cách ngắn gọn, chính xác, liên quan đến vấn đề mà người dùng quan \n\ntâm. Giải pháp cho vấn đề này là bài toán Tóm tắt văn bản hướng truy vấn, một dạng \n\ncủa bài toán tóm tắt văn bản tự động. \n\nBài toán tóm tắt văn bản tự động vô cùng phức tạp nhưng rất hữu dụng, do đó đã \n\ncó nhiều công ty lớn, các nhà khoa học, nhóm nghiên cứu đầu tư thời gian và tiền bạc \n\nđể tìm ra các hướng giải quyết hiệu quả nhất. Các hội nghị nổi tiếng liên quan đến \n\ntóm tắt văn bản như: DUC(2001-2007), TAC(2008), ALC(2001-2007)\u2026 đã đưa ra \n\nrất nhiều kết quả phân tích và các giải pháp hữu ích. Một số hệ thống tóm tắt văn bản \n\nđã được ứng dụng vào thực tế và cho thấy lợi ích của nó như MEAD, LexRank, \n\nAutoSummarize trong Microsoft Office Word\u2026 Đối với tóm tắt hướng truy vấn, \n\ncũng có rất nhiều công trình nghiên cứu, ứng dụng, chủ yếu là sử dụng trong các máy \n\ntìm kiếm hoặc hệ thống hỏi đáp tự động. \n\nTuy nhiên các công trình đó phần lớn dành cho tiếng Anh, với tiếng Việt thì chưa \n\ncó nhiều nghiên cứu, vì thế trong đồ án này, em xin chọn đề tài \u201cTóm tắt văn bản \n\nhướng truy vấn\u201d. Với mục đích tìm hiểu quy trình tóm tắt văn bản và các vấn đề liên \n\nquan, tổng hợp một số kỹ thuật sử thường sử dụng trong tóm tắt văn bản, dựa vào đó \n\nđề xuất, cài đặt thử nghiệm một hướng tiếp cận phù hợp với bài toán tóm tắt đơn văn \n\nbản hướng truy vấn cho tiếng Việt. \n\n2. Phạm vi nghiên cứu \n\n Các vấn đề xoay quan tóm tắt văn bản \n\n Một số hướng tiếp cận tóm tắt văn bản hướng truy vấn \n\n Thực hiện một phương pháp tóm tắt trích rút, đơn văn bản, hướng truy vấn \n\nphù hợp với tiếng Việt \n\n3. Tóm tắt báo cáo \n\nNội dung của báo cáo bao gồm các phần cụ thể như sau: \n\nPhần 1. Đặt vấn đề và định hướng giải quyết \n\nI. Đặt vấn đề: Nêu vấn đề cần giải quyết trong đồ án \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 12 \n\n   \n\nII. Tổng quan về tóm tắt văn bản tự động: Trình bày các định nghĩa, phân loại, \n\ncách biểu diễn văn bản, quy trình thực hiện bài toán tóm tắt văn bản, các kỹ thuật \n\nthường dùng, các tiêu chí và một số phương pháp đánh giá hệ thống tóm tắt. \n\nIII. Bài toán tóm tắt văn bản hướng truy vấn: Trình bày một số hướng tiếp cận \n\ncho bài toán tóm tắt hướng truy vấn và đề xuất một hướng tiếp cận phù hợp cho văn \n\nbản tiếng Việt.  \n\nPhần 2. Giải quyết vấn đề \n\nI.  Phân tích mô hình thực hiện bài toán: Đưa ra mô hình cụ thể, và phân tích \n\nchi tiết các bước thực hiện dựa trên hướng tiếp cận đã đề xuất. \n\nII. Cài đặt thử nghiệm: Xây dựng các công cụ và dữ liệu mẫu để thực hiện kiểm \n\nthử, đánh giá mô hình. Từ đó nhận xét ưu nhược điểm và khả năng ứng dụng. \n\nPhần 3. Kết luận và đề xuất: Trình bày các vấn đề đã giải quyết được trong đồ \n\nán, các vấn đề tồn tại và đề xuất hướng phát triển. \n\n  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 13 \n\n   \n\nPHẦN 1. ĐẶT VẤN ĐỀ VÀ ĐỊNH HƯỚNG GIẢI QUYẾT \n\nI. ĐẶT VẤN ĐỀ \n\nNhư đã nêu ở trên, mục tiêu cụ thể của đồ án là đề xuất và thử nghiệm một hướng \n\ntiếp cận cho bài toán tóm tắt hướng truy vấn đơn văn bản áp dụng được cho tiếng \n\nViệt. Cụ thể bài toán cần giải quyết được phát biểu như sau: \n\nĐầu vào: Văn bản, truy vấn, độ rút gọn \n\nĐầu ra: Bản tóm tắt của văn bản đầu vào xoay quanh vấn đề nêu trong truy vấn \n\nĐể giải quyết được bài toán này, việc trước hết là tìm hiểu cơ sở lý thuyết về tóm \n\ntắt văn bản, tóm tắt hướng truy vấn, từ đó xác định hướng giải quyết và thực hiện cài \n\nđặt thử nghiệm. \n\nII. TỔNG QUAN VỀ TÓM TẮT VĂN BẢN TỰ ĐỘNG \n\n2.1. Định nghĩa \n\nTóm tắt văn bản là quá trình làm giảm độ dài, độ phức tạp của văn bản mà vẫn \n\ngiữ lại được nội dung quan trọng của văn bản đó. Công việc tóm tắt văn bản đã xuất \n\nhiện từ rất lâu đời, và nó được làm thủ công, do con người đọc, rút ra các ý chính rồi \n\ntrình bày lại một cách ngắn gọn, dễ hiểu. Mục đích là giúp người sử dụng có cái nhìn \n\ntổng quan về nội dung trình bày trong văn bản, để quyết định sử dụng văn bản đó hợp \n\nlý. Tuy nhiên với lượng văn bản nhiều và dài thì việc làm thủ công vô cùng tốn thời \n\ngian, công sức. \n\nNgày nay, thời đại công nghệ thông tin phát triển mạnh, tóm tắt văn bản tự động \n\n(gọi tắt là tóm tắt văn bản) được nghiên cứu phát triển nhằm mục đích làm thay con \n\nngười công việc nặng nhọc đó. Đã có rất nhiều định nghĩa được đưa ra, tuy nhiên có \n\nthể sử dụng định nghĩa ngắn gọn sau: \n\n\u201cTóm tắt văn bản là quá trình rút ra những thông tin quan trọng nhất từ một hay \n\nnhiều nguồn văn bản để tạo ra một văn bản gọn hơn phục vụ cho một số nhiệm vụ \n\nhay người dùng cụ thể\u201d \n\n2.2. Các tiêu chí đánh giá \n\n Độ mạch lạc (Coherence): đánh giá mức độ rõ ràng của văn bản tóm tắt, tính \n\nsúc tích, khả năng có thể đọc và hiểu được của bài viết\u2026 \n\n Độ hàm chứa thông tin (Informationess): tỉ lệ thông tin của văn bản gốc trong \n\nvăn bản tóm tắt. \n\n Độ liên quan (Relevance): xác định mức độ phù hợp của văn bản tóm tắt với \n\nchủ đề cho trước (chủ đề có thể là một câu truy vấn). \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 14 \n\n   \n\n Độ dễ đọc hiểu (Reading Comprehence): một người được giao việc đọc văn \n\nbản kết quả, sau đó trả lời các câu hỏi, hệ thống sẽ phải cho điểm và từ đó đưa ra \n\nphần trăm những câu trả lời đúng. \n\n2.3. Ứng dụng của tóm tắt văn bản \n\nTóm tắt văn bản có nhiều ứng dụng trong thực tế, một số ứng dụng nổi bật như: \n\n Tóm tắt tự động các tin tức trên báo điện tử. \n\n Trợ giúp thông minh việc đọc và khai thác thông tin. \n\n Tóm lược danh sách tìm kiếm từ các Search Engine. \n\n Giản lược nội dung trình bày cho các thiết bị cầm tay. \n\n Sinh tự động chủ đề, tiêu đề, dẫn đường văn bản. \n\n Hỗ trợ tóm lược nội dung cuộc họp, website, chương trình phát thanh và \n\ntruyền hình, sổ tay công việc. \n\n2.4. Phân loại tóm tắt văn bản \n\nCó nhiều cách phân loại tóm tắt, phụ thuộc vào tiêu chí sử dụng để phân loại, sau \n\nđây là một số cách phân loại cần quan tâm: \n\n2.4.1. Theo đầu vào hệ thống \n\nTóm tắt đơn văn bản là từ một văn bản nguồn cho ra bản ngắn gọn của văn bản \n\nđó. Ngược lại, tóm tắt đa văn bản là từ nhiều văn bản nguồn cũng chỉ cho ra một \n\nđoạn tóm tắt, chứ không có nghĩa là thực hiện nhiều việc tóm tắt một văn bản đồng \n\nthời cho nhiều văn bản khác nhau. Rõ ràng, tóm tắt đa văn bản thì khó hơn, vì ngoài \n\nnhững công việc của tóm tắt đơn văn bản, tóm tắt đa văn bản còn phải thực hiện các \n\ncông việc như tiền xử lý trích rút, tích hợp thống nhất khuôn dạng và hiển thị kết quả \n\ntheo cách riêng. Ngoài ra, tóm tắt đa văn bản còn phải đối mặt với các vấn đề như dư \n\nthừa trùng lặp dữ liệu giữa các văn bản nguồn, nội dung các văn bản nguồn phân tán, \n\nđộ rút gọn yêu cầu cao, thời gian xử lý cần phải nhanh trong khi sự phức tạp trong xử \n\nlý lớn. \n\n2.4.2. Theo đầu ra hệ thống \n\nTóm tắt trích rút là quá trình thu gọn văn bản mà trong kết quả ra chứa các đơn \n\nvị ngữ liệu văn bản nguồn. Tóm tắt tóm lược là quá trình thu gọn văn bản mà trong \n\nkết quả ra có một số các đơn vị ngữ liệu mới được sinh ra từ các đơn vị ngữ liệu văn \n\nbản nguồn. \n\n2.4.3. Theo mục đích tóm tắt \n\nTóm tắt chung là tóm tắt theo quan điểm ban đầu của tác giả văn bản gốc. Tóm \n\ntắt hướng truy vấn là tóm tắt theo quan điểm mong muốn của người dùng ứng dụng \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 15 \n\n   \n\nthông qua các tham số truyền vào câu truy vấn. Tóm tắt hướng truy vấn được cài đặt \n\nvà áp dụng nhiều hơn nhưng trong lĩnh vực hẹp hơn, đi sâu vào các chuyên ngành cụ \n\nthể. \n\n2.5. Mô hình biểu diễn văn bản \n\nVăn bản thông thường là dạng dữ liệu phi cấu trúc, do vậy muốn xử lý chúng \n\ntrước hết phải biểu diễn thành dạng có cấu trúc. Các cấu trúc này phải có khả năng \n\nthao tác bằng các phép toán cơ bản như cộng, nhân, đại số quan hệ... Có ba mô hình \n\nthỏa mãn yêu cầu đó thường được sử dụng là: \n\n2.5.1. Mô hình boolean \n\nTrong mô hình boolean, văn bản, vốn là tập hợp của các term (thuật ngữ), được \n\nbiểu diễn bởi chỉ số từng term và trọng số của chúng. Trọng số của từng term - dùng \n\nđể đánh giá độ quan trọng của chúng - trong mô hình này chỉ mang hai giá trị 0 và 1, \n\ntùy theo sự xuất hiện của term đó trong văn bản. \n\n \n\nTrong đó wi là trọng số của term ti trong văn bản D. \n\nĐối với vấn đề truy vấn, trong mô hình này câu truy vấn bao gồm các văn bản \n\ntìm kiếm liên hệ với nhau thông qua các phép đại số quan hệ cơ bản như NOT (phủ \n\nđịnh), AND (và) hay OR (hoặc). Câu truy vấn có thể biểu diễn thành dạng vector với \n\ncác thành phần liên kết và các phép toán quan hệ cơ bản. Từ đây, độ liên quan giữa \n\nmột văn bản và truy vấn được xác định thông qua các thành phần liên kết. Độ liên \n\nquan này chỉ có thể mang hai giá trị : 0 \u2013 văn bản không phù hợp với truy vấn và 1 \u2013 \n\nvăn bản phù hợp. \n\nDo vậy có thể thấy rằng hạn chế lớn nhất của mô hình này đó là việc đánh giá độ \n\nliên quan chỉ trả về hai kết quả, hoặc phù hợp hoặc không, như vậy yêu cầu của hệ \n\nthống khi cần sắp xếp và chọn lựa các văn bản theo mức độ liên quan đến truy vấn sẽ \n\nkhông đạt. Độ liên quan của mô hình này không thể phân chia thành các mức khác \n\nnhau, do vậy không phản ánh được thực tế là việc liên quan giữa văn bản và truy vấn \n\ncó thể là mờ, không chắn chắn. Hạn chế này được loại bỏ khi ta sử dụng một mô hình \n\ntổng quát hơn \u2013 Mô hình không gian vector (VSM). \n\n2.5.2. Mô hình không gian vector \n\nNhư trên đã đề cập, mô hình không gian vector là mô hình tổng quát hơn mô hình \n\nBoolean. Các văn bản được biểu diễn thành các vector nhiều chiều, với trọng số không \n\nchỉ mang hai giá trị là 0 hay 1 mà có thể mang các giá trị khác tùy theo cách đánh giá, \n\ntính toán. Một khác biệt nữa so với mô hình boolean là các phép toán cơ bản của mô \n\nhình không gian vector. Các phép toán đại số quan hệ dĩ nhiên không phù hợp nữa, \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 16 \n\n   \n\nthay vào đó là các phép toán vector như cộng hai vector, nhân hai vector, tích vô \n\nhướng\u2026 \n\nKhi biểu diễn văn bản thành các vector, vấn đề về truy vấn và xác định độ liên \n\nquan hoàn toàn được giải quyết. Truy vấn là kết quả của các phép toán vector giữa \n\ncác vector biểu diễn cho những văn bản cấu thành nên truy vấn, như vậy, truy vấn \n\ntrong trường hợp này cũng là một văn bản đặc biệt. Việc xác định độ liên quan giữa \n\ntruy vấn và văn bản được quy thành độ liên quan giữa văn bản và văn bản. Hai văn \n\nbản là hai vector, vậy khoảng cách hay góc giữa chúng đều có thể đại diện cho sự liên \n\nquan giữa hai văn bản này. Tất nhiên, để áp dụng được các phép toán vector cơ bản, \n\nhai vector cần chuẩn hóa về số chiều (độ dài). \n\nCác chỉ số sử dụng trong phương pháp này: \n\n Tần suất thuật ngữ của một từ w trong một văn bản d, ký hiệu TF(w,d), có \n\nthể sử dụng các công thức sau, với fij là số lần xuất hiện của từ wi trong văn bản dj:  \n\n \n\n Tần suất văn bản của một từ w, ký hiệu DF(w) là số lượng văn bản mà từ w \n\ncó xuất hiện. Nghịch đảo của tần suất văn bản của một từ w, ký hiệu IDF(w) được \n\ncho bởi công thức: \n\n \n\nTrong đó: m là tổng số văn bản,, h là số văn bản chứa từ w \n\n Tần suất TF-IDF là kết hợp của hai loại tần suất nói trên: \n\nTF-IDF(w,d) = TF(w,d) * IDF(w) \n\nTheo mô hình này, mỗi văn bản sẽ được biểu diễn dưới dạng D(t1, t2,\u2026,tn) với n \n\nlà tổng số thuật ngữ xuất hiện, mỗi thuật ngữ sẽ được đánh index, ti là trọng số của \n\nthuật ngữ thứ i(trong danh sách thuật ngữ) trong văn bản D. Khi đó độ liên quan giữa \n\nhai văn bản biểu diễn bởi 2 vector X(x1, x2, \u2026, xn) và Y(y1, y2,\u2026,yn) được tính bằng \n\ncông thức Cosin: \n\n \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 17 \n\n   \n\n2.5.3. Mô hình tập thô dung sai \n\n Mô hình tập thô dung sai (Tolerance Rough Set Model) là một mô hình mới, \n\ntiên tiến dựa trên lý thuyết về logic mờ và tập mờ (Fuzzy Set). Điều cốt lõi của lý \n\nthuyết này là việc xác định chính xác một giả thiết nào đó (ví dụ như hai văn bản này \n\ncó phù hợp, có giống nhau không...) là một điều rất khó. Tuy nhiên chúng ta có thể \n\nchỉ ra một cặp xấp xỉ trên và xấp xỉ dưới để khẳng định được giả thiết đó là đúng. Sử \n\ndụng các suy diễn hợp lý để xác định và \u201clàm đẹp\u201d các ngưỡng này. Các phép toán \n\ncơ bản trong mô hình tập thô dựa trên các quan hệ tương đương các tính chất như đối \n\nxứng, phản xạ, bắc cầu... Lý thuyết logic mờ đã và đang được ứng dụng rất mạnh mẽ \n\ntrong lĩnh vực Trí tuệ nhân tạo. \n\nMô hình tập thô gần đây được sử dụng nhiều cho các bài toán tìm kiếm cũng như \n\nphân nhóm văn bản\u2026 Tuy nhiên khi áp dụng mô hình tập thô cho quá trình xử lý văn \n\nbản thì tính chất bắc cầu không còn phù hợp. Nhóm tác giả Hồ Tú Bảo, Saori \n\nKawasaki, Nguyễn Ngọc Bình đã đề xuất ra mô hình tập thô dung sai trong đó bỏ đi \n\ntính chất bắc cầu trong quá trình xử lý văn bản. Lý thuyết tập thô được các nhà nghiên \n\ncứu Trí tuệ nhân tạo phát triển và ngày càng thể hiện được tính ưu việt không chỉ \n\ntrong  việc biểu diễn và thao tác văn bản mà còn trong các vấn đề khác của lĩnh vực \n\nnày. \n\n2.6. Mô hình tóm tắt văn bản \n\n \n\nHình 1: Mô hình chung của tóm tắt văn bản \n\nMột mô hình tóm tắt văn bản tổng quát gồm các pha sau: \n\n Phân tích (Analysis): Phân tích văn bản đầu vào để đưa ra những mô tả bao \n\ngồm các thông tin dùng để tìm kiếm, đánh giá các đơn vị ngữ liệu quan trọng cũng \n\nnhư các tham số đầu vào cho việc tóm tắt. \n\n Biến đổi (Transformation): Lựa chọn các thông tin trích chọn được, biến đổi \n\nđể giản lược và thống nhất, kết quả là các đơn vị ngữ liệu đã được tóm tắt. \n\n Hiển thị (Generation): Từ các đơn vị ngữ liệu đã tóm tắt, liên kết chúng lại \n\nthành đoạn theo một thứ tự nào đó hoặc theo cấu kết ngữ pháp rồi hiển thị phù hợp \n\nvới yêu cầu người dùng. \n\nMột hệ Tóm lược (Abstraction) bao gồm tất cả các pha trên, tuy nhiên một hệ \n\nTrích rút (Extraction) chỉ gồm pha Phân tích và Pha Hiển thị, không có pha biến đổi. \n\nThậm chí trong các pha phân tích và hiển thị, chỉ có một số công đoạn được sử dụng. \n\nPhân tích \n\n(Analysis)\n\nBiến đổi \n\n(Transform)\n\nHiển thị \n\n(Generation)\n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 18 \n\n   \n\n \n\nHình 2: Mô hình tóm tắt văn bản trích rút \n\nNhư vậy một hệ Trích rút tiến hành ít bước hơn, các phương pháp thường dùng \n\nlà thống kê, học trên ngữ liệu. Còn hệ Tóm lược thì phức tạp, do kết hợp các phương \n\npháp của xử lý ngôn ngữ tự nhiên. Vì vậy, kết quả của các hệ Tóm lược thường thuyết \n\nphục hơn (về mặt dễ đọc, dễ hiểu, liên kết ngôn ngữ tốt, gần gũi với con người). \n\nTrong mỗi pha có thể áp dụng nhiều kỹ thuật xử lý khác nhau, chi tiết sẽ được \n\ntrình bày ở phần tiếp theo. \n\n2.7. Các phương pháp áp dụng trong các pha \n\n2.7.1. Pha Phân tích \n\nỞ pha này văn bản nguồn sẽ được tách thành các đoạn, câu, từ, kết hợp với các \n\nthông số đầu vào và áp dụng một số thuật toán cụ thể để chọn ra các đoạn hoặc câu \n\nphù hợp làm đầu vào cho pha tiếp theo. \n\nCác phương pháp áp dụng trong pha Phân tích được chia thành hai loại: Phương \n\npháp thống kê và Phương pháp cấu trúc. \n\n2.7.1.1. Phương pháp thống kê \n\nPhương pháp này sử dụng các số liệu thống kê về độ quan trọng của từ, câu hay \n\nđoạn, nhận được từ các nghiên cứu về ngôn ngữ học hay thông qua các phương pháp \n\nhọc máy dựa trên tập mẫu để trích rút ra các đơn vị ngữ liệu quan trọng  \n\n Phương pháp vị trí \n\nPhương pháp vị trí bao gồm các phương pháp xác định độ quan trọng dựa trên \n\nthống kê về vị trí của từ, ngữ hay câu trong văn bản. Các thống kê này tất nhiên phụ \n\nthuộc vào thể loại văn bản\u2026 \n\n Chủ đề - Tiêu đề (Title-based): Chủ đề các đoạn văn bản hay tiêu đề các bảng \n\nthường chứa các từ và ngữ quan trọng, nên trích rút thông tin từ đây. \n\n Đầu - cuối đoạn (First - Last Sentence): Xác suất câu đầu đoạn hay câu cuối \n\nđoạn chứa ý chính của cả đoạn là rất lớn, đặc biệt là câu đầu đoạn. Ngoài ra, \n\ncác đoạn đầu và cuối trong văn bản cũng quan trọng hơn các đoạn giữa. \n\n Minh họa - Chú thích (Comments): Trong các câu chú thích, câu minh họa \n\ncho ảnh hay đồ thị thường chứa các thông tin quan trọng. Tuy nhiên, các câu \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 19 \n\n   \n\nnày thường chỉ được dùng để đánh giá độ quan trọng của các câu khác liên \n\nquan, chứ không được chọn làm đầu vào cho pha tiếp. \n\n Phương pháp ngữ cố định \n\nCác ngữ cố định có đặc điểm thống kê rất tốt. Sau các ngữ này thường là các câu \n\nhay từ có độ quan trọng là xác định. Người ta chia thành hai loại ngữ cố định, một \n\nloại mang lại độ quan trọng cho thành phần đi sau, được gọi là ngữ nhấn mạnh, một \n\nloại giúp ta loại bỏ, không xét đến những thành phần đi sau vì nó không có nhiều giá \n\ntrị trong việc trích rút, được gọi là ngữ dư thừa: \n\n Ngữ nhấn mạnh (Bonus phrase - Emphasizer): Ngữ nhấn mạnh gồm các ngữ \n\nnhư \u201cnói chung là\u2026\u201d, \u201cđặc biệt là\u2026\u201d, \u201ccuối cùng thì\u2026\u201d, \u201ctrong bài viết này \n\ntôi muốn chỉ ra\u2026\u201d, \u201cbài viết nói về\u2026\u201d, \u201cnội dung gồm\u2026\u201d,..v..v... \n\n Ngữ dư thừa (Stigma phrases): Một số ngữ dư thừa: \u201chiếm khi mà\u2026\u201d, \u201cbài \n\nnày không nói đến\u2026\u201d, \u201cKhông thể nào\u2026\u201d, ..v..v... \n\n Phương pháp thống kê tần suất từ \n\nĐộ quan trọng của từ phụ thuộc vào số lần xuất hiện của từ đó trong các văn bản \n\nliên quan. Các kỹ thuật như TF.IPF hay Tập thuật ngữ thường xuyên (Frequent Item \n\nSet) dùng cho công việc xác định tần suất của từ. \n\n2.7.1.2. Phương pháp cấu trúc \n\nLà các phương pháp sử dụng các mối liên hệ cấu trúc - ngữ pháp - ngữ nghĩa để \n\nxác định các đơn vị ngữ liệu quan trọng. Tư tưởng chính của các phương pháp này là \n\nnhững đơn vị ngữ liệu nào có chứa các thành phần liên kết nhiều với các thành phần \n\nkhác sẽ có độ quan trọng lớn. Việc đánh giá các mối quan hệ sẽ dựa trên các mạng \n\nngữ nghĩa, các quan hệ cú pháp hoặc thông qua các phương pháp xác định độ liên \n\nquan truyền thống. \n\n Phương pháp quan hệ lẫn nhau: Phương pháp này xác định mối quan hệ \n\ngiữa các đoạn trong văn bản hay các câu trong đoạn với nhau thông qua các kỹ thuật \n\nthu thập thông tin ở mức văn bản. Các đoạn (câu) trong văn bản nguồn được tính toán \n\nđộ liên quan lẫn nhau sử dụng các kỹ thuật như Cosine, TF.IPF hay N-gram Overlap. \n\nSau đó chọn ra đoạn (câu) có độ liên quan lớn nhất. \n\n Phương pháp liên kết từ vựng: Phương pháp liên kết từ vựng sử dụng các từ \n\nđiển quan hệ từ vựng đế xây dựng các chuỗi từ liên kết với nhau vể mặt ngữ nghĩa. \n\nVí dụ \u201ccây\u201d là một loại \u201cthực vật\u201d, có bộ phận là \u201clá\u201d, chất liệu là \u201cgỗ\u201d. Các từ \u201ccây\u201d, \n\n\u201cthực vật\u201d, \u201clá\u201d, \u201cgỗ\u201d có quan hệ ngữ nghĩa nào đó với nhau. Sau khi xây dựng được \n\ncác chuỗi từ này, đánh giá độ mạnh của chúng và có những trích chọn phù hợp. \n\n Phương pháp Liên kết tham chiếu: Phương pháp liên kết tham chiếu còn \n\nđược gọi là phương pháp trích chọn trùng lặp (Anaphora-based Method). Theo \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 20 \n\n   \n\nphương pháp này, các cụm trùng lặp được chọn ra, phân rã xem đâu là từ tham chiếu \n\nvà từ được tham chiếu. Sau khi phân tách các cụm trùng lặp, chúng ta tạo chuỗi các \n\ntừ tham chiếu đến cùng một từ được tham chiếu. Chuỗi dài nhất sẽ được coi là trọng \n\ntâm của đoạn, các câu chứa các từ trong chuỗi này có một độ ưu tiên nào đó khi xét \n\ntrích chọn. \n\n Phương pháp quan hệ câu: Dựa trên các từ thể hiện mối quan hệ giữa các \n\ncâu chúng ta cấu trúc hóa đoạn văn bản từ các đơn vị thành phần như ngữ, mệnh đề, \n\ncâu... Sau đó đơn vị được coi như trung tâm sẽ được trích chọn. \n\n2.7.2. Pha Biến đổi \n\nỞ pha này, các câu sẽ được biến đổi, làm gọn lại hoặc kết hợp nhiều câu tạo thành \n\ncâu mới ngắn gọn hơn. Các phương pháp trong pha này không làm tăng thêm độ \n\nchính xác mà chỉ giúp cho văn bản kết quả ngắn gọn hơn mà vẫn sát nghĩa và thuật \n\ntoán thưởng rất phức tạp. Có thể chia làm 2 loại: \n\n2.7.2.1. Giản lược về cấu trúc câu \n\nGiản lược về cấu trúc câu là việc lược bỏ trong câu các phần thừa, ít mang giá trị, \n\nlàm cho cấu trúc câu thu gọn lại. Công việc này thường dựa trên phân tích cú pháp \n\ncác thành phần trong câu. \n\n2.7.2.2. Giản lược về mặt ngữ nghĩa \n\n Phương pháp trừu tượng hóa khái niệm \n\nTư tưởng của phương pháp này là từ các khái niệm cụ thể thay thế bằng khái niệm \n\nchung. \n\nVí dụ: \u201cTôi ăn dâu, táo và đào\u201d => \u201cTôi ăn trái cây\u201d \n\n Phương pháp thay thế bộ phận \n\nTư tưởng của phương pháp này là từ các khái niệm bộ phận thay thế bằng khái \n\nniệm toàn bộ. \n\nVí dụ: \u201cXích, líp, ghi đông, bàn đạp \u2026\u201d => \u201cCái xe đạp\u2026\u201d. \n\n Phương pháp thay thế ngữ tương đương \n\nTư tưởng của phương pháp này là các ngữ đóng vai trò như nhau trong câu được \n\nthay bằng một ngữ chung. \n\nVí dụ: \u201cAnh ấy bước vào, ngồi xuống ghế, xem thực đơn, gọi món, ăn, trả tiền và \n\nra về\u201d => \u201cAnh ấy đi ăn tiệm\u201d. \n\n Phương pháp thay thế từ, ngữ đồng nghĩa ngắn hơn \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 21 \n\n   \n\nMột phương pháp khác khá dễ hiểu đấy là việc thay thế một từ, ngữ bằng một từ, \n\nngữ khác đồng nghĩa hoặc gần nghĩa nhưng có độ dài ngắn hơn. Điều này thường \n\nthông qua một từ điển các từ đồng nghĩa (Thesaurus). \n\n Phương pháp thay thế bởi đại diện \n\nTư tưởng của phương pháp này là thay thế một ngữ bằng một ngữ khác có ý nghĩa \n\nđại diện cho ngữ ban đầu. \n\nVí dụ: \u201cNgười phát ngôn viên của chính phủ Hoa Kỳ thông báo\u2026\u201d => \n\n\u201cWashington thông báo\u2026\u201d. \n\n2.7.3. Pha Hiển thị \n\n2.7.3.1. Phương pháp hiển thị phân đoạn \n\nĐây là phương pháp đơn giản nhất. Các đơn vị ngữ liệu được trích rút hay giản \n\nlược từ các pha trước được liên kết lại thành đoạn theo thứ tự tiền định của chúng, \n\nkhông thêm bớt từ nối và cũng không sắp xếp lại các đơn vị ngữ liệu. Văn bản kết \n\nquả của phương pháp này có độ dễ đọc dễ hiểu kém, thậm chí lủng củng về nghĩa vì \n\ncác đơn vị ngữ liệu được trích rút mắc phải một số lỗi như mập mờ tham chiếu, không \n\ncó từ nối hoặc là thừa từ và ngữ. \n\n2.7.3.2. Phương pháp hiển thị liên kết \n\nViệc hiển thị liên kết là tiếp nhận các đơn vị ngữ liệu đã được trích rút và giản \n\nlược từ các pha trước đó, phân tích mối quan hệ về nghĩa của các câu rồi thêm bớt \n\ncác từ nối, từ dẫn và sắp xếp theo một thứ tự mới dựa vào những gì đã thu thập sao \n\ncho thỏa mãn yêu cầu về hiển thị và yêu cầu về độ dễ đọc, dễ hiểu của người dùng. \n\n2.8. Đánh giá kết quả tóm tắt \n\nĐánh giá một bản tóm tắt là một công việc khó bởi không tồn tại một bản tóm tắt \n\nlý tưởng cho một (hoặc một tập) văn bản đưa ra. Hơn nữa, việc đánh giá nội dung \n\ntóm tắt cũng rất khó khăn. Trường hợp kết quả là một câu trả lời cho một câu hỏi, ta \n\ncó thể xác định được câu trả lời đó đúng hay sai, nhưng trong các trường hợp khác, \n\nthật khó trả lời liệu đầu ra là phải một kết quả đúng hay không? Thực tế luôn có khả \n\nnăng một hệ thống sinh ra một bản tóm tắt tốt nhưng lại sai khác với bản tóm tắt do \n\nngười thực hiện. Bên cạnh đó, khi việc đánh giá được thực hiện bởi con người thì chi \n\nphí đánh giá sẽ rất cao. Mặt khác, tóm tắt văn bản còn liên quan đến tỉ lệ nén văn bản, \n\ndo đó, việc đánh giá bản tóm tắt cần phải quan tâm đến vấn đề này, khi đó độ phức \n\ntạp và chi phí đánh giá sẽ tăng cao. \n\nDưới đây là hai phương pháp đánh giá tự động thường sử dụng: \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 22 \n\n   \n\n2.8.1. Sử dụng so khớp n-gram \n\nPhương pháp này được Lin và Hovy đưa ra năm 2002 dựa trên mô hình n-gram \n\ncủa độ đo BLEU (Bilingual Evaluation Understudy [1], độ đo đánh giá kết quả dịch \n\nmáy). Ý tưởng của phương pháp này là so khớp n-gram liên tiếp của bản tóm tắt thủ \n\ncông và tóm tắt tự động, theo công thức sau: \n\nScore=α1*Score1+ α2*Score2+ α3*Score3+ α4*Score4 \n\nTrong đó: \n\nScorei = Số i-gram trùng nhau/Tổng số i-gram của bản tóm tắt thủ công \n\n   αi là hệ số đánh giá độ quan trọng của các Scorei \n\n2.8.2. Sử dụng các độ đo ROUGE \n\nROUGE(Recall-Oriented Understudy of Gisting Evaluation [2]) cũng được đưa \n\nra bởi Lin, vào năm 2009, đây là tập hợp các độ đo dựa trên mô hình n-gram của \n\nBLEU với nhiều cách tính khác nhau. Thường sử dụng nhất là độ đo ROUGE-N, với \n\nn là giá trị của mô hình n-gram, n={1,2,3,4}. \n\nCông thức của độ đo ROUGE-N như sau: Cho R=(r1, r2, \u2026, rn) là tập các tóm tắt \n\nmẫu, s là tóm tắt tự động, Ωn(d) là vector biểu diễn mô hình n-gram của văn bản d. \n\n \n\nĐộ đo ROUGE được sử dụng làm độ đo chính thức của các hội nghị DUC 2004-\n\n2007 và TAC 2008-2012. \n\n2.9. Một số hệ thống tóm tắt văn bản tiêu biểu \n\nHiện tại, trên thế giới đã có rất nhiều nghiên cứu và dự án xây dựng các ứng dụng \n\ntóm tắt văn bản. Các ứng dụng này có thể đáp ứng rất nhiều các mục đích khác nhau. \n\nCó thể kể ra một số ứng dụng Tóm tắt văn bản tiêu biểu như sau: \n\n SUMMARIST: Một hệ thống Trích rút văn bản năm thứ tiếng (tiếng Anh, \n\ntiếng Nhật, tiếng Tây Ban Nha, tiếng Ả-rập và tiếng Hàn Quốc). Hiện tại \n\nSUMMARIST đang nghiên cứu để cải tiến trở thành một hệ thống Tóm lược \n\nvăn bản và hỗ trợ nhiều ngôn ngữ hơn như tiếng Pháp và Indonesia. \n\n SweSUM: Ứng dụng Tóm tắt văn bản đa ngôn ngữ của Học viện công nghệ \n\nhoàng gia Thụy Điển. SweSUM có thể tóm tắt các văn bản có ngôn ngữ vùng \n\nScandinavi như Thụy Điển, Đan Mạch, Na Uy và các ngôn ngữ khác như tiếng \n\nAnh, Pháp, Đức, Tây Ban Nha và cả tiếng Iran. \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 23 \n\n   \n\n SumUM: Hệ thống Tóm lược văn bản kỹ thuật của nhóm nghiên cứu xử lý \n\nngôn ngữ tự nhiên trường Đại học Montréal, Canada. SumUM có thể thực hiện \n\ncả chức năng tóm tắt chỉ định và tóm tắt thông tin rất tốt.. \n\n FJCL: Hệ thống Rút trích văn bản tiếng Nhật được phát triển trong phòng \n\nnghiên cứu Ikeda của trường đại học Gifu. Đây là một hệ thống sử dụng các \n\nphương pháp áp dụng cho hệ ngôn ngữ đơn âm tiết (monosyllabic language \n\nsystem) như tiếng Nhật, Hàn Quốc, Trung Quốc và Việt Nam. \n\n Pertinence Summarizer: Hệ thống tóm tắt tin tức đa ngôn ngữ trực tuyến nổi \n\ntiếng. Hiện tại để thử nghiệm khả năng của mình, Pertinence đã được tích hợp \n\nvới Google và tóm tắt tự động danh sách tìm kiếm trả về từ Google thông qua \n\ncâu truy vấn đưa vào. Chúng ta có thể thử nghiệm hệ thống này trên trang web: \n\nwww.pertinence.net. \n\n MEAD: Nền tảng cho các hệ thống Tóm tắt nhiều văn bản và đa ngôn ngữ. \n\nĐây là một bộ công cụ xây dựng trên nền Linux và Solaris, sử dụng ngôn ngữ \n\nPerl - Một ngôn ngữ có khả năng xử lý văn bản rất linh hoạt và mạnh mẽ. \n\nMEAD biểu diễn, lưu trữ dữ liệu ở dạng XML, cung tấp cho chúng ta khung \n\nứng dụng để cài đặt các ứng dụng Tóm tắt văn bản cho ngôn ngữ mà ta muốn. \n\nNgoài ra MEAD cũng cung cấp các công cụ để xây dựng các ứng dụng đánh \n\ngiá hệ thống tóm tắt theo các tiêu chí và các tập mẫu nổi tiếng. MEAD được \n\nxây dựng bởi các chuyên gia nổi tiếng về Xử lý ngôn ngữ ở khắp nơi trên thế \n\ngiới dưới sự tài trợ của Chương trình Nghiên cứu Công nghệ thông tin của Tổ \n\nchức Khoa học quốc gia Mỹ. MEAD được cung cấp ở dạng mã nguồn mở để \n\nnghiên cứu và kế thừa. Hiện tại phiên bản mới nhất của MEAD là MEAD \n\nv3.07. \n\n Microsoft Word AutoSummary: Microsoft cũng cài đặt chức năng Trích rút \n\nvà sinh tiêu đề trong Microsoft Word từ phiên bản Word '97. Chúng ta có thể \n\nthử bằng cách chọn Tools - AutoSummarize trên thanh công cụ (có thể khác \n\ntùy vào phiên bản). Công cụ này cho phép chúng ta chọn thông số về độ rút \n\ngọn, trích rút hay sinh tiêu đề... \n\nNgoài ra còn các hệ thống Tóm tắt văn bản nổi tiếng khác như ANES hay \n\nSUMMONS. Tuy nhiên tại Việt Nam hiện nay chưa có một nghiên cứu và ứng dụng \n\nTóm tắt văn bản chính thức nào. \n\n  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 24 \n\n   \n\nIII. BÀI TOÁN TÓM TẮT VĂN BẢN HƯỚNG TRUY VẤN \n\n3.1. Định nghĩa \n\nTheo định nghĩa ở trên, tóm tắt văn bản hướng truy vấn là một dạng tóm tắt văn \n\nbản (khi phân chia theo mục đích tóm tắt), điểm đặc trưng là ở giai đoạn tiền xử lý, \n\nviệc tính toán sẽ phụ thuộc một phần vào truy vấn người dùng. \n\n3.2. Ứng dụng của bài toán \n\nTóm tắt hướng truy vấn thường sử dụng trong việc tóm tắt kết quả trả về của máy \n\ntìm kiếm thông tin, hoặc trong các hệ thống hỏi đáp tự động. \n\nHiện nay, đối với máy tìm kiếm, hệ thống sẽ tóm tắt văn bản theo tóm tắt đơn văn \n\nbản thông thường, lưu vào cơ sở dữ liệu, và thực hiện tìm kiếm trên bản tóm tắt đó \n\nđể giảm thời gian tìm kiếm. Sau khi xác định được văn bản phù hợp, văn bản đó sẽ \n\nđược tóm tắt lại theo truy vấn người dùng để đưa ra hiển thị kèm với kết quả. Đối với \n\nhệ thống hỏi đáp tự động, hệ thống sẽ tiến hành phân loại câu hỏi và thực hiện so \n\nkhớp hoặc tính tương đồng với câu hỏi trong cơ sở dữ liệu để xác định câu trả lời phù \n\nhợp nhất, sau đó tóm tắt văn bản chứa câu trả lời, sử dụng câu trả lời như truy vấn, \n\nvà hiển thị kèm với câu trả lời, có đánh dấu câu trả lời. \n\nTóm lại, tóm tắt hướng truy vấn thường được tích hợp ở giai đoạn xử lý kết quả \n\ncủa hệ thống tìm kiếm thông tin và hỏi đáp tự động, mục đích là thêm thông tin để \n\nkết quả rõ ràng và dễ hiểu hơn với người dùng \n\n3.3. Một số hướng tiếp cận phổ biến \n\n3.3.1. Dựa trên đồ thị \n\nPhương pháp này được đưa ra bởi [3] Jagadeesh và đồng sự, áp dụng cho tóm tắt \n\ntrích rút đa văn bản. Đồ thị của văn bản sẽ được xây dựng dựa trên việc phân tích các \n\ncâu trong đó để tìm ra các cụm danh từ(noun phrases), sau đó phân tích các cụm danh \n\ntừ này để tìm ra mối quan hệ giữa các danh từ sử dụng các hàm heuristic. Đồ thị thu \n\nđược sẽ bao gồm 2 dạng nút, nút thành phần(là các danh từ trích rút từ văn bản) và \n\nnút liên kết, có 2 loại nút liên kết là isa(là một) và related_to(liên quan với). \n\nSau khi xây dựng đồ thị cho mỗi câu, chúng sẽ được kết hợp để tạo đồ thị cho \n\ntoàn văn bản. Một thuật toán tìm kiếm sẽ được sử dụng để tìm các câu quan trọng đưa \n\nvào tóm tắt. Có 3 giải thuật có thể áp dụng: \n\n- Dựa trên tâm các đồ thị: một đồ thị trung tâm cho tất cả văn bản được xây \n\ndựng, tích hợp thêm đồ thị của truy vấn. Sau đó các câu có đồ thị tương \n\nđồng với tâm lớn nhất sẽ được chọn \n\n- Dựa trên đồ thị truy vấn: các câu có đồ thị tương đồng với đồ thị truy vấn \n\nlớn nhất sẽ được chọn \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 25 \n\n   \n\n- Dựa trên việc kết hợp câu đã chọn: giống bước trên nhưng sau khi chọn \n\nđược mỗi câu thì kết hợp câu đó vào tâm tạo thành tâm mới \n\nPhương pháp này cho kết quả tương đối chính xác nhưng phụ thuộc chủ yếu vào \n\ngiải đoạn phân tích cú pháp để tìm các cụm danh từ, do đó cần bộ phân tích cú pháp \n\nchính xác. \n\n3.3.2. Dựa trên cấu trúc diễn ngôn \n\nPhương pháp này được trình bày bởi W. Bosma [4], mục đích là tạo ra bản tóm \n\ntắt ngắn gọn chứa câu trả lời để đưa ra kết quả trong hệ thống hỏi đáp tự động. Trong \n\nđó mỗi văn bản được biểu diễn bởi đồ thị có trọng số dựa trên lý thuyết diễn ngôn, \n\nmỗi đỉnh đại diện cho một câu, trọng số trên mỗi cạnh là khoảng cách giữa hai câu. \n\nMột thuật toán tìm kiếm đồ thị sẽ được sử dụng để chọn ra các câu có tổng trọng số \n\ntrên đường đi tới câu trả lời(vai trò như truy vấn) nhỏ nhất. \n\n3.3.3. Dựa trên tần số từ và độ tương đồng câu \n\nPhương pháp này trình bày bởi Siva kumar và đồng sự [5] áp dụng cho tóm tắt \n\ntrích rút đa văn bản. Trước tiên các văn bản sẽ được biểu diễn trong mô hình không \n\ngian vector, mỗi câu được tính khoảng cách với câu truy vấn, sau đó sử dụng thuật \n\ntoán phân cụm, chia các câu vào các cụm. Mỗi câu được tính điểm số vị trí và điểm \n\nsố độ quan trọng trong cụm, sau đó từ các cụm có điểm số cao nhất, trích rút ra các \n\ncâu có điểm số cao nhất tạo thành tóm tắt. \n\n3.4. Đề xuất hướng giải quyết cho tiếng Việt \n\nQua tìm hiểu về các vấn đề liên quan trong tóm tắt và đặc trưng của tiếng Việt, \n\ndễ nhận thấy rằng việc tiếp cận ở mức cú pháp và ngữ nghĩa là khá khó khăn, một \n\nphần là vì công cụ và dữ liệu hỗ trợ, tuy đã có một số công cụ gán nhãn từ vựng và \n\nphân tích cú pháp cho độ chính xác cao nhưng thường chỉ áp dụng cho lĩnh vực hẹp, \n\nvà còn ở mức nghiên cứu, chưa được công bố chính thức. Mặt khác, do đặc trưng về \n\nngữ pháp nên các hướng tiếp cận đó thường không chính xác với tiếng Việt. \n\nDo đó em xin đề xuất mô hình trích rút các câu quan trọng cho bài toán tóm tắt \n\nhướng truy vấn dựa trên tần số từ và độ tương đồng câu, áp dụng cho tóm tắt đơn \n\nvăn bản. Mô tả sơ lược như sau: Đầu tiên sử dụng câu truy vấn làm tâm tóm tắt, sau \n\nđó tìm câu có độ tương đồng với tâm lớn nhất, mỗi câu được chọn sẽ kết hợp với tâm \n\ntạo nên tâm mới. Sau khi kết thúc sẽ loại bỏ câu truy vấn khỏi kết quả. Phương pháp \n\nnày dựa theo ý tưởng ở giải thuật thứ 2 trong hướng tiếp cận dựa trên đồ thị đã nêu ở \n\ntrên, nhưng các câu ở đây biểu diễn theo mô hình không gian vector và độ tương đồng \n\nsử dụng độ đo cosin. \n\nPhạm vi ứng dụng hướng tới của mô hình là tích hợp vào modul trả kết quả của \n\nbộ máy tìm kiếm văn bản(search engine), thực hiện tóm tắt văn bản kết quả theo tập \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 26 \n\n   \n\ntừ khóa đã tìm kiếm(chính là truy vấn người dùng). Do đó có một số ràng buộc với \n\ndữ liệu đầu vào. \n\nVì văn bản đã được máy tìm kiếm lựa chọn nên nội dung của văn bản và truy vấn \n\nsẽ liên quan với nhau. Do đó các câu chứa nhiều từ khóa trong truy vấn, hay trong \n\ntrường hợp này là độ tương đồng lớn, sẽ mang các thông tin quan trọng liên quan đến \n\ntruy vấn mà người dùng quan tâm. Tuy nhiên trong vấn đề tìm kiếm, phần lớn người \n\ndùng thường không nắm rõ được nội dung mình muốn biết nên mới sử dụng tìm kiếm, \n\nmà chỉ biết các từ khóa liên quan tới vấn đề đó. Ví dụ như tìm kiếm thông tin về giá \n\nvàng, người ta không biết giá vàng tăng hay giảm, có biến động gì gần đây. Hoặc tìm \n\ncách sửa một lỗi máy tính thì người dùng sẽ đưa ra các thông tin về lỗi đó, sau khi \n\nxem bản tóm tắt của các kết quả từ máy tìm kiếm, sẽ biết được kết quả nào phù hợp \n\nđể quyết định đọc hay không. \n\nTrong giải thuật chọn câu, các câu được chọn sẽ được thêm vào truy vấn, với mục \n\nđích làm thêm từ khóa liên quan đến truy vấn. Nhưng không phải từ nào trong các \n\ncâu đó cũng đều quan trọng nên các từ xuất hiện trong truy vấn gốc được nhân lên \n\nmột trọng số α. Do đó kết quả tóm tắt sẽ ưu tiên các từ khóa trong truy vấn, và các từ \n\nkhóa xuất hiện nhiều trong các câu được chọn. Theo đó thì bản tóm tắt sẽ dễ hiểu hơn \n\nvì bao gồm các thông tin liên quan tới truy vấn. \n\nTổng quan về modul đó như sau: \n\n Đầu vào \n\n- Văn bản: văn bản đầu vào sử dụng bộ mã Unicode utf-8, chỉ chứa text, chính \n\nxác về chính tả, dấu câu, không quá ngắn(5 câu trở lên), nội dung phải liên \n\nquan tới truy vấn. \n\n- Truy vấn: sử dụng bộ mã như văn bản, là một đoạn văn bản chứa các từ khóa \n\ncần tìm kiếm, nếu cần chính xác thì dùng dấu phảy để ngăn cách các từ khóa \n\n- Độ rút gọn: có thể là số lượng từ (100-150 từ) hoặc phần trăm văn bản nguồn \n\n(10-20%). \n\n Thực hiện tóm tắt \n\nBước này áp dụng mô hình tóm tắt đã đề xuất để tạo kết quả \n\n- Chuẩn hóa: bước này sẽ thực hiện xử lý tiêu đề, các đoạn văn trong ngoặc đơn  \n\n- Tách câu, tách từ: thực hiện tách câu, tách từ sử dụng công cụ VNTokenizer \n\n- Loại bỏ từ dừng: tìm kiếm và loại bỏ các từ dừng dựa trên danh sách có sẵn \n\n- Xử lý từ đồng nghĩa: đồng bộ các từ đồng nghĩa về cùng 1 dạng  \n\n- Mô hình hóa văn bản: tính TF.IDF và chuyển các câu về dạng vector \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 27 \n\n   \n\n- Trích rút câu, tạo tóm tắt: đây là giải thuật đã đề xuất, thực hiện tính toán độ \n\ntương đồng sử dụng độ đo cosin và một số phép toán trên vector để tìm kiếm \n\ncác câu phù hợp đưa vào kết quả tóm tắt, và được ghép lại theo phương pháp \n\nhiển thị phân đoạn. \n\n Đầu ra: văn bản tóm tắt \n\n Chi tiết các kỹ thuật sử dụng trong các bước sẽ trình bày ở phần sau. \n\n  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 28 \n\n   \n\nPHẦN 2. GIẢI QUYẾT VẤN ĐỀ \n\nI.  PHÂN TÍCH MÔ HÌNH THỰC HIỆN BÀI TOÁN \n\nDựa vào các kiến thức về tóm tắt văn bản đã trình bày ở trên, trong phần này em \n\nsẽ trình bày chi tiết các kỹ thuật áp dụng trong từng bước của mô hình xử lý đã đề \n\nxuất. \n\n \n\nHình 3: Mô hình tóm tắt văn bản hướng truy vấn \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 29 \n\n   \n\n1.1. Giai đoạn phân tích \n\n1.1.1. Chuẩn hóa \n\n Xử lý câu tiêu đề \n\nCâu tiêu đề của một văn bản (nếu có) thường mang nội dung chính trình bày trong \n\nvăn bản, do đó các từ khóa trong đó cũng được dùng để phát hiện tóm tắt (một số giải \n\nthuật còn tăng trọng số cho những từ xuất hiện trong tiêu đề), nhưng không đưa câu \n\ntiêu đề vào kết quả tóm tắt, nên cần phát hiện để loại bỏ khỏi kết quả. Việc phát hiện \n\ncâu tiêu đề có thể dựa vào dấu hiệu \u201ccâu tiêu đề là câu duy nhất của đoạn đầu tiên\u201d. \n\nTrong giải thuật này chỉ sử dụng câu tiêu đề như câu thông thường, sau đó loại khỏi \n\nkết quả (nếu nó được chọn vào kết quả). \n\n Xử lý các cụm từ trong ngoặc \n\nCác cụm từ trong ngoặc có thể là chú thích hoặc viết tắt của cụm từ nào đó, nếu \n\nlà chú thích thì có thể bỏ qua còn từ viết tắt thì khá quan trọng, nhất là đối với tóm \n\ntắt hướng truy vấn. \n\nVí dụ: Sinh viên tình nguyện(SVTN) đi đến các vùng sâu để giúp đỡ đồng bào \n\nCác câu sau câu này sẽ sử dụng cụm từ SVTN, nếu truy vấn có từ khóa \u201csinh viên \n\ntình nguyện\u201d thì các câu sử dụng từ viết tắt sẽ không được quan tâm. \n\nViệc xử lý từ viết tắt không đơn giản là phát hiện các từ trong ngoặc, tùy từng \n\nloại văn bản của chuyên ngành nào đó, các từ viết tắt vẫn được sử dụng mà không \n\ngây hiểu lầm cho người đọc, vì trong các lĩnh vực ấy nó chỉ có thể thay thế cho cụm \n\ntừ cố định nào đó, hoặc do thói quen, sử dụng nhiều thì mọi người đều biết. \n\nVí dụ: UBND thường được dùng thay thế cho \u201cỦy ban nhân dân\u201d \n\nTrong giải thuật này chỉ xử lý các cụm từ viết tắt chữ đầu trong ngoặc đơn, còn \n\ncác trường hợp khác do chưa xây dựng được bộ dữ liệu cụ thể nên không xét đến. \n\nCác cụm từ trong ngoặc đơn khác sẽ bị xóa đi. \n\n1.1.2. Tách câu, tách từ \n\nTrong tiếng Việt, dấu cách (space) không được sử dụng như 1 kí hiệu phân tách \n\ntừ, nó chỉ có ý nghĩa phân tách các âm tiết với nhau, có khoảng 70% các từ gồm 2 âm \n\ntiết, và 14% các từ gồm 3 âm tiết, còn lại là 1 âm tiết. Hơn nữa, việc kết hợp các âm \n\ntiết có nhiều cách, mỗi cách cho một nghĩa khác nhau. Vì thế, để xử lý tiếng Việt, bài \n\ntoán tách từ (word segmentation) là 1 trong những bài toán cơ bản và quan trọng bậc \n\nnhất. Ngoài tiếng Việt, có khá nhiều các ngôn ngữ châu Á khác cũng cần bước tách \n\ntừ, ví dụ như: tiếng Nhật, tiếng Trung, tiếng Hàn,\u2026 do đó vấn đề này nhận được sự \n\nquan tâm rộng rãi và có nhiều hướng tiếp cận khác nhau. \n\nMột số phương pháp có thể áp dụng: \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 30 \n\n   \n\no So khớp từ dài nhất (Longest Matching) \n\no So khớp cực đại (Maximum Matching) \n\no Mô hình Markov ẩn (Hidden Markov Models- HMM) \n\no Học dựa trên sự cải biến (Transformation-based Learning \u2013 TBL) \n\no Chuyển đổi trạng thái trọng số hữu hạn(Weighted Finite State Transducer) \n\no Độ hỗn loạn cực đại (Maximum Entropy \u2013 ME) \n\no Máy học sử dụng vectơ hỗ trợ (Support Vector Machines) \n\no Trường xác xuất có điều kiện (CRFs) \n\nBài toán tách từ khá phức tạp, do đó việc tách từ trong bước này sẽ sử dụng công \n\ncụ VNTokenizer, được phát triển bởi nhóm tác giả Lê Hồng Phương. \n\nĐây là công cụ tách từ tự động cho tiếng Việt, mã nguồn mở, được viết bằng ngôn \n\nngữ Java. Phiên bản cũ nhất là phiên bản vnTokenizer 2.0 được xây dựng vào năm \n\n2005 khi đó nó mới là một ứng dụng đơn với giao diện đơn giản. Để sử dụng trong \n\nchương trình lần này, phiên bản mới nhất 4.1.1c, mã nguồn của công cụ được tải tại \n\nwebsite của dự án VLSP [6]. \n\nCông cụ này được xây dựng sử dụng kết hợp từ điển (từ điển tiếng Việt được lấy \n\ntừ đề tài VLSP) và ngram, trong đó mô hình ngram được huấn luyện sử dụng treebank \n\ntiếng Việt (70,000 câu đã được tách từ), treebank là kho ngữ liệu câu được chú giải \n\nngữ pháp. \n\nVới độ chính xác xấp xỉ 97% (theo thống kê của tác giả trên website) là kết quả \n\nrất cao so với công cụ tách từ hiện nay. \n\nNgoài ra việc tách câu khá đơn giản nhưng cần xử lý các trường hợp nhập nhằng \n\ndấu chấm câu và dấu chấm trong từ(trong email, số thập phân, địa chỉ web). Do đó \n\nđể tiết kiệm thời gian, việc tách câu trong phần này sử dụng luôn modul tách câu \n\ntrong công cụ VNTokenizer. \n\n1.1.3. Loại bỏ từ dừng \n\nTừ dừng (StopWord) là những từ thường xuất hiện nhiều trong các tài liệu nhưng \n\nthường chỉ mang ý nhấn mạnh, bổ nghĩa\u2026 nó có ý nghĩa lớn trong một số phương \n\npháp dựa trên dấu hiệu đặc biệt, nhưng trong phương pháp dựa trên tần số từ đang \n\nxét thì các từ này làm giảm độ chính xác. Trong giải thuật này chủ yếu dựa trên trọng \n\nsố từ nên việc loại bỏ từ dừng là rất cần thiết. \n\nTừ dừng sẽ được loại bỏ nhờ một danh sách từ dừng xây dựng sẵn, tham khảo tại \n\n[7], sau khi tách từ, các từ xuất hiện trong từ điển từ dừng sẽ bị xóa. Dưới đây là một \n\nsố từ dừng trích trong file sẽ sử dụng. \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 31 \n\n   \n\nthậm chí vì vậy tuy nhiên \n\nthật ra với lại thế là \n\ntrước kia đáng lẽ sau cùng \n\ntuy vậy ắt hẳn quả thật \n\nBảng 1: Ví dụ một số từ dừng \n\nNgoài ra ở bước này, các dấu câu, dấu phảy cũng bị xóa vì nó cũng giống từ dừng. \n\n1.1.4. Xử lý từ đồng nghĩa \n\nCó 3 loại từ đồng nghĩa cần xét đến: \n\n Từ có nghĩa giống nhau hoặc gần giống nhau. \n\nVí dụ: siêng năng, chăm chỉ, cần cù, \u2026 \n\n Từ đồng nghĩa hoàn toàn \n\nVí dụ: hổ, cọp, hùm, \u2026 \n\n Từ đồng nghĩa không hoàn toàn \n\nVí dụ:  \n\nĂn, xơi, chén, \u2026(biểu thị thái độ, tình cảm khác nhau đối với người đối \n\nthoại hoặc điều được nói đến). \n\nMang, khiêng, vác, \u2026(biểu thị những cách thức hành động khác nhau). \n\nVới loại 1 và loại 2 thì các từ đồng nghĩa có thể thay thế cho nhau. Còn loại 3 thì \n\nphải xét đến ngữ nghĩa của từ trong ngữ cảnh của văn bản, đây có thể coi là bài toán \n\nphức tạp nhất trong xử lý ngôn ngữ, hiện nay chưa có nhiều nghiên cứu. \n\nViệc xử lý từ đồng nghĩa là rất quan trọng, nhất là trong bài toán tóm tắt hướng \n\ntruy vấn. Trong mô hình lần này, do chỉ xử lý ở mức nông, nên không xét đến các \n\nvấn đề ở mức cú pháp và ngữ nghĩa, nhưng để tăng độ chính xác, bài toán sẽ sử dụng \n\nviệc đồng nhất các từ đồng nghĩa(xử lý chung cho cả 3 loại trên) dựa trên từ điển \n\nđồng nghĩa thô xây dựng sẵn, bộ từ điển này gồm gần 2800 mục, xây dựng bằng cách \n\ndùng công cụ tải các trang của từ điển Việt \u2013 Việt tại trang tratu.soha.vn, sau đó tách \n\nthẻ có chứa các từ đồng nghĩa rồi ghép lại. Mỗi mục gồm các từ gần nghĩa hoặc đồng \n\nnghĩa với nhau về mặt nào đó, và mỗi từ chỉ xuất hiện trong một mục, trên thực tế có \n\nnhững từ có thể ở nhiều mục, nhưng số lượng các từ đó không nhiều nên trong bộ từ \n\nđiển này sẽ sử dụng nghĩa phổ biến nhất của các từ đó. Tuy chưa được đầy đủ và xử \n\nlý đơn giản nhưng cũng góp phần tăng độ chính xác cho việc tóm tắt. Dưới đây là \n\nmột số mục từ trong bộ từ đồng nghĩa sẽ sử dụng. \n\n \n\nhttp://tratu.soha.vn/\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 32 \n\n   \n\nlãnh thổ, bờ cõi, biên thuỳ, biên giới,biên cương \n\nrỗi rãi, rỗi, rảnh rỗi, rảnh rang, rảnh \n\nthương nhân, nhà buôn, thương gia, doanh nhân, doanh gia \n\nquả cảm, gan góc, dũng cảm, gan dạ, dũng mãnh, can đảm, anh dũng \n\ntả, mô tả, miêu tả, diễn tả, diễn đạt, biểu đạt \n\nBảng 2: Một số mục từ đồng nghĩa \n\nSau bước tách từ và loại bỏ từ dừng, các câu sẽ được xử lý theo theo cách duyệt \n\ntất cả các từ, với mỗi từ, tìm từ đó trong từ điển đồng nghĩa, nếu có thì thực hiện thay \n\nthế từ đó bằng từ đầu tiên trong mục từ chứa nó. \n\n1.1.5. Mô hình hóa văn bản \n\nViệc cuối cùng trong giai đoạn tiền xử lý là mô hình hóa văn bản, sử dụng mô \n\nhình không gian vector. Tương tự các công thức dùng để mô hình hóa văn bản ở trên, \n\nđể mô hình hóa câu, ta sử dụng công thức sau TF.ISF, công thức này tương tự như \n\nTF.IDF nhưng các thông số ở trong phạm vi câu và văn bản. Cụ thể mỗi từ tần số của \n\nmỗi từ wi trong câu sj  được tính như sau: \n\n \n\nTrong đó: \n\nfij là số lần xuất hiện của từ ti trong câu sj, \n\nm là tổng số câu trong văn bản \n\nhi là tổng số câu mà từ ti xuất hiện. \n\nα là hệ số đánh giá độ quan trọng của từ, nếu từ xuất hiện trong truy \n\nvấn thì α>1, còn lại thì α=1 \n\nVới hệ số α cho từ xuất hiện trong truy vấn, trong quá trình kiểm thử trên tập mẫu \n\nthì α=4  cho kết quả tốt nhất. \n\n1.1.6. Chọn câu phù hợp tạo tóm tắt \n\nBước này sẽ áp dụng các giải thuật đánh giá câu quan trọng để đưa vào kết quả \n\ntóm tắt. Để hạn chế hiện tượng trùng lặp thông tin trong kết quả tóm tắt, trước khi \n\nđưa vào lựa chọn, các câu sẽ được so sánh với nhau để tìm các câu gần tương tự nhau, \n\nvà loại bỏ câu có vị trí xa tiêu đề hơn. Độ đo sử dụng để loại bỏ câu trùng lặp và chọn \n\ncâu phù hợp tạo tóm tắt là độ đo cosin đã trình bày ở trên, nhưng hai vector được tính \n\ntoán bây giờ là biểu diễn cho hai câu. \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 33 \n\n   \n\nGiải thuật loại bỏ câu trùng lặp như sau: \n\nBước 1: xét câu si, tính độ tương đồng với các câu sau nó sj \n\nBước 2: với mỗi câu sj, nếu độ tương đồng Ωij>α thì loại bỏ câu sj \n\nBước 3: nếu hết văn bản thì dừng lại, không thì tăng i lên 1 và quay lại bước 1 \n\nQua thực nghiệm trên một số văn bản, cho thấy ngưỡng α=0.8 cho kết quả tương \n\nđối chính xác. Do đó trong bước này sẽ thực hiện loại bỏ một câu nếu có độ tương tự \n\nlớn hơn 0.8 với câu nào đó đứng trước nó, theo thứ tự vị trí trong văn bản. \n\nQuá trình chọn câu quan trọng sẽ thực hiện như hình dưới đây \n\n \n\nHình 4: Minh họa quá trình chọn câu quan trọng \n\nSau khi chuyển biểu diễn các câu về mô hình không gian vector, mỗi câu sẽ là \n\nmột vector, văn bản là danh sách các vector, độ tương đồng giữa các câu sẽ được tính \n\ntoán sử dụng độ đo cosin.  \n\nGiải thuật chọn câu theo các bước sau: \n\nBước 1: khởi tạo tâm là truy vấn \n\nBước 2: tính độ tương đồng Ω của các câu trong văn bản với tâm \n\nBước 3: chọn câu có Ω lớn nhất, kết hợp vào tâm, xóa câu đó khỏi văn bản \n\nBước 4: kiểm tra độ dài, nếu chưa đủ, tính toán lại tâm và quay lại bước 2 \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 34 \n\n   \n\nTâm của tóm tắt sẽ được tính toán lại dựa trên công thức tính vector trọng tâm \n\ncủa nhóm, và độ tương tự của 1 câu với tâm sẽ là độ tương tự với vector đó. \n\n*) Véc tơ trọng tâm của nhóm \n\nGiả sử có một tập câu = {s1, s2, \u2026, sm} có lần lượt các véc tơ biểu diễn là v1, v2, \n\n\u2026, vm. Khi đó, véc tơ trọng tâm của tập câu được tính theo công thức: \n\n1\n\nm\n\ni\n\ni\ncen\n\nv\n\nV\nm\n\n\n\n\n \n\n \n\n1.2. Giai đoạn hiển thị \n\nỞ bước này, văn bản tóm tắt sẽ được tạo ra bằng cách ghép các câu được chọn \n\ntheo thứ tự trong văn bản, đó chính là phương pháp hiển thị phân đoạn. \n\n  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 35 \n\n   \n\nII. CÀI ĐẶT THỬ NGHIỆM \n\n2.1. Chương trình thử nghiệm \n\nĐể thực hiện thử nghiệm em đã xây dựng một số công cụ phục vụ tóm tắt 1 văn \n\nbản, công cụ tạo mẫu và công cụ kiểm thử trên mẫu: \n\n- Môi trường cài đặt: Java JDK 7u17, Windows 7 32bit. \n\n- Công cụ lập trình Netbeans 7.3. \n\n2.1.1. Các công cụ đã xây dựng \n\n2.1.1.1. Chương trình tóm tắt \n\nĐây là chương trình thực hiện tóm tắt một văn bản dựa trên giải thuật đã phân \n\ntích ở trên. Chi tiết các chức năng đã ghi chú đầy đủ trên ảnh giao diện chương trình. \n\nĐầu vào của chương trình là văn bản gốc, truy vấn, và độ rút gọn, đầu ra sẽ là văn \n\nbản tóm tắt, có thể xem chi tiết một số bước xử lý ở chức năng Note góc dưới trái \n\ngiao diện. \n\n \n\nHình 5: Giao diện chương trình demo \n\n2.1.1.2. Công cụ tạo tập mẫu \n\nCông cụ này hỗ trợ, tạo, chỉnh sửa các bản tóm tắt thủ công. Chức năng chính là \n\nquản lý các văn bản mẫu bao gồm văn bản gốc và bản tóm tắt thủ công, được tích \n\nhợp chức năng tách từ, tách câu của VNTokenizer nên việc tạo văn bản mẫu sẽ chính \n\nxác và hiệu quả hơn. Ngoài ra còn có chức năng phát hiện ra các văn bản lỗi font, các \n\nvăn bản này không thể sử dụng trong các công cụ đi kèm nên cần loại bỏ. \n\n \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 36 \n\n   \n\n \n\nHình 6: Chương trình quản lý tập mẫu \n\n2.1.1.3. Công cụ kiểm thử \n\nCông cụ này được xây dựng dựa trên việc tích hợp giải thuật đã đề xuất ở trên và \n\ntích hợp thêm hai giải thuật để so sánh, việc so sánh dựa trên độ đo BLEUS, chi tiết \n\nvề cách thực hiện sẽ trình bày ở phần sau. \n\n \n\nHình 7: Giao diện chương trình kiểm thử \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 37 \n\n   \n\n2.2. Thử nghiệm một văn bản \n\nPhần này em sử dụng công cụ tóm tắt đã xây dựng để thử nghiệm một văn bản. \n\nKết quả thực hiện thu được như sau: \n\n2.2.1. Đầu vào \n\n Văn bản: \n\nBảo vệ vững chắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình{1} \n\nChiều ngày 26-4, Chủ tịch nước Trương Tấn Sang và Tổ Đại biểu Quốc hội \n\n(ĐBQH) số 1, Đoàn ĐBQH TP Hồ Chí Minh tiếp tục có buổi tiếp xúc với gần 400 cử \n\ntri của quận 1{2}. Ghi nhận các ý kiến của cử tri, Chủ tịch nước đánh giá cao tinh \n\nthần đóng góp ý kiến của mọi người, nhất là vấn đề sửa đổi Hiến Pháp và các đạo \n\nluật{3}. Trả lời câu hỏi được đông đảo cử tri quan tâm về chủ trương bảo vệ chủ \n\nquyền lãnh thổ, củng cố quốc phòng - an ninh, Chủ tịch nước Trương Tấn Sang khẳng \n\nđịnh chủ trương của Đảng, Nhà nước trước sau như một là kiên quyết bảo vệ vững \n\nchắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình, theo hệ thống luật pháp \n\nquốc tế{4}. Tuy nhiên, Chủ tịch nước cũng khẳng định \u201ckhông bao giờ bảo vệ chủ \n\nquyền bằng nói miệng\u201d; chủ trương hòa hiếu không có nghĩa là không làm gì{5}. \n\nNước ta cũng mua sắm trang bị vũ khí, nhưng không phải để gây chiến tranh, chạy \n\nđua vũ trang mà là tăng cường phòng thủ, bảo vệ chủ quyền lãnh thổ{6}. Chủ tịch \n\nnước cho biết, chủ trương hòa hiếu luôn được các nước bạn bè trên thế giới ủng \n\nhộ{7}. \n\nĐề cập đến tình hình biển, đảo, Chủ tịch nước bày tỏ thông cảm với những lo \n\nlắng, bức xúc của cử tri, mong cử tri phải bình tĩnh, không nghe những lời kích động \n\ncủa kẻ xấu{8}. Những mâu thuẫn trên Biển Đông là có, nhưng biện pháp hòa hiếu \n\ncủa nước ta đã có kết quả tốt, Nhà nước luôn hỗ trợ ngư dân ra khơi, số lượng tàu \n\ncá đánh bắt xa bờ ngày càng tăng{9}. Nước ta phấn đấu đến năm 2020 sẽ phát triển \n\nkinh tế biển đạt 52%-53% GDP, trong đó, dầu khí, vận tải biển, đánh bắt hải sản là \n\nthế mạnh lớn{10}. Mục tiêu cuối cùng của nước ta là chủ quyền lãnh thổ vững chắc, \n\nquốc phòng - an ninh ổn định, kinh tế phát triển{11}. \n\nLiên quan đến các vấn đề kinh tế - xã hội, Chủ tịch nước Trương Tấn Sang cho \n\nbiết kinh tế nước nhà có những phát triển đáng kể, nông nghiệp đạt nhiều thắng lợi, \n\ncác ngành thuộc về dầu khí tăng trưởng khá{12}. Tuy nhiên, Chủ tịch nước mong cử \n\ntri hiểu kinh tế Việt Nam dùng chủ yếu là tiền mặt, nên sẽ có những hệ quả về giá cả \n\nthị trường, thu nhập người dân liên quan đến việc tăng lương, tăng giảm giá vàng, \n\ngiá xăng, dầu{13}. \n\nTổng số 259 từ / 13 câu \n\n Câu truy vấn: bảo vệ chủ quyền lãnh thổ \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 38 \n\n   \n\n Độ rút gọn: 100 từ \n\n2.2.2. Kết quả tóm tắt \n\nKết quả được chọn theo thứ tự 4, 11, 6, 5, 7, 9 tổng số 111 từ / 6 câu \n\n{4} Trả lời câu hỏi được đông đảo cử tri quan tâm về chủ trương bảo vệ chủ \n\nquyền lãnh thổ, củng cố quốc phòng - an ninh, Chủ tịch nước Trương Tấn Sang khẳng \n\nđịnh chủ trương của Đảng, Nhà nước trước sau như một là kiên quyết bảo vệ vững \n\nchắc độc lập chủ quyền lãnh thổ bằng biện pháp hòa bình, theo hệ thống luật pháp \n\nquốc tế. \n\n{5} Tuy nhiên, Chủ tịch nước cũng khẳng định \u201ckhông bao giờ bảo vệ chủ quyền \n\nbằng nói miệng\u201d; chủ trương hòa hiếu không có nghĩa là không làm gì. \n\n{6} Nước ta cũng mua sắm trang bị vũ khí, nhưng không phải để gây chiến tranh, \n\nchạy đua vũ trang mà là tăng cường phòng thủ, bảo vệ chủ quyền lãnh thổ. \n\n{7} Chủ tịch nước cho biết, chủ trương hòa hiếu luôn được các nước bạn bè trên \n\nthế giới ủng hộ. \n\n{9} Những mâu thuẫn trên Biển Đông là có, nhưng biện pháp hòa hiếu của nước \n\nta đã có kết quả tốt, Nhà nước luôn hỗ trợ ngư dân ra khơi, số lượng tàu cá đánh bắt \n\nxa bờ ngày càng tăng. \n\n{11} Mục tiêu cuối cùng của nước ta là chủ quyền lãnh thổ vững chắc, quốc phòng \n\n- an ninh ổn định, kinh tế phát triển. \n\n2.2.3. Nhận xét \n\nSau khi chạy thử nghiệm trên một số văn bản, em nhận thấy kết quả tóm tắt khá \n\nchính xác, đã nêu lên được các vấn đề liên quan tới truy vấn mà trong văn bản trình \n\nbày. Để đánh giá chất lượng thực sự của mô hình, trong phần sau sẽ thực hiện kiểm \n\nthử trên lượng dữ liệu đủ lớn. \n\n2.3. Thử nghiệm trên tập mẫu \n\n2.3.1. Dữ liệu thử nghiệm \n\nCác mẫu trong thử nghiệm lần này được tạo ra bằng cách sử dụng công cụ hỗ trợ \n\nđã nêu ở trên với văn bản mẫu là các bài báo trên các báo điện tử: \n\no http://vnexpress.net/ \n\no http://laodong.com.vn/ \n\no http://dantri.com.vn/ \n\nCác bài báo sử dụng được lấy từ các chuyên mục: Văn hóa, Xã hội, Chính trị, \n\nPháp luật, Kinh tế. \n\nhttp://vnexpress.net/\nhttp://laodong.com.vn/\nhttp://dantri.com.vn/\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 39 \n\n   \n\nĐộ dài mỗi bản tóm tắt thủ công là xấp xỉ 120 từ. Bảng mã Unicode utf-8, định \n\ndạng .txt, số lượng 50 mẫu. \n\nThông tin độ dài của tập mẫu được trình bày ở bảng dưới đây: \n\n Lớn nhất Nhỏ nhất Trung bình \n\nĐộ dài văn bản theo từ (đã loại bỏ từ dừng) 823 180 371 \n\nĐộ dài văn bản theo câu 35 9 18 \n\nBảng 3: Thông tin tập mẫu sử dụng để đánh giá \n\n2.3.2. Độ đo BLEUS \n\nĐộ đo sẽ sử dụng trong phần đánh giá này là BLEUS, cải tiến của độ đo BLEU, \n\nsử dụng cho n-gram của từ. \n\n N-gram \n\nN-gram của từ là chuỗi gồm n từ, tập các n-gram của một văn bản được tạo nên \n\nbằng cách ghép n từ liên tiếp cho tới khi hết văn bản. \n\nN-gram Hôm_nay trời mưa to \n\nUnigram(1-gram) Hôm_nay, trời, mưa, to \n\nBigram(2-gram) Hôm_nay trời, trời mưa, mưa to \n\nTrigram(3-gram) Hôm_nay trời mưa, trời mưa to \n\nFourgram(4-gram) Hôm_nay trời mưa to \n\nBảng 4: Ví dụ về n-gram \n\n Độ đo BLEUS \n\nBLEU là độ đo dựa trên sự đồng hiện của các n-gram, bao gồm 1-gram, 2-gram, \n\n3-gram, 4-gram. \n\nCông thức của độ đo này như sau: \n\n \n\nTrong đó: \n\nD1 là bản tóm tắt tự động(do chương trình tạo ra) \n\nD2 là bản tóm tắt thủ công \n\nXk là số k-gram trùng nhau ở hai văn bản \n\nYk là số k-gram trong văn bản D1 \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 40 \n\n   \n\nβ là điểm phạt, được tính như sau: \n\n \n\n với a là số 1-gram trong D2, b là số 1-gram trong D1 \n\nNhược điểm của độ đo BLEU là sẽ trả về 0 nếu như hai văn bản không có 4-gram \n\nnào trùng nhau, do đó ta sẽ sử dụng một dạng khác của BLEU đó là BLEUS \n\n[11](Smooth BLEU). Độ đo này khắc phục nhược điểm của độ đo BLEU bằng cách \n\nthay Xk  = 0 thành 2-n, cụ thể như sau:  \n\n- Nếu k=2 thì X2=1/2, X3=1/4, X4=1/8  \n\n- Nếu k=3 thì X3=1/2, X4=1/4 \n\n- Nếu k=4 thì X4=1/2 \n\n2.3.3. Kết quả thử nghiệm \n\nĐể tính toán kết quả, mỗi mẫu sẽ được thực hiện để tạo bản tóm tắt và thực hiện \n\ntính điểm BLEUS, chi tiết như sau: \n\nBước 1: Tải văn bản gốc và văn bản tóm tắt tương ứng, tách tiêu đề của văn bản \n\ngốc làm truy vấn. \n\nBước 2: Gọi modul tóm tắt với đầu vào là văn bản gốc và độ rút gọn 120 từ. \n\nBước 3: Thực hiện tách từ (sử dụng công cụ vntokenizer) cho văn bản tóm tắt thủ \n\ncông và văn bản tóm tắt tự động. \n\nBước 4: Tính điểm số dựa vào độ đo BLEUS cho từng kết quả tóm tắt. \n\nBước 5: Hiển thị kết quả lên giao diện. \n\nSau khi thực hiện giải thuật đánh giá, kết quả thống kê thu được như sau: \n\n Lớn nhất Nhỏ nhất Trung bình \n\nĐiểm số 0.806 0.254 0.518 \n\nBảng 5: Kết quả kiểm thử độ đo BLEUS của tập mẫu \n\nMột số nhận xét về kết quả kiểm thử: \n\n- Tốc độ thực hiện nhanh (trung bình khoảng 60ms) \n\n- Theo Papineni và đồng sự [9], thì độ đo BLEU từ 0.3 là chấp nhận được, từ \n\n0.5 là tương đối tốt, như vậy thì điểm số trung bình của mẫu là tương đối tốt, \n\nmột số mẫu có điểm số nhỏ nhưng số lượng không đáng kể \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 41 \n\n   \n\n2.3.4. Nhận xét, đánh giá mô hình \n\n- Ưu điểm: tốc độ nhanh, kết quả tóm tắt tương đối tốt, không cần sử dụng dữ \n\nliệu học. \n\n- Nhược điểm: vẫn mang nhược điểm của phương pháp tóm tắt trích rút là đứt \n\nmạch, nhập nhằng tham chiếu \n\n- Khả năng ứng dụng: với tốc độ thực hiện nhanh, cài đặt đơn giản, tuy vẫn có \n\nnhược điểm của tóm tắt trích rút nhưng mô hình này hoàn toàn có thể cài đặt \n\nsử dụng trong thực tế, vì với máy tìm kiếm thì đưa ra thông tin quan trọng hơn \n\nsự liền mạch của văn bản tóm tắt. \n\n \n\n  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 42 \n\n   \n\nPHẦN 3. KẾT LUẬN VÀ ĐỀ XUẤT \n\n1. Các công việc đã thực hiện được \n\nVề cơ bản, đồ án đã thực hiện được các mục tiêu đề ra ban đầu: \n\n- Tìm hiểu về tóm tắt văn bản tự động \n\n- Đề xuất và phân tích các bước thực hiện một mô hình tóm tắt văn bản \n\nhướng truy vấn cho tiếng Việt \n\n- Cài đặt chương trình thử nghiệm và đánh giá kết quả \n\nTuy nhiên, do tài liệu tham khảo chưa nhiều và thời gian có hạn nên vẫn còn một \n\nsố việc chưa thực hiện hoặc chưa tốt: \n\n- Cơ sở lý thuyết trình bày còn sơ sài \n\n- Độ chính xác của dữ liệu thử nghiệm chưa cao và số lượng còn ít dẫn đến \n\nkết quả đánh giá chưa thật chính xác \n\n2. Đề xuất hướng phát triển \n\nNhằm tăng chất lượng của mô hình để đưa vào ứng dụng thực tế, em có một số \n\nđề xuất như sau: \n\n- Xử lý chi tiết các từ viết tắt \n\n- Tích hợp phân giải đồng tham chiếu \n\n- Có một giải thuật xác định từ dừng thay vì dùng danh sách có sẵn \n\n- Xây dựng từ điển đồng nghĩa đầy đủ và chính xác hơn \n\n- Có thêm modul xử lý các bảng mã khác nhau \n\n \n\n  \n\n\n\n  \n\nHoàng Đức Thọ    20082559    Lớp Hệ Thống Thông Tin    K53 Trang 43 \n\n   \n\nTÀI LIỆU THAM KHẢO \n\n \n\n Danh sách tài liệu \n\n[3]  Ahmed A. Mohamed; Sanguthevar Rajasekaran, \"Query-Based \n\nSummarization Based on Document Graphs,\" Author, Mansfield, Connecticut, US, \n\n2006. \n\n[4]  Wauter Bosma, \"Query-Based Summarization using Rhetorical Structure \n\nTheory,\" in Human Media Interaction, Enschede The Netherlands, 2003.  \n\n[5]  A. P. Siva kumar ; Dr. P. Premchand; Dr. A. Govardhan, Query-Based \n\nSummarizer Based on Similarity of Sentences and Word Frequency, JNTUACE \n\nAnantapur, India: International Journal of Data Mining & Knowledge Management \n\nProcess, 2011.  \n\n[8]  Chin-Yew Lin and Franz Josef Och, ORANGE: a Method for Evaluating \n\nAutomatic Evaluation Metrics for Machine Translation, Stroudsburg, PA, USA: \n\nAssociation for Computational Linguistics, 2004.  \n\n[9]  Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, \"BLEU: a \n\nMethod for Automatic Evaluation of Machine Translation,\" in 02 Proceedings of \n\nthe 40th Annual Meeting on Association for Computational Linguistics, \n\nStroudsburg, PA, USA, 2002.  \n\n[12]  Lê Quý Tài, \"Nghiên cứu các phương pháp xử lý tiếng Việt ứng dụng cho \n\ntóm tắt văn bản,\" Luận văn thạc sĩ, Hà Nội, 2011. \n\n \n\nDanh sách website \n\n[1]  \"BLEU - Wikipedia,\" Wikipedia, [Online]. Available: \n\nhttp://en.wikipedia.org/wiki/BLEU. [Accessed 10 05 2013]. \n\n[2]  Wikipedia, \"ROUGE Metric,\" Wikipedia, [Online]. Available: \n\nhttp://en.wikipedia.org/wiki/ROUGE_(metric). [Accessed 30 05 2013]. \n\n[6]  \"Xử lý văn bản,\" [Online]. Available: \n\nhttp://vlsp.vietlp.org:8080/demo/?page=resources. [Accessed 09 05 2013]. \n\n[7]  \"KLTN10-wiki,\" [Online]. Available: https://code.google.com/p/kltn10-\n\nwiki/source/browse/. [Accessed 18 5 2013]. \n\n[10]  \"N-Gram Wikipedia,\" [Online]. Available: http://en.wikipedia.org/wiki/N-\n\ngram. [Accessed 09 05 2013]. \n\n[11]  \"KantanMt.com,\" [Online]. Available: \n\nhttp://www.kantanmt.com/whatisbleuscore.php. [Accessed 10 05 2013]. \n\n\n","m":[13608,-1],"n":"2019.08.08.01.41.26QMXCOE5B.pdf"}}